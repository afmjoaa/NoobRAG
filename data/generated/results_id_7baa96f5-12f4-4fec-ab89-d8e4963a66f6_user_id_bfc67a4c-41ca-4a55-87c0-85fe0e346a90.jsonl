{"question":"How do North African harissa marinade and Thai massaman curry compare in terms of their coconut content?","answer":"While harissa paste used for marinades in North African cuisine does not contain coconut as an ingredient (it's primarily made with chilies, spices, and olive oil), Thai massaman curry is specifically characterized by its coconut flavor. Thai cuisine commonly uses coconut milk as one of its main flavorings, and massaman is described as a yellow Thai curry with a distinctive coconut flavor.","context":["Harissa is a favourite spicy condiment from North Africa found mainly in Tunisia, Morocco and Algeria. Tunisian cuisine commonly includes all kinds of exciting variations of harissa in predominantly chicken, seafood and lamb dishes. Not as scarce as you might think in the rest of the world, harissa paste can be bought readymade in tubes and tubs in certain stores and delis. However, a good base harissa paste is really quick and easy to make and it’s so much tastier than the store bought versions. Depending on your taste preferences and those of your guests you can make it as hot, sweet or smoky as you like. What is important is your choice of chilli. The type of chilli you use will impact flavour and kick. For a very mild harissa you can use roasted red bell peppers instead of chilli. We use bell peppers with a touch of chilli to give ours a light zing so as not to overpower diners with spice-sensitive palettes.\nRecipe by: GOLD Restaurant\nServes: 8 (starter)\nPreparation: 30 minutes (plus two hours for marinating)\nCooking: 30 minutes (frying)\nT = tablespoon\nt = teaspoon\n- 2 medium red peppers and 1 red chilli OR 6 red chillies\n- 1 ½ t caraway seeds\n- 1 ½ t coriander seeds (or fresh)\n- 3 T garlic, finely chopped\n- 3 T extra virgin olive oil for paste\n- 1 ½ cups vegetable oil for frying\n- 1 cup boiling water to soak chillies (chilli-only recipe)\n- ¼ cup boiling water to soak chilli (red pepper and chilli recipe)\n- ½ cup freshly squeezed lemon juice\n- 16 medium-sized chicken wings (or small drumsticks)\n- Salt to taste\nTo make the harissa paste:\nIf you are following the spicier chilli-only recipe, place the chillies in a bowl. Add a cup of boiling water and allow them to soak for 20 minutes or so until soft.\nRed pepper and chilli recipe\nIf you are following the red pepper and chilli recipe, slice your peppers lengthways into long quarters. Remove the stems and seeds. Place the quarters in a skillet for 2 to 3 minutes on a medium heat and dry roast to char slightly on both sides. Remove peppers, allow them to cool and chop finely. Soak your chilli in a small bowl with ¼ cup of boiling water for 20 minutes or so until soft.\n- Place the caraway, coriander and cumin spices in a skillet and dry fry over a low to medium heat for a minute, swirling them to prevent burning. You can tell they’re ready after 3 minutes or so when they become fragrant.\n- Remove the skillet from the heat and transfer the roasted spices to a grinder and blitz (or mortar and pestle and grind) until powdery.\n- Drain the chilli/chillies and reserve the liquid for later.\n- Remove and discard the seeds and stems of your chillies. If you are following the red pepper and chilli recipe you will have already done this in Step 1.\n- Combine the chillies and/or red peppers and all the dry ingredients in the bowl of a food processor (or use your mortar and pestle). Put the food processor on low and slowly pour in the extra virgin olive oil to form a puréed, thick paste. If you want your paste a little thinner add some of the reserved chilli water until you get the consistency you want.\nTo prepare and cook the chicken:\n- Place your wings or drumsticks in a bowl and season with salt. Add your harissa paste to the bowl and rub it into the chicken with your hands. Cover and leave to marinate for at least two hours.\n- Fry the wings or drumsticks in a pan in hot oil on a medium heat until the skin on both sides is crispy.\n- Serve hot.\n- Harissa paste can pre prepared and kept in the refrigerator for up to three weeks. In fact, the flavour deepens if left for a day or two. If you have left over paste keep it in a sealed jar with a thin layer of extra virgin olive oil poured conservatively on top before sealing. Every time you use the harissa, add a fresh thin layer of olive oil.\n- You can also add to your harissa paste, fresh or dried mint, fresh cilantro, tomatoes, cayenne pepper or paprika. It all depends on your personal preference. Have fun creating your own signature brand of harissa paste.","Thai food is known worldwide for its quality, diversity of flavors and textures and its imaginative use of food combinations. With its unique blend of hot, spicy, sweet, sour, bitter and piquant flavors, Thai food is hugely appealing to the modern palate.\nHistorically, Thai food has drawn its main influences from India and China. In addition, Thailand”s close proximity to Vietnam, Burma and Cambodia has had a major impact on the evolution of modern Thai cuisine. Modern Thai food, however, has somehow managed to retain its identity while incorporating the best of what neighboring cuisines have to offer.\nRegional Thai Food\nEach region of Thailand has its own distinct style of cooking. Northern and Northeastern Thai food, for example, is influenced by the cuisine of Laos and Burma, whereas Southern Thai food has its origins in Malaysian-style cooking. In central Thailand the cuisine is remarkably similar to the typical Thai food served in Thai restaurants abroad.\nThai Food Staples\nHere are a few Thai food staples:\nRice: Rice is a traditional, staple Thai food and has always been the most important dish (along with noodles) in any Thai meal.\nRice is served as a main course, in Thailand, rather than as an accompaniment. Long-grain rice is more common in Northern Thailand, with “sticky,” short-grain rice found mainly in the Southern regions. Jasmine rice originates from Thailand and is much sought after throughout the regions for its delicate, subtle flavors.\nFish: Fish, as a main ingredient or as a flavoring, is featured in numerous authentic Thai recipes. As nam pla (fish sauce), kapee (shrimp paste), jim (a dip) or simply as a food item served on its own, raw or cooked, Thai cuisine is based on a mind-boggling variety of different fish dishes.\nFlavorings and Other Staples\nThe main flavorings used in Thai food include:\n- black pepper\n- coconut milk\n- kaffir lime\nA popular flavoring ingredient in all Thai food is a roasted chili paste called nahm prik pow. Made by mixing a variety of ingredients such as shrimp paste, garlic and more, this secret ingredient is what gives many Thai dishes that extra kick.\nThai Food Facts\nHere are a few little-known facts about Thai food:\n- Chili peppers, a staple ingredient in Thai recipes, were first introduced from Portugal in the early 16th century.\n- Contrary to popular belief, peanut sauce is rarely used in Thai food, except for preparing Western-style satay.\n- “Kaeng” is the Thai word for curry.\n- Thai food is usually steamed, stir-fried or grilled.\nThai Food and Table Etiquette\nThe ritual of sharing is central to Thai table etiquette. Thai food is generally cut into small pieces before serving in order to make sharing easier in polite company.\nAt the start of the meal each guest is customarily served a separate bowl of rice. The accepted etiquette involves placing a spoonful or two of rice on a plate and then taking one of the accompanying dishes that have been arranged in the center to eat with the rice. Dipping into several curries or accompaniments at the same time is considered particularly bad form.\nThai food is usually consumed using a spoon and fork. The spoon is held in the right hand and used to place morsels of food into the mouth. The fork is used only for maneuvering the food and should never actually be placed in the mouth. Chopsticks are rarely used to eat Thai food, except for Chinese-style noodle dishes and rice porridge.\nRecommended Thai Recipes\nThai cuisine accommodates a variety of palates. Some popular recipes include:\n- tom yam gung: hot and sour seafood soup (often made with shrimp)\n- tom yam kung: prawn, lemongrass and mushroom soup\n- tom yam gai: hot and sour chicken soup\n- kaeng kiaw wan kai: a thick sauce with chunks of chicken and small pieces of eggplants\n- kaeng kiaw wan neua: beef curry\n- plaamuk thwad krathiem prik tai: squid fried with garlic and black pepper (also made with fish)\n- nua phat namman hoi: beef in oyster sauce\n- muu phat priew wan: sweet and sour pork\n- hormok talay: fish and seafood mousse\n- pad Thai: pan-fried rice noodles with morsels of meat and/or vegetables\n- kaeng pet: red hot chili-based curry with beef or pork\n- massaman: yellow Thai curry\n- penang neua: southern-style “dry” curry with a characteristic coconut flavor\n- som tam: grated papaya salad\n- sticky rice: a main dish popular in northern Thailand\n- larb gai: spicy Thai chicken salad\n- gai yang: marinated, grilled chicken\n- tom kha kai: thick coconut milk curry with chicken and lemongrass\n- khanom: delicious sweets typically made from coconut milk, fruit, especially bananas, and tapioca; custards, creams, puddings and cakes made from palm sugar, egg yolks and cooked in flower-scented syrups.\nThai food that is served by street vendors or in street-side, open-front food shops comes in two main varieties: wet (nam) and dry (haeng). When ordering Thai food, be sure to specify whether you want your food “nam” or “haeng.”\nDid You Know That …\nDid you know that popular lunch-time Thai foods such as thick shark”s fin soup, goose in soy sauce, roast duck with green vegetables and many mushroom-based dishes are actually derived from Chinese cuisine and have a distinct Cantonese flavor?"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:a819ce01-b1b4-4a46-9e9c-040c795e020b>","<urn:uuid:32824ec1-d8f2-4907-a3e5-9623637d6026>"],"error":null}
{"question":"I have both arthritis and trouble with high-impact exercise - how does a recommended warm-up routine differ between general fitness and arthritis-specific needs?","answer":"For arthritis sufferers, the warm-up needs to be longer and more thorough than for general fitness. While the average person can get by with a 5-minute warm-up, people with arthritis should do 10 minutes or longer. Both populations should include dynamic stretching exercises that mimic upcoming workout movements, avoid static stretching during warm-up, and gradually increase intensity. The warm-up should include four key components: loosening joints, stretching muscles, raising heart rate, and practicing movements. For arthritis specifically, it's recommended to do range-of-motion exercises first, and potentially use warm water to ease stiffness before exercising. The goal for both groups remains the same: to increase body temperature, heart rate, and breathing while preparing the body psychologically for exercise.","context":["Arthritis, whether it be osteoarthritis, rheumatoid or some other form, becomes more common with age, but that doesn’t mean you still can’t get a calorie-blasting, body-pumping workout. One of the best things for stiff, achy joints is movement. Research shows cardiovascular AND resistance exercise offer benefits for people with arthritis. People with arthritis who don’t exercise are at high risk for loss of bone mass, muscle atrophy, loss of flexibility and decreased functionality.\nHow does exercise help arthritis symptoms? Regular exercise strengthens the muscles that support the joints to help stabilize them. Plus, it helps with weight loss, and when you shed those extra pounds, it takes pressure off of the joints. Did you know each extra pound that you carry around adds four to six times greater pressure on your joints?\nAccording to the Arthritis Research Primary Care Center at Keele University in England, 25% of cases of knee arthritis can be blamed on being overweight or obese. Losing weight, if you’re overweight, is one of the best ways to take pressure off your joints and exercise can help you do that.\nOne of the biggest problems arthritis sufferers experience is stiffness, especially early in the morning. Exercise increases flexibility and range-of-motion and helps reduce rigidity. Unfortunately, there’s still the perception that exercise is bad for joints and can lead to joint damage, despite lack of scientific evidence. In fact, a number of studies show that regular exercise actually lowers the risk for arthritis of the knees and improves symptoms in people who already have the disease. As a result of research like this, the American College of Rheumatology encourages people with arthritis to stay active.\nGuidelines for Exercising with Arthritis\nDepending upon the extent of your arthritis, your doctor may recommend limiting the amount of high-impact exercise you do, activity that involves running or jumping. No problem. You can still get an effective cardiovascular workout with low-impact step training, spin classes, brisk walking, and circuit training.\nNot that you shouldn’t take precautions when exercising with arthritis. If you do high-impact workouts, alternate them with low-impact ones and give yourself adequate recovery time between your workouts. If you experience pain during a workout or feel stiff or sore afterward, you’re overdoing it. Remember, low impact doesn’t have to mean low intensity. If you experience a flare-up, take a day off and do stretching exercises to work on flexibility.\nCircuit training can be another joint-friendly way to exercise. Circuit training combines the benefits of a cardiovascular workout, assuming you don’t rest between exercises, with muscle endurance and can be a safe and effective form of exercise if you have arthritis. If a particular circuit training exercise feels uncomfortable, you can always modify it.\nRelieve Stiffness Before Exercising\nIf you have arthritis, you’re probably familiar with the stiffness you feel when you first get out of bed. Spend 10 minutes or so doing range-of-motion exercises to work out some of the stiffness and increase your flexibility. Then head for the shower and repeat range-of-motion exercises as the warm water rains down on your muscles and joints. The warm water will ease any stiffness and discomfort you might be having. If you exercise in the morning, do this before beginning your workout. Cold, stiff muscles and joints increase the risk of injury. If you have a choice on when to exercise, later in the day is best when your body temperature is higher and your muscles are joints are the most flexible\nResistance Training with Arthritis\nResistance training is crucial for strengthening the muscles that surround and support your joints and for preserving muscle and bone tissue. Strengthening the muscles over a joint helps the muscles better absorb shock. Better shock absorption means less stress on your joints. Plus, exercise is essential for bone health. Arthritis and osteoporosis is a double whammy – so make sure you’re giving your bones the stimulation they need to stay strong.\nIf you can’t do high-impact exercise, the type that maximally boosts bone growth, resistance training assumes even greater importance. During resistance training, muscles pull on bones and stimulate the production of new bone. The best resistance exercises for bone growth are “closed chain” ones where hands or feet are fixed to the floor such as squats, lunges, and push-ups.\nIf you have arthritis in your hands, you may find gripping heavy weights uncomfortable. Another alternative for stiff or painful hands is to use resistance bands rather than weights. You can still get a full-body workout using resistance bands without the discomfort of grasping heavy weights. Resistance training strengthens not only the muscle group you’re targeting, but stabilizer muscles as well.\nDon’t Skimp on the Warm-Up\nBefore doing any form of exercise, get the blood flowing to your muscles and joints by doing a warm-up. Warming up is vital if you suffer from joint stiffness or arthritis. The average person can get by with a 5-minute warm-up, but 10 minutes or even longer is best if you have arthritis. Do dynamic stretching exercises, not static ones, during the warm-up.\nThe best dynamic stretching exercises are those that mimic the movements you’ll do during your workout. If you’re working the lower body, air squats, leg swings and walking lunges without resistance are good warm-up exercises. Save the static stretches, where you hold the stretch for 20 or 30 seconds, until the end of your workout, as part of the cool-down. Avoid any type of ballistic or bouncing stretches, and be careful not to overstretch arthritis joints.\nKeep Your Workouts Varied\nDoing a variety of types of workouts not only reduces boredom it will keep you from overusing the same muscles and joints. Make yoga workouts a part of your routine too to help with flexibility. Just remember, if something hurts, don’t do it or modify the exercise.\nThe Bottom Line\nContrary to popular belief, exercise is safe and beneficial for people with arthritis. As a precaution, talk to your doctor first.\nArthritis Foundation. “Exercising with Osteoarthritis”\nIDEA Health and Fitness Association. “Training Clients With Arthritis”\nMed Page Today. “Weight Still Top Risk Factor for Knee Arthritis, Pain” 12/29/14.\nRheumatology (2001) 40 (4): 432-437. doi: 10.1093/rheumatology/40.4.432.\nAmerican College of Rheumatology. “Exercise and Arthritis”\nRelated Articles By Cathe:","A warm up generally consists of a gradual increase in intensity in physical activity (a “pulse raiser”), joint mobility exercise, and stretching, followed by the activity. For example, before running or playing an intensive sport, athletes might slowly jog to warm their muscles and increase their heart rate.\nWhat are the components of a warmup?\nThere are four key elements, or parts, which should be included to ensure an effective and complete warm-up. These elements consist of the general warm-up, static stretching, a sports-specific warm-up, and dynamic stretching.\nWhat are the 3 goals of warming up?\nThe warm up is used to prepare the body for activity. The main objectives are to increase heart rate and breathing, increase body temperature, and also psychologically prepare the body for exercise.\nWhat are the 5 parts of a warm up?\nTerms in this set (5)\n- Pulse raiser. Eg- jogging and skipping. Slowly increases heart rate and body temperature.\n- Mobility. Eg-arm swing and hip circles. …\n- Dynamic movement. Eg-shuttle runs. …\n- Stretching. Eg-groin walk and open and close the gate. …\n- Skill rehearsal. Eg-passing drills for football.\nWhat are the 3 parts of a workout?\nA complete fitness and exercise program should incorporate three basic components: Endurance (Aerobic), Flexibility, and Strength. Each of these components has specific guidelines, which govern their effectiveness.\nWhat are the 4 components of warm up?\nA good warmup comprises four steps: loosening joints, stretching muscles, pumping the heart, and practice movements.\nWhen stretching you should never what?\nOne of the biggest DON’TS when it comes to stretching is never hold your breath! By holding your breath while stretching, you are depriving your muscles of the oxygenated blood they need. In doing so you are building up more lactic acid, which can cause extreme pain.\nWhat are the goals of a warm up?\nThe purpose of a warm-up is to warm your body and prepare it for the exercises to come. Usually a warm-up will consist of activities at a slower pace and reduced intensity. The goal of a warm-up is to increase your body temperature, therefore warming up your muscles.\nHow do you properly warm up?\n- General warm-up. To begin your warm-up do 5 minutes of light (low intensity) physical activity such as walking, jogging on the spot or on a trampoline, or cycling. …\n- Sport-specific warm-up. One of the best ways to warm up is to perform the upcoming exercise at a slow pace. …\nWhats a good warm up?\n15 Best Dynamic Warm-Up Exercises To Prevent Injury\n- Marching in place while swinging your arms.\n- Jumping jacks.\n- Walking jacks.\n- Arm circles and shoulder shrugs.\n- Mountain Climbers.\n- Swinging toe touches.\n- Leg swings (forward and side to side).\n- Hip rotations (like stepping over a fence)\nWhat is the first stage of warm up?\nStage one: Raising the heart rate\nThis is aerobic activity such as jogging. This usually lasts around five minutes and is important because: It raises the body temperature and heart rate, which helps to warm the muscles. Muscles react and contract faster when they are warm.\nWhat are the 2 types of warm up?\nThere are two types of warm ups, a general warm up and a sport specific warm up.\nIs the 7 minute workout enough?\nSlentz said he would expect minimal health benefit from a seven-minute workout, but perhaps a modest physical-function benefit. “Someone who does this workout will not burn enough calories to actually get metabolic benefits,” he said.\nWhat is the toughest workout?\nThe Hardest Bodyweight Workout You’ll Ever Do\n- 20 x Burpees. Why: Burpees are an immense full-body exercise, working your arms, chest, quads, hamstrings, glutes and abs with every rep. …\n- 20 x Bodyweight Squats. …\n- 20 x Walking Lunges (10 x Each Leg) …\n- 20 x Step-Ups (10 x Each Leg) …\n- 10 x Tricep Dips. …\n- 10 x Alternating Staggered Push-Ups. …\n- 30 Second Plank.\nWhat are the 12 components of physical fitness?\nWhat are the 12 components of physical fitness and examples?\n- 1 – Body Composition.\n- 3 – Cardiovascular Endurance.\n- 4 – Muscular Endurance.\n- 5 – Muscular Strength. 6 – Speed. 7 – Power. 8 – Reaction Time. 9 – Agility. 10 – Coordination. 11 – Static Balance. 12 – Dynamic Balance. 13 – Fun (yeah I know I made it up, but it is important)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:7f281531-13d9-49a3-a728-2987ccd2f150>","<urn:uuid:148a47b5-36d6-4aa0-a391-ba8ca4b410ad>"],"error":null}
{"question":"What's the difference between psychological fatigue effects and alcohol effects on memory performance?","answer":"According to studies, 50-80% of fatigue cases are predominantly due to psychological factors like stress, leading to impaired recollection of timing and events. In comparison, alcohol has been shown to have a linear effect on recognition memory performance, accounting for 96.2% of variance in accuracy. Both conditions impair memory performance, but while fatigue's effects are largely linked to psychological factors, alcohol's impact appears to be more directly related to reduced processing resources.","context":["How and Why Fatigue Increases Safety Risks\nFatigue decreases productivity and increases the risk of workplace accidents by affecting a worker’s ability to think clearly, to the point that they are unaware of their own impairment.\nMental or physical exhaustion also reduces the ability to recognise and assess risks and inhibits co-ordination, reaction times and normal function, according to WorkCover Queensland.\nThey say that staying awake for 17 hours is equivalent to having a blood alcohol level of 0.05%, while being awake for 21 hours has the same effect as a blood alcohol level of 0.1%.\nThis is particularly concerning when fatigued people are performing tasks where the consequence of an error would be very serious, such as operating machinery, working at heights, performing electrical work and working with flammable or dangerous substances.\nWhat work increases fatigue?\nAdequate sleep is the most important way to prevent and counter-act fatigue. Adults typically require seven to eight hours daily of deep, uninterrupted sleep.\nPoor quality sleep, being awake for long periods and body clock disruption all contribute to fatigue, as do health and emotional issues.\nAccording to Better Health Victoria, studies have found that 50 to 80 per cent of fatigue cases are predominantly due to psychological factors, such as stress.\nWork schedules and job demands can also have a significant effect on sleep, such as:\n- Shift work and overtime which doesn’t allow for adequate rests between shifts.\n- Night shifts which disrupt a worker’s body clock.\n- Work which is high pressure, requires concentrating for long periods, sustained physical effort or repetitive actions.\n- Harsh or uncomfortable work conditions causing workers to tire more quickly.\nShift workers, night workers, FIFO and DIDO workers, seasonal workers and on-call or call-back workers are at a greater risk of fatigue.\nHow to manage fatigue\nManagers should take into consideration fatigue when designing rosters or setting company policies regarding overtime and shift work.\nEnsuring adequate rest time for workers between shifts will reduce the risk of fatigue, while scheduling critical tasks for the daytime (but not the afternoon slump between 2-4pm) will have a positive impact on safety.\nJob-rotation to reduce mental and physical exhaustion from tasks and providing adequate break rooms with facilities and comfortable conditions can also reduce fatigue.\nWorkers can also be encouraged to adopt a variety of different strategies to fight fatigue by maintaining adequate hydration levels and improving their diet, sleeping habits, lifestyle and psychological wellbeing.\n- Drinking adequate healthy fluids – including eliminating energy drinks which have been banned on some construction sites, reducing or cutting out caffeine – particularly before sleeping, not skipping meals, maintaining a healthy diet and eating plenty of iron-rich foods.\n- Going to bed and getting up at the same time, avoiding daytime naps and having a warm bath and shower.\n- Quitting smoking as it leads to lower energy levels and fatigue for a number of reasons, including reduced oxygen levels in the blood.\n- Increasing physical activity which can improve sleep as well as having positive physical and mental effects.\n- Avoiding abuse of alcohol or recreational drugs which also contribute to fatigue and have been found to be a particular problem in the construction industry.\n- Reducing stress through relaxing activities, talking to a professional about ongoing problems or issues, and taking time out.\nCommon effects of fatigue:\n- Lack of concentration\n- Impaired recollection of timing and events\n- Poor judgement\n- Reduced capacity for communicating with others\n- Reduced hand-eye coordination\n- Reduced visual perception\n- Reduced vigilance\n- Reduced capacity to judge risk\n- Slower reaction times\n- Micro sleeps\n- Heart disease and high blood pressure\n- Lower fertility\n- Poor mental health\n- Stomach disorders\nMore information can be found in the Safe Work Australia Guide for Managing the Risk of Fatigue at Work.","Alcohol, reaction time and memory: a meta-analysis\nMaylor, Elizabeth A. and Rabbitt, Patrick. (1993) Alcohol, reaction time and memory: a meta-analysis. British Journal of Psychology, Vol.84 (No.3). pp. 301-317. ISSN 0007-1269Full text not available from this repository.\nOfficial URL: http://dx.doi.org/10.1111/j.2044-8295.1993.tb02485...\nModerate doses of alcohol impair performance on a variety of information processing tasks. Two separate meta-analyses were conducted on the results of (1) reaction time studies, and (2) recognition memory studies, representing 25 and 16 different task conditions, respectively. In both cases, performance with alcohol (either 0.8 or 1.0 ml/kg body weight) was plotted as a function of performance with no alcohol. For reaction time, a linear fit accounted for 99.7 per cent of the variance. The same function applied not only to the mean but to the distribution of reaction times from the 5th to the 95th percentiles. For recognition memory, a linear fit accounted for 96.2 per cent of the variance in accuracy (expressed as the logarithm of proportion correct). Thus alcohol appears to have a general linear effect on information processing, rather than specific effects on a subset of stages. It is concluded that the results are consistent with a reduced processing resources hypothesis for the impairment with alcohol.\n|Item Type:||Journal Article|\n|Subjects:||B Philosophy. Psychology. Religion > BF Psychology|\n|Divisions:||Faculty of Science > Psychology|\n|Library of Congress Subject Headings (LCSH):||Alcohol -- Physiological effect, Reaction time -- Effect of drugs on, Drinking of alcoholic beverages, Memory -- Effect of drugs on , Human information processing -- Effect of drugs on , Cognition -- Testing|\n|Journal or Publication Title:||British Journal of Psychology|\n|Publisher:||John Wiley & Sons Ltd.|\n|Official Date:||August 1993|\n|Page Range:||pp. 301-317|\n|Funder:||Economic and Social Research Council (Great Britain) (ESRC), Medical Research Council (Great Britain) (MRC)|\n|Grant number:||PG8612638 (MRC), (ESRC)|\nBirnbaum, I. M. & Parker, E. S. (1977). Acute effects of alcohol on storage and retrieval. In I. M. Birnbaum & E. S. Parker (Eds), Alcohol and Human Memory. Hillsdale, NJ: Erlbaum.\nBrinley, J. F. (1965). Cognitive sets, speed and accuracy of performance in the elderly. In A. T. Welford & J. E. Birren (Eds), Behavior, Aging and the Nervous System, pp. 114-149. Springfield, IL: Thomas.\nCarpenter, J. A. (1959). The e*ect of caffeine and alcohol on simple visual reaction time. Journal of Comparative and Physiological Psychology, 52, 491-496.\nCarpenter, J. A. (1962). Effects of alcohol on some psychological processes. Quarterly Journal of Studies on Alcohol, 23, 274-314.\nCerella, J. (1985). Information processing rates in the elderly. Psychological Bulletin, 98, 67-83.\nCerella, J. (1990). Aging and information-processing rate. In J. E. Birren & K. W. Schaie (Eds), Handbook of the Psychology of Aging, 3rd ea., pp. 201-221. San Diego, CA: Academic Press.\nCotton, J. W. (1989). Interpreting data from two-period crossover design (also termed the replicated 2 x 2 Latin square design). Psychological Bulletin, 106, 503-515.\nCraik, F. I. M. (1977). Similarities between the effects of aging and alcoholic intoxication on memory performance, construed within a 'levels of processing' framework. In I. M. Birnbaum & E. S. Parker (Eds), Alcohol and Human Memory. Hillsdale, NJ: Erlbaum.\nHasher, L. & Zacks, R. T. (1979). Automatic and effortful processes in memory. Journal of Experimental Psychology: General, 108, 356-388.\nHaut, J. S., Beckwith, B. E., Petros, T. V. & Russell, S. (1989). Gender differences in retrieval from long-term memory following acute intoxication with ethanol. Physiology and Behavior, 45, 1161-1165.\nHunt, E. (1978). Mechanics of verbal ability. Psychological Review, 85, 109-130.\nHuntley, M. S. Jr (1972). Influences of alcohol and S-R uncertainty upon spatial localization time. Psychopharmacologia (Berlin), 27, 131-140.\nHuntley, M. S. Jr (1974). Effects of alcohol, uncertainty and novelty upon response selection. Psychopharmacologia (Berlin), 39, 259-266.\nJellinek, E. M. & McFarland, R. A. (1940). Analysis of psychological experiments on the effects of alcohol. Quarterly Journal of Studies on Alcohol, 1, 272-371.\nKail, R. (1991). Developmental change in speed of processing during childhood and adolescence. Psychological Bulletin, 109, 490-501.\nMaylor, E. A. & Rabbitt, P. M. A. (1987a). Effect of alcohol on rate of forgetting. Psychopharmacology, 91, 230-235.\nMaylor, E. A. & Rabbitt, P. M. A. (1987b). Effects of alcohol and practice on choice reaction time. Perception and Psychophysics, 42, 465-475.\nMaylor, E. A. & Rabbitt, P. M. A. (1988). Amount of practice and degree of attentional control have no influence on the adverse effect of alcohol in word categorization and visual search tasks. Perception and Psychophysics, 44, 117-126.\nMaylor, E. A. & Rabbitt, P. M. A. (1989). Relationship between rate of preparation for, and processing of, an event-requiring a choice response. Quarterly Journal of Experimental Psychology, 41A, 47-62.\nMaylor, E. A., Rabbitt, P. M. A. & Connolly, S. A. V. (1989). Rate of processing and judgment of response speed: Comparing the effects of alcohol and practice. Perception and Psychophysics, 45, 431-438.\nMaylor, E. A., Rabbitt, P. M. A., James, G. H. & Kerr, S. A. (199Oa). Comparing the effects of alcohol and intelligence on text recall and recognition. British Journal of Psychology, 81, 299-313.\nMaylor, E. A., Rabbitt, P. M. A., James, G. H. & Kerr, S. A. (199Ob). Effects of alcohol and extended practice on divided-attention performance. Perception and Psychophysics, 48, 445-452.\nMaylor, E. A., Rabbitt, P. M. A., James, G. H. & Kerr, S. A. (1992). Effects of alcohol, practice and task complexity on reaction time distributions. Quarterly Journal of Experimental Psychology, 44A, 119-139.\nMaylor, E. A., Rabbitt, P. M. A. & Kingstone, A. F. (1987). Effects of alcohol on word categorization and recognition memory. British Journal of Psychology, 78, 233-239.\nMaylor, E. A., Rabbitt, P. M. A. & Kingstone, A. F. (1988). Effects of alcohol on lexical access. Psychopharmacology, 95, 119-123.\nMaylor, E. A., Rabbitt, P. M. A., Sahgal, A. & Wright, C. (1987). Effects of alcohol on speed and accuracy in choice reaction time and visual search. Acta Psychologica, 65, 147-163.\nMyerson, J., Hale, S., Wagstaff, D., Poon, L. W. & Smith, G. A. (1990). The information-loss model: A mathematical theory of age-related cognitive slowing. Psychological Review, 97, 475-487.\nOborne, D. J. & Rogers, Y. (1983). Interactions of alcohol and caffeine on human reaction time. Aviation, Space, and Environmental Medicine, 54, 528-534.\nRabbitt, P. M. A. & Maylor, E. A. (1991). Investigating models of human performance. British Journal of Psychology, 82, 259-290.\nRobinson, G. H. & Peebles, W. J. (1974). Interactions between alcohol, task difficulty, and compatibility in a choice-reaction task. Perceptual & Motor Skills, 38, 459-466.\nSalthouse, T. A. (1985). A Theory of Cognitive Aging. Amsterdam: North-Holland.\nSalthouse, T. A. (1991). Theoretical Perspectives on Cognitive Aging. Hillsdale, NJ: Erlbaum.\nSalthouse, T. A. & Somberg, B. L. (1982). Isolating the age difference in speeded performance. Journal of Gerontology, 37, 59-63.\nSchneider, W., Dumais, S. T. & Shiffrin, R. M. (1984). Automatic and control processing and attention. In R. Parasuraman & D. R. Davies (Eds), Varieties of Attention, pp. 1-27. New York: Academic Press.\nSedman, A. J., Wilkinson, P. K., Sakmar, E., Weidler, D. J. & Wagner, J. G. (1976). Food effects on absorption and metabolism of alcohol. Journal of Studies on Alcohol, 37, 1197-1214.\nSmith, E. (1968). Choice RT: An analysis of the major theoretical positions. Psychological Bulletin, 69, 77-110.\nSmith, G. A., Poon, L. W., Hale, S. & Myerson, J. (1988). A regular relationship between old and young adults' latencies on their best, average and worst trials. Australian Journal of Psychology, 40, 195-210.\nSternberg, S. (1966). High speed scanning in human memory. Science, 153, 652-654.\nTharp, V. K. Jr, Rundell, O. H. Jr, Lester, B. K. & Williams, H. L. (1974). Alcohol and information processing. Psychopharmacologia (Berlin), 40, 33-52.\nWallgren, H. & Barry, H. III (1970). Actions of Alcohol. New York: Elsevier.\nWelford, A. T. (1958). Ageing and Human Skill. London: Oxford University Press.\nActions (login required)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:9de48fda-c521-452f-ae97-cce66923b5ad>","<urn:uuid:ee3dbbc2-793a-4db3-9058-aaaf903cb408>"],"error":null}
{"question":"How did early e-commerce platforms influence online banking adoption, and what key features should users look for in modern mobile banking apps?","answer":"E-commerce platforms like Amazon and eBay, which launched in 1995, played a crucial role in normalizing online payments and increasing confidence in online banking. Amazon's success, offering wider product selection at lower prices, encouraged broader acceptance of online banking services in Europe and the US. eBay's growth led to the development of new payment services like PayPal (originally Confinity) to handle online payments. As for modern mobile banking apps, key features to look for include real-time balance and transaction history viewing, the ability to transfer funds between accounts easily, and robust security measures like biometric authentication and two-factor authentication. The app should also provide transaction alerts and easy accessibility for managing finances on-the-go.","context":["The Evolution of the Bank Account – Part III: The Rise of the Internet and Online Banking\nIf the technological advances of the 1960s and 70s made the bank account more accessible, the personal computer (PC) and the subsequent rise of the internet took convenience to the next level.\nBefore the internet, banking involved visiting your local branch or, at the very least, a trip to the closest ATM. But once personal computers and internet connections became household fixtures, all that changed.\nIt soon became possible to manage your bank account and make transactions at any time of day from the comfort of your own home. And as the internet evolved and computers became more sophisticated, they brought about further changes that made the bank account even more central to our day-to-day lives.\n1983: the birth of online banking\nThe UK’s Nottingham Building Society is often credited as the first bank to offer online banking facilities in Europe. As early as 1983, the society’s customers could check their balance, pay bills, transfer money and even apply for a loan from home using a system called Homelink.\nUnfortunately, Homelink only lasted about two years, mainly because it was too expensive to operate. However, it would become the blueprint for online banking as we know it today.\nFrench banks had more luck with their first online banking prototype, called the Minitel. Launched in 1984, it became immensely popular across the country. When it finally went out of service in 2012, an estimated 600,000 Minitel units were still in use.\nBanks and the internet: the early days\nThe first bank websites were essentially online brochures. They had product information, photos, contact numbers and branch maps, but they didn’t interact with customers.\nSoon, banks realized that going online meant less overhead and more profits, some of which could be passed onto consumers in the form of lower fees and better interest rates. Online banking also eliminated queues, drastically reduced waiting times and made it easier to deliver a more personalized customer experience. As a result, banks prioritized building an online presence.\nBy the mid-1990s, PCs and household internet connections were becoming widespread, and so was online banking. Nordic countries subsidized PCs and invested heavily in the internet, which is why the region has one of the world’s highest internet penetration rates today. Forward-thinking policies and the quality of the infrastructure also made Scandinavia a natural breeding ground for new financial technologies.\nNormalizing online payments: the rise of e-commerce sites\nDespite its convenience, many customers approached online banking with caution. People were especially reluctant to make online payments, due in part to a perceived lack of security on the internet. Then, in 1995, Amazon opened its first online store.\nOriginally named Cadabra — until CEO Jeff Bezos changed the name after a lawyer misheard it as “Cadaver” — Amazon offered a much wider selection of products than traditional brick-and-mortar shops. And because it had a significantly lower overhead, prices were far cheaper. Its success encouraged many others to go online, including eBay, which opened its virtual doors in September 1995.\nAs e-commerce sites grew in popularity, so did online banking. Online shopping buoyed confidence in online payments, which in turn led to wider acceptance of online banking services both in Europe and the US.\neBay and the birth of online payment services\nIn the early days of online shopping, most people paid for their purchases with a credit or debit card. While this was the quickest and safest payment method available, it wasn’t always practical, and this was especially problematic for some eBay merchants.\nLegend has it that eBay founder Peter Omidyar started the site to help his girlfriend, an avid Pez dispenser collector, reach out and network with other like-minded people. The website quickly grew into a marketplace for all sorts of vintage items, collectables and used goods. Since most of these traders were either individuals or very small businesses, accepting card payments wasn’t a viable option.\nLuckily, in 1998, a company called Confinity launched a service that could handle online payments on merchants’ behalf. The service proved popular with online shoppers, too. Once you registered and connected your bank account, you could use Confinity to pay without having to input your card details. Confinity eventually merged with a company called X.com to become PayPal.\nMobile banking: your bank account in your pocket\nThe internet went mobile in 1999 when the first cell phones with wireless application protocol (WAP) support came out. Banks started offering mobile banking services soon after. Unsurprisingly, one of the first banks in the world to offer mobile banking hailed from Scandinavia: Norwegian bank DnB.\nThe first mobile banking services relied on SMS alerts. By sending a request via text message, you could check your account balance, top up your cell phone credit or even pay bills on the go. SMS banking also improved online security by leaps and bounds. You could now receive one-time passwords or alerts flagging unusual account activity.\nMobile banking evolved in tandem with mobile devices. More sophisticated smartphones and better internet connections drove banks to improve their mobile services. Soon, you could use an app to locate the nearest ATM, transfer money or apply for other banking products. In short, you could carry your bank account in your pocket wherever you went.\nThe 2008 financial crisis: a new dawn\nAs technological innovation was rapidly modernizing the bank account, the banking industry itself was about to face its biggest crisis since 1929.\nIn September 2008, banking giant Lehman Brothers collapsed, leading to the largest bankruptcy filing in history. Several other huge international banks suffered crippling financial losses or filed for bankruptcy themselves. The ensuing financial crisis lead to unprecedented levels of government intervention both in Europe and the US.\nAs it turned out, the financial crisis would be a boon for the bank account. Further technological advancement, the European regulatory landscape and the increasingly conservative attitudes of traditional banks after the financial crisis would lead to the creation of a new breed of bank account operated by challenger banks.\nHow did rapid developments in mobile technology and the EU’s regulatory landscape help the bank account adapt to the challenges of the digital age? Read more in the fourth installment of this five-part series!\nThis article was originally published in The Paypers.","Are you bored with ready in lengthy strains on the financial institution or making an attempt to squeeze in a go to throughout your busy work schedule? Look no additional than cellular banking apps.\nWith only a faucet in your cellphone, you’ll be able to have entry to your entire monetary info and carry out transactions proper from the palm of your hand. Cell banking apps supply a mess of benefits over conventional banking strategies.\nNot solely do they prevent time, however in addition they present straightforward accessibility and comfort. On this final information to cellular banking apps, we’ll discover the options to search for in an app, safety measures which can be in place, and examine a number of the high cellular banking apps available on the market.\nSo sit again and prepare to take management of your funds with only a few faucets in your cellphone!\nIf you happen to’re within the technical aspect of those apps, and even contemplating creating your individual, you may discover this text on tips on how to create a cellular banking app useful.\n- Cell banking apps present straightforward accessibility and comfort, saving time and permitting use from anyplace.\n- Safety features comparable to MFA, biometric authentication, and transaction alerts present added safety for customers’ accounts.\n- Key options to search for in a cellular banking app embrace real-time steadiness and transaction historical past, fund switch choices, and robust safety measures.\n- Maximizing the cellular banking expertise entails utilizing a safe community, organising alerts for account exercise, and exploring all of the options of the app. Nonetheless, warning should be taken when utilizing public Wi-Fi as a result of vital danger of information theft.\nThe Benefits of Cell Banking Apps\nWith cellular banking apps, you’ll be able to simply handle your funds on-the-go, saving time and rising comfort. Gone are the times while you needed to go to a financial institution department or ATM to verify your account steadiness, switch funds, or pay payments. With only a few faucets in your smartphone display, you’ll be able to accomplish all these duties and extra from just about anyplace.\nOne of many key benefits of cellular banking apps is that they can help you keep on high of your funds in real-time. You now not have to attend for paper statements or log into a pc to see how a lot cash is in your accounts. With a cellular app, you’ll be able to immediately view your balances, transaction historical past, and different account particulars as quickly as they turn into accessible.\nOne other advantage of cellular banking apps is that they provide enhanced security measures in comparison with conventional strategies of banking. Most apps require customers to arrange multifactor authentication (MFA), which provides an additional layer of safety towards fraudsters who may attempt to entry your accounts with out authorization. Moreover, many banks use encryption know-how to safeguard delicate info comparable to passwords and account numbers from being intercepted by hackers.\nIf you happen to’re on the lookout for a handy and safe option to handle your funds whereas on-the-go, cellular banking apps are undoubtedly value contemplating. They provide real-time entry to account info and transactions, enhanced security measures like MFA and encryption know-how, and the power to carry out varied monetary duties from anyplace with an web connection. So why not give them a attempt at present?\nOptions to Search for in a Cell Banking App\nWhen selecting a cellular banking app, it’s essential to search for options that make managing your funds simpler and extra handy. One of the essential options to contemplate is the power to view account balances and transaction historical past in real-time. This lets you preserve monitor of your spending and keep away from overdraft charges by figuring out precisely how a lot cash you could have accessible.\nOne other characteristic to search for is the power to switch funds between accounts or ship cash to family and friends simply. Many cellular banking apps supply fast and safe methods to switch cash with out having to go to a bodily financial institution location or use third-party companies like Venmo or PayPal. This will prevent time and problem, particularly if it is advisable ship cash urgently.\nSafety must be a high precedence when selecting a cellular banking app. Search for apps that supply biometric authentication, comparable to fingerprint or facial recognition, in addition to two-factor authentication for added safety. It’s additionally essential that the app makes use of encryption know-how to guard your monetary info whereas it’s being transmitted over the web.\nBy choosing an app with sturdy safety measures in place, you’ll be able to have peace of thoughts figuring out that your delicate info is protected from cyber threats.\nSafety Measures in Cell Banking Apps\nDefend your monetary info from cyber threats by selecting a cellular banking app with sturdy safety measures. These measures embrace biometric authentication and encryption know-how. Biometric authentication ensures that solely you’ll be able to entry your account via fingerprint or face recognition. Encryption know-how protects your information by changing it into unreadable code. These options make it tough for hackers to steal your private info and use it for fraudulent actions.\nOther than these primary safety measures, some cellular banking apps additionally supply further options like transaction alerts and two-factor authentication. Transaction alerts notify you each time a transaction is constituted of your account, permitting you to detect any unauthorized exercise instantly. Two-factor authentication entails utilizing two totally different strategies to confirm your identification earlier than granting entry to the app, making it virtually unattainable for anybody else to log in with out authorization.\nAll the time be cautious when utilizing public Wi-Fi, because it poses a big danger of information theft. Keep away from logging in to delicate accounts like on-line banking when utilizing public Wi-Fi networks or unsecured units. When accessing cellular banking apps outdoors safe networks, use a VPN (Digital Personal Community) that encrypts all visitors between the machine and the web connection.\nBy taking these precautions and selecting a dependable cellular banking app with sturdy safety measures, you’ll be able to benefit from the comfort of digital banking with out compromising on security.\nIdeas for Maximizing Your Cell Banking Expertise\nTo get essentially the most out of your cellular banking expertise, you’ll need to make the most of some easy but efficient ideas.\nAt the beginning, be sure to’re utilizing a safe community when accessing your cellular banking app. Keep away from utilizing public Wi-Fi or different unsecured networks that might probably compromise your private info.\nOne other useful tip is to arrange alerts for any exercise in your account. This will embrace notifications for deposits, withdrawals, and even low balances. By staying on high of those alerts, you’ll be able to shortly determine any fraudulent or unauthorized exercise in your account.\nLastly, don’t be afraid to discover all of the options of your cellular banking app. Many apps supply further instruments comparable to budgeting and monetary planning sources that may enable you handle your cash extra successfully. Take a while to familiarize your self with all the pieces the app has to supply, so you’ll be able to absolutely maximize its potential and benefit from your cellular banking expertise.\nThe Way forward for Cell Banking Apps\nAs we delve into the way forward for cellular banking apps, it’s clear that innovation and know-how will proceed to drive this sector ahead. The digital banking panorama is evolving at an unprecedented tempo, with new developments rising which can be set to redefine the way in which we handle our funds.\nOne vital pattern is the combination of synthetic intelligence (AI) in cellular banking apps. AI can improve personalization, making banking extra intuitive and user-friendly. For example, AI-powered chatbots can present instantaneous customer support, whereas machine-learning algorithms can supply customized monetary recommendation primarily based on a person’s spending habits and monetary targets.\nOne other rising pattern is the convergence of banking with different monetary companies. Increasingly more, we’re seeing cellular banking apps providing a one-stop-shop for all monetary wants, together with insurance coverage, investments, and even cryptocurrency transactions. This pattern in direction of ‘tremendous apps’ is especially prevalent in Asia and is more likely to unfold globally.\nBiometric authentication is one other space the place we are able to anticipate to see developments. Whereas fingerprints and facial recognition are already utilized by some banks, future apps could incorporate extra subtle biometric applied sciences, comparable to voice recognition and even heartbeat evaluation, for enhanced safety.\nBlockchain know-how, recognized for its position in cryptocurrencies, additionally holds potential for cellular banking, providing potentialities for safe, clear transactions and lowered fraud.\nThe way forward for cellular banking apps is undoubtedly thrilling, promising a world the place managing funds is extra seamless, safe, and tailor-made to particular person wants than ever earlier than.\nSo there you could have it – the final word information to cellular banking apps! By now, you need to be satisfied of the various benefits of utilizing a cellular banking app.\nNot solely does it save time and problem, however it additionally offers you larger management over your funds. When buying round for a cellular banking app, keep in mind to search for options comparable to straightforward navigation, real-time updates, and robust safety measures.\nAnd don’t neglect to match totally different apps to seek out the one which most closely fits your wants. With the following tips in thoughts, you’re properly in your option to maximizing your cellular banking expertise.\nSo why not give it a attempt at present? You may simply be shocked at how a lot simpler managing your cash will be when all the pieces is true at your fingertips!"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:619c5217-2c45-43b8-9c35-8c83154bd8d0>","<urn:uuid:ad6225c9-a712-4135-a360-d744f025f3fe>"],"error":null}
{"question":"Which type of symmetry connects to energy conservation in physics? !!","answer":"Time translation symmetry, which means that the laws of physics do not change with time, corresponds to the law of conservation of energy. This relationship is established through Noether's theorem, which links symmetries to conservation laws. The conservation of energy law states that energy can neither be created nor destroyed, although it can be transformed from one form to another (such as mechanical, kinetic, chemical). In an isolated system, the sum of all forms of energy remains constant.","context":["People have been searching for the meaning of life for ages. Since time immemorial, when people spent their lives hunting wild animals, there were still some people who drew pictures in caves. People are still searching for the meaning of life like themselves, some are pursuing God and some are practicing science. Today we will be discovering something that is extremely simple and beautiful and lies in front of our own eyes. The name of this wonderful thing is symmetry.\nTo put it bluntly, a common example is to cut a piece of paper in half. Now no difference can be understood between the two pieces. Many people understand symmetry but its real meaning is much deeper and it requires serious knowledge of physics. We would rather move slowly towards that explanation. Now let’s take a look at some of the symmetries of our daily life.\nThe symmetry of daily life\nFirst of all, let’s move on to our old example where we try to explain symmetry by cutting paper. We do not understand the difference between the two parts of the paper. When an object is divided into two parts and no difference is found between the parts, it is called bilateral symmetry. If a human body is divided into two parts (you don’t have to do it with your own hands, just think about it in your head), then the parts can be seen to be exactly the same.\nBy cutting down a circle into two semi-circles, we also see bilateral symmetry, but with it comes another type of symmetry which we commonly call rotational symmetry. If we rotate a round object a little, we see that there is no change in the shape of the object. A well-known example of this is the well-known London Eye in England. If you think about it, you will understand that the definition has started to fall apart. The next example will make my statement clear.\nWhen a car is constantly moving in the same direction without taking any turns and no change in the appearance of the car, it is called translational symmetry. So far, many people have noticed that the explanation of our paper-cutting is no longer going on. What is the way out then? I will try my best to explain the simple meaning of this difficult topic in the next section\nThe science of symmetry\nSo, how do we explain this stuff? Walk straight on the street, symmetry, turn the cricket ball again, symmetry, right hand left hand, we get it again! So how do we easily understand the meaning of this? There is an answer, but it will take some mathematics, but I promise, I will not show it by numbers. I will leave the language of numbers here and explain it in our wordy language. So, let’s get started.\nLet’s hope everyone has heard of ‘coordinate transformation’ here. If you have studied vectors, you will know that there are 2-3 axes according to which the position of a point changes. If the position of an object changes with respect to an axis but the object does not change, then it can be called symmetry.\nA bit of a mathematical description here but please bear with me as I shall be giving examples. As the car moves in a straight path along a straight axis it basically stays the same car, the shape or volume of the ball does not change even though the adjustment changes towards the spin of the ball when the bowler spins the ball. That’s called symmetry in simple words. Let us see then, what is the connection of symmetry with physics? And why is it such a beautiful thing!\nSymmetry and Conservation\nLet’s move on to the most beautiful theorem of physics called ‘Noether’s theorem’. We’ve all heard about conservation law. Simply put, Noether’s theorem says that any symmetry that can be differentiated has a corresponding conservation law.\nP.S: Interested people please follow this topic on their own. I have to make it simpler for people to understand and the real deal is different.\nIf we have rotational symmetry, then from there we will get the Law of Conservation of Angular Momentum, from translational symmetry we will get the Law of Conservation of Linear Momentum. There is another symmetry which is called time translation symmetry and it means that the laws of physics do not change with time and it gives birth to our very well-known law of conservation of energy.\nMany things can be explained with symmetry like our familiar Gauss law in electrostatics. It is also useful in quantum mechanics, cosmology, etc. An important example is the broken CPT symmetry through which our universe is being driven. This means that if we have another anti-universe in our universe, our universe will not be different from it. As long as people are alive, they will find symmetry or any pattern in life because this is our religion, this is the difference between us and other living beings. Let’s move on to a future full of endless possibilities where there are many discoveries to be made and new mysteries uncovered!","conservation lawArticle Free Pass\nconservation law, also called law of conservation, in physics, several principles that state that certain physical properties (i.e., measurable quantities) do not change in the course of time within an isolated physical system. In classical physics, laws of this type govern energy, momentum, angular momentum, mass, and electric charge. In particle physics, other conservation laws apply to properties of subatomic particles that are invariant during interactions. An important function of conservation laws is that they make it possible to predict the macroscopic behaviour of a system without having to consider the microscopic details of the course of a physical process or chemical reaction.\nConservation of energy implies that energy can be neither created nor destroyed, although it can be changed from one form (mechanical, kinetic, chemical, etc.) into another. In an isolated system the sum of all forms of energy therefore remains constant. For example, a falling body has a constant amount of energy, but the form of the energy changes from potential to kinetic. According to the theory of relativity, energy and mass are equivalent. Thus, the rest mass of a body may be considered a form of potential energy, part of which can be converted into other forms of energy.\nConservation of linear momentum expresses the fact that a body or system of bodies in motion retains its total momentum, the product of mass and vector velocity, unless an external force is applied to it. In an isolated system (such as the universe), there are no external forces, so momentum is always conserved. Because momentum is conserved, its components in any direction will also be conserved. Application of the law of conservation of momentum is important in the solution of collision problems. The operation of rockets exemplifies the conservation of momentum: the increased forward momentum of the rocket is equal but opposite in sign to the momentum of the ejected exhaust gases.\nConservation of angular momentum of rotating bodies is analogous to the conservation of linear momentum. Angular momentum is a vector quantity whose conservation expresses the law that a body or system that is rotating continues to rotate at the same rate unless a twisting force, called a torque, is applied to it. The angular momentum of each bit of matter consists of the product of its mass, its distance from the axis of rotation, and the component of its velocity perpendicular to the line from the axis.\nConservation of mass implies that matter can be neither created nor destroyed—i.e., processes that change the physical or chemical properties of substances within an isolated system (such as conversion of a liquid to a gas) leave the total mass unchanged. Strictly speaking, mass is not a conserved quantity. However, except in nuclear reactions, the conversion of rest mass into other forms of mass-energy is so small that, to a high degree of precision, rest mass may be thought of as conserved.\nConservation of charge states that the total amount of electric charge in a system does not change with time. At a subatomic level, charged particles can be created, but always in pairs with equal positive and negative charge so that the total amount of charge always remains constant.\nIn particle physics, other conservation laws apply to certain properties of nuclear particles, such as baryon number, lepton number, and strangeness. Such laws apply in addition to those of mass, energy, and momentum encountered in everyday life and may be thought of as analogous to the conservation of electric charge. See also symmetry.\nThe laws of conservation of energy, momentum, and angular momentum are all derived from classical mechanics. Nevertheless, all remain true in quantum mechanics and relativistic mechanics, which have replaced classical mechanics as the most fundamental of all laws. In the deepest sense, the three conservation laws express the facts, respectively, that physics does not change with passing time, with displacement in space, or with rotation in space.\nWhat made you want to look up conservation law?"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:f783a481-a07c-4d2d-832b-3200e8b8f4db>","<urn:uuid:01dacf21-84e3-4aaf-af72-1560d4c40661>"],"error":null}
{"question":"How long can you store leftover steel-cut oatmeal in the fridge?","answer":"Leftover steel-cut oatmeal can be refrigerated for up to a week. When stored in the fridge, it firms up, but can be softened again by adding a splash of milk and heating it in the microwave for a minute or two.","context":["When it is cold and dreary outside, there is oatmeal for breakfast. It's an \"If A, then B\" kind of situation. If you have a little extra time — a weekend morning, say, or a handy snow day — it's worth pulling out the steel-cut oats. Yes, they take longer to cook than our standby rolled oats, but the trade-off is the best bowl of oatmeal you've ever had.\nSteel-cut oats are made from whole oat groats — the \"steel-cut\" part of the name comes from how the groats are chopped into small, nubbly pieces. Chopping them makes them easier to cook (whole groats take even longer to cook than steel-cut oats!), and it also exposes the starches inside the oats to the water. These starches, in turn, dissolve into the water during cooking, creating the kind of thickened, creamy porridge of Goldilocks' dreams.\nThe basic ratio for making steel-cut oatmeal is 1 cup of oats to 3 to 4 cups of water — I've found that less water keeps the oats more intact and chewy while more water makes a silkier porridge. I like them both! Play with it and see what ratio you like best. And if you want a real treat, you can also swap out some or all of the water for milk.\nCooking steel-cut oats is easy-peasy — boil water, add oats, reduce heat, and simmer — but it does require some patience. The oats take a good 20 to 30 minutes to become tender and decide they want to make a porridge. Start tasting the oatmeal around the 20 minute mark and keep cooking until you're happy with it. Sometimes I find that the oats are tender at 20 minutes, but leaving the pot bubbling for a little longer helps thicken everything up.\nSteel-cut oats have a nuttier, earthier flavor than rolled oats. I honestly love this oatmeal all on its own with nothing more than a splash of cream and a sprinkle of sugar. But of course, you can bring the whole line-up of oatmeal toppings out to play: chopped nuts, dried and fresh fruits, maple syrup and honey, cinnamon, fruit preserves and all the rest of your favorite toppers.\nBy the way, leftover steel-cut oatmeal can be refrigerated for up to a week. If you love steel-cut oats for breakfast, you can make a big batch on the weekend and parcel it out all week long. It firms up in the fridge, but a splash of milk and a minute or two in the microwave softens it right back up again.\nAdd a scant 1/8 teaspoon of salt.\nHow to Cook Steel-Cut Oats in 30 minutes\nServes 4 to 6\nWhat You Need\n3-4 cups water (or a mix of water and milk)\n1 cup steel-cut oats\nScant 1/8 teaspoon salt\nMeasuring cups and spoons\n2 quart saucepan\n- Bring the water to a boil: Use 3 cups of water for firmer, more intact oat grains or 4 cups of water for creamier oatmeal. Pour the water into a saucepan and bring it to a boil over high heat.\n- Stir in the oats and the salt: Pour the oats into the water, add the salt, and stir.\n- Return to a boil: Let the water come back up to a rolling boil — this should only take a few seconds. Be watchful as the water comes back to a boil as it can sometimes foam up and spill out of the pan.\n- Reduce heat to low: Once the water is boiling, reduce the heat to low and bring the oats to a simmer. You may need to play with the exact setting on your stove — aim to keep the oats at a barely perceptible simmer. You should see steam coming off the water with a bubble or two every few seconds.\n- Simmer for 20 to 30 minutes: Let the oats simmer for anywhere from 20 to 30 minutes, stirring occasionally and scraping the bottom of the pan. Cook until the oats are very tender and the oatmeal is as creamy as you like it — longer cooking will make thicker oatmeal.\n- Serve immediately or refrigerate for 1 week: The oats are ready to eat immediately. You can also let the oats cool and then store them in an airtight container in the fridge for up to a week. The oats will thicken in the fridge; stir a little milk or water into them when reheating to loosen.\nMore On Steel-Cut Oats:\nWant more smart tutorials for getting things done around the home?\nSee more How To posts\nWe're looking for great examples of your own household intelligence too!\nSubmit your own tutorials or ideas here!\n(Image credits: Emma Christensen)"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:8d55859a-d250-46e5-8041-d6586fd6877b>"],"error":null}
{"question":"Which requires deeper planting holes: standard fruit trees or small garden plants less than 3 inches tall?","answer":"Standard fruit trees require deeper planting holes than small garden plants. Small plants that are 3 inches or less need holes 6 to 12 inches deep, while standard fruit trees, which can grow 25-30 feet tall, need holes at least 2 feet deep when planting bare root trees.","context":["Protecting your investment in your plants starts by digging a hole the right size, with the right conditions. If you dig the hole incorrectly, essentially all you do is create a bigger pot for your plant.\nPlanting your transplants in the right type of hole can make all the difference in their success. Look at the difference in the same variety of tomato planted in holes prepared in different ways. Which tomato – or shrub or tree – would you prefer to have in your yard?\nThere are a few things to keep in mind:\n- Hole size – depends upon the height of the plant and the size of the pot. As the pots and plants get larger, so does the hole. Smaller plants – 3 inches or less – need a hole 6 to 12 inches deep. Larger garden plants – pots greater than 3 inches, I dig a hole at about twice the diameter of the existing pot and 1.5 to 2 times as deep as I want to plant. You want to make sure you have plenty room for loose soil in the bottom of your hole, so roots thrive.\n- Soil conditions – read the label for your new plant. Do the soil conditions required by the plant match your planting location? Perhaps your soil is too sandy. Or, it may have too much clay, and not allow for proper drainage. You’ll want to check that.\n- Other plant factors – such as light requirements, space requirements, and even wind, should be considered.\n- Loose, un-compacted soil – Perhaps the most important concept for the long term survival of your plant is create a hole in and with un-compacted soil. Plants need water and air to survive. Compacted soils – from heavy equipment, too much foot traffic or many other sources – don’t have large enough soil pores in them. And roots have a very hard time pushing through compacted soils. We can fix this a bit with a good hole, but if the overall area is too compacted, this may stunt growth, and you won’t get the robust plant you hoped for. So, working with a hole of the proper size (check back to step one!), take a trowel or garden spade and starting at the bottom of the hole, push gently into the sides of the hole and pry outward. The soil will break off in small clumps of various sizes. If you look closely at the sides of the hole now, you can see some natural structure and cracks along the sides of the hole. These cracks help air and water movement, and root growth. Do not follow conventional “wisdom” and use your foot to press down the soil after you plant. If you do, you compact the soil, undoing this good work you’ve done. Taking this step to make sure your soil isn’t compacted on the sides of you hole will pay off in future dividends.\n- Place your plant in the hole. I use some compost under the plant, to bring the crown just below the surface of the soil. I put the compost into my hole with about half the loose soil, then mix it together. Compost improves soil structure that improves air and water movement, and often increases water availability to plants.\nFor more information on digging a proper hole, ASA and SSSA have developed two videos. One is shorter, and can be found at https://youtu.be/EHq2CP6Gso4. It quickly describes steps 1 and 4. Another video goes into more depth about many variations regarding the soil that will help your plant investments best succeed. It can be found at http://soils.peachnewmedia.com/store/seminar/seminar.php?seminar=60123. I highly recommend that all serious gardeners and landscapers watch these videos, and help our soil work in the best way possible to support plant growth – and protect those garden center investments!\nAnswered by Clay Robinson, University of Illinois Urbana-Champaign\nTo receive notices about future blogs, be sure to subscribe to Soils Matter by clicking on the Follow button on the upper right! Explore more on our webpage About Soils. There you will find more information about Soil Basics, Community Gardens, Green Infrastructure, Green Roofs, Soil Contaminants, materials for Teachers and more.","PLUOTS Methley Plum Black Gold Sweet Cherry Arkansas Black Heirloom\nPleaceful Valley by Stark Bro's Nurseries by Stark Bro's Nurseries Pleaceful Valley\nFruit Trees for your back yard\nWere should my backyard orchard be planted?\nFruit trees require full sun locations for best production but if you can provide them with 6 hours of hot days sun this will be ample sun to produce fruit for you.\nWhat soil do I have?\nFruit Trees prefer a well drained soil, But if we have soil that is more clay or all sand we can add soil amendments and build a soil bed that will encourage fruit production.\nWhat Fruit do I want?\nWe all may have a wish list but we may have to take a step back and ask what are the best fruits to grow in our area ?, varieties of fruit will depend on which part of the country you live in.\nWhat Purpose do I want Fruit Trees for?\nWhat Size do I want my tree to grow?\npatio, dwarf, semi-dwarf, standard, and more recently Coulmnar or \"colonnade\".\nEach type grows to a certain size range and stops growing after that.\nStandard 25-30 Feet\nSemi Dwarf 10-12 Feet\nDwarf 8-10 Feet\nPatio 4-6 Feet\nWhat is my Zone?\nThis question alone will greatly affect the above answers and narrow your selection in some cases\nselecting varieties for our own particular area based on hardiness is best for home gardeners. We all want to be successful in our Back Yard Orchard and most of us don’t want to spend hours and hours like the producers do caring for our trees.\nNote for warmer climents there are Chilling Hours related with varieties that many help with selection.\nMost pollination can be done with out spending extra amounts on unwanted trees. Knowing the varieties and their pollinators is the best way to insure good pollination and more than likely we are adding a few different varieties of the same fruit and they will be able to do the job.\nMost varieties require a pollinator and Bees being the best pollinator will travel miles to other orchards so pollination usually isn’t an issue.\nPlanting fruit trees\nBare root or container\nIf planting a Container tree dig your hole twice the size of the container they come in and just as deep knowing that the graft (the knob on the lower trunk of the tree) needs to be above ground to insure good growth.\nUse a good planting mix that you mix with half of the soil you removed from the hole.\nNever place leaves or manure in the hole while planting or fertilizer, some Garden center trees will have some sort of slow release fertilizer added to their soil and there is no need to add fertilizer while planting that can be done on top of the soil later.\nAfter planting your tree, be sure to water the tree deeply. This will insure that the tree is going to bed for the season wet not dry. In cold climates Trees need to Freeze wet not dry to prevent Winter Kill. In warm weather climates the trees may not be growing and producing in the fall but they are alive and need moisture in these dry times.\nFertilizer isn’t as important now in the fall as it will be in the spring.\nIf planting a Bare Root Tree\nremember always to keep the roots of the bare root trees moist while you prepare to plant. If needed heal your trees into some moist soil while your holes are being dug or get your holes dug ahead of time of receiving your trees.\nBe sure to soak your bare root tree in a bucket of fresh water for at least 10 to 12 hours this will allow the roots to take on needed moisture for planting. All along the roots and trunk of the trees there are doormat root cells and these take in water.\nDig your holes for your bare root trees according to the size of the root mass, at least 3 feet wide and 2 feet deep. Plant your tree using the soil that came out of the hole mixed with a good planting mix , if you choose to add other amendments studies have shown that the best amendments are low bulk sources of minerals, such as bone meal, soft rock phosphate and kelp meal and should be mixed with some topsoil and added to the bottom of the hole ,under the tree.\nTraining and Trimming Fruit Trees\ninformation taken from North Carolina Extension Office\nA primary objective of training and pruning is to develop a strong tree framework that will support fruit production. Improperly trained fruit trees generally have very upright branch angles, which result in serious limb breakage under a heavy fruit load. This significantly reduces the productivity of the tree and may greatly reduce tree life. Another goal of annual training and pruning is to remove dead, diseased, or broken limbs.\nTraining young fruit trees is essential for proper tree development. It is better to direct tree growth with training than to correct it with pruning.\nPruning is most often done during the winter, commonly referred to as dormant pruning. Training includes summer training and summer pruning as well as dormant pruning. The goal of tree training is to direct tree growth and minimize cutting.\nDormant Pruning vs. Summer Pruning\nTrees respond very differently to dormant and summer pruning. Dormant pruning is an invigorating process. During the fall, energy is stored primarily in the trunk and root system to support the top portion of the tree. If a large portion of the tree is removed during the winter, while the tree is dormant, the tree's energy reserve is unchanged. In the spring, the tree responds by producing many new vigorous, upright shoots, called water sprouts, which shade the tree and inhibit proper development. Heavy dormant pruning also promotes excessive vegetative vigor, which uses much of the tree's energy, leaving little for fruit growth and development.\nHistorically, much of the vigorous, upright vegetative growth has been removed during the dormant season; heavy dormant pruning results in a yearly cycle with excessive vegetative growth and little or no fruit production.\nTiming of dormant pruning is critical. Pruning should begin as late in the winter as possible to avoid winter injury. Apple and pecan trees should be pruned first, followed by cherry, peach, and plum trees. A good rule to follow is to prune the latest blooming trees first and the earliest blooming last. Another factor to consider is tree age. Within a particular fruit type, the oldest trees should be pruned first. Younger trees are more prone to winter injury from early pruning.\nSummer pruning eliminates an energy or food producing portion of the tree and results in reduced tree growth. Pruning can begin as soon as the buds start to grow, but it is generally started after vegetative growth is several inches long. For most purposes, summer pruning should be limited to removing the upright and vigorous current season's growth; only thinning cuts should be used. To minimize the potential for winter injury, summer pruning should not be done after the end of July.\nWhen making pruning cuts, it is important to use techniques that will allow the cut surface to heal quickly. Rapid healing minimizes the incidence of disease and insect infection. Pruning cuts should be flush with the adjacent branch without leaving stubs. Also, when large horizontal cuts are made, they should be slightly angled so that water does not set on the cut surface, allowing the growth of rot and disease organisms.\nMany compounds are available as wound dressing or pruning paints. But the best treatment is to make proper pruning cuts and allow the tree to heal naturally. If preferred, tree paints and wound dressing may be used for aesthetic reasons, but they will not promote healing.\nBark Protection: Protect trees from rabbits, mice, voles, other rodents, mechanical damage and sun scald tree guards inexpensive and easy to put on. These protectors are sold at most farm stores we did get this link from Peaceful Valley in Grass Valley California.\nWhat Varieties are good for my area?\nI called and spoke to my local orchards and they were able to give me some great advice for my back yard orchard keeping in mind that you should explain that you are not wanting to jump into the orchard business but would like them to recommend a few varieties that are a sure thing and take less work.\nAnna is the executive Director for the Wisconsin Apple Growers Association and she was very helpful with these varieties for zone 4-5.\nEarly Season: Cortland (cooking and Eating)\nMid Season : Jersey Mac ,Paula Reds and Macintosh,\nLate Season ; Jonathon and Ida red\nI spoke with David Lillard of Mercier Orchards of Blue Ridge Georgia and was also very helpful for Zone 7, recommendations.\nTwig Varieties which are an heirloom apple Red Twig Black Twig most common of the native apples. Not a lot to look at but very disease resistant hardy as well as productive.\nRoam Beauty not a good looking apple but consistent and great flavor.\nLate Season: Granny Smith 100% the best apple for the area.\nRoma, Fuji and Pink Lady\nhe also told me something very interesting. “The last tree to bloom is the first tree I harvest, sounds backwards but it is true”\nI recieved some very helpful information from Sarah at Stark Bro's Nurseries from Louisiana, MO .\nI asked Sarah to help us with some Plum varieties for the home orchard.\nMost plums you find in grocery stores (the round reddish-purple colored ones) are Japanese plums. The trees are ideal for people who live in zones 5-8 (although you may find certain cold-hardy or heat-tolerant varieties as well). One of the best plum trees I can think of is the Methley Plum. It's a seasonal looker (especially its showy blossoms in the spring), a self-pollinating tree, and disease resistant, which means less need for sprays. Ideal for backyard growers!\nDwarf plum trees get to be 8-10 feet tall. Methley is a heat-tolerant variety plum, so even people in zone 9 can grow this tree successfully. I would also recommend the Santa Rosa plum, for very similar characteristics to the Methley plum, but the fruit is slightly larger and the tree is a more vigorous producer of the fruit.\nSweet cherries thrive in very similar zones as plums. Most are ideal for the 5-8 zone range with a few exceptions, depending on the variety.\nThere is a sweet cherry variety called Blackgold that is frost tolerant (it blooms late to avoid late spring frosts that can zap blossoms and ruin chances at fruit production that year), disease-resistant, crack resistant (cherries can be prone to cracking especially when the weather has been dry and then it rains while the fruit is maturing.\nCracking is *mostly* an aesthetic thing, since the fruit is still edible if it does.) and it is self-pollinating as well. Similarly, there is a sweet cherry variety called Whitegold (easy to remember these two together!) that has a yellow-red fruit, as opposed to the dark fruit of the Blackgold, and it has all of the resistant qualities of the Blackgold cherry tree."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:3e05c275-17f4-4bfe-bb6f-b7baa8f91a6f>","<urn:uuid:14623bab-c426-4aeb-ae2a-d6e7a956a497>"],"error":null}
{"question":"As an athlete recovering from knee surgery, what are the main differences between closed and open kinetic chain exercises for rehabilitation, and what is the recommended timeline for returning to sports after ACL surgery?","answer":"Closed kinetic chain (CKC) exercises, like semi-squats, involve keeping the limb in contact with a surface and provide more sensory feedback for movement control compared to open kinetic chain (OKC) exercises, where the limb moves freely in space (like straight leg raises). CKC exercises show better results in muscle characteristics and disease signs, improving quadriceps strength and patellar alignment more effectively. Regarding return to sports after ACL surgery, the timeline typically extends to at least 8 months, though many experts consider this too early. Returning too soon carries a significant risk of re-injury - up to 45% risk of tearing the new ACL without proper rehabilitation, though this can be reduced to 18-20% with proper training. Athletes must pass specific functional tests before starting activities like running programs (at 3 months) and continue working on strength and neuromuscular control before full return to sports.","context":["Subject: Conservative treatment of patellar chondromalacia has been the subject of several studies. One recommended treatment is a strengthening exercise of the quadriceps muscle, which may be performed in closed or open kinetic chains. This study was designed to compare the effect of straight leg raise (SLR) and semi-squat exercises on the treatment of patellar chondromalacia, which has not been done to date.\nMaterial and methods: 32 female university students with a diagnosis of patellar chondromalacia were randomly assigned to two experimental groups: SLR and semi-squat exercise. Before starting exercise protocols, Q angle, maximal isometric voluntary contraction force (MIVCF) of quadriceps, crepitation, circumference of thigh 5 and 10 cm above the patella and patellofemoral pain according to the visual analogue scale (VAS) were assessed. Both groups then followed a 3-week programme of quadriceps muscle strengthening exercises (SLR or semi-squat) starting with 20 exercises twice a day and increasing each session by 5 exercises every 2 days. All measurements were repeated at the end of each week and then again 2 weeks after the 3-week exercise programme.\nResults: Reduced Q angle (mean differences (SD) 0.8 (0.3), p = 0.016) and crepitation (19.9 (8.5), p = 0.04), and an increase in the MIVCF of the quadriceps (15.8 (5.6), p = 0.01) and thigh circumference (1.5 (0.3), p = 0.001) were found in semi-squat group compared with SLR group. However, patellofemoral pain was decreased significantly in both groups.\nConclusion: The results of this study indicate that semi-squat exercises (closed kinetic chain) are more effective than SLR exercise (open kinetic chain) in the treatment of patellar chondromalacia. More studies are needed to investigate the long-term effect of these types of exercise.\nStatistics from Altmetric.com\nPatellar chondromalacia is one of the most common syndromes involved in anterior knee pain, especially in youth.1 Patients with patellofemoral joint dysfunction may report pain, atrophy in the vastus medialis (VM) muscles and crepitation.2–4 Therefore, treatment of this dysfunction, which has been performed conservatively in 80% to 90% of cases,5 is of great importance.\nThe basis of conservative treatment is strengthening of the VM muscle, which may improve patellar alignment by optimizing muscle performance.6 7 Furthermore, this process may prevent unequal pressure on the patellofemoral joint surface and help to reduce joint inflammation and heal the syndrome by correcting the pattern of load distribution on the joint surface.8–10 Different techniques have been recommended for VM strengthening, which may be classified as open or closed kinetic chain exercises.[11 12] The general rule in open kinetic chain (OKC) exercises is that the end of the limb moves freely in space. During closed kinetic chain (CKC) exercises, the end of the limb is in contact with a surface or base and the adjacent joints accompany the movement.13 It has been reported that CKC exercises may provide more sensory feedback that might be used to control movement, compared to OKC exercises.14\nThe common exercise for strengthening the VM muscle in OKC is the straight leg raise (SLR), while the squat is commonly used in CKC.6 15 The results of studies comparing the effects of these exercises are controversial. For example, Witvrouw and colleagues16 showed that there is no difference between these two methods and concluded that both exercises may improve muscle function, relieve pain and optimize performance. They found that CKC exercises produced better results in muscle characteristics and improved signs of disease; however, in a more long-term study, they found neither type of exercise to be preferable.17 Other studies have shown that CKC exercises may improve muscle performance.18 21\nAccording to the results of these studies, it seems that there is no general agreement about the effectiveness of the therapeutic effect of SLR and semi-squat exercises on the patellar chondromalacia syndrome. This study has been designed to investigate the effect of OKC and CKC exercises on patients with patella chondromalacia.\nMATERIAL AND METHODS\nThis study was approved by the ethical committee of the Semnan University of Medical Sciences. Thirty-two female university students suffering from patellar chondromalacia were randomly assigned to one of the two experimental groups (OKC or CKC). Subjects were asked to complete a questionnaire containing the following questions: (a) Do you have any pain during climbing up and down stairs? (b) Do you have any pain after sitting for a long time with the knee flexed? (c) Do you have any problem with knee extension after sitting for a long time with the knee flexed? (d) Does your leg give way during walking? (e) Do you have a history of neuromuscular disease? (f) Do you have a history of musculoskeletal disease? Inclusion criteria included positive answers to questions a to d and a positive Clark test. The subjects who reported a history of neuromuscular or musculoskeletal disorders or who had a deformity in the knee or ankle joint were eliminated from the study.\nThe statistician for each group drew up a computer-generated randomization list. It was given to the physiotherapy department in a sealed numbered envelope. Once the selected subjects had signed their informed consent forms, they were given the appropriate numbered envelope, which contained the subject’s allocation to either the SLR or semi-squat groups. This information was then given to the physiotherapist to administer the appropriate intervention\nSubjects in the OKC group followed an SLR exercise programme for 3 weeks (20 times twice daily) with extended knee. The number of exercises was increased by 5 every 2 days, so by the end of the programme (day 21) the subject was performing 70 SLR exercises twice a day. To perform the SLR exercise, the subject should be in a supine position with hip and knee extended in the exercise limb and the nonexercise limb in hip and knee flexion (fig 1A). The subject was asked to lift the lower limb with extended knee until 45° hip flexion and hold it for 3–4 s, and then let it down for a 3–4 s rest.\nThe subjects in the CKC group followed a semi-squat exercise programme for 3 weeks (20 times twice daily). The number of exercises was increased by 5 every 2 days, so by the end of the programme (day 21) the subject was performing 70 semi-squats twice a day. To perform the semi-squat exercise, the subject was asked to stand on the lower limb to be exercised and hold onto a stable surface using their hand, while the nonexercise lower limb was in 90° hip and knee flexion. The subject was then ordered to flex the extended knee 15–20° and hold this position for 3–4 s, then bring it to full extension and remain in this position for a 3–4 s rest (fig 1B).\nTo ensure the programme was followed, a timetable was given to all subjects and they were asked to tick the appropriate box after each set of exercises.\nAll measurements were performed before the first treatment session, at the end of therapy and 2 weeks following the end of the programme. Measurements included the Q angle, thigh circumference at 5 and 10 cm above patella, degree of anterior knee pain, crepitation, and isometric maximum voluntary contraction force (IMVCF).\nIn order to measure the Q angle, the subjects were placed in the supine position and asked to relax the quadriceps muscle, then the centre of the patella was marked from the crossing of two horizontal and vertical diameters of patella. Two lines were drawn from the centre of the patella: one line to the anterior superior iliac spine and another line to the tibia tuberosity. The angle between these lines (measured by hand-held goniometer) is considered to be the Q angle, which is normally between 13° and 18°.\nThe circumference of the thigh 5 and 10 cm from the upper border of patella was measured using a tape measure. The difference between left and right thigh circumference was a measurement of VM atrophy.\nAnterior knee pain was measured using a visual analogue scale (VAS), on which the patients could grade their pain along a 10 cm line ranging from 0 (\"no pain at all\") to 10 (\"the most severe pain that I can imagine\").\nThe crepitation sound is usually heard during knee joint movements in the patient with patellar chondromalacia, due to the load of limb and muscle contraction that produces compressing force in the patellofemoral joint and causes crepitation. To assess this sound, the examiner held both sides of patella and the knee was flexed and extended passively; subjects were asked to assist the movement. Any sound heard during this manoeuvre was considered crepitation.\nTo measure the strength of the quadriceps muscle, a 500 kg load cell, which was connected to a digital monitor (Load cell model BS-7220, Bongshine, Korea), was used with a quadriceps table. The subject was positioned on the quadriceps table so the knee was fixed at 20° of flexion. The trunk was in the upright position and the subject was asked to hold the edge of the table to prevent unwanted movements. The load cell was connected to the distal part of the test leg by a nonstretchable strap at a right angle. After calibration and adjustment of the output to zero, the subject was asked to push the strap by knee extension. The subject was encouraged to produce MIVCF by shouting “more” and “more”. The measurement was repeated three times with a 1 min rest between each record and the maximum value was recorded as the IMVCF.\nAt the end of each week, we measured the VAS, thigh circumference and crepitation. These were measured again with the Q angle and MIVCF at the end of the exercise programme and 2 weeks later.\nTo compare the effect of SLR versus semi-squat exercises, an intention to treat analysis was used that involved all subjects who were randomly assigned to their group. Student t tests were used to compare the mean changes in the IMVCF, Q angle, thigh circumference and anterior knee pain between the experimental groups.\nThirty-two female university students complaining of patellar chondromalacia were randomly assigned to either the SLR or semi-squat group. Table 1 shows the measured parameters before intervention in both groups; no significant difference was found in the baseline values.\nFollowing intervention, the Q angle was reduced in both groups, while the comparison of mean changes showed a significant reduction in the semi-squat group (1.6 (SD 0.4)) compared to the SLR group (0.7 (SD 0.3)) (p = 0.016).\nCrepitation was seen in at least 90% of subjects in both groups before the exercise programme began. However, this was reduced to 55.6% in the SLR group and 36.7% in the semi-squat group at the end of the programme. This reduction remained stable 2 weeks after intervention.\nAfter intervention, the comparison of mean changes between experimental groups showed a significantly increased muscle force in the semi-squat group (55.9 N (SD 20.2)) compared to the SLR group (40.1 N (SD 28.5)) (p = 0.01).\nFigure 2 shows the mean change in thigh circumference 5 and 10 cm above the patella after 3 weeks of intervention in both experimental groups. The results indicate a significant increase of thigh circumference in the semi-squat group at 5 cm (p = 0.002) and 10 cm (p = 0.01) above the patella compared to the SLR group. These results remained unchanged at 2 weeks of follow-up.\nAt the end of the 3-week exercise programme, significant pain relief was seen in both SLR (3.1 (SD 1.5)) and semi-squat (2.8 (SD 2.3)) groups, while no significant difference was seen between groups (p = 0.13). This reduction remained unchanged at 2 weeks of follow-up.\nThis study was designed to investigate the effect of open and closed kinetic chain exercises on the treatment of patellar chondromalacia. Our results showed that CKC semi-squat exercises are more effective than OKC SLR exercises. One of the observed effects in the semi-squat group was a reduced Q angle. This was confirmed by Doucette and Child8 who reported that CKC exercises may increase functional ability and activity of VM muscles compared to the vastus lateralis muscle. This increased VM muscle activity may correct the patellar alignment towards medial and reduce the Q angle.6 18\nThe reduction in crepitation found in our study was also reported by Post (2005) who showed CKC exercise may cause better functional activity and less crepitation compared to the OKC exercises.5 They also showed a greater improvement in muscle strength with CKC exercise, which was confirmed by our results. It seems from these findings that CKC exercises may produce better patellofemoral joint performance during knee flexion and extension.18\nIncreased thigh circumference after CKC and OKC has not been reported in the literature. However, an increased circumference at 5 and 10 cm above the patella was found in our study, which was accompanied by increased muscle strength after semi-squat exercise. These findings may indicate that CKC exercise is more effective than OKC exercise in producing structural changes in the VM muscle, which is the main muscle controlling the terminal 20° knee extension.2 18\nRelief of anterior knee pain has been reported using different exercise protocols such as CKS, OKS or isokinetic exercises.16 19 Such pain relief was also found in our study in both groups. However, long-term rest and avoidance of stressful activities such as stepping up and down may prevent increased pressure on the patellofemoral joint surface, which may account for the same pattern of pain relief seen in both experimental groups.1 5 A similar pattern of pain relief has been reported by other research teams.16 17\nCo-contraction of hamstring and quadriceps muscles during CKC exercises has been reported in some studies and it has been suggested that this may improve knee joint performance and so improve patellofemoral joint performance.20 21 While the quadriceps muscles act eccentrically to control knee joint flexion, hamstring muscles act to control hip joint flexion.22 Because the hamstring muscle is a two-joint muscle and its activity affects the knee joint also, the simultaneous activities of quadriceps and hamstring muscles on the knee joint may provide more stability for the knee joint and the patellofemoral joint.9 18 This could be another reason for choosing CKC exercises over OKC exercises. On the other hand, the existence of eccentric activity of quadriceps muscles to control knee flexion may be an effective factor to strengthen the quadriceps muscle by the squat exercise.12 23\nThe results of the present study indicate that CKC exercises within the terminal degrees of knee extension may improve patellofemoral joint performance by increasing quadriceps muscle strength and patellar alignment correction. Our findings showed that semi-squat exercises may be considered as an effective conservative method of treatment for patients with patellar chondromalacia.\nWhat is already known on this topic\nPatellar chondromalacia is one of the most common syndromes of anterior knee pain, especially in youth, and exercise therapy has been found to be the most effective method for its treatment.\nThe best type of exercise is the subject of controversy.\nWhat this study adds\nOur study showed that semi-squat exercise (closed kinetic chain) is more effective than straight leg raise exercise (open kinetic chain) in the treatment of patellar chondromalacia.\nThis study was supported by the Semnan University of Medical Sciences. We are grateful to physiotherapists Abdi, Shorgashti and Dehgani for their assistance and those who gave up their time to participate.\nCompeting interests: None declared.\nIf you wish to reuse any or all of this article please use the link below which will take you to the Copyright Clearance Center’s RightsLink service. You will be able to get a quick price and instant permission to reuse the content in many different ways.","Having ACL surgery is a big commitment. It is a painful procedure with a long-anticipated recovery. As your surgeons, we know all of you have one goal in mind, returning to sports after your ACL reconstruction. The research around the return to sports after knee surgery has been studied aggressively for decades. We have great statistics and great rehabilitation programs to guide you. Many of you will try and rush your return to sports too soon. If you attempt to return to sports too soon after ACL surgery then you run the risk of tearing or re-injuring your new ACL.\nBelow are 5 expert Sports Medicine opinions about when an athlete can expect to return to sports after having an ACL ligament reconstruction on their knee.\nA successful return to sports after ACL surgery is your number one goal. There are many variables that go into determining when you should try to return to sports after ACL surgery. The risks of returning to the playing field too early after ACL surgery include suffering a re-tear of your new ACL. A successful return to sports after ACL surgery requires a team approach. It involves you, your surgeon, your athletic trainer and your physical therapist. We have very strict criteria for when an athlete can return to sports after ACL surgery. If you attempt to return to sports too soon you have a significant risk of tearing your new ACL.\nRelated reading …\n- Physical Therapy and ACL Injuries\n- Can I return to sports after ACL surgery?\n- Risks of reinjury after ACL surgery\nThe statistics can be alarming. You might have a 45% risk of tearing your new ACL if you have not rehabilitated your knee properly. You can drive that risk down to 18-20% with the proper training. Unfortunately, once you tear your ACL you are always at risk of tearing the new ACL.\nThe first goal of your physical therapy after ACL surgery early on is to get back your motion and strength. The later stages of the recovery process involve improving your balance, agility, jumping and landing skills. Doing so will decrease the risk of re-injuring your knee and re-tearing your ACL. Your recovery from an ACL reconstruction involves not only the physical aspects of your recovery but perhaps equally as important, the emotional and psychological components. We will get into this in more detail in a later series with many experts who specialize in rehabilitation of ACL injuries.\nThe research regarding the immediate management of an athlete after ACL surgery continues to evolve. It turns out that immediate PT might weaken your new ACL graft. Some surgeons are starting physical therapy a week or two after surgery because of this research. Once PT has started, the research today shows that many people will tolerate an accelerated ACL surgery physical therapy program and be able to return to sports as early as 8 months. There are many experts who feel that might be too early. Thus there is a lot of confusion on the proper way to return to sports after ACL surgery.\nWhat criteria do our experts use to determine when you might be able to return to sports after an ACL reconstruction? Once again we have asked our panel of ACL experts to offer their insights.\nHow Do You Manage Your Athletes After ACL Surgery … and\nWhen Do You Let Your Athletes Return To Sports After ACL Surgery?\nS.S: My ACL surgery post-op protocol involves brief ( about 7 days ) immobilization of the knee in full extension and full weight bearing as tolerated. In some animal studies done at HSS, a short period of post-op immobilization leads to better quality ACL graft biologic tendon to bone attachment. In addition, this has helped me encourage patients to achieve early post-op full extension of the knee, which is very important. After about 7 days, I remove the brace and start physical therapy to reduce swelling, get full range of motion and start isometric strengthening progressing to closed chain lower extremity strengthening. I modify this program for patients with a meniscus repair or a multi-ligament reconstruction. I will allow patients to start a running program at 3 months if they can pass a series of four, simple to administer, functional tests. These tests were developed by a joint group of orthopedic surgeons and physical therapists and were published in a special issue of the journal Sports Health. During this time they continue to work on strength and neuromuscular control.\nD.G : I work very aggressively to have the patient regain full knee extension in the first few days or at least a week or two after surgery. I also have them work with the physical therapist to regain quadriceps strength as quickly as possible. I tend to allow full weight-bearing unless I perform a repair of a bucket-handle meniscus tear. Otherwise, I use a fairly standard protocol, usually restricting jogging for 10 to 12 weeks after surgery and progressing to sport-specific activities in the coming weeks.\nD.O : Initially, start physical therapy within a week. Unless I need to perform a microfracture, I typically do not use a continuous passive motion machine (CPM). Icing after surgery is a great pain reliever. The compression ice machines work great, but typically they are not covered by insurance. A frozen bag of peas can work pretty well in its place.\nAs you can see, determining when to return athletes to sports is a challenging issue. We want to limit your risk of re-injury as much as you do. Routine bracing after ACL surgery is not proven to be necessary. We also differ slightly when it comes to rehabilitation immediately following an ACL reconstruction. It turns out, as Dr Slattery pointed out, that waiting a while before starting PT might be of benefit by allowing your new ligament to start to heal. Stressing full extension as Dr Geier pointed out is critical.\nBottom line.. do not rush your return to sports. Get that leg and your mechanics and stability as close to normal as possible. It will be time well spent."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:b3911d24-5816-4be6-be66-bf5b426b3c82>","<urn:uuid:ef81b139-3132-43f1-8463-ef7d42657216>"],"error":null}
{"question":"I'm preparing my garden for next season and worried about soil health. How do I replenish soil nutrients after harvesting, and what role do plant varieties play in disease resistance? 🤔","answer":"To replenish soil nutrients after harvesting, you should add soil amendments such as compost (either homemade or store-bought organic matter) and spread it in a thick layer over the beds, then turn it over with a shovel to work it into the soil. Regarding disease resistance, choosing the right plant varieties is crucial. Look for plant labels with specific disease resistance codes: 'V' for verticillium wilt resistance, 'F' for fusarium wilt resistance, 'N' for nematode resistance, 'T' for tobacco mosaic virus resistance, 'S' for stemphylium gray leaf spot resistance, and 'A' for alternaria stem canker resistance. While these resistant varieties aren't guaranteed to be immune, they significantly lower the chances of disease.","context":["Hopefully you have had a bountiful summer reaping the rewards from your edible garden. It’s getting to that time when you will pluck the last pepper and bring in the last of the tomatoes. You may have a full belly and a satisfied smile on your face but the gardening game is always on-going. What’s next?\nThe care you give your garden at the end of the growing season plays a big factor in how well your edible garden will do in the coming seasons. Use our tips for fall clean up and help set yourself up for success in the years to come.\nEnjoy the last harvest\nWhen the time has come to wrap up the summer garden, harvest all the remaining produce. Many of the fruits, like tomatoes, can be set in a cupboard to continue ripening after they’ve been picked. Take inventory of all that you have and plan an autumn feast. Then think about canning all the excess or giving it to a food pantry.\nMost of your herbs, like rosemary, oregano, thyme and lavender can be dried for use over the winter. To save the seeds from produce like squash, beans and even tomatoes, leave the vegetables on the plant to ripen completely. If they start to shrivel up, that’s okay. Separate the seeds from the pulp, rinse off completely and then spread out on flat sheet pans to dry out. Once dried, store in a small jar placed in a cool, dry spot. Don’t forget to label each item.\nClean up dead plants\nIf there is any remaining fruit or veggies hanging on plants, pull them off. You can place plants in the compost pile and you don’t want to be adding seeds to the compost. No compost pile? Well, fall is the perfect time to start one. Plants that are showing any indication of pests or disease should be thrown in the yard waste container – do not put infected plants in the compost.\nWhen plants have been removed you can pull out weeds that spent the summer hiding under the veggies. Weeds can be included in the compost pile – but again, not if they have produced seeds.\nClean up pots and containers\nIf you have grown small veggies or herbs in pots you will need to clean them out for the winter. Pull out plants including the root ball. If the soil was new this season you can leave about half of it in the pot to use again next year. Soil older than one season should be replaced for optimal nutrients to your plants.\nIf the plants have shown any signs of disease or pests, then all of the soil should be removed. Scrub out the pots with a mix of dish soap and vinegar in a bucket of water. Turn pots upside down and allow them to dry completely. They will be ready for your cool weather crops or can be stored away in a sheltered location until next spring.\nFeed the soil\nWe’ll never stop preaching that good soil is imperative for a successful garden and even more important for an edible garden. Your plants have spent the summer eating up the nutrients in the garden beds and they need to be replenished.\nNow is a good time for adding soil amendments. If you have been turning your own compost, spread out the results of your hard work. If not, visit your local nursery to pick up some bagged organic matter. Spread a thick layer of either product over the beds. Once spread pick up a shovel and turn over the matter working it into the soil.\nIn North Texas cool weather crops do very well. If you want to put in some “cool” veggies, now is the time. If not, you can just let the beds rest until you are ready to plant in the spring.\nSpread out some mulch\nIf you’re waiting until spring to plant your next crop, you can put in a layer of mulch to cover the surface of the beds. This will help to control weed growth and it also serves to keep the soil warmer making it better prepped for spring planting.\nTend to perennial crops\nIf you have perennial plants like berries, you should prune out scrawny vines. Chose a few of the healthiest vines to keep on each plant and then cut the others back to the ground. Large growing vines like grapes should be thinned out.\nStrawberry plants tend to grow very densely and they can also be thinned. In this case, pull up excess by the root and transplant them to another bed or share the bounty with friends. Asparagus and artichokes can be cut back to around six inches above the soil.\nClean up tools\nAll the apparatus you use in the garden can be very costly. Be kind to your pocketbook by being kind to your supplies. Clean up trellises, tomato cages, growing spikes, etc. and store them away for the winter. Tools in particular need special attention. You should dunk shovels, spades, pruning shears, etc. in solution of water and bleach. This helps to stop the spread of disease.\nIf tools need sharpened now is the time to do it to be ready for spring. Give the wooden handles as well as the metal tips a coating of oil. This helps to hydrate the wood and prevents rust on the metal.\nThink about next year\nDid you make notes throughout the growing season? If so, refresh your memory as to how everything performed and think about any changes you’d like to make for next year. What was successful and what did you most enjoy? If you will be eliminating some plants and adding others, think about available space and start plotting your course.\nWinter will speed by quicker than you think. Use this time well to prepare for next year’s crops. You’ve got your clean up finished, now the planning is the fun part.","Be sure to sanitize tools regularly to halt the spread of disease from one plant to another\nBy Kate Russell\nPlants may not have an active immune system, but that doesn’t mean they just roll over and take whatever hits them. When pathogens strike, plants can respond in two different ways: they use structures and chemicals already in place, and they can make changes when a pathogen is sensed.\nJust as our skin blocks many pathogens from entry, a plant’s skin, or epidermis, does the same thing. That’s why insect feeding and mechanical damage can increase the chance of a disease taking hold — the plant’s first line of defense has been breached.\nPlant cell walls also block viruses, bacteria, and fungi. Unlike our human immune system, which uses white blood cells to actively hunt down and destroy invaders, plant cells have antimicrobial defenses built right in.\nThese defenses take the form of saponins, glucosides, and antimicrobial proteins. Enzyme inhibitors can also stop some pathogens from feeding on the plant. Plants also have chemicals that can neutralize toxins created by a pathogen. Finally, receptors can recognize a pathogen and alert the plant to take further action.\nOnce a pathogen is recognized, cell walls are reinforced and defensive chemicals, such as hydrogen peroxide, as well as those enzymes and proteins, are manufactured.\nIn some cases, plants have evolved a behavior called a ‘hypersensitive response’ in which the tissue surrounding an infection is killed off, to block further infection to neighboring cells.\nRather than treating a disease after it occurs, it is far easier to grow plants that have built-in defenses. This reduces the need for pesticides and fungicides.\nWhen shopping for plants, look at the plant label to see if that particular variety is resistant to diseases that tend to appear in your garden. Plant labels use the following codes to designate specific disease resistances:\nA – Alternaria stem canker\nF – Fusarium wilt\nN – Nematodes\nT – Tobacco mosaic virus (TMV)\nS – Stemphylium gray leaf spot\nV – Verticillium wilt\nSo, if you see a plant label with the letters, V, F, and N on it, that particular plant is resistant against verticillium wilt, fusarium wilt, and nematodes. This does not mean the plant is guaranteed to not get these diseases, but it does mean the chances are significantly lower.\nYou can help your plants fight disease by selecting resistant varieties, spacing your plants properly, employing crop rotation, and providing an adequate amount of water and nutrients.\nAlso, be sure to sanitize your tools regularly, to halt the spread of disease from one plant to another.\nKate Russell is a UCCE Master Gardener in Santa Clara County. For more information, visit mgsantaclara.ucanr.edu or call (408) 282-3105 between 9:30 a.m. and 12:30 p.m. Monday through Friday.\nLatest posts by Kate Russell (see all)\n- Your Garden . . . with Kate Russell: Trap cropping can be effective way to lure pests from MH gardens - August 23, 2019\n- Your Garden . . . with Kate Russell: Plants use structures and chemicals already in place to fight disease - August 9, 2019\n- Your Garden . . . with Kate Russell: Morgan Hill is a great place to start a garden - July 26, 2019"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:5b2ce8b8-8f21-42a4-acbb-c83df0e86b43>","<urn:uuid:9b939cb4-2553-4355-aa8b-abac6b1f0c0b>"],"error":null}
{"question":"How do company requirements for business traveler tracking in Airbnb compare to homeowners association insurance monitoring needs?","answer":"For business travel, companies require employees to book Airbnb using company email addresses to enable traveler tracking through the company dashboard for duty of care and emergency situations. Similarly, with homeowners associations, property owners need to monitor the association's insurance coverage for common areas and track their reserves for repairs. However, while business travel tracking is managed through Airbnb's dashboard tools, homeowners must actively verify their association's coverage and may need additional loss assessment endorsements to cover potential repair assessments for common elements.","context":["Travel managers weigh in on what to consider when you are ready to incorporate Airbnb for Work into your travel policy or guidelines\nThere is a very strong likelihood that some of your employees are using sharing economy providers when they travel for work, even if those providers are not included in your company’s official travel policy or guidelines.\n“The sharing economy trends that have come to define personal travel are now significantly influencing business travel as well,” said Susan Chapman-Hughes, Senior Vice President of American Express Global Commercial Payments.\nPrompted by employee use of sharing economy travel providers for business travel, two key trends are driving their incorporation into official travel policy. The first is a growing recognition of the cost savings benefits and increased traveler satisfaction that result from using providers like Lyft, Uber, and Airbnb.\n“Corporate resistance to the shared economy has softened a bit from a year or so ago because companies are seeing the difference in cost and sophistication and realize that most of the major issues they thought would be obstacles aren’t anymore,” said Bill La Peer, President and Chief Operating Officer at travel consultant firm Zulu Solutions.\nA second trend driving adoption is that sharing economy travel providers are introducing or refining tools and platforms that simplify how travel managers track and manage travelers, bookings, and expense reports.\n“Companies like Lyft and Airbnb are addressing the corporate market with tools and features that meet corporate requirements,” said Neil Hammond, a partner at GoldSpring Consulting LLC, a travel management consulting firm. “This is helping adoption in the corporate travel world.”\nIt’s not difficult to add Airbnb to your travel policy. However, as sharing economy travel providers are unlike traditional travel suppliers in several ways, here are a few recommendations and insights from colleagues on what to consider when you have decided to officially incorporate Airbnb for Work into your travel policy or guidelines.\nGet feedback from all stakeholders\nThe first step is to gather feedback from all key stakeholders to ensure that the guidelines you put in your travel policy for employee use of Airbnb are consistent with overall company policy.\nFor example, human resources and legal will want to provide input on guidelines for team travel where multiple employees are sharing an Airbnb, as well as other use scenarios. Safety and security will want to understand how Airbnb enables traveler tracking on the Airbnb for Work company dashboard and all the measures that are in place to protect travelers and hosts. Your CFO, finance department, and/or your corporate credit card administrator will need to understand how the company dashboard’s expense management tools will work with existing systems, and they’ll want to provide input on expense and reimbursement procedures for Airbnb bookings.\nIdentify your goals\nFeedback from stakeholders will enable you to address their concerns and also identify specific goals for incorporating Airbnb into your official travel policy. Knowing your goals will be fundamental to writing specific guidelines for employees.\nFor example, is your primary goal for incorporating Airbnb cost savings on your accommodation spend? Or, is your primary focus on increasing employee satisfaction by giving your travelers more accommodation choices in local neighborhoods? It could be a little of both. Or, perhaps you are looking for an alternative option to serviced corporate apartments or hotels for employees that require extended stays, or for relocations.\nOnce you establish your goals, you’ll reference them to create a custom Airbnb for Work program for your company.\nIncorporate your company culture\nCompany culture will play a big role in setting guidelines around adopting Airbnb for Work into a travel program. Some companies have specific guidelines in place outlining when employees should book a hotel and when they can book an Airbnb, as well as allowances for Airbnb property type, price, and whether the host can be present. Others have more flexible parameters.\nAt Culture Amp, a SaaS employee feedback and analytics firm, employees are free to choose a hotel or an Airbnb listing as long as it remains within certain parameters.\n“For accommodation, you have the freedom to book hotels or Airbnb as you wish” within upper limits set for price, said Damien Williams, Head of Finance for Culture Amp. “Overall, we expect people to book the equivalent of a four-star property,” he said. “What we are saying is we are not five-star, we are not a Fortune 500—we are a tech startup and that doesn’t resonate with our culture. But we’re not a three-star either. We’re not scrappy, we’re not bootstrapped anymore. So, four-star as a rule of thumb feels right for us.”\nBrandon Gries, Travel and Event Coordinator for Hudl, a software company that provides online tools for coaches and athletes, encourages use of Airbnb for business travel for cost savings, but does not mandate it in travel policy. “I’m not going to require anybody to do it because some people are unfamiliar with [Airbnb] as it’s non-traditional,” Gries said. “But I am going to encourage it and put it in the policy as something we feel that is safe for them but also going to help us out on the company side because it will add some cost savings on our end.”\nDetermine guidelines for different travel scenarios\nAirbnb accommodations can be used for a wider range of travel scenarios than most traditional hotels. Common Airbnb uses for business travel include short-term stays for individuals, team travel, extended stays and relocations, and offsite meetings. “Bleisure” travel—trips that mix business trips with leisure travel—is growing in popularity, particularly among millennials.\nYou might want to consider writing guidelines in your travel policy around each of these scenarios that are consistent with your identified goals for using Airbnb, your company culture, and your relationships with and commitments to your other preferred accommodation providers.\nSpecify if you allow stays in properties where the host is present\nOfficial adoption of Airbnb for Work in your travel policy gives you access to a dashboard filter so you can easily search for work-ready listings. These are private homes and apartments where the host is not present, that offer 24/7 entry access, and provide travelers with the amenities they need to be their most productive.\nDo you want to require your travelers to use these properties or other private Airbnb accommodations, or will they be allowed to stay in Airbnb properties where the host is present?\nAt Box, a cloud management and file sharing service for businesses, travel policy around use of Airbnb for business trips has few limitations and allows travelers to stay in hosted as well as private properties. “We’ve left it pretty open and trust our employees to make the right decisions,” said Rachel Ersted, Senior Treasury Analyst at Box. “We assume that given how competitive the rates are on Airbnb they are going to be choosing a listing that can accommodate all of their needs and make them very comfortable.”\nMore specific guidelines regarding the type of Airbnb accommodation allowed and the price ceiling are written into travel policy at IES Communications, a cabling and communications company. “It has to be a full home, it can’t be a shared space” where the host is present, said Gayla Steeneck, Travel Supervisor for IES, which primarily uses Airbnb for employees on extended-stay installation projects.\nEncourage or require travelers to use their company email address for bookings\nSome of your employees—and many of your millennial employees—are likely familiar with Airbnb and have stayed in Airbnb properties for their personal travel. Most travel managers require or strongly encourage their employees to register and then use their company email address to book business travel with Airbnb through the company dashboard. The registration process is simple and takes just a few minutes.\nAdding Airbnb for Work to your travel program gives you access to a company dashboard that has an array of travel management tools. Making sure your business travelers book Airbnb using their company email address ensures that you can fully utilize the dashboard’s tools. These will enable you to track employees staying in Airbnb listings on business trips, capture booking information for expense reporting, and view average company-wide rates using Airbnb to document cost savings.\n“We want them to use the Medallia link to Airbnb, which gives us visibility to see who is booking what, when, and where, via the dashboard,” said Alla Neys, Director of Global Travel Programs for Medallia, a company that offers a cloud-based platform to capture customer feedback. “We also want to ensure they select suitable locations—that’s actually spelled out in the requirements—and make sure there is a good balance between using Airbnb and our preferred hotel program. So, if the cost is equal to or lower than a preferred hotel it’s okay to book Airbnb. So far, it’s worked great.”\nBox also encourages employees to book through their company’s Airbnb account to enable traveler tracking on the Airbnb for Work dashboard, “because part of duty of care is knowing where people are in the case of an emergency,” Ersted said. “It also makes it easier for their receipts to feed through Concur so we know that number is going to be accurate.”\nLet people know that Airbnb is part of your travel policy\nOnce you have expanded your travel policy to include Airbnb for Work, the final step is to let employees know Airbnb is officially part of your travel program, and make sure they understand the company’s guidelines for use. “So much of the success of introducing something new to a travel management program is in the communications,” said Jeanne Liu, Vice President of Research at the Global Business Travel Association (GBTA).\nWhile this might sound obvious, according to Chapman-Hughes of American Express Global Commercial Payments, not all travel managers are communicating effectively. “Nearly one in five travelers are still unsure whether their employer’s policies allow for sharing economy services, making it especially important for companies to communicate clear details about the services and amenities that their policy covers,” she said.\nCommunication strategies are as unique as each company or organization, but common methods include emails, social media posts, digital and/or print flyers, newsletter announcements, and postings in the travel section of a company’s intranet. Most travel managers use a combination of communication methods that are introduced over a specific timeline so there are several information touchpoints. Some have found it effective to announce inclusion of Airbnb for Work in company travel policy during an event like a lunch-and-learn or travel fair, or to cover it during new hire orientations.\nAirbnb can help you actualize significant cost savings for your company and increased traveler satisfaction levels for your employees—but only if you get stakeholder buy-in and support, spell out clear guidelines around bookings, and effectively communicate that you’ve expanded your policy to include Airbnb for Work.","The worst time to find out that you have no insurance, or inadequate insurance, is after a loss. If any of the following situations apply to you, a standard insurance program might not be enough.\n1 Problem: Your home is 30 or more years old. Insurance will cover the cost of bringing a damaged or destroyed building back to its previous state. But will you have enough to make sure it complies with current building codes? Some communities require an owner to demolish and completely rebuild a building that has been damaged over a certain percent (often 50 percent). The standard homeowners policy does not cover demolition costs.\nSolution: Add “ordinance or law coverage.” This policy endorsement (addition) will cover your additional costs of complying with ordinances or laws when rebuilding after an insured loss.\n2 Problem: You have a historic or highly customized home. If your homeowners policy provides “actual cash value” coverage, it will pay a maximum of the replacement value of your lost or damaged property, less depreciation. That probably won’t come anywhere close to the cost of replacing the special craftsmanship and materials that go into many historic homes. Even an ordinary “replacement cost value” policy probably won’t provide enough protection.\nSolution: Buy a homeowners policy that pays losses on a restoration cost or guaranteed value basis. A restoration cost policy will pay to restore your home’s features, while a guaranteed value policy will pay up to a maximum amount that you select.\n3 Problem: Your property is subject to a homeowners association. Since you share ownership of common areas with others, you’ll want to check that the association has appropriate insurance coverage. You’ll also want to make sure it has enough reserves to pay for repairing or replacing common elements near the end of their useful life. Associations that lack reserves for necessary repairs can assess members to pay the difference.\nSolution: Buy a loss assessment endorsement for your policy. This will add coverage for assessments when common elements owned by the homeowners association need repairs.\n4 Problem: You live in an area where costs are increasing rapidly. Unless you’re vigilant about updating your coverage, your policy might not pay enough to repair or replace your home after a loss. This problem could become worse if a disaster affects many properties in your area. Labor and material shortages would push up the cost of repairs.\nSolution: You can add an inflation guard endorsement to your homeowners policy. This will automatically increase your coverage limits every year by a specified percentage.\n5 Problem: You occasionally rent out your home. Short-term rentals can bring in cash—they also increase your risk exposures.\nSolution: Minimize your risk by requiring tenants to pay a deposit and/or provide proof of their own coverage. Airbnb provides landlords some protection—it will reimburse hosts for up to $1 million of damage to eligible property. However, this is not insurance and is not regulated by the state insurance department. If you plan to rent your home through Airbnb or a similar service, please call us to discuss your insurance needs.\n6 Problem: You have business equipment or property at your home. The typical homeowners insurance policy limits coverage for “business personal property” to $2,500, which might not be enough.\nSolution: Add an increased limits business property endorsement to cover business personal property at home and off premises. If your business property consists of computers or electronics, you might need a computer or electronic equipment endorsement for your homeowners policy. Without this endorsement, the typical homeowners policy limits coverage for computers and electronics to $2,500; one high-end computer and accessories could easily cost more than that to replace.\n7 Problem: You have valuable trees and shrubs. Landscaping can add as much as 20 percent to a home’s value. Is yours protected?\nSolution: Know your coverage. Most homeowners policies will cover a tree or shrub damaged or destroyed by a “covered peril.” These typically include fire, lightning, explosion, aircraft, vehicles not owned by the resident, theft, vandalism and malicious mischief. Most policies limit coverage for any one tree or shrub to $500 apiece, to a maximum of 5 percent of the amount of the coverage on your home’s structure.\n8 Problem: You have people who are not related to you living in your home. Your policy might not cover them.\nThe homeowners policy covers the “named insured,” or person whose name is on the policy. (If your house is jointly owned, both owners should be named on the policy.) The policy also insures people who are related to the named insured and other people under age 21 who are in the care of any insured. The policy might not cover other people, particularly for liability, even if you consider them household members.\nSolution: Contact us to discuss your situation. You can ask your insurer to cover another individual as a named insured or insured.\n9 Problem: You own high-value collectibles, jewelry, antiques or firearms. Homeowners policies usually put a lower sublimit on coverage for these high-worth items. If your policy limits coverage to $2,500, your valuables might be underinsured.\nSolution: Add an endorsement to your homeowners policy or buy a separate “floater” insurance policy. We can help you decide which is best for your needs.\n10 Problem: You have remodeled, added to or upgraded your home. Do you have enough coverage?\nSolution: Check your insurance coverage at least annually, and after any significant remodel or upgrade. Update your limits as needed.\nIf you have any questions on your coverage, or if you’d like to schedule a policy review, please contact us."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:d2fd2097-0625-47ff-b71c-c1e64556973d>","<urn:uuid:6a792a98-d8e2-4db6-928e-1a04e558ebc9>"],"error":null}
{"question":"What is the key difference between warp and weft knitting in terms of yarn requirements?","answer":"In weft knitting, the entire fabric can be produced from a single yarn, while warp knitting requires one yarn for every wale (vertical column of stitches). This means warp knits must have a whole set of warp yarns - one or more for each needle on the machine.","context":["Gauge and Quality\nThe size of the needle and the spacing of the needles on knitting machines determine the number and size of the knit stitches and their closeness those are known as knitting element. Each wale is formed on one needle. The number of needles is equal to the number of Wales. The closeness of the stitches determines whether a knit fabric will be lightweight and open or heavier and more dense. The term gauge is used to describe the closeness of knit stitches. Gauge is the number of needles in a measured space on the knitting machine. Higher-gauge fabrics (those with more stitches) are made with finer needles; lower gauge fabrics are made with coarser or larger needles.\nThe term cut is also used to designate the number of needles per inch in the needle bed of a circular weft knitting machine. To describe the stitch density of a single or double knit fabric, the fabric may be designated as an 18-, 20-, 22-, or 24cut fabric. The higher the cut, the closer the stitches; the lower the cut, the coarser the fabric.\nVarying types of knitting machines measure gauge over different distances on the machine. For example, circular knit hosiery measures the number of needles in 1.0 inch, fullfashioned knitting in 1.5 inches, and Raschel knits in 2.0 inches.\nBecause of these differences, it is best to keep in mind the generalized principle that the higher the gauge, the closer the stitches.\nThe quality of needles used in manufacturing knit goods is related directly to the quality of the fabric produced. Needles of uneven size and quality will produce knit fabrics with unevensized stitches and imperfect surface appearance.\nIn warp knits, those knits in which the yarns interlace in the long direction, one or more yarns are allotted to each needle on the machine, and those yarns follow the long direction of the fabric. For weft knits, those in which the yarns interlace crosswise or horizontally, one or more yarns are used for each course, and these yarns move across the fabric. In weft knits, one yarn may have from twenty to several hundred needles associated with it. To summarize, weft knits can be made with one yarn, but warp knits must have a whole set of warp yarns, that is, one or more for each needle.\nOnce the basic distinction between warp and weft knits has been made, further subdivisions of knit classifications are usually based on the types of machines used in their production. The majority of knit fabrics are named after the machines on which they are constructed. For this reason, the discussion of knitted fabrics that follows is organized around the types of machines used in manufacturing knit fabrics and the types of knit fabrics made on these machines.\n1. Flat or circular jersey, or single knit, machine: one needle bed and one set of needles.\n2. Flat or circular rib machine: two needle beds and two sets of needles.\n3. Flat or circular purl, or links-links, machine: two needle beds and one set of needles.","Thursday, December 17, 2009\nWeft and warp knitting\nThere are two major varieties of knitting: weft knitting and warp knitting. In the more common weft knitting, the wales are perpendicular to the course of the yarn; however, in warp knitting, the wales and courses run roughly parallel. In weft knitting, the entire fabric may be produced from a single yarn, by adding stitches to each wale in turn, moving across the fabric as in a raster scan. By contrast, in warp knitting, one yarn is required for every wale. Since a typical piece of knitted fabric may have hundreds of wales, warp knitting is typically done by machine, whereas weft knitting is done by both hand and machine. Warp-knitted fabrics such as tricot and milanese are resistant to runs, and are commonly used in lingerie.\nWeft-knit fabrics may also be knit with multiple yarns, usually to produce interesting color patterns. The two most common approaches are intarsia and double knitting. In intarsia, the yarns are used in well-segregated regions, e.g., a red apple on a field of green; in that case, the yarns are kept on separate spools and only one is knitted at any time. In the more complex double knitting, two or more yarns alternate repeatedly within one row and all the yarns must be carried along the row, as seen in Fair Isle sweaters. Double knitting can produce two separate knitted fabrics simultaneously, e.g., two socks; however, the two fabrics are usually integrated into one, giving it great warmth and excellent drape.\nIn the knit stitch on the left, the next (red) loop passes through the previous (white) loop from below, whereas in the purl stitch (right), the next stitch enters from above. Thus, a knit stitch on one side of the fabric appears as a purl stitch on the other, and vice versa. Knit (or plain) and purl stitches\nIn securing the previous stitch in a wale, the next stitch can pass through the previous loop either from below or above. If the former, the stitch is denoted as a knit stitch or a plain stitch; if the latter, as a purl stitch. The two stitches are related in that a knit stitch seen from one side of the fabric appears as a purl stitch on the other side.\nThe two types of stitches have a different visual effect; the knit stitches look like \"V\"'s stacked vertically, whereas the purl stitches look like a wavy horizontal line across the fabric. Patterns and pictures can be created in knitted fabrics by using knit and purl stitches as \"pixels\"; however, such pixels are usually rectangular, rather than square, depending on the gauge of the knitting. Individual stitches, or rows of stitches, may be made taller by drawing more yarn into the new loop (an elongated stitch), which is the basis for uneven knitting: a row of tall stitches may alternate with one or more rows of short stitches for an interesting visual effect. Short and tall stitches may also alternate within a row, forming a fish-like oval pattern.\nTwo courses of red yarn illustrating two basic fabric types. The lower red course is knit into the white row below it and is itself knit on the next row; this produces stockinette stitch. The upper red course is purled into the row below and then is knit, consistent with garter stitch.In the simplest knitted fabrics, all of the stitches are knit or purl; these fabrics are denoted as stockinette and reverse stockinette, respectively. Vertical stripes (ribbing) are possible by having alternating wales of knit and purl stitches; for example, a common choice is 2x2 ribbing, in which two wales of knit stitches are followed by two wales of purl stitches, etc. Horizontal striping (welting) is also possible, by alternating rows of knit and purl stitches; the simplest of these is garter stitch, so-called because its great elasticity made it well-suited for garters. Checkerboard patterns (basketweave) are also possible, the smallest of which is known as seed stitch: the stitches alternate between knit and purl in every wale and along every row.\nFabrics in which the number of knit and purl stitches are not the same, such as stockinette, have a tendency to curl; by contrast, those in which knit and purl stitches are arranged symmetrically (such as ribbing, garter stitch or seed stitch) tend to lie flat and drape well. Wales of purl stitches have a tendency to recede, whereas those of knit stitches tend to come forward. Thus, the purl wales in ribbing tend to be invisible, since the neighboring knit wales come forward. Conversely, rows of purl stitches tend to form an embossed ridge relative to a row of knit stitches. This is the basis of shadow knitting, in which the appearance of a knitted fabric changes when viewed from different directions.\nTypically, a new stitch is passed through a single unsecured (\"active\") loop, thus lengthening that wale by one stitch. However, this need not be so; the new loop may be passed through an already secured stitch lower down on the fabric, or even between secured stitches (a dip stitch). Depending on the distance between where the loop is drawn through the fabric and where it is knitted, dip stitches can produce a subtle stippling or long lines across the surface of the fabric, e.g., the lower leaves of a flower. The new loop may also be passed between two stitches in the present row, thus clustering the intervening stitches; this approach is often used to produce a smocking effect in the fabric. The new loop may also be passed through two or more previous stitches, producing a decrease and merging wales together. The merged stitches need not be from the same row; for example, a tuck can be formed by knitting stitches together from two different rows, producing a raised horizontal welt on the fabric.\nNot every stitch in a row need be knitted; some may be left as is and knitted on a subsequent row. This is known as slip-stitch knitting. The slipped stitches are naturally longer than the knitted ones. For example, a stitch slipped for one row before knitting would be roughly twice as tall as its knitted counterparts. This can produce interesting visual effects, although the resulting fabric is more rigid, because the slipped stitch \"pulls\" on its neighbours and is less deformable. Slip-stitch knitting plays an important role in mosaic knitting, an important technique in hand-knitting patterned fabrics; mosaic-knit fabrics tend to be stiffer than patterned fabrics produced by other methods such as Fair-Isle knitting.\nIn some cases, a stitch may be deliberately left unsecured by a new stitch and its wale allowed to disassemble. This is known as drop-stitch knitting, and produces a vertical ladder of see-through holes in the fabric, corresponding to where the wale had been.\nThe stitches on the right are right-plaited, whereas the stitches on the left are left-plaited.\nWithin limits, an arbitrary number of twists may be added to new stitches, whether they be knit or purl. Here, a single twist is illustrated, with left-plaited and right-plaited stitches on the left and right, respectively. Right- and left-plaited stitches\nSee also: Plaited stitch (knitting)\nBoth knit and purl stitches may be twisted: usually once if at all, but sometimes twice and (very rarely) thrice. When seen from above, the twist can be clockwise (right yarn over left) or counterclockwise (left yarn over right); these are denoted as right- and left-plaited stitches, respectively. Hand-knitters generally produce right-plaited stitches by knitting or purling through the back loops, i.e., passing the needle through the initial stitch in an unusual way, but wrapping the yarn as usual. By contrast, the left-plaited stitch is generally formed by hand-knitters by wrapping the yarn in the opposite way, rather than by any change in the needle. Although they are mirror images in form, right- and left-plaited stitches are functionally equivalent. Both types of plaited stitches gives a subtle but interesting visual texture, and tend to draw the fabric inwards, making it stiffer. Plaited stitches are a common method for knitting jewelry from fine metal wire.\nIllustration of entrelac. The blue and white wales are parallel to each other, but both are perpendicular to the brown and gold wales, resembling basket weaving. Edges and joins between knitted fabrics\nThe initial and final edges of a knitted fabric are known as the cast-on and bound-off edges. The side edges are known as the selvages; the word derives from \"self-edges\", meaning that the stitches do not need to be secured by anything else. Many types of selvages have been developed, with different elastic and ornamental properties. Vertical and horizontal edges can be introduced within a knitted fabric, e.g., for button holes, by binding off and re-casting on again (horizontal) or by knitting the fabrics on either side of a vertical edge separately.\nTwo knitted fabrics can be joined by embroidery-based grafting methods, most commonly the Kitchener stitch. New wales can be begun from any of the edges of a knitted fabric; this is known as picking up stitches and is the basis for entrelac, in which the wales run perpendicular to one another in a checkerboard pattern.\nIllustration of cable knitting. The central braid is formed from 2x2 ribbing in which the background is formed of purl stitches and the cables are each two wales of knit stitches. By changing the order in which the stitches are knit, the wales can be made to cross. Cables, increases and lace\nOrdinarily, stitches are knitted in the same order in every row, and the wales of the fabric run parallel and vertically along the fabric. However, this need not be so. The order in which stitches are knitted may be permuted so that wales cross over one another, forming a cable pattern. Cables patterns tend to draw the fabric together, making it denser and less elastic; Aran sweaters are a common form of knitted cabling. Arbitrarily complex braid patterns can be done in cable knitting, with the proviso that the wales must move ever upwards; it is generally impossible for a wale to move up and then down the fabric. Knitters have developed methods for giving the illusion of a circular wale, such as appear in Celtic knots, but these are inexact approximations. However, such circular wales are possible using Swiss darning, a form of embroidery, or by knitting a tube separately and attaching it to the knitted fabric.\nIn lace knitting, the pattern is formed by making small, stable holes in the fabric, generally with yarn overs.A wale can split into two or more wales using increases, most commonly involving a yarn over. Depending on how the increase is done, there is often a hole in the fabric at the point of the increase. This is used to great effect in lace knitting, which consists of making patterns and pictures using such holes, rather than with the stitches themselves. The large and many holes in lacy knitting makes it extremely elastic; for example, some Shetland \"wedding-ring\" shawls are so fine that they may be drawn through a wedding ring.\nBy combining increases and decreases, it is possible to make the direction of a wale slant away from vertical, even in weft knitting. This is the basis for bias knitting, and can be used for visual effect, similar to the direction of a brush-stroke in oil painting.\n Ornamentations and additions\nVarious point-like ornaments may be added to knitting for their look or to improve the wear of the fabric. Examples include various types of bobbles, sequins and beads. Long loops can also be drawn out and secured, forming a \"shaggy\" texture to the fabric; this is known as loop knitting. Additional patterns can be made on the surface of the knitted fabric using embroidery; if the embroidery resembles knitting, it is often called Swiss darning. Various closures for the garments, such as frogs and buttons can be added; usually buttonholes are knitted into the garment, rather than cut.\nOrnamental pieces may also be knitted separately and then attached using applique. For example, differently colored leaves and petals of a flower could be knit separately and applied to form the final picture. Separately knitted tubes can be applied to a knitted fabric to form complex Celtic knots and other patterns that would be difficult to knit.\nUnknitted yarns may be worked into knitted fabrics for warmth, as is done in tufting and \"weaving\" (also known as \"couching\").\nTypes of knitting"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:2c5d7aa4-7db4-4652-8676-d9535b29a54a>","<urn:uuid:687a71c9-d466-4b90-9321-b9ac4bd8af8f>"],"error":null}
{"question":"How does the Czech Republic's education system promote literacy and access to knowledge, and what role does online disinformation play in challenging educational efforts?","answer":"The Czech Republic has a comprehensive education system that has effectively eliminated illiteracy. Education is mandatory for ages 6-15, with the state maintaining full control over the system. The system includes preschool, elementary, high school, grammar school, and university levels, with equal access due to no monetary barriers (though textbooks and meals must be paid separately). However, this educational foundation is challenged by the spread of online hoaxes and disinformation. These false messages can manipulate public opinion and require critical thinking skills to verify information. The phenomenon includes various forms, from harmless jokes to extensive fraud, and can particularly impact vulnerable groups by reinforcing prejudices and stereotypes. Experts recommend being cautious when communicating online and verifying information from multiple sources before sharing.","context":["Not only are the city lights the most stunning highlights of the country’s captivating attractions, but they are also among the most appealing. This emerging nation, which is situated in the central region of the European continent, has been instrumental in fostering the expansion and consolidation of a nation that was formerly subdivided into two separate nations. Poland can be found to the north-east of the Czech Republic; Germany can be found to its west and northwest; Slovakia can be found to its east; and Austria can be found to its south. Prague, the country’s largest city and the location of the majority of the nation’s economic activity, serves as the nation’s capital. The city is also the country’s largest urban center. Bohemia, Moravia, and Silesia are all historically significant parts of the Czech Republic. The Czech Republic is a signatory to both the North Atlantic Treaty Organization and the European Union (EU).\nThe dissolution of the Austro-Hungarian Empire in the wake of World War I prepared the way for the establishment of the Czechoslovak Republic as an independent state the following year, in 1918. In addition, a communist regime came to power in Czechoslovakia in a coup d’etat in the year 1948. Reforms, such as the Velvet Revolution in 1989, were implemented as a result of the dissatisfaction of the people with the communist rule. On January 1, 1993, the country was peacefully divided into two new nations: the Czech Republic and Slovakia.\nThe government of this nation is a Parliamentary Republic, and it is managed by the Prime Minister, the President, and the Supreme Court. The legal system is overseen by the Supreme Court. There are two legislative bodies that make up the country’s Parliament; their names are the Senate and the Chamber of Deputies.\nThe nation is endowed with magnificent castles and landscapes, both of which give visitors the impression that they are touring a royal estate. The nation’s main city, Prague, is rich with a variety of venues for the performing arts, including theaters, music venues, and art galleries. The steadfast people of the country have done an incredible job of preserving the country’s history, which has helped bring the country and all of Europe closer together.\nCULTURE AND OLD WAYS OF DOING THINGS\nThe cultural preeminence of the Czech Republic may be traced back to the Middle Ages, when artists and musicians from all across the nation exhibited their remarkable abilities to an appreciative audience. The people of the country have continued to play a significant role in the development and maintenance of the cultural features of the country. The nation and its people have been brought closer together via its singular manifestos by the numerous customs, works of art, and styles that have been passed down through the generations. Many diverse artists have contributed to the resuscitation and growth of the country’s art sector by honing their skills to create exceptional works of art. The world-famous painters of the Czech Republic have left behind works of art that have been passed down through the centuries and carefully preserved.\nThe 14th century paved the way for the development of a distinctive Czech painting style. The museums in the country, such as the National Museum of Prague, the Museum of Military History, the Museum of Decorative Arts, and Bertramka: Mozart and Duseks Museum, are among the country’s most popular tourist destinations because they house and maintain a variety of important pieces of art. In the 19th century, the remarkable Josef Mánes had shown what a Czech traditional painting should be. In addition to this, the country’s theater sector has expanded in recent years. Both the National Theatre in Prague and the National Theatre in Bratislava are held in extremely high esteem across the nation and are popular tourist destinations.\nIn addition, Czech music has received a lot of praise and recognition in this country. Bedrich Smetana, a prominent musician recognized as the “father of Bohemian national music,” is a composer who exemplifies a tremendous music prowess. He is also known as an outstanding pianist. Leos Janácek, a well-respected opera performer, has performed works that feature both traditional and folk-inspired themes. In addition, Czech literature has been of enormous significance, both in terms of its contribution to the development of the Czech language and in terms of its influence on the development of other languages, such as Latin and German.\nThe Czech language, which is spoken by Czechs both in their own country and all over the world, is the official language of the Czech Republic. The origins of the Czech language may be traced back to West Slavic (a combination of Czech, Polish, Slovak, Sorbian, and Kashubian). The Czech language is spoken in a number of other countries as well, including Austria, the Ukraine, Germany, Croatia, and western Romania. The Czech language is spoken natively by 96% of the people living in the Czech Republic. On the other hand, people of various nationalities who have settled in the country have picked up the language as well.\nThe origins of the Czech language may be traced back to the 10th century, when it began to differentiate itself from Slavonic. In addition, the development of literature and the expansion of its usage across the country also took place during the Middle Ages. Along with the expansion of the Bohemian state into neighboring countries, the Czech language also made its way outside the limits of the Czech Republic.\nDue to the fact that Czech and Slovak have a similar linguistic style, speakers of both languages are able to comprehend each other’s written works despite the fact that their spoken languages are distinct. When traveling across the nation and exploring its many amazing sites, visitors have the option of employing an interpreter to help them. Having said that, another language spoken there is English.\nThere are also a number of dialect variants spoken in the nation, which may be broken down into two categories: Common Czech and the dialect spoken in Moravia and Silesia. In Bohemia, the majority of the population speaks Common Czech.\nForms and styles of the Czech language may be traced back to Slavic languages; as a result, the Czech language and several Slavic languages share branches of Indo-European styles. The sequence of words in Czech is generally rather close to the order of words in English.\nSlovak, German, Polish, and Romany are some of the additional languages spoken in this nation in addition to English.\nEducation has consistently ranked towards the top of a nation’s list of priorities as one of the most essential aspects. A record of the country’s illiteracy rate has never been kept due to the fact that the state maintains complete control over the educational system. Education, both mandatory and elective, is available to children between the ages of 6 and 15. Basic classes make up the foundation of the Czech Republic’s educational system. Preschool students are often between the ages of 2 and 5 years old, while elementary students are typically between the ages of 6 and 15 years old. The degrees of education that are provided in the nation include high school, grammar school, and universities. Because to the lack of monetary barriers, citizens of the Czech Republic have equal access to quality educational opportunities. On the other hand, expenses such as textbooks and meals are not included in the tuition and must be paid individually.\nIn the nation, the educational program known as Basic Education lasts for a total of nine years. After completion of the curriculum, participants will get their Vysvden, also known as their Primary School Leaving Certificate. Another part of the education system in the Czech Republic is known as General Secondary, and it consists of a total of 8 years of study. This program is open to students between the ages of 11 and 19. In addition, another General Secondary category is provided, which is the entrance after the seventh year of the primary school. This category lasts for a total of six years following the primary school. In addition, the students in the Gymnasiums receive training that will prepare them for their future careers. There are three different kinds of schools that make up secondary education: secondary general schools (often known as gymnasiums), secondary technical schools, and secondary vocational schools. Higher education can be obtained in a university setting or through non-university settings, such as the bachelor’s degree and master’s degree study programs. On the other side, higher education at the university level consists of programs leading to the bachelor’s, master’s, and doctoral degrees. Courses in areas such as engineering, medicine, humanities, sciences, economics, agriculture, teacher training, veterinary medicine, and the arts can be found at both public and private educational institutions.\nThe health care industry in the Czech Republic is centered on a national health care system that includes both public and private treatment options. People living in the nation are eligible for services and benefits such as health insurance, which are offered by the government as well as other sectors. In addition, individual contributions or contributions made by the state themselves are a part of the health insurance system in the Czech Republic. In addition, the National Health Service, which is part of the Ministry of Health, provides support to the universities and regional hospitals that are a part of the health care system in the country, allowing them to provide a wider range of excellent patient care in settings that have been upgraded. In 1999, the percentage of GDP that was spent on healthcare was around 7.2%.\nAt the municipal level, health care is provided for primary care, including general medical care, maternity and child health, dental, gynecology, emergency medical services, and key preventative services such as screening and immunization. In addition, the country’s secondary and tertiary health care facilities have offered a broad array of services and features, such as specialist ambulatory medical services, internal medicine, surgery, paediatrics, and gynecology. These are only few of the specialties that are available.\nThe high standard of care provided by hospitals across the nation has led to improvements in both the level of care provided by physicians to their patients and the level of care provided by hospitals to the general population. Medical services like as X-rays, immunizations, and annual checkups are provided to each and every student in the nation’s public and private schools.\nHealth awareness efforts around the nation have included the incorporation of preventative measures for TB, hepatitis, and encephalitis. In the year 2000, the rate of infant mortality was approximately 4 for every 1,000 live births, and the overall fertility rate was approximately 1.2. As of the year 2000, the typical expected lifespan was 75 years.\nThe European Health Insurance Card (EIC) is a card that travelers from Europe may use in countries within the European Economic Area (EEA) and Switzerland to receive emergency medical care at no cost or at a discounted rate.\nThis European nation has experienced phenomenal growth over the course of the past several decades. The Czech Republic, which is both one of the most and one of the most highly industrialized countries in the post-Communist states of Central and Eastern Europe, has achieved stable and flourishing economic advancements in recent years. The Czech Republic is blessed with a wealth of natural resources, and its primary industries include metallurgy, ceramics, pharmaceuticals, machinery and equipment, glass manufacture, and iron and steel manufacturing. Goods that are imported and exported include vehicles and their components, gasoline, raw materials, and chemical products. The production of steel and related goods has historically played a significant role in the economy of the country. Wheat, potatoes, and sugarbeets are all examples of products that come from the country’s agricultural sector.\nThe prosperous economic advantages of the Czech Republic offer well-developed infrastructures and factories suitable for producing goods, equipments, and other machinery-related products that are appreciated internationally. These products include goods, equipments, and other products. Both the European Union and the World Trade Organization count the Czech Republic as one of their member states. This nation has been successful in luring investments from outside its borders due to its central location on the European continent. The trade policy of the Czech Republic is very similar to the trade policy of the other countries that are members of the European Union. There are high tariffs on agricultural and manufactured goods, and there are also non-tariff barriers in the form of agricultural and manufactured subsidies, quotas, import restrictions, and services.\nThe Czech Republic’s tax rates are among the lowest in Europe. A value-added tax (also known as VAT), an inheritance tax, and a real estate transfer tax are all types of taxes that are levied in the country. The national government has incurred significant costs, accounting for around 42.6% of GDP. These costs include expenditures made on petrochemical refiners and telecommunications. The country’s economy is one of the most developed and advanced in all of Central and Eastern Europe, particularly in terms of its banking industry.History Of Syria","The online hoax phenomenon and how to address it\nModern media and communications technology are connecting people across the global village, facilitating the dissemination and sharing of information without any of the previous obstacles posed by space and time. The demand for open communications and the concurrent flood of information, however, increasingly require us to be able to think critically and verify the information we receive.\nIf we do not take the time to check the sources of the information we receive online, we might easily believe, for example, that Romani people receive higher welfare payments than anybody else in the Czech Republic because of their nationality, that the number of Romani minority members here has doubled in just 14 years, or that the Czech actor Jan Werich warned against Islam back in 1938. With the aid of leading experts in the field, therefore, the magazine Romano vod'i is mapping a phenomenon that is part of today's flood of information, that of online HOAXES.\nThis originally English-language term means a message, the content of which is false or startling, that constitutes a fabrication, fraud, misrepresentation or prank. English linguist Robert Nares (1753-1829) inferred the probable origin of the term in the older word \"hocus\", which means an illusion or a trick.\nThis phenomenon was not born with the discovery of the Internet or online social networking, but is a new form of the urban legends and rumors that have come to life from time to time ever since the Middle Ages. The Internet and social networks, however, provide exceptionally fertile ground for such false messages to be used as a tool for manipulating public opinion.\nThe dangers flowing from this kind of manipulation were demonstrated in the Czech Republic in 2012 by the example of a 15-year-old boy from the town of Břeclav who severely injured himself falling from the upper story of a building and who then attempted to explain his injuries by inventing the story that Romani people had assaulted him, and the consequence of his lie was not just an anti-Romani hate campaign by many media outlets nationwide, but also an enraged mob of 3 000 assembling on the town square. The phenomenon of such alarming or deceptive communications has long been studied by Josef Džubák, who specializes in hoaxes as the operator of the website www.hoax.cz.\nDžubák points out that hoaxes are a broad category of phenomena, ranging from harmless jokes to extensive fraud. One particular category is so-called phishing, or the effort to tempt Internet users to provide private information such as bank account numbers, birthdates or passwords for the purpose of misusing that information.\nWhen using the Internet, Džubák recommends being appropriately cautious when communicating with strangers. While he acknowledges that almost anybody can be easily fooled, he believes the basis for online safety is to verify dubious information and not to blindly disseminate it.\nHoaxes make connections that can be significant in the context of more vulnerable or less well-known groups such as refugees or Roma. Disinformation has the potential to bolster prejudices or stereotypes and to cause panic among members of mainstream society, and even panic based on a hoax can have absolutely real consequences.\nFor that reason, hoaxes are also being debunked by the HateFree initiative, which is implemented by the Czech Government Agency for Social Inclusion. Lukáš Houdek, the head of that project, believes it is important not to succumb to facile judgments and that we must do our best to understand information in the relevant context.\nHoudek believes it is crucial to verify information, and the initiative has therefore prepared an easy users' guide for how to verify whether information is false or misleading, which is one way to prevent the dissemination of hateful content. Journalist František Kostlán also understands debunking hoaxes to be part of his profession and has been involved in reporting on many scandals in which Romani people have been the targets of such crooked messages.\nKostlán admits that it took him the longest amount of time to debunk a fabricated report about Romani people receiving higher welfare payments than non-Roma, even though there was not the slightest shred of evidence for that allegation. It can also take a lot of work to debunk forged citations from historical sources, especially if the false information intentionally bolsters prejudices already shared by most people.\nA serious journalist simply must verify information - of that Kostlán is convinced, which is why he does not like media outlets that are not consistent enough when it comes to objectivity or that have completely abandoned their societal role in this regard. Before we swallow some \"guaranteed information\" along with the fishing pole that hooked us, it is always useful to prevent ourselves from succumbing to simple emotions by attempting to assess the information analytically and critically.\nHOW TO ADDRESS A HOAX\nThe basis of addressing hoaxes is being able to recognize their typical forms and signs - for example, a fake request for aid, or so-called chain messages, or a call to share news. Other indicators include poorly-translated texts or \"pen-pals from abroad\" who frequently present themselves as having inherited property or as owning real estate.\nInternet users can preventively install so-called anti-spam filters, which are used either by e-mail programs (e.g., Outlook) or directly by your e-mail server. These programs automatically filter out spam.\nRule Number One is: Never click on attachments to spam e-mails or on the links inside them! Clicking can result in infecting your computer with malware or a virus, theft of your personal data, or \"just\" the inclusion of your e-mail address on a list for spam.\nIf a message does not contain the typical features of a hoax, but seems suspicious to you nonetheless, it always pays to verify its origin. There is a regularly updated list at www.hoax.cz that can aid you.\nIt is always worth ascertaining whether more than one source is reporting the information you have received (and not just as far as hoaxes are concerned). Directly contact the person the message is about, or contact the relevant institutions or professionals concerned.\n- Czech-language internet users, Roma included, fall for debunked hoax about mass wedding of adults and children\n- Czech Republic: Anti-refugee hoax online after gas station attendants mistake Roma from Slovakia for \"refugees\"\n- EU Justice Ministers call on Facebook to be stricter about removing hoaxes and threats\n- Yet another Czech tabloid news server perpetrates a racist hoax\n- Czech Republic: HateFree Culture project refutes online hoaxes about refugees\n- UK: Right-wing extremists use social networks to propagandize through kidnapping hoax\n- Czech tabloid report on Romani political party may be a hoax\n- Hoax party ridicules Czech Christian Democrat leader Cunek\n- Czech politician not to be compensated over nickname, courts say reasonable use of it is allowed\n- Czech Police arrest two Romani men for attack on police, confirm media exaggerated the incident\n- Czech media again exaggerate assault incident, promote antigypsyist stereotypes\n- Czech capital sees public discussion on future form and role of the Lety memorial to the genocide of Roma\n- Czech Museum of Romani Culture officially takes charge of memorial at Romani genocide site in Hodonín u Kunštátu\n- Analysis: A propaganda war needs angry, defiant, disgusted, nerve-wracked people - and the Czech Republic qualifies\n- Czech online media spread disinformation about refugees in Sweden\n- Czech President says 90 % of \"inadaptable citizens\" are Romani\n- Alica Sigmund Heráková responds to Czech daily about the word \"gypsy\": Yes, it is derogatory\n- Romani psychology student who is a ROMEA scholarship winner featured on Czech Television\n- Czech journalist reports on her experiences working minimum wage jobs, book and documentary film to follow\n- Tomáš Bystrý began at ROMEA 15 years ago, today he decides what news Czech Radio will broadcast\nTags:Hoax, Média, RV 5/2016, situace ve společnosti\nPre peskere pindre: Romani leaders in Czech Republic learn how to avoid financial transactions with those who humiliate Roma10.5.2018 8:56\nEmiliya Dancheva: Can we trust the European Parliament if its members are deaf and blind to anti-Gypsyism in Bulgaria?9.5.2018 6:55\nKaždý diskutující musí dodržovat PRAVIDLA DISKUZE SERVERU Romea.cz. Moderátoři serveru Romea.cz si vyhrazují právo bez předchozího upozornění skrýt nevhodné příspěvky z diskuse na Romea.cz. Ty pak budou viditelné jen pro vás a vaše přátele na Facebooku. Při opakovaném porušení pravidel mohou moderátoři zablokovat zobrazování vašich příspěvků v diskusích na Romea.cz ostatním uživatelům."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:e184b190-7bb9-45f9-9ab8-ccfd263c63dd>","<urn:uuid:0ef9ad24-a019-480e-8657-8afb2c1d2577>"],"error":null}
{"question":"What are the traditional agricultural practices associated with Lohri in Punjab, and how might projected climate changes impact crop production in South Asia?","answer":"In Punjab, Lohri marks a resting period for farmers who sow their Rabi winter crops in October and harvest in April. By January, when fields are full and crops are at peak height, farmers celebrate with traditional songs and dances. However, climate projections indicate severe challenges ahead for South Asian agriculture. The region, home to 22% of the world's population including 40% of its poor, faces projected crop production losses of 10-40% by century's end. The situation is particularly concerning due to expected recession of Himalayan glaciers, which are crucial water sources for rivers in the Indo-Gangetic plains, potentially affecting food security for millions in Pakistan, Nepal, Bhutan, India and Bangladesh.","context":["Lohri – Harvest Festival\nLohri – Harvest Festival of Punjab and Haryana is also referred as the bonfire festival. Huge bonfires are lit to thanks the God for abundant crops.\nWHEN IS LOHRI CELEBRATED? – Lohri – Harvest Festival is celebrated on 13th of January during the month of Paush or Magh, a day before Makar Sankranti. This festival marks the departure of the winter season and onset of spring.\nThis festival is celebrated across the country as the harvest festival under different names like Pongal– in Tamil Nadu,Bihu in Assam,Bhogi in Andhra pradesh and the Sankranti in Karnataka,Bihar and Uttar Pradesh.\nWHY IS LOHRI CELEBRATED?\nLohri – Harvest Festival is considered as a resting period for farmers before the cutting and gathering of their crops. Farmers sow Rabi or winter crop (the main crop of Punjab) in October and harvest them in April.\nIt is in January, when the fields are full and the crop is at full height, farmers thank god for their great harvest season and prized crops and celebrate Lohri by singing their traditional folk songs and dances.\nHOW IS LOHRI CELEBRATED?\nLohri – Harvest Festival is a merry-making festival where people relax, sing and rejoice. The focus of Lohri is on bonfire. People gather logs of wood and light flames of bonfire on their front porches thanking fire god for their golden crops before harvesting them.\nAt night there is puja, involving parikrama around the fire followed by distribution of prasad. People say prayers and shout “Aadar aye dilather jaye” (May honor come and poverty vanish from everyone’s life!).\n‘Prasad”’comprises of six main things : til, gazak, gur, moongphali, phuliya and popcorn is distributed. The tradition is to throw sweets, puffed rice and popcorn into the fire and thank god for abundant crops, prosperity and a good harvest season.\nChildren go from door to door singing praises for Dulha Bhatti and asking for the Lohri prasad. Family and friend exchange greetings and gifts on this happy occasion.\nThis is particularly a happy occasion for newly weds and a new born baby. Parents give gifts to their newly married daughters and send sweets to their friends and relatives. Let’s learn about the story behind – Lohri – Harvest Festival.\nSTORY OF DULLA BHATTI\nOn this day praises are sung in honor of Dulla bhatti/dulha bhatti – the herioc son of punjab. As the legend goes Dulla bhatti was a hero who led a rebellion during Mughal rule against King Akbar.\nDulla and his bandits used to loot the riches and distribute the loot among the poor. This act of kindness made him a robin-hood among people and some say that the tradition of giving and exchanging gifts during lohri is inspired by Dulla Bhatti’s acts of generosity.\nAnother legend related to Dulla bhatti says that he protected young girls from Mughal soldiers and rich zamindars. Later arranged marriages for these saved young girls and since there was no priest to chant hymns or mantras for their marriage, he lit up bonfire and the bride and the groom took pheras around this bonfire and sang praises in his name.\nRECIPES OF LOHRI – HARVEST FESTIVAL","A new study finds global warming is already depressing rice yields:\nClimate change, the monsoon, and rice yield in India – Auffhammer et al. (2011) “Recent research indicates that monsoon rainfall became less frequent but more intense in India during the latter half of the Twentieth Century, thus increasing the risk of drought and flood damage to the country’s wet-season (kharif) rice crop. Our statistical analysis of state-level Indian data confirms that drought and extreme rainfall negatively affected rice yield (harvest per hectare) in predominantly rainfed areas during 1966–2002, with drought having a much greater impact than extreme rainfall. Using Monte Carlo simulation, we find that yield would have been 1.7% higher on average if monsoon characteristics, especially drought frequency, had not changed since 1960. Yield would have received an additional boost of nearly 4% if two other meteorological changes (warmer nights and lower rainfall at the end of the growing season) had not occurred. In combination, these changes would have increased cumulative harvest during 1966–2002 by an amount equivalent to about a fifth of the increase caused by improvements in farming technology. Climate change has evidently already negatively affected India’s hundreds of millions of rice producers and consumers.” Maximilian Auffhammer, V. Ramanathan and Jeffrey R. Vincent, Climatic Change, DOI: 10.1007/s10584-011-0208-4.\nH/t AGWObserver. Milo Hamilton, a \"global corporate rice buyer for Uncle Ben's,\" consultant, and president of firstgrain.com, brings the knowledge:\nIf you have come to hear my short-term price outlook, well here it is: The loss since June of large portions of world wheat and coarse grain production has left us with much higher and more volatile prices for alternatives for farmers to plant in the next year. Even rice may be affected in some areas at the margin by the high prices of corn, wheat and soybeans in particular. Rice as well has suffered some losses in India, Indonesia, Pakistan, China, Cambodia and Thailand as well as in the Western Hemisphere, last year in South America, this year in the United States due to record setting night time temperatures. We may have lost upwards of half a million MT of US paddy rice versus the September estimate from the US Department of Agriculture.Increased nighttime warming relative to the average temperature is, of course, one of the telltale features of anthropogenic warming and will be an increasing problem in the years to come.\nHamilton also note the uniquely thirsty nature of rice as a crop:\nThe loss of reliable glacier runoff, worsening droughts, and the salinization of the water table that can be expected with rising seas will all exacerbate a problem of water scarcity created by overpopulation, subsidy and waste.\nWater is a particularly difficult issue for all countries with large populations and low levels of ground water per capita. In particular, because rice takes two or three times as much ground water as other rain fed crops, the cost of water can lead to radical changes in how and where rice is grown. A good example is Egypt that is trying to face in to a future where its major River the Nile is projected to stop flowing into the sea within a decade. Notice that Egyptian experts estimate that it takes about six billion cubic meters of water to grow one million acres of Egyptian rice. If folks start charging for water, the price of rice could go to very high levels.\nThe long-term outlook for rice is grim:\nAccompanied by a 50% increase in population. Remember the number -- 14.5 trillion calories a day. It's non-negotiable. And it's under threat.\nSouth Asia is home to nearly 22% of the world’s population, including 40% of the world’s poor. Agriculture plays a critical role in terms of employment and livelihood security for a large majority of people in all countries of the region. The region is prone to climatic extremes, which regularly impact agricultural production and farmers’ livelihood. Himalayan glaciers, a major source of water for the rivers in the Indo-Gangetic plains, are projected to significantly recede in future that could affect food and livelihood security of millions of people in Pakistan, Nepal, Bhutan, India and Bangladesh. Climate change is further projected to cause a 10–40% loss in crop production in the region by the end of the century."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:805f6d11-62f9-41ca-8af8-445641af4eb2>","<urn:uuid:e7353464-b8c1-456b-9c10-9413df20dfea>"],"error":null}
{"question":"I've heard about upcoming planetary alignments: what will be the most spectacular conjunction events involving Venus and Jupiter in the next few decades, and what's the best way to observe these bright planets individually?","answer":"Several remarkable Venus-Jupiter conjunctions are upcoming, including March 1, 2023, March 14, 2071, and June 21, 2074 - with a particularly special event on June 27, 2074 when Venus and Jupiter will align with the Moon. For individual viewing, Jupiter appears as the fourth brightest celestial object and is particularly visible in the western sky during June. Venus is typically visible most of the year except when it's lost in the sun's glare (usually around June). Venus can be spotted in the west during evening hours or in the east before sunrise, appearing as a bright light that requires a telescope for detailed observation.","context":["Take your vitamins and stick around for the next century’s super-spectacles, including the longest total solar eclipse in U.S. history (2045) or the spectacular return of Halley’s Comet in 2061.\nThe Magnificent Seven (Four for Canada) Total Eclipses\nTotality causes humans and animals alike to moan and babble, as normally invisible deep-pink prominences leap from the Sun’s edge like nuclear geysers. Alas, this ineffable experience of totality happens just once every 360 years, on average, from any given site on Earth.\n- August 21, 2017, will bring the first American totality: the 120-mile-wide shadow will slash the country from coast to coast like a calligraphy brushstroke. See the Almanac’s 2017 Total Solar Eclipse Guide and Map!\n- Another American totality occurs on April 8, 2024, followed by the longest eclipse in U.S. history (a 6-½ minute totality) on August 12, 2045, that again will cross the country from the Pacific to the Atlantic — an inspiration, perhaps, for today’s observers to stay healthy.\n- After a shorter totality in 2052 over Georgia, the country then receives a rare present: two total solar eclipses within a single year, on May 11, 2078, and May 1, 2079. Finally, the century closes with a totality for the northern and Atlantic states in September of 2099. And that’s it — the only occasions in the next 100 years in which stay-at-home Americans can stand fully in the Moon’s shadow.\n- For Canadian eclipse addicts, the April 8, 2024, event will also be seen from the Maritime provinces. The next one, on August 23, 2044, actually begins at sunrise on the border with Montana, then hightails it northward through the western Prairies toward the North Pole. After that, it’s a long wait until the eclipse of May 1, 2079, visible from the Maritimes, and the totality of September 14, 2099, seen in southwestern Canada.\nIn terms of sheer spectacle, the closest runner-up to solar totality is probably Earth’s encounter with a Great Comet. While 1996’s Hyakutake and 1997’s Hale-Bopp did indeed break a 20-year Great Comet drought, neither was as spectacular — that is, bright, with a long tail — as some of the finest historical visitors. The most demanding comet lovers desire a comet with both qualities, like Halley’s memorable 1910 visit, or the “Great January comet” of that same extraordinary year. While most spectacular comets have initially uncharted orbits of thousands of years and therefore visit us with no advance notice, the one trusty short-period comet that can be predicted is also the most famous of all — Halley’s comet.\nUnfortunately, during Halley’s most recent visit, in 1985-86, Earth was in nearly the worst possible position, the equivalent of the outfield bleacher seats. But the Earth/Halley geometry will be wonderful for its return in 2061. Then, it should span half the sky. Moreover, it will float in front of the stars of the Big Dipper, making it prominent for observers in the United States and Canada.\nThe finest reliable showers will continue to be summer’s Perseids of August 11, which will slowly creep to August 12 as the century advances, and December’s rich Geminid display on December 13, which will also migrate ahead one night toward century’s end. Anyone can predict which years these will appear at their best by looking up the phases of the Moon for those dates. Meteors are greatly diminished by a Moon that falls between the first and last quarter phases. See more information and viewing tips for the Perseid Meteor Shower and the Geminid Meteor Shower.\nOf course, for true spectacle, observers will be looking for a meteor “storm,” the 50-to-100-shooting-stars-per-second display that happened in 1799, 1833, and 1966. Right now, it appears that the on-again, off-again 33-⅓-year periodicity of the Leonids should continue, giving us good opportunities in 2033, 2066, and 2099.\nTruly awesome conjunctions require a meeting of at least two of the three planets that can attain dazzling brilliance (Venus, Jupiter, and, rarely, Mars), or the Moon with one or more of these. We’ll throw in bright but not briliant Saturn and Mercury only when a conjunction involving them is ultra-close. To qualify, the celestial targets must pass extremely near each other in the night sky — perhaps even merge into a single, ultrabright, alien-looking sky-object. (While events involving Venus usually occur in twilight, the conjunctions below remain visible long enough to stand out against a satisfyingly dark backdrop.)\nThe following list presents a comprehensive list of the best planetary events of the 21st century that can be seen during the nightfall-to-10 P.M. period when most people are willing to venture out.\nDates of Dazzling Conjunctions\nJ=Jupiter V=Venus M=Mars S=Saturn Merc=Mercury\nIn all these cases, face west toward the fading evening twilight.\nApril 5, 2000 M, J\nMay 10, 2002 M, V\nJune 30, 2007 V, S\nDecember 1, 2008 V, J, Moon\nFebruary 20, 2015 V, M, Moon\nJune 30, July 1, and July 15 Yr? V, J\nDecember 20, 2020 J, S\nMarch 1, 2023 V, J\nDecember 1-2, 2033 J, M\nApril 13, 2038 J, Uranus\nFebruary 23, 2047 V, M\nMarch 7, 2047 V, J\nMay 13, 2066 V, M\nJuly 1, 2066 V, S\nMarch 14, 2071 V, J\nJune 21, 2074 V, J\nJune 27. 2074 V, J, Moon\nJune 28, 2076 M, J\nOctober 31, 2076 M, S, Moon\nFebruary 27, 2079 V, M\nNovember 7, 2080 M, S, J\nNovember 15, 2080 M, S, J\nNovember 17, 2080 M, S, J, Ura, Moon\nDecember 24, 2080 V, J\nMarch 6, 2082 V, J\nApril 28, 2065 J, M, Moon\nJune 13, 2085 J, V, M\nMay 15, 2098 V, M\nJune 29, 2098 V, J\nPaste this article to a refrigerator you plan to keep for ten decades. But there’s no substitute for keeping your eyes wide open after nightfall—for many of the best celestial spectacles, such as awesome long-period comets, Northern Lights, and bolides (exploding meteors), arrive with little or no warning, brilliant bombshells in the heavens.\nFor your annual “calendar of the heavens,” be sure to pick up your copy of The Old Farmer’s Almanac!","The five brightest planets are Mercury, Venus, Mars, Jupiter and Saturn. So long as you know when and where to look you can spot all five of these spectacular planets, just as people have enjoyed doing since ancient times.\nAll of these planets may not be visible at the same time. The overall brightness and visibility of each planet varies depending on the point in its regular cycle and other factors.\nPlanets do not generate their own light; instead we are able to see them because they reflect a portion of the sun’s light back out into space. This is known as albedo, and the amount of sunlight reflected on a given night depends on cloud coverage, the size of the planet, and the actual reflectivity of its surface. The planet’s distance from the sun, apparent size and relative positioning to other planets impacts if you can see it with your naked eye or not.\nLooking up at the sky during the early morning hours before sunrise often promises the best planetary viewing opportunities.\nWhen Can You See Saturn?\nMay, June and July are great months for viewing Saturn because it’s at its brightest and it remains visible all night. Saturn rises in the east, moves across the sky and sets to the west.\nInto late May and early June, Saturn is in opposition with the sun, meaning it rises when the sun sets. At this point it’s easiest to spot Saturn by first locating the sun and then looking to the opposite corner of the sky.\nSaturn, Mars and Antares (brightest star in Scorpius the Scorpion) form a noticeable triangle that can be helpful in identification.\nWhen Can You See Mercury?\nMercury sits low in the sky and close to the sun, qualities that make it rather difficult to spot but not impossible. Mercury is best viewed whenever it sits high above the horizon. Mercury is easiest to spot during predawn when you’ll find it in the eastern portion of the sky. In the Northern Hemisphere it’s easiest to see Mercury between April and May during the evening and October and November during the morning.\nMercury becomes brighter throughout November as it makes its way around the sun. At the start of November, Mercury rises around 90 minutes before sunrise, so your best chance at seeing it is an hour prior to dawn. Another good time to see Mercury is an hour after sunset.\nWhen Can You See Venus?\nVenus is so bright that it is often lost to the glare of the sun in June. Aside from the month or two that Venus disappears to the far side of the sun it can be viewed most of the year.\nVenus orbits in closer proximity to the sun than it does to Earth so it’s easiest to find by first locating the sun. Venus can be seen in the west during the evening and to the east in the early morning before the sun rises.\nVenus appears as a bright light, you’ll need to use a telescope in order to see anything more.\nWhen Can You See Jupiter?\nJupiter is the fourth brightest celestial object just behind Venus. Since Venus is lost in the glare of the sun in June, it makes for a great opportunity to see Jupiter. Jupiter shows itself in the western portion of the sky. In fact, Jupiter is considered the brightest star in June.\nCompared to Mars and Saturn, Jupiter shines the brightest.\nWhen Can You See Mars?\nYou can see Mars from dusk until dawn. As evening descends it sits low in the southeast sky. Mars gives off a notable red coloring that differentiates it from other planets. For instance, Jupiter shines bright white.\nMars is located in direct opposition from the sun, which means when the sun rises, Mars sets and visa-versa. Mars is highest in the sky around midnight, making it easier to spot. Mars sits close to the moon and appears as the brightest object in the sky aside from the moon and Jupiter.\nWhen looking at Mars, you should be able to see the bright star Antares as well as Saturn.\nMars is better viewed with the naked eye, as it is rather small and disappointing when viewed through a telescope. After Mercury, it is the smallest planet in our solar system."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:8ae81e60-e098-44ad-9f4c-c6f795178bf8>","<urn:uuid:af11cd20-45e1-456e-96a0-12d9a14e2e50>"],"error":null}
{"question":"How do MVD Entertainment Group and Rock Ridge Music compare in terms of their approach to music distribution?","answer":"MVD Entertainment Group and Rock Ridge Music have different distribution approaches. MVD is a full-service distributor handling multiple formats including DVD, Blu-ray, CD, vinyl, and merchandise, with their business split equally between music films, non-music films, and audio distribution. They particularly focus on European and UK labels. Rock Ridge Music, on the other hand, operates through Alternative Distribution Alliance (Warner Music Group) and distributes hard copies of music, merchandise, and digital music internationally, with a stronger focus on American artists like Reel Big Fish and Sister Hazel.","context":["By Patrick Prince\nAlmost 30 years ago, the MVD Entertainment Group sprang up from industry veteran Tom Seaman’s business acumen on music videotape distribution. Seaman built a family-run business that is now a full-service music and movie distributor specializing in DVD, Blu-ray, CD, vinyl and music merchandise, including limited-edition collectibles. The family-run business is preserved today with Tom’s son, Ed Seaman, leading the charge as MVD’s COO.\nGOLDMINE: MVD distributes a lot of “audiovisual content” on DVD/Blu-ray — from Patsy Cline live footage to ‘60s documentaries on the Beatles and Dylan. Is it safe to say that this format is your best seller?\nEd Seaman: Music-related film is still a huge part of our business, but we’ve expanded so much in the last 15 years in terms of content and genres. So music films are now about one-third of our overall business, with non-music film at about one-third and audio distribution the other one-third.\nGM: Is there a specific music genre or artist that sells the best with audiovisual? For instance, the Beatles docs must do well.\nES: It’s a funny question. What sells best in music films largely has to do with the collectability of an artist along with the previous exploitations by that artist. The biggest factor is the collectability. If you see lots of people walking around with an artist’s T-shirt, that usually means that artist will sell well on home video. And, of course, the quality and content is crucial, considering how fans interact and chatter in today’s world; when the fans start talking about how great a music doc is, the sales follow. And vice versa.\nGM: MVD founder Tom Seaman initially focused on music videotape.\nES: Indeed – and MVD stands for Music Video Distributors. About 10 years ago at the height of DVD sales, we were at a convention and someone looked at our Music Video Distributors banner and said, “So, you guys sell videotapes or something?” We decided to rebrand at that moment.\nGM: MVD also distributes soundtracks. Please elaborate on how well soundtracks sell. Soundtracks seem to do better than people are aware, no?\nES: We’ve gained some critical mass with soundtracks, picking up some nice labels and great content. It is a natural progression for us, in many ways the missing link between film and music. I believe collectability is critical on packaged goods for soundtracks, whereas digitally it is far more impulse purchase.\nGM: It does make it unique that the soundtracks you have are available in more than just CD format — for instance, the limited-edition, color vinyl of the soundtrack for the film “Song One.” A film like “Song One” — it’s setting of the Greenwich Village folk scene — seems perfect for your kind of distribution.\nES: Vinyl ties into that collectiblity and cult status — although the big draw on this release is that Jenny Lewis contributed to the songwriting.\nGM: Talk about how MVD merged with Big Daddy Music Distribution to expand into audio distribution.\nES: MVD started audio distribution largely as a result of many of our European DVD labels stressing that they wished we did CD distribution, too. In 2006, we pulled the trigger and launched MVD Audio, and soon after took on the merge with Big Daddy, taking over their existing distribution. It solidified us as a player in audio distribution and really helped put us on the map. It also opened up certain audio customers and digital platforms for us — essentially the whole was bigger than the sum of its parts.\nGM: Is there a specific, recent audio release that has done well for MVD?\nES: The Todd Rundgren (“Global” album) is doing really well and we expected that; his fans are so loyal and he supports his releases extremely well, doing tours, interviews, in-stores, whatever it takes.\nGM: You recently welcomed Let Them Eat Vinyl Records to your distribution list. Let Them Eat Vinyl Records brings a niche to many American listeners who enjoy bootleg albums — concert audio that isn’t mass produced.\nES: We are buying these non-exclusively — we really see it as filling a demand for the fans.\nGM: You also distribute many other foreign labels: SlipTrick, Cherry Red Records, etc. How has your experience been with foreign labels in general? It definitely fills a void for record collectors in the U.S.\nES: For whatever reason our business model really resonates with European and U.K. labels. It has always been a large part of our business and looks to grow bigger. There is a European perception that U.S. companies are dishonest, and we have always worked very hard to dispel those feelings; I think our labels in Europe have a lot of faith and trust in us, and we are committed to never let them down.\nGM: Will MVD be selling more and more vinyl in the near future?\nES: Of course — although we all have to be wary of the pitfalls of vinyl and make sure that what gets released should be released. We are all seeing too many records come out that are just a different color of an existing record; there is already backlash about this kind of thing. The good news is that fans have access to so much data these days and are more savvy as a result. So records that shouldn’t have been released in the first place suffer from low sales. But yes — we are committed to the format.\nGM: MVD has always been a family-run business. Do you believe that a family-run business like MVD is more stable than conglomerates in today’s entertainment industry?\nES: I don’t know — running a business is a difficult balancing act no matter what. There are pros and cons with either. The personal commitments of family-run can work for or against the business. At the end of the day, regardless of ownership, the most important thing is having a team that treats the business like their own and commits themselves fully to their career. And that trait is not necessarily dependent on family-run businesses.","Rock Ridge Music\n|Rock Ridge Music|\n|Founder||Tom Derr, Chris Henderson, Jason Spiewak|\n|Distributor(s)||ADA (Warner Music Group)|\n|Country of origin||United States|\nRock Ridge Music is an independent record label and artist management company based in Newark, New Jersey. Founded in 2004, it has signed, managed, and/or promoted artists including Reel Big Fish, Sister Hazel, Rachel Platten, Attack! Attack! UK, The Ike Reilly Assassination, and Fiction Family.\nRock Ridge Music was founded in 2004 by Tom Derr and Jason Spiewak in Washington Crossing, PA along with partner Chris Henderson. CEO Derr was the former Vice-President of Marketing and Artist Development for Universal Records, and had also previously worked at RCA Records and A&M Records. Spiewak had held positions at Artemis Records and TVT Records. Chris Henderson, guitarist for modern rock group 3 Doors Down, joined in 2004 and went on to become Vice President of A&R for the label. The company moved it’s headquarters to Newark, NJ in 2007 and opened a Nashville, TN office at the beginning of 2014.\nIn 2005, Cynthia Cochrane joined as a partner, serving as General Manager and Creative Director from 2006 to 2012. She had previously held positions at Universal Motown Records Group, Capitol Records, Blue Note Records and BMG Music. Cochrane was named President in 2013 following Spiewak’s departure from the company.\nRock Ridge Music's first release, The Ike Reilly Assassination's Sparkle In The Finish, hit stores on October 12, 2004. The company was launched as a full-service independent record label and subsequently added management and marketing consulting services as well. The label has released albums from artists such as Reel Big Fish, Psychostick, Fiction Family, Rachel Platten and others. Management clients include Aaron & The Spell, Grace & Tony, JD Eicher & the Goodnights, Charlie Oxford, Joe Bachman, Cody Joe Tillman and Christian Lopez as well as previous management roster acts such as Sister Hazel, Pat McGee, Ingram Hill and Tony Lucca.\nTheir marketing division, Rock Ridge Marketing, has worked with artists signed to a number labels, including majors such as J Records, Decca, A&M/Octone and RCA, and indies such as Chime Entertainment, TVT Records, and Razor & Tie. They have worked on campaigns for acts including Daughtry, Better Than Ezra, Collective Soul, Blackberry Smoke, Buckcherry, Barry Manilow and Rod Stewart.\nRock Ridge Music distributes hard copies of music, merchandise, digital music, and other media internationally. Their CDs are distributed by Alternative Distribution Alliance (Warner Music Group).\n|Sister Hazel||Chasing Daylight||2003|\n|Five.Bolt.Main||Complete||2006||\"The Gift\" reached #42 on Mediabase Active Rock chart on 3/28/06, #47 on R&R on 4/7/06|\n|Psychostick||We Couldn't Think Of A Title||2006||Track \"BEER!!!\" reached #37 on the Mediabase Mainstream Rock chart on 10/6/06, and #44 on the Mediabase Active Rock chart on 2/11/07|\n|Kittie||Never Again EP||2006|\n|Bernie Williams||Moving Forward||2009||#1 on the Jazz Radio chart (twice in 2010)|\n|Cherry Poppin' Daddies||Susquehanna||2009|\n|Cherry Poppin' Daddies||Skaboy JFK||2009|\n|Rachel Platten||Be Here||2011||#21 on the Billboard Adult Top 40 in 2011|\n|Reel Big Fish||Candy Coated Fury||2012||#80 on the Billboard 200 in 2012|\n|Grace & Tony||November||2013|\n- \"Industry Profile: Tom Derr\". Celebrity Access. Retrieved 2013-07-17.\n- Vasquetelle, Israel (January 8, 2011). \"New Era Record Label and Music Industry Executive Interview: Jason Spiewak of Rock Ridge Music\". Insomniac Magazine. Retrieved 2013-07-17.\n- \"Mission\". Rock Ridge Music. Retrieved 2013-07-17.\n- \"Cynthia Cochrane Named GM At Rock Ridge Music\". All Access. April 22, 200. Retrieved 2013-07-17.\n- \"Services\". Rock Ridge Marketing. Retrieved 2013-07-17.\n- \"Music Inc. Sounds Aligns with Rock Ridge Music\". Music Inc. Retrieved 2013-07-17."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:7281bbb6-fdd8-4d0c-9d1b-c2a9ff3bc5cd>","<urn:uuid:6ada93d3-6fcb-4a1d-b5a7-445cbad1a99c>"],"error":null}
{"question":"What types of real-world operations fall under the category of stability operations?","answer":"Stability operations can involve foreign humanitarian assistance and disaster response, peace operations, counterinsurgency, or combinations of these activities. These operations are usually undertaken in fragile and conflict-affected states.","context":["The US Army Command and General Staff College is currently developing its ideas and requirements for a stability operations simulation that would be used in professional military education at the CGSC and elsewhere. They’re also crowd-sourcing ideas and feedback—and so they’ve asked for your help, via PAXsims. There is a summary of the challenge below, and two attached documents to look over (here and here).\nThe US military defines stability operations as “various military missions, tasks, and activities conducted outside the United States in coordination with other instruments of national power to maintain or reestablish a safe and secure environment, provide essential governmental services, emergency infrastructure reconstruction, and humanitarian relief.” This might involve foreign humanitarian assistance and disaster response, peace operations, counterinsurgency, or combinations of these—usually undertaken in fragile and conflict-affected states. (For more detail, have a look at the US Army field manual on the subject, FM 3-07.)\nFor those of you who aren’t used to the jargon of the military and the military simulation community some of the material attached below will be unfamiliar. Don’t worry about that, however—the core question here is really one of “what do simulation users need to learn about stability operations, and how might a simulation best teach them that?” Folks who work in the humanitarian and development communities, or who work on the politics and economics of fragile and conflict-affected states, may have especially valuable “outside” perspectives to offer.\nIf you do have comments, ideas, or suggestions, please post them here in the comments section.\n* * *\nAttached below is a very rough draft of requirements for a stability operations simulation intended to support staff exercises at the US Army Command and General Staff College. We’re looking for comments, and we’re interested in any simulations that might already fit these.\nOverview: This document\noutlines required functional capabilities and training effects for a Stability Operations simulation enabling student staff exercises at echelons from battalion through brigade. There is no requirement to interface with the Live, Virtual, Constructive – Integrating Architecture (LVC-IA). At this time, the only Mission Command System that needs to be populated is Command Post of the Future (CPoF). There is no requirement to federate with other simulations. Stimulating additional Mission Command systems, federating with other simulations, and working with LVC-IA is acceptable if and only if there is no additional workload or cost associated with the capability and those systems are not required for fully capable operation. This document will assist the Material Developer to better understand the required functional capabilities and training effects to be included in the Simulation.\nDescription: The purpose of this Use Case is to provide requirements for a simulation to support competitive-play low-overhead educational staff-centric stability operations exercises conducted at battalion through brigade level by Professional Military Education (PME) students acting as commanders and key staff officers. This simulation is focused on Stability Operations and enables experiential educational environments. It adjudicates the results of student staff planning and decisions, requiring students to adapt their plans to an evolving situation. This is not a predictive simulation. It is intended to produce generally plausible outcomes whose dilemmas will drive student learning.\nMore detailed technical specifications can be found in this enclosure.\nThis is not a formal statement of requirements, nor is it a solicitation for bids. There will be a long and difficult road between these documents and spending money (and us getting the simulation we need). Eventually, the final version of these documents will go to the National Simulation Center (NSC). Assuming it makes it through a Requirements Board process, the NSC will turn them over to PEO-STRI, who will contract out to have it made. There are no guarantees that the process will go through all those steps.\nHowever, we’d like to have the best thinking on this we can, in hopes of getting the best product at the far end should we get there.\nA few other notes, framing what this is supposed to be:\n- As noted above, this is not a predictive simulation. It is intended to produce generally plausible outcomes whose dilemmas will drive student learning.\n- There will not be a full staff, let alone all the supporting & subordinate staffs. Thus, the simulation has to produce data directly into a student-useful format. Correlating spot reports isn’t a useful employment of student’s time; analyzing the meaning of the summary of activity reports is. This allows for a lot of abstraction in the simulation.\nLast but not least, apologies for the format. Yes, there is a lot of overlap between the primary document and Enclosure 1. This may give you a window into the “wonderful” world of requirements writing, though.\nDeputy Chief, Simulations\nDigital Leader Development Center\nUS Army Command and General Staff College"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:aab93f1e-ec14-4c2a-b999-990c292f034b>"],"error":null}
{"question":"How is MIDI functionality implemented in the Stylophone Studio 5?","answer":"The Stylophone Studio 5 supports both MIDI in and MIDI out over USB using an Atmel AVR ATmega32U4 microcontroller with the LUFA USB stack. The firmware handles several MIDI commands: Program change (for setting tuning: 0=bass, 1=standard, 2=treble), Pitch-bend (with semi-tone range in both directions), and Control Change (1 - Vibrato on/off). Since the Stylophone is monophonic, it uses a note-stealing algorithm based on a FIFO (First In First Out) linked list to handle polyphonic MIDI events. The system can operate with or without USB connectivity - when USB is connected, all events are sent as MIDI out commands to the host.","context":["The Stylophone Studio 5 is a project to recreate the original 1968 Dubreq Stylophone which sounds and reacts just like the original (and even contains a replica of the original circuitry) however it also fully supports both MIDI in and MIDI out over USB and can be controlled by studio software such as Cubase.\nThere have been plenty of projects on the web allowing MIDI out from modified Stylophones (which is fairly easy to do since it only requires an ADC on the original keyboard output), however providing MIDI in to the instrument is far more complicated to achieve (which is why versions 1 to 4 never made the grade!). Since the original Stylophone is completely analogue the control circuitry must be carefully designed so as not to interfere with the sound of the instrument. Furthermore the original is 9 volts which means it cannot be directly controlled by a microcontroller.\nThe Stylophone Studio 5 design overcomes these issues and even provides features not possible on the original such as pitch-bend control and automatic tuning. The original 1968 Stylophone was available in three different tunings: bass, standard and treble. Each of these tunings was implemented by changing capacitor values on the circuit. The Stylophone Studio 5 supports all three models using an automatic circuit reconfiguration. The tuning, vibrato and overall tone output is all controllable via MIDI.\nAlthough I do own an original 1968 Stylophone (from which all of the reverse engineering was performed) and it is possible to alter the original for both MIDI in and out (using the same techniques detailed here) I decided it was better to build from scratch as I didn't want to damage my original in any way. At all stages the audio output from both the Stylophone Studio 5 and the original were compared on an oscilloscope to ensure as much likeness as possible in the sounds.\nYouTube Demonstration Video\nThe hardware can be split into 4 distinct sections: the microcontroller, the Stylophone tone generator, the frequency counter and the Stylophone control panel and keyboard. Each one of these parts is described in detail below.\nThe microcontroller is an Atmel AVR ATmega32U4 which was chosen for several reasons. It has in built USB and can support MIDI using the LUFA USB stack and it has a very high frequency PWM generation which is required as part of the DAC which controls the primary oscillator. The microcontroller also provides ADCs which are used to read the keyboard to detect keypresses. The microcontoller also connects to the CD4066 analogue switch ICs which are used to provide control between the 5V microcontroller and the 9V Stylophone oscillator.\nThe overall schematic for the microcontroller is shown below:\nThe Stylophone Tone Generator\nThe tone generator is a combination of two oscillators. The primary oscillator is a current controlled PUT (Programmable Uni-Junction Transistor) relaxation oscillator which is responsible for generating the overall tone of the instrument. A secondary low-frequency phase-shift oscillator provides the vibrato (vibrato is the relative slow wavering of a sound around the notes centre pitch). The sound produced by the Stylophone is quite 'brass' like due to the output shape of the PUT, the following DSO trace shows the leading-edge of the typical waveform from the cathode of the PUT:\nThe final stage of the generator is a simple one transistor inverting amplifier which (in the original model) powered the inbuilt speaker. Since the Stylophone Studio 5 does not have an inbuilt speaker it is replaced with an equivalent resistor. The output from the amplifier is then passed through a resistor to the line-out socket. Since the bass Stylophone's output is considerably louder than the standard and treble Stylophones an analogue mixer channel is included to attenuate the bass output when required to ensure a more uniform output volume no-matter the tuning setting. The following DSO trace shows the output of the Stylophone Studio from the inverting amplifier:\nSince the original Stylophone used a resistor network to control the pitch of the Stylophone, the PUT relaxation oscillator is current controlled. So in the design we pass 9Vs through an analogue switch. The analogue switch is controlled with a high-frequency PWM signal from the microcontroller which has 10-bit accuracy (meaning that 0% duty-cycle is 0 and 100% duty-cycle is 1023). Note that the high-frequency (around 94 Khz) is required so that the series resistor and capacitors (already present in the original design) can act as an RC filter to the PWM signal which smooths out the PWM and ensures no artefacts of the signal are present in the final sound.\nIf we place a 10000 ohm (10K) resistor in series with the output from the multiplexor (R1) and have the PWM at 100% duty (on all the time), the current output from the circuit can be predicted using ohms law which states:\nI = Vin / R1\nSo in this case I = 9 / 10000 = 0.0009\nSince this is fixed we can only vary the voltage V using the PWM. With a voltage of 9V and a PWM duty-cycle of 50% the average voltage over time is 4.5V. This means that the effective resistance of the circuit is doubled (and therefore the current (I) is halved):\nI = (Vin / 2) / R1\nI = 4.5 / 10000\nI = 0.00045\nUsing this we can simulate different resistance values by varying the PWM duty-cycle. For example using the formula above we can state that:\nVadj = (Vin / 100) * d\nWhere Vavg is the average voltage given for Vin and the current duty-cycle (d) in %.\nTherefore, given a known value for R1 we can calculate the overall resistance (z) of the circuit using:\nz = Vin / (((Vin / 100) * d) / R1)\nSince Vin is cancelled out by this equation we can simplify it to:\nz = (100 * R1) / d\nWhich means, if we know the value of R1 and the required overall resistance ‘z’ we can calculate the required duty-cycle by solving the equation above in terms of d:\nd = (100 * R1) / z\nFor example, if we require a resistance of 20000 ohms (with R1 equal to 10000 ohms) we get:\nd = (100 * 10000) / 20000\nd = 1000000 / 20000\nd = 50%\nNote that the minimum resistance we can represent is fixed by the resistor on the multiplexer's output pin. The maximum is dependent on the resolution of the PWM.\nThe overall schematic for the Stylophone tone generator is shown below:\nThe Frequency Counter\nSince the oscillator is analogue the frequency produced by the oscillator for a given current is based on the dynamics of the PUT and the tolerance of the surrounding components, even using 1% tolerance resistors and good capacitors the output is still variable from circuit to circuit and (to make matters worse) is also effected by environmental conditions such as temperature. This means that the Stylophone Studio requires a frequency counter to allow it to automatically tune the Stylophone. The frequency counter uses a timer/counter on the microcontroller however, since the oscillator output is both AC and 9 volts it must be conditioned before being fed to the counter. The frequency counter uses a capacitor/diode combination to remove the negative part of the output signal and bias the signal from 0Vs as shown in the following DSO trace:\nThis is then fed into a comparator which converts the triangle-like wave output into a 5V peak square-wave which can drive the microcontroller's timer input. Since the frequencies are relatively low (as they are audio signals) the microcontroller requires a relatively long sample to get an accurate reading (1 second). To ensure it only counts during the 1 second duration a second pin on the microcontroller is used to allow and deny the signal as required.\nTo speed up tuning further it is possible to predict the output frequency from the PUT oscillator for a known PWM duty-cycle however the maths is quite involved. To do this we need to return to my original Reverse Engineering the Stylophone project where I demonstrate how to calculate the possible output frequencies of the Stylophone based on the functioning of the PUT relaxation oscillator, the resistance to 9Vs and the value of the tuning capacitor.\nThe procedure is basically the same as the original Stylophone however in the Studio design the resistor values are fixed (there is no tuning potentiometer) so we calculate the value of η (eta) from the 1K8 and 2K2 voltage divider. Following the circuit diagram we can calculate eta as:\nη = 2200 / (1800 + 2200) = 0.55\nOnce we have eta the formula for calculating the frequency is given as:\nSince eta is a constant we can calculate this first and fix it in the formula:\nx = ln(1/(1-eta)) = 0.798507696 = 0.8 (rounded up)\nSo now our formula becomes:\nf = 1/(r * c * 0.8)\nFor the standard tuning the value of c is 100 nano-farads. This should be represented in farads giving a value of 0.0000001 farads.\nSince we need the required resistance we have to solve the equation in terms of r, so firstly we simplify the formula above:\nf = 5 / (4 * c * r)\nAnd then solve it in terms of r:\nr = 5 / (4 * c * f)\nTo make things easier in the code we can produce and simplify three formulas (one for each tuning mode) where we set c as a constant.\nFor bass tuning (where C is 200nF) the formula becomes:\nBass_resistance = 6250000 / f\nFor standard tuning (where C is 100nF) the formula becomes:\nStandard_resistance = 12500000 / f\nFor treble tuning (where C is 47nF) the formula becomes:\nTreble_resistance = 26595745 / f\nNow we go back to our original calculation that calculates the required duty-cycle based on the target resistance:\nd = (1023 * R1) / z\nSince (from the circuit diagram) we know that R1 is 33Kohms this gives:\nd = 33759000 / z\nand we know that to calculate z (for standard tuning) we can state that:\nd = 33759000 / (12500000 / f)\nSo now if we insert the required frequency (f) we get the required duty-cycle (d) for standard tuning. Again we can simplify the formula one more time (to make the numbers smaller):\nd_standard = 33759 * f / 12500\nWe can now do the same thing for both the bass and treble tuning modes to complete our set of formulas:\nd_bass = 33759000 / (6250000 / f)\nd_treble = 33759000 / (26595745 / f)\nd_bass = 33759 * f / 6250\nd_treble = 613800 * f / 483559\nSo, as a final example, if tuning is standard and the required frequency is 220Hz we would require a DAC value of 594.1584 to produce the correct tone:\nD_standard = 33759 * 220 / 12500 = 594.1584 from a 10-bit duty-cycle\nThis calculation is used in the firmware to pick a sensible starting point for tuning so as to save time during the process.\nControl panel and keyboard\nThe control panel and keyboard consist of 3 control switches (for the vibrato, tuning mode and to activate automatic tuning) and the Stylophone's keyboard. In honour of the original the keyboard is also based on a resistor network, however in this case there are two resistor networks which feed the input to two of the ATmega's ADC inputs.\nIn order to calculate the correct resistor values for the networks I used a simple Ohm's law calculation which allowed me to calculate what values would be needed to ensure that each note has a non-overlapping voltage range which can be easily read by the ADC. The calculation is based on resistors with a 5% tolerance (however in the final build I used 1% tolerance resistors):\nAs can be seen in the table, by using increasing sizes of resistors you can get separated values for each of the two sets of 10 keys, the resulting circuit schematic is shown in the following diagram:\nIn the Eagle CAD file I created a custom part which is an exact representation of the original keyboard for the Stylophone to make producing a PCB much easier. The tin coating (which you can see in the pictures and video) was applied using Liquid Tin which makes the surface much more resistant to wear and scratches than a plain copper PCB. I also used much bigger switches to make it easier to play and control the instrument.\nYou can see the finished PCB complete with tin coating in the following picture:\nThe firmware is based on the LUFA USB stack and provides both MIDI in and out via USB. For both MIDI in and out the firmware supports the following commands:\nProgram change (sets the tuning, 0 = bass, 1= standard and 2 = treble)\nPitch-bend (semi-tone range in both directions)\nControl Change (1 - Vibrato on/off)\nThe firmware code is fairly self explanatory and is heavily commented to aid reading and understanding. The only 'confusing' module is the note-stealing algorithm. Since the Stylophone is monophonic it requires an algorithm to deal with polyphonic events being passed via MIDI (more than one note on at a time). The note-stealing algorithm decides which note to play when more than one note is sent. It is basically a linked list which operates on a FIFO (First In First Out) basis, however it is a matter of taste and playing style when deciding how it should be implemented. I did it in the style that I felt most natural to me, you are, of course, welcome to dream up your own schemes.\nThe firmware is designed to operate with or without USB connectivity. If USB is connected then all events are sent as MIDI out commands to the host. If the USB is not connected the Stylophone operates exactly the same allowing it to be used with out a computer connected.\nThe firmware is provided as an AVR Studio 5 project and contains all the required source files for both the Stylophone and the underlying LUFA stack.\nThe Stylophone Studio sound module is mounted in a Velleman G738 enclosure (and the PCB is designed to fit over the mounting holes provided). The keyboard is mounted in a PacTec KEU-7LP enclosure.\nThe front panel for the keyboard was made by printing the required graphics onto glossy photo-paper (using an ink-jet printer). This was then laminated (using a normal office laminating machine) and then the holes for the keyboard and switches were cut. Once cut it was passed once again through the laminating machine before being glued in place on the front of the enclosure.\nIf you have any questions about this project or require more detail about any part, please head over to the forums and ask. I will try to help where I can!\nDonate to waitingforfriday.com:\nIf you like this site and want to help support future projects, or you just want to show appreciation for a project you built, used or enjoyed, please consider leaving a PayPal donation. It's quick, secure and helps us to run the site and fund future projects!\nPayPal, fast, easy and secure\nJoin the EFF:\nThe owner of this site is a member of the EFF and you should be a member too! The EFF protects the rights of open-source, open-hardware authors all over the world."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"sensitive"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:71495196-4c53-4b3e-ac9d-10471836310d>"],"error":null}
{"question":"Which age groups are recommended to receive pneumococcal vaccines versus hepatitis B vaccines?","answer":"For pneumococcal vaccines, PCV is recommended for all children under 5 years old and all adults 65 years and older, while PPSV is recommended for adults 65 and older and people aged 2-64 with certain risk conditions. The hepatitis B vaccine is recommended for all infants at birth, children up to 18 years, adults living with diabetes, and those at high risk due to their jobs, lifestyle, living situations, or country of birth. Since everyone has some risk, all adults should consider getting the hepatitis B vaccine for lifetime protection.","context":["What Is Pneumococcal Disease?\nPneumococcal disease is an infection caused by bacteria. It can lead to:\nIt is spread by person-to-person contact.\nWhat Is the Pneumococcal Vaccine?\nThere are 2 types of pneumococcal vaccines:\n- Pneumococcal conjugate vaccine (PCV)—Recommended for all children younger than 5 years old, all adults aged 65 years and older, and those aged 6 years and older with certain risk factors or diseases. The PCV13 vaccine protects against 13 types of pneumococcal bacteria.\n- Pneumococcal polysaccharide vaccine (PPSV)—Recommended for certain children and adults, and all adults 65 years old and older. People aged 2-64 years with certain risk factors or diseases should also be given this vaccine. The PCV23 vaccine protects against 23 types of pneumococcal bacteria.\nAdults 65 years old and older may receive PCV followed by PPSV. Ask your doctor if you should receive both vaccines.\nThe vaccines are made from inactivated bacteria. They are given by injection under the skin or into the muscle. The goal of getting a vaccine is that later, when you are exposed to the bacteria, you will not get sick from it.\nWho Should Get Vaccinated and When?\nThe PCV is routinely given in 4 doses at 2, 4, 6, and 12-15 months. It can also be given to children with high-risk conditions. It is also recommended for all adults aged 65 years and older.\nIf your child has not been vaccinated or missed a dose, talk to their doctor. Depending on your child's age, additional doses may be needed. Also, an additional dose may be needed if your child has a condition that increases the risk of severe disease.\nThe PPSV is given to adults aged 65 years and older.\nPPSV is also given to anyone aged 2-64 years who have certain conditions, such as:\n- Heart or lung disease\n- Sickle cell anemia\n- Alcohol use disorder\n- Cerebrospinal fluid leaks\n- Cochlear implants\n- Hodgkin's disease\n- Lymphoma or leukemia\n- Kidney failure\n- Multiple myeloma\n- Nephrotic syndrome\n- HIV or AIDS or other disease the creates a weak immune system\n- Damaged spleen or no spleen\n- An organ transplant\nPPSV is also given to anyone aged 2-64 years who is taking a drug or treatment that lowers the body's ability to resist infection, such as:\n- Long-term steroids\n- Certain cancer drugs\n- Radiation therapy\nThe vaccine should be given at least 2 weeks before cancer treatment begins.\nPPSV should also be given to any adult aged 19-64 years old who:\n- Is a smoker\n- Has asthma\nIn some cases, a second dose of PPSV may be needed. For example, a second dose is recommended for people 65 and older who got their first dose before they turned 65 and it has been more than 5 years since that dose. A second dose is also recommended for people 2 through 64 who have:\n- A damaged spleen or no spleen\n- Sickle cell disease\n- HIV infection or AIDS\n- Cancer, leukemia, lymphoma, or multiple myeloma\n- Nephrotic syndrome\n- An organ or bone marrow transplant\n- Been taking medication that lowers immunity, such as chemotherapy or long-term steroids\nWhen a second dose is given, it should be 5 years after the first dose.\nWhat Are the Risks Associated With the Pneumococcal Vaccine?\nGenerally, all vaccines have a small risk of serious problems. Side effects of PCV include:\n- Redness, tenderness, or swelling at the injection site\n- Loss of appetite\nAcetaminophen is sometimes given to reduce pain and fever that may occur after getting a vaccine. Giving the medication at the time of the shot may weaken the vaccine's effectiveness. Discuss the risks and benefits of taking acetaminophen with the doctor.\nHalf of the people who get the vaccine have mild side effects. However, developing the disease is much more likely to cause serious problems than getting the vaccine. Side effects may include:\n- Redness or pain at the injection site\n- Muscle aches\n- Severe allergic reactions—rare\nWho Should Not Get Vaccinated?\nChildren who should not receive the vaccine are those who:\n- Have had a life-threatening allergic reaction to a previous dose of PCV\n- Have had a severe allergy to one of the vaccine's parts\n- Are very ill\nYou should not receive the PPSV if you:\n- Had a life-threatening allergic reaction to a previous dose of PPSV\n- Had a severe allergy to one of the vaccine's components\n- Are very ill\nWhat Other Ways Can Pneumococcal Disease Be Prevented Besides Vaccination?\nYou can prevent pneumococcal disease if you:\n- Avoid close contact with people who have infections.\n- Wash your hands regularly to reduce your risk of infection.\nWhat Happens in the Event of an Outbreak?\nIn the event of an outbreak, all people who are eligible for a vaccine should receive it.\n- Reviewer: EBSCO Medical Review Board David L. Horn, MD, FACP\n- Review Date: 11/2018 -\n- Update Date: 02/08/2017 -","Safety And Adverse Events\nCommon and local adverse events\nHA vaccine is well tolerated. Reactions are generally mild and transient, and are usually limited to soreness and redness at the injection site. Other less frequent reactions include headache, irritability, malaise, fever, fatigue and gastrointestinal symptoms. Injection site reactions occur less frequently in children than in adults as do mild, systemic events . No significant difference in reactions is evident between initial and subsequent doses of vaccine or in the presence of pre-existing immunity.\nRefer to Hepatitis B Vaccine in Part 4 for information about HAHB vaccine.\nInjection site reactions following receipt of standard human Ig include tenderness, erythema and stiffness of local muscles, which may persist for several hours. Mild fever or malaise may occasionally occur.\nLess common and serious or severe adverse events\nLess common side effects following receipt of standard human Ig include flushing, headache, chills and nausea. Urticaria, angioedema and anaphylactic reactions may occur rarely.\nGuidance on reporting Adverse Events Following Immunization\nVaccine providers are asked to report, through local public health officials, any serious or unexpected adverse event temporally related to vaccination. An unexpected AEFI is an event that is not listed in available product information but may be due to the immunization, or a change in the frequency of a known AEFI.\nContraindications and precautions\nWhy It Is Used\nHepatitis B virus causes a liver infection that can lead to serious complications, including liver cancer. It is common in people throughout the world, particularly in Asia and sub-Saharan Africa.\nThe Canadian National Advisory Committee on Immunization recommends hepatitis B immunization for all children. Pregnant women and other adults who do not have immunity and who have a high chance of exposure should be vaccinated.\nHow Hepatitis Is Spread\nHepatitis A: About 20,000 people in the U.S. contract hepatitis A each year. The hepatitis A virus is found in the stool of the infected person. It is spread through contaminated food or water or by certain types of sexual contact.\nChildren who get hepatitis A often don’t have symptoms, so they can have the virus and not know it. However, they can still spread it easily. Fortunately, children are now routinely vaccinated against hepatitis A.\nMost people who get hepatitis A recover completely within two weeks to six months and don’t have any liver damage. In rare cases, hepatitis A can cause liver failure and even death in older adults or people with underlying liver disease.\nHepatitis B: Every year, about 40,000 people in the U.S. become infected with hepatitis B. Acute hepatitis lasts from a few weeks to several months. Many infected people are able to clear the virus and remain virus-free after the acute stage. However, for others, the virus remains in the body, and they develop chronic hepatitis B infection, which is a serious, lifelong condition. About 1.2 million people in the U.S. have chronic hepatitis B. Of these, 15% to 25% will develop more serious health problems, such as liver damage, cirrhosis, liver failure, and liver cancer, and some people die as a result of hepatitis B-related disease.\nYou May Like: Difference Between Hepatitis B And C\nHow Does Hepatitis A Spread\nContaminated food or water is the most common source of hepatitis A infection. Contamination can happen at any point in the food growing, processing or cooking process. Travelers are at an increased risk. Take extra precautions in developing countries with poor sanitary conditions.\nIt is possible for the disease to spread through close contact with an infected person. This includes sex or caring for an infected person.\nVaccination is the best form of protection.\nVaccine For Hepatitis B\nHepatitis B Vaccine\nIt takes only a few shots to protect yourself and your loved ones against hepatitis B for a lifetime.\nThe hepatitis B vaccine is a safe and effective vaccine that is recommended for all infants at birth and for children up to 18 years. The hepatitis B vaccine is also recommended for adults living with diabetes and those at high risk for infection due to their jobs, lifestyle, living situations, or country of birth. Since everyone is at some risk, all adults should seriously consider getting the hepatitis B vaccine for a lifetime protection against a preventable chronic liver disease.\nThe hepatitis B vaccine is also known as the first anti-cancer vaccine because it prevents hepatitis B, the leading cause of liver cancer worldwide.\nYou cannot get hepatitis B from the vaccine. All hepatitis B vaccines that have been used since 1986 are made synthetically meaning the hepatitis B vaccines do not contain any blood products. Learn more.\nIf you have a current HBV infection or have recovered from a past HBV infection, the hepatitis B vaccine series will not benefit you or clear the virus. However, the vaccine can provide a lifetime of protection for loved ones who do not have hepatitis B and get the vaccine as soon as possible. Testing is the only way to know if you or your loved ones have a current infection or have recovered from a past infection.\nHepatitis B Vaccine Recommendations\nThree-Dose Hepatitis B Vaccine Schedule\nYou May Like: How To Read Hepatitis C Test Results\nWhat Is Hepatitis B Virus\nHepatitis B virus attacks the liver. Hepatitis B virus infections are known as the “silent epidemic” because many infected people don’t experience symptoms until decades later when they develop hepatitis , cirrhosis , or cancer of the liver . Every year in the United States about 22,000 new hepatitis B infections occur and about 2,000 people die from their infections.\nSymptoms Of Hepatitis B\nMany people with hepatitis B will not experience any symptoms and may fight off the virus without realising they had it.\nIf symptoms do develop, they tend to happen 2 or 3 months after exposure to the hepatitis B virus.\nSymptoms of hepatitis B include:\n- flu-like symptoms, including tiredness, a fever, and general aches and pains\n- loss of appetite\n- tummy pain\n- yellowing of the skin and eyes\nThese symptoms will usually pass within 1 to 3 months , although occasionally the infection can last for 6 months or more .\nYou May Like: How Do You Pass Hepatitis C\nPrevent Hepatitis B Infections In Newborns\nIf you are pregnant and have hepatitis B, talk with your doctor about lowering the risk that the infection will spread to your baby. Your doctor will check your virus levels during pregnancy. If virus levels are high, your doctor may recommend treatment during pregnancy to lower virus levels and reduce the chance that hepatitis B will spread to your baby. Your doctor may refer you to a liver specialist to find out if you need hepatitis B treatment and to check for liver damage.\nWhen it is time to give birth, tell the doctor and staff who deliver your baby that you have hepatitis B. A health care professional should give your baby the hepatitis B vaccine and HBIG right after birth. The vaccine and HBIG will greatly reduce the chance of your baby getting the infection.\nWhat To Think About\nIf you are exposed to HBV before you have received all three shots in the vaccination series, a dose of hepatitis B immune globulin usually will prevent infection until the vaccine takes effect.\nIf you have already had hepatitis B and have developed protective antibodies to the virus, you do not need the vaccine because you have lifetime protection against the infection. If you are not sure whether you have had hepatitis B, you can be tested, or you can be vaccinated without testing. The vaccine is not harmful for you if you are already immune.\nIf you have chronic HBV infection, the vaccine will be ineffective, although it is not harmful.\nThe vaccine is safe for women who are pregnant or breastfeeding.\nYou May Like: Can Hepatitis B Be Cured With Antibiotics\nWhat Are Clinical Trials For Hepatitis B\nClinical trialsand other types of clinical studiesare part of medical research and involve people like you. When you volunteer to take part in a clinical study, you help doctors and researchers learn more about disease and improve health care for people in the future.\nResearchers are studying many aspects of hepatitis B, such as\n- progression of hepatitis B and long-term outcomes\n- new treatments for hepatitis B\n- prevention of reactivated or worsening hepatitis B in people receiving cancer treatment\nHow Do Doctors Treat Hepatitis B\nDoctors typically dont treat hepatitis B unless it becomes chronic. Doctors may treat chronic hepatitis B with antiviral medicines that attack the virus.\nNot everyone with chronic hepatitis B needs treatment. If blood tests show that hepatitis B could be damaging a persons liver, a doctor may prescribe antiviral medicines to lower the chances of liver damage and complications.\nMedicines that you take by mouth include\nA medicine that doctors can give as a shot is peginterferon alfa-2a .\nThe length of treatment varies. Hepatitis B medicines may cause side effects. Talk with your doctor about the side effects of treatment. Tell your doctor before taking any other prescription or over-the-counter medicines.\nYou May Like: Is Hepatitis C Contagious Sexually\nConcurrent Administration Of Vaccines\nHB-containing vaccines may be administered concomitantly with other vaccines or with HBIg. Different injection sites and separate needles and syringes must be used for concurrent parenteral injections.\nRefer to Timing of Vaccine Administration in Part 1 for additional information about concurrent administration of vaccines.\nOutlook For Hepatitis B\nThe vast majority of people infected with hepatitis B in adulthood are able to fight off the virus and fully recover within 1 to 3 months.\nMost will then be immune to the infection for life.\nBabies and children with hepatitis B are more likely to develop a chronic infection.\nChronic hepatitis B affects around:\n- 90% of babies with hepatitis B\n- 20% of older children with hepatitis B\n- 5% of adults with hepatitis B\nPage last reviewed: 30 January 2019 Next review due: 30 January 2022\nRead Also: Can You Get Hepatitis From Saliva\nWhat Are The Side Effects\nThe most common of the hepatitis B vaccine are mild and include:\n- Low fever or,\n- Sore arm from the shot.\nPrepare for your child’s vaccine visit and learn about how you can:\n- Research vaccines and ready your child before the visit\n- Comfort your child during the appointment\n- Care for your child after the shot\nHepatitis A Vaccine And International Travel\nWho should get the hepatitis A vaccine before traveling internationally?\nAll unvaccinated people, along with those who have never had hepatitis A, should be vaccinated before traveling to countries where hepatitis A is common. Travelers to urban areas, resorts, and luxury hotels in countries where hepatitis A is common are still at risk. International travelers have been infected, even though they regularly washed their hands and were careful about what they drank and ate. Those who are too young or cant get vaccinated because of a previous, life-threatening reaction to the hepatitis A vaccine or vaccine component should receive immune globulin. Travelers to other countries where hepatitis A does not commonly occur are not recommended to receive hepatitis A vaccine before travel.\nHow soon before travel should I get the hepatitis A vaccine?\nYou should get the first dose of hepatitis A vaccine as soon as you plan international travel to a country where hepatitis A is common. The vaccine will provide some protection even if you get vaccinated closer to departure. For older adults , people who are immunocompromised, and people with chronic liver disease or other chronic medical conditions the health-care provider may consider, based on several factors, giving an injection of immune globulin at the same time in different limbs.\nWhat should I do if I am traveling internationally but cannot receive hepatitis A vaccine?\nAlso Check: How Do People Catch Hepatitis B\nWhat Is The Hepatitis A Vaccine\nThe hepatitis A vaccine is a dose of inactive virus that stimulates your natural immune system. After the hepatitis A vaccine is given, your body makes antibodies that will protect you against the hepatitis A virus.\nVaccination for hepatitis A requires 2 shots, 6 months apart. The vaccine is given with an injection, into the muscle of the upper arm. If for some reason the second injection doesn’t take place at 6 months, you can receive the second dose at a later time.\nIf you need hepatitis B vaccination in addition to hepatitis A, you can do these individually or as a combined vaccine that covers both. The combination vaccine is given as 3 injections over a 6-month period–an initial dose, followed by a second dose 1 month later, and then a third dose 5 months after the second.\nWhy Is The Hepb Vaccine Recommended\nPeople who dont know they’re infected can spread the hepatitis B virus. So it cant be avoided just by being careful. That’s why health experts recommend that all babies get the vaccine right from birth.\nThe HepB injection usually creates long-term immunity. Most infants who get the HepB series are protected from hepatitis B infection beyond childhood, into their adult years.\nEliminating the risk of infection also decreases risk for cirrhosis of the liver, chronic liver disease, and liver cancer.\nAlso Check: What Is Hepatitis C Genotype 1a\nIf I Already Have Hepatitis B Can The Vaccine Treat It\nNo. The hepatitis vaccine prevents hepatitis, but doesnt cure it if you already have it. If you have hepatitis B, there are other treatment options.\nHowever, if you recently got exposed to the hepatitis B virus and you havent had the vaccine yet, tell your doctor right away. The vaccine and possibly other treatment can reduce your chances of getting hepatitis B if you get it within 2 weeks after you came into contact with the virus. The sooner you seek care after being exposed to hepatitis B, the better, so try to get there right away.\nWho Should Not Get The Vaccine\nSpeak with your health care provider if you have had a life-threatening reaction to a previous dose of hepatitis A vaccine, or any component of the vaccine including neomycin, or to latex.\nThere is no need to delay getting immunized because of a cold or other mild illness. However, if you have concerns speak with your health care provider.\nAlso Check: Who To Screen For Hepatitis C\nWho Should Get The Hbv Vaccine\nThe Centers for Disease Control and Prevention recommends that children should get their first hepatitis B vaccine at birth and complete the doses by 6 to 18 months of age. However, the HBV vaccine is still recommended for all children if they havent already gotten it, from infanthood up to 19 years old. Most U.S. states require a hepatitis B vaccine for school admittance, however.\nIts also recommended for adults at an increased risk of catching the HBV infection, or anyone who fears they have or will be exposed to it in the near future.\nThe HBV vaccine is even safe to administer to pregnant women.\nWho Is The Vaccine Recommended For\nThe HBV vaccine is recommended for adults who:\n- Are sexually active with or live in the same house as a person with HBV\n- Are sexually active with more than one partner\n- Seek care in a clinic for sexually transmitted diseases, HIV testing or treatment, or drug treatment\n- Men who have sex with other men\n- People who inject drugs or have a job that involves contact with human blood\n- People who are on the staff of or a client in an institution for the developmentally disabled\n- Hemodialysis patients or those with end-stage renal disease\n- People with HIV\n- Dialysis patients\n- Those with chronic liver disease\n- Those who live or travel for more than six months a year in countries where Hepatitis B is common\n- Prisoners in a correctional facility\nAlso Check: Can Hepatitis C Be Passed From Mother To Child\nWhat Is Hepatitis A & B\nHepatitis A and B are two viruses that affect your livers ability to function. Hepatitis A is usually spread through the ingestion of contaminated food or water or close contact including sexual relations with someone who is already infected. Hepatitis B is spread through contact with the blood or other body fluids of an infected person, including contact with objects that could have blood or body fluids on them such as toothbrushes and razors.\nThe hepatitis A virus can cause a flu-like illness, a yellowing of the skin or eyes , along with severe stomach pains and diarrhea. The hepatitis B virus can cause a short-term flu-like illness, or long-term infection that can lead to liver damage, liver cancer or death. Babies and young children infected with hepatitis B are more likely to get this chronic form of the disease.\nWhat Are Dosages Of Hepatitis B Vaccine\nDosages of Hepatitis B Vaccine:\n- 40 mcg/ml\n- 5 mcg/0.5 ml\n- 10 mcg/0.5 mg\nDosage Considerations Should be Given as Follows:\n- Engerix B: 1 mL intramuscularly at 0, 1, and 6 months\n- Recombivax HB: 1 mL intramuscularly at 0, 1, and 6 months\n- Adults receiving dialysis or other immunocompromising conditions\n- Recombivax HB : 40 mcg intramuscularly at 0, 1, and 6 months, OR\n- Engerix-B : 40 mcg intramuscularly at 0, 1, and 6 months\n- Unvaccinated children should complete a 3-dose series\n- Children aged 11-15 years: 2-dose series of adult formulation Recombivax HB is licensed for use in children aged 11 through 15 years\n- low blood pressure\n- pain when urinating\nSuspected adverse events after administration of any vaccine may be reported to Vaccine Adverse Events Reporting System , 1-800-822-7967\nThis document does not contain all possible side effects and others may occur. Check with your physician for additional information about side effects.\nYou May Like: How Is Hepatitis C Test Done"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:deb5e164-25b0-4df2-8b9b-5da8e208708d>","<urn:uuid:7e73c843-507d-43be-8c79-314b79052f45>"],"error":null}
{"question":"How do the emergency mental health services for adults differ between Saint Clare's inpatient ACIS unit and SHN's outpatient Day Hospital program?","answer":"Saint Clare's ACIS (Adult Crisis Intervention Services) is a 24-hour voluntary inpatient unit providing comprehensive psychiatric interventions through a multi-disciplinary team for adults 18+ who require hospitalization and crisis stabilization. In contrast, SHN's Day Hospital is a three-week outpatient alternative to inpatient admission that provides support and education regarding mental health issues, and can also serve as a transition back into the community after an inpatient stay.","context":["Inpatient Programs & Services\nIn addition to our many outpatient programs, Saint Clare’s offers\ninpatient units for adult, child, and adolescent patients who require\nthe resources and safety of a hospital setting.\nAdult Crisis Intervention Service (ACIS)\nAdult Crisis Intervention Services is a voluntary inpatient unit that provides\nbehavioral health services to adults 18+ who require hospitalization.\nThis unit provides comprehensive psychiatric interventions to those who\nare in crisis and need stabilization in a secure environment. Our services\nare delivered through a multi-disciplinary team - including a psychiatrist,\nsocial workers, registered nurses, and behavioral health counselors -\nand include a variety of treatments such as group therapy, individual\ncounseling, special activities and leisure counseling. The team’s\ngoal is to assist individuals in developing coping skills to manage life\ncrises and maintain wellness and recovery.\nThe ACIS unit is available 24-hours a day. For more information, please\ncall Psychiatric Emergency Services at 973-625-6150.\nAlcohol and Chemical Dependency Unit (ACDU)\nThe Alcohol and Chemical Dependency Unit is an inpatient unit that offers\nmedical detoxification services to individuals addicted to opioids, alcohol\nand benzodiazepines. It is for patients who require a hospital setting\ndue to acute intoxication or withdrawal, or for those whose chemical dependency\nhas progressed to the point where an inpatient admission is necessary\nto address the severity of their addiction. The Alcohol and Chemical Dependency\nUnit provides assessment, consultation and treatment 24 hours a day, seven\ndays a week.\nFor more information on the Alcohol and Chemical Dependency Unit, please\ncall the Behavioral Health Access Center at 1-888-626-2111 between the\nhours of 8 am-6:30 pm. After 6:30 pm, and on weekends, please call the\nunit directly at 973-316-1888.\nChildren’s Crisis Intervention Services (CCIS)\nChildren’s Crisis Intervention Services is designated by the New\nJersey Division of Child Behavioral Health Services as a 28-bed child\nand adolescent inpatient psychiatric unit. It serves children and adolescents\nages 5 through 17 who have been professionally assessed for psychiatric\nhospitalization. The unit utilizes patient and family education and treatment\nto develop coping skills and strengthen support system. A comprehensive\npost-discharge plan is developed to reduce or prevent future hospitalization.\nCCIS Services employs a multidisciplinary treatment team - which includes\nboard certified child psychiatrists, masters-prepared clinicians, registered\nnurses, and behavioral health counselors – who work together to\nprovide the best possible care and the safest environment for young patients.\nPatients are offered both individual and group therapies, and the individual’s\nfamily is actively involved in all aspects of the care provided. The services\noffered through the Children’s Crisis Intervention Services treatment\nprogram include medication and medication monitoring, discharge planning,\nand linking the patient and family to the appropriate services available.\nFor more information on Children’s Crisis Intervention Services,\nplease call Psychiatric Emergency Services at 973-625-0280.\nPsychiatric Intensive Care Unit (PICU)\nThe Psychiatric Intensive Care Unit is designed to help adults 18+ who\nsuffer from various forms of acute mental illness and exhibit danger to\nthemselves or others. The PICU is an involuntary, inpatient unit that\nprovides highly structured, intensive treatment to individuals who are\nexperiencing serious behavioral, emotional, or psychological problems.\nThe program offers treatment, resource linkages, and learning opportunities\nthat relate to each person’s individual goals. All patients and\nfamilies are treated with courtesy, consideration and respect for dignity\nand individuality, while focusing on the principles of wellness and recovery.\nFor more information, please call Psychiatric Emergency Services Psychiatric\nEmergency Services at 973-625-0280.\nInpatient Programs and Services\nSaint Clare’s Behavioral Health Boonton\n130 Powerville Road, Boonton, NJ 07005","Adult Outpatient Mental Health services at SHN a range of individual and group programming for those living with a mental illness. Services are available at SHN’s Birchmount and Centenary hospitals.\nOutpatient psychiatrist offices are available at SHN’s Centenary and Birchmount sites. To better meet the needs of Scarborough residents and their families, SHN partnered with the Central East GTA Family Health Team to provide Shared Care. This is a collaborative model where a psychiatrist along with other members of the mental health care team, when needed, visit the Family Health Team office a few times each month to work with family physicians and their staff to assess patients with mental health issues and work together on a treatment plan best suited for each patient. This exciting collaborative model is being expanded to include other family practice offices in Scarborough.\n- Must be 18 years of age or older\n- Individual is living with a serious mental illness\n- Individual has a level of functional impairment that interferes with their ability to live safely and productively in the community\nA physician referral is required to see a psychiatrist.\nClozaril Clinic services are offered by a nurse in consultation with a psychiatrist during visits. Bloodwork is drawn on site and is monitored by the psychiatrist.\nDepot clinics are offered by a nurse. The nurse administers a long acting anti-psychotic medication, as prescribed by the psychiatrist and provides psychoeducation and information on healthy eating and how to maintain an active lifestyle.\nThe Day Hospital is a three-week alternative to inpatient admission, but can also be a transition back into the community after an inpatient stay. This option is available at SHN’s Centenary hospital. Patients are provided with support and education regarding their mental health issues. For more information call 416-284-8131 ext. 7319.\nDay Treatment is a longer program that helps patients develop specific skills for coping with depression and anxiety. Day Treatment is available at SHN’s Centenary hospital. For more information, please call 416-281-7318.\nFirst Intervention Treatment Team (FITT)\nSHN offers a specialized program for young adults experiencing their first episode of psychosis. The First Intervention Treatment Team (FITT) provides assessment, treatment, and case management services, and accepts clients up to 35 years of age who reside in Scarborough. Learn more about FITT.\nMental Health App Library\nThe Mental Health Adult Outpatient Program has curated a Mental Health App Library consisting of 18 SHN physician- and therapist-approved apps for Android and Apple operating systems. Patients can access trusted apps that provide support for anxiety, relaxation, depression, sleep, and post-traumatic stress disorder. The free apps are meant to complement prescribed treatment plans, and are not intended to replace professional treatment.\nSHN is a leader in e-therapy work, offering two first-in-Canada projects for a community hospital: Internet-delivered cognitive behavioural therapy (iCBT) for anxiety and depression, and iMindful, an online mindfulness therapy program for oncology patients. Both programs enable patients to access treatment wherever and whenever it is most convenient for them, and each requires physician referral."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:3c145dd9-d22c-497e-9a6c-0029c119918b>","<urn:uuid:21af8806-7f0a-49a3-8679-a8aeac3888d0>"],"error":null}
{"question":"What are the physical properties of biochar that make it effective for carbon sequestration, and how does it compare to other natural carbon sinks?","answer":"Biochar has a large sponge-like surface area of 300 m2 per 1g with thousands of microscopic holes created during pyrolysis. This structure allows it to store five times more nutrients and water than its own weight, while remaining stable in soil for over 1,000 years. During production, about 489 kg CO2 per 1,000 kg of organic material is sequestered. Compared to other natural carbon sinks, biochar offers unique advantages. While oceans store 50 times more carbon than the atmosphere and peatlands trap carbon by staying waterlogged, biochar provides a more permanent solution as it remains stable for centuries. Other sinks like plants and trees only store carbon temporarily until death and decomposition, while shale and limestone, though significant carbon reservoirs, require intensive processing that releases CO2 when used industrially.","context":["Biochar – A Carrier of Hope and Nutrients\nWhat is Biochar and how is it different from charcoal?\nYou may know charcoal from firing BBQs. Biochar, however, is a special type of charcoal produced by a thermal process called pyrolysis (from the Greek, ‘pyro’, meaning fire and ‘lysis’, meaning separation). During pyrolysis organic matter such as wood waste, organic kitchen waste, rice husks, grass cuttings etc. is thermos-chemically disintegrated in an oxygen-free environment at high temperatures of between 400 °C and 900 °C. Biochar starts out as organic material and becomes more mineral-like with the heating (Wilson K 2014). The carbon sequestration achieved in the process is 489 kg CO2 per 1,000 kg of organic material (Gerber 2009), which means almost half of plant wastes’ total carbon will be permanently stored in the biochar for more than 1,000 years (Schmidt HP 2011). When incorporated into the soil CO2 is actively taken out of our atmosphere, creating a so-called ‘carbon sink’ which is able to slow down climate change.\nHans-Peter Schmidt, a biochar expert, said in an article published in the Ithaka journal (1/2012) (http://www.ithaka-journal.net):\n“The current imbalance in the world’s carbon and nitrogen cycle is not just the main cause of climate change, but also a direct threat to ecosystems through eutrophication, desertification and a decline in biodiversity. Re-balancing through regularly recycling organic material with its carbon, nitrogen and phosphor content is needed. Biochar has the potential to play a key role, as it not only converts the carbon found in a wide range of biomasses into a stable form, but also binds volatile nutrients from biomass residues, thereby recycling them for agricultural use. Though still “early days” for biochar, the prospects for its use are good, whether in crop or livestock farming, or in industry.”\nSoil and Biochar\nHealthy soil can be pictured as a living being that consists of innumerable small organisms, inorganic minerals, water, roots of plants and organic matter. Almost 90 % of all organisms on our planet are living in the soil (Schmidt HP 2010). Once natural vegetation has been removed microorganisms disappear, the soil slowly loses its natural fertility and gets depleted in nutrients. In order to still be able to grow crops, non-organic farmers add tons and tons of inorganic fertilizer, not knowing that the inorganic fertilizer kills the soil life. In order to compensate for that loss even more inorganic fertilizer is added, at high cost to the farmer and the planet – most of these fertilizers are oil- and gas-based. This is a deadly spiral, which ends in contaminated soil and groundwater often resulting in ‘badlands’ – biodiversity deserts. There is an urgent need to maintain and build healthy, living soils which keep fertility.\nSince ancient times it is known that poor soils can be significantly improved by adding biochar. In South America biochar amended soil is known as “terra preta” black soil. Scientific experiments in the Brazilian Amazon have shown that a thousand years after application of the biochar crops still grow better on biochar amended soil than on freshly cleared rainforest soil.\nBefore applying biochar to the soil it has to be “activated”, meaning it has to be loaded with nutrients and microorganisms, which can e.g. be achieved by mixing it with compost or organic fertilizer. The pyrolysis process creates thousands of microscopic holes in each piece of Biochar. One gram of Biochar could, theoretically, unfold to be the size of a soccer pitch. This extremely high surface area means that lots of microorganisms can colonise the Biochar and later colonise depleted soil; the Biochar also helps soil to retain water. Once activated/loaded Biochar is mixed into depleted top soil, or simply put on the soil surface as a top dressing ideally covered with mulch. Over time the soil will become more alive, restoring itself and getting back into its healthy natural cycle.\nSEM images of the popular bio-char (y sectional surface) after the partial gasification\nHow does Biochar modify soil?\nBiochar serves as a carrier for nutrients, water and habitat for microorganisms, all crucial for a healthy soil and healthy plants. Due to its big sponge-like surface (300 m2 per 1 g) biochar is able to store a five times higher amount of nutrients and water than its own weight (Schmidt HP 2014). All the stored nutrients are easily available for plants.\nKey facts about biochar (according to Schmidt HP 2010, 2011, 2012):\n• Biochar stores nutrients like nitrogen and prevents them from being washed away\n• Stored nutrients are easily available for plants and microorganisms. Through the stimulation of microbial symbiosis, the plant takes up the nutrients from the porous carbon structure.\n• Biochar provides habitat for microorganisms, which are crucial in processing nutrients and building new fertile soil\n• Plant growth and plant health is improved\n• Increase of myccorhiza, so plants can access nutrients more easily\n• Biochar improves water retention and stabilizes soils\n• Biochar helps to prevent erosion and stagnant moisture and releases water through dry periods\n• Biochar improves aeration and reduces emission of climate-wrecking gases like methane or nitrous oxide\n• Biochar is capable of binding toxic substances (heavy metal, pesticides, etc) which is not only important for healthy plants but also for clean water and ground water protection\n• Biochar is raising the soil’s pH-value, again making nutrients more accessible to plants\n• Biochar reduces waste problems by recycling organic materials such as arboricultural waste, old bamboo scaffolding, old palettes, rice husks, coconut fibres, organic kitchen waste and so on – keeping them out of the landfill where they decay and release carbon into the atmosphere.\nHow is Biochar used in KFBG\nBiochar is used in KFBG to improve poor soils for organic farming, gardens and forest restoration. It helps us to reduce and recycle organic wastes.\nWe have had a small Biochar machine for several years. In July 2015 we have installed a new state-of-the-art machine, custom built in Australia, which has almost no emissions and, as it is the size of a shipping container, can handle a large volume of wood everyday if needed. As we change our abandoned, unproductive mono-crop orchards in the middle areas of KFBG, over the next two decades, we will convert all the cut wood to biochar and put this back onto the old orchard terraces, with mulch to enrich the depleted soil, ready for planting a wide range of native tree seedlings to create a healthy native forest and seed nursery.\nFurther information and links:\nSchmidt HP: Terra Preta – model of a cultural technique\nSchmidt HP: Climate Farming – A Master Plan for Sustainable Agriculture\nSchmidt HP: Biochar – a key technology for the planet\nWilson K: How biochar works in soil\nGerber H (2009): CO2-Bilanz des Pyregreaktors, Ithaka-Journal 2009, www.ithaka-journal.net/60, ISSN 1663-0521\nSchmidt HP (2010): Climate Farming – A Master Plan for Sustainable Agriculture, 1/2010, S.314–317, www.ithaka-journal.net; Publisher: Delinat-Institut für Ökologie und Klimafarming, CH-1974 Arbaz; www.delinat-institut.org, www.ithaka-journal.net. ISN 1663-0521\nSchmidt HP (2011): Pflanzenkohle, Ithaka Journal 1/2011: 75–82 (2011); www.ithaka-journal.net; Publisher: Delinat-Institut für Ökologie und Klimafarming, CH-1974 Arbaz; www.delinat-institut.org, www.ithaka-journal.net. ISSN 1663-0521\nSchmidt HP (2011): Pflanzenkohle – Landwirtschaft als Klimaretter – ein Jahresbericht. Ithaka Journal 1/2011: 9–13 (2011), www.ithaka-journal.net; Publisher: Delinat-Institut für Ökologie und Klimafarming, CH-1974 Arbaz; www.delinat-institut.org, www.ithaka-journal.net\nSchmidt HP (2012): Pflanzenkohle, eine Schlüsseltechnologie zur Schließung der Stoffkreisläufe, Ithaka Journal 1/2012: 75–79 (2012); www.ithaka-journal.net; Publisher: Delinat-Institut für Ökologie und Klimafarming, CH-1974 Arbaz, www.delinat-institut.org, www.ithaka-journal.net. ISSN 1663-0521\nSchmidt HP (2014): Terra Preta – model of a cultural technique, the Biochar Journal 2014, Arbaz, Switzerland.\nISSN 2297-1114; www.biochar-journal.org/en/ct/4\nWilson K (2014): How biochar works in soil, the Biochar Journal 2014, Arbaz, Switzerland. ISSN 2297-1114","Soil carbon sequestration\nA guide to soil carbon sequestration, where healthy soils absorb water and carbon dioxide\nWhat is soil carbon sequestration (meaning/definition)?\nSoil carbon sequestration is the process of removing carbon dioxide from the air via plants and trees. Carbon becomes locked up in the soil through many biological processes including the incorporation of leaf and other plant litter by creatures living in the soil. Sometimes this process happens as part of the agricultural cycle and plant remains are incorporated during ploughing and tilling.\nSoil carbon sequestration is the process of locking carbon into soils. There are many processes that contribute to sequestration. In agriculture remains from the harvest may be incorporated into the as part of the cultivation process: ploughing and discing for example. Composts and manures applied as top dressing or through injection are other routes used in farming to provide nutrients and carbon rich materials into the surface layers. In forests and uncultivated lands leaves, plant litter and fire debris are all degraded and incorporated into the surface layers through natural processes; actions of fauna and fungi for example. The net effect of such processes is to incorporate carbon into soils and as such remove carbon dioxide from the atmosphere through the previous plant growth that led to the plant, crop litter or animal feed. These processes do not lead to a total permanent removal of carbon dioxide. They are rather part of a dynamic equilibrium between the above examples of carbon incorporations and soil processes that release carbon dioxide and methane (and nitrogen oxides) back into the atmosphere. Where the soil is less disturbed by agriculture carbonaceous rich material does build up in the soil.\nThere are concerns that rising global temperatures may disturb this equilibria and release more carbon dioxide than is being sequestered. In turn this may create a feedback loop with yet more warming etc.\nThe role of biochar in soil carbon sequestration\nBiochar is a material with high stability in the living environment. Through incorporation into the soil it can help improve soil performance in agriculture and horticulture. Importantly it remains stable in the soil for decades, centuries and possibly longer. It is a viable means for carbon sequestration and at the same time helps plants grow better in many conditions. This double benefit is in sharp contrast to some other approaches to carbon sequestration that are currently being developed and trialled.\nOther natural carbon sinks\nWhilst soil and the addition of biochar is one very important carbon sink, there are other natural carbon sink systems to be aware of\nThe ocean absorbs and stores x50 more carbon than the atmosphere via physical and biological mechanisms.\nCarbon dioxide easily dissolves in sea water, which then helps support animal and plant life. The dead material then sinks to the seabed and is then essentially sequestered longer term.\nThe physical mechanism is the natural process of ocean circulation where dense water drags down sequestered carbon.\nPlants and trees depend on the soil for health. They sequester carbon via the process of photosynthesis and become a carbon sink until they die. At this point the material slowly begin to break down and release the carbon as carbon dioxide back into the atmosphere.\nPeatlands are similar to soil but stay very stable due to them being waterlogged, slowing down the decomposition process trapping the carbon as a sink. If they dry out or are mined then the carbon is released as carbon dioxide back into the atmosphere.\nIn some cases peat builds up in bogs over millennia making deposits metres deep.\nShale contains organic carbon (OC) and carbonates. It is believed to make up ~33% of all rock formations on the earths surface and therefore is the largest total mass of organic carbon on earth. It should not be underestimated as to how important it is.\nLimestone is a sedimentary rock composed primarily of calcium carbonate (CaCO3). It essentially locks up the carbon from decaying organic material like shells, algae and coral. The process of turning limestone into concrete is an energy intensive one, which releases the carbon dioxide into the atmosphere.\nThe benefits of carbon farming and regenerative agriculture\nReduce disturbance of the top soil, make fine drills and plant directly into the ground.\nThis leads to more water storage, microbe growth and healthier more vigorous plants.\nPlant cover crops between seasons, this provides diversity of root exudate, feeding the soil biology, building a healthy diverse soil.\nThis is the process of combining trees and agriculture together. This can either be planting trees directly into crop fields, growing trees next to agricultural fields or farming in a forest environment that already exists.\nThis optimises the beneficial interactions between trees and crops under ground, as well as bring in pollinators and biodiversity above ground.\nAnimals are a great way to improve soils. They eat the top layer of organic material, drop manure/urine full of microbes and nitrogen as well as break up the top layer of material with their hooves, stimulating growth. Its important to move them on quickly and allow that patch of land to rejuvenate. It is worth the extra planning and work involved.\nProvide the ground with with material that will breakdown and provide the soil with nutrients and microorganisms.\nAll of these techniques can lead to more localised rainfall, pull carbon out of the atmosphere through photosynthesis and reduce the risk of desertification – turning the soil into dust, making it vulnerable to wind and water erosion.\nFuture carbon capture and storage (CCS) technologies\nThere is also growing interest in capturing carbon dioxide at the end of industrial processes such as power generation, cement or steel manufacture etc. This typically would use a chemical system to capture the carbon dioxide in one step and release it in a second step thus producing a concentrated stream of pure carbon dioxide that can be dried and compressed for piping or shipping to a well and pumped as a super critical fluid into a deep sub-surface formation (rock) where it would be permanently stored. An alternative is to separate the carbon dioxide using a membrane that is selective for transmitting the gas but resists transmitting other gases. The carbon dioxide would then be dried and compressed before being piped or shipped and pumped into the reservoir. These simple sounding steps hide a multitude of challenges that will need to be overcome to make these processes work. The projected costs for these processes are very high. The carbon dioxide in the ground has no value but represents a long term liability w.r.t. the need to maintain monitoring for well and reservoir stability as well as leakage.\nSome are seeing advantage in directly stripping CO2 out of the air to offset earlier CO2 emissions eg by Microsoft. Others see commercial advantage in using the recovered CO2 in greenhouse horticulture. Climeworks recently reported costs to strip out the gas at $800/tonne but they aim for $100 per tonne. This would be before costs to dispose of the collected gas eg by sequestration in a sub-surface aquifer. With current approaches the DAC route appears to be very expensive. $800/tonne for capturing CO2 is equivalent to ca $2900/tonne for carbon. On this basis biochar would be a bargain.\nThere are at least a couple of alternative approaches to CCS. One that has very recently been in the news is the use of basalt or silicate rock flour spread on the land to absorb and react with carbon dioxide in the air to form a mineral carbonate. A paper in Nature claimed there were stockpiles of basalt available as a by-product from mining.\nBeerling, D.J., Kantzas, E.P., Lomas, M.R. et al. Potential for large-scale CO2 removal via enhanced rock weathering with croplands. Nature 583, 242–248 (2020)\nWith all these approaches, the costs are high, there are many technical obstacles to overcome and the scales required are enormous. There is an opportunity for biochar to be used to offset carbon dioxide emissions. Biochar is resistant to degradation in the environment making it a suitable vehicle for offsetting. What’s more it is a product with value and prospectively value at very large scale through its use in agriculture, horticulture, forestry and in the urban environment. The traditional methods for making biochar are themselves carbon dioxide intensive but using electrical heating with renewable electricity this can be radically reduced. The market in biochar needs to be expanded with some urgency to enable this opportunity to flourish."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:911ac082-e677-4038-978f-60d9b8244cab>","<urn:uuid:f76d14ea-a31b-40ec-8cd9-731851399436>"],"error":null}
{"question":"Compare the effects of pooling versus convolution on image processing?","answer":"Pooling and convolution have distinct effects on image processing. Pooling reduces the number of features in a feature map by applying a filter (like max pooling) that summarizes features in a region, making the representation less sensitive to feature location and helping prevent overfitting. Convolution, on the other hand, is a mathematical operation that merges two sets of information by applying filters (kernels) across the input image to detect features. The convolution operation creates feature maps by sliding the filter over the input and performing element-wise matrix multiplication and summation at each location. While pooling down-samples and provides translation invariance, convolution helps in feature detection and pattern recognition.","context":["Welcome to this tutorial on max pooling in Python. In this tutorial we will learn everything there is to learn about max-pooling.\nAfter this tutorial we will be able to answer the following questions :\n- What is pooling?\n- Why do we need pooling?\n- What is max pooling in Python?\n- How to perform max-pooling?\nLet’s get started.\nWhat is pooling?\nPooling is a technique that reduces the number of features in a feature map. The operation involves applying a 2-Dimensional filter across a feature map. Doing this summarizes the features present in a region of the map.\nWhat is a feature map?\nA feature map is what we get as the output after applying the convolution layer on the input image. Convolution layers are the building blocks of Convolutional Neural Networks (CNN). CNNs are popular for their application in object detection.\nConvolution layer applies a filter over the entire image repeatedly to detect features. The output of this convolution layer is a 2-Dimensional map that is known as a feature map.\nBut why do we need pooling? Let’s try and answer this question next.\nWhy do we need pooling?\nOne of the problems with feature maps generated from the convolution layer is that they are too sensitive to the location of the features in the image.\nOne solution for this is down-sampling of the feature map and that is exactly what pooling does.\nBy reducing the number of features we are able to avoid the problem of over-fitting to some extent. It also reduces the computational cost involved in the training of the model.\nWhat is max pooling in Python?\nThere are different types of pooling techniques. Max pooling is one of them.\nWhile applying max-pooling, the filter selects the maximum out of the pixels covered under the filter. The filter acts as a window out of which only the maximum value is selected for the output.\nThe operation of max pooling can be understood with the following example:\nIf we take the image array to be:\n[[2, 3, 4, 2], [8, 5, 5, 1], [6, 7, 9, 4], [3, 1, 4, 5]]\nApply a max-pooling filter with size 2X2 and a stride of 2 on this array.\nWe fill get the following output :\n[[8 5] [7 9]]\nNote how every value in the output is the maximum value from a 2X2 window in the original array.\nHow is max pooling done in python?\nNow that we have understood what is max pooling, let’s learn how to write a python code for it.\nWe will use the Keras to implement max pooling.\nThe Python code for applying max pooling on a numpy array is as follows:\nimport numpy as np from keras.models import Sequential from keras.layers import MaxPooling2D arr = np.array([[2, 3, 4, 2], [8, 5, 5, 1], [6, 7, 9, 4], [3, 1, 4, 5]]) #reshaping arr = image.reshape(1, 4, 4, 1) #define a max pooling layer max_pool = MaxPooling2D(pool_size = 2, strides = 2) #define a sequential model with just one pooling layer model = Sequential( [max_pool]) #get the output output = model.predict(arr) #print the output output = np.squeeze(output) print(output)\nWe get the output as :\n[[8 5] [7 9]]\nIn this example, we used a small array to explain the concept, but in reality feature maps of images can be much bigger in size.\nThis tutorial was about max-pooling in Python. We learned about pooling and the need for pooling. In the final section of the tutorial, we used Keras to implement max-pooling.\nAnother type of pooling technique that is quite popular is average-pooling. In average pooling, the average value is calculated for each window. Hope you had fun learning with us.","Convolution Neural Network: A Convolutional neural network (CNN, or ConvNet) is a class of deep, feed-forward artificial neural networks, most commonly applied to analyzing visual imagery.\nCNN's use a variation of multilayer perceptrons designed to require minimal preprocessing. They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and translation invariance characteristics.\nConvolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex. Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field. The receptive fields of different neurons partially overlap such that they cover the entire visual field.\nCNN's use relatively little pre-processing compared to other image classification algorithms. This means that the network learns the filters that in traditional algorithms were hand-engineered. This independence from prior knowledge and human effort in feature design is a major advantage.\nHere, we have an image, convolution neural network and having output label image.\nConvolution Operation: In this tutorial, we are going to talk about the convolution. Here, we describe the convolution function:\nConvolution is a combined integration of the two functions and it shows you how one function modifies the other or modifies the shape of other.\nConvolution is a mathematical operation to merge two sets of information. In our case, the convolution is applied to the input data using a convolution filter to produce a feature map. There are a lot of terms being used so let's visualize them one by one.\nOn the left side is the input to the convolution layer, for example, the input image. On the right is the convolution filter, also called the kernel, we will use these terms interchangeably. This is called a 3x3 convolution due to the shape of the filter.\nWe perform the convolution operation by sliding this filter over the input. At every location, we do element-wise matrix multiplication and sum the result. This sum goes into the feature map. Now, we have some input message and we create a feature map. We create multiple feature map because we use different filters.\nReLU Layer: In this tutorial, we are going to talk about the ReLU layer. Here, we are applying the rectifier because we want to increase non-linearity in our image. They propose different types of rectified function.\nPooling: In this tutorial, we are going to talk about the max pooling.\nMax pooling is a sample-based discretization process. The objective is to down-sample an input representation (image, hidden-layer output matrix, etc.), reducing its dimensionality and allowing for assumptions to be made about features contained in the sub-regions binned.\nThis is done so in part to help over-fitting by providing an abstracted form of the representation. As well, it reduces the computational cost by reducing the number of parameters to learn and provides basic translation invariance to the internal representation.\nMax pooling is done by applying a max filter to (usually) non-overlapping subregions of the initial representation.\nWe are taking the maximum of the pixel that we or the values that we have. This helping with preventing overfitting. We applied the convolution operation and now we apply the pooling.\nFlattening: Here, we have the pooled featured map. After that, we apply the convolution operation to our image and then we apply the pooling to the result of the collision. So, we are going to flatten it into the column. Here, we see many pooling layers. We put them into one log column sequentially. In the input image, we apply the convolution. And also apply the rectifier function.\nFull Connection: Today, we are talking about the full connection. In this step, we are adding a whole artificial neural network to our convolutional neural network. Here, we are calling them fully connected which are the hidden layer. The main purpose of the artificial neural network to combine our feature into more attributes. Here, we used to call a cost function in an artificial neural network and we used mean square error there in common illusional neural network. It is called a loss function and we use across entropy function for that. We are trying to optimize it to minimize that function to optimize our network. We had an artificial neural network is back propagated and some things are adjusted t help optimize. It all done through a gradient descent of backpropagation. The dog neuron knows that the answer it is actually a dog because at the end we are comparing to the picture or to the label on the picture.\nCNN in Python 1: In this tutorial, we are going to implement the CNN in python. Here, we build our convolutional neural network model, we will simply need to change the image of\nThen, we will be able to train a convolutional neural network to predict if some new brain image contains the tumor is yes or no. Now, we have to input these image in our convolution neural that work.\nHere, in the working directory, we have a dataset which are all our images of cats and dogs. In each folder the training set and the test set we would get for example 5000 image.\nThe first pillar of the structure is to separate our images into two separate folders. A training set folder and testing set folder. Here, we see different dog pictures. Now, we can take some pictures of our friends and replace these dogs picture by that picture. Then, we will able to train an algorithm that will predict. And, there are images of a cat. Here, the training set contained 8000 customers and the test set contained 2000 customer. Here, also,4000 images for dogs and 4000 images of cats. So, there are 80 percent and 20 percent split. We already import this dataset.we do not need to encode the dataset because the independent variable is some way of a pixel and the three channel. We need to split the dataset into the training set and test set. Now, we need to apply the feature scaling.\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n# Importing the dataset\ndataset = pd.read_csv('Churn_Modelling.csv')\nX = dataset.iloc[:, 3:13].values\ny = dataset.iloc[:, 13].values\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\nCNN in Python 2: In this tutorial, we are going to talk about the convolution neural network. In the first step is to import all the keras packages that we will need to make our CNN model. Here, the first package is sequential. We use sequential packages to initialize our neural network. Now, we import convolution layers and we are working on images and since images are in two dimensions. We use the 2D packages to deal with images. And we also add our pooling layers. And next is flatten. Here, we also use the last dense packages. We use to add the fully connected layers and a classic artificial neural network. Now, I execute the code.\nNow, we are going to create an object of this sequential class. We are going to call this object classifier and we call the sequential method.\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nCNN in Python 4: In this tutorial, we are going to take care of the first state of convolutions. Here, we take the classifier object and also include the method add. Here, we include convolution2D. Here, we use the 32 feature detectors three by three-dimension for feature detector. We need to specify what are the expected format of our input images. The input image converted into a 3D array if the image is a color image and into a 2D array if it is a black and white image. The 3D means three channel. We need to start with the 2D array dimension. We need to import here for our input shape argument. Therefore, 64 to 64 and then the number of channel 3 that is we are using tensor flow. We have one last argument to input which is the activation function exactly as we did for our fully connected layers. We used this activation function to activate the neurons in the neural network. Here, we are using the rectifier function.\n# Initialising the CNN\nclassifier = Sequential()\n# Step 1 - Convolution\nclassifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))\nCNN in Python 5: Today, we will take care of the second step pulling. We call the classifier. For the classifier object, we use the add method. And we add the new parenthesis max pooling. We use the max pool size 2 and 2.This line will reduce the size of our maps and it's well divided by two. The size of the feature map is divided by two. For flattening, we use the classifier object and use the add method. We use the parenthesis Flatten().\nIn the same way, For Full connection, we use the classifier object and use the add method. We use the parenthesis Dense (). Also has a parenthesis output_dim is equal to 128. We need to choose a number that is not too small to make the classifier a good model and also not too big. Here, we will go with this 128 hidden nodes in the hidden layer. And another activation function is a rectifier. Now, we copy paste the code. And, add the sigmoid function. now, we add 128 to 1. Then, we get the final layer, which predicts the output.\n# Step 2 - Pooling\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n# Adding a second convolutional layer\nclassifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n# Step 3 - Flattening\n# Step 4 - Full connection\nclassifier.add(Dense(output_dim = 128, activation = 'relu'))\nclassifier.add(Dense(output_dim = 1, activation = 'sigmoid'))\nCNN in Python 8: In this tutorial, we need to compile the whole thing by choosing to cast a grade. To compile this, we add the compile method and also add the parameter in the optimizer. The optimizer is equal to the Adam. Ans we use loss is equal to bunary_cross entropy. And, the metrics is equal to the accuracy.\n# Compiling the CNN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nCNN in Python 9: In this tutorial, we are going to fit the CNN image. We actually need a lot of images to find and generalize some correlations. The amount of our training images is augmented because the transformation is random transformation. Image augmentation is a technique that allows you to enrich our dataset our train set. Now, image augmentation is applied to the training set. Here, we create ImageDataGenerator class. We will rescale all our pixel values between 0 and 1. By rescaling them using this rescale equals one over 255 then all our pixels will be between 0 and 1. She arranged that to apply random transaction and we will keep this open to value zoom range. So this 0.2 values here are just some parameters of how much we want to apply these random transformations. We call it the test set because this code section will create the test set. We have 8000 images in our training set. we need to replace 2000 by 8000 right. Now, we generate a fit method onto our classifier. Now, we execute it. And we create another object. Here, 8000 and 2000 images belonging to two classes.2000 image of our test set. After execution, we get 75% accuracy. We get three predictions out of four..there is a difference between the accuracy in the training set and accuracy in the test set.\nfrom keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\nshear_range = 0.2,\nzoom_range = 0.2,\nhorizontal_flip = True)\ntest_datagen = ImageDataGenerator(rescale = 1./255)\ntraining_set = train_datagen.flow_from_directory('dataset/training_set',\ntarget_size = (64, 64),\nbatch_size = 32,\nclass_mode = 'binary')\ntest_set = test_datagen.flow_from_directory('dataset/test_set',\ntarget_size = (64, 64),\nbatch_size = 32,\nclass_mode = 'binary')\nsamples_per_epoch = 8000,\nnb_epoch = 25,\nvalidation_data = test_set,\nnb_val_samples = 2000)\nCNN in Python 10: In this tutorial, we are going to talk about if we achieve our goal to get an accuracy of more than 80 percent on the test. Only adding a convolutional layer, we will see how it will definitely improve our performance results. Now, we add another convolution layer. Here, we going to keep the same parameter. Now, we execute the whole code. The accuracy of the training set is about 85.The accuracy of stains on the test that began at 55 percent almost 56 percent. We got indeed 64 percent and 68 percent on the test set. We get an accuracy of 85 percent for the training set and 82 percent for the test. We get a difference of 3 percent as opposed to this 10 percent difference that we got in.\nSoftmax and Cross-Entropy: In softmax function in order to help us out of the situation.\nThe softmax function or the normalized exponential function is a generalization of the logistic function. It takes the exponent and put the power of zed and adds it up so that one's two across all. Here we use a function called mean squared which we used as the cost function for assessing our natural performance. Our goal is to minimize the MSE in order to optimize our network performance."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:7ff2b255-b02f-4512-9f40-97e5fe87a548>","<urn:uuid:8cc2057d-1c31-41ce-8b08-90d88ef8947f>"],"error":null}
{"question":"When did Christmas start being officially celebrated on December 25?","answer":"Christmas began to be formally celebrated on December 25 around the year 400, with evidence of earlier celebrations by Pope Liberius (352-66) in Rome, St. Gregory Nazianzus in Constantinople (379), and St. Ambrose in Milan. The exception was Palestine, where Christmas was celebrated on January 6 until the mid-600s before switching to December 25.","context":["What is the actual date of the birth of Christ?\nOne would think that if anyone's date of birth were remembered exactly, it would be that of our Savior, Jesus Christ. Unfortunately, the gospels do not pinpoint the date of Christ's birth. The reason is probably that the focus of the gospels is on the kerygma or mystery of redemption — the passion, death and resurrection of Christ. This focus is also probably why St. Mark's Gospel does not even include the Christmas story, but begins with the Baptism of the Lord at the River Jordan. Easter, on the other hand, can be better dated because of its concurrence with Passover.\nPrior to the legalization of Christianity by the Emperor Constantine in the year 313, no universal date or even formal celebration of Christmas is found. For instance, Origen (d.255), St. Irenaeus (d. 202), and Tertullian (d. 220) do not include Christmas or its date on their lists of feasts and celebrations.\nAfter legalization, the Church was better able to establish ;universal dates of feasts and to organize the public celebration. Moreover, we now see the Church addressing controversies concerning Jesus as true God and true man and how He entered this world. Such concern would focus more attention on the importance of celebrating Christmas, the birth of our Lord.\nOn the more practical side of this issue, Roman pagans used to gather at the hill where the Vatican is presently located to commemorate the \"Birth of the Unconquered Sun\" This pagan feast was celebrated throughout the Empire either on Dec. 25 (according to the Julian Calendar) or on Jan. 6 (according to the Egyptian calendar). Although not proven with certainty, some historians credit Constantine, who declared Sunday as a day; of rest in the Empire, with replacing the pagan festival with that of Christmas. Interestingly, since the 200s, Jesus was honored with the title, \"Sun of Justice.\"\nSomehow all of these elements converged to the formal celebration of Christmas on Dec. 25. For instance, Christmas was celebrated in Rome by Pope Liberius (352-66) on Dec. 25. On Dec. 25, 379, St. Gregory Nazianzus preached a Christmas sermon in Constantinople. In the Cathedral of Milan, St. Ambrose (d. 397) celebrated Christmas. Therefore, by; the year 400, generally, the birth of Christ was set on Dec. 25 with the exception of Palestine, where it was celebrated on Jan. 6 until the mid-600s, when it was then transferred to Dec. 25.\nAs an aside, the Feast of the Epiphany also emerged in Gaul (the Roman province of present-day France) about the year 361. This feast was moved to Jan. 6, which remains the official date.\nWhile the concern for exact dating may preoccupy us at times, I believe the most important point is celebrating the birth of our Lord. Remember that the title \"Christmas\" is derived from the Old English title \"Cristes Maesse\" which means \"The Mass of Christ.\" This Christmas, may we lift up our hearts at the Holy Sacrifice of the Mass and receive our Lord, born into our souls through the grace of the Holy Eucharist.\nSaunders, Rev. William. \"The First Christmas.\" Arlington Catholic Herald.\nThis article is reprinted with permission from Arlington Catholic Herald.\nFather William P. Saunders is pastor of Our Lady of Hope Parish in Potomac Falls and former dean of the Notre Dame Graduate School of Christendom College. Father has been writing his weekly \"Straight Answers\" column for the Arlington Catholic Herald since 1993. The above article is one of those \"Straight Answers\" columns. Father Saunders is the author of Straight Answers, Answers to 100 Questions about the Catholic Faith, a book based on 100 of his columns and published by Cathedral Press in Baltimore.Copyright © 2003 Arlington Catholic Herald\nback to top"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:691311f8-7b02-4062-8128-3379d69a98fe>"],"error":null}
{"question":"I'm a building manager looking for ways to reduce costs - what are the different types of chillers available and how can we optimize their efficiency?","answer":"There are three main types of chillers based on compressor technology: scroll compressors (20-200 tons), screw compressors (up to 500 tons), and centrifugal compressors (200+ tons). Scroll chillers use multiple compressors for stepped control and offer some redundancy. Screw chillers use a single compressor with modulating capacity control. Centrifugal chillers are highly efficient and compact, using inlet vanes and sometimes VFDs for capacity control. To optimize efficiency, several key actions are recommended: 1) Regular inspection and cleaning of condenser coils to ensure proper heat transfer, 2) Maintaining proper refrigerant charge, which can reduce cooling costs by 5-10%, 3) For water-cooled systems, maintaining proper water flow and preventing fouling in condenser loops, and 4) Implementing IoT and AI technologies for predictive maintenance and real-time monitoring of system performance metrics like kW/ton, temperatures, and flow rates.","context":["Selecting the right chiller is generally dictated by capacity, and there are many philosophies on the best way to control, operate, and calculate system operational costs.\n- Understand the variety of chiller options based on load requirements.\n- Learn to calculate a simplified cost/ton estimate for estimating chiller initial investment costs.\n- Know the appropriate calculations for determining chiller plant operational costs.\nChilled water systems are cooling systems that circulate chilled water throughout a building for cooling and dehumidifying a building’s air. They come in all shapes, sizes, and configurations. Chilled water systems are closed-loop systems, meaning that the system water is continually recirculated and not exposed to atmospheric pressure, similar to domestic water systems. While selecting the type of chiller to use is generally dictated by capacity, there are still many philosophies on the best way to control, operate, and calculate system operational costs.\nThe first step in chiller selection is understanding the options available. A building’s block load will determine the overall capacity, whereas part load will determine the number and quantity of chillers required, with multiple chillers providing the ability to stage chillers in response to load. A block load will take into account building diversity and load changes based on exposure, internal and external loads, and building schedules because all portions of the building will not be peaking simultaneously. The function of a space may also dictate sizing and plant reliability. Essential services, such as data centers or hospitals, require reliability and redundancy with the use of a backup chiller or chillers for N+1 or 2N redundancy based on an owner’s requirements. Furthermore, the hourly building profile run time may require equal or unequally sized chillers.\nThe first category of chillers is defined by the method used to compress the refrigerant. Positive displacement compressors operate with two mechanical devices, such as scroll- or screw-shaped rotors. These devices trap refrigerant vapor and compress it by gradually reducing the volume to increase the pressure.\nMost small chilled water plants—up to approximately 200 tons in capacity—use scroll compressors for production of chilled water. Scroll chillers start as low as 20 tons and increase in size to approximately 200 tons. As the capacity increases, the chillers increase the quantity of scroll compressors, typically of equal sizes to provide the total chiller capacity required. The disadvantage is that chiller capacity control is provided as stepped control instead of modulating control. Although the multiple compressors may be a disadvantage for capacity control, generally they are piped with multiple refrigerant circuits which provide some system redundancy. For example, an 80-ton chiller may have four 20-ton compressors, with two compressors on each refrigerant circuit. Failure of one compressor will cause a loss of capacity but will still allow the chiller to remain in service and provide partial cooling output.\nOnce the capacity exceeds the size of multiple scroll compressors, typically four to six 30-ton scroll compressors, chillers use screw compressors. Screw compressors are available in sizes up to about 500 tons. Screw compressors have the ability to vary the cooling output capacity from 100% to 20% via the use of a slide vane to limit refrigerant delivery to the compressor and provide a smooth, modulating transition between capacities. It is important to note that screw chillers have only one compressor, so a loss in the compressor would cause a complete loss in chiller capacity. Screw chillers typically have very good full-load and part-load kW/ton efficiencies. Screw compressors also are generally louder than scroll compressors, with higher noise levels in the lower frequencies octave bands.\nThe third and final type of compressor, a centrifugal compressor, operates on a different compressor philosophy that relies on dynamic compression to compress and raise the refrigerant pressure. A rotating impeller is used to accelerate the refrigerant and allow the conversion of velocity energy into pressure energy. Centrifugal chillers start at approximately 200 tons and go up to thousands of tons depending on the number of compressors. Centrifugal compressors are typically used for compressing large volumes of refrigerant to relatively low pressures and can be configured specifically to the application by changing the number of stages, compressor speed and size, impeller diameter, refrigerant type, and condenser and evaporator shell sizes. Capacity control of centrifugal chillers is accomplished through inlet vanes at the inlet of the compressor that varies the refrigerant flow in stages in response to the building load. A variable frequency drive (VFD) also could be used for capacity control to vary the speed of the impeller rotation in conjunction with inlet vanes. Inlet vanes and VFDs accomplish different objectives: inlet vanes are used for buildings that may have a large load variation, while VFDs should be used for buildings that have large variations in lift, which equates to changes in condenser relief. VFDs are not always an appropriate option for chillers and their use greatly depends their ability to vary temperatures. Regardless, close attention should be paid to low load conditions near 20% capacity, in which the efficiency degrades rapidly and causes the chiller to operate in a condition known as surging.\nCentrifugal chillers also operate at high speeds, which can result in more vibrations and noise transmission into the building structure, but are extremely reliable and robust devices. Centrifugal compressors have great efficiencies throughout their operating range and are relatively compact for the amount of tonnage that can be provided per sq ft of mechanical room space. A centrifugal chiller can vary capacity continuously in lieu of stepped control, which can provide capacity output based on the building load profile. This enables accurate temperature control while using only the energy required. Figure 2 shows two centrifugal chillers serving an office building.","What are Chiller Systems?\nCommercial buildings use Heating, Ventilation and Air Conditioning (HVAC) systems to dehumidify and to cool the building. Modern commercial buildings seek efficient HVAC systems and components as part of broader initiatives centered on building performance and sustainability. Building occupants similarly carry great expectations, that the HVAC system will function as intended . . . to create a comfortable interior environment regardless of the conditions external to the building.\nChillers have become an essential HVAC component of a wide variety of commercial facilities, including hotels, restaurants, hospitals, sporting arenas, industrial and manufacturing plants, etc. The industry has long recognized that chiller systems represent the single largest consumer of electrical usage in most facilities. They can easily consume more than 50% of the total electrical usage during seasonal periods. According to the US Department of Energy (DOE), chillers can combine to use approximately 20% of the total electric power generated in North America. Moreover, the DOE estimates that chillers can expend up to 30% in additional energy usage due to various operational inefficiencies. These acknowledged inefficiencies cost companies and building facilities billions of dollars annually.\nIn general, a chiller facilitates the transfer of heat from an internal environment to an external environment. This heat-transfer device relies on the physical state of a refrigerant as it circulates through the chiller system. Certainly, chillers can function as the heart of any central HVAC system.\nHow Does a Chiller Work?\nA chiller works on the principle of vapor compression or vapor absorption. Chillers provide a continuous flow of coolant to the cold side of a process water system at a desired temperature of about 50°F (10°C). The coolant is then pumped through the process, extracting heat out of one area of a facility (e.g., machinery, process equipment, etc.) as it flows back to the return side of the process water system.\nA chiller uses a vapor compression mechanical refrigeration system that connects to the process water system through a device called an evaporator. Refrigerant circulates through an evaporator, compressor, condenser and expansion device of a chiller. A thermodynamic process occurs in each of above components of a chiller. The evaporator functions as a heat exchanger such that heat captured by the process coolant flow transfers to the refrigerant. As the heat-transfer takes place, the refrigerant evaporates, changing from a low-pressure liquid into vapor, while the temperature of the process coolant reduces.\nThe refrigerant then flows to a compressor, which performs multiple functions. First, it removes refrigerant from the evaporator and ensures that the pressure in the evaporator remains low enough to absorb heat at the correct rate. Second, it raises the pressure in outgoing refrigerant vapor to ensure that its temperature remains high enough to release heat when it reaches the condenser. The refrigerant returns to a liquid state at the condenser. The latent heat given up as the refrigerant changes from vapor to liquid is carried away from the environment by a cooling medium (air or water).\nTypes of Chillers:\nAs described, two different cooling mediums (air or water) can facilitate the transfer of the latent heat given up as the refrigerant changes from vapor to liquid. Thus, chillers can use two different types of condensers, air-cooled and water-cooled.\n- Air-cooled condensers resemble the “radiators” that cool automobile engines. They use a motorized blower to force air across a grid of refrigerant lines. Unless they are specially designed for high-ambient conditions, air-cooled condensers require ambient temperatures of 95°F (35°C) or below to operate effectively.\n- Water-cooled condensers perform the same function as air-cooled condensers, but require two steps to complete the heat transfer. First, heat moves from refrigerant vapor into the condenser water. Then, the warm condenser water is pumped to a cooling tower where the process heat is ultimately discharged to the atmosphere.\nWater-cooled chillers feature a water-cooled condenser connected with a cooling tower. They have commonly been used for medium and large installations that have a sufficient water supply. Water-cooled chillers can produce more constant performance for commercial and industrial air conditioning because of the relative independence to fluctuations of the ambient temperature. Water-cooled chillers range in size from small 20-ton capacity models to several thousand-ton models that cool the world’s largest facilities such as airports, shopping malls and other facilities.\nA typical water-cooled chiller uses recirculating condenser water from a cooling tower to condense the refrigerant. A water-cooled chiller contains a refrigerant dependent on the entering condenser water temperature (and flow rate), which functions in relation to the ambient wet-bulb temperature. Since the wet-bulb temperature is always lower than the dry-bulb temperature, the refrigerant condensing temperature (and pressure) in a water-cooled chiller can often operate significantly lower than an air-cooled chiller. Thus, water-cooled chillers can operate more efficiently.\nWater-cooled chillers typically reside indoors in an environment protected from the elements. Hence, water-cooled chiller can offer a longer lifespan. Water-cooled chillers typically represent the only option for larger installations. The additional cooling tower system will require additional installation expense and maintenance as compared to air-cooled chillers.\nAir-cooled chillers rely on a condenser cooled by the environment air. Thus, air-cooled chillers may find common application in smaller or medium installations where space constraints may exist. An air-cooled chiller can represent the most practical choice in scenarios where water represents a scarce resource.\nA typical air-cooled chiller can feature propeller fans or mechanical refrigeration cycles to draw ambient air over a finned coil to condense the refrigerant. The condensation of the refrigerant vapor in the air-cooled condenser enables the transfer of heat to the atmosphere.\nAir-cooled chillers offer the significant advantage of lower installation costs. Simpler maintenance also results due to their relative simplicity as compared to water-cooled chillers. Air-cooled chillers will occupy less space, but will mostly reside outside a facility. Thus, the outdoor elements will compromise their functional lifespan.\nThe all-inclusive nature of air-cooled chillers reduces maintenance costs. Their relative simplicity coupled with reduced space requirements produces great advantages in many types of installations.\nActions to Increase Efficiency of Chiller Systems:\nChiller costs consume a substantial part of your building’s utility bills. What measures should one take to obtain energy savings through maximal efficiency of the chiller system? Let’s examine some possibilities.\nChiller systems will operate more efficiently through proper ongoing maintenance. Most organizations recognize this value and have taken steps as part of their day-to-day facility management best practices. Some common best practices for chiller systems include:\n- Inspect and clean condenser coils. Heat transfer has a large effect on chiller systems and remains fundamental to producing efficient chiller operation. Routine maintenance should inspect condenser coils for clogging and free air passage.\n- Maintain refrigerant charge. A chiller’s cooling quotient depends on proper refrigerant levels in the system. Maintaining proper refrigerant charge can greatly impact energy efficiency by reducing cooling costs by nearly 5-10%.\n- Maintain condenser water: Condenser water loops used with cooling towers must maintain proper water flow as designed. Any debris like sand, erosive solids and contamination materials can affect the condenser water loop. Fouling or scaling can inhibit water flow and greatly impact the chiller operating efficiency.\nArtificial Intelligence (AI) continues to advance in everyday practical applications. Machinery such as chiller systems will benefit from AI algorithms that can detect potential failures before they occur. Predictive maintenance leverages the collection and analysis of chiller system operational data to determine when maintenance actions should be taken prior to catastrophic failure. As chillers systems represent the heart of most modern HVAC systems, the prevention of catastrophic failures that produce significant “downtime” will save on emergency repair costs as well as reputation. The critical role played by a chiller system warrants the increased scrutiny. Big Data and AI will minimize downtime and maximize productivity.\nThe Internet of Things (IoT) provides the data collection tool that can enable AI applications such as predictive maintenance. In fact, the future of HVAC is AI and IoT. IoT enables the collection of real-time data from a chiller to enable continual analysis of its operation. The granular IoT data collected from a chiller will go far beyond that obtained by visual inspection. IoT connects building engineers to real-time visibility of critical HVAC assets, thereby enabling informed monitoring of actual operating conditions.\nChillers operate as part of a complex HVAC system. Water-cooled chillers have greater complexity due to the connection to a cooling tower system. Evaluating overall chiller plant performance will therefore involve an analysis of total power consumption of the compressor, pumps, cooling tower fans, etc. to evaluate comprehensive efficiency measures such as kW/ton.\nOptimization of the overall chiller plant must be performed holistically. Various adjustments focusing on optimal chilled water set points, chiller sequencing and load balancing, peak demand management, cooling tower water management, etc. can only be performed with operational data. IoT can provide the tools for such optimization by providing real-time monitoring of power consumption from each part of the chiller plant, supply/return temperatures from the chiller and cooling tower, water flow rates from the condenser water loop, etc. IoT has found practical application in HVAC to facilitate true optimization.\nChiller operational efficiency will greatly impact your building operating costs. Ongoing routine maintenance represents the minimum from the perspective of facility management. Predictive maintenance and optimization of the chiller system requires real-time operational data. IoT has opened the door to new forms of chiller efficiencies.\nEditor's Note: This post was originally published in November 2017 and has been completely revamped and updated for accuracy and comprehensiveness."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:90224870-a9a3-4015-bf19-e65b05e37d43>","<urn:uuid:0e282f18-3d8a-49ec-b001-5ee3512f7143>"],"error":null}
{"question":"Historical development cultivation Chianti region from Medieval times to present - what changes occurred?","answer":"After the medieval fights ended, significant changes occurred in Chianti's cultivation. The valleys were cleared and cultivated, leading to the establishment of chestnut woods and oaks, along with olive groves and vineyards. These specific cultivations that began during this transition period continue to contribute to the region's richness today. This was a significant change from the earlier landscape, which was mostly highland-like with mild mountain tops, rich in woods, water, and game during the Etruscan and Roman periods.","context":["The gentle hills of Chianti, Tuscany's Famous Wine Region\nTuscany is located in the center of Italy and, in the center of Tuscany, between Florence, Siena and Arezzo is Chianti, a charming hill-covered region surrounded by the main \"art\" cities in the region.\nThe name \"Chianti\", synonymous of excellent wine all around the world, is currently used to identify several different areas of the territory so it is better to clarify what the term means.\nGeographically speaking Chianti is a hilly land that stretches for about 20 km (from North-South-Southeast).\nThe highest point is Monte San Michele, Mount St. Michael, at 893 mt. There are 5 rivers that cross and define the area with: the Pesa, Greve, Ombrone, Staggia and Arbia rivers.\nUnder the historical point of view, the name should be given only to the municipalities of Gaiole, Raddaand Castellina (justly called \"in Chianti\") that were part of the ancient \"Florentine Military League of Chianti\" whose symbol was a black rooster.\nMore recently, due to the regulation of the wine's designation, with the word \"Chianti\" we mean the area within the three municipalities of the Chianti League stated above in addition to San Casciano and Tavarnelle in Val di Pesa, Greve and part of Barberino Val D'Elsa, as well as the Sienese areas of Castelnuovo Berardenga and Poggibonsi. Only wines produced within these municipalities can be named \"Chianti Classico\" and are certified with the famous Black Rooster symbol.\nThe Chianti Area\nAs you stand upon a hill, the view of the silver of the olive trees, the green geometry of the vineyards, the roads lined with tall green cypresses and the borders of the woods lined with yellow broom combine in a palette of colors that seem to create a unique painting.\nThis is enough to tempt anyone to visit this land, maybe as the ideal place to start discovering Tuscany, since it is the heart of Tuscany and then move towards other destinations with a better understanding of what to expect.\nRoads in Chianti are good even though they are famously winding; but that is their charm since you can admire the beautiful landscape around you.\nFrom Florence take the SR222 to enter into Chianti, known as the new Chiantigiana road, from Ponte a Ema. From Siena you take the old Chiantigiana road avoiding the Firenze-Siena highway.\nMinor roads, connecting small villages to big towns, encourage tourists to discover and stop in various Tuscan treasures. This is the reason for the name \"Chiantishire\" given to this area because of the many foreigners living here.\nMentioning just one place in Chianti doesn't do justice to the thousands of other places to visit. However, Badia a Passignano needs to be mentioned since it was the beautiful, ancient headquarters of the Chianti League (easily reachable from the Firenze-Siena highway), the tiny medieval village of Volpaia, so charming as to be chosen as a movie set, and the massive historical Castle of Brolio, the residence of the Grand Baron Ricasoli who invented modern wine-making.\nA brief history\nThe ancient Chianti region, first Etruscan and then Roman, rich of woods, water and game looked more as an highland than a hill land with mild mountain tops. Except from the main roads, Chianti was not accessible, preserving it from ruinous barbarian invasions after the decline of the Roman Empire.\nFrom the Middle Ages to the Renaissance, it was a continuous battle field for the fights between Siena and Florence that wanted control over these lands. Castles and fortresses that lie on top of many hills overlooking the countryside bear testimony to this glorious and tormented past.\nCastles, towns and villages, farms, parish churches, Renaissance villas, often covered by woods and valleys, built in stone standing out as natural elements of the landscape: these are the treasures that can be discovered by a more curious tourist in Chianti.\nWhen medieval fights ended, some valleys were cleared and cultivated: chestnut woods and oaks, as well as olive groves and vineyards then started to take over. All of these specific cultivations continue to contribute to enrich the Chianti region today."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:08b849a1-c66d-4c94-aab6-62ba0bb35257>"],"error":null}
{"question":"What's the highest elevation: Khyber Pass in Pakistan or the Central Eastern Alps?","answer":"The Central Eastern Alps have a much higher elevation at 4,049 meters (13,284 ft), compared to the Khyber Pass which has an elevation of 1,070 meters (3,510 ft).","context":["The Khyber Pass (Pashto: د خیبر درہ, Urdu: درۂ خیبر) is a mountain pass in the northwest of Pakistan, on the border with Afghanistan. It connects the town of Landi Kotal to the Valley of Peshawar at Jamrud by traversing part of the Spin Ghar mountains. An integral part of the ancient Silk Road, it has long had substantial cultural, economic, and geopolitical significance for Eurasian trade. Throughout history, it has been an important trade route between Central Asia and South Asia and a vital strategic military choke point for various states that came to control it. The summit of the pass is 5 km (3.1 mi) inside Pakistan at Landi Kotal, while the lowest point is at Jamrud in the Valley of Peshawar. The Khyber Pass is part of Asian Highway 1 (AH1).\nد خیبر درہ\n|Elevation||1,070 m (3,510 ft)|\n|Traversed by||N-5 National Highway; Khyber Pass Railway|\n|Location||Between Landi Kotal and Jamrud|\n|Range||Spīn Ghar (Safēd Kōh)|\nIn a number of editions of the Indo-Aryan Migration Theory, the Indo-Aryans began relocating to India through the Khyber Pass. Well-known invasions of the area have been predominantly through the Khyber Pass, such as the invasions by Cyrus, Darius I, Genghis Khan and later Mongols such as Duwa, Qutlugh Khwaja and Kebek. Prior to the Kushan era, the Khyber Pass was not a widely used trade route.\nThe Khyber Pass became a critical part of the Silk Road, which connected Shanghai in the East to Cádiz on the coast of Spain. The Parthian and Roman Empires fought for control of passes such as these to gain access to the silk, jade, rhubarb, and other luxuries moving from China to Western Asia and Europe. Through the Khyber Pass, Gandhara (in present-day Pakistan) became a regional center of trade connecting Bagram in Afghanistan to Taxila in Pakistan, adding Indian luxury goods such as ivory, pepper, and textiles to the Silk Road commerce.:74\nFinally, Sikhs under Ranjit Singh captured the Khyber Pass in 1834 until they were defeated by the forces of Wazir Akbar Khan in 1837. Hari Singh Nalwa, who manned the Khyber Pass for years, became a household name in Afghanistan.:186\nTo the north of the Khyber Pass lies the country of the Mullagori tribe. To the south is Afridi Tirah, while the inhabitants of villages in the Pass itself are Afridi clansmen. Throughout the centuries the Pashtun clans, particularly the Afridis and the Afghan Shinwaris, have regarded the Pass as their own preserve and have levied a toll on travellers for safe conduct. Since this has long been their main source of income, resistance to challenges to the Shinwaris' authority has often been fierce.\nFor strategic reasons, after the First World War the British built a heavily engineered railway through the Pass. The Khyber Pass Railway from Jamrud, near Peshawar, to the Afghan border near Landi Kotal was opened in 1925.\nThe Pass became widely known to thousands of Westerners and Japanese who traveled it in the days of the hippie trail, taking a bus or car from Kabul to the Afghan border. At the Pakistani frontier post, travelers were advised not to wander away from the road, as the location was a barely controlled Federally Administered Tribal Area. Then, after customs formalities, a quick daylight drive through the Pass was made. Monuments left by British Army units, as well as hillside forts, could be viewed from the highway.\nThe area of the Khyber Pass has been connected with a counterfeit arms industry, making various types of weapons known to gun collectors as Khyber Pass copies, using local steel and blacksmiths' forges.\nDuring the war in Afghanistan, the Khyber Pass has been a major route for resupplying military armament and food to the NATO forces in the Afghan theater of conflict since the US started the invasion of Afghanistan in 2001. Almost 80 percent of the NATO and US supplies that are brought in by road were transported through the Khyber Pass. It has also been used to transport civilians from the Afghan side to the Pakistani one. Until the end of 2007, the route had been relatively safe since the tribes living there (mainly Afridi, a Pashtun tribe) were paid by the Pakistani government to keep the area safe. However, after that year, the Taliban began to control the region, and so there started to exist wider tensions in their political relationship.\nSince the end of 2008, supply convoys and depots in this western part have increasingly come under attack by elements from or supposedly sympathetic to the Pakistani Taliban.\nIn January 2009, Pakistan sealed off the bridge as part of a military offensive against Taliban guerrillas. This military operation was mainly focused on Jamrud, a district on the Khyber road. The target was to “dynamite or bulldoze homes belonging to men suspected of harboring or supporting Taliban militants or carrying out other illegal activities”. The result meant that more than 70 people were arrested and 45 homes were destroyed. In addition, two children and one woman were killed. As a response, in early February 2009, Taliban insurgents cut off the Khyber Pass temporarily by blowing up a key bridge.\nThis increasingly unstable situation in northwest Pakistan, made the US and NATO broaden supply routes, through Central Asia (Turkmenistan, Uzbekistan and Tajikistan). Even the option of supplying material through the Iranian far southeastern port of Chabahar was considered.\nIn 2010, the already complicated relationship with Pakistan (always accused by the US of hosting the Taliban in this border area without reporting it) became tougher after the NATO forces, under the pretext of mitigating the Taliban's power over this area, executed an attack with drones over the Durand line, passing the frontier of Afghanistan and killing three Pakistani soldiers. Pakistan answered by closing the pass on 30 September which caused a convoy of several NATO trucks to queue at the closed border. This convoy was attacked by extremists apparently linked to Al Qaida which caused the destruction of more than 29 oil tankers and trucks and the killing of several soldiers. NATO chief members had to issue a formal apology to the Pakistan government so the supply traffic at this pass could be restored.\nIn August 2011, the activity at the Khyber pass was again halted by the Khyber Agency administration due to the more possible attacks of the insurgency over the NATO forces, which had suffered a period of large number of assaults over the trucks heading to supply the NATO and ISAF coalitions all over the frontier line. This instability made the Pakistan Oil Tanker Owners Association demand more protection from the Pakistani and US government threatening not to supply fuel for the Afghan side.\nThis section needs additional citations for verification. (October 2017) (Learn how and when to remove this template message)\nA number of locations around the world have been named after the Khyber Pass:\n- Khyber Road in Phoenix Park, Dublin, Ireland. \n- A suburb of Civil Lines, Delhi, India.\n- Khyber Pass Road, a major road in the suburb of Newmarket, Auckland, New Zealand.\n- An artificial rockwork feature at East Park, Kingston upon Hull, UK.\n- A steep and twisting road up the West Cliff at Whitby, UK.\n- A pedestrian alley in Stromness, Orkney, Scotland\n- Khyber Pass Pub in Philadelphia, Pennsylvania.\n- Khyber Himalayan Resort and Spa in Gulmarg Jammu and Kashmir.\n- A mountain bike trail connecting the Top of the World trail at Whistler Resort to the Whistler Creekside Village.\nOther references include the following:\n- 'Khyber Pass' is Cockney rhyming slang meaning 'arse'. This use is alluded to in the 1968 film Carry On Up the Khyber.\n- The podcast Twilight Histories has an episode called \"Napoleon in Afghanistan\" which partly takes place in the Khyber Pass.\n- The Vampire Weekend song \"M79\" references the Khyber Pass.\n- The Tom Cochrane song \"Life Is a Highway\" (covered by Rascal Flatts and others) references the Khyber Pass.\n- The album Rio Grande Blood by Ministry (2006) has a song called \"Khyber Pass\" which references it as a possible hiding place for then missing and at large Osama bin Laden. This song was also featured at the end of the film The Hurt Locker.\n- The song \"Red War\" by Probot, featuring Max Cavalera on vocals, mentions the pass.\n- British rock band Pink Floyd references the Khyber in their song \"Up the Khyber\", featured on the soundtrack to the film More\n- Parts of the 1985 Jay McInerney book Ransom take place in or near the Khyber Pass.\n- The Khyber pass features in several of Rudyard Kipling's poems: it appears by name in \"The Ballad of the King's Jest\", as \"the Pass\" in \"Arithmetic on the Frontier\", and semi-fictionalized as the Tongue of Jagai in \"The Ballad of East and West\".\n- Tarn, William Woodthorpe (2010). The Greeks in Bactria and India. Cambridge University Press. ISBN 9781108009416. Retrieved 28 March 2017.\n- Insight Guides Silk Road. Apa Publications (UK) Limited. 2017. p. 424. ISBN 9781786716996.\n- Arnold, Guy (2014). World Strategic Highways. Routledge. p. 12. ISBN 9781135933739.\n- Docherty, Paddy (2008). The Khyber Pass: A History of Empire and Invasion. Union Square Press. ISBN 978-1-4027-5696-2.\n- Nalwa, Vanit (2009). Hari Singh Nalwa, \"champion of the Khalsaji\" (1791-1837). New Delhi: Manohar. pp. 318–. ISBN 978-81-7304-785-5.\n- \"Introducing The Khyber Pass\". Lonelyplanet.com. 2009-03-24. Archived from the original on 2011-06-07. Retrieved 2010-11-12.\n- Oppel Jr, Richard A. (2 January 2009). \"Pakistan Briefly Reopens Key NATO Supply Route\". The New York Times. Archived from the original on 20 May 2013. Retrieved 18 June 2012.\n- \"Pakistan and Afghanistan\". Institute for the Study of War. Archived from the original on 9 February 2012. Retrieved 18 June 2012.\n- \"Pakistan Reopens Khyber Pass To US/NATO\". Archived from the original on 24 July 2012. Retrieved 18 June 2012.\n- Karin Brulliard (October 9, 2010). \"Pakistan reopens border to NATO supply trucks\". Washington Post Foreign Service. Archived from the original on 9 February 2011. Retrieved 18 June 2012.\n- Ahmad Nabi (August 17, 2011). \"Nato supplies via Khyber Pass halted due to security\". Archived from the original on 11 January 2012. Retrieved 18 June 2012.\n- McNally, Frank. \"The Irish Times\". The Irish Times. The Irish Times. Retrieved 29 August 2018.\n- Khyber Pass Map Archived 2011-10-30 at the Wayback Machine. Mapsofindia.com (2013-03-01). Retrieved on 2013-07-12.\n- \"Khyber Pass Delhi\". Google Maps. Retrieved 2013-07-12.\n- MGF City , Khyber Pass , North Delhi at the Wayback Machine (archived 2012-03-10)\n- \"East's Eden\". Kingston upon Hull City Council. September 2002. Archived from the original on 2013-05-17.\n- Historic England. \"Details from listed building database (1001519)\". National Heritage List for England. Retrieved 14 January 2013.\n- \"OpenStreetMap\". OpenStreetMap. Retrieved 2019-08-07.\n- National Geographic Society (2011-11-21). \"The Khyber Pass\". National Geographic Society. Retrieved 2019-08-07.\n- \"The Ballad of East and West\". www.kiplingsociety.co.uk. Retrieved 2019-08-07.\n- Molesworth, Lt-Gen. G.N. (1962). Afghanistan 1919 : an Account of Operations in the Third Afghan War. Asia Publishing House. OCLC 7233999.","Central Eastern Alps\nThe Central Eastern Alps (German: Zentralalpen or Zentrale Ostalpen), also referred to as Austrian Central Alps (German: Österreichische Zentralalpen) or just Central Alps comprise the main chain of the Eastern Alps in Austria and the adjacent regions of Switzerland, Liechtenstein, Italy and Slovenia. Below it are the Southern Limestone Alps.\n|Central Eastern Alps|\n|Elevation||4,049 m (13,284 ft)|\nCentral Eastern Alps ranges (purple lines showing international borders and borders of Austrian states):\n|Countries||Austria, Switzerland, Liechtenstein, Italy and Slovenia|\n|States||Vorarlberg, Tyrol, Salzburg, Carinthia, Styria, Graubünden, South Tyrol and Lombardy|\n|Parent range||Eastern Alps|\n|Age of rock||Mesozoic and Tertiary|\n|Type of rock||Gneiss and Slate|\nThe term \"Central Alps\" is very common in the Geography of Austria as one of the seven major landscape regions of the country. \"Central Eastern Alps\" is usually used in connection with the Alpine Club classification of the Eastern Alps (Alpenvereinseinteilung, AVE). The Central Alps form the eastern part of the Alpine divide, its central chain of mountains, as well as those ranges that extend or accompany it to the north and south.\nThe highest mountain in the Austrian Central Alps is Grossglockner at 3,798 metres (12,461 ft).\nThe term \"Central Eastern Alps\" may also be used more broadly to refer to a larger area of the Eastern Alps, mainly located in Austria, extending from the foot of the Bergamasque Alps at Lake Como and the Bernina Range in the Graubünden canton of eastern Switzerland along the Liechtenstein shore of the Rhine in the west as far as to the lower promontories east of the Mur River including the Hochwechsel in Austrian Styria. The valleys of the rivers Inn, Salzach and Enns mark their northern boundary, the Drau river (roughly corresponding to the Periadriatic Seam) their southern border. In the proposed SOIUSA system, the \"Central-eastern Alps\" include the Rhaetian Alps, of which the Bernina Range includes the 4,049-meter Piz Bernina in Switzerland, the easternmost 4,000-meter peak of the Alps. In the AVE system, however, the full list of mountain groups in the Alpine Club classification of the Eastern Alps includes the Bernina and neighboring ranges within the Western Limestone Alps, not the Central Eastern Alps as the Alpine Club defines them.\nCentral Alps as a major landscape region in AustriaEdit\nThe Central and Northern Alps are separated by the Northern Longitudinal Trough (nördliche Längstalfurche), the line Klostertal–Arlberg–Inn Valley–Salzach Valley as far as Lake Zell–Wagrain Heights–Upper Enns Valley–Schober Pass–Mürz Valley Alps–Semmering–southern Vienna Basin. The Central Alps and Southern Alps are separated from one another by the Southern Longitudinal Valley (südlichen Längstalzug) Puster Valley (Rienz Valle–Toblach Field–upper Drava (Drau) Valley)–Drava Valley–Klagenfurt Basin–Meža (Mieß), or the Periadriatic Seam, which is not entirely identical with the Southern Longitudinal Trough.\nThe range has the highest summits in the Eastern Alps and is the most glaciated. In the transition zone between the East und West Alps its peaks clearly dominate the region to the west (Piz d'Err, Piz Roseg). On the perimeter, however, there are also less high, often less rugged mountain chains, like the Gurktal Alps and the eastern foothills.\nThe Central Alps consist mainly of the gneiss and slate rocks of the various Austroalpine nappes (Lower and Upper Austroalpine), with the exception of the Hohe Tauern and Engadine windows, where they are composed mostly of Jurassic rock and limestones and, locally, (Bergell and Rieserferner) also of granite. The Austroalpine nappes are thrusted over the Penninic nappe stack. Massifs of autochthonous, crystalline rock, which hardly moved at all during Alpine folding, do not occur in the Central Alps – unlike the case in the Western Alps. The aforementioned granite intruded near the fracture zone of the Periadriatic Seam. The Western Alps do not have this division into the Northern Limestone Alps, Central Alps and Southern Limestone Alps.\nThe Austroalpine submerges itself at the eastern edge of the Alps under the Tertiary sediments of the Alpine Foreland in the east and the Pannonian Basin. This fracture zone exhibits active volcanism (e.g. in the Styrian thermal region).\nAlpine Club classificationEdit\nThe Central Eastern Alps also comprise the following ranges of the West Eastern Alps according to AVE classification, which geologically belong to the Southern Alps and are also subsumed under the Western Limestone Alps division.:\n|Name||Map||Country||Highest mountain||Height (m)||Image|\n|63||Plessur Alps||Switzerland||Aroser Rothorn||2,980|\n|64||Oberhalbstein Alps|| Switzerland\n|65||Albula Alps||Switzerland||Piz Kesch||3,418|\n|66||Bernina Group|| Italy\n|67||Livigno Alps|| Italy\n|Cima de’ Piazzi||3,439|\n|68||Bergamasque Alps[a]||Italy||Pizzo di Coca||3,052|\n- The Bergamasque Alps are – geologically and petrologically – part of the Southern Limestone Alps, and thus the Southern Alps\nThe Ortler Alps as well as the Sobretta-Gavia Group are also sometimes classified with the Central Alps, because they lie north of the geological fault of the Periadriatic Seam; in a general regional geographic sense, however, they are seen as part of the Southern Limestone Alps, because they are found south of the longitudinal trough Veltlin (Adda)–Vintschgau (Etsch). Also in terms of rock, the Ortler main crest is part of the Southern Limestone Alps.\nMedia related to Central Eastern Alps at Wikimedia Commons"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"sensitive"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:013bd7d4-917d-46c9-852d-ab1bfd37f7c7>","<urn:uuid:ff16d077-1240-4da7-ab05-478c729c4a51>"],"error":null}
{"question":"compare radiation control methods in transportation security versus workplace safety programs","answer":"Transportation security focuses on specific measures like placarding requirements, security plans, and DOT regulations as outlined in the 2010 DOT-PHMSA updates, while workplace radiation safety programs employ broader control methods including time control around materials, distance restrictions through fencing, shielding, and administrative controls like NORM policies. Both areas require comprehensive documentation and training, but workplace programs additionally include specific monitoring requirements such as gamma radiation surveys, contamination surveys, and air monitoring for radon gas and radioactive dusts.","context":["This volume of the Radwaste Desk Reference contains fundamental practical and regulatory information on the transportation of radioactive waste. Because its information is based entirely on industry practice, the work can serve as an extensive “how-to” manual for both the newcomer and the experienced radwaste professional.\nThe technical, regulatory, and economic factors affecting radwaste management are so broad that no one individual is an accomplished expert in all aspects. Therefore, a need exists for a comprehensive reference manual capturing the collective knowledge of recognized industry experts on a variety of radwaste issues. In the first half of the 1990s, the Electric Power Research Institute (EPRI) met this need by developing a four-volume Radwaste Desk Reference covering all aspects of radwaste management. Volume 5, Transportation, was issued in 1995 and revised in 2000.\nIn 2003, the Department of Transportation (DOT) significantly revised the transportation regulations to include requirements for transportation security. In 2004, the Transportation Security Administration (TSA) issued new regulations for transportation security, and the U.S. Nuclear Regulatory Commission (NRC) issued additional security measures in 2005. Given the broad impact of these new rules and measures on nuclear utilities, a revision to the Transportation volume is necessary.\nIn 2010, the DOT Pipeline and Hazardous Materials Safety Administration (PHMSA) issued letters of interpretations to questions related to placarding requirements for Class 7 (radioactive) materials. The responses are official interpretations and clarifications of the hazardous Materials Regulation and resulted in the need for inclusion in this reference document. The DOT-PHMSA also issued a Risk-Based Adjustment of the Transportation Security Plan Requirements, Final Rule, effective October 1, 2010. Those changes are also addressed in this revision of the Radwaste Desk Reference.\nTo update the information in Volume 5 of the Radwaste Desk Reference to capture existing knowledge, regulatory requirements, additional security measures, and checklists related to the transportation security plan requirements and placarding of Class 7 (radioactive) materials\nThis transportation update uses a question-and-answer format consistent with the existing volumes of the Radwaste Desk Reference. This format allows the information to be accessed by radwaste professionals with a variety of training, experience, and interests. The questions are consistent with the scope of questions and information on transportation issues addressed in the existing Volume 5, expanded to incorporate the DOT-PHMSA 2010 changes to the transportation security plan and the official interpretations of placarding Class 7 (radioactive) materials. Essentially, the changes made to this volume are as follows:\n- The revision of Sections 2 and 10 on placarding\n- The revision of Section 8 on transportation security\n- The revision of the transportation security review checklist in Section 11\n- Updated terms in the Glossary\n- Updated bibliographical sources related to the DOT rules and interpretations\nThis updated volume of the Radwaste Desk Reference is an easy-to-comprehend guide to managing radwaste transportation, including transportation security. It can be used as a training manual for new radwaste technicians and supervisors; as a review guide for experienced radwaste professionals; or as a primary resource reference book for nuclear facilities, shippers, and transporters of radioactive materials as well as universities. It includes transportation checklists that can be compared to and/or incorporated into existing waste management program procedures, used as stand-alone checklists, or used as quality assurance/quality control (QA/QC) audit and inspection checklists. This report can also be used as a guide for nuclear managers and experienced radwaste supervisors for evaluating and understanding the more complex regulatory, economic, security, and management issues affecting radwaste practices.","Radiation Safety is the protection of workers\nfrom the harmful effects of radiation.\nIndustries that produce NORM can concentrate the radioactive materials found in our environment to levels that exceed Canada’s Radiation Protection Regulations. Exposures to radiation cannot be prevented, however they can be controlled. A proper Radiation Safety Program will control both internal and external radiation exposures. Radiation Protection Programs or safe work practices are required by regulations.\nIn the Oil and Gas Industry we have seen levels as high as 450 µSv/hr on contact of waste and 50 µSv/hr at 1 meter. An incidentally exposed worker could not spend more than 20 hours within 1 meter of the waste without exceeding the regulatory limit for an external exposure. We have also seen waste with activity levels up to 28,600 Bq/g. Inhalation or ingestion (Internal Exposure) of a volume less than the size of the tip of a pencil would exceed regulatory limits.\nImplementation of a Radiation Safety Program will ensure workers maintain exposures to levels that are well below regulatory limits and maintained under the principle of ALARA (As Low As Reasonable Achievable). This principle is recognized by all levels of governments and a requirement under the Radiation Protection Regulations. This principle means the following:\n“All radiation exposures are considered potentially hazardous to health regardless of any regulatory limit. A regulatory limit is an exposure that should not be exceeded. It is simply not acceptable to just maintain worker exposures to values below regulatory limits. Organizations must maintain exposures as low as reasonable achievable social and economic factors taken into consideration.”\nMany organizations have NORM policies and procedures that outline the appropriate PPE to be worn when working with NORM impacted materials or waste. These types of policies only prevent inhalation or ingestion exposures. A detailed Radiation Safety Program will include:\n- Identification of who is in charge of overall radiation safety for the organization. This is not necessarily the person on a NORM site but rather the person workers can call to address radiation safety concerns. This person is typically called the corporate Radiation Safety Officer (RSO) and must have extensive knowledge and experience in radiation protection.\n- Outlines the corporations requirements on surveys to identify NORM impacted waste and materials as well as monitoring requirements and will include the following:\n- Gamma radiation surveys requirements for detection of NORM impacted materials and waste.\n- Contamination surveys to identify objects that require cleaning or need to be controlled. These types of surveys prevent NORM accumulations from being spread around a worksite giving potential for workers to ingest.\n- Air monitoring requirements to detect levels of radon gas in the work area or low level radioactive dusts (LLRD’s). Health Canada has established maximum concentration limits of radon in air that a workplace cannot exceed. Monitoring for LLRD’s determines the need for respiratory protection and dust control measures. If LLRD’s cannot be eliminated, air monitoring is required to verify the internal exposures of workers in the event of respiratory malfunction.\n- Radiation Survey requirements. Radiation surveys are required to verify if external exposures in a work area need to be controlled. Control of these work areas are typically completed by controlling the amount of time workers may spend in that area.\n- Identifies how internal exposures will be controlled within the organization. This may include engineered controls at specific sites or administrative controls such as NORM policies, procedures or codes of practice. These policies outline how contamination will be controlled to prevent ingestion such as setting up control area’s and how inhalation will be prevented by dust control measures and appropriate PPE. A control area is an area where exposure to radiation may occur and is identified by signage. Special policy and procedures are required within this area to control radiation exposures.\n- Identifies how external Exposures will be controlled within the organization. External exposures cannot be eliminated only controlled as we live in a world where radiation is all around us (i.e. Gamma rays from the sun). External exposures can be controlled from NORM impacted materials or waste through the following means:\n- By controlling the amount of time we spend around the NORM impacted materials or waste.\n- By keeping our distance from the NORMN impacted material or waste such as putting up fencing and restricting access to NORM impacted areas.\n- Shielding the NORM impacted materials or waste to prevent the gamma rays from reaching workers. This method typically is not practical in the oil and gas industry for NORM impacted materials or waste. It is however common with man-made sources where the size of the source is small and can be housed in materials such as a lead lined enclosure.\n- Defines record keeping requirements. Exposures to workers are based off yearly exposures. As such records must be maintained from exposures do to daily work activities in order to compile these yearly assessments. A radiation safety program outlines how these records will be maintained to verify worker exposures.\n- Defines training requirements for workers.\n- Defines transport requirements and procedures. NORM impacted materials or waste with activities greater than 70 Bq/g fall under the requirements of the packaging and transport of nuclear substances regulations (PTNSR). NORM Waste or materials with activities less than 70 Bq/g fall under provincial authority and only require a manifest. This activity of 70 Bq/g assumes a single radionuclide. NORM waste can have radionuclides from both the U238 and Th232 decay series and as such are considered a mixture of radionuclides. The PTNSR outlines the method for determining the activities of mixtures to verify if the PTNSR apply for the mixture.\nNote: Prior to shipment you must determine the activity of the waste to verify appropriate regulations applicable to the shipment. Laboratory analysis can verify the activity of a NORM impacted shipment or estimates, by a qualified radiation expert, can be utilized.\nNormtek has a mobile laboratory for completing sample analysis prior to transport. The CNSC requires transporters of NORM impacted materials or waste have a written Radiation Safety Program if activities fall under their regulatory control (Radiation Protection Program Design for the Transport of Nuclear Substances GD-314)."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:fc69626f-bfd9-44e0-a1e7-57748a7c96a4>","<urn:uuid:45207f5c-c811-48b7-a0af-2769444e4bd7>"],"error":null}
{"question":"What specific soil conditions are optimal for underground construction in both large-scale Earthscrapers and smaller residential earth-sheltered homes, and how do these requirements affect their global implementation potential?","answer":"Granular soil is identified as the optimal ground-type for underground construction, as it allows for efficient water filtering and drainage around structures. Both Earthscrapers and earth-sheltered homes face limitations in areas with thick, non-porous soils like clay or permafrost, or in regions with high humidity, where there's increased risk of interior leaking and condensation. Very loose soil is also problematic as it can cause foundation instability and sinking. These soil requirements, combined with the need for expensive or eco-friendly building materials, currently limit the global application of underground structures. This is particularly challenging for widespread implementation in areas lacking access to suitable construction materials. The success of underground construction projects depends heavily on proper soil conditions to ensure structural integrity and prevent water-related issues.","context":["by A’liya Spinner\nA City Beneath Glass\nAnita locks her front door behind her as she steps outside, swinging her purse up onto her shoulder and squinting slightly in the sun. It streams down in warm beams through a curved, glass dome overhead, illuminating a bustling, underground world, waking up around her as the sounds of machinery, voices, and the general hum of society echoed across the giant pit at the center of the Earth-scraper. Once, it had frightened Anita to walk outside her apartment and see a gaping chasm (behind a reinforced safety rail, of course), but once she’d started her new job at an office near the lowest levels, she was grateful for it— even that deep underground, it’s nice to see sunlight streaming down from above.\nContent, she begins her walk to the large, communal elevators that connect residential levels to the rest of the structure— there’s a high-speed train that rings each story of the Earth-scraper for those who dislike walking, but she enjoys the morning stroll. The central shaft of the Earth-scraper guides a pleasant breeze that warms her skin and flutters huge, rippling banners overhead. Some are advertisements for new shops in the lower rings, but others are merely decorations, colorful and holiday-themed for the season. Ribbons have been tied around the rail, and giant ornaments hang from the edges of the glass-domed ceiling; Anita appreciates the effort to make the Earth-scraper feel more like a community enthused with the spirit of celebration. The first years of living there, she sometimes felt like a troglodyte in a high-tech cave, surrounded by nothing but drab metal and stone and the monotony of everyday life. Now, it’s much more pleasant.\nThere’s a spring to her step as she walks, checking her phone for any texts or emails. None yet, which is fine by her. She likes her morning walks uninterrupted, before a busy day of work in the lower levels. A particularly strong gust of wind— churned by huge air purifiers built into the infrastructure of the Earth-scraper— brushes past her, and she pauses. And sneezes. And then sneezes again, covering her mouth with her sleeve.\nWhen she regains control of herself, Anita looks up and spies one of her friendliest neighbors, stopped beside her on the walkway and dressed in scrubs; vaguely, she remembers that he works at the urgent care in the middle of Earthscraper, taking emergency patients that don’t have the time or severity to go to the surface. She laughs and nods.\n“Unfortunately,” she replies, surreptitiously wiping her nose. “The green levels are all in full bloom— in December.” She glances up, towards the higher stories of the Earthscraper, full of gardens that provided not only fresh food and fresh air, but a frequent supply of pollen.\n“I guess nobody told the plants it’s winter on the surface,” he answers. “Sometimes I forget, too. I went topside the other day and forgot my coat— nearly froze my fingers off.”\n“Tell me about it.” Anita nods, relating to the feeling of living in another world, separate from the crowded bustle of the surface. Most of her life and work was in the Earthscraper, its own little community of people, things to do, and places to see.\n“Are you heading to the elevators?” Her neighbor begins to walk, pointing to a distant crowd of people that they would soon be joining.\n“Yeah, I’ll walk with you,” she answers, falling into place beside him. The warm air of the Earthscraper moved slowly around them, like the breath of a giant buried beneath the surface, starting to stir with a new form of life below the ground.\nInfrastructure beneath the ground is nothing new. Many urban centers use underground train systems to facilitate public transport, an idea first proposed in 1843, for the city of London. Though the first subways were destructive to build (requiring roads to be dug up and then recovered) and released noxious fumes, they were also immediately successful at transporting millions of people. As they became safer to ride and easier to build, the novel subway spread rapidly across Europe, and soon the rest of the world. Modern underground infrastructure is also utilized in sewage systems, pipes and cables, storage, and maintenance access— but rarely do we see large, habitable houses, offices, or tourist destinations underneath the ground.\nYet life underground isn’t as foreign as it might seem— over forty subterranean cities have been discovered around the world, such as Derinkuyu, an underground Turkish city that may have once held 20,000 people at its height in 800 BC. Near Derinkuyu is a potentially even larger site dating back 5,000 years, yet to be fully uncovered and studied. These cities— complete with homes, room for livestock and crops, and recreation— were not buried by volcanic eruptions or tectonic movement; these were intentional, subsurface settlements that have persisted for thousands of years. Now, they may be making a comeback, not for their defensive strength against foreign armies, but for their potential as a more climate-friendly solution to modern living.\nWhen constructed well, subsurface homes are less destructive to the ecosystem around them. Solar panels are easily positioned to provide energy to homes, while the ground remains otherwise intact for grass, native plants, and wildlife traffic, and the unpaved soil acts as a natural drainage system. Heating and cooling costs also decrease thanks to the insulating quality of the ground, especially in extreme climates with low humidity. Earth-sheltered buildings are less prone to damage from natural disasters, particularly fires, hurricanes, and tornadoes, a potentially life-saving design in communities currently under duress from climate change causing an increase in dangerous weather and wildfire. And, though the initial construction cost is higher than a traditional home, a foundation of recycled concrete and stone makes the house studier, requires less upkeep overtime, and reduces dependency on wood. But some architects want to take it far beyond an underground suburb; one entry to the eVolo Skyscraper Competition proposed a self-sufficient, subterranean community in the desert.\nThe 900-foot deep structure would be covered by a skylight dome designed to blend non-invasively to the desert ecosystem. Then, below the surface, high terraces grow produce for the community with unfiltered access to the sunlight. Under them are homes, work areas, and recreation spaces, connected by an underground, high-speed rail to other, nearby settlements. And the structure itself acts as a thermal funnel, venting heat through the surface dome and regulating the temperature with much more ease than surface buildings in the desert. Similarly, in Mexico City, plans for an enormous, inverted “Earthscraper” have been unveiled. The underground structure is proposed to contain thirty-five stories of offices, housing, gardens, and a museum, circumventing the law that prevents skyscrapers from exceeding eight stories within city limits, and preserving the integrity of the historical, above-ground architecture near Mexico City’s central plaza. A glass “roof” provides natural light to many (though likely not all) of the levels, while curated micro-ecosystems are designed to keep the air fresh and clean. The designer hopes that— despite the daunting 800 million dollar price tag— his Earthscraper, a “mini-city” in its own right, is the sustainable solution to population growth without uncontrollable urban sprawl.\nAdvancements in subsurface construction have already made these otherwise far-fetched ideas seem increasingly possible. In Ticino, Switzerland, the tunnel system connecting a hydroelectric power-plant to its water source received a complete overhaul, located entirely underground to avoid disrupting the natural landscape. Despite passing through porous, water-filled layers and weak zones of loose rocks, innovative technology allowed the tunnel to be evacuated and sealed against leaks without contaminating the natural aquifers, or disturbing the forest above construction. Though a singular instance, the Ticino corridor was a pioneer in the sustainable refurbishment of preexisting infrastructure, and a possible blueprint for the underground tunnel and piping systems needed to support an inverted Earthscraper neighborhood.\nOf course, as with any feat of complex engineering and infrastructural change, there are plenty of challenges that we are faced with, both on an architectural and sustainability scale. Small, residential homes and larger, city-scale Earthscrapers are faced with different obstacles, but ultimately may share some of the same solutions. And, perhaps most importantly (and yet impossible to fully address), how will these buildings retain the feeling of “home”? Can you have neighbors, or a neighborhood, when all homes are covered by wildlife and hidden in the landscape? Can an Earthscraper beneath Mexico plaza still participate in military parades, festivals, and daily, interconnected city life? Such questions must also be considered, alongside the engineering plans, because no matter how eco-friendly buildings may be, families, communities, and retailers will not want to inhabit them if they do not also feel like proper homes, worthy of the cost and effort associated with them. But how close are we to this dilemma— how likely are we to see a significant shift towards subsurface architecture in our lifetimes?\nSmall, Earth-sheltered homes are already a novelty that have been built around the world, and are safely lived in by architectural enthusiasts and tourists. However, there are still concerns many have when considering an underground house. In particular, many homeowners worry about ventilation— lack of windows and airflow can cause the air to get stale or contaminated, so structures must maintain surface access and be engineered for fast exchange of interior and exterior air, which will require above-ground maintenance. Access to light is another necessity that requires careful consideration of surface area— a balance of windows and solar panels at the top of the house will help balance natural sunlight with eco-friendly electricity, to power UV-lamps and interior light to keep occupants healthy and well-illuminated. Of course, more glass above the surface will prevent seamless integration into the natural landscape, but even that is significantly less invasive to the ecosystem than a traditional home.\nThe other major barrier in the normalization of Earth-sheltered houses is concern for the type of soil available for construction. Granular soil makes the best ground-type for construction, allowing water to filter and drain easily around the home. In thick, non-porous soils, like clay or permafrost— or in areas of high humidity— the risk of interior leaking or condensation increases. And ground that is too loose can be unsafe to build a foundation in or on without sinking, similar to surface infrastructure. This makes the global application of these homes more limited, particularly in areas without access to the more expensive or eco-friendly building materials that create the foundations of many Earth-submerged homes. Hopefully, as techniques to build and integrate these buildings more seamlessly into the ground develop, their popularity, ease, and cost-effectivity will spread to a wider variety of land and countries.\nThe true architectural difficulty accompanies the construction of the “Earthscrapers”, intended to house many people, as well as provide versatile spaces capable of working, growing plants, and facilitating inevitable tourism. They are expensive and disruptive to build, require significant investment of materials and work hours, and, as of now, there is no fully operational model of success in the world. They also face more exacerbated versions of the difficulties faced by residential buildings; in hotter climates, will the beating sun combined with the bustle of machines and thousands of people create more heat than the structure can naturally dissipate, and how can a structure 35-stories deep remain well ventilated? Some of these issues can be addressed with the inclusion of “green rings” of high-oxygen producing plants, which lower temperatures and clean the air. But even this raises the question of how to efficiently conserve and recycle water in such a massive complex, especially if built in the desert-like environments where they have some of the greatest potential to flourish.\nAll of these combine to create the biggest roadblock in a functioning, subsurface neighborhood: the logistics of keeping it running. The engineering is not beyond what we’re capable of with modern technology, and there are already governments interested in investing in these projects. There are even more proposals to repurpose and expand old mines into subsurface theme parks, hotels, and residential housing. Once built, however, how can it be sustained? In an isolated, desert environment, solar panels can provide power, but what about Mexico City’s crowded central plaza, or in climates that do not receive near-constant sunlight? Waste removal on an industrial scale— especially working against the force of gravity to reach preexisting processing centers at the surface. The mundane operation of such a structure could quickly become an unsustainable power demand, which defeats the central idea of an inverted skyscraper being cleaner and more eco-conscious, especially if it must draw on power generated by fossil fuels. There are some proposed solutions to these issues, such as using fiber optic systems to carry sunlight to the deepest levels of the structure, or drawing water directly from nearby underground aquifers through piping systems, which is then filtered “on-site” at a processing plant built into the Earthscraper itself. These, and other sustainability-related questions, will have to be addressed before building can even begin; otherwise, an underground neighborhood may have an overall negative impact on the environment that it was created to protect.","by A’liya Spinner\nA City Beneath Glass\nAnita locks her front door behind her as she steps outside, swinging her purse up onto her shoulder and squinting slightly in the sun. It streams down in warm beams through a curved, glass dome overhead, illuminating a bustling, underground world, waking up around her as the sounds of machinery, voices, and the general hum of society echoed across the giant pit at the center of the Earth-scraper. Once, it had frightened Anita to walk outside her apartment and see a gaping chasm (behind a reinforced safety rail, of course), but once she’d started her new job at an office near the lowest levels, she was grateful for it— even that deep underground, it’s nice to see sunlight streaming down from above.\nContent, she begins her walk to the large, communal elevators that connect residential levels to the rest of the structure— there’s a high-speed train that rings each story of the Earth-scraper for those who dislike walking, but she enjoys the morning stroll. The central shaft of the Earth-scraper guides a pleasant breeze that warms her skin and flutters huge, rippling banners overhead. Some are advertisements for new shops in the lower rings, but others are merely decorations, colorful and holiday-themed for the season. Ribbons have been tied around the rail, and giant ornaments hang from the edges of the glass-domed ceiling; Anita appreciates the effort to make the Earth-scraper feel more like a community enthused with the spirit of celebration. The first years of living there, she sometimes felt like a troglodyte in a high-tech cave, surrounded by nothing but drab metal and stone and the monotony of everyday life. Now, it’s much more pleasant.\nThere’s a spring to her step as she walks, checking her phone for any texts or emails. None yet, which is fine by her. She likes her morning walks uninterrupted, before a busy day of work in the lower levels. A particularly strong gust of wind— churned by huge air purifiers built into the infrastructure of the Earth-scraper— brushes past her, and she pauses. And sneezes. And then sneezes again, covering her mouth with her sleeve.\nWhen she regains control of herself, Anita looks up and spies one of her friendliest neighbors, stopped beside her on the walkway and dressed in scrubs; vaguely, she remembers that he works at the urgent care in the middle of Earthscraper, taking emergency patients that don’t have the time or severity to go to the surface. She laughs and nods.\n“Unfortunately,” she replies, surreptitiously wiping her nose. “The green levels are all in full bloom— in December.” She glances up, towards the higher stories of the Earthscraper, full of gardens that provided not only fresh food and fresh air, but a frequent supply of pollen.\n“I guess nobody told the plants it’s winter on the surface,” he answers. “Sometimes I forget, too. I went topside the other day and forgot my coat— nearly froze my fingers off.”\n“Tell me about it.” Anita nods, relating to the feeling of living in another world, separate from the crowded bustle of the surface. Most of her life and work was in the Earthscraper, its own little community of people, things to do, and places to see.\n“Are you heading to the elevators?” Her neighbor begins to walk, pointing to a distant crowd of people that they would soon be joining.\n“Yeah, I’ll walk with you,” she answers, falling into place beside him. The warm air of the Earthscraper moved slowly around them, like the breath of a giant buried beneath the surface, starting to stir with a new form of life below the ground.\nInfrastructure beneath the ground is nothing new. Many urban centers use underground train systems to facilitate public transport, an idea first proposed in 1843, for the city of London. Though the first subways were destructive to build (requiring roads to be dug up and then recovered) and released noxious fumes, they were also immediately successful at transporting millions of people. As they became safer to ride and easier to build, the novel subway spread rapidly across Europe, and soon the rest of the world. Modern underground infrastructure is also utilized in sewage systems, pipes and cables, storage, and maintenance access— but rarely do we see large, habitable houses, offices, or tourist destinations underneath the ground.\nYet life underground isn’t as foreign as it might seem— over forty subterranean cities have been discovered around the world, such as Derinkuyu, an underground Turkish city that may have once held 20,000 people at its height in 800 BC. Near Derinkuyu is a potentially even larger site dating back 5,000 years, yet to be fully uncovered and studied. These cities— complete with homes, room for livestock and crops, and recreation— were not buried by volcanic eruptions or tectonic movement; these were intentional, subsurface settlements that have persisted for thousands of years. Now, they may be making a comeback, not for their defensive strength against foreign armies, but for their potential as a more climate-friendly solution to modern living.\nWhen constructed well, subsurface homes are less destructive to the ecosystem around them. Solar panels are easily positioned to provide energy to homes, while the ground remains otherwise intact for grass, native plants, and wildlife traffic, and the unpaved soil acts as a natural drainage system. Heating and cooling costs also decrease thanks to the insulating quality of the ground, especially in extreme climates with low humidity. Earth-sheltered buildings are less prone to damage from natural disasters, particularly fires, hurricanes, and tornadoes, a potentially life-saving design in communities currently under duress from climate change causing an increase in dangerous weather and wildfire. And, though the initial construction cost is higher than a traditional home, a foundation of recycled concrete and stone makes the house studier, requires less upkeep overtime, and reduces dependency on wood. But some architects want to take it far beyond an underground suburb; one entry to the eVolo Skyscraper Competition proposed a self-sufficient, subterranean community in the desert.\nThe 900-foot deep structure would be covered by a skylight dome designed to blend non-invasively to the desert ecosystem. Then, below the surface, high terraces grow produce for the community with unfiltered access to the sunlight. Under them are homes, work areas, and recreation spaces, connected by an underground, high-speed rail to other, nearby settlements. And the structure itself acts as a thermal funnel, venting heat through the surface dome and regulating the temperature with much more ease than surface buildings in the desert. Similarly, in Mexico City, plans for an enormous, inverted “Earthscraper” have been unveiled. The underground structure is proposed to contain thirty-five stories of offices, housing, gardens, and a museum, circumventing the law that prevents skyscrapers from exceeding eight stories within city limits, and preserving the integrity of the historical, above-ground architecture near Mexico City’s central plaza. A glass “roof” provides natural light to many (though likely not all) of the levels, while curated micro-ecosystems are designed to keep the air fresh and clean. The designer hopes that— despite the daunting 800 million dollar price tag— his Earthscraper, a “mini-city” in its own right, is the sustainable solution to population growth without uncontrollable urban sprawl.\nAdvancements in subsurface construction have already made these otherwise far-fetched ideas seem increasingly possible. In Ticino, Switzerland, the tunnel system connecting a hydroelectric power-plant to its water source received a complete overhaul, located entirely underground to avoid disrupting the natural landscape. Despite passing through porous, water-filled layers and weak zones of loose rocks, innovative technology allowed the tunnel to be evacuated and sealed against leaks without contaminating the natural aquifers, or disturbing the forest above construction. Though a singular instance, the Ticino corridor was a pioneer in the sustainable refurbishment of preexisting infrastructure, and a possible blueprint for the underground tunnel and piping systems needed to support an inverted Earthscraper neighborhood.\nOf course, as with any feat of complex engineering and infrastructural change, there are plenty of challenges that we are faced with, both on an architectural and sustainability scale. Small, residential homes and larger, city-scale Earthscrapers are faced with different obstacles, but ultimately may share some of the same solutions. And, perhaps most importantly (and yet impossible to fully address), how will these buildings retain the feeling of “home”? Can you have neighbors, or a neighborhood, when all homes are covered by wildlife and hidden in the landscape? Can an Earthscraper beneath Mexico plaza still participate in military parades, festivals, and daily, interconnected city life? Such questions must also be considered, alongside the engineering plans, because no matter how eco-friendly buildings may be, families, communities, and retailers will not want to inhabit them if they do not also feel like proper homes, worthy of the cost and effort associated with them. But how close are we to this dilemma— how likely are we to see a significant shift towards subsurface architecture in our lifetimes?\nSmall, Earth-sheltered homes are already a novelty that have been built around the world, and are safely lived in by architectural enthusiasts and tourists. However, there are still concerns many have when considering an underground house. In particular, many homeowners worry about ventilation— lack of windows and airflow can cause the air to get stale or contaminated, so structures must maintain surface access and be engineered for fast exchange of interior and exterior air, which will require above-ground maintenance. Access to light is another necessity that requires careful consideration of surface area— a balance of windows and solar panels at the top of the house will help balance natural sunlight with eco-friendly electricity, to power UV-lamps and interior light to keep occupants healthy and well-illuminated. Of course, more glass above the surface will prevent seamless integration into the natural landscape, but even that is significantly less invasive to the ecosystem than a traditional home.\nThe other major barrier in the normalization of Earth-sheltered houses is concern for the type of soil available for construction. Granular soil makes the best ground-type for construction, allowing water to filter and drain easily around the home. In thick, non-porous soils, like clay or permafrost— or in areas of high humidity— the risk of interior leaking or condensation increases. And ground that is too loose can be unsafe to build a foundation in or on without sinking, similar to surface infrastructure. This makes the global application of these homes more limited, particularly in areas without access to the more expensive or eco-friendly building materials that create the foundations of many Earth-submerged homes. Hopefully, as techniques to build and integrate these buildings more seamlessly into the ground develop, their popularity, ease, and cost-effectivity will spread to a wider variety of land and countries.\nThe true architectural difficulty accompanies the construction of the “Earthscrapers”, intended to house many people, as well as provide versatile spaces capable of working, growing plants, and facilitating inevitable tourism. They are expensive and disruptive to build, require significant investment of materials and work hours, and, as of now, there is no fully operational model of success in the world. They also face more exacerbated versions of the difficulties faced by residential buildings; in hotter climates, will the beating sun combined with the bustle of machines and thousands of people create more heat than the structure can naturally dissipate, and how can a structure 35-stories deep remain well ventilated? Some of these issues can be addressed with the inclusion of “green rings” of high-oxygen producing plants, which lower temperatures and clean the air. But even this raises the question of how to efficiently conserve and recycle water in such a massive complex, especially if built in the desert-like environments where they have some of the greatest potential to flourish.\nAll of these combine to create the biggest roadblock in a functioning, subsurface neighborhood: the logistics of keeping it running. The engineering is not beyond what we’re capable of with modern technology, and there are already governments interested in investing in these projects. There are even more proposals to repurpose and expand old mines into subsurface theme parks, hotels, and residential housing. Once built, however, how can it be sustained? In an isolated, desert environment, solar panels can provide power, but what about Mexico City’s crowded central plaza, or in climates that do not receive near-constant sunlight? Waste removal on an industrial scale— especially working against the force of gravity to reach preexisting processing centers at the surface. The mundane operation of such a structure could quickly become an unsustainable power demand, which defeats the central idea of an inverted skyscraper being cleaner and more eco-conscious, especially if it must draw on power generated by fossil fuels. There are some proposed solutions to these issues, such as using fiber optic systems to carry sunlight to the deepest levels of the structure, or drawing water directly from nearby underground aquifers through piping systems, which is then filtered “on-site” at a processing plant built into the Earthscraper itself. These, and other sustainability-related questions, will have to be addressed before building can even begin; otherwise, an underground neighborhood may have an overall negative impact on the environment that it was created to protect."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:eabe1751-76e6-4f01-880a-0dab4099f946>","<urn:uuid:eabe1751-76e6-4f01-880a-0dab4099f946>"],"error":null}
{"question":"How do the concepts of healthy ego-boundary in Gestalt theory compare with Erikson's Basic Trust vs. Mistrust stage in terms of their impact on a person's relationship with the world?","answer":"A healthy ego-boundary in Gestalt theory and positive resolution of the Basic Trust vs. Mistrust stage both contribute to positive relationships with the external world, but in different ways. In Gestalt theory, a healthy ego-boundary is characterized by being firm yet pliable, giving the person a clear sense of self, self-belief, and the ability to relate well to others. Similarly, in Erikson's theory, when infants receive good parental care during the Basic Trust vs. Mistrust stage (18 months to 2 years), they develop trust, confidence, and security in their relationship with the world. Both concepts emphasize the importance of early development in forming healthy relationships with others and maintaining a secure sense of self.","context":["TWO MAJOR ASPECTS OF GESTALT THEORY\n1. The Cycle of Awareness\nThe circleÂ representsÂ theÂ self/the person/the organism. Outside the circle is the environ-ment, i.e., everything which is not the person. The perimeter of the circle represents the boundary between the self and the environment, often referred to as the ego-boundary.Â In physical terms this can actually be the skin; psychologically it is a personâs sense of him or herself.\nA healthy ego-boundary is firm, yet pliable. Such a person would have a clear sense of who he or she was, self-belief and the ability to relate well to others.\nAn unhealthy ego-boundary could be:-\na) overly permeable. Such a person may appear to be compliant, too eager to please, easily influenced. He or she would not have a strong sense of themselves, and often lose that sense altogether in a close relationship.\nb) too rigid and impenetrable. Such a person may appear inflexible.Â He or she might not relate well to others, indeed may find it impossible to enjoy a close, intimate relationship with someone.Â There is no space to grow and develop as a person.\nWe need to remember that thoughts and feelings actually generate energy. Energy is real. You may not necessarily be able to see it or smell it, but it exists nevertheless.\nSo, if we decide that we want something, energy is produced to help us obtain that something; and that energy needs to be expressed, out from the body and on to the environment in some way (just speaking is one way!), otherwise, the energy stays trapped inside the body.\n1.Â Sensation dryness in the mouth\n2.Â Awareness realising one is thirsty\n3.Â Mobilisation deciding to have a drink and going towards it\n4.Â Action actually getting the drink\n5.Â Final contact drinking (the organism is in contact with the environment)\n6.Â Satisfaction thirst is quenched\n7.Â Withdrawal – a kind of limbo, state of homeostasis orÂ balance, before another Â Â Â Â Â need emerges\nThe clockwise journey around the Cycle of AwarenessÂ represents a healthy flow of energy, generated in the organism and finally expressed out on to the environment.\nThe example given is a physical one for simplicityâs sake, but the same pattern exists for emotional needs.\nHowever, in unhealthy functioning, âblocksâ can occur at each point. These âblocksâ or âboundary disturbancesâ or in Freudian terms, âdefence mechanismsâ, interrupt the natural flow of having our needs met.\n1. Â Desensitisation: perhaps as a result of abuse or neglect, we numb ourselves to pain and discomfort, become stoical.\n- Deflection:like denial. We refuse to be aware of feeling that might be painful\n3.Â Introjection: instead of deciding what we want and going for it, we are stuck with what we think we ought to do, or must not do, or how we think we should feel\n4.Â Projection:attributing a feeling or behaviour perhaps to someone else and not recognising it in oneself.\n5.Â Retroflection: emotion, such as anger, is bottled up inside instead of being expressed. Doing to yourself what you would like to do to other\n6.Â Egotism: instead of feeling satisfaction at a job well done, we go over and over it, Â analysing everything to death\n7.Â Confluence: not being able to let go. Losing oneself in a relationship.\n- The Five Level Model of Neurosis\nThe circle in the middle represents the core self, the real authentic person, before he or she developed layers of defences for self-protection, like an onion has layers. The task of therapy is to remove the layers, like peeling that onion, but,Â ofÂ course,Â slowly,Â gradually, carefully. Those defences were developed out of necessity, even for survival, so they need to be acknowledged for their original usefulness and respectfully laid to rest when their obsolescence is finally realised.\na) The outer layer – called the clichÃ©-layer, consists of socially accepted behaviour, meaningless small talk, clichÃ©d greetings, e.g.,\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âHello, how are you?â\nâFineâÂ (though your heart is breaking!)\nSome families only communicate at this level.\nb)Â The role-layer – We act as if we are only whatever our role is,Â e.g., helpless victims or born losers, a powerful boss, a devoted parent, a hard-working provider, the trouble-maker, the diplomat. So, if the role is taken away through bereavement, redundancy, divorce, children growing up and moving away, many people feel a loss of identity, because the real self is so buried; fortunately it is retrievable.\nc)Â The impasse-layer – In therapy, there comes a point when a client feels âstuckâ, resistant, very anxious, confused, uneasy, uncomfortable. It is an important stage in therapy, because the client is close to catharsis.\nNoviceÂ therapistsÂ oftenÂ feelÂ helplessÂ andÂ frustratedÂ atÂ this point, particularly where they see therapy as a mainly cognitive activity. Experienced therapists will welcome it and actively work towards it. In this layer, we begin to experience two aspects of ourselves locked in conflict, the healthy part which wants to complete the unfinished business, and the less healthy part that wants to avoid the suffering (anything for a quiet life).\nd) The implosive-layer/death-layer -Â is the paralysis of opposing forces.Â We pull ourselves together, contract our muscles, implode, because we dare not let go, in case something awful happens, like going berserk. If a client can tolerate this awful feeling, âstay with itâ, he/she will eventually explode.\ne)Â This is the catharsis, to the explosive or authentic-layer\nThere are four types of explosion:Â Â Â Â Â Â Â Â Â i) Anger,Â Â Â ii) Grief,Â Â Â iii) Orgasm,Â Â Â iv) Joy\nSo the person reaches his or her true self, an authentic person, feeling what he or she really feels and expressing it fully.","Erickson’s theory revised\nErickson’s Psychosocial Development Stages\nErickson’s psychosocial theory looks closely at the impact of external factors that a person has to go through from childhood to adulthood. According to the theory, every person has eight stages that they must go through over their entire life cycle. These stages are discussed below.\nBasic Trust vs. Mistrust. This stage is mostly observed during infancy between 18 months and 2 years. When a baby is very well taken care of by the parents, the baby will grow with a lot of trust, confidence and will also feel very secure. If the care lacks, however, in the baby’s early years, they may develop general mistrust to the world and insecurity (Shaffer, David 43).\nAutonomy vs. Shame. This stage occurs when the child is about 18 months to 3 years. A child gets the opportunity to build autonomy and build their self-esteem at this stage. He/she gets the opportunity to learn new skills and also get to know right from wrong. The child that was shown care will believe in himself/herself and will be confident rather than being shy. On the other hand, the child who faced negligence will be defiant, and stubbornness can appear.\nInitiative vs. Guilt. This is the stage when the child is between 3 -5 years and is most likely in preschool (Greene, Roberta 96). This is when the child’s curiosity heightens and you find that they will ask lots of questions. They will also try to imitate the adults in one way or the other. The child that received care at infancy will always take roles that are positive while the other child might not have the confidence to take even ant roles. They underestimate themselves.\nIndustry vs. Inferiority. This stage is that of a school age child between 6-12 years. Learning, accomplishing new skills and acquiring knowledge are the main issues that take place during this stage (Greene, Roberta 94). It’s also when the child gets to develop socially. At this stage, the most important relationship to the child is with their school and neighborhood. Albeit parents are still important to them, they do not play the major role they once did.\nIdentity vs. Role Confusion. This stage is between 12-18 years. Development at this point depends entirely on what a person does. Adolescents try hard to identify themselves and get to struggle to fit in.\nIsolation vs Intimacy and Solidarity. These are now the young adults of 18-35 years. Here, people begin looking for love and companionship. The most significant relationships at this stage are not those of neighborhood, parents, or even school but those of friends and marital partners (Shaffer, David 43).\nGenerativity vs. Self-absorption or stagnation. These are the middle-aged adults between 35-65 years (Shaffer, David 43). During this stage, the most important things are a career, work, and family. Working to be stable and trying to make a difference in the society is what this stage is all about. Family, the local church as well as other communities form important relationships for them.\nIntegrity vs. Despair. This stage is the late adult stage between 55 and 65–death. According to Erickson, much of life is preparatory for middle adulthood and late adulthood has a lot to do with reflection. Some older adults look back and appreciate themselves for having lived a meaningful life and having useful to the society (Greene, Roberta 96). At this point, there is a sense of despair for those who failed in their middle adulthood.\nIn conclusion, development continues throughout life, and each stage brings about a different societal difficulty that has to be resolved.\nGreene, Roberta R. Human Behavior Theory & Social Work Practice. New Brunswick, N.J: Aldine Transaction, 2008. Print.\nShaffer, David R. Social and Personality Development. Australia: Wadsworth/Cengage Learning, 2009. Print.\nGet a verified expert to help you with any urgent paper!Hire a Writer\nfrom $10 per-page"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:328d900a-14b2-40a7-a54f-4c89efea2bc9>","<urn:uuid:da143c32-4c6e-4371-be6d-150d6577963a>"],"error":null}
{"question":"What role did legal documents play in the lives of Madam C.J. Walker and Brooke Astor regarding their charitable giving?","answer":"For Madam C.J. Walker, her will served as an effective instrument to ensure her charitable intentions were carried out, directing two-thirds of her estate's future net profits to charity and successfully bequeathing nearly $100,000 to orphanages, institutions, and individuals. In contrast, Brooke Astor's legal documents were used as tools of exploitation, with three codicils being executed that redirected almost $100 million of her charitable bequests against her wishes, particularly impacting institutions focused on education. These cases demonstrate how legal instruments can either protect or undermine a person's charitable intentions.","context":["Decision-making, fraud, and undue influence—illustrated through the lens of the Brooke Astor story\nRemarks prepared for Our Aging Brains: Decision-making, Fraud, and Undue Influence, part of the Project on Law and Applied Neuroscience, a collaboration between the Center for Law, Brain & Behavior at Massachusetts General Hospital and the Petrie-Flom Center for Health Law Policy, Biotechnology, and Bioethics at Harvard Law School; April 27, 2018.\n“Elder abuse is not substantiated”\nThe meaning of elder abuse remains misunderstood, even by professionals.\nI know—from hard-learned experience—when I, and many others, worked to save my grandmother from abuse by my father.\nIn a December 2006 court decision, my grandmother’s guardianship judge authorized reimbursement of my legal fees for bringing a guardianship petition for my grandmother, stating, “Although this matter voluntarily settled before the hearing, I find the petitioner Philip Marshall was the prevailing party…”\nBut the judge also decided to award my father a portion of his legal fees, writing, “I make this ruling based on the conclusion of the court evaluator that the allegations in the petition regarding Mrs. Astor’s medical and dental care, and the other allegations of intentional elder abuse by the Marshalls, were not substantiated.” [italics added]\nThis decision probably has much to do with the misunderstanding of elder abuse, elder financial exploitation, testamentary capacity, undue influence, and many other critical legal concerns addressed here, today, and for millions of seniors and their circles of support (personal and professional) all along the way.\n“Astor son is cleared,” headlined The New York Times, which quoted my father’s lawyer saying, “This is a case that was given birth from allegations that were absolutely fictitious regarding Mr. Marshall’s care of his mother.’” (2006)\nOn the dark December day of this decision, our Pyrrhic victory found us losing the greater war against elder abuse.\nWas my grandmother’s case to be elder justice’s Plessey v Ferguson?\nWere we to repurpose my family’s ‘dirty laundry’ as surrender flags, giving up on the greater cause in to which we had been so thrust?\nThis one clause catapulted our campaign from case to cause.\nAnd, just as my father declared that he had been vindicated, the Manhattan District Attorney’s Elder Abuse Unit expanded its own investigation, empanelled a grand jury, and issued subpoenas.\nIn November 2007, my father and a lawyer were indicted.\nIn April 2009, a criminal trial began.\nExecuting codicils while “delusional”\nSubstantial, serial changes to my grandmother’s will began in 2002—and escalated.\nIn my grandmother’s case three lawyers combined to create a ‘perfect storm’ coming in to her frail life in the winter of ’03-’04 to execute three codicils that redistributed almost $100 million of her bequests to charities, directing them to my father’s control.\nFirst, my grandmother’s long-standing lawyer and good “friend” who was head of trusts and estates for an internationally recognized firm.\nThis lawyer, who was a co-trustee of the Vincent Astor Trust, was planning to be attorney and co-executor of my grandmother’s estate.\nThis lawyer, as his last of several acts just before he was fired, took the highly unusual step of preparing a self-described “First and Final Codicil.” (For discussion, see an interview conducted by Lori A. Stiegel, Senior Attorney, ABA Commission on Law and Aging, with Expert Witness Alex Forger 2011)\nThis lawyer betrayed my grandmother’s trust and compromised her testamentary wishes.\nAnother lawyer, who my grandmother had never met before, but presumed to act in her best interest, executed a second codicil, changed her executors, and executed a new power of attorney. This lawyer covered up his tracks to, at, and from, the signing of the codicil. Multiple versions of his memo memorializing the event were crafted to suggest that my grandmother had testamentary capacity. (memo drafts)\nAnd last, a lawyer, Francis Morrissey. In the 1990s he had been suspended from practicing law.\nThis lawyer, who had known my father’s third wife for years, insinuated himself in to my grandmother’s life and orchestrated much of this from the sidelines — while waiting for the residual in the form of fees as newly appointed co-executor and estate attorney.\nThis lawyer’s suspect forgery of my grandmother’s signature on a third codicil later spurred the Manhattan District Attorney, as it started its own investigation.\nWhile my grandmother’s will to live remained strong, her (testamentary) will, to give, had been completely compromised — four years after my father, claimed she was “delusional” in a seven-page letter to Dr. Howard Fillit, a geriatric neurologist.\nAfter the execution of these codicils, my grandmother was fearful of “men in suits.” At night, she asked nurses to look under her bed for the, “man who wants to kill me.”\nFollowing diagnosis by Dr. Fillit, my father told her country butler to keep the news to himself. Upon request my father have him a short list of the signs of Alzheimer’s disease—and instructed him to call her lawyer if they had any questions. Staff received no professional support.\nMy grandmother’s wellbeing was direct casualty of an effort to exploit her when, and because, she was in the throes of Alzheimer’s disease.\nAs perpetrators know, psychological manipulation by undue influence is so effective in commanding their power while further debilitating seniors who have cognitive impairment and may lack testamentary capacity. Undue influence can compromise seniors’ wellbeing—and their wishes.\nIn horror, I realized this was happening to my grandmother when she was most vulnerable.\nAfter her hundredth birthday, I grew increasingly concerned for my grandmother. I began speaking with her supportive staff and caregivers.\nA transaction had raised red flags. I heard that while my father was cutting back on my grandmother’s expenses, he had sold her favorite painting—Flags, Fifth Avenue, by Childe Hassam— that she had bequeathed to the Metropolitan Museum of Art. (New York Times, 2006)\nThe sale realized $10 million, two of which my father kept as a “commission.”\nOn hearing of the sale, my grandmother, who had been led to believe she was running out of money, asked, “Now, can I buy dresses?”\nMy grandmother went from the limelight, center stage as lead actor in her own life, to being ‘gaslighted’ by her own son, who psychologically broke her down into believing she was going broke.\nMy grandmother knew she was subject to undue influence, evidenced by testimony during my father’s trial.\nAs reported by The New York Times, according to an attending nurse, Ms. Noble, Mrs. Astor said, “‘I give up. They get all that they want. I’m so gaga, what can I do?’”\nDuring the signing of a codicil, my grandmother attempted to defend herself; again, quoting the Times, “‘I won’t be pushed into any business, do you hear me?’ Ms. Noble said that Mrs. Astor told her son.” and “…when the Marshalls visited the apartment, Ms. Noble said that Mrs. Astor told her: ‘What do they want? Tell them I will pay them to leave.’”\nUndue influence is elusive — from isolated seniors at home, to professionals’ offices, to our court houses, and for responders along the way. Even its definition is elusive.\nBut advances are being made. For example, in 2014 California updated its laws and its 1872 definition of ‘undue influence’ so judges, for the first time, have specific means to evaluate its existence in a given case.\nA new statutory legal definition, California Probate Code and Welfare and Institutions Code, and a pilot California Undue Influence Screening Tool (CUIST) to help adult protective services personnel are all aimed to maximize use and effectiveness in the field—and, hopefully, in court.(Marshall and Quinn 2017)\nWe advance from case to cause, when we go from case to case laws.\nIn the Redstone/Viacom conflict in 2016, it is unfortunate that California Judge David J. Cowan, who was deciding one of the related cases, did not rule on Sumner Redstone’s competency—or undue influence. (Hollywood Reporter 2016)\nWhen the conflict came to Massachusetts before Judge George F. Phelan of Norfolk County Probate Court, as noted in The New York Times, “Multiple times, Judge Phelan asked whether a finding of undue influence should invalidate the dismissals from the trust, and cited a section of Massachusetts trust code on the matter.” (2016) Shortly after, the case was settled out of court.\nIsolation and cognitive impairment\nMy grandmother was cognitively impaired and isolated, yet her case is far from isolated: millions of victims suffer similar injury every day. (Pillemer et al 2015)\nWhile seniors may be isolated and cognitively impaired; each of us (personally and professionally) may be, too.\nProfessionals are isolated…in disciplinary silos — even in their own industry. This hampers collection and sharing of information to detect, respond to, and prevent theft; and in taking a proactive, strengths-based approach to aging.\nPerpetrators know this, to their advantage.\nWe need consistent terminology and much more multidisciplinary work to aid in research, response, performance measurement, and asset allocation—especially toward prevention.\nWe need data sharing within and across disciplines.\nThis urgency and opportunity is underscored by findings of last November’s conference at the “Philly Fed,” co-sponsored by UPenn, on Aging, Cognition and Financial Health and its proposal to have the healthcare and financial industries share data, cradled in a trust framework with privacy concerns in mind. (Aging, Cognition and Financial Health: Building a Robust System for Older Americans, hosted by the Consumer Finance Institute of the Federal Reserve Bank of Philadelphia and co-sponsored by the Penn Memory Centerand Healthy Brain Research Network Centerat the University of Pennsylvania.)\nProfessionals also isolate themselves from themselves — from their personal experience.\nColleagues associated with The Gerontological Society of America examined both facets of their lives last year in a special issue, “Aging: It’s Personal,” different from anything The Gerontologist has ever published. Rachel Pruchno, issue editor, notes, “Although science tells us about average experiences, these reflections show that real life is sometimes much more complex and much messier.” (2017, 4)\nThis why I am so grateful for our conference leaders today who, from the outset, explained to me how their personal circumstances have informed and compelled their work — and their appreciation of community-wide conversations.\nFor, our silence protects perpetrators, not their victims.\nThis why public engagement — here, this morning — is so valued.\nOur shared stories will help translational research come full circle, to embrace all stakeholders in protecting our perimeter against abuse when we consider communities countrywide as living laboratories.\nSeniors may be cognitively impaired. We all may be ‘cognitively impaired,’ and missing pieces, when it comes to elder justice.\nAgeism is the fundamental impediment to elder justice, due to its ‘fear factor’— as we are scared to death…of death , and any of its associations. (Becker 1973, Solomon) This impairs seniors and our future self, every day.\nWe are only more scared by the existential trauma of dementia, including its stigma — with the (scarlet) “Big-A” at the forefront.\nPerpetrators know this, to their advantage as they weaponize dementia (alleged or actual) and legal instruments — POAs and guardianship, included.\nTribulation to trial\nWe advanced from tribulation to trail. From the tribulation of hearing the allegations in my petition for guardianship were unsubstantiated, to a criminal trial that proved otherwise.\nYet, it took a six-month trial—which included over seventy witnesses for the People and none for the defense—to prove, beyond a reasonable doubt, that my grandmother was cognitively impaired, lacked testamentary capacity, was subject to a scheme to defraud, and was a victim of abuse.\nMy father was convicted on 14 counts. All but one were upheld on appeal.\nBefore we acted, my grandmother was poly-victimized and re-victimized.\nHowever, she was not victimized after intervention— only because she was not cognizant…of the guardianship judge’s finding that, “elder abuse was not substantiated,” or that, during the criminal trial, it was claimed by the defense she had a “lucid moment” while signing legal documents.\nIn Surrogates, whose proceedings had been put on hold, a settlement was reached that provided for charities (especially those with an emphasis on education) largely as my grandmother wished.\nHere, if her wishes had not been met, New York teachers would have received nothing more than a lesson plan in how elder abuse—and a legal system inadequately informed by neuroscience, psychology, and psychiatry—can be used to exploit.\nMy grandmother’s case gained national attention. Most cases are not even known. Only one in 24 cases of elder abuse are reported—and only one in 44 cases of elder financial exploitation, the most prevalent form of abuse. (Under the Radar 2011)\nPerpetrators frequently take advantage of victim vulnerability, undue influence, and legal instruments, which they use as a weapon and a shield—to steal.\nIf caught, they know perpetrator accountability and victim recovery can be compromised by our inadequate understanding of neuroscience, psychology, psychiatry ,and legal doctrine of financial decision-making in older adults.\nToday takes us one step closer to society’s proactive prevention of, and response to, abuse—and to making elder justice as American as grandmother and AAPL pie.\n— Philip C. Marshall, Founder, Beyond Brooke","W is for Madam C. J. Walker, First Female Self-Made Millionaire in U.S., #AtoZ Challenge\nBy Scurlock Studio (Washington, D.C.) (photographers). [Public domain], via Wikimedia Commons\nMadam C. J. Walker was born Sarah Breedlove, the last of six children, on December 23rd, 1867, in Louisiana.\nSarah’s parents and four older brothers and one sister were slaves on Robert W. Burney’s Madison Parish plantation, but Sarah was born a free child, as the Emancipation Proclamation was signed before her birth.\nHer mum died when she was 5 and her dad died when she was 7 – she lived with her older sister Louvenia, and brother-in-law Jesse Powell in Mississippi, and became a domestic servant at the age of 10.\nShe married at the age of 14, and had one daughter, Lelia, who was 2 when her husband died – she remarried but left this husband and moved to Missouri. There she married again, Charles Joseph Walker, a newspaper advertising salesman. Although she eventually divorced him in 1912, she kept his name and became known as Madam C. J. Walker.\nIn 1888 she moved to Saint Louis, Missouri, where three of her brothers, who were barbers, lived. She learned about hair care from them, and ended up selling hair care products for an African hair care entrepreneur, Annie Turbo Malone.\nSarah began to adapt the products and develop her own product line. From there, she started her own career.\nBetween 1911 and 1919, during the height of her career, Sarah and her company employed several thousand women as sales agents for its products, and employed 20,000 women selling products door to door. She also understood the power of advertising and harnessed this to advertise in African American newspapers and magazines.\nShe encouraged her employees by giving prizes to the best sales agents – helped other black women build their own careers, and rewarded those who made the largest contributions to charities in their communities.\nShe became a political activist, promoting black interests, and donating money to black causes. Profits from her business helped her donate to many causes and in 1918 the National Association of Coloured Women’s Clubs honoured her for making the largest individual contribution to help preserve Frederick Douglass’s Anacostia house. She pledged $5,000 to the NAACP’s anti-lynching fund. At the time it was the largest gift the NAACP had ever received. She also bequeathed nearly $100,000 to orphanages, institutions, and individuals and her will directed two-thirds of future net profits of her estate to charity.\nShe was one of the wealthiest African American women in the US, the WORLD’S MOST SUCCESSFUL FEMALE ENTREPRENEUR of her time, (let alone most successful black woman!) and one of the most successful African-American business owners ever.\nShe died on May 25th, 1919.\nEventually, by the 1920s, her empire expanded as far as Cuba, Jamaica, Haiti, Panama, and Costa Rica, carried on by her daughter.\nThe firm is still going today strong today as evidenced by their reply to my tweet of this post! Hooray!\nIf you’d like to read about more extraordinary women, why not buy the book Reaching the Stars, Poems about Extraordinary Women and Girls, by me, Jan Dean and Michaela Morgan – link below, press on book!\n- Posted in: A-Z Challenge 2017 ♦ Extraordinary Women ♦ Liz Brownlee ♦ Poems ♦ Reaching the Stars ♦ Reaching the Stars Poems\n- Tagged: Black activsist, black hair products, entrepreneur, Extraordinary Women, Jan Dean, Liz Brownlee, Madam C. J. Walker, Michaela Morgan, Poems about extraordinary women and girls, poetry, Reaching the Stars, self-made millionaire"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:0a020a87-05f6-42ce-b05c-4983a4eec8f5>","<urn:uuid:dcc86ce7-9144-4b96-9dd0-b6ed6d972128>"],"error":null}
{"question":"Did Saruq Al Hadid's trade peak coincide with Amenhotep III's Sed Festivals?","answer":"The documents do not provide enough information to determine if Saruq Al Hadid's trade activities coincided specifically with Amenhotep III's Sed Festivals. While we know that Saruq Al Hadid had trade connections during Egypt's 18th dynasty through seals from Thutmose III's time, and we know that Amenhotep III celebrated three Sed Festivals during his 38-year reign, there is no explicit temporal connection made between these events. The Saruq Al Hadid site shows evidence of trade with Egypt, but the precise timing relative to Amenhotep III's celebrations cannot be determined from the available information.","context":["Dubai: If you think Dubai became a centre of trade in the region only after the development of the Dubai Creek, you are mistaken. There is now evidence that the emirate had strong trade links with Egypt to the Indian subcontinent even 4000 years ago.\nThe findings from the Saruq Al Hadid archeological site, which tell the oldest history of Dubai discovered so far, have helped archeologists map the trading links that existed between Dubai and other countries in the region during the Iron Age.\nThe ancient trade map displayed at the temporary museum in Shindagha Heritage Village showcases almost 900 objects discovered from the Saruq Al Hadid archeological site.\nThe ancient trade map is displayed at the newly opened temporary museum in Shindagha Heritage Village that showcases almost 900 objects discovered from the site.\nSaruq Al Hadid lies in the middle of Rub Al Khali desert, some 70km south of Dubai towards the border with Abu Dhabi. But it was well placed to access the major trade routes of the ancient Middle East because it sat at a crossroads on the sea and land routes between Egypt, India, Mesopotamia and Oman.\nRashad Bukhash, the director of Architectural Heritage Department at Dubai Municipality which supervises the archeological site and the museum, told Gulf News that the discoveries from Saruq Al Hadid have so far showed Dubai’s long-distance trade links with Egypt, Syria, Iraq, Iran, Oman, Bahrain, India, Pakistan and Afghanistan.\nMany objects excavated from the site have features that are seen in objects made far from Saruq Al Hadid. This suggests that Saruq Al Hadid must have had some kind of trading connection with these distant cultures, cementing the proof for Dubai’s role as a centre of trade and civilisation in the Arabian Peninsula during that era.\nIncense burners found at the site. Zarina Fernandes/Gulf News\n“It was a central city which traded in different metals, precious stones and pottery,” said Bukhash.\n“Many things were brought from outside while many things were manufactured here and exported from Dubai to different parts of the world.”\nBukhash said Saruq Al Hadid was a place “where all different things were coming and going through…”\n“It shows the age-old tradition of Dubai being a hub for trade even in those days.”\nA storage jar with snake decorations. Zarina Fernandes/Gulf News\nWhat are the discoveries that lead us to believe this?\nIn olden times, Bukhash noted, people used seals/stamps for making impressions in stones, clay or wax to show the country of origin of goods when they were traded with other countries. Such seals from Egypt, Mesopotamia, and Dilmun in modern Bahrain have been recovered from Saruq Al Hadid.\nArcheologists have a catalogue showing stamps used during the times of different pharaohs in Egypt. “Each pharaoh had his own stamp … The ones which we found from Saruq Al Hadid are from the pharaoh called Thutmose III [the sixth pharaoh of the 18th dynasty] who lived in the same period of Saruq Al Hadid civilisation.”\nAn incense burner with feet in the shape of bull hooves shows links between the Arabian Peninsula and Mesopotamia at that time since it is an ancient artistic tradition that originated over 4000 years ago in northern Mesopotamia.\nThis delicately decorated shell disc may have been used as a form of jewellery. Zarina Fernandes/Gulf News\nThe decorative styles and shapes of pottery vessels have provided clues about the site’s trading links and outside cultural influences. The designs of some of the vessels show influences from Mesopotamia, Dilmun and other regions that were important when Saruq Al Hadid civilisation was at its peak.\nPrecious stones and beads that were prevalent in ancient India, Afghanistan, Iran, and Yemen have also been found at the site.\nThe objects made from olive wood, it is believed, might have been imported from the eastern Mediterranean region. “They could have been imported from Syria,” said Bukhash.\nThe presence of gold threads from the site indicates that gold ornaments and artefacts were manufactured in Saruq Al Hadid and probably exported to different places. Archeologists working in Sharjah’s Maliha site have found gold ornaments similar to those manufactured at this site.\n“But from where did they bring the gold threads found on the site … from Oman, Saudi Arabia or Yemen? It is not exactly clear,” said Bukhash.\nShatha Al Mulla, project engineer of the Saruq Al Hadid museum, said the source of raw materials for many metals is believed to be Al Hajar Mountains in Oman.\n“They (people of Saruq Al Hadid) also could be linked to agricultural land from these mountains of Oman. That is where you could find a lot of soil suitable for cultivation,” said Al Mulla, an architect with the department.\nHowever, what exactly were the means of their transportation is not yet clear.\n“The camel bones are evidence that domesticated camels were present at the site and they were probably used for trade as well,” said Al Mulla.\nShe said the presence of fish bones shows that fish were brought from the coast, proving that this place had links with the sea. “But we have not yet got any evidence for their use of boats or dhows. It is still a mystery.”\nFurther excavations and research at the site are likely to throw more light on these aspects.\nTop 15 mysteries about Iron Age Dubai\nWhile the Saruq Al Hadid archeological site has shed light on the Iron Age civilisation in Dubai, there are many mysteries surrounding the discoveries from the site which may or may not be answered with further research. Here are the top 15.\n1. Who were these people? What were there tribe, language and religion?\n2. Why did they live in the middle of the desert, not very close to the sea or mountains like in many ancient civilisations?\n3. How was their daily life? What did they use to eat and wear?\n4. Where were they living and where were they buried?\n5. From where and how were they getting metals like bronze, iron and gold?\n6. What exactly were their modes of long-distance transportation? Apart from camels, did they use boats or anything else?\n7. What is the mystery of the snakes? Were they worshipping the snakes? Was it holy for them? Why are they seen in many objects?\n8. What is the secret of six-headed stars in decorated shells and other objects?\n9. What were the huge metal anklets used for? Were they used for camels as ornaments or for restricting their movement during long-distance journeys?\n10. Why did they use two metals in making some daggers with handle from bronze and body from iron?\n11. Where did the objects made of olive wood come from? Were they imported from Syria or were they growing olive trees here?\n12. What were the gold rings that inspired the new Dubai Expo 2020 logo used for? Were they part of any ornaments or were they buttons in the clothes of any rich or ruling person?\n13. What were the small metal human figurines used for? Were they toys for children, or as charms? Or were they simply objects made by metalworkers in an idle moment?\n14. What was inside the huge pots? Were they used as decorative pieces or for storing water or oil?\n15. How did the civilisation end? When was the last time they were there? Why did they disappear from the site?","The Thutmosid royal family ruled Egypt for almost 150 years when Amenhotep III was born to Thutmose IV and his minor wife Mutemwiya in approximately 1388 BC. Succeeding his father on the throne as the ninth king of the dynasty, Amenhotep ruled between 1386 and 1350 BC.\nEgyptologists list his length of reign as varying between 38 to 40 years. Most experts believe he became pharaoh sometime between the age of six and 12 years of age under the guidance of an unknown co-regent.\nAmenhotep was his actual birth name, meaning “Amun I Pleased, Ruler of Thebes”. Although he was often known as “Amenhotep the Magnificent”, his actual thrown name was Nub-maat-re, or “Lord of Truth is Re”.\nDuring the second year of his reign he married Tiye. Although she was not of royal blood, she came from a powerful Egyptian family. Amenhotep took many wives during his reign. His harem included at least six foreign diplomatic arrangements and two of his own daughters.\nEgyptologists have identified two sons and four daughters. His first son, the crown prince Thutmose, died at an early age. His second son by Queen Tiye, Amenhotep IV, succeeded him and later changed his name to Akhenaton. His grandson was the famous King Tutankhamun.\nAmenhotep’s reign focused on expanding diplomatic contacts instead of military campaigns. Early in his reign, successful expeditions in Nubia appear to be his most significant military involvement. The majority of his accomplishments focused on building and cultivating the arts.\nLike many Egyptian pharaohs, Amenhotep worked to ensure his place not only as a kingbut also as a god. Reliefs at his Temple of Amun at Luxor indicate that his birth was not simply royal, but also blessed and brought about by the gods. Egyptians credit him with building the famous Colossi of Memnon, which was actually the foundation of his mortuary temple. Although the temple was raided during the 19th dynasty for its stone, archaeologists believe that it was the largest mortuary temple built in ancient Egypt.\nMore statues exist today of Amenhotep than any other pharaoh. Over 250 statues reveal an expansion of the arts during the king’s rule. A new sense of detail and artistry emerged in the statues and reliefs.\nQuestions of Co-Regency\nAlthough no concrete evidence has been presented, a few historians believe that a co-regencybetween Amenhotep and his son Akhenaton may have existed. Although most Egyptologists dismiss this theory, multi-national teams of Egyptologists continue to research the issue.\nThe King’s Afterlife\nEgyptologists identify tomb KV22 in the West Valley of the Kings as the tomb of Amenhotep III. Decorated with a version of the “Book of What is in the Underworld”, the tomb uniquely featured the king as the royal ka. The tomb showed evidence of many raids from antiquity to modern times. Every object inside was damaged or fragmented.\nAmenhotep’s mummy was located in a royal cache within the tomb of Amehotep II. Investigations of the mummy reveal the king to be between 40 and 50 years old at the time of his death. Reliefs show that he was ill towards the end of his reign. His cause of death is unknown.\nSed Festival Stela of Amenhotep III\nThe Sed Festival dates from the dawn of early Egyptian kings of the Old Kingdom When a king served 30 years of his reign, he performed a series of tests to demonstrate his fitness for continuing as Pharaoh. On completion, the king’s rejuvenated vitality enabled him to serve three more years before holding another Sed Festival. To commemorate an event, a stela, which is a stone of various size and composition, is inscribed with highlights of the event. Proclamations informed the people living in Egypt of an upcoming Sed Festival together with stelae.\nA Sed Festival Stela of Amenhotep III (Hellenized as Amenophis III) was taken from Egypt to Europe by an art dealer. It is now believed to be in the United States but on not public display. In Europe, Dr. Eric Cassirer at one time owned the stela. The dimensions of the white alabaster stela are 10 x 9 cm (3.94 x 3.54 in), but only the upper half of the stela survived. It was shaped in the form of a temple pylon with a gradual narrowing near the top.\nFront view: The god Heh, who represents one million, holds notched palm leaves signifying years. Above his head, Heh appears to support the cartouche of Amenhotep III symbolically for a million years.\nSide view: A series of festival (hd) emblems together with a Sed (sd) emblem identifying the stela as one made for Amenhotep III’s Sed Festival royal jubilee.\nTop view: The top shows malicious damage to the stela where the cartouche chipped away.\nBack view: Like the top view, the cartouche has been eradicated.\nCassirer suggests Akhenaten, Amenhotep III’s son and successor, was responsible for defacing the king’s name on the stela.Akhenaten detested his royal family name so much, he changed his own name from Amenhotep IV to Akhenaten; he vandalized any reference to the god Amun since Akhenaten had chosen to worship another god, the Aten. Other gods displayed on the stela, Re and Ma’et, showed no sign of vandalism.\nThe stela is believed to have been displayed prominently in Akhenaten’s new capital city of Amarna. With the royal name and Amun references removed, it likely had a prominent place in a temple or palace of Akhenaten. Akhenaten could then display the stela without reminders of his old family name or the false god Amun yet celebrate his father’s achievement.\nAmenhotep III’s Sed Festival\nAmenhotep wanted his Sed Festivals to be far more spectacular than those of the past. He served as king for 38 years celebrating three Sed Festivals during his reign. Rameses II set the record for Sed Festivals with 14 during his 67-year reign.\nAmenhotep III appointed Amenhotep, son of Hapu, as the official to plan the ceremony. Amenhotep-Hapu was one of the few courtiers alive to serve at last Sed Festival (Amenhotep II). Amenhotep-Hapu enlisted scribes to gather information from records and inscriptions of prior Sed Festivals often from much earlier dynasties. Most of descriptions were found in ancient funerary temples. In addition to the rituals, they collected descriptions of costumes worn at previous festivals.\nTemples were built and statues erected up and down the Nile. Craftsmen and jewelers created ornaments commentating the event including jewelry, ornaments, and stelae. Malqata, “House of Rejoicing,” the temple complex built by Amenhotep III, served as the focal point for the Sed Festivals. Malqata featured an artificial lake Amenhotep built for his wife, Queen Tiy, that would be used in the Sed Festival.\nThe scribe Nebmerutef coordinated every step of the event. He directed Amenhotep III to use his mace to knock on the temple doors. Beside him, Amenhotep-Hapu mirrored his effort like a royal shadow. The king was followed by Queen Tiy and the royal daughters. When moving to another venue, the banner of the jackal god Wepwawet, “Opener of Ways” preceded the King. The king changed his costume at each major activity of the celebration.\nOne of the major highlights of the Festival was the king’s dual coronation. He is enthroned separately for Upper and Lower Egypt. For Upper Egypt, Amenhotep wears the white crown but changes to the red crown for the Lower Egypt coronation.\nBased on indications left by Queen Tiy’s steward Khenruef, the festival may have lasted two to eight months. Khenruef accompanied the king as he traveled the empire probably reenacting the ceremony for different audiences.\nAt the time of the festival, Amenhotep III had three official wives. The “Great wife,” Queen Tiy. Their daughter Sitamem who was promoted to a queen at the time of the Sed Festival. The third queen, Gilukhepa, was a daughter of the king of Mitanni, a traditional Egyptian rival. No mention is made of the royal harem.\nAlthough shunned by common Egyptians, incest was not uncommon among royalty. In fact, most Egyptian creation stories depend on it. By the time of the Sed Festival, Queen Tiy would be past her child-bearing years. However, a sculpture restored by Amenhotep for his grandfather, Amenhotep II, shows Sitamem with a young prince beside her.\nAs a reward for a lifetime of serving the Egyptian kings, Amenhotep-Hapu received his own funerary temple. The location was behind that of his king, Amenhotep III. Some of Amenhotep III’s workshops were razed to make room for Amenhotep-Hapu’s temple.\nSome of the known information about Amenhotep’s Sed Festival comes from an unlikely source: the trash heap at Malqata Palace. Many jars bearing the names of donors to Amenhotep III to celebrate his festival. The donors were not just the rich but also small servants. The jars bear the donor’s name, title, and date. The jars were stored without respect to their origin.\nAfter the Sed Festival, Amenhotep III transcended from being a near-god to one divine. Few Egyptian kings lived long enough for their own celebration. Those who survived used the celebration as the affirmation of transition to divinity."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:c70e02af-1c17-4f72-b04e-fef2366b3787>","<urn:uuid:0d828aec-ea91-449a-bdac-287dc6412955>"],"error":null}
{"question":"How does blockchain's smart contract capability enhance healthcare data management, and what privacy controls exist across different blockchain types?","answer":"Smart contracts in blockchain platforms like Ethereum and Hyperledger can automate the medical consent process and control data access through logic-based conditional agreements. Regarding privacy controls, private blockchains offer strong privacy through self-contained networks managed by single entities, while permissioned blockchains allow multiple authorized participants to maintain privacy while sharing data. Public blockchains have limited privacy controls but offer the highest security and decentralization. Healthcare implementations would need to balance these options to maintain patient data privacy while enabling necessary access across providers.","context":["What is Blockchain?\nBlockchain. It’s a term that’s been on the tip of everyone’s tongue following recent, exciting advances in the technology, and growing media attention on the cryptocurrency market. Rightfully so, there is also a healthy mix of skepticism and cautious optimism depending on who you speak with. This year’s Health Datapalooza program aims to address the hype with multiple sessions including a main stage panel titled “AI, Blockchain, Machine Learning, IOT...from Buzzwords to Reality in Healthcare.” We hope this two-part blog will help you understand how blockchain works, considerations for health-related applications, and what the future holds.\nAt its core, blockchain technology represents a data structure that makes it possible to create a digital ledger of transactions and share it among a distributed network of computers with the potential for increased security, reductions in cost, decreased transaction times, and greater transparency - all while eliminating the need for a trusted third-party or intermediary. Blockchain technology uses cryptography to allow each participant in the network to make additions to the ledger in a secure manner without the need for a central authority, as long as any additions and changes are validated and agreed upon by network participants as adhering to the rules of the specific blockchain protocol.\nBlockchain technology, conceptualized by early pioneers such as the pseudonymous programmer(s) Satoshi Nakamoto with the widely known Bitcoin blockchain platform, was crafted in response to problems related to trust and the need for disintermediation in transaction processing. Blockchain’s elimination of central authorities, third-parties, or intermediaries for common transactions result in ‘trustless’ transactions where two parties conduct a transaction (i.e., peer-to-peer) by trusting the rules and cryptography in the underlying blockchain protocol. These features alleviate the common double spend problem (i.e., using the same digital money files such as Bitcoins more than once) with blockchain transactions structured to be irreversible and final within their timestamped universal ledger.\nBlockchain technology can also be classified into three categories based upon the entities who control and participate in the specific blockchain platform ecosystem: Private, permissioned, and public.\nPrivate blockchains are controlled by single entities managing all of the nodes and validators (i.e., key members of the organization’s blockchain network which independently check the data being conveyed through the network). Their distributed ledgers provide auditability of transactions within an organization, and the self-contained nature promotes privacy versus public blockchains. However, private blockchains lack true decentralization, leaving them potentially susceptible to the dictates of centralized governance and decision making. Attackers targeting an organization’s validator nodes, can also lead to the risk of blockchain rule changes or ledger modifications which compromises the integrity of the blockchain.\nPermissioned, or consortium, blockchains are those in which a group of participants (typically in a formal business agreement) each run a validator node. This promotes greater decentralization than private blockchains depending on the number of participants and validator nodes in the system. However, potential collusion between a majority participants or compromising the majority of validator nodes can result in a compromised blockchain. Permissioned blockchains have shown promise for multiple parties focused on eliminating issues of trust within their network using a transparent ledger supporting inter-party transactions. Permissioned and private blockchains afford greater privacy and transaction throughput with fewer validator and participating nodes, at the cost of security and potentially immutability.\nPublic blockchains, like the Bitcoin and Ethereum® platforms, allow anyone with a computer and internet connection to participate by downloading the necessary client software to run a node, regardless of whether they choose to actively conduct transactions or act as a validator. Public blockchains offer the greatest degree of decentralization, security, and likelihood of a ledger remaining immutable, at the cost of lower throughput, greater overhead in the form of transaction fees (typically paid to nodes that secure the network and confirm transactions), and lack of substantial privacy controls. These limitations make public blockchains a more difficult proposition for organizations from a data security/anonymity standpoint, though some interesting breakthroughs on are on the horizon in this regard.\nAs with the internet, which evolved from smaller networks or intranets, it is likely that many participants will initially gravitate towards private or permissioned blockchain technology. As the technology matures and new applications beyond cryptocurrency gain traction, the advantages of public blockchains will help advance their use.\nOkay, but HOW does it work?\nThe general concept of blockchain technology is that it represents a distributed, decentralized ledger that is secured cryptographically and, except under rare circumstances, immutable. The following figure outlines the processes occurring on a public blockchain from transaction origination to confirmation.\nBlockchain can be perceived as a key for a specific lock on a specific door, rather than a master key for doorway. There are additional nuances with various blockchain protocols and applications in addition to distinctions between public, permissioned, and private blockchains. These differences result in potential trade-offs and should be assessed by any organization considering the application of blockchain to their business.\nWhen should I consider blockchain?\nUltimately, blockchain technology brings a new and potentially game-changing solution to help address traditionally challenging issues of trust and the secure exchange of information in many multi-party transactional processes. In the context of health care, whether it’s health records and registries, claims processing, aid disbursement, or provenance in supply chain or chain of custody, blockchain can help close the trust gap through trustless, mathematically verifiable transactions, the elimination of intermediaries in a decentralized peer-to-peer network, and automation of conditional agreements.\nThe advent of more advanced blockchain platforms such as Ethereum® and Hyperledger™ (which comprises multiple blockchain technologies) offer the capability to incorporate logic-based, conditional agreements commonly referred to as “smart contracts” which can support the automation of transactions based on coded conditions and logic. This capability greatly expands the potential use cases for blockchain beyond peer-to-peer payments and simple value transactions to more ambitious applications built on an “Internet of Agreement” such as:\n- Blockchain enabled crowdfunding;\n- Supply chain management and other provenance-based use cases;\n- Identity verification, management, and eventually, self-sovereign identity;\n- Registries (Birth, Death, Land, Voting, etc.);\n- Asset management (tokenizing physical assets on the blockchain);\n- Decentralized data storage and dissemination;\n- Unique incentive programs for cross-market use; and,\n- Many more… it’s likely the best use cases have not even been thought of yet!\nThese use cases show exciting potential as blockchain technology matures at a rapid pace. Bitcoin, the oldest blockchain, has been around for eight years but has only gained widespread use in the past year. Other blockchain platforms such as Ethereum® and Hyperledger’s suite of solutions face a number of challenges - from scalability and access (most of the public blockchains have not achieved widespread use and scalability), to security and privacy protection, the technology and processes underlying blockchain are rapidly evolving and will take time to mature which makes a strong case for small scale projects and piloting proof of concepts.Whatever its ultimate use, blockchain technology can no longer be ignored by the federal, commercial, and non-profit health care sectors which rely upon the secure exchange of highly sensitive information. Stakeholders in the health care ecosystem are starting to get their feet wet with blockchain. Collaborations abound and an increasing interest in small projects and pilot initiatives to allow organizations test the technology – and their risk tolerance. While prudence is necessary, the significant potential advantages of blockchain technology present an incredible opportunity for early adopters in health care.\nPlease stay tuned for our second blog post which will further explore specific applications of blockchain and expand on the future potential for this exciting technology in research, clinical, and public health.","Medical records have traditionally been the exclusive domain of doctors. Recent years have allowed patients to request access to data held about them, including their health files, and to exercise certain rights over this information. These new paradigms in ownership as well as access to personal data in an increasingly technological world have drawn attention to how healthcare records are managed. Further, after a number of information breaches across several fields, attention is increasingly directed at how information can be safeguarded from hackers seeking to profit from personal data.\nTraditional medical record systems lack mechanisms for patient control over data. Those which are electronic typically lack interoperability - they are disconnected from like-for-like systems at nearby hospitals and healthcare providers. This is a major concern in Britain, as it leads to clinical and administrative errors, as well as confusion and inconvenience for patients in the wake of the resulting inefficiency, in lacking an appropriate mechanism to transfer data which has already been recorded. Crucially, it can prevent vital information from being available at critical moments in a patient’s care. Our paper describes how Blockchain can overcome hurdles including interoperability and data privacy and security faced by legacy medical record systems.\nWhat is Blockchain?\nBlockchain decentralises the storage of data. Every time a piece of information is added to the chain of records, the chain is updated in all of the systems (‘nodes’) that make up that Blockchain network. The data stored in each of these nodes can be compared to each other in order to validate the data. Cryptographic validity mechanisms ensure that only one ‘correct’ chain of records is stored across the system, and requires that in order for a change to a record to be made, a majority of the network’s nodes need to agree to that change. This has traditionally been useful in the context of bank transaction ledgers, and is now making its way into the realm of medical records, which require similar integrity.\nWhy is Blockchain so useful in Healthcare?\nDecentralised systems are more difficult to compromise, because they use public-key cryptography to secure data. Further, as Blockchain preserves information in its original form on many different nodes, it creates an immutable record of the truth. Systems can also be set up to control and audit access to data: ‘smart contracts’ streamline the medical consent process together with consent for data access.\nIn addition to enabling immutability, the decentralised nature of Blockchain means that any healthcare provider part of such a network could add data to a patient’s record, and access their other data with consent. Patients often visit several doctors in different hospitals. Having a complete medical history would save doctors precious time.\nHow do we implement Blockchain into the Healthcare System?\nImplementing Blockchain would necessarily mean a shifting control of data from the government to patients, whether directly, or via an intermediary data-managing company. Exacted well, it would operate in accordance with GDPR, assimilate past data, and be user friendly enough to encourage adoption. Interoperability would reduce financial costs, administrative delays, and errors. Improved consent processes and data security would create and maintain patient trust in the system, allowing for the versatile data collected to be exploited in order to advance personalised care in clinical research."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:57dae13f-bc5c-40f8-b65e-8f1899092c1b>","<urn:uuid:4738ef03-11ce-4f56-80a7-c8519e3174e8>"],"error":null}
{"question":"How do townhouses differ when they're part of a condominium versus when they're individually owned?","answer":"Townhouses can exist under different ownership structures. When individually owned as real estate, a townhouse is a house connected on at least one side to another house with independent sidewalls. However, when part of a condominium arrangement, townhouse-style units may share walls or roofs as part of a single structure, while still having individual ground floor entries, back patios or yards, and different faces and rooflines. The key distinction is that in a condominium townhouse, the owner only owns the interior space while sharing ownership of common areas with other unit owners.","context":["GLOSSARY OF TERMS\nAcceleration Clause: Clause in a note or deed of trust which \"accelerates\" or hastens the time when the balance owed becomes due immediately upon the sale of the land or when payment is overdue.\nAmortization: The reduction of a loan by equal installment payments over a given period of time.\nAppreciation: The increase in value such as the increase in value of real property.\nAssessed Value: Value placed on the real property by the County Tax Assessor for tax purposes only.\nClosing Costs: The costs to the buyer or seller, or both, for loan fees, escrow fees, title insurance policies and transfer of ownership charges.\nClose of Escrow: The final procedure in which documents are executed and recorded by the County Recorder.\nCondominium: A structure of 2 or more units, the interior space of which is individually owned, the balance of the property (including land and buildings) is owned in common by the owners of the individual Units.\nCooperative Apartment: Also called a co-op. A structure of 2 or more units in which the right to occupy a unit is obtained by the purchase of stock in the corporation which owns the building.\nCounter Offer: An offer (instead of acceptance) in response to an offer.\nDeed: A written document by which the title to the land is conveyed from one entity to another. Commonly recorded at close of escrow.\nDeed of Trust: A written document by which the title to the property is conveyed to a trustee as security for the repayment of a loan.\nDefault: Failure to fulfill a duty or promise, or discharge an obligation such as the nonpayment of installments.\nDocumentary Transfer Tax: A county and city tax on the transfer of real property. The tax may attach whenever the consideration given in a transaction exceeds $100.00, exclusive of remaining liens and encumbrances. The rate of tax is $0.55 per $500.00 of consideration in LA County.\nEarnest Money: This is the deposit money given to the real estate broker or given to the seller by the potential buyer to show that he is serious about buying the property. This money is applied against the down payment but in certain circumstances may be forfeited if the transaction does not go through.\nEasement: A right or interest in the property which entitles the holder thereof to some use, privilege or benefit such as to place pole lines, pipe lines, or driveway, etc.\nEquity: The total value of the property less the mortgage against it.\nExclusive Agent: The one and only real estate broker contracted to sell a property within a given period of time.\nExclusive Listing: An exclusive right in favor of one real estate broker to sell a property within a specified period of time. If the seller sells the property himself within that period, he must pay the broker the regular commission.\nFee Simple: An absolute ownership of land with unrestricted rights of disposing of same.\nForeclosure: A procedure to deprive a person of the right to redeem a mortgage when regular payments have not been kept up. Foreclosure proceedings under a deed of trust with power of sale include the public sale of the property to satisfy the obligation.\nLien: A charge upon the property for the payment of a debt.\nLiquidated Damages: A definite amount of damages, set forth in a contract, to be paid by the party breaching the contract. A predetermined estimate of actual damages from a breach.\nMechanic's Lien: A lien created by statute for the purpose of securing priority of payment for the price or value of work performed and materials furnished in construction or repair of improvements to land, and which attaches to the land as well as the improvements.\nMortgage: A written document by which land is put up as security for the repayment of a loan.\nMultiple Listing Service: Some real estate brokers are members of an association in which they agree to share certain listings and the sale commissions in relations thereto with the other members.\nOffer: A written promise to buy property at a specific price and terms usually submitted on the Real Estate Purchase Contract and Receipt for Deposit. When the seller accepts the offer in writing, a contract is made, providing all essential terms are covered.\nOption to Purchase: The right to buy a property at a given price within a specific period of time.\nPlanned Development Project: It differs from a standard subdivision only in that it has in addition, areas owned and used in common with the other owners of separately owned lots.\nPoints: A one-time charge assessed by the lending institution at the time the loan is made.\nPreliminary Title Report: A report showing the condition of title before a sale or loan transaction. After completion of the transaction, a title insurance policy is issued.\nRealtor: A registered mark which identifies a professional in real estate who subscribes to a strict Code of Ethics as a member of the National Association of Realtors.\nSecond Deed of Trust: When the loan secured by the first deed of trust and the down payment do not add up to the purchase price, a second loan secured by a second deed trust is necessary. It usually carries a higher interest rate and runs for a shorter period of time.\nSet Back Line: Established building line to regulate the distance from the street line at which buildings, structures or improvements may be erected.\nTitle: A right to ownership of real property.\nTitle Insurance: Evidence of title guaranteed by the insurer in the form of a policy of title insurance. It protects buyers and lenders against loss sustained by reason of possible defects in the title to the property or due to unforeseen occurrences.\nTownhouse: Originally a house in a city as opposed to a country estate. More recently the term is applied to certain types of row houses, whether planned unit developments or condominiums.","Monday, January 29, 2018 / by Sean Zanganeh\nAlthough all are part of the common-interest housing category, condos, co-ops, townhouses, and apartments may mean different things to different buyers, so here is a breakdown of what each word means and the advantages or disadvantages of one over another for the homebuyer.\nFirst, let’s get the low-down on what makes up the common-interest housing real estate category. Common-interest housing is composed of areas owned individually and areas shared by all owners. The shared or common areas typically include landscaping, pools, parking, and clubhouses, but may also include exteriors, fences, and roofs of certain types of properties. Any community development that has shared property, including individually separate homes in developments with shared playgrounds and pools, falls into this category. Often, a management service or homeowners’ association manages the common areas.\nSpecifically, a condo—or more properly, a condominium—is a single housing unit within the shared property owned by the homeowner. This may be a unit in a tower building (also called an apartment) or a conjoined house with its own ground floor exterior entry (often called a townhouse, although a townhouse is not always a condominium), a single family home or a mobile home in a planned community. The term “condominium” is a legal term in the United States and so is governed by laws of real estate ownership.\nIn a condominium-style common-interest development (CID), the homeowner owns the interior space of the property independent of the other units and may buy or sell the real estate property as the sole owner of that specific unit.\nA co-op—or cooperative housing development—differs in that “owners” own shares in the corporation that owns the real estate development rather than owning an actual unit. Each shareholder has a vote in the real estate corporation and share ownership authorizes the occupancy of a specific unit. Typically, shareholders pay a “share” of the monthly expenses of the real estate corporation. As with a condominium, cooperatives may be apartment-style units in a single building, townhomes or patio homes, single family homes, or even mobile homes. The legal term “cooperative” refers to the real estate ownership structure rather than the property type.\nSo, what is an apartment? Or a townhouse?\nA townhome is a style of house connected on at least one side of the structure to another house. It may be individually owned real estate or part of a CID. A true townhome will have independent sidewalls even though they may touch the walls of another townhome. That being said, many condominium, cooperative, and rental unit designs mimic townhomes, with individual groundfloor entries, back patios or yards, and even differing faces and rooflines. These units may share a wall or roof, however, as part of a single structure.\nAn apartment is another matter. In common usage, “apartment” is a rental unit rather than privately owned real estate. The person occupying the unit does not own it, but leases it from the owner of the entire real estate development. But in legal terms, an apartment is a part of a residential structure occupied by one housing unit (family, roommates, etc.). An apartment, then, can be a rental, but it may also be a condominium unit (homeowner owns the interior space and shares the other spaces) or a cooperative unit (owner owns shares of the entire development equal to the unit being occupied).\nConsult your real estate professional to see which type of CID is the best fit for your circumstances in your local real estate market."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:1de5ac57-9122-48e4-bc53-29d76ad2ce88>","<urn:uuid:47b5e5ef-11a7-4dba-9b66-ea2d13114da9>"],"error":null}
{"question":"在Primary Stroke Center认证方面，BCH和Firelands Regional Medical Center有什么相似和不同之处？请比较。","answer":"Both hospitals are certified as Primary Stroke Centers, but through different accrediting bodies. Boulder Community Health (BCH) received its Advanced Certification as a Primary Stroke Center from The Joint Commission in conjunction with the American Heart Association/American Stroke Association. Meanwhile, Firelands Regional Medical Center received its Primary Stroke Center certification from the Healthcare Facilities Accreditation Program (HFAP). Both centers provide emergency stroke treatment and comprehensive care, including rehabilitation services. However, Firelands has specifically been certified since 2007 and includes TeleStroke technology in their care options, while BCH uniquely features a Stroke Alert system where paramedics can alert the stroke care team while en route.","context":["Boulder Community Health has an outstanding team of physicians, nurses, rehabilitation specialists and other clinical professionals who work together to provide the best possible care for our stroke patients. Our program has been awarded Advanced Certification as a Primary Stroke Center by The Joint Commission (the nation’s largest standards-setting and accrediting body in health care), in conjunction with the American Heart Association/American Stroke Association.\nBCH has one of only five Colorado hospitals north of Denver that have been designated as Primary Stroke Centers. In order to achieve this designation, Boulder Community voluntarily underwent a rigorous on-site review of our stroke program’s clinical practice guidelines and performance measurement activities.\nWe are also a proud recipient of the Get With The Guidelines®-Stroke Gold-Plus Quality Achievement Award, a quality improvement program created by the American Heart Association/American Stroke Association. Our stroke program was recognized for implementing specific quality improvement measures for the rapid diagnosis and treatment of stroke patients. These measures include aggressive use of medications and risk-reduction therapies aimed at reducing death and disability and improving the lives of stroke patients.\nFull range of services\nThe comprehensive stroke program at BCH incorporates the entire continuum of care for stroke patients, from emergency treatment and advanced diagnostic technology to both acute and critical inpatient treatments and extensive rehabilitation services.\nAdditional vital components of the program include:\n- Direct contact with neurologists - all patients arriving at the Foothills Hospital Emergency Department who show signs or symptoms of stroke will have a consultation with a neurologist without having to wait to be admitted to the hospital.\n- Expedited care through life-saving Stroke Alert protocol – BCH utilizes a Stroke Alert system in which in-field paramedics directly alert the BCH stroke care team while en route to the hospital, enabling immediate treatment for the patient upon arrival.\n- Easy access to an extensive support network – BCH holds free, monthly support group meetings for stroke patients.\nStroke Treatment at Foothills Hospital\nMany treatments can reverse symptoms or limit the damage caused by stroke if administered within a few hours of the symptoms starting. Faster diagnosis and treatment also mean rehabilitation can be started sooner, which can reduce the severity of stroke-related damage.\nWith our team approach to stroke treatment, care begins while you are being transported to the hospital by ambulance. The Emergency Department is alerted so that appropriate medical personnel and diagnostic equipment are ready upon your arrival.\nPhysicians can then quickly determine if you are having an ischemic brain attack. An ischemic brain attack is a stroke resulting from a blocked artery in your brain caused by a clot or by damage from high blood pressure or diabetes. If so, the clot-dissolving drug t-PA can be administered within three hours from the onset of the stroke to help restore blood flow to the brain and improve your overall chance of recovery.\nIt is likely you will have a CT scan and other tests to confirm the possible diagnosis of the stroke and provide doctors with information about the exact location and type of stroke.\nA neurologist, a physician who specializes in treating strokes, will review all your test results, and confer with your personal physician if possible. If you have suffered a cerebral hemorrhage (arteries leading to the brain burst and blood floods the brain tissue) and surgery is needed, a skilled neurosurgeon will be called to provide that care.\nDuring your hospital stay, a neurologist will work with your doctor to direct your care. Our nurses—from the Emergency Department through the Intensive Care Unit and general nursing units—have received extra stroke care education.\nAfter a stroke, many people have some disability. Rehabilitation is an important part of recovery, restoring functions lost from the stroke. Our rehabilitation teams work to retrain and educate you on how to walk, eat, dress, bathe and complete personal care. They also provide help so you can return to work and relearn how to manage your daily activities.\nThe hospital provides both inpatient and outpatient care, especially important for those who have been partially paralyzed or whose speech or thought processes have been affected by a stroke.\nFor more information regarding inpatient rehabilitation for stroke, contact us at (303) 440-2250. For more information regarding outpatient rehabilitation, contact us at (303) 441-0493.\nInpatient Rehabilitation Services\nOutpatient Rehabilitation Services\nOur HomeCare agency provides nursing care, physical therapy, speech therapy and occupational therapy in your home so that you may continue your progress over longer periods of time.\nBCH holds free, monthly support group meetings for stroke patients.\nReturn to Top","Quality Measures & Performance Improvement\nQuality measures are available to allow Firelands Regional Medical Center to compare itself with industry leaders and identify opportunities upon which to focus resources and efforts for improvement. Such comparisons can also help consumers choose resources for their healthcare based on quality processes and outcomes. When choosing Firelands, you can do so with confidence.\nSignificant Accreditations, Certifications, and Recognitions\n- American Academy of Sleep Medicine (AASM) -- sets standards and promotes excellence in sleep medicine health care, education and research. The AASM accredits both sleep disorder centers and home sleep apnea testing programs.\n- American College of Cardiology (ACC) -- a nonprofit medical society dedicated to enhancing the lives of cardiovascular patients through continuous quality improvement, patient-centered care, payment innovation and professionalism.\n- American College of Radiology (ACR) -- a professional medical society dedicated to serving patients and society by empowering radiology professionals to advance the practice, science and professions of radiological care.\n- American College of Surgeons (ACS) Commission on Cancer -- benefits an array of health care professionals, patients, and facilities through standard-setting, accreditation, and educational activities. The Commission on Cancer develops educational resources, offers useful training opportunities, and stays up to date on the latest cancer care trends and treatments.\n- American College of Surgeons (ACS) Verified Level III Trauma Center -- verifies processes and resources are in place to provide optimal care to the injured patient.\n- American Diabetes Association -- works to prevent and cure diabetes and to improve the lives of all people affected by diabetes. Each year, the American Diabetes Association recognizes and honors individuals who have met the National Standards for Diabetes Self-Management Education (DSME) which are designed to define quality diabetes self-management education that can be implemented in diverse settings and will facilitate improvement in health care outcomes.\n- College of American Pathologists (CAP) -- the leading organization of board-certified pathologists and serves patients, pathologists and the public by fostering and advocating excellence in the practice of pathology and laboratory medicine worldwide.\n- Commission on Accreditation of Rehabilitation (CARF) -- an independent, nonprofit accreditor of human service providers in the areas of aging services, behavioral health, child and youth services, DMEPOS, employment and community services, and medical rehabilitation.\n- Healthcare Facilities Accreditation Program (HFAP) -- authorized by the Centers for Medicare and Medicaid Services (CMS) to survey all hospitals for compliance with the Medicare Conditions of Participation and Coverage.\n- Intersocietal Accreditation Commission (IAC) -- develops standards and methods for evaluation of the quality of care delivered. The IAC provides accreditation programs for vascular testing, echocardiography, nuclear/PET, MRI, diagnostic CT, dental CT, carotid stenting, vein treatment and management and cardiac electrophysiology.\n- National League of Nursing Accrediting Commission -- Accreditation Commission for Education in Nursing (ACEN) is the entity that is responsible for the specialized accreditation of nursing education programs, both postsecondary and higher degree, which offer either a certificate, a diploma, or a recognized professional degree (clinical doctorate, master’s/post-master’s certificate, baccalaureate, associate, diploma, and practical).\n- Primary Stroke Center -- from the Healthcare Facilities Accreditation Program (HFAP), an independent, nationally-recognized accreditation authority. This Primary Stroke Certifications shows that Firelands has the capacity to stabilize and treat acute stroke patients, provide acute care and administer tPA and other acute therapies safely and efficiently. Firelands has been certified as a Primary Stroke Center since 2007. The stroke care provided at Firelands includes emergency care, including TeleStroke technology, diagnostic care, physicians specializing in stroke care, comprehensive rehabilitation and services to assist patients in recovery from stroke.\nIf you have questions about quality measures or would like help in looking at this publicly reported information, please contact the quality and patient satisfaction department at 419-557-6817."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:289ad28a-ef9d-4155-98d7-70edadadfa5b>","<urn:uuid:6e48f2eb-982a-4e5b-bcf8-30a4de55e3db>"],"error":null}
{"question":"How do Russian and U.S. private military contractors differ in terms of their relationship with government forces?","answer":"Russian PMCs like Wagner operate in close coordination with official military forces, effectively serving as a fifth branch of their armed forces, with training occurring at government facilities like the GRU base in Molokino. They act in concert with regular forces, as seen in operations like the recapture of Palmyra in 2016. In contrast, U.S. contractors, while also integrated with military operations, maintain a more distinct separation, though they perform tasks that were previously done by uniformed personnel. The U.S. government has notably distanced itself from contractor casualties, while Russia has evolved to partially legalize and incorporate PMCs into their military strategy, particularly in hybrid warfare operations.","context":["By Kiril Avramov and Ruslan Trad\nLife comes at you fast.\nOne minute in 2015 Kiril Shadrin was a loyal Russian infantryman; the next, he was a ‘volunteer’ in the Donbass; and then in 2017 he suddenly left for Syria, where he re-emerged as a member of a Syrian paramilitary pro-government organization under the supervision of the Syrian Department of General Intelligence. In conflicts across the world, there are now many Kirils – Russian soldiers occupying a grey zone between serviceman, mercenary and spook.\nRegardless of the Kremlin’s official denial of their existence, the presence of such personnel becomes painfully evident as incidents unfold in the prolonged and bloody Syrian conflict. There, Russia is experimenting with hybrid proxy warfare, blurring the lines between official foreign policy and private groups, Russian action and that of independent parties. It is already including what it has learned in its playbook for gray zone conflict.\n— ISIS Hunters (@ISIS_Hunters) September 18, 2017\nAs the armed conflict in Syria transformed from a full-blown civil war to a brutal proxy war, the main actors involved began to experiment with hybrid approaches to proxy warfare. Russia has taken advantage of the chaos on the ground to test combining official, direct military involvement with opaque private military companies (PMCs). Syria has proven to be an excellent laboratory for testing the operational potential and “deniability” of a mix of official and unofficial efforts.\nAs Russia is a relative newcomer at using PMCs abroad for deniability and force augmentation, the results of this “cooperation” are likely to have a deep impact both in Syria and elsewhere. This experiment has strategic, tactical and legal implications both on the battlefield and abroad, for Russia and for the potential targets of hybridized proxy war.\nShifting Russian attitudes towards PMCs\nWhile mercenary activity has a long history in Russia, the use of modern PMCs is a new and novel development, emerging both from internal political and public pressure, and legal and strategic concerns. Prior to 2014, mercenary activity was suppressed by the various state security organs, due to fears of rivalry between the official security apparatus and the PMCs, the loss of supervision and control over PMC activities, and a possible competition over state funding.\nHowever, the expansionist appetite of Russian foreign policy in the Middle East and military involvement abroad in general, coupled with lobbying pressure from oil and gas sector operators, created a situation where the legal void needed to be filled even by partial means. But another driving factor was the Kremlin’s evolving understanding of PMCs’ flexibility and deployability in the course of hybrid warfare.\nAfter a bill legalizing PMCs failed in 2014, amendments to the federal law concerning conscription and military service rapidly passed in 2016. The new bill struck a tricky balance, legalizing the Russian PMCs’ personnel operating abroad without necessarily settling the legality of the PMCs themselves, as the amendments allow for “participation in activities to maintain or restore international peace and security” (limited to a year) and “suppression of international terrorist activities outside the territory of the Russian Federation.”\nThis shift in the official Russian administration’s attitude towards contractors resulted from several different factors, namely President Vladimir Putin’s desire for more flexible military policy options, domestic economic interests (of both the PMCs themselves and their customers), and the relative ease and efficiency of modernizing private-sector units, compared to Russia’s troubled military modernization project. Providing legal cover for PMCs also gives Russian authorities more latitude to spin information for the public and generally to reduce domestic pressure in crises involving captured soldiers and casualties.\nOut of the post-Soviet chaos …\nIn the past several years dozens of Russian PMCs have popped up, many of them short-lived. When a PMC goes defunct, its personnel often splinter into new groups and proliferate, as in the case of Tigr Top-Rent Security that was established in 2005 and went defunct the very next year.\nIn Ukraine, PMC personnel (a large portion of them ex-military) can be easily traced in groups such as RSB-Group, E.N.O.T Corp. and Moran Security Group. Members of these groups are often veterans of Russian efforts in Yugoslavia, the Caucasus, Iraq and Afghanistan, and they have been spotted not only in Ukraine but also in Syria. These groups, born in the chaos of the post-Soviet transition and early Russian efforts abroad, were the early beginnings of a Russian PMC foreign business outreach.\nThroughout the 2000s, Russian entities such as Tigr Top-Rent Security and Redut-Antiterror have used Iraq, Afghanistan and certain African countries to test the waters of the modern PMC business. Some of the more established PMCs (alongside other Russian militias) used Eastern Ukraine as a training ground before deployment to Syria. Volunteers from the so-called Novorossiya with close connections to Russian PMCs were tested in Ukraine before moving on to Syria.\nResults of these early efforts were mixed, as can been seen in the stories of two of the most notorious PMCs: The Slavonic Corps and Wagner. The so-called Slavonic Corps, a 267-strong unit founded under the auspices of Moran Security Group’s head – Vyacheslav Kalashnikov, a lieutenant colonel in the Federal Security Service (FSB) reserves – was sent to Syria after signing a contract with the government and began to provide security for key Syrian energy sites. As it turned out upon arrival in Syria, the Corps were probably contracted by a local kingpin, possibly on direct orders from Bashar al-Assad’s government, and were used as an offensive force to recapture the very oil fields that they were supposed to guard.\nTheir story – while one of utter fiasco, as they were inadequately equipped, poorly managed and able to execute only a single ill-fated combat operation – still illustrates the dynamics and direction of Russian efforts.\nPMC Wagner and the ISIS Hunters\nWhereas the Slavonic Corps met disaster, Wagner – started by a former lieutenant colonel of the 2nd Spetznaz (Special Forces) Brigade of the Russian Main Intelligence Directorate (GRU) who was working for Moran and then the Corps – began as a small contractor but is now effectively a private army. Wagner makes heavy use of mercenaries and probably has about 2,500 people distributed in different operational units that provide security for key Syrian infrastructure and energy sites.\nPrior to their departure to Syria, the new Wagner recruits were trained at the base of the Main Intelligence Directorate (GRU) 10th Special Mission’s brigade in Molokino, near the southern Russian city of Krasnodar. Publicly, their designation was solely security provision, however as it became evident in 2018, for the past two years, the company has been very actively involved in training, intelligence collection and forward operations on behalf of Assad’s army. On paper, no official links between the Russian forces in Syria and Wagner exist. In essence the Wagner personnel are actively augmenting the Russian troops on the ground in execution of their “special tasks.”\nCase in point would be the successful recapture of Palmyra 2016, where Wagner personnel augmented the advance of regular troops. One might argue that the active engagement of Wagner in the Middle East is suspiciously coincidental with the mass deployment of Russian armed forces in Syria in 2015, thus advancing the idea that Wagner is a thin cover for the special operations units of the regular armed forces.\nIf not an integral part of the armed forces, then certainly the two entities act in concert, where Wagner is carefully curated by elements of GRU and FSB.\nWhile early Russian PMCs began outside of Syria and bear some resemblance to Western contractors, Russia’s efforts in Syria have spawned units tailored to fighting in the Middle East, such as the “ISIS Hunters” that serve as valuable asset on the propaganda and psychological warfare front at home and for designated foreign audiences.\nThe Hunters (a spinoff of circles close to Wagner) were used in Russian propaganda efforts at home and in the West. The unit gained visibility in March 2017, when information on a special unit augmenting the Syrian government forces and with a particular focus on operations against ISIS has appeared in Russian media. It was quickly replicated by media outlets tightly connected with Russian propaganda abroad known to reproduce and spread “controlled leaks” in “target countries,” such as Bulgaria, designated for disinformation offensives.\nAlthough the Hunters strive to portray themselves as a local phenomenon, they never managed to get rid of the halo of a Russian creation, and probably because of this, their popularity does not extend beyond the Russian media and certain Western outlets sympathetic to Russian concerns. However, the ISIS Hunters do have an additional function that is far from being portrayed as “the scourge of ISIS.”\nOne of their main tasks is security provision for the Syrian army’s strategic sites, such as gas and oil fields, overlapping with Euro Polis, a company connected to a close Putin confidant. While the details regarding the Syrian contracts of Euro Polis are protected as a commercial secret, it is clear that the ISIS Hunters are an important part of the company’s activities, as the company is linked business moguls close to Wagner. These in turn are connected directly to the Russian government and personally to Putin.\nA tested model to export\nSyria has proved to be the perfect application of a hybrid military-PMC deployment model, and it is now ready to be exported elsewhere. Russia’s deployments of its own forces abroad operating alongside PMCs are on the rise. This suggests that the hybrid operational concept has moved beyond the experimental phase and is ready for wider export outside Syria, perhaps to Libya, Egypt and possibly Sudan, where there are specific Russian geopolitical and security interests connected to the former Soviet security presence in the Middle East and Africa.\nThe footprint of Russian PMCs in Syria is significant and has demonstrated the capacity of the Kremlin to apply military pressure abroad without officially deploying regular troops. PMCs give the Kremlin a way to limit its exposure to domestic pressures while still applying force abroad. The case of Kiril Shadrin – the soldier turned paramilitary contractor – is illustrative of probably hundreds of Russian citizens and citizens of Central Asian countries who have participated in operations in Syria.\nThe widely-publicized capture of Roman Vasilievich Zabolotny and Grigorii Mihailovich Surkanov by ISIS sheds additional light on the interaction between the Russian Armed Forces and Russian PMCs abroad, where the boundary between public and private becomes blurred in the name of claiming official armed forces operational successes, while reducing the body count via PMCs.\nAs Putin triumphantly announced Russia’s withdrawal from Syria for the third time, it is obvious that Russia has no real intention to abandon the region. Certain elements of the regular Russian forces may now be withdrawing, but Russian PMCs in Syria and other locations in the Middle East and Africa are in for the long haul.\nDr. Kiril Avramov is a post-doctoral fellow at the Intelligence Studies Project at the University of Texas at Austin. He is an Assistant Professor of Political Science at the Department of Political Science and former Vice-Rector of the New Bulgarian University in Sofia and a former Senior Fulbright Visiting Researcher at CREEES, UT Austin, Texas.\nYou can follow him on Twitter: @avramovok.\nRuslan Trad is a freelance journalist and analyst with over ten years’ experience covering and analysis of MENA, Balkans and Turkey regional issues; co-founder of De Re Militari Journal; and author of the book “The Murder of a Revolution” (2017).\nYou can follow him on Twitter: @ruslantrad.\nAll views and opinions expressed in this article are those of the authors, and do not necessarily reflect the opinions or positions of The Defense Post.\nThe Defense Post aims to publish a wide range of high-quality opinion and analysis from a diverse array of people – do you want to send us yours? Click here to submit an Op-Ed.","Someday historians will doubtlessly try to compile a top ten or dirty dozen list of the saddest and most contemptible aspects of U.S. wars in Afghanistan and Iraq. I hope that when they get around to it they will deal with the costs of those wars.\nNo, contrary, to what you are thinking, I am not talking about the economic costs of those conflicts, about which there has been a torrent of commentary since the release of the final report of the Commission on Wartime Contracting in Iraq and Afghanistan (CWC).\nThe cost I am talking about is much more basic and far more unsettling, given what it says about the U.S. government. That is the cost in terms of the number of private military and security contractors (PMSC) killed in the course of fulfilling their contracts and whose deaths has been almost entirely ignored. To its credit the Commission did mention it but it was a rare exception.\nI know what some people are saying, that contractors weren't part of regular military forces and thus don't merit acknowledgement or that they were only in it for the money. The first part of such reasoning ignores the fact that for all practical, de facto, if not de jure, purposes, PMSC are now so tightly integrated with regular military forces, that they are a fifth branch of the Department of Defense.\nEven the Pentagon's own planning documents such as the Pentagon's Quadrennial Defense Review acknowledge that \"The services provided by contractors will continue to be valued as part of a balanced approach that properly considers both mission requirements and overall return.\"\nThe second part of the reasoning ignores the fact that most people in the military are not doing it for free. Like contractors they get also paid. If you think soldiers, marines, sailors and airmen are indifferent to issues of compensation and benefits just pick up any issue of Stars and Stripes and see the articles regarding Tricare, pension, or GI Bill benefits.\nWith regard to governmental policy towards acknowledging the ultimate sacrifice by private contractors it sometimes appears that the U.S. government is channeling various dictatorships that have disappeared their own citizens.\nTrue, the U.S. and other governments who employ PMSC in Iraq and Afghanistan haven't actually murdered any contractors, with the corpse disposed of in such a way as to prevent it ever being found, so that the person apparently vanishes. And yes, their bodies are returned to their loved ones and mourned, at least in their hometowns. The companies that employed them will note their deaths, and their dependents, at least if those killed were American, will get the benefits due them under the Defense Base Act.\nBut aside from that they are like the disappeared ones; vanished with almost no public acknowledgement of their contributions and treated like so much disposable trash. You will never see the PBS NewsHour listing any contractor among the periodic listings of those killed in Iraq or Afghanistan. Regardless of what you think of the utility of using PMSC such an attitude is just plain morally wrong. It is akin to what a prosecutor would call \"depraved indifference.\"\nBut from a coldblooded policymaking perspective this makes sense. To better understand what I mean consider the public forum the CWC held this past May 2. One of the witnesses was Steve Schooner, a professor of Government Contract Law at the George Washington University and co-director of the Government Procurement Law program. He is one of the few scholars who have studied this issue in detail. In the then forthcoming journal article, Dead Contractors: The Un-Examined Effect of Surrogates on the Public's Casualty Sensitivity he wrote:\nIn the modern era, most studies suggest that \"majorities of considered the potential and actual casualties in U.S. wars and military operations to be an important factor in their support.\"6 Specifically, an inverse relationship exists between the number of military deaths and public support.7 Economists have dubbed this the \"casualty sensitivity\" effect.8\nThis article asserts that this stark and monolithic metric requires re-examination in light of a little-known phenomenon: on the modern battlefield, contractor personnel are dying at rates similar to--and at times in excess of--soldiers. The increased risk to contractors' health and well-being logically follows the expanded role of contractors in modern governance and defense. The post-millennial U.S. military--like the modern U.S. government--is more heterogeneous than ever before. The military is populated by a \"blended workforce\" that integrates soldiers with private-sector contractor employees--comprised of both U.S. citizens and, to a large extent, foreign nationals--in every conceivable aspect of the mission abroad. Not surprisingly, one result of this integration is that contractors are dying alongside--or in the place of--soldiers at unprecedented and (arguably) alarming rates. For the most part, this \"substitution\" has taken place outside of the cognizance of the public and, potentially, Congress.9\nIn other words, the unacknowledged contractor death means a lower casualty sensitivity effect and thus it is easier to go to and stay at war.\nAs Schooner said during his testimony:\nWhat you said is, \"These contractors' deaths and injuries should not be ignored, but should be part of the public debate on the cost of war.\" That is one of the most responsible and transparent statements that anyone in the United States federal government has made in the last decade on this topic.\nMore than anything else, the reason I want to encourage you to do more about this is the president of the United States, the United States Congress, individually and collectively, and almost all senior officials in our related agencies have refused to address this issue publicly, and I think it's tremendously important.\nIn the mid-1990s, I started submitting FOIA requests to attempt to get more information. And the only agency that had any information on this at all, interestingly enough, was the Department of Labor. Because of the Defense Base Act insurance program, the Department of Labor collects information on contractors who have been injured or killed supporting the government.\nAnd they collect the data mostly so that they can report lost working hours, basically an FTE equivalent. So they keep track of how many days the employees miss and then how many days the contractors miss. But that's based on Defense Base Act insurance claims.\nSo I collected a bunch of information to the Freedom of Information Act, and lo and behold, the numbers were staggering. Since the early 2000s to then -- I believe the article came out in 2008 -- the numbers climbed to the point where, literally, contractors were representing one out of every four deaths.\nSo one out of every four people who came home from Iraq and Afghanistan in a bag or a box was a contractor, but nobody would talk about it. The newspapers wouldn't report on it. No newspaper larger than Houston Chronicle would publish anything on it.\nThe president wouldn't talk about it. The members of Congress wouldn't talk about it. And DOD wouldn't even acknowledge that they were responsible for keeping track of the contractors that were dying in their battle space.\nThe point to keep in mind is that just because a contractor isn't engaging in offensive combat doesn't mean they aren't doing military work. Schooner noted:\nBut the point here -- and the reason I used the term \"surrogates\" is, these contractors are performing tasks that a generation ago would've been performed by somebody in uniform. Most people agree that the most dangerous job in Iraq and Afghanistan is being behind the wheel of a truck, delivering anything.\nIt's being behind that windshield and catching the shrapnel when the IED goes off. But it wasn't so long ago that people in uniform were driving those trucks.\nOr, to parse the data a different and more fundamental way:\nWhat I want you to focus on is that since 2009, I can't make this any more simple -- more contractors have died in Iraq than members of the military.\n2009, 2010, first quarter of 2011, more contractors have died in Iraq than members of the military. All right, the scary thing, if you jump over to figures 9 and 10, over on page 50, we're seeing the same trend line basically happening in Afghanistan as well.\nWe haven't actually tipped over as much, but what you see is, as these conflicts evolve, we're reducing members of the military and we're exposing contractors much more aggressively to the fatalities.\nIf you thought I was a little over the top when I wrote earlier that PMSC are treated like so much disposable trash consider this bit from Schooner's Q&A:\nI'm not accusing the Defense Department of affirmatively putting contractors in harm's way as surrogates for the military, OK? But frankly, the data might suggest that that is in fact what's happening.\nI'm not accusing anyone individually. But let's take this at different layers. The military has a pretty good idea of what the dangerous jobs are.\nOne interesting decision early on, for example -- we talked about this in the paper -- is when body armor was first becoming a huge issue in the Congress. Body armor was mandated for members of the military. But frankly, the military was a little slow to mandate the same body armor for the contractors.\nWhile, for a variety of reasons, I have frequently been critical of PMS use as a policy I am absolutely disgusted by the way their ultimate sacrifice has been airbrushed out of the official record. At a minimum the number of contractors wounded and killed in Iraq and Afghanistan should be included in all future tallies of the human costs of the Afghanistan and Iraq wars, as well as other U.S. military operations.\nFollow David Isenberg on Twitter: www.twitter.com/vanidan"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:262c54c8-6c82-4436-946d-a0ca346ffc8d>","<urn:uuid:2efa51a4-fd05-4b17-9dc4-61816f373276>"],"error":null}
{"question":"As a law student studying criminal cases - what's considered an unlawful killing in English law, and what employment documentation practices are considered unlawful in US immigration law?","answer":"In English law, unlawful killing is a verdict that can be returned by an inquest when someone has been killed by unknown persons without lawful excuse and in breach of criminal law. This includes murder, manslaughter, infanticide and death by dangerous driving, and typically leads to a police investigation. Regarding U.S. immigration law, unlawful employment documentation practices include requesting Department of Homeland Security-issued documents while rejecting other valid documents, requesting additional documents only from non-citizens, and reverifying permanent residents' work eligibility when their cards expire. These practices violate the Immigration and Nationality Act and can result in civil penalties, mandatory training requirements, and DOJ monitoring.","context":["Law Of The United States\nSupreme Court discovered some exceptions to treatments out there to undocumented staff for violations of the NLRA. Additionally, a courtroom may grant a protective order towards discovery of citizenship data if such data would damage the undocumented employee (by focusing the matter on citizenship status rather than employment rights and due to this fact stop restoration). Generally, undocumented employees concerned in a labor dispute might not have immigration proceedings introduced towards them – This is because the DOL and ICE have agreed to not intervene with each other. Since all employees regardless of immigration standing are protected by the employment laws of the DOL, ICE, topic to some exceptions, could not start immigration proceedings against an undocumented employee during a labor dispute.\nAlcohol is a think about thousands of automotive accidents and a big proportion of crime. Drinking too much alcohol can lead to dependence and addiction. Using sure medicine that are prescribed for pain can lead to addiction.\nTexas private employers are able to resolve whether or not to present employee’s compensation insurance protection for their employees. Generally, the employer is required to notify the employee of whether or not they supply protection.\nFrom ‘Lawyer’s Lawyer’ To Pop Culture Icon: How Rbg Became Notorious\nThis includes homicide, manslaughter, infanticide and inflicting dying by dangerous driving. A verdict of illegal killing generally leads to a police investigation, with the purpose of gathering adequate evidence to determine, cost and prosecute those accountable.\n- This part provides info on laws, laws, insurance policies, other authorities, and instructive materials and notices, together with links to govt orders, Administrative Appeals Office (AAO) decisions, U.S.\n- Judge An official of the Judicial branch with authority to determine lawsuits introduced before courts.\n- Used generically, the time period decide can also discuss with all judicial officers, including Supreme Court justices.\n- Witness A particular person referred to as upon by either facet in a lawsuit to give testimony earlier than the court or jury.\nAllowing employers to treat undocumented workers in a different way and unfairly encourages violation of the IRCA and disrespect for the law in general. If employers aren’t required by legislation to provide their undocumented workers the same rights guaranteed to work-approved employees, employers will be extra likely to hire undocumented staff and thereby enhance the issue the IRCA is making an attempt to stop. Undocumented employees have a right to affix and organize unions under the NLRA, so the employer was in violation of the legislation.In this case, however, the U.S.\n” This is called the emotive element insofar as I am expressing my feelings about some specific behavior. Second, I (the speaker) am trying to get you to donate to charity and am essentially giving the command, “Donate to charity! ” This known as the prescriptive component in the sense that I am prescribing some particular conduct. When excited about the terminology individuals use to explain medicine, it makes no difference to the people who find themselves affected by addiction or love someone with an dependancy.\nThere are so many the reason why licit and illicit drugs are essential to find out about, not only to grasp the phrases, but in addition to figure out tips on how to help a liked one who needs help. Professional help is on the horizon for individuals who attain out or ask for assist for a loved one. of or referring to stage plays by which musical numbers had been inserted because of legal guidelines that gave only some theaters the exclusive proper to produce straight dramas. In English regulation, illegal killing is a verdict that may be returned by an inquest in England and Wales when someone has been killed by one or several unknown persons. The verdict means that the killing was done without lawful excuse and in breach of legal law.\nAre You A Solo Or Small Firm Attorney? Our Practice Management Center Is For You.\nWhether licit or illicit, medication like nicotine and alcohol may be completely dangerous. More deaths are caused annually by tobacco than HIV, unlawful drug use, alcohol use, suicides, and murders combined.","When Verifying Work Eligibility, Avoid Asking for Too Much\nBy Jacob M. Monty, Monty & Ramirez LLP\nWhile it’s important to verify employees’ work eligibility, be sure you don’t violate their rights under the Immigration and Nationality Act (INA) by asking for too much information. Many employers have reached settlements with the U.S. Department of Justice (DOJ) after violating the Act while attempting to verify work eligibility.\nOverstepping Immigration Law\nThe DOJ recently settled with two employers for violating employees’ rights under the INA. The agency said United General Bakery, Inc., and McDonald’s should not have requested specific and/or additional documents to verify noncitizens’ work eligibility. The actions violated the law because individuals should be treated the same, regardless of their citizenship status.\nThe U.S. Citizenship and Immigration Services (USCIS) sets specific guidelines and lists valid documents individuals may produce to verify their employment eligibility. According to the settlements, both employers:\n- Requested Department of Homeland Security-issued employment eligibility documents while rejecting other documents that were valid under USCIS’s guidelines; and\n- Failed to request similar documents from U.S. citizens.\nUnited General Bakery also routinely requested additional documents from lawful permanent citizens when their permanent resident cards expired. Under those circumstances, an employer can be penalized if employees or the DOJ can show it didn’t similarly reverify documentation for U.S. citizens. Individuals with permanent resident cards are assumed to have continuous authorization to work, so reverifying their eligibility violates the INA.\nThe DOJ found both employers failed to follow USCIS guidelines for verifying employment and engaged in an unfair documentary practice based on citizenship status in violation of the INA. Specifically, they asked only noncitizens to produce additional or certain kinds of paperwork while U.S. citizens could present standard documentation. Both settlements underscore employers’ ongoing struggle to verify work eligibility while complying with the Act.\nThey’re Sorry—Now What?\nUnited General Bakery was hit with a civil penalty of $45,000, while McDonald’s was ordered to pay more—$82,000—likely because more employees were affected. Both employers were required to post the “If You Have the Right to Work” poster about immigrant and employee rights and create or revise their employment policies to:\n- Prohibit discrimination based on citizenship, immigration status, or national origin;\n- Include equal employment opportunity statements; and\n- Explain how to complain about discrimination in the hiring or firing process.\nThe employers may not retaliate against individuals for filing a charge or participating in an investigation or action under the INA. They also must train HR personnel about their obligations under the Act and are subject to DOJ compliance monitoring.\nIn addition, McDonald’s was ordered to pay lost wages plus interest to the complaining individual or anyone who suffered an economic injury because of its work eligibility verification practices. Its HR personnel must complete a training assessment to be sure they understand the proper Form I-9 procedures.\nHow to Protect your Organization\nIt’s important to verify workers’ employment eligibility, but also be sure you aren’t violating their rights under the INA. It’s a fine line, to be certain, but you can start by reviewing your internal policies and procedures to ensure they’re aligned with the law. Here are some additional tips:\n- Provide applicants with the official I-9 list of acceptable documents, and don’t require them to pony up specific paperwork. (The same is true if you’re reverifying an employee’s work authorization.)\n- Treat everyone the same regardless of their citizenship status.\n- Don’t have discriminatory statements on your job postings that favor U.S. citizens; and\n- Train HR personnel on your internal policies and procedures, and make sure they’re properly implementing them. Doing so can help you to avoid potential costly civil penalties and DOJ investigations in the future.\nJacob M. Monty—the managing partner of Monty & Ramirez, LLP and editor of Texas Employment Law Letter—practices at the intersection of immigration and labor law."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:8347b947-031f-4f0c-a1c6-4e77e5190275>","<urn:uuid:28bb188d-9e95-42d9-932c-a57370d004e5>"],"error":null}
{"question":"As a wine enthusiast studying terroir differences, how do the soil compositions of Gimblett Gravels in New Zealand compare to those of Pauillac in Bordeaux's Left Bank in terms of their impact on wine production?","answer":"While both regions feature gravel soils, they have key differences in their subsurface composition that affect wine production. Gimblett Gravels has deep gravel beds with subsurface lenses that are primarily silty or sandy, lacking the clay strata that characterize Pauillac. This difference makes irrigation essential in Gimblett Gravels, while Pauillac's well-draining gravelly soils with clay layers allow Cabernet Sauvignon to reach high levels of complexity and concentration without irrigation. As a result, Pauillac wines tend to be full-bodied with compact tannins, while Gimblett Gravels wines show a certain delicacy of style.","context":["Andrew Jefford tastes a selection of Gimblett Gravels wines from the 2013 vintage and explores the history and soils of this area within New Zealand's Hawke's Bay.\nSee Andrew Jefford’s tasting notes on Gimblett Gravels wine from the 2013 vintage – scroll down this article\nIn the established wine-growing zones typical of Europe, each new vintage promises a change of stylistic emphasis. We already know the script: that’s the character and potential of each region, defined by innumerable past efforts. How, though, will next summer’s performance turn out on stage? Will it be a flop, or win an Oscar?\nLeave Europe, and things are different. We still don’t know the potential; there’s always a greater vintage ahead. These regions have scripts which are still being written. Newly planted wine regions are more like young children than film stars; the vintage is the school report they bring home at the end of each term. Each report tells us a little more about the child or the class in question.\nThe region I’m thinking of is just 34 years old; indeed most of its planted 630 ha of vines have gone into the ground in the last 25 years. It’s also unique in terms of its status. Gimblett Gravels is not a wine region but a trademark, dating from 2001, and belonging to a producers’ association. It lies within the New Zealand region of Hawke’s Bay.\nThe idea behind going private in this way is both to avoid Coonawarra-style terroir disputes, and to amplify the terroir focus from the off: all of the 700 ha of plantable land lies on the former course of the Ngaruroro River. It switched its route (as the Rhône has done many times) after floods in 1867, leaving deep gravel beds layered with lenses of silt and loamy sand: the Omahu Gravels. River-gravel vineyards often prove auspicious in other vineyard regions, notably Bordeaux’s Médoc and the Southern Rhône itself.\nThere are nonetheless differences with European models. Irrigation is considered essential in the Gimblett Gravels, as it is in Argentina’s Mendoza. There are no controls over the grape varieties planted or the winemaking methods used, including must adjustment; and there is no tasting panel to which the wines must be submitted — so no notion of ‘typicity’ other than the one provided by the market, in rewarding some wines with higher prices than others. Bordeaux varieties account for around 60 per cent of plantings, and Syrah for another 20 per cent or so.\nThe Gimblett Gravels Association circulates its own school report – in the form of a surface-shipped annual tasting case, independently selected by Andrew Caillard MW, and sent to commentators around the world. Last year’s case, to be honest, was a ‘could do better’: the 2012 vintage in Hawke’s Bay was long, cool and challenging, and the wines were often tart and shrill (and overoaked); they made unalluring drinking.\nHappily, the 2013 case is more exciting; indeed it’s the first one of the five which have been sent out so far which seems to me to make a compelling case for this much-fancied, often-lauded zone of New Zealand’s North Island. (The tendency to exhibit marked vintage quality swings may, in itself, be significant: Europe’s greatest regions tend to perform in this way, too.)\nThere is a climate challenge here. The wider Hawke’s Bay area is a little too cool to ripen Bordeaux varieties and Syrah satisfactorily, not so much in terms of overall heat summation as in terms of daytime heat: the sea breezes mean that many summer days peak at 25˚C, which according to Steve Smith MW is not enough of a warm throb for complete phenolic ripeness, even though satisfactory sugar levels can be reached.\nGimblett Gravels, by contrast, is a hot spot within Hawke’s Bay (its summer-day maxima are 2˚C-3˚C higher than elsewhere in the region), and by crop thinning, deficit irrigating and bunch positioning, growers have no trouble getting to full ripeness in favourable vintages.\n2013 certainly looks like one of those: there were very few green notes in the wines, the fruit flesh was rounder and more tender than I had noted in previous vintages, and there was a little more structure and tannic power to the wines, balancing out their marked acidities (see notes below). This is a region where climate change might be expected to lend a helping hand to winegrowers rather than put them out of business.\nWhat of the soils? The key difference between the very young Gimblett Gravels, and the older Médoc and Southern Rhône gravels seems to be that the sub-surface lenses within the banks are principally silty or sandy in this part of Hawke’s Bay, and lack the clay strata which are such a feature of (for example) Pauillac and St Estèphe, just as they are of Châteauneuf du Pape’s Crau plateau.\nThis is major reason why irrigation is essential here, at least for the time being; perhaps deeper root penetration might one day permit vines to be dry farmed. At a guess, then, one might expect that the wines will always have a certain delicacy of style. Margaux rather than Pauillac, let’s say, or St Joseph rather than Hermitage. In terms of the balances and the style of energy in the wines, better analogies than these for previous vintages would have been Chinon or Bourgueil, but with 2013 the wines have taken a clear step ‘down latitude’.\nAs in the past, the Bordeaux blends seem to me to have been deeper, more complex and more successful than the Syrah, and that’s still my view with this year’s case, too. This year, though, the gap is less marked – and in any case the Syrah is unquestionably distinctive enough to justify its place in what must be vineyards of rapidly rising value. All the oak regimes could be eased back further, though none of these wines was grossly over-oaked. I feel producers could afford to be more adventurous with their extractions when the vintage allows, and no one need fret about acidity here.\nBut let’s not judge the class too soon: terroir will always surprise us, and there are decades of development ahead within an ineluctably warming world. What the 2013 vintage shows is that there is real talent here – not just in the stones and the sunlight, but in those crafting the wines. 2012 may have been ‘could do better’, but 2013 looks like ‘should go far’.\nThe 2013 Gimblett Gravels Tasting Case\nBeach House, Cabernet Franc\nClear, vivacious, pungent and fresh raspberry scents, with a dramatic, bracing palate which contrives to soften towards tar at the end: every inch the soloist. Don’t serve this too warm. 88 points (out of 100)\nAnthony Joseph Vidal, Legacy Syrah\nQuietly classy scents: pressed black fruits with a sweet sheen. Calm, smooth, pristine, pure and fresh on the palate: a light-bodied Syrah of unstrenuous, naturally articulated appeal. 89\nCraggy Range, Le Sol Syrah\nSome of the Syrahs almost seem to have a thiol-like note when first opened, and this is one of them (though it’s not under screwcap) – but there is also pristine blackcurrant here. On the palate, it is soft, smooth, resonant and beautifully defined: fresh air in the cool of the morning. There’s a little juniper mixed in with the blackcurrant on the palate. 90\nEsk Valley, Winemaker’s Reserve Syrah\nSpice, oak, ripe leaf and clean blackcurrant scents, then an ample, fruit-saturated palate with the best textural wealth of any of the Syrahs in this selection, giving the wine’s exuberant style plenty of shape and persistence. 89\nMission Estate, Jewelstone Syrah\nA richer, creamier style of black-fruit aroma than its peers, yet the palate is fresh, bright and cascading, with lots of pure-scented appeal and discreet supporting textural wealth. 89\nTe Awa, Syrah\nThis wine needs some air (or a quick decant), but once it’s had it, you’ll find it packed with ripe Morello cherry scent and flavour, and with a liquorice root finish: very choice, tasty and moreish. It seems almost like a juicy Côtes de Nuits in its fruit style, and that fruit lyricism, perfume and intrinsic sweetness bodes well for the future. 90\nVilla Maria, Braided Gravels Merlot, Single Vineyard\nAn exotic style of Merlot, with notes of tomato and peach as well as more classical plum and tobacco. It’s an attractively soft wine with round fruit and plenty of nascent complexity, though structurally lighter than some of its peers in the case. 88\nAnthony Joseph Vidal, Legacy\nThe Cabernet Sauvignon-Merlot blend has classic blackcurrant and black cherry scents with a sweet sheen. Smooth, beguiling, amply contoured and very satisfying on the palate: glowing ripeness of fruit plus a classic sea-breeze lift. 90\nMills Reef, Elspeth\nThis pure Cabernet takes the ripeness further than its peers in the sample case: blackberry, raspberry and creamy coffee notes, while on the palate there is more of that creamy coffee, and even a prune note behind the blackberry. Mellow, opulent and relaxed: amazing to see a wine of this style from anywhere in Hawke’s Bay. It could do with beefier tannins, but there’s lots to enjoy in the luxurious fruit. 90\nNewton Forrest Estate, Cornerstone\nSweet red fruits are what you first notice on the nose in this Cabernet Sauvignon-Merlot-Malbec blend, but with time in the glass there are autumnal leaf and leaf-compost notes. On the palate, this is engaging and assured, with near-European levels of structure and textural depth. The creamy fruit of the mid palate modulates to something dryer, more austere and more penetrating by the end. An excellent effort. 92\nTrinity Hill, The Gimblett\nMore aromatically forthcoming than many of its peers, this Bordeaux blend (Cabernet Sauvignon 40%, Merlot 30%, Cabernet Franc 29% and Petit Verdot 1%) shows lots of exuberant red fruit and a liquorice-fenugreek spice edge. Fresh, charming and complex on the palate, and more classical here than the aromas suggested; firm shaping tannins and a little finishing austerity to gather the threads together. 91\nSquawking Magpie, SQM Cabernets/Merlot\nThis blend of the two Cabernets and Merlot has lots to say for itself: plenty of vivid fruit, but also notes of spice, blood and milk chocolate, too. It’s another wine with impressive ripeness and complexity on the palate: red and black autumn berries, crab apple and cranberry, but folded together seamlessly and with some promising tannins to lend depth and perspective. Pristine definition and clarity, too. 92\nMore Jefford on Monday columns:\nBack in November, I reported on a conversation with Philippe Guigal – but omitted the final intriguing remark he made:…\nDinner with Sassicaia Something like this isn’t meant to occur in Europe, where wine has been made for thousands of…\nYou’ll all know that the new (fourth) edition of The Oxford Companion to Wine has been published. Santa will, I’m…\nWinemaker Samuel Guibert of Mas de Daumas Gassac, who divides his time between France and California, noted in a recent…","St Estèphe is the most northern of Médoc communal crus. Its unique terroir is made up of layers of gravel which are supported by a dense clay base. This subsoil retains water in dry seasons and works particularly well with Merlot, a largely planted variety which is used to flesh out Cabernet Sauvignon. This clay base also creates powerful, textured tannins which enable St Estèphe to stand out from the pack. Like St Julien, it is one of the four most important communal appellations of the Médoc which does not contain any first growths, despite its southern border being a stone’s throw from Château Lafite. Nonetheless, it is home to some excellent châteaux such as Cos d’Estournel, Montrose, Calon Ségur and Lafon Rochet.\nDue south of St Estèphe lies Pauillac, the king of the Left Bank communes. It is home to three first growths as well as a plethora of other classified growths. Its renowned well-draining, gravelly soils enable its dominant grape Cabernet Sauvignon to reach fantastic heights of complexity and concentration. As a result, the wines tend to be full-bodied with compact tannins and good freshness. Its aromatics are often what one associates with classic Bordeaux: pencil shavings, black currant and occasional mint. Some of the most famous châteaux of the commune are Latour, Mouton Rothschild, Lafite Rothschild, Pichon Baron, Pichon Lalande and Lynch Bages.\nSt Julien is like the middle child of the Médoc – not as assertive as Pauillac or as coquettish as Margaux. It lies firmly between the two more outspoken communes and as a result produces a blend of them both. Its wines have often been sought out by aficionados for their balance and consistency, particularly in the UK. Yet due to its middle child nature, it can occasionally be overlooked globally and as a result underrated by those markets outside the UK. Despite the fact that it has no first growths, it has several second growths including Léoville Las Cases, Léoville Barton, Léoville Poyferré and Ducru Beaucaillou as well as the celebrated châteaux such as Talbot and Beychevelle.\nPlump, silky and seductive are the words often used to describe wines from Margaux. Because of their style, they tend to be user friendly and more approachable when young. This is in part due to its terroir which is comprised of the thinnest soil as well as the highest proportion of chunky gravel in all of the Médoc. It drains well but also is it more susceptible to vintage variation. The wines tend to have the highest proportions of Merlot within the “core” of the Médoc further adding to its ample roundness and openness. It is home to the largest number of classified growths including its namesake first growth, Château Margaux, as well as third growths, Palmer and d’Issan.\nLocated directly south of the city of Bordeaux, the district of Graves was named after the intense gravel terrain which heavily dominates the soil and which was deposited during the last Ice Age. Besides being well draining, it also adds profound mineral complexity to its wines. In addition, it is the only appellation within the region that is equally famous for red and white wines. For many years, it was considered the premium Bordelais wine region and its most famous château, Haut Brion, was collected by the likes of renowned enthusiasts, Thomas Jefferson and Samuel Pepys. In 1987, the communal appellation, Pessac-Léognan, was created distinguishing a “cru” from within the larger Graves district. As it is a warmer region, its grapes are often picked 2-3 weeks earlier than the Médoc. The most renowned châteaux of this communal appellation include Haut Brion, La Mission Haut Brion, Laville Haut Brion, Haut Bailly and Domaine de Chevalier.\nThe small sub-region of Pomerol is situated northeast of the industrious city of Libourne. Its soils are predominately iron-rich clay with a smattering of gravel that produce wines with extraordinary power and depth. As a result of this clay-dominance, it has the highest percentage of Merlot planted in all of Bordeaux. Certain châteaux are produced exclusively from this grape, but most incorporate smaller quantities of Cabernet Sauvignon and Cabernet Franc as well. Despite its hefty (if not exclusive) proportion of Merlot, many people think of wines from this region as separate entities. As one wine aficionado stated recently, “It’s not Merlot. It’s Pomerol.” Despite the region’s small size, it contains some of the world’s most sought after (and expensive) wines includingPétrus, Le Pin, Lafleur, l’Evangile and Vieux Château Certan. Unlike other Bordelais subregions, there is no system of classification. The châteaux are traded on reputation alone.\nSouth of Pomerol lies the medieval, perched village of St Emilion. Surrounding this village are vines that produce round , rich and often hedonistic wines. Despite a myriad of soil types, two main ones dominate – the gravelly, limestone slopes that delve down to the valley from the plateau and the valley itself which is comprised of limestone, gravel, clay and sand. Despite its popularity today, it was not until the 1980s to early 1990s that attention was brought to this region. Robert Parker, the famous wine critic, began reviewing their Merlot-dominated wines and giving them hefty scores. The rest is history as they say. Similar to the Médoc, there is a classification system in place which dates from 1955 and outlines several levels of quality. These include its regional appellation of St Emilion, St Emilion Grand Cru, St Emilion Grand Cru Classé and St Emilion Premier Grand Cru Classé, which is further divided into “A” (Ausone and Cheval Blanc) and “B” (including Angélus, Canon, Figeacand a handful of others). To ensure better accuracy, the classification is redone every 10 years enabling certain châteaux to be upgraded or downgraded depending on on the quality of their more recent vintages."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:1c28d2ef-b936-44ee-a57b-12b169605d85>","<urn:uuid:9017f90d-06c3-4c20-8b65-e2d5b62421f9>"],"error":null}
{"question":"What are the key differences between functional level strategy and global strategy in terms of their scope and implementation?","answer":"Functional level strategy and global strategy differ significantly in scope and implementation. Functional level strategy operates at the departmental level, focusing on day-to-day operational decisions and specific goals for individual business functions like marketing, HR, or production - all aligned with higher-level corporate strategies. In contrast, global strategy operates at an international scale, requiring firms to coordinate product and pricing strategies across multiple markets worldwide. While functional strategies are implemented within specific departments with existing resources, global strategies demand careful consideration of different regional markets, require extensive coordination across international locations, and typically involve highly centralized decision-making to maintain consistency across markets.","context":["Functional level strategy is correlated and in line with the company’s growth. Effective level strategies are actions and goals assigned to different departments that support your business-level strategy and corporate-level strategy. These strategies specify whether you want to see results from the daily operations of certain sections (or functions) of your business.\nAn effective level strategy may sound like a daunting concept, but when you understand where it fits in with the overall strategy of your business, you should have no problem developing effective level strategies that will drive your business to success.\ntypes of business strategies\nBefore examining the operational level strategy in more detail, it is important that you understand another type of business strategy. These are part of the functional level strategy of any organization.\nWhy? Because you don’t sit down with your food runners and give them the goal of increasing market share. That goal – that strategy – involves a higher level of your business.\n1) Corporate level strategy\nThink of your corporate strategy as the driving force behind your business. These high-level strategies will define the main purpose (s) of your organization.\nWhen you set your own corporate strategy, it directly affects decision-making in every part of your business. This will help you:\nSet priorities and common goals\nFocus on using resources\nSpecify expected results or achievements\nThe strategy we mentioned earlier – increasing market share – involves it at the corporate level. Once you set it as your corporate level strategy, it automatically affects what happens at the next level.\n2) Business level strategy\nThe director is working on his effective level of strategy\nBusiness-level strategies translate corporate strategies into more explicit actions. In short, your business strategies will define the actions and actions necessary to achieve your corporate strategy.\nFor example, creating a corporate strategy to increase market share may be the business strategies that support this goal:\nThe marketing budget is being increased\nImprove product quality\nThese strategies then take you to the next level of your business.\n3) Effective Level Strategy\nEffective level strategies are actions and goals assigned to different departments that support your business level strategy and corporate level strategy. These strategies specify whether you want to see results from the daily operations of certain sections (or functions) of your business.\nYour operational level strategies reflect the fact that corporate and business objectives typically require the involvement of multiple functional areas (e.g., HR, manufacturing, research, and development, etc.). So, continuing your corporate-level strategy to increase market share is your effective level strategy:\nHR: Increase recruitment of highly trained staff\nMarketing: Improve brand recognition\nProduction: Reduction in rejection\nOnce these strategies are set, departmental managers can set individual employee assignments to support departmental goals. These are parts of the functional level strategy of any organization.\nWhat do you mean by effective strategy?\nAn ‘effective strategy’ is a strategy or organizational plan adopted by each functional area, e.g. Marketing, manufacturing, finance, human resources and more, aligning with overall business or corporate strategies to achieve organizational level goals.\nWhat are the 3 levels of strategy?\nStrategy can be formulated at three levels: corporate level, business level and operational level. At the corporate level, the strategy is created for your organization as a whole. Corporate strategy deals with decisions related to various business areas where the firm operates and competes.\nWhat are the business strategies?\nUsually, they define the business by answering high-level questions. … Effective business strategies improve the application of business and corporate strategies. Effective strategies include marketing strategies and human resources strategies.\nWhat is the functional level?\nIn addition to the functional level of the domain, you can also set the functional level of a forest. A domain functional level is set individually for each domain. The forest functioning level is set for the entire forest and consequently affects all the domains within that forest.\nWhat are effective strategies?\nThe most common operational strategies used in management are financial strategies, marketing strategies, production strategies, human resources strategies (personnel strategies), and research and development strategies.\nWhat are 5 business-level strategies?\nBelow are five types of business-level strategies. Cost Leadership: This type of strategy is based solely on pricing as a competitive factor. In the case of commodity products, many producers try to reduce their cost structure and transfer value to the customer in case of lower prices.\nWhat are the 3 types of decision-making?\nDecision Making Style – An Overview. We determine the types of decision making by looking at the results and the affected entity. At the highest level, we have chosen to categorize decisions into three main types: consumer decision making, business decision making, and personal decision making.\nWhat are the three primary strategies for strategy formation?\nThese include analysis, strategy assignment, and goal setting. The final two steps in strategic management constitute implementation. These steps include creating the structure (internal environment) and getting feedback from the process.\nWhat are the 5 Functional Areas of Business?\nCommon areas of business include sales, marketing, finance and accounting, customer service, human resources, research and development, production, and distribution.\nFunctional Level Strategies How can operational level strategy play a role in efficiency?\nEffective level strategies can improve an organization’s ability to achieve superior efficiency, quality, innovation and customer response by reducing costs and improving productivity in ways such as economies of scale, learning effects, marketing strategies, or efficient information technologies. MC d\nWhat is an example of an organization’s operational level?\nThe operational level of the organization is where a team of experts in marketing, finance, production/management, accounting, information management, research and development, and/or human resources focus on a specific strategic direction to create the value of the organization.\nWhat are effective strategies?\nEffective strategies are the core, routine activities that must be provided in each functional area for human resource management, marketing, finance, manufacturing / activities and R&D business products and services.\nWhat is the difference between forest functional level and domain operational level?\nAn enterprise domain is usually composed of a domain controller that runs on different versions of the Windows server operating system. … A domain within a forest can operate at a higher operational level than a forest, but no domain can operate at a lower operational level than a forest.\nWhat are the key three of corporate strategies?\nThe three main types of corporate strategies are growth, stability, and renewal. A. Growth – A growth strategy is when a company increases the number of markets or products offered by its current business (S) or through new business (S).\nWhat is an effective business model?\nThe functional areas of the business that are usually set function-specific goals are human resources, manufacturing, research and development, marketing, and possibly information technology.\nThe core variable of effective level strategies is available\nYour functional level strategy will have the most details of the three strategy types. Of course, you will have specific goals and operational items for each category. But you also have different metrics by which you measure the success of your team’s performance.\nEffective level strategies should always be in alignment with their top business-level strategies and corporate-level strategies.\nFor example, if your corporate strategy is to improve market share and your business strategy is to improve brand recognition, you do not want one of your effective strategy marketing departments to update their computer system. Those goals are beyond alignment.\nIf three strategy levels point to the same outcome, you will ensure your success (and gain the support of high-level management).\nWhen trying to measure your progress, it can be easy to include too much information and equip your data. It is important to remember what your business-level strategies and corporate level strategies are, and to determine whether you are only progressing toward those goals.\n4) Existing resources\nEach operational level strategy that you set up should be used by both existing departments – tools and personnel that each department offers.\nPut another way, don’t want your marketing department strategies to be based on resources you don’t have. Doing so can severely undermine its broader goals (at the business and corporate levels).\nIn addition to vertical alignment, effective leveling strategies should be integrated horizontally within and between categories.\nFor example, coordinate those activities with the purchase, inventory and any new processes in the shipping and production department within your management department. That way, actionable items in one category don’t put a speed bump on actionable items in another category.\nNow that you know the effective level strategy and how it fits into your business classification, let’s examine specific examples of goals that work at this level.\nExamples of Effective Level Strategies\nFor example, let’s imagine that XX defines three corporate-level goals: efficiency, quality, and distribution. Here is how these objectives will be revealed as a functional level strategy in each of the six categories.\nReduce the cost of hiring and training by reducing employee turnover.\nProvide extensive training to reduce staffing errors.\nStreamline acquisition and talent education.\nMaximize cost-effective targeting of ad campaigns.\nProviding an accurate assessment of customer product priorities.\nIdentify and respond to market trends as they evolve.\nPlease negotiate the purchase price to provide increased value.\nSelect vendors you want to partner with.\nManage distributions to avoid extensive inventory.\nIncrease high-quality production.\nAdjust the minimum production demands to the minimum delay.\nSimplify and automate the data collection process.\nReduce errors in the data provided in other sections.\nProvide access to information in real-time.\nResearch and development\nTest the feasibility of the concepts before producing a full-scale prototype.\nDesign products that integrate customer needs and production capabilities.\nAccelerate overall innovation using the parallel design process.\nThe benefits of effective level strategies\nMarketing as part of an effective level strategy\nEffective level strategy is precise because it is usually more difficult to set than your corporate and business strategies. But taking the time to hammer out the operational strategies of each department can help you align your goals with the top staff at your organization.\nThis will help managers across your organization get a better idea of how their departments (and the employees they create) will have an impact on your department and corporate-level strategies. And when all parts of your business combine to achieve a single goal, success is inevitable.\nWhat are competitive strategies?\nCompetitive strategy is defined as the long-term planning of specific companies to gain the competitive advantage of competitors in the industry. … These strategies play a very important role when the industry is very competitive and almost all similar products are offered to the customers.\nWhat are the five strategies?\nHe calls 5P’s as their strategy. They stand for plan, pattern, position, vision, and movement. These five components allow a company to implement more effective strategies.\nWhat is the level strategy?\nBusiness-level strategy. An average organization should focus on satisfying customer needs or preferences in order to achieve average returns above its core competencies. … business-level strategy is related to a firm position in the industry, compared to competitors and five competitive forces.\nWhat are four generic strategies?\nAccording to Michael Porter, here are four generic strategies:\nCost Leadership. You target a broader market (greater demand) and offer the lowest possible price.\nSeparation. You have a broad market target (high demand), but your product or service has unique features.\nFocus on cost\nFocus on the difference.\nWhat are the 7 steps to decision making?\nStep 1: Identify the decision. You understand that you need to make a decision.\nStep 2: Collect relevant information.\nStep 3: Identify the options.\nStep 4: Weight the evidence.\nStep 5: Choose between options.\nStep :: Take action.\nStep :: Review your decision and its consequences.\nHow do you formulate a strategy?\nThe five stages of the process are goal setting, analysis, strategy formulation, strategy implementation and strategy monitoring.\nClear your vision The purpose of setting goals is to clear the vision for your business.\nCollect and analyze data.\nFormulate a strategy.\nImplement your strategy.\nEvaluation and control.\nWhat is the strategic operational strategy?\nAn ‘effective strategy’ is a strategy or organizational plan adopted by each functional area, e.g. Marketing, manufacturing, finance, human resources, and more, aligning with overall business or corporate strategies to achieve organizational level goals. It is a part of the functional level strategy of any organization.\nMore Interesting Articles\n- Deal With Bosses Who Put You on the Defensive Quo\n- Deal with a Team Member who Questions your Authority\n- Withstand a Bullying Boss Trying to Discredit You\n- How to Respond to an Annoyed Boss\n- How to Deal With Manipulative Coworkers\n- How to Make a Great Business Presentation Introduction\n- Architecture Presentation Tips that Give Professional Look\n- Shortlisted Tips for Facing an Interview for Success\n- Things to Say in a Promotion Letter in Workplace\n- How to Deal with a Boss who Under-Appreciates You\n- How to Ask for a Promotion on Performance Evaluation\n- How to Impress People at Staff Meetings\n- How to Conduct a Formal Briefing in Workplace\n- Workplace Presentation Tips – Beginners to Professionals\n- How to Reply to Accolades from the Boss\n- How to Deal With a Co-Worker Who Refuses to Help\n- Handle a Supervisor Who Talks Down and Belittles You\n- How to Deal with an Upset Boss Professionally\n- Deal With a Coworker Who Is always in a Bad Mood and Tired\n- Coworker Issues – How to Deal who Steps on Your Toes","File Name: corporate business and functional strategy .zip\nManagement may draw up several alternative strategic scenarios and appraise them […]. Management may draw up several alternative strategic scenarios and appraise them against the long-term objectives of the organization. To begin implementing the selected strategy or continue a revalidated one , management fleshes it out in terms of the actions to be taken in the near future.\nGrowth platforms are specifically named initiatives selected by a business organization to fuel revenue and earnings growth. Distinguish between the varying integrations and diversifications that allow businesses to pursue strategic growth.\nGrowth platforms may be strategic or tactical. Strategic growth platforms are longer-term initiatives for high-scale revenue increases. Generic examples of commonly selected strategic growth platforms include pursuit of specific and new product areas, entry into new distribution channels, vertical or horizontal integration, and new product development.\nIllustrative examples of growth platforms include:. Wikipedia growth goals and projections : These graphs show goals and projections for growth for Wikipedia visitors and contributors from The Bridgespan Group for Strategy Development.\nThe graph in the left panel shows the target growth trajectory in number of visitors, from less than million to over million. The graph in the right panel shows an overall increase in the number of contributors across all Wikipedias, with more growth indicated for the already higher-traffic Wikipedias.\nMarket penetration occurs when a company penetrates a market in which current products already exist. This strategy generally requires great competitive strength, a strong brand, or both, as most market penetrations demand actively taking market share from current incumbents. It is an aggressive and often risky approach to growth. Market development strategy entails expanding the potential market through new users or new uses for a product.\nThe strategy is best accomplished through identifying unique niche needs in a specific type of user and filling those needs. Market research is critical in development strategies.\nNew users can be defined as new geographic segments, new demographic segments, new institutional segments, or new psychographic segments. In business and engineering, new product development NPD is the process of developing, researching, and bringing a new product to market. A product is a set of benefits offered for exchange and can be tangible that is, something physical you can touch or intangible for example, a service, experience, or belief.\nIdentifying new needs or new ways of filling them and developing a new process or product that accomplishes this aim are the goal of this growth strategy. NPD requires investment in research and development, usually over the long term, and extensive trial and error. In business, consolidation refers to the mergers and acquisitions of many smaller companies into much larger ones for economic benefit. Consolidation or amalgamation is the act of merging two or more organizations into one.\nIn strategic management, it often refers to the mergers and acquisitions of many smaller companies into much larger ones. Consolidation occurs when two companies combine to form a new enterprise altogether; neither of the previous companies survives independently. The logic driving consolidation is the creation of economies of scale, economies of scope, new locations, new technology, or some other form of increased competitive capacity.\nThis activity can help an enterprise grow rapidly in its sector or location of origin or expand into a new field or new location. Generally speaking, a merger is a combination of organizations in which each abandons its previous brand and business models, creating a new organization with the combined capacities of each one.\nIn an acquisition, one organization buys out another, with the acquired company usually placing its processes under the brand name of the acquirer. Mergers and acquisitions of U. Banks : This diagram of bank mergers in the United States shows how extensive the consolidation of various companies has been. What start as more than 50 distinct companies have eventually consolidated into fewer than In the pure sense of the term, a merger happens when two firms, often about the same size, agree to go forward as a single new company rather than remain separately owned and operated.\nFor example, in the merger of Glaxo Wellcome and SmithKline Beecham, both firms ceased to exist independently; a new company, GlaxoSmithKline, was created. Not every merger with a new name is successful. The following motives are considered to improve financial performance: economy of scale, economy of scope, increased revenue or market share, cross-selling, synergy, taxation, geographical or other diversification, resource transfer, vertical integration, and hiring.\nOther motives for merger and acquisition that may not add shareholder value include diversification, manager overconfidence, empire-building, and management compensation. Because of the costs involved, consolidation is a very high-level strategic decision.\nAll stakeholders in both organizations should be consulted, and agreements will often take many months or years to conclude.\nCultural conflicts between two different organizations are not uncommon, as the mission, vision, and values of the individuals and groups within them are likely to differ.\nManaging this type of change strategically is complex and rife with conflict. Mismanagement during these processes can minimize the potential synergistic gains and reduce the efficacy of the new strategic plan. Explain the concept of global strategy within the context of international business and a globalized economy.\nHow can the organization build the necessary global presence? What are the optimal locations around the world for the various value-chain activities? How can the organization turn a global presence into global competitive advantage?\nA global strategy may be appropriate in industries where firms face strong pressures to reduce costs but weak pressures to respond locally; globalization therefore allows these firms to sell a standardized product worldwide. By expanding to a broader consumer base, these firms can take advantage of scale economies cost advantages that an enterprise obtains due to expansion and learning-curve effects because they are able to mass-produce a standard product that can be exported providing that demand is greater than the costs involved.\nGlobalization is not limited to cost leadership, however. Differentiation strategies also enable economies of scope, either fulfilling different needs in different markets with a similar series of products, or developing new products based upon the needs and consumption habits of a new market. Differentiation as part of a global strategy will often require localization, as organizations must adapt to consumer tastes better to compete in the new country. For example, Coca Cola tastes different depending on the country where it is bought because of differences in local preferences.\nStarbucks sources coffee beans from all over the world, as climate dramatically affects the type and quality of the bean. The globalization strategy of Starbucks—while it includes selling in many countries—is hugely depending on global sourcing, and strategic managers must carefully monitor this process for costs and benefits. Global strategies require firms to coordinate tightly their product and pricing strategies across international markets and locations; therefore, firms that pursue a global strategy are typically highly centralized.\nWith global markets in mind, strategic managers must expand their perspective and use varied models to generate different strategies for different places.\nFor example, companies must now conduct a PESTEL analysis for each region in which they operate and recognize expense and competition deviations between regions. For example, tariffs in country A may be much higher than country B, but country B has fewer individuals willing to pay a high price for the good the organization is selling. These analyses are how strategists incorporate global concerns into strategic management. Gross domestic product GDP worldwide : The map identifies GDP nominal in different countries;countries with higher GDPs offer high consumer spending opportunities for multinational enterprises.\nThe U. A strategic alliance is a cooperation where each member expects the benefit from cooperation will outweigh the cost of individual efforts. A strategic alliance is a relationship between two or more parties to pursue a set of agreed-upon goals or to meet a critical business need while remaining independent organizations.\nThe alliance is a cooperation or collaboration that aims for a synergy where each partner hopes that the benefits from the alliance will be greater than those from individual efforts. Partners may provide the strategic alliance with resources such as products, distribution channels, manufacturing capability, project funding, capital equipment, knowledge, expertise, or intellectual property. The alliance often involves technology transfer access to knowledge and expertise , economic specialization David C.\nMowery, Joanne E. Oxley, Brian S. Strategic Alliances and Interfirm Knowledge Transfer. Winter Strategic Management Journal , Vol. Because the number of patents has increased in recent years, technology transfers in strategic alliances have become more common.\nCooperative sourcing is a collaboration or negotiation between different companies with similar business processes. To save costs, the competitor with the best production capability can insource the business process of the other competitors.\nThis practice is especially common in IT-oriented industries as a result of low to no variable costs, e. Since all of the negotiating parties can be outsourcers or insourcers, the main challenge in this collaboration is to find a stable coalition and the company with the best production function. High switching costs, costs for searching potential cooperative sourcers, and negotiating may result in inefficient solutions.\nUpper management is tasked with the developing complex interactive strategies when entering a strategic alliance. Aligning stakeholders from different businesses and ensuring the costs do not outweigh the benefits requires careful managerial consideration. The following steps highlight key aspects of the strategic alliance process:. In the emerging global economy, e-business has become an increasingly necessary component of business strategy.\nThe term electronic business commonly referred to as E-business or e-business is sometimes used interchangeably with e-commerce. In fact, e-business encompasses a broader definition that includes not only e-commerce, but customer relationship management CRM , business partnerships, e-learning, and electronic transactions within an organization.\nAutomated online assistant : In e-commerce, electronic i. Electronic-business methods enable companies to link their internal and external data-processing systems more efficiently and flexibly, to work more closely with suppliers and partners, and to better satisfy the needs and expectations of customers. In practice, e-business is more than just e-commerce. While e-business refers to a strategic focus with an emphasis on the functions that occur using electronic capabilities, e-commerce is a subset of an overall e-business strategy.\nE-business involves business processes that span the entire value chain: electronic purchasing and supply-chain management, electronic order processing, customer service, and business partner collaboration. Special technical standards for e-business facilitate the exchange of data between companies. E-business software allows the integration of intrafirm and interfirm business processes.\nE-business can be conducted using the Internet, intranets, extranets, or some combination of these. In the emerging global economy, e-commerce and e-business have become increasingly necessary components of business strategy and strong catalysts for economic development. The integration of information and communications technology ICT in business has revolutionized relationships within organizations and those among organizations and individuals.\nThe objective of this work is to review the literature of the main concepts that lead to determining the strategic approach, creation of strategies, organizational structures, strategy formulation, and strategic evaluation as a guide for the organizational management, taking into account the effects produced by the different types of strategies on the performance of organizations. In this article, the systemic literature review method was used to synthesize the result of multiple investigations and scientific literature. The process of reading and analysis of the literature was carried out through digital search engines with keywords in areas related to the strategic management. This research reveals the lack of scientific literature containing important theoretical concepts that serve the strategists as a guide in the creation, formulation, and evaluation of strategies. This review contributes to the existing literature by examining the impact of the strategic management on the organizational performance.\nDefinition : Functional Level Strategy can be defined as the day to day strategy which is formulated to assist in the execution of corporate and business level strategies. These strategies are framed as per the guidelines given by the top level management. Functional Level Strategy is concerned with operational level decision making, called tactical decisions , for various functional areas such as production, marketing, research and development, finance, personnel and so forth.\nA strategy is the central, integrated, externally oriented concept of how a firm will achieve its objectives. Strategy formulation The process of deciding what to do; also called strategizing. Neither can succeed without the other; the two processes are interdependent from the standpoint that implementation should provide information that is used to periodically modify the strategy.\nThis a really important question as planning happens all the time and as this question suggests at different levels and with different scopes of influence. Before I answer this, first some definitions :. The corporate strategy is the broadest and most long-ranging. It must be developed first to provide direction to the business and functional area planning efforts where the activities are planned and managed. So, it is the largest doll that all the others fit into.\nНо мне она неизвестна. - Видите ли, ситуация не столь проста. Вы сказали, что самолет улетел почти пустой.\nCorporate level strategy addresses the entire strategic scope of the firm.Maurelle Q. 02.06.2021 at 04:06\nStrategy can be nothing but a buzzword, but successful businesses make it mean something.Loring C. 03.06.2021 at 08:41\nPDF | On Mar 14, , Okechukwu Ikeanyibe published Strategy Formulation: Corporate, Business and Functional Strategies | Find, read and.Hocounheida 06.06.2021 at 18:31\nGrowth platforms are specifically named initiatives selected by a business organization to fuel revenue and earnings growth."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:571a5bc7-7eb0-49a7-b1a4-f3aad8653812>","<urn:uuid:1b9695bc-b011-4bfa-8bfa-63a49251cd22>"],"error":null}
{"question":"Which disaster claimed more lives: the Heppner, Oregon flash flood of 1903 or the Chicago Fire of 1871?","answer":"The Great Chicago Fire of 1871 was deadlier, killing at least 300 people and leaving 100,000 homeless. The 1903 Heppner flash flood in Oregon resulted in 200-225 deaths when Willow Creek suddenly overflowed into the town centre.","context":["If you have just heard that the local forecast contains the possibility of a flash flood, then you may be wondering what is a flash flood?\nAccording to the National Weather Service, a flood is an overflow of water onto normally dry land. Unlike a regular flood, flash floods can happen lightning-fast, hence the name flash flood.\nWhat is a flash flood?\nA flash flood must occur within six hours of heavy rainfall or another event that means that flooding is imminent, according to the National Weather Service. In most cases, the flooding will occur within three hours. In addition to heavy rain, a mudslide or dam and levee breaks can cause the National Weather Service to issue a flash flood warning.\nWhere do flash floods occur?\nFlash floods can occur anywhere, but they are more likely to occur in developed areas, like cities, than in rural ones. The reason is that the water has fewer places to sink into the ground in cities where many areas are paved, covered in concrete, or made of another material that water cannot get under. The way that buildings are often built close together in cities also means that water is often channeled. Water almost always runs downhill. Therefore, some areas may have more flooding than others.\nWill you have time to prepare for a flash flood?\nIn many cases, there is little or no time to prepare for a flash flood. Make sure that you keep your eyes on the local forecast so that you receive the warning as early as possible if one is issued. Then, move to the highest point possible.\nDuring a flash flood, storm drains can become quickly overwhelmed, sending torrents of water to lower points. The same is true of pipes and other items designed to carry water underground.\nYou should never go to the basements or underground parking garages if a flash flood is imminent. It is never safe to try to drive or walk through standing water. Any flowing water -- not just during flash flooding -- can sweep your vehicle away or you off your feet.\nAccording to the Federal Emergency Management Agency (FEMA), just six inches of water in a flash flooding event can reach the bottom of most passenger cars, causing the cars to lose control or stall. A stalled car is the last thing you want during flash flooding. You're stationery as water flows around you. A foot of water will float many vehicles. Two feet of rushing water will carry away most vehicles, including SUVs and pickups. When encountering a flooded roadway, remember \"Turn Around, Don't Drown.\" It's hard to gauge what is under all the flooding. There could be chunks of the road that are missing.\nMust it always rain where a flash flood occurs?\nYou may not see a drop of rain before being inundated with flooding. Rain may have occurred at a higher elevation and run into your area. Snow may melt quickly and spark flash flooding. A levee or dam may also break and send a wall of water crashing your way.\nWhat was the deadliest flash flood to occur in the 1900s?\nThere have been many deadly flash floods throughout history, but the most deadly occurred in India when the water went over the top of the Machchhu Dam. The disaster may have killed up to 45,000 people, but no one knows for sure because the government dug mass graves and buried people quickly before diseases could spread. It is estimated that the dam break that occurred on August 11, 1979, was made worse by the fact that people downstream from the dam failed to get word that the levee was about to break. Therefore, they did not have time to get out of harm's way. Over 100 people sought refuge in a temple on a hill in Morbi, but the water overtook the temple, and they had no place to go.\nWhat are some of the deadliest flash floods in the United States?\nThe deadliest flash flood to occur in the United States was the Johnstown Flood occurring in Johnstown, Pennsylvania, on May 31, 1899. This flood, which killed more than 2,200 people, happened after the South Fork Dam broke, releasing about 14.55 million cubic meters of water into a valley. Another deadly one occurred on June 14, 1903, in Heppner, Oregon, when torrential rains knocked a steam laundry off its foundation. Then, the store acted like a dam holding back the water before finally crumbling. When it fell, a wall of water reaching up to 50 feet tall crashed down on the community. The storm left 247 people dead in its wake.\nWhat should you do if the local forecast calls for flooding?\nIf the local forecast includes a flood watch, then check your emergency kit to be sure that it is ready if one occurs. Then, think through which roads have the highest elevations. If possible, plan to get out of low-lying areas before a flood warning is issued. If you are under evacuation notice, be sure to stay tuned to your local news sources and follow orders. If you cannot get out of a building, then head to the highest level and call 911.\nThe National Weather Service first issues a flood watch if there is time telling you that conditions may be right for sudden flooding. You should prepare your emergency kit, especially if you are in an urban area, as the water has less room to sink into the ground. If the National Weather Service issues a flood warning, then take action immediately. Stay tuned to local news sources to see if a flooding evacuation is ordered and follow local authorities' recommendations.\nNow that we've answered your \"What is a flash flood?\" question, we hope you use this life-saving information if you are ever caught in a flash flood. The first rule of survival in a flash flood, and any other emergency, is not to panic. Heed all watches and warnings from meteorologists and prepare for the possibility of flash floods the moment a watch is issued.\nWeather explained: What is a flash flood?\nIn addition to heavy rain, a mudslide, dam or levee break can cause the National Weather Service to issue a flash flood warning.\nMore TOP STORIES News","Natural and Man-Made Disasters\nNatural and man-made disasters have claimed the lives of thousands over the past century. Listed below are a few of the more well-known catastrophic events.\nThe Great Hurricane of 1780\nOctober 10-16, 1780\nThe Great Hurricane of 1780 is considered the deadliest Atlantic tropical cyclone of all time. About 22,000 people died when the storm swept over Martinique, St. Eustatius and Barbados between October 10 and October 16. Thousands of deaths also occurred offshore.\nThe Perfect Storm\nIn October 1991, the atmosphere seemed to go crazy. Three separate weather elements (including Hurricane Grace) crashed together to form a storm of mammoth proportion--a blockbuster nor'easter--off the New England coast. As Halloween neared, the storm played tricks that veteran meteorologists had never seen a typical nor'easter perform, such as backing up into the Eastern Seaboard to unleash its titanic waves on bewildered beach towns. USATODAY.com meteorologists James West and Chris Vaccaro look day-by-day at a meteorological bomb that seemed so complete it was dubbed the \"perfect storm.\".\n1825: October 7: Miramichi Fire, Maine and the Canadian province of New Brunswick: burned 3 million acres, killed 160 people and left 15,000 homeless.\n1849: May 17: The St. Louis Fire, St. Louis, Missouri: the first fire in US history in which a firefighter was killed in the line of duty. Captain Thomas B. Targee was killed while a fire break was being made. steamboat fire, the White Cloud; death toll, 3.\n1865: April 27: Worst Ship Disaster: Riverboat Sultana, Mississippi River: Sultana's boiler exploded, engulfing the ship in flames; transporting 2,300 war-weary Union troops home, only 600 survived. More people died in the Sultana disaster than on the Titanic or the Lusitania.\n1871: October 8: The Peshtigo Fire Wisconsin/Michigan: estimate at least 1,500 people dead - eight hundred died in Peshtigo, Wisconsin alone; the Peshtigo Fire killed more people than any fire to date, but was overshadowed at the time by the Great Chicago Fire, which began the same day. Estimiated 3.8 million acres burned.\n1871: October 8: The Great Chicago Fire, Chicago, Illinois: at least 300 people were dead, 100,000 people were homeless, and $200 million worth of property was destroyed.\n1888: March 11-14: Great White Hurricane, East Coast: The Blizzard of 1888 killed 400; accumulation of up to 5 feet of snow. Damage estimated at $20 million.\n1889: May 31st: The Johnstown Flood, Johnstown, Pensylvania: the result of several days of extremely heavy rainfall, exacerbated by the failure of the South Fork Dam; over 2,200 dead; over $17 million (USD) in damages.\n1894: September 1: The Minnesota Forest Fire, Hinckley, Minnesota: \"The Day the Air Caught Fire\"; at least 418 killed; over 307,000 acres burned.\n1900: September 8: The 1900 Galveston Hurricane, Galveston, Texas: estimated winds of 135 miles per hour cat. 4 storm on the Saffir-Simpson Hurricane Scale.; extimated death toll between 6,000-12,000 Deaths; Deadliest hurricane to hit the United States.\n1903: December 30: Iroquois Theater Fire, Chicago Illinois: The Iroquois Theater was supposedly fireproof - 602 dead\n1903: June 14: Flash flood - Heppner, Oregon: The entire village of Heppner was swept awy by a sudden flash flood when Willow Creek overflowed into the town centre. 200-225 people died. No weather records were kept as the weather officer and his entire family were killed.\n1904: February 8: Baltimore Fire, Baltimore, Maryland: destroyed downtown Baltimore; fire burned over 30 hours, destroying 1,526 buildings spanning 70 city blocks.\n1904: June 15: General Slocum Paddleboat Fire, New York City, New York: 1,031 dead; a \"floating fire trap\"\n1906: April 18: The Great 1906 San Francisco Earthquake and fire, San Francisco, California: registered 8.25 on the Richter scale; estimates range from 700 to 3,000 dead or missing, approximately 225,000 injuries and $400,000,000 in 1906 dollars.\n1907: December 6: Monongah Mining Disaster, Monongah, West Virginia: \"The worst mining disaster in American History\" death toll 362 men and boys.\n1910: March 1: Avalanche, Wellington, Washington: 2 trains snowbound in Stevens Pass in Cascade Range swept off tracks into canyon 150 ft below, killing 96.\n1910: September 10: The Big Burn of 1910, Wallace, Idaho: at least 7 people died along with 78 firefighters.\n1911: March 25: Triangle Shirtwaist Fire, New York City, New York: 146 dead.\n1913: December 1-5: Flood, Central to North Texas: 177 dead.\n1913:: Great Flood of 1913, Ohio River Basin: 467 persons drowned; 147 million dollars damage; \". . .second mostly deadly of record for the nation.\" (David Ludlum)\n1915: May 7: Sinking of the Lusitania, New York City, New York: departed from New York May 1st for Liverpool, carrying 1959 passengers; torpedoed by German U-boat; 1,200 dead\n1915: July 24: Excursion Steamer Eastland, Chicago, Illinois: Eastland Disaster \"reputation for being top-heavy and had at several times in the past been reported as listing in an alarming way\"; rolled over while still in port with 2,572 persons on board; 844 perished--making this Chicago's worst single disaster.\n1918: March - November: Spanish influenza , Nationwide: outbreak of Spanish influenza killed over 500,000 people in the worst single U.S. epidemic.\n1918: October 12: The Cloquet-Moose Lake Disaster, Cloquet Minnesota and 25 other communities: destroyed by forest fire, 559 die\n1918: July 9: Train collision, Nashville, Tennessee: 101 killed in a 2-train collision near Nashville\n1921: September 8-10 Flood, Central Texas: Thrall: 32\" in 12 hours (record); 215 deaths\n1925: March 18: Tri-State Tornado, Montana, Illinois, Indiana: The most violent single twister in U.S. history. It caused the deaths of 695 people and injured over 2,000. Property damage was estimated at $16.5 million.\n1927: April 1: Flood, Mississippi River: flooded over 18 million acres killing 313; 670,000 homeless; river levees broke at 47 spots; 750,000 homes underwater\n1928:: The Hurricane of 1928, Okeechobee, Florida: category 5; atmospheric pressure at landfall was measured at 929 mbar (hPa) and winds \"in excess\" of 150 mph; \"at least\" 2,500 deaths; the second-deadliest natural disaster in United States history behind the Galveston Hurricane of 1900 (as of 2004)\n1930's:: Many States \"The Dirty Thirties\": Longest drought of 20th century. Peak periods were 1930, 1934, 1936, 1939, and 1940. During 1934, dry regions stretched solidly from New York and Pennsylvania across the Great Plains to the Calififornia coast. A great \"dust bowl\" covered 50 million acres in the south-central plains during the winter of 1935-1936.\n1935: September 2: Labor Day Hurricane, Florida Keys: category 5 winds on the Saffir-Simpson Hurricane Scale; strongest hurricane to hit the United States coastline last century, wind gusts 150-200 mph; 400+ casualties\n1937: March 18: Texas School Explosion, New London, Texas: over 300 students and teachers died\n1938: May 16: Terminal Hotel Fire, Atlanta, Georgia: 35 dead\n1938: September 21: Long Island Express - The Great Hurricane of 1938, New England: category 5 storm on the Saffir-Simpson Scale with maximum sustained winds of 161 mph; claimed 600 lives\n1942: November 28: Cocoanut Grove Nightclub Fire, Boston, Massachusetts: 499 dead\n1944: July 17: Port Chicago Naval Magazine Explosion, San Francisco, California: 320 casualties\n1946: April 1 1946: Aleutian Tsunami, The Hawaiian Islands: generated by a magnitude 7.1 earthquake in the Aleutian Islands if Alaska; city of Hilo, Hawaii hardest hit with 96 killed; before dissipating, the tsunami it took the lives of more than 165 people and caused over $26 million (1946 dollars) in damage\n1947: April 16 & 17: Texas City Disaster, Texas City, Texas: ship explosion; started with the fire and detonation of approximately 17,000,000 pounds (7,700 tonnes) of ammonium nitrate on board the French-registered vessel SS Grandcamp; the SS Highflyer (or High Flyer), moored about 600 feet away from the Grandcamp and contained an additional 2,000,000 pounds (900 tonnes) of ammonium nitrate and 4,000,000 pounds (1,800 tonnes) of sulfur, exploded about 15 hours after the Grandchamp; considered the worst industrial accident in United States history; more than 516 lives lost\n1955: August 3-20: Atlantic hurricane of 1955, Northeastern United States: Hurricane Connie begins pounding U.S. for 11 days; Hurricane Diane, following Hurricane Connie floods Connecticut River killing 190 and doing $1.8 billion damage; Hurricane Diane kills 200; first billion $ damage storm (N.E. U.S.)\n1956: July 25: SS Andrea Doria collides with eastward-bound SS Stockholm, Off Nantucket, Massachusetts: collision caused 51 deaths; 2 rescuers were also killed - total death count 53; one of history's most famous maritime disasters\n1957: June 27: Hurricane Audrey, Texas and Louisiana: peak of 145 mph winds before making landfall near Sabine Pass, Texas on June 27 - Category 4 hurricane; 12-foot storm surge devastated Cameron, Louisiana, causing $150 million in damage; official death toll 390; unofficial, more than 500; earliest storm of any Atlantic hurricane season to reach Category 4 intensity in recorded history of the basin; Audrey was the strongest storm to form prior to August, and held this record for nearly fifty years before Hurricane Dennis broke it in 2005 (which was itself broken only nine days later by Hurricane Emily). Emily remains the strongest storm ever to form in June.\n1958: December 1: Our Lady of Angels School Fire, Chicago, Illinois: fire in a Catholic elementary school; 92 children and three nuns parished; To Sleep with the Angels : A Story of a Fire\n1960: December 19: USS Constellation, New York Naval Shipyard, Brooklyn, New York: a Kitty Hawk-class supercarrier, was the third ship of the United States Navy to be named in honor of the \"new constellation of stars\" on the flag of the United States; nicknamed 'America's Flagship'; decommissioned on August 7, 2003, after 41 years, nine months and 11 days of naval service; fire swept through Constellation while she was under construction at a Brooklyn Navy Yard pier, injuring 150, killing 50, and doing $75 million worth of damage\n1963: April 10: Atomic-powered submarine Thresher sank, North Atlantic: 129 dead\n1964: March 27: The Great Alaskan Earthquake and Tsunami, Alaska: 90% of the deaths in Alaska during the 1964 earthquake and subsequent tsunamis were due to the tsunamis; largest earthquake in North America and the second largest ever recorded (largest occurred in Chile in 1960); 9 deaths attributed to earthquake; 8.4 - 8.6 on the Richter Scale; 106 deaths due to tsunamis; 115 total deaths in Alaska; other resulting deaths: Newport, Oregon - 4; Crescent City, California - 11; Kalmath River, California - 1\n1967: December 15: The Point Pleasant/Silver Bridge Disaster Silver Bridge spanned over the Ohio River connecting Point Pleasant, West Virgnia and Kanauga, Ohio: suspension bridge constructed in 1928; collapsed claiming 46 lives and injuring 9\n1972: June 9: Burst dam, flood, Rapid City, South Dakota: 238 dead\n1972: February 26: Coal Refuse Dam Failure, Man, West Virginia: dam gave way killing 125 people, injuring 1,000 and leaving 4,000 homeless in Buffalo Creek in Logan County, West Virginia\n1972: July 19: TWA Flight 327 112 Dead, Sioux Gateway Airport, Iowa: interestingly, all information about this incident have been wiped from historical records\n1977: May 28: Beverly Hills Supper Club Fire, Southgate, Kentucky: hotel fire; claimed 165 lives\n1977: July 19: Burst dam, flood, Johnstown, Pennsylvania: excessive rain in a short period of time caused the dam to burst; the flash flood that ensued killed 77 people and caused $325 million in damage\n1978: April 27: Willow Island Cooling Tower Collapse, Willow Island, West Virginia: power plant cooling tower under construction; scaffolding collapsed killing 51\n1979: May 25: American Airlines Flight 191, O'Hare Airport, Chicago, Illinois: crashed, killing all 271 on board and two on the ground; Flight 191 was the deadliest plane disaster on U.S. soil until surpassed by the crashes of American Airlines Flight 11 and United Airlines Flight 175 in the September 11, 2001 attacks.\n1980: November 21: MGM Grand Hotel/Casino Fire, Las Vegas, Nevada: 85 deaths\n1981: July 17: Hyatt Regency walkway collapse, Kansas City, Missouri: two skywalks filled with people at the Hyatt Regency Hotel in Kansas City, Missouri collapse into a crowded atrium lobby killing 114\n1985: August 2: Delta Air Lines L1011-1, Dallas-Fort Worth, Texas: crashed shortly before landing after encountering a wind shear from a passing thunderstorm; eight of the 11 crew members and 128 of the 152 passengers were killed; one person in a passing car was also killed\n1986: August 31: Aeromexico DC-9, Dead, Cerritos, California: collided with a single engine Piper Archer which had made an unauthorized penetration of controlled airspace; all 6 crew members and 58 passengers were killed; the three occupants of the Piper and 18 people on the ground were also killed; total 85 dead\n1987: August 16: Northwest MD82 Crash, Detroit, Michigan: crew neglected to properly set flaps for takeoff; aircraft stalled soon after take-off, crashing onto a highway; all six crew and 148 of 149 passengers were killed; two people on the ground were also killed\n1987: December 7: Pacific Southwest Airlines BAe146-200, near San Luis Obispo, California: recently fired USAir employee used his now invalidated credentials to board the aircraft with a pistol and apparently killed his former manager and both pilots (USAir had recently purchased PSA); all five crew members and 37 passengers killed\n1989: March 24: Oilspill, Prince William Sound, Alaska: Tanker Exxon Valdez hit an undersea reef and spilled 10 million-plus gallons of oil into the water, causing the worst oil spill in U.S. history.\n1989: October 17: Earthquake (San Andréa's fault), San Francisco, California: magnitude 7.1 earthquake; worst earthquake since 1906; 63 deaths, 3,757 injuries, $ 5,900,000,000 damages - most costly natural disaster in the United States at that time\n1989: September 10: Hurricane Hugo, Hit Charleston, South Carolina: Category 5 hurricane that struck Puerto Rico, St. Croix, South Carolina and North Carolina, killing at least 70 people; caused billions of US dollars in damages (mostly in South Carolina), and is still one of the costliest hurricanes in history (surpassed by Hurricane Andrew)\n1990: January 25: Avianca Boeing 707, Flight 52, Cove Neck, New York: aircraft crashed while in a holding pattern awaiting landing at New York's Kennedy Airport; bad weather a factor; 73 of 158 killed\n1992: August 24: Hurricane Andrew, Dade County, Florida: most destructive United States hurricane of record; peak gust of 164 mph--measured 130 feet above the ground--while a 177 mph gust was measured at a private home; 23 deaths in the United States and three more in the Bahamas; $26.5 billion in damage in the United States, of which $1 billion occurred in Louisiana and the rest in south Florida; majority of damage in Florida was due to the winds (the death toll is controversial as many believe there were thousands in the Everglades never accounted for)\n1994: September 8: USAir Flight 427, near Pittsburgh, Pennsylvania: aircraft lost control at about 6,000 feet (1830 meters) during approach; all five crew members and 127 passengers were killed\n1994: January 17: Northridge Earthquake, Los Angeles, California: 6.7 magnitude earthquake; 57 dead, 1500 serious injuries\n1995: April 19: Oklahoma City Bombing, Oklahoma City, Oklahoma: terrorist attack on the Alfred P. Murrah Federal Building, a U.S. government office complex in downtown Oklahoma City, Oklahoma, was destroyed, killing 168 people; largest domestic terrorist attack in the history of the United States and was the largest act of terrorism within U.S. borders until September 11, 2001\n1996: May 11: ValuJet Airlines DC9-32, near Miami, Florida: fire in the cargo caused this plane to crash into the Florida Everglades about 15 miles from the airport; 105 passengers and five crew members were killed\n1996: July 17: TWA Flight 800, Long Island, New York: catastrophic in flight breakup shortly after departure; all 18 crew and 212 passengers perished\n1998: September 2: MD 11 Swiss-Air Flight 111, crashes near Nova Scotia, Canada: aircraft crashed at night in the Atlantic Ocean close to shore about 50 miles southwest of Halifax, Nova Scotia; all 15 crew members and 214 passengers were killed\n1999: October 31: EgyptAir 767-300ER Flight 990, Atlantic Ocean near Nantucket Island, Massachusetts: aircraft crashed into the ocean about 60 miles south of Nantucket Island; NTSB determined that the aircraft departed from controlled flight and crashed into the Atlantic Ocean as a result of flight control inputs by the first officer; all 14 crew members and 203 passengers were killed\n1999: August 18-25: Hurricane Bret, Kenedy County, Texas: winds 125 mph, pressure 944, category 4\n2000: January 31: Alaska Airlines MD83 Flight 261, Off Point Mugu, California: 83 passengers and five crew members were killed\n2001: September 11: Alaska Airlines MD83 Flight 261, New York City, New York; Arlington, Virginia; and Shanksville, Pennsylvania: Hijackers crashed 2 commercial jets into twin towers of World Trade Center; 2 more hijacked jets were crashed into the Pentagon and a field in rural Pennsylvania. Total dead numbered 2,992, including the 19 hijackers. Islamic al-Qaeda terrorist group blamed.\n|Copyright Information: Public Domain.|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:02e9e9ff-b932-4b13-9ff2-8d3806d4e41a>","<urn:uuid:5251be61-6d40-4580-bef6-762b5cd1539c>"],"error":null}
{"question":"Hey! Checking the specs on my hearing aid and electronic case - how do IP ratings work for solids vs liquids protection? Break it down for me.","answer":"IP ratings use a two-digit system where each digit represents different types of protection. The first digit (0-6) indicates protection against solid objects - from no protection (0) to total dust protection (6). The second digit (0-8) indicates water resistance - from no protection (0) to protection against long periods of immersion (8). For example, with hearing aids, a higher second digit means better water resistance, like in IP87 which would work for about 30 minutes in water. However, no hearing aids are completely waterproof, only water-resistant. The ratings help determine if devices can handle specific conditions like rain, sweat, or brief immersion. For solid protection, levels range from protecting against objects over 50mm (level 1) to complete dust protection (level 6).","context":["As a swimmer, you love being in the water. The pool is like your second home (when you were younger, everyone said you were part fish–that’s how often you wanted to swim). The water seems a bit…louder… than normal today. And then you realize your oversight: you went into the pool with your hearing aid in. And you don’t know if it’s waterproof or not.\nUsually, this would be somewhat of a worry. Normally, modern hearing aids are resistant to water to some degree. But being resistant to water is not the same as actually being waterproof.\nWater resistance ratings and hearing aids\nKeeping your hearing aids clean and dry is the best way to keep them in proper working order. But some hearing aids are made so a little splash here and there won’t be a problem. It all depends on something called an IP rating–that’s the officially allocated water resistance number.\nHere’s how the IP rating works: every hearing aid is assigned a two-digit number. The first number shows the device’s resistance against dirt, dust, and other types of dry erosion.\nThe second number (and the one we’re really interested in here) signifies how resistant your device is to water. The device will last longer under water the greater this number is. So a device with a rating of IP87 will be very resistant to sand and work for around thirty minutes in water.\nAlthough there are no hearing aids currently available that are entirely waterproof, there are some that can have a high water resistance rating.\nIs water resistance worthwhile?\nThe sophisticated electronics inside your hearing aid case won’t mesh well with water. Before you go for a swim or into the shower you will definitely want to take out your hearing aid and depending on the IP rating, try not to use them in excessively humid weather. If you drop your hearing aid in the deep end of the pool, a high IP rating won’t help much, but there are other scenarios where it can be useful:\n- If you sweat significantly, whether at rest or when exercising (sweat, after all, is a type of water)\n- You love boating or other water activities that generate over-spray\n- You have a record of forgetting to take your hearing aids out before you take a shower or go out into the rain\n- If the climate where you live is rainy or overly humid\nThis list is just the tip of the iceberg. Of course, what level of water resistance will be adequate for your daily life will only be able to be identified after a consultation.\nYour hearing aids need to be taken care of\nIt’s important to note that water-resistant does not mean maintenance-free. Between sweat-filled runs, it will be in your best interest to ensure that you clean your hearing aids and keep them dry.\nIn some cases, that could mean obtaining a dehumidifier. But in most situations, a clean dry storage place will work fine (depending on where you live). But certain kinds of moisture can leave residue (like sweat), so to get the best benefits, you will also want to take enough time to clean your hearing aids thoroughly.\nIf your hearing aids get wet, what should you do?\nJust because there’s no such thing as a waterproof hearing aid doesn’t mean you need to panic if your hearing aid gets wet. Well, no–mostly because panicking won’t help anything anyway. But you need to give your hearing aids enough time to dry out thoroughly and if they have a low IP rating, we can help you determine if there is any damage.\nHow much damage your hearing aid has sustained can be approximated based on the IP rating. If you can avoid getting your hearing aids wet, you will get the best results. The drier your hearing devices stay, the better.","Rugged Rating Organizations and Standards\nRatings are set by various government agencies, industry groups and/or independent laboratories and are cited by manufacturers in order to establish a more exact degree of environmental protection and reliability. Some of the more common standards include:\nIP Ratings (Ingress Protection) Rating for Equipment and Enclosures\nA three-digit number established by the International Electrotechnical Commission, is used to provide an IP Rating to a piece of electronic equipment or to an enclosure for electronic equipment. The IP code indicates the level, or amount of the protection.\nThe three digits represent three different forms of environmental influence:\nThe first digit represents protection against ingress of solid objects.\nThe second digit represents protection against ingress of liquids.\nThe third digit represents protection against mechanical impact damage.\n(*The third digit is often omitted, resulting in a 2-digit IP Rating covering ingress against solid objects and liquids only).\nThe larger the value of each digit, the greater the protection from that influence. As an example, a product rated as IP573 would be better protected against environmental factors than another similar product that was only rated as IP432.\n|First Number (Solids)||Second Number (Liquids)||Third Number (Mechanical Impact)|\n|0||No protection||No protection||No protection|\n|1||Protected against solid objects over 50mm e.g. hands, large tools.||Protected against vertically falling drops of water or condensation.||Protected against 0.225 joule impact (150g @ 15cm).|\n|2||Protected against solid objects over 12mm e.g. hands, large tools.||Protected against direct sprays of water up to 15° from vertical.||Protected against 0.375 joule impact (250g @ 15cm).|\n|3||Protected against solid objects over 2.5mm e.g. wire, small tools.||Protected against direct sprays of water up to 60° from vertical.||Protected against 0.5 joule impact (250g @ 20cm).|\n|4||Protected against solid objects over 1.0mm e.g. wires.||Protected against water sprayed from any direction. Limited ingress permitted.|\n|5||Limited protection against dust ingress (no harmful deposit)||Protected against low pressure water jets from any direction. Limited ingress permitted.||Protected against 2.0 joule impact (500g @ 40cm).|\n|6||Totally protected against dust ingress.||Protected against high pressure water jets from any direction. Limited ingress permitted. (Shipdeck)|\n|7||N/A||Protected against the effects of immersion between 15cm and 1M.||Protected against 6.0 joule impact (1.5Kg @ 40cm).|\n|8||N/A||Protected against long periods of immersion under pressure.|\nProtected against 20 joule impact (5Kg @ 40Protected against 0.225 joule impact (150g @ 15cm).cm).\nNEMA stands for the National Electrical Manufacturers Association. They provide a forum for the standardization of electrical equipment, enabling consumers to select from a range of safe, effective, and compatible electrical products. The organization has also made numerous contributions to the electrical industry by shaping public policy development and operating as a central confidential agency for gathering, compiling, and analyzing market statistics and economics data.\nEnvironmental ratings for enclosures based on \"NEMA\" Type designations\n|Enclosure Type Designation||Intended Use and Description|\n|1||Indoor use primarily to provide a degree of protection against limited amounts of falling dirt.|\n|2||Indoor use primarily to provide a degree of protection against limited amounts of falling water and dirt.|\n|3||Outdoor use primarily to provide a degree of protection against rain, sleet, wind blown dust and damage from external ice formation.|\n|3R||Outdoor use primarily to provide a degree of protection against rain, sleet, and damage from external ice formation.|\n|3S||Outdoor use primarily to provide a degree of protection against rain, sleet, windblown dust and to provide for operation of external mechanisms when ice laden.|\n|4||Indoor or outdoor use primarily to provide a degree of protection against windblown dust and rain, splashing water, hose-directed water and damage from external ice formation.|\n|4X||Indoor or outdoor use primarily to provide a degree of protection against corrosion, windblown dust and rain, splashing water, hose-directed water, and damage from external ice formation.|\n|5||Indoor use primarily to provide a degree of protection against settling airborne dust, falling dirt, and dripping noncorrosive liquids.|\n|6||Indoor or outdoor use primarily to provide a degree of protection again hose-directed water, and the entry of water during occasional temporary submersion at a limited depth and damage from external ice formation.|\n|6P||Indoor or outdoor use primarily to provide a degree of protection against hose-directed water, the entry of water during prolonged submersion at a limited depth and damage from external ice formation.|\n|7||Indoor use in locations classified as Class I, Division 1, Groups A, B, C or D hazardous locations as defined in the National Electric Code (NFPA 70) (Commonly referred to as explosion-proof).|\n|8||Indoor or outdoor use in locations classified as Class I, Division 2, Groups A, B, C or D hazardous locations as defined in the National Electric Code (NFPA 70) (commonly referred to as oil immersed).|\n|9||Indoor use in locations classified as Class II, Division 1, Groups E, F and G hazardous locations as defined in the National Electric Code (NFPA 70) (commonly referred to as dust-ignition proof).|\n|10||Intended to meet the applicable requirements of the Mine Safety and Health Administration (MSHA).|\n|12 and 12K||Indoor use primarily to provide a degree of protection against circulating dust, falling dirt, and dripping noncorrosive liquids.|\n|13||Indoor use primarily to provide a degree of protection against dust, spraying of water, oil, and noncorrosive coolant.|\nConversion of \"NEMA\" Type to \"IP\" Code designations*\n|Type Number||IP Designation|\n|4 and 4X||IP56|\n|6 and 6P||IP67|\n|12 and 12K||IP52|\n* Table cannot be used to convert \"IP\" Codes to \"NEMA\" Types. See NEMA 250 for additional details.\nMIL-STD (Military Standard) or MIL SPEC (Military Specification)\nIs a series of performance and manufacturing guidelines set by the US Department of Defense for military and commercial equipment and applications. These guidelines specify allowable parts and environmental condition ranges that a tool or other device must be able to operate in to meet compliance.\nMIL-STD 810 E and F are generally accepted as the highest standard for ruggedized testing by mobile computer manufacturers.\nMIL-STD-810G testing is for a range of extreme conditions including 72\" drops, shocks, vibration, humidity, altitude, rain-, dust- and sand-resistance, temperature extremes and thermal shock. MIL-STD-810G, which was created in October 2008, supersedes MIL-STD-810F.\nMIL-STD 810 test method is used to generate confidence in the environmental worthiness and overall durability of material system design. The testing process follows guidelines which include program documentation, program roles, test standards and laboratory test method guidelines for all categories. The laboratory test methods are broken down into 24 categories. The required compliance test categories include:\n|Low Pressure (Altitude)||Method 500.4|\n|High Temperature||Method 501.4|\n|Low Temperature||Method 502.4|\n|Temperature Shock||Method 503.4|\n|Contamination by Fluids||Method 504|\n|Solar Radiation (Sunshine)||Method 505.4|\n|Salt Fog||Method 509.4|\n|Sand and Dust||Method 510.4|\n|Explosive Atmosphere||Method 511.4|\n|Acoustic Noise||Method 515.5|\n|Acidic Atmosphere||Method 518|\n|Gunfire Vibration||Method 519.5|\n|Temperature, Humidity, Vibration, and Altitude||Method 520.2|\n|Icing/Freezing Rain||Method 521.2|\n|Ballistic Shock||Method 522|\nBefore testing can begin, the item has to have environmental exposure, which means that the test item is run under standard ambient conditions to ensure the item is operating properly and to ensure pretest baseline performance data is collected.\nThe actual tests are carried out according to pre-defined test plans and criteria. The tests can be laboratory or natural environment field tests, or a combination, which ever applies. The test procedure is dependent on the environment tested. The procedure(s) and its execution provide the basis for collecting the necessary information.\nAfter completion of each environmental test, the post-test data is examined and recorded in accordance with material specifications and program guidelines. The results are compared with the pre-test data. The post test record includes: test sequence used, deviations from planned test program, performance data, test conditions and a signature of the test team, to name a few. A final test report will be created for each test which includes an analysis of the test results.\nYou may notice some products will carry a MIL-STD 810E rating and some may state they are MIL-STD 810F compliant. MIL-STD 810F is a revision of MIL-STD 810E. The tests and methods are basically the same but much of the standard has been rewritten to provide clearer direction. Many of the changes that can be found with the MIL-STD 810F are minor or administrative in nature, but technical changes and improvements can be found throughout (i.e. additional technical testing guidelines).\nIS (Intrinsic Safety)\nIS is a term representing the Hazardous Location classifications as described in the National Fire Protection Association's (NFPA) National Electrical Code (Article 500). The National Electrical Code (NEC) defines Hazardous Locations as those areas \"where fire or explosion hazards may exist due to flammable gases or vapors, flammable liquids, combustible dust, or ignitable fibers or flyings.\"\nAn intrinsic safety rating details the specific Hazardous Location in which an electrical device can be used without fear of electrostatic discharge that may cause an explosion.\nSUMMARY OF CLASS I, II, III HAZARDOUS LOCATIONS\n|CLASSES||GROUPS||DIVISION I||DIVISION 2|\n|I. Gases, vapors and liquids||A: Acetylene\nB: Hydrogen, etc\nC: Ether, etc\nD: Hydrocarbons, fuels, solvents, etc\n|Normally explosive and hazardous||Not normally present in explosive concentrations (but may accidentally exist)|\n|II. Dusts||E: Metal dusts\nF: Carbon dusts\nG: Flour, starch, grain, plastic, chemical dust\n|Ignitable quantities normally or possibly in suspension||Dust not normally suspended in an ignitable concentration (but may exist)|\n|III. Fibers and flyings||Textiles, wood-working etc.||Handled or used in manufacturing||Stored or handled in storage|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:fb7379ac-ac73-4a09-8e0c-cecfe83a9ebf>","<urn:uuid:a15af1e6-fde8-4514-b3ff-f5d192b1a575>"],"error":null}
{"question":"As a neuroscience researcher, I am curious about experimental replication challenges in psychology - what are the controversies surrounding Kamin's blocking effect replication, and how does this compare to the evidence base for meditation's effects on depression?","answer":"The replication of Kamin's blocking effect has faced significant challenges, with Maes and colleagues reporting fifteen failed replication attempts despite using well-established procedures. This has led to questions about publication bias and the robustness of the effect, though some researchers like Soto argue these failures may be due to specific experimental conditions. In contrast, meditation's effects on depression have been documented across multiple types of practices with more consistent results. Meditation has been shown to reduce stress levels, improve emotional well-being, increase self-awareness, enhance focus, regulate mood, improve sleep, and increase self-compassion. Various forms of meditation, including mindfulness, loving-kindness, transcendental meditation, and yoga nidra, have demonstrated benefits for managing depression symptoms, though it's important to note that meditation is recommended as an adjunct to professional treatment rather than a replacement.","context":["This article needs additional citations for verification. (July 2011)\nIn Kamin's blocking effect the conditioning of an association between two stimuli, a conditioned stimulus (CS) and an unconditioned stimulus (US) is impaired if, during the conditioning process, the CS is presented together with a second CS that has already been associated with the unconditioned stimulus.\nFor example, an agent (such as a mouse in the figure) is exposed to a light (the first conditioned stimulus, CS1), together with food (the unconditioned stimulus, US). After repeated pairings of CS1 and US, the agent salivates when the light comes on (conditioned response, CR). Then, there are more conditioning trials, this time with the light (CS1) and a tone (CS2) together with the US. Now, when tested, the agent does not salivate to the tone (CS2). In other words, an association between the tone CS2 and the US has been \"blocked\" because the CS1–US association already exists.\nThis effect was most famously explained by the Rescorla–Wagner model. The model says, essentially, that if one CS (here the light) already fully predicts that the US will come, nothing will be learned about a second CS (here the tone) that accompanies the first CS. Blocking is an outcome of other models that also base learning on the difference between what is predicted and what actually happens.\nWhile some argue that blocking demonstrates that the organism did not learn the association between the CS2 and the US, this is not necessarily the case. For instance, after a traditional blocking paradigm, the CS2 does not elicit a response (alone). However, if the response to the CS1 is extinguished, the organism will begin to respond to CS2 alone. This demonstrates that the association between the CS2 and the US was initially learned but in comparison to the stronger predictive value of the CS1 there is no conditioned response. However, after extinction, the CS2 does have more predictive value than the now extinguished CS1. However, this finding was not replicated in a later, similar study.\nThe reverse of blocking is often called backward blocking. In backward blocking, the subject is exposed to the compound stimulus (CS1 and CS2 together) first, and only later to CS1 alone. In some human and animal studies, subjects show a reduction in the association between CS2 and the US, though the effect is often weaker than the standard blocking effect, and vanishes under some conditions. This effect is not predicted by the Rescorla–Wagner model although other models have been proposed that capture this effect.\nRobustness of the effect\nMaes and colleagues reported fifteen experiments that attempted to replicate the blocking effect. None of them succeeded despite using procedures well-established in previous literature. They argue that publication bias may have produced a false confidence in the robustness of the effect. However, Soto (2018) has questioned this conclusion arguing that they come as a consequence of the type of stimuli used in these studies, and shows how contemporary models of associative learning can predict these results on the basis of this observation.\n- ^ Kamin, L.J. (1969). Predictability, surprise, attention and conditioning. In B.A. Campbell & R.M. Church (eds.), Punishment and aversive behavior, 279–96, New York: Appleton-Century-Crofts\n- ^ Bouton, M. E.(2007) Learning and Behavior: A Contemporary Synthesis Sunderland, MA: Sinauer\n- ^ Blaisdell, A., Gunther, L. & Miller, R. (1999). Recovery from blocking achieved by extinguishing the blocking CS. Animal Learning & Behavior, 27, 63-76.\n- ^ Holland, P. (1999). Overshadowing and blocking as acquisition deficits: No recovery after extinction of overshadowing or blocking cues. The Quarterly Journal of Experimental Psychology, 52B, 307-333.\nSkibba, Ramin (26 September 2016). \"Psychologists fail to replicate well-known behaviour linked to learning\". Nature News. Retrieved 10 September 2017.\nIn every case, they failed to observe a statistically significant blocking effect.\n- ^ Maes, E.; Boddez, Y.; Alfei, J. M.; Krypotos, A.-M.; D'Hooge, R.; De Houwer, J.; Beckers, T. (2016). \"The elusive nature of the blocking effect: 15 failures to replicate\". Journal of Experimental Psychology: General. 145 (9): e49–e71. doi:10.1037/xge0000200. hdl:1854/LU-7241679. PMID 27428670.\n- ^ Soto, F. A. (2018). Contemporary associative learning theory predicts failures to obtain blocking: Comment on Maes et al.(2016).","Depression is a mental health disorder characterized by persistent feelings of sadness, hopelessness, and a lack of interest or pleasure in activities. It goes beyond temporary feelings of sadness that everyone experiences from time to time. Depression affects how a person thinks, feels, and behaves, and it can lead to a variety of emotional and physical problems.\nThe symptoms of depression can vary from person to person, but some common signs include:\nPersistent sadness or emptiness\nLoss of interest or pleasure in activities once enjoyed\nChanges in appetite and weight (either significant weight loss or weight gain)\nDifficulty sleeping or sleeping too much\nRestlessness or irritability\nFatigue or loss of energy\nFeelings of worthlessness, guilt, or hopelessness\nDifficulty concentrating or making decisions\nThoughts of death or suicide\nDepression can be caused by a combination of genetic, biological, environmental, and psychological factors. It is a complex condition, and the exact causes can vary from person to person. Some common risk factors for depression include a family history of the disorder, certain medical conditions, traumatic life events, chronic stress, and certain medications.\nIt is important to note that depression is a treatable condition. Treatment options may include psychotherapy (such as cognitive-behavioral therapy), medication (such as antidepressant medications), or a combination of both. Lifestyle changes, such as regular exercise, maintaining a healthy diet, and getting enough sleep, can also be beneficial in managing depression.\nMeditation can be a helpful tool in managing and reducing symptoms of depression. Here are some of the benefits that meditation can offer:\nStress reduction: Meditation has been shown to reduce stress levels by activating the body’s relaxation response. This can help alleviate the physical and emotional symptoms of stress that often accompany depression.\nImproved emotional well-being: Regular meditation practice can enhance emotional well-being by increasing positive emotions and reducing negative emotions. It can promote feelings of calmness, inner peace, and contentment, which can be particularly beneficial for individuals struggling with depression.\nIncreased self-awareness: Meditation cultivates a sense of self-awareness, allowing individuals to observe their thoughts and emotions without judgment. This heightened self-awareness can help identify negative thought patterns and behaviors that contribute to depression, enabling individuals to develop healthier coping mechanisms.\nEnhanced focus and concentration: Depression often affects concentration and cognitive function. Meditation practices, such as mindfulness meditation, can improve focus and concentration by training the mind to stay present and redirect attention to the present moment. This can help counteract the cognitive difficulties associated with depression.\nRegulation of mood: Regular meditation practice has been shown to positively impact mood regulation. It can help individuals develop skills to navigate and regulate their emotions, reducing the intensity and duration of depressive episodes.\nImproved sleep: Depression can disrupt sleep patterns, leading to insomnia or excessive sleep. Meditation techniques, such as progressive muscle relaxation or guided imagery, can promote relaxation and better sleep quality, which can indirectly alleviate depressive symptoms.\nIncreased self-compassion: Depression often involves self-critical thoughts and feelings of low self-worth. Meditation practices, such as loving-kindness meditation, can foster self-compassion and self-acceptance. This can counteract the negative self-perception common in depression and promote a more positive relationship with oneself.\nIt’s important to note that while meditation can be a helpful adjunct to treatment for depression, it is not a substitute for professional help. If you’re experiencing symptoms of depression, it’s essential to consult with a mental health professional for a comprehensive evaluation and appropriate treatment plan.\nIn addition to mindfulness meditation, which is commonly associated with depression, there are several other types of meditation that can be beneficial for managing depression. Here are a few examples:\nLoving-Kindness Meditation (Metta): Loving-kindness meditation involves directing positive thoughts, well-wishes, and compassion towards oneself and others. It can help cultivate feelings of love, kindness, and empathy, which can counteract the negative self-perception and social isolation often experienced in depression.\nTranscendental Meditation (TM): TM is a form of meditation that involves the use of a mantra, a specific word or sound, repeated silently to oneself. It aims to quiet the mind and access deeper levels of consciousness. TM has been found to reduce symptoms of depression and anxiety and improve overall well-being.\nYoga and Yoga Nidra: Yoga combines physical postures, breath control, and meditation to promote relaxation, flexibility, and mental clarity. It can help alleviate symptoms of depression by reducing stress, improving mood, and enhancing self-awareness. Yoga Nidra, also known as “yogic sleep,” is a guided meditation technique that promotes deep relaxation and can be particularly helpful for individuals with depression-related sleep disturbances.\nBreath-focused Meditation: This type of meditation involves focusing on the breath as a point of concentration. It can help bring the mind to the present moment, reduce rumination on negative thoughts, and induce a state of calmness and relaxation.\nBody Scan Meditation: Body scan meditation involves systematically directing attention to different parts of the body, noticing physical sensations without judgment. It can promote relaxation, body awareness, and release tension, which can be beneficial for individuals with depression-related physical symptoms or somatic complaints.\nWalking Meditation: Walking meditation involves bringing mindfulness and awareness to the experience of walking. It can be done indoors or outdoors and can help promote relaxation, grounding, and a sense of connection with the body and the environment. Walking meditation can be particularly useful for individuals who find it challenging to sit still for traditional meditation practices.\nIt’s important to remember that different types of meditation work for different individuals, and it may be helpful to explore and experiment with different techniques to find what resonates best with you. It is also recommended to learn meditation techniques from qualified instructors or through guided meditation resources such as books, apps, or online programs."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:bb9ef8f8-708e-491f-b522-51d91040cb36>","<urn:uuid:76f248bd-2697-43e4-b96e-77d227b79446>"],"error":null}
{"question":"How did radio stations' approach to popular music differ between Los Lonely Boys' era and the early days of Top 40?","answer":"In the early 1950s, Top 40 radio was established by Todd Storz based on the concept of frequently repeating currently popular songs, with stations playing about 40 songs in a three-hour rotation. By Los Lonely Boys' time in the 2000s, the approach had evolved significantly - major labels like Epic and Columbia were heavily focused on mainstream radio appeal, initially rejecting songs like 'Heaven' for sounding too 'gospel' despite its eventual success.","context":["Los Lonely Boys didn’t record their Grammy-winning “Heaven” with the intentions of it becoming a radio phenomenon. Big labels like Epic and Columbia had initially rejected the eventual 2004 hit for sounding too “gospel” to gain mainstream popularity.\n“Finally, after we had the song for four years or five years, everybody pretended like this song was great from the beginning,” said bassist Jojo Garza. “We were like, ‘Shut the hell up. Nobody around believed in this song.’”\nShortly after signing with Epic, the West Texas brothers had a thrilling ride, which included Grammy nods, huge support from Willie Nelson and opportunities to play with music legends like Santana, Paul McCartney, Tim McGraw and ZZ Top.\nNow, the Garzas have left the glaring national spotlight for a bit, although they’re still touring around the world and, of course, in Texas.\nWhen my journalistic duty compelled me to ask them a “well, duh” question like, “Why continue to tour Texas,” Garza, good-heartedly replied, “Are you kidding me?” leaving me to blush at my obvious question.\n“We are from Texas. People in Texas deserve music that is bred in Texas,” he said.\nHere is the rest of the interview with Jojo Garza of Los Lonely Boys:\nQ While growing up in San Angelo, you and your brothers Henry and Ringo got your start touring with your dad, who played the Tejano folk music called conjunto. Since y’all are playing more rock ’n’ roll than conjunto, how has that training influenced Los Lonely Boy’s music today?\nA We were really influenced by our father, but our mom’s side was also playing conjunto music — her brother and her dad. She was a very skilled singer. Our aunts and uncles were like you need to learn to speak the language. There was a time that our father branched out from his brothers and he was learning about rock n’ roll, The Beatles and Chuck Berry and Ritchie Valens.\nThen he got into country music — Willie Nelson, Waylon Jennings, Johnny Cash, Ronny Milsap. All those genres of music really connects in this musical web. It’s like people — we’re all one in the same.\nMy dad’s got a new band again with our sister, our stepmom and our cousins and our uncle. They’re Los Capitanas and Las Serenas del Mar and that’s Captains and Mermaids of the Sea. We’re trying to get them to open up and make a record soon.\nQ What kind of music is he playing?\nA He’s doing conjunto. He’s starting all over again. He’s always been musical since he was a little kid. He loves to play for people and he loves to write. He writes all day long. Because he has been doing it for so long, he just doesn’t want to stop. He’s incorporating some stuff in English and incorporating Spanish rhythms and vice versa. He has a record out now.\nA You’ve called your music “Texican Rock ’n’ Roll.” How do you think Chicano rock music is thriving in Texas?\nA I think it’s pretty rare, believe it or not. We’ve been in the business for a while, but it’s still rare to have Texican rockers or Chicano rockers or Latino rockers. We’re finding as we’re going across the country and around the world, that it’s still a small number of people like Carlos Santana, Los Lobos, Ritchie Valens, of course, Los lonely Boys. There are only so many of us, so to keep it alive is important.\nTo be out there and promoting it basically showing the roots from where we come from — you can call it Americana, Tejana, blues — it’s got a wide variety of genres that show Chicanos and Latinos just love music. We sing in our own language too, but we can sing in English, Japanese, and we can play all kinds of instruments, sitars and what not.\nQ Why move to Austin-based Playing in Traffic Records from Epic?\nA It wasn’t really a choice. Once the label drops you, they drop you. To be honest with you, it was a great venture that we had with Epic. We did a lot of good things together. Of course, we give our thanks to the good Lord first, but we have to give thanks to the people here giving the work.\nJust at the final end, they weren’t offering anything, so we weren’t going to be over there with our hand out. Our manager Kevin Womack started a record label Playing in Traffic, and we have our own label. The only reason Playing in Traffic is the big affiliate name is because we don’t have any other artist on Lonely Tone Records yet.\nQ You guys gained wild success with “Heaven.” Are you guys looking for more hits like that?\nA We weren’t looking for a hit. We were just playing music and paying our bills. These guys found us and said, “Hey man, do you want to make a million dollars and sell a million records?”\nNobody liked the song “Heaven” at all. Epic didn’t even want anything to do with it. Neither did Columbia or RCA or anybody. They were like, “No, we’re not doing this gospel thing.” First off, we’re not a gospel band.\nWe are believers in Jesus Christ and God, but we’re not labeling ourselves gospel or rock. We know that we’re human beings, not angels. Just like everybody, we like to have a good time, and go out on Saturday nights with our girls, and not all of that will go in the Gospel category.\nWe’re not looking for another hit. Don’t get me wrong. It would be nice to be touring and have that notoriety. We had an opportunity to win a Grammy, and that’s really nice stuff. The most important thing is that we’re still able to be touring and people still want to freaking hear us.\nQ What was your favorite thing about growing up in West Texas?\nA The heat. You have to learn to endure it — the sun beating down on you with no remorse. It has a lot to do with how we live in West Texas and the music we create and how much water we drink.\nQ You guys released Rockpango last year. How was recording it? Has it diverged from the Los Lonely Boy sound?\nA We’re proud of it. We’re still promoting it and out playing the songs.\nWe hadn’t had a real work out in a few years. It was our first real album in three years. We went into the studio with the frame of mind of getting it done. And at the same time, our names our on it and it’s going down in history. It will never be changed.\nWe went in with a couple ideas of new sounds, experimenting with many different melodies and rhythms and incorporating it into what we call “rockpango” which was a Mexican rock party. People are still digging it. As far as new material, we’re always working on new material.\nLos Lonely Boys live\nWhere: Tequila Rok, 260 Crockett St., Beaumont\nWhen: Doors open at 8 p.m. Friday\nCost: $20 for 18 and up","(Pictured: The Beach Boys do a public appearance to promote their latest album, 1979.)\nThe concept of the Top 40 dates back to the early 50s, and the famous epiphany of Todd Storz, who sat in an Omaha restaurant for several hours one night listening to patrons play the same songs on the jukebox over and over. At the end of the night, a waitress went over to the box, put in a couple of coins, and played the same songs she’d been hearing all night long. It dawned on Storz that perhaps his radio station might prosper by concentrating on currently popular songs repeated frequently.\nBy the 1960s, “Top 40” was the shorthand term for hit-oriented pop music radio—a manageable number of songs that a station could turn over entirely in three hours or so—and it stuck until the early 80s, when it was replaced by “contemporary hit radio,” or CHR. If you cruise through the charts at ARSA you’ll see that playlist and/or chart sizes vary widely; some radio stations charted more than 40 songs and some less. But 40 is the number that captures the imagination. And so reaching the Top 40, especially the Top 40 in Billboard magazine, the bible of the recording industry, is an accomplishment.\nAll of this is the introduction to another ongoing series. I’ve done a couple similar series in the past. Down in the Bottom was about the one-hit artists to peak between #90 and #100 in Billboard from 1955 through 1986. Bubbling Under Adventures looked at all of the songs to peak at #101 from 1955 through 1986. The new series that starts today (and which will appear intermittently, whenever I get around to it) will examine every song that spent just a single week in the Top 40 between 1964 and 1986.\nThere about 150 such songs. Almost exactly half came between 1964 and 1969, while the other half came between 1970 and 1986. The year 1964 had the most, with 17, just nosing out 1965 with 16; the fewest came in 1982 and 1986, with only one each. Ten artists have two songs on the list; everybody else has just one. Some of the songs are quite famous despite their relatively low placing on the Hot 100; others have been completely forgotten.\nRather than going through the list in chronological order, we’ll jump around. Let’s start with some of the most famous acts in history.\nThe Beatles are on the list with “I Don’t Want to Spoil the Party,” which appeared in the Top 40 at #39 during the week of March 20, 1965. It needs an asterisk, however: “I Don’t Want to Spoil the Party” is the separately listed B-side of “Eight Days a Week,” which was at #1 for the weeks of March 13 and March 20.\nOn the subject of asterisks, Bill Haley and the Comets’ “Rock Around the Clock,” which had reached #1 in the summer of 1955, returned to the Top 40 for the week of May 25, 1974, hitting #39 thanks to its use as the theme song for the first season of Happy Days. Later that year, the Beach Boys’ “Surfin’ USA,” a #3 hit in 1963, spent the week of September 28 at #36, thanks to its inclusion in the Endless Summer compilation, which would reach #1 on the album chart one week later.\nThe Beach Boys are one of the acts who appear on this list twice. In 1979, “Good Timin’,” from L.A. (Light Album), spent the week of June 9 at #40. It had been sitting in the vaults since 1974 and has those glorious Beach Boys harmonies, but it’s a little sleepy.\nElvis Presley and Bob Dylan are also on the list. The Elvis version of “Until It’s Time for You to Go” spent the week of March 11, 1972, at #40. Written by Buffy Sainte-Marie, “Until It’s Time for You to Go” was covered by a lot of people in the 70s. Versions by Neil Diamond and the R&B group New Birth also made the Hot 100; Glen Campbell, Barbra Streisand, Cher, and others cut it, too. Dylan’s “Subterranean Homesick Blues,” despite being one of his most famous singles, made only #39 for the week of May 15, 1965 (although it went to #6 on the Easy Listening chart).\nIn the next installment: artists whose lone Top 40 hit was their lone Hot 100 hit."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:3315078f-05bf-481c-91b0-18ecf796318f>","<urn:uuid:3fed004e-43ea-427d-bc78-4d761f0ca6a5>"],"error":null}
{"question":"Which musical production had better commercial success - the 1917 war songs album 'Yankees to the Ranks' with its list price of $16.99, or the Fiddler on the Roof soundtrack that sold over 500,000 copies in the US?","answer":"The Fiddler on the Roof soundtrack had greater documented commercial success, selling over 500,000 copies in the US and being part of the top-grossing film of 1971. While the 'Yankees to the Ranks' album's list price is given as $16.99, there is no information about its sales figures to make a direct sales comparison.","context":["1917: \"Yankees to the Ranks\" presents 25 songs from the year the U.S. declared war on Germany and entered into World War I. The 24-page color booklet includes extensive notes on all the songs and an interpretive historical essay that tells the story of patriotic volunteerism. Old favorite artists such as Billy Murray, Campbell and Burr, and Collins and Harlan are all here in clear restored audio; so too are newcomers Van and Schenck, Marion Harris, Dietrich and Wright, Anna Wheaton with James Harrod, Arthur Fields, and the Original Dixieland Jazz Band on their first record! List price: $16.99\n- Catalogue number: ARCH 9017\n- UPC: 778632905559\n- Original release date: June 12, 2012\n- Running length: 76:58 / 25 tracks\n- Notes & packaging: Includes a 24-page full-color booklet\n- Tracks recorded: 1916-1917\n- Contains racially derogatory language\n- In Archeophone’s Phonographic Yearbook series\nSample all tracks\n|1.||My Own Iona||Rene Dietrich and Horace Wright||1916|\n|2.||For Me and My Gal||Gus Van and Joe Schenck||1917|\n|3.||Over There||American Quartet||1917|\n|4.||Pack Up Your Troubles in Your Old Kit Bag (And Smile, Smile, Smile)||James F. Harrison and the Knickerbocker Quartet||1916|\n|5.||Hush-a-Bye Ma Baby (The Missouri Waltz)||Elsie Baker||1916|\n|6.||Lookout Mountain||Albert Campbell and Henry Burr||1917|\n|7.||Lily of the Valley||Arthur Collins and Byron Harlan||1917|\n|9.||Katinka Medley||Victor Military Band||1916|\n|10.||I Ain’t Got Nobody Much||Marion Harris||1916|\n|11.||‘Till the Clouds Roll By||Anna Wheaton and James Harrod||1917|\n|12.||Good-Bye Broadway, Hello France||American Quartet||1917|\n|13.||Over There||Peerless Quartet||1917|\n|14.||The Star Spangled Banner||John McCormack and Male Chorus||1917|\n|15.||I May Be Gone for a Long, Long Time||Shannon Four||1917|\n|17.||Livery Stable Blues||Original Dixieland Jass Band||1917|\n|18.||Oh Johnny, Oh Johnny, Oh!||American Quartet||1917|\n|19.||Where Do We Go From Here?||Arthur Fields and the Peerless Quartet||1917|\n|20.||Joan of Arc||Henry Burr||1917|\n|21.||Poor Butterfly||Victor Military Band||1916|\n|22.||They’re Wearing Them Higher in Hawaii||Arthur Collins and Byron Harlan||1916|\n|23.||What Do You Want to Make Those Eyes at Me For?||Ada Jones and Billy Murray||1917|\n|24.||They Go Wild, Simply Wild, Over Me||Marion Harris||1917|\n|25.||Over There||Nora Bayes||1917|\n1917: “Yankees to the Ranks” presents 25 songs from the year the U.S. declared war on Germany and entered into World War I. President Woodrow Wilson had kept the nation neutral up through his November 1916 re-election, but the wheel of fortune could not be slowed down. Once Americans caught wind of the infamous Zimmermann Telegram–a German missive to Mexico offering terms in the event of an alliance against the U.S.–they had had enough of the Kaiser’s flaunting of American neutrality. After the April 6th declaration of hostilities, Americans of (almost) every political stripe signed up to help with the war effort, no matter how big or small it might have seemed. This, Archeophone’s fourteenth installment in The Phonographic Yearbook series, tells the story of patriotic volunteerism and presents the soundtrack to the year’s events in clear, masterful restored audio. Old favorite artists such as Billy Murray, Campbell and Burr, and Collins and Harlan are all here; so too are newcomers Van and Schenck, Marion Harris, Dietrich and Wright, Anna Wheaton with James Harrod, Arthur Fields, and the Original Dixieland Jazz Band on their first record!\nThe fad for all things Hawaiian had slowed down by 1917, but not before “My Own Iona” and “They’re Wearing Them Higher in Hawaii” made popular inroads. The former features authentic Hawaiian ukuleles played by Helen Louise and Frank Ferera, while the latter merely engages in predictable, if tuneful, wordplay. The public’s interest in things “exotic” shows up again in the Victor Military Band’s recording of Rudolf Friml’s “Katinka” (a medley of “Your Photo,” “Allah’s Holiday,” and “Rackety Coo”) and Raymond Hubbell’s “Poor Butterfly”–two of the biggest Broadway shows between 1916 and 1917.\n“Jass” and Other Novelties\nThe goofiness of “Lily of the Valley,” expertly staged by Collins and Harlan, sounds like a throwback to an earlier time, while “M-I-S-S-I-S-S-I-P-P-I” has proved to be a timeless child’s play song, here presented by veteran Ada Jones on one of the peculiar early Emerson small discs. Marion Harris’ first releases, on the other hand, of “I Ain’t Got Nobody Much” and “They Go Wild, Simply Wild, Over Me” presaged something musically new afoot. If there were any doubt about the direction popular music was heading, the Original Dixieland ‘Jass’ Band answered the question with what has been called the first jazz record ever released, “Livery Stable Blues.” The players imitate barnyard sounds to humorous effect, giving critics of jazz ammunition as they fired off screeds calling it nothing more than loud animal noises. The music has lasted, whereas the complaints have diminished. We humbly submit that this restoration is as fine as you will find.\nThe War Comes Over Here in Song\nIt may have been the year that the ODJB broke out, but the real story of popular music in 1917 is, of course, the war songs that remain with us to this day. “Over There” was the biggest of them all. The all-time great anthem by George M. Cohan was so popular that at least three versions of it–by the American Quartet, the Peerless Quartet, and Nora Bayes–were among the biggest hits of the year. “Good-Bye Broadway, Hello France” and “I May Be Gone for a Long, Long Time” (by the newly formed Shannon Four) also scored big, as did a rousing version of “The Star Spangled Banner,” by recently-naturalized John McCormack. War-themed numbers of a more comical nature also found willing ears: “Where Do We Go from Here?” by Arthur Fields in front of the Peerless Quartet and “Oh Johnny, Oh Johnny, Oh!” by the American Quartet. “Johnny” was curious for having been published twice, the second sheet music featuring new patriotic lyrics. The original lyrics are here and they were made popular again in World War II by the Andrews Sisters.\n“While you’ve a lucifer to light your fag…”\nBut remember that many of the war songs came originally from the Brits, including “Pack Up Your Troubles in Your Old Kit Bag (and Smile, Smile, Smile),” rendered here by the Knickerbocker Quartet, with baritone James F. Harrison guesting in the lead role. A “lucifer” is a match, and a “fag” is a cigarette. The song and its central character, Private Perks, try to make the best out of a bad–and worsening–situation. Henry Burr’s “Joan of Arc” (also recorded by its lyricist, Willie Weston) is an American tune, but it reflects poignantly on the patron saint of the people of Lafayette, who came to this nation’s aid in its early time of dire need.\nAmidst the crazy novelties and jazz on the one hand and the march to war on the other stand a number of beautiful songs that have stood the test of time. “Hush-a-Bye Ma Baby (The Missouri Waltz)” was originally just a tune that got words added in time for Edna Brown (really Elsie Baker) to make it a haunting masterpiece of 1917. It eventually became Missouri’s state song. Then there’s “Lookout Mountain” by Campbell and Burr, referencing the side of the great mountain that faces Chattanooga, Tennessee, where a girl waits “with a mountain of love for me.” The Sterling Trio (Campbell, Burr, and John H. Meyer) give us “Indiana,” the original recording of the song sung every year by Jim Nabors at the Indianapolis 500. And finally we have the lilting melodies of “‘Till the Clouds Roll By,” from Oh! Boy! performed by its star, Anna Wheaton with James Harrod, and the wedding bliss of “For Me and My Gal” by sensations-to-be Gus Van and Joe Schenck.\nThis release is included in the following packages.\nSave $8 when you order our four yearbooks from the mid-nineteen teens together.\nSave 15% when you order all in-stock editions of our Phonographic Yearbook series together.\nSave 20% on our entire catalogue","Title: Fiddler On The Roof (Original Motion Picture Soundtrack Recording)\nStyle: Soundtrack, Musical\nFormat: MP3 FLAC ASF WMA AIFF AA MPC DXD RA\nFLAC size: 1609 mb | MP3 size: 1429 mb | WMA size: 1760 mb\nAdapted By, Conductor – John Williams (4). Artwork – Bob Cato. Lyrics By – Sheldon Harnick. Music By – Jerry Bock. Performer – Chorus (tracks: 1, 4, 5, 7 to 9, 13), Orchestra. Performer – Molly Picon, Norma Crane, Paul Mann (3), Topol. Soloist – Isaac Stern.\nThe 2001 CD reissue is even more the creature of Williams than of Bock and Harnick, adding several short instrumental orchestral pieces. But it also adds a good previously unheard song, \"Any Day Now,\" sung by Paul Michael Glaser, who played Perchik, and probably intended to replace \"Now I Have Everything,\" although it, too, was left on the cutting room floor of a film that already ran three hours. Fiddler on the Roof, musical.\nAlbum · 2001 · 14 Songs. Chaim Topol, Norma Crane, Patience Collier, Ruth Madoc, Zvee Scooler & \"Fiddler on the Roof\" Motion Picture Chorus. Chaim Topol, Norma Crane, Michele Marsh, Michael Gläser & \"Fiddler on the Roof\" Motion Picture Chorus. 9. Wedding Celebration and the Bottle Dance. John Williams & \"Fiddler on the Roof\" Motion Picture Chorus & Orchestra.\nIsaac Stern Plays Mozart (CD04) (2013). Isaac Stern Plays Mozart (CD03) (2013).\nJohn Williams-Indiana Jones and the Temple of Doom (Original Soundtrack/Film Score, 2009). Wayne Shorter - Speak No Evil (1999). Having seen the film more than once, the CD brings back the memories of certain scenes. Whoever saw the film and loves it will love the soundtrack.\nJohn Williams won an Academy Award, his first, for the Fiddler On The Roof film soundtrack. Williams adapted the original, much-beloved Broadway music composed by Jerry Bock and Sheldon Harnick for the movie, which became the top-grossing film of 1971. The soundtrack has proven equally popular, selling over 500,000 copies in the US. 192 kHz, 24-bit, 96 kHz, 24-bit PCM – EMI/EMI Records (USA) Studio Masters.\nFiddler On The Roof Motion Picture Chorus Matchmaker. Fiddler on the Roof\" Fiddler on the Roof - Tradition. John Williams Prologue And Tradition & Main Title.\nSend \"John Williams\" Ringtones to your Cell. Album: Fiddler On The Roof (Original Motion Picture Soundtrack).\n|A1||Prologue And \"Tradition\" & Main Title||11:16|\n|B1||If I Were A Rich Man||5:24|\n|B4||Miracle Of Miracles||2:04|\n|C3||Wedding Celebration And \"The Bottle Dance\"||3:52|\n|D1||Do You Love Me?||3:11|\n|D2||Far From The Home I Love||3:00|\n|D3||Chava Ballet Sequence||2:33|\n- Record Company – United Artists Music And Records Group, Inc.\n- Manufactured By – United Artists Records, Inc.\n- Copyright (c) – United Artists Records, Inc.\n- Published By – Sunbeam Music Corp.\n- Adapted By [Music], Conductor – John Williams\n- Artwork [Album Design] – Bob Cato\n- Lyrics By [Lyrics For Stage Play And Film By] – Sheldon Harnick\n- Music By [Music For Stage Play And Film By] – Jerry Bock\n- Performer – Chorus* (tracks: A1, B2, B3, C1 to C3, D4), Orchestra*\n- Performer [Starring] – Molly Picon, Norma Crane, Paul Mann , Topol\n- Soloist – Isaac Stern\nNotesDeluxe 2 record set. Gatefold cover plus a two-leaf picture booklet. Orange Cloud Labels with \"Fiddler On The Roof\" printed to left of spindle hole.\nBarcode and Other Identifiers\n- Rights Society: BMI\n- Matrix / Runout (Side 1): UAS-10900-1 77\n- Matrix / Runout (Side 2): UAS-10900-B X SET 3 E 77\n- Matrix / Runout (Side 3): UAS-10900-3 77\n- Matrix / Runout (Side 4): UAS-10900-4 ECK 77\n|UAS 10900||John Williams||Fiddler On The Roof (Original Motion Picture Soundtrack Recording) (2xLP, Album)||United Artists Records||UAS 10900||Canada||Unknown|\n|U 5013||John Williams||Fiddler On The Roof (Original Motion Picture Soundtrack Recording) (8-Trk)||United Artists Records||U 5013||Canada||Unknown|\n|79/F||John Williams , Isaac Stern||John Williams , Isaac Stern - Fiddler On The Roof (Original Soundtrack) (Cass, Album, Unofficial)||Schubert||79/F||Poland||Unknown|\n|UAS 10900||John Williams||Fiddler On The Roof (Original Motion Picture Soundtrack Recording) (2xLP, RE, Gat)||United Artists Records||UAS 10900||Canada||Unknown|\n|72435-35266-2-7||John Williams , Isaac Stern||John Williams , Isaac Stern - Fiddler On The Roof (Original Motion Picture Soundtrack Recording) - 30th Anniversary Edition (CD, Album, RE)||EMI||72435-35266-2-7||Europe||2001|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:a417988f-0907-41c2-a587-973a5970107a>","<urn:uuid:e189cf38-abb0-49cb-aa3d-ab7453f55344>"],"error":null}
{"question":"How do modern agricultural space constraints compare between vertical farming and tobacco curing, and what technological solutions are employed in each method?","answer":"Vertical farming addresses space constraints by expanding production vertically using multilayer indoor systems, significantly reducing land usage compared to conventional agriculture's 1.5 billion hectares. It employs advanced technology including automated sensors, imaging techniques, and artificial intelligence for environmental control. In tobacco curing, space is utilized through specialized barns built facing North and South to control airflow, with leaves hung on eucalyptus sticks holding 144 leaves each. The barns use polyethylene sheeting (visqueen) for humidity control and employ temperature gauges and monitoring systems to maintain precise conditions during the 45-65 day curing period.","context":["Tobacco Farming is as much a science, as it is a process, to Nick Perdomo.\nHang ’em high!\nOnce they arrive at the curing barn the leaves are sewn, tied, and then hung on eucalyptus sticks to dry from 45 to 65 days. Each stick holds 144 leaves. During that time period they’ll release their chlorophyll and seal their colors which will prepare them for the first fermentation process.\nAfter we hang the tobaccos, the most important time period for us are the first 12 to 14 days. That’s the period where the colors are sealed-in as the leaves begin to wilt and start taking on a more yellowish hue. We line our curing barns with visqueen, a polyethylene plastic sheeting that helps maintain humidity, preventing it from dissipating easily through the walls of the barn. For the first 20 days we keep the barns at 75% humidity. If the humidity rises above 75 %, we make a charcoal fire on the floor of the barn. The heat from the fire helps dry the air and bring the relative ambient humidity back down to a 75% level. During this period, we have technicians checking the central veins of the leaves to make sure they’re drying evenly, as well as making sure there is no mold forming around the leaves.\nThe Sealing of Colors\nOne of the ways we control the environment in the curing barns at our tobacco farming operation is the direction in which they are built. Our barns face North and South, because the prevailing winds in Estelí normally tend to blow from East to West. We open the barn door windows when necessary in order to maintain the proper humidity and keep a consistent airflow. Though they need a regulated amount of humidity, the leaves also need a certain amount of air flow to help prevent the leaves from acquiring mold. Colors are very important to us, too; not just because we can use them for wrappers, but to keep everything as consistent as possible. That’s why our motto is to treat every leaf as though it was a wrapper leaf. When you look at the leaves that have been drying longer, you notice they are more brownish and red in color. As the leaves continue to cure, the colors will darken and parallel throughout the leaf. Each leaf will then later be classified by size, texture, and quality.\nAfter the leaves have completed their 45-65 day drying period they’re ready to go through the first fermentation process. We move the leaves to our pre-industry area where the leaves are classified, weighed, and tied into “hands” of 35 leaves each. Because the central vein line in each leaf still has moisture in it, we build piles called pilones, which are essentially compost heaps. We do this because, biochemically, the tobacco processes itself under pressure, while at the same time allows any excess moisture to dissipate.\nThe fermentation period varies depending on the classification of each leaf. Seco leaves, the larger, thinner leaves from the bottom of the plant have the shortest fermentation period. Viso leaves, which come from the central part of the plant, are medium in size, so these leaves take a bit longer to ferment. Ligero leaves, the thickest and most powerful leaves, come from the top of the plant; therefore they take the longest to ferment.\nAs the tobacco ferments, it heats up in the pilon. This heat has to be carefully controlled and monitored, so we have temperature gauges that we place in each pilon. During this initial stage of fermentation, we want the temperature to reach about 110 to 115 degrees. When a pilon reaches its optimal temperature, we must “turn it” so that it does not overheat. We shake the tobacco out, to aerate and cool it down. This is done simply by picking up each hand of tobacco and literally shaking them for a few seconds. After each hand is shaken we begin building another pilon. The top leaves from the first pilon will now go to the bottom of the new one; the bottom leaves will go to the top, while the center leaves will go out and the outer leaves will go in. That is called a “complete rotation,” and it’s done this way so all of the tobacco is fermented as uniformly as possible.\nYou may have heard the expression, “we listen to the tobacco,” and that’s really what we do. By monitoring the temperature inside the pilon, the tobacco tells us when it’s ready to turn. This isn’t something you can do just randomly. We’ll turn each pilon as many times as it takes to ferment it properly. The first fermentation process is complete when the temperature of the pilon maintains its required temperature for a certain period of time without increasing. At this point, we move to the second fermentation period.\nTo start the second fermentation process, the pilon must be broken down and the tobacco receives its first watering using clean, natural water. Remember I told you that we use both traditional methods and modern technology? This watering process, which is done using a sprinkler system, falls under the traditional category. This process has been used for more than 100 years of tobacco farming, and I believe it’s still the best system for preparing tobacco during fermentation.\nDuring the watering process, each hand of tobacco is sprayed with a very fine, cloud-like mist of water. To do this properly, the worker spreads the hand open like a flower, and then wets the leaves turning the bunch in a 360-degree radius under the mist. He then turns the hand over to wet the tail section where the leaves are tied. This ensures that the entire hand is wet inside and out.\nAfter each hand has been watered, another worker carefully shakes the tobacco making sure that there are no heavy droplets of water, which could stain the tobacco. All that should be left is a thin film of water on each leaf, making it moist and supple. After 10 hands are completed, they are tied together and placed in a room standing on the tail end. Once the entire pilon has undergone this watering process it will be aerated for 12 to 14 hours. This rest period is critical as it allows some of the moisture to dissipate before reconstructing the pilon and starting the second fermentation process.\nThis is the phase where the tobacco really begins to take-off, and that’s where we’ll pick it up next month.","Agricultural systems around the world need to adapt to the rapidly changing environmental, demographic, and socioeconomic landscapes, and new alternative practices, such as vertical agriculture, may offer new opportunities to accelerate such adaptation.\nNext Gen Farming Without Soil and 90% Less Water | GRATEFUL\nWhat is vertical farming and why is it important\nModern agricultural systems encompass an estimated 1.5 billion hectares of the world’s surface area. With a growing population and resource needs, the availability of arable land is shrinking rapidly.\nSince the agricultural revolution, conventional agriculture has focused on practices requiring considerable quantities of space, water, fertilizer, and pesticides. The past 50 years have seen an accelerating rate of increase in these requirements as modern food production aims to increase productivity in the hopes of addressing growing food insecurity.\nLooking into the future, yield production is forecasted to decrease due to widespread environmental and socioeconomic changes that will generate unpredictable consequences on food systems.\nIn response, many strategies have been developed as alternatives to conventional agricultural practices. These strategies have focused on key principles and their combination to be effective: require less space, less water, and increase yield per unit of area. Moreover, due to the negative effects of agrichemicals, modern practices have also aimed to use significantly less to avoid potentially adverse effects for humans and animals.\nOne such alternative is the development of vertical agriculture, also referred to as vertical farming. As the name implies, vertical agriculture relies on expanding production vertically and not horizontally. Vertical agriculture is a multilayer indoor plant production system that allows for precise control of growth factors, such as light, temperature, humidity, carbon dioxide concentration, water, and nutrients.\nThis allows for the growing and production of crops year-round, completely independent of solar light and other external conditions. Indeed, vertical agriculture makes use of key concepts within ecology and physiology to optimize growing and fertilization within controlled conditions. For instance, elements of photobiology, thermomorphogenesis, hydroponics, and genetic breeding, are all used commonly across systems of vertical agriculture.\nBenefits, challenges, and disadvantages moving from horizontal to vertical farming\nAs a result of tight control over crop breeding, growing, and harvesting, vertical farming provides several benefits relative to conventional methods of ‘horizontal’ food production. This was the topic of a literature review by Kalantari et al. published in 2016 in the Journal of Landscape Ecology.\nFrom a systems perspective, the enclosed design prevents pests and diseases from entering by the adoption of a high level of hygiene, continuous monitoring, and non-chemical disinfection, providing security from crops. Moreover, recent technology has also allowed for automated control over environmental conditions by using sensors and imaging techniques in combination with crop simulation models and artificial intelligence, limiting the need for physical labor.\nVertical farming also allows for flexible organization, with designs ranging from large vertical walls covered with crops to large hangars or re-used shipping containers that can be transported. Consequently, vertical agricultural systems, can comprise many varying sizes and be located within many different areas from the middle of highly urbanized cities to more suburban or rural areas.\nMoreover, the verticality element of this system also provides nutrient and water flow, helping to reuse costly resources. The reduction in space also means there is a significant increase in yield per area, holding extensive potential for a future world of urbanization.\nFrom an economic perspective, vertical farming also provides for more jobs in localized areas and is community-focused by addressing the needs of immediate areas, which in turn can provide food at a lower price. Finally, the optionality of location for vertical systems also allows producers to reduce transport costs, as consumers may access them within urban areas, or transport can be minimized to nearby areas.\nHowever, despite the design, environmental, and economic advantages, vertical farming also incorporates several issues that remain a challenge to its broader implementation as a system.\nVertical farming has a high energy requirement and needs extensive investment costs to implement and develop successfully. Moreover, indoor issues relating to excessive UV, heat, and ozone-induced plant damage may have unpredictable repercussions for plant growth.\nAdditionally, vertical systems are difficult to adapt to a larger scale. They are costly to build and maintain and have yet to demonstrate the ability to provide food for larger areas than community-scale populations. This would make it difficult to implement in areas at higher risk of food insecurity, such as developing agricultural nations.\nThe lack of empirical research on a broader scale has meant that vertical farming has yet to develop past the concept stage on community levels, as persistent issues make it difficult to break through to a larger scale.\nImage Credit: YEINISM/Shutterstock.com\nGrowing skywards - the implications of vertical farming in a rapidly populating and changing world\nAmong the development of alternative agricultural practices, vertical agriculture provides a promising solution for many of the challenges facing current agricultural policies. However, for vertical systems to be integrated on a larger scale requires further technological progress and economic investment.\nNevertheless, gradually implementing more verticality, or combining it with other practices aiming for more sustainable practices may be promising. For instance, the combination of verticality with other practices such as intercropping may be particularly beneficial for developing more sustainable food systems.\nIncorporating technological progress into vertical systems also holds promise, with automated sensors and machinery able to operate near-independently. Progress in gene editing and plant genome modifications will also allow for faster, bigger, and healthier crops, allowing vertical agriculture to produce more over time.\nThroughout agricultural history, farming systems have typically spread over large spans of land, yet the reduction in arable land, as well as the increase in demand to house growing populations, means that such strategies need to be reconsidered, and vertical agriculture may play a role looking into the future.\nContinue Reading: Benefits of Vertical Agriculture and Hydroponics\n- Beacham, A. M., Vickers, L. H., & Monaghan, J. M. (2019). Vertical farming: a summary of approaches to growing skywards. The Journal of Horticultural Science and Biotechnology, 94(3), 277–283. doi: 10.1080/14620316.2019.1574214\n- Chaudhry A. R. and Mishra V. P.,(2019) A Comparative Analysis of Vertical Agriculture Systems in Residential Apartments, Advances in Science and Engineering Technology International Conferences (ASET), 2019, pp. 1-5, doi: 10.1109/ICASET.2019.8714358\n- Sarkar, A., & Majumder, M. (2015). Opportunities and Challenges in Sustainability of Vertical Eco-Farming: A Review. Journal of Advanced Agricultural Technologies, 2(2). doi: 10.12720/joaat.2.2.98-105\n- SharathKumar, M., Heuvelink, E., & Marcelis, L. F. (2020). Vertical Farming: Moving from Genetic to Environmental Modification. Trends in Plant Science, 25(8), 724–727. doi: 10.1016/j.tplants.2020.05.012"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:6a63e9aa-8e5f-4e96-8a22-aa599a33e84f>","<urn:uuid:3566e03d-b8ac-4d36-b13c-9d56f4d7ba0e>"],"error":null}
{"question":"¿Cuál es la diferencia en temperatura de operación entre el sistema de fotones únicos de la Universidad Hebrea y el sistema de computación cuántica de IBM?","answer":"The Hebrew University's single photon source operates at room temperature (ambient temperatures), while IBM's quantum computing system requires temperatures as close as possible to absolute zero (-273.15°C, -460°F) to maintain qubits in a coherent state.","context":["A compact, efficient single photon source that operates at ambient temperatures on a chip\nQuantum information science and technology has emerged as a new paradigm for dramatically faster computation and secure communication in the 21st century. At the heart of any quantum system is the most basic building block, the quantum bit or qbit, which carries the quantum information that can be transferred and processed (this is the quantum analogue of the bit used in current information systems). The most promising carrier qbit for ultimately fast, long distance quantum information transfer is the photon, the quantum unit of light.\nThe challenge facing scientists is to produce artificial sources of photons for various quantum information tasks. One of the biggest challenges is the development of efficient, scalable photon sources that can be mounted on a chip and operate at room temperature. Most sources used in labs today have to be very cold (at the temperature of liquid Helium, about -270C), which requires large and expensive refrigerators. Many sources also emit photons in undefined directions, making efficient collection a hard problem.\nNow, a team of scientists from the Hebrew University of Jerusalem has demonstrated an efficient and compact single photon source that can operate on a chip at ambient temperatures. Using tiny nanocrystals made of semiconducting materials, the scientists developed a method in which a single nanocrystal can be accurately positioned on top of a specially designed and carefully fabricated nano-antenna.\nIn the same way large antennas on rooftops direct emission of classical radio waves for cellular and satellite transmissions, the nano-antenna efficiently directed the single photons emitted from the nanocrystals into a well-defined direction in space. This combined nanocrystals-nanoantenna device was able to produce a highly directional stream of single photons all flying to the same direction with a record low divergence angle. These photons were then collected with a very simple optical setup, and sent to be detected and analyzed using single photon detectors.\nThe team demonstrated that this hybrid device enhances the collection efficiency of single photons by more than a factor of 10 compared to a single nanocrystal without the antenna, without the need for complex and bulky optical collection systems used in many other experiments. Experimental results show that almost 40% of the photons are easily collected with a very simple optical apparatus, and over 20% of the photons are emitted into a very low numerical aperture, a 20-fold improvement over a freestanding quantum dot, and with a probability of more than 70% for a single photon emission. The single photon purity is limited only by emission from the metal, an obstacle that can be bypassed with careful design and fabrication.\nThe antennas were fabricated using simple metallic and dielectric layers using methods that are compatible with current industrial fabrication technologies, and many such devices can be fabricated densely on one small chip. The team is now working on a new generation of improved devices that will allow deterministic production of single photons straight from the chip into optical fibers, without any additional optical components, with a near unity efficiency.\n\"This research paves a promising route for a high purity, high efficiency, on-chip single photon source operating at room temperature, a concept that can be extended to many types of quantum emitters. A highly directional single photon source could lead to a significant progress in producing compact, cheap, and efficient sources of quantum information bits for future quantum technological applications\", said Prof. Ronen Rapaport, of the Racah Institute of Physics, The Department of Applied Physics, and the Center of Nanoscience and Nanotechnology at the Hebrew University of Jerusalem.\nThe Hebrew University of Jerusalem is Israel's leading academic and research institution, producing one-third of all civilian research in Israel. For more information, visit http://new.huji.ac.il/en.","Europe, Japan: D-Wave would really like you to play with its – count 'em – '2,000-qubit' quantum Leap cloud service\nSolve tricky maths in a fraction of the time... supposedly\nCanadian startup D-Wave Systems has extended the availability of its Leap branded cloud-based quantum computing service to Europe and Japan.\nWith Leap, researchers will be granted free access to a live D-Wave 2000Q machine with - it is claimed - 2,000 quantum bits, or qubits.\nDevelopers will also be free to use the company's Quantum Application Environment, launched last year, which enables them to write quantum applications in Python.\nEach D-Wave 2000Q normally costs around $15m.\nIt is important to note that the debate on whether D-Wave's systems can be considered \"true\" quantum computers has raged since the company released its first commercial product in 2011.\nIf you're worried that quantum computers will crack your crypto, don't be – at least, not for a decade or so. Here's whyREAD MORE\nRather than focusing on maintaining its qubits in a coherent state – like Google, IBM and Intel – the company uses a process called quantum annealing to solve combinatorial optimisation problems. The process is less finnicky but also less useful, which is why D-Wave claims to offer a 2,000-qubit machine, and IBM presents a 20-qubit computer.\nWhile a traditional bit contains either 1 or 0, a qubit can be both at the same time, in a state called superposition, like Schrödinger's cat is simultaneously alive and dead. Using superposition, quantum computers can take advantage of the significantly greater number of possible states, theoretically allowing for vastly superior computing power.\nBut in order to harness this physical phenomenon, a true quantum computer requires temperatures that are as close as possible to absolute zero (-273.15°C, -460°F). Such calculations can also be disturbed by loud noises, bright lights – pretty much any and all interactions with the physical world.\nQuantum computing could help break traditional encryption algorithms and solve complex modelling and combinatorial problems – useful in a wide variety of fields, from molecular biology to global finance. So far, all of these are potential applications – right now, researchers are busy defining developer tools and standards.\n\"Our work with D-Wave has allowed our team and our research partners to develop early applications ranging from a traffic IoT platform, to factory automation and beyond,\" said Masayoshi Terabe, quantum computing project lead at Denso, one of the world's largest car part manufacturers.\n\"Expanding access to more developers and researchers around the world will only serve our efforts as we continue exploring this new frontier of innovation with colleagues here in Japan and overseas.\"\n'Quantum supremacy will soon be ours!', says Google as it reveals 72-qubit quantum chipREAD MORE\nQuantum computing is a hot topic, and getting hotter every day: in January, IBM launched its 20-qubit System Q, available as a cloud service. Berkeley-based startup Rigetti makes its own quantum chips and launched a cloud-based beta in February. And March brought the launch of the Microsoft Quantum Network – the company doesn't have its own chips, but developed a programming language designed for quantum algorithms, called Q#.\nGoogle is working on a 72-qubit chip called Bristlecone, and said it believes the architecture will eventually outperform the most powerful conventional supercomputers – an achievement researchers have dubbed \"quantum supremacy\".\nIntel is taking it slow and working towards a system with a million qubits.\nAlibaba has an 11-qubit quantum system, available in the cloud.\nYet another vendor in this space is Fujitsu, which developed its own \"quantum-inspired\" digital annealing chip, currently being trialled by NatWest.\nDespite the level of interest, last year's report from the US National Academies of Sciences, Engineering, and Medicine suggested that this technology is unlikely to become useful in the next ten years.\nBut that doesn't mean useful research can't be done today: in December 2018, the US Senate passed the National Quantum Initiative Act, earmarking $1.2bn for quantum research funding over the next 10 years. ®"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:2703fe33-9da8-4084-9f57-2b12edfee811>","<urn:uuid:da8987b5-3c41-4f2a-a60d-3992ea9c8503>"],"error":null}
{"question":"How do various protein measurements in dairy feed relate to animal health outcomes, and what monitoring methods can assess protein utilization efficiency?","answer":"Protein measurements in dairy feed are primarily assessed through crude protein (CP) analysis, which measures total nitrogen content. However, CP doesn't distinguish between true protein and other nitrogen sources like ammonia and soluble nitrogen. High levels of these degraded protein products can lead to health issues in dairy cows. When ammonia levels exceed 50 mg/ml of rumen fluid, it crosses the rumen wall, potentially causing alkalosis when rumen pH exceeds 7.2. Blood alcalosis becomes lethal at 1mg/100ml of ammonia. To monitor protein utilization efficiency, milk urea nitrogen (MUN) testing can be used - values above 16 mg/dl signal excess dietary protein relative to carbohydrates. In grazing studies, supplemented cows showed improved protein utilization with lower MUN values (11.3 vs 14.1 mg/dl). Both blood and milk urea remain valuable indicators of nitrogen utilization from the diet.","context":["The nutrient quality of well-managed pastures is often higher than the same plant material harvested as silage or hay. Well-managed spring and autumn pastures may be 25% crude protein or even higher. On some occasions, we have observed 30% crude protein in the spring. The protein content usually decreases during the warmer months and fiber content tends to decrease.\nIs the Protein Content of Pasture Too High?\nThe topic of high protein in pastures has been discussed at various meetings. With high quality pastures often containing 25% protein or higher, even supplementation with low protein supplements will not reduce the total ration crude protein (CP) down to the suggested 16 to 18%. Not only is the total protein too high, but the protein in pasture is highly degradable in the rumen (70 to 80% of CP) and not efficiently utilized in the rumen.\nGrains and supplements that are high in readily fermentable carbohydrates need to be fed to enable rumen microbes to \"capture\" this protein and synthesize microbial protein, which is ultimately utilized by the dairy cow.\nIn addition, the rumen undegradable protein (RUP), and the protein and amino acids reaching the small intestine may be inadequate to meet the requirements of early lactation, high producing cows.\nThe consequences of this excess total and rapidly degradable protein in pasture and inadequate amounts of supplemental fermentable carbohydrates include:\n- fast nutrient passage through the rumen\n- loose manure\n- reduced milk fat percent\n- loss of body condition\n- less than optimum milk production\nWhen excess protein is fed, the protein is deaminated by rumen microbes to ammonia in the rumen. When inadequate dietary carbohydrates are available to \"capture\" the ammonia, the ammonia is absorbed from the rumen. High degradability of the protein in pasture can lead to losses of up to 50% of the ammonia-nitrogen from the rumen at high pasture intake. This ammonia is converted to urea in the liver to detoxify the excess ammonia. The metabolic costs associated with absorption of ammonia and detoxifying ammonia to urea require energy. This is commonly referred to as urea cost, or the energy that is used to excrete the excess ammonia from high protein diets. In turn, this energy is not available for milk production, and results in less than optimal animal performance.\nUrea Cost - Milk Loss\nThe energy required for this \"urea cost\" may result in 3 to 6 lb less milk/cow/day. Pastures with 25% to 30% crude protein instead of 20% can result in this amount of lost milk production. The large milk production loss often seen when cows move to pasture in the spring may be associated with this urea cost. Using nutrition models, up to 9 lb/cow/day lost milk yield may occur in some situations with high producing cows. This process results in inefficient utilization of pasture protein, with perhaps only 16 to 18% of the dietary nitrogen appearing in milk. The excretion of over 80% of the dietary protein is a loss of the most expensive nutrient and is harmful to the environment. Strategic supplementation can increase dietary protein utilization (feed to milk) to about 25%.\nMilk Urea Nitrogen\nThe urea that is produced in the liver from excess rumen ammonia eventually appears in milk as milk urea nitrogen (MUN). Therefore, MUN testing can help monitor excess dietary protein and inadequate dietary carbohydrates. When cows graze pasture as the major forage, the MUN values are generally higher than with a non-grazing feeding program. However, studies at Cornell and Penn State Universities that monitored numerous grazing herds, all of which were feeding supplemental concentrates and forages, found MUN values of 14 to 15 mg/dl. These were not excessive since we consider values above 16 to signal excess dietary protein in relation to dietary carbohydrates.\nIn a recent study at Penn State, we found somewhat elevated MUN in cows fed only pasture (Table 1). Milk yield was 20 lb/day higher when fed 19 lb of concentrate, indicating a greater than 1 lb milk per 1 lb concentrate fed. Milk fat percent was lower and milk protein percent was higher with supplementation. The MUN was nearly 3 mg/dl lower (14.1 vs. 11.3) with supplementation suggesting improved utilization of dietary protein.\nTable 1. Milk production of unsupplemented and supplemented Holstein cows grazing cool season grasses with 20% crude protein during 6-month grazing season.a\n|aBargo et al., 2002. J. Dairy Sci. 85:1777-1792. |\nbCows fed 19 lb concentrate supplement per day.\n|Milk fat, %||3.80||3.30|\n|Milk protein, %||2.96||3.10|\nAfter fertilization with nitrogen (N) from urea, the total and rumen degradable protein in pasture often increases. In turn, the MUN increases because of this higher protein intake. In a recent study at Penn State, we found elevated crude protein in pasture (25 to 30%) about two weeks following each of four N fertilizations (Figure 1). In turn, the MUN reached about 18 to 22 mg/dl, a significant increase compared to the MUN prior to the N fertilization. Clearly, these high MUN values, which occurred following application of 50 lb nitrogen fertilizer/A, indicate a high loss of protein in the rumen and a high \"energy cost\" to excrete the excess urea.\nFigure 1. The crude protein % of pasture and the weekly milk urea nitrogen (MUN) content in relationship to four fertilization times (indicated by arrows) with 50 lb N/acre from urea.\nMilk production typically declined after each fertilizer application. The use of N fertilizers other than urea may have minimized this situation. These data suggest that N fertilization should occur more than two weeks prior to the cows grazing the pasture. Monitoring of MUN in milk can be a useful tool to monitor the dietary protein and energy with a pasture-based system.\nIs Dietary Protein Supplement Needed?\nFrom this discussion, we could conclude that concentrate supplements with proper amounts and types of nonfiber carbohydrates will improve the utilization of the protein in pasture and that the concentrate should contain little additional protein. Grains which supply readily fermentable carbohydrates to \"capture\" some of this ammonia are most important. We generally recommend the concentrate supplements for primarily pasture-based forage program contain about 12 to 14% total protein. This will provide a total ration of about 16 to 18% CP. This supplement may require the addition of a small amount (0.4 to 0.8 lb) of a protein supplement. This supplement can provide some peptides and amino acids that are required by rumen microorganisms.\nDo we need to supply RUP to high producing cows?\nThe National Research Council nutritional guidelines (2001) indicate that rumen undegradable protein is often needed for cows producing more than above 70 to 80 lb of milk/day. Research studies and field experiences do not report a consistent response to increasing the RUP in supplements. A Penn State study found that small amounts (0.5 to 1.0 lb/day) of RUP increased milk protein yield in multiparous cows averaging 80 lb milk/day and fed pasture as the primary forage. Protein sources such as brewers, distillers, corn gluten meal, and roasted/cooked soybeans are good sources of RUP and 0.5 to 1.5 lb of RUP should be considered with grazing cows producing greater than 70 to 80 lb of milk. Costs need to be considered. However, energy is the first limiting nutrient and must be supplemented to the rumen to optimize the capture of nitrogen from pasture and to optimize rumen microbial production.\nTo answer the question in the title; yes, the crude protein content of pasture can be too high and be detrimental to cow performance due to the energy required to excrete the N that is not utilized in the rumen. Strategic feeding of concentrate supplements that contain the proper types and amounts of rumen fermentable carbohydrates can improve the utilization of this excess protein and improve milk yield. In addition, improved utilization of the high protein in high quality pasture may improve reproductive efficiency.\nPublished as pages 71-74 in proceedings from \"Nutrition of Dairy Cows on Pasture-Based Systems\" held March 31, 2003 in Grantville, PA.","At a time when feed represents 40-60 per cent of milk production costs, every gram of nutrient counts. Forage protein content is a key nutritive element that varies greatly according to the crop species, maturity and the soil.\nPoor silage-making processes can lead to the degradation of protein into ammonia and soluble nitrogen inside the silage. When produced in excess, these products are detrimental to the animal and lead to a decrease in performance and health problems.\nAssessing protein content The University of Kentucky's College of Agriculture, Food and Environment extension professor Donna Amaral-Phillips describes forage nutrient content analysis as \"the first key step towards developing a sound and practical nutritional program for a dairy business\". In this analysis, crude protein (CP) is, with energy value, one of the most important nutrients for livestock, which can be a limiting factor for animal performance. Forage protein content varies greatly according to the crop species, maturity and the soil (use of fertiliser).\nIt is, however, important to keep in mind that CP, which appears on the analysis, is an indirect measure of the protein content, based on the total amount of nitrogen in the forage. This is based on the fact that proteins are the only organic molecules containing nitrogen atoms.\nThus, CP level represents protein content, but also other sources of nitrogen with no feeding value, such as soluble nitrogen and ammonia, which come from the degradation of proteins in the forage. Hence, the actual true protein level can vary for a given CP value.\nExcess mineral nitrogen It is typically known that the ensiling process does not alter the CP content of forage. However, if the true protein content and not overall nitrogen content (CP value) is examined, this is different. Indeed, silage fermentation is often a source of protein degradation, known as proteolysis. This results from the action of either: Forage endogenous enzymes, which are released from the plant cells at harvest. Proteolytic micro-organisms, such as clostridia or enterobacteria, present on the plant.\nBoth of these have to be inhibited as quickly as possible following harvest to keep proteolysis to a minimum (see Figure 1). Thus, silage of poor quality (with clostridia and enterobacteria dominating the fermentation) will show proteolysis and high release of ammonia.\nImpact on performance Excessive proteolysis in silage not only decreases the true protein content of the forage, leading to loss of nutritive value, but also produces nitrogen sources that are detrimental to the animal, its health and performance.\nThe excess of ammonia cannot be all used by the rumen microflora and will be absorbed through the rumen wall and transferred to the liver through the blood flow. In the liver, it will be detoxified into urea, which will be eliminated by the kidneys in urine and saliva.\nHowever, the detoxifying capacities of the liver and the kidneys are limited. An excess of ammonia and urea in the blood and an excess of ammonia in the rumen can be observed. These high levels result in several pathologies for the animal, mainly due to the toxicity of ammonia: alkalosis (when rumen pH >7.2), but also other performance and reproduction troubles (see Table 1).\nIn addition, the excretion of excessive urea is an energy-consuming process -- energy that can no longer be used for milk production.\nIt is estimated that the energy lost due to an excess of 2 per cent in protein in the diet is 1.5 megajoules/day, this being equal to a potential of 0.5 litres milk/day.\nMonitoring blood and milk urea remain interesting indicators of nitrogen utilisation from the diet. Ammonia may cross the rumen wall when above 50 milligrams/millilitres of rumen fluid. As soon as the ammonia reaches 1mg/100ml (blood alcalosis), intoxication becomes lethal. Thus, it is crucial to keep protein degradation, or proteolysis, to a minimum during the ensiling process to preserve the nutritive quality of silage (see Table 2).\nControlling proteolysis Good silage preservation aims at maintaining the silage value as close as possible to the fresh forage in the field: this includes the preservation of its protein content. Certain good silage practices can help ensure an optimal fermentation pattern and thus lower protein losses. Here are some recommendations to attain this goal:\nAt harvest: High dry matter (DM) inhibits proteolytic enzymatic activity. Ensiling at correct DM may minimise proteolysis. Proteolytic micro-organisms are mainly located in the soil. A cutting height above 6-7 centimetres should limit soil contamination and the presence of these micro-organisms. Ensuring a rapid and strong acidification at ensiling quickly inhibits the activity of proteases and proteolytic bacteria. The use of specific acidifying inoculants, designed and selected bacteria for forages, accelerates the acidification process, thus limiting proteolysis. Optimal packing and sealing to favour anaerobiosis: the absence of oxygen within the silo inhibits proteases and contributes to a better acidification.\nAfter harvest: Avoid silage heating: the increase in temperature increases Maillard reaction and proteolysis. Certain forages, in particular when high in DM, are prone to heating. This can be prevented by the use at harvest of adapted silage inoculants containing Lactobacillus buchneri 40788, proven to prevent mould development after ensiling and heating.\nArticle provided by Lallemand Animal Nutrition, website www.lallemandanimalnutrition.com<>"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:d778bf6e-e24d-4ca9-be3a-12f17701ec40>","<urn:uuid:6c44ff2f-7406-4753-b90e-c89ab2468e14>"],"error":null}
{"question":"What visibility conditions can divers expect in Noonu Atoll compared to Oman's diving sites?","answer":"In Noonu Atoll, diving visibility typically ranges between 10 to 20 meters. In Oman, visibility varies between 5 and 30 meters across different regions, with visibility sometimes reduced due to nutrient blooms, though these blooms attract large shoals of fish. May is considered the best time for visibility in Oman.","context":["SCUBA DIVING IN OMAN\nOn land, Oman is an amazingly varied country. With mountains, deserts, wadis and beaches, there is no shortage of adventures to be had. The country is growing in popularity, fast becoming one of the Middle East’s most attractive destinations. But the opportunities in Oman don’t end there. With over 2000 km of coastline fringed with warm, nutrient-rich seas, it should be no surprise that there’s excitement to be had under the water too. With coral reefs comparable to the Red Sea and an abundance of sea creatures large and small, scuba diving in Oman is an attractive prospect.\nWHAT CAN YOU SEE?\nOman’s underwater realm supports fascinating life of all shapes and sizes. Whale sharks and white tip reef sharks, green and hawksbill turtles, spinner and bottlenose dolphins – the list goes on. Huge honeycomb moray eels stretch out from the reefs, and at the smaller end of the scale – among vibrant beds of bush and table coral – there’s a huge variety of reef fish, as well as macro level species like seahorses and nudibranches. As such, diving in Oman gives you the opportunity to see an incredible range of aquatic life.\nWATCH THE VIDEO\nWHERE TO DIVE\nThere are dive centres located all around Oman. While the majority of these are close to Muscat, diving opportunities can be found from Musandam in the North to Salalah in the South.\nA small rocky island 4 km from Muscat, it’s also known as Shark Island on account of the black tip reef sharks that cruise the shallow sandbanks. The reefs here are incredibly varied, featuring every type of coral found in Oman. Large schools of fish swim by and the coral gardens are abuzz with life. Honeycomb moray eels sway back and forth hypnotically, and groups of mobula rays can be seen demonstrating amazing acrobatic feats. The calm waters around Fahal Island are suitable for divers of all levels.\nBandar Al Khairan\nAnother location close to the capital, just 25 km from Muscat, Bandar Al Khairan features many different dive sites strung together along a dramatic coastline, where distinctive limestone cliffs descend to the water in well protected small bays and coves. Like Fahal Island, shallow coral reefs are teeming with colourful fish and home to more massive honeycomb moray eels, and the calm waters make the dive sites of Bandar Al Khairan suitable for all levels. They are easily accessible by boat and are well serviced by Extra Divers Qantab.\nAl Munnassir is the wreck of a 3,000 ton navy landing vessel, scuppered by the Oman Navy in 2003 to create an artificial reef. Just a little further down the coast from Bandar Al Khairan, the wreck has become a complex ecosystem in a relatively short time. It is known as one of the best places to see nudibranches, and is home to seahorses and many varieties of soft coral. To dive the Al Munnassir, advanced open water certification is needed.\nThese UNESCO protected islands are regarded as the very best place to dive in Oman. An hour and a half by boat from Muscat, they are home to turtle nesting beaches, rare marine birds and immaculate coral reefs. Indeed, the densest nesting grounds in the world for hawksbill turtles are found here. The underwater environment is truly unspoilt and the nutrient-rich waters attract an abundance of sea life, including whale sharks late in the year. There is diving to suit all levels. Forward planning is required due to permit restrictions and minimum numbers required for the trip. Additionally, the area is often at the mercy of weather and sea conditions.\nSurrounded by the warm waters of the Indian Ocean and Gulf of Oman, Musandam has an incredibly wide biodiversity of marine life. This area is often described as the ‘fjords of Arabia’, with its long brilliant blue inlets bordered by steep-sided mountains, an ancient seabed thrust from the depths. Underwater, the unique deep drops‐offs and upwelling of cool water provide an abundance of plankton, making it a rich feeding ground for a huge variety of species. Dive sites in Musandam are accessible from Khasab or Dibba and are suitable for divers of all levels.\nMirbat (near Salalah)\nIn the far south of Oman, the area around Salalah is like no other. During the summer months, a monsoon known as the khareef sweeps in from the Arabian Sea. Below the surface, cold swells and falling underwater temperatures brought by the khareef make this one of the few places in the world to dive among both coral reefs and kelp forests. With colder water and rougher seas, the marine life is also significantly different. 22 species of whales and dolphins cavort in these waters, and it’s not uncommon to dive alongside huge humpbacks or acrobatic spinner dolphins. Around 20 dive sites are covered by dive centres such as Extra Divers Mirbat. The conditions make diving here more suited to experienced divers.\nWHEN TO DIVE\nIt’s possible to dive all year round in Oman, except in the south where diving is suspended from June-Sept due to the monsoon conditions.\nIn the Muscat area, the best times temperature wise are April-May and Sept-Oct when the water hovers around 28-30°C. In the winter months Jan-Feb, temperatures can dip down to 23°C. When we dived near Muscat in late November, temperatures were a pleasant 25-26°C.\nAround Salalah, the monsoon flips water temperatures on their head, being at their lowest during the summer monsoon. Temperatures rise to around 28°C in October before cooling again over winter and rising again in spring.\nIn Musandam some of the widest ranging temperatures can be seen, swinging from 32°C in summer to 23°C in winter. The best times are April-May and Sept-Nov.\nFor more detailed Oman water temperatures, click here.\nRegions and dive sites can vary greatly but expect visibility to be between 5 and 30 metres. Visibility can sometimes be reduced due to nutrient blooms. The upside however is that such blooms attract large shoals of fish. Visibilty is said to be best in May.\nSeasonal Marine Life\nPerhaps the biggest seasonal draw when diving in Oman is whale shark season. The best time to see the world’s biggest fish is from Sept-Nov with the Daymaniyat Islands being the prime location. The kelp forests off the south coast are the other major seasonal variation, with Oct-Dec being the best time for these.\nThe cost of scuba diving in Oman can vary depending on a couple of factors: location and the type of trip you plan on doing. If you’re diving around Muscat or Salalah, then the cost of a day trip is fairly similar. However, prices for a day trip from Dibba in Musandam can be double. If you’re interested in a liveaboard, then as you’d expect, these trips can be very expensive.\nThe cost of diving in Oman isn’t always immediately apparent when researching where and who to dive with. For example there are plenty of dive centres in Khasab, but prices are not displayed on their websites so you’ll have to get in touch with them directly. By far the most transparent are the four Extra Divers dive centres. They provide a full list of costs and packages on offer. What’s more, as part of a worldwide organisation you can expect their equipment and facilities to be of a good standard.\nPrices for a two dive day trip range from 33-41 OMR around Muscat and Salalah, with full equipment rental from 15-17 OMR. A compulsory dive permit of 4 OMR per day must be paid regardless of location, with a further permit needed for trips to protected areas like the Daymaniyat Islands.\nIt’s possible to dive in Oman without a guide as long as you have enough experience and dive in a buddy system. As such, prices for a guide are often separate so be sure to check this when booking.\nIf you’re interested in the liveaboard experience then there are a few options. Traditional dhow boat trips in Musandam range from $1400 for a 7 day trip. More high end options like the Oman Aggressor start from $2999, with possibilities to dive in Musandam, the Daymaniyat Islands and/or the Hallaniyat Islands in the south.\nOur Experience Diving In Oman\nIf like us you want to combine scuba diving in Oman with a journey around the country, then a two or three dive day trip might be just what you’re looking for.\nAt the start of our month long Oman road trip, we had what turned out to be a couple of really nice dives. Just half an hour from Muscat, Extra Divers Qantab were on our radar. They covered a wide range of good looking dive sites and their pricing was reasonable and readily available. We also managed to sandwich the dive day with two of our favourite wild camp spots.\nThe Dive Sites\nOur excellent dive team took us on the 30 minute speedboat ride to Fahal Island, cruising past dusty orange limestone cliffs and the harbour at Muttrah.","Liveaboard Diving in Noonu Atoll\nWhat To Expect On A Noonu Atoll Liveaboard\nA liveaboard to Noonu Atoll, which lies at the south end of a long atoll group that crowns the north of the Maldives, will usually be running a Northern or Central Atolls itinerary. Noonu is joined with Shaviyani Atoll, above which lies the Maldives' new frontier of Haa Alifu and Haa Dhalu (the Far Northern Atolls). Noonu's location puts it in the center of the Northern Atolls action, and being connected to the far north gives it a bit extra: sharks. Sharks can't often be seen in most of the Northern Atolls, but Noonu is an exception.\nNoonu Atoll Underwater\nMaldives liveaboard diving in Noonu Atoll offers colorful thilas with plenty of soft coral, black coral, and gorgonian fans, some hard coral gardens, and grey reef or blacktip reef sharks. Like its Northern Atolls neighbors, Noonu enjoys great variety and volume of reef fish, hunted by larger predators like tuna and barracuda. The Northern Atolls topography of overhangs and caverns is present in Noonu dive sites, along with some particularly memorable and unique formations, described below.\nDive Sites Of Noonu Atoll\nFor sharks, dive cruises visit Orimas Thila, where a particular channel hosts swarms of grey reef sharks numbering in the twenties or higher. Sharks frequent this kandu to take advantage of the spa services offered by small cleaner wrasse, which they allow inside their gills and mouths to remove parasites and detritus. Expect your dive guide to bring you to a resting point just down-current, where you can kneel in comfort without disturbing the inhabitants. This dive site is ideal for checking out a whole community of sharks doing their thing, from small juveniles to adults over three meters long.\nChristmas Tree Rock is also a must-do for most Noonu Atoll dive tours. The topography here consists of large shelves of life-encrusted rock that divers can peer under and swim through to search for big and small reef inhabitants. Adding to the Christmas tree imagery, small dancing fish of vibrant pink, yellow, and blue ornament the different levels of the ìtreeî with their bright colors. Reef sharks and rays rest in the dark, and large pelagics like tuna stream through the blue water off the sides. With a hard coral garden at the top, Christmas Tree Rock is often cited by divers as one of their favorite Northern Atolls dive sites, as well as a Maldives diving favorite in general.\nDive sites abound in Noonu Atoll, and if your dive dhoni ventures off the beaten track, local dive sites offer plenty to discover. Fairy Meadow, The Dome, and Golden Caves are just a few of the many where healthy, varied fish life, overhangs, and colorful soft corals entrance divers year after year.\nTop Tips for Divers\nIn the Maldives, a new Green Tax of 6 USD per person per night applies for every tourist in the country. The official language is Maldivian, also called Dhivehi.\nGear to bring includes your own mask, booties, fins, and dive computer. These are personalized pieces of equipment which we donít recommend renting. An ill-fitting mask or pair of fins can make diving virtually impossible, and a dive computer is your most-important piece of safety equipment.\nGetting To Noonu Atoll\nLike anywhere in the Maldives, Noonu Atoll is best dived by liveaboard; in no other way can you access so many dive sites, often near uninhabited islands or far from land altogether. The length of liveaboard itineraries that include Noonu Atoll is usually 10 or 11 nights, with a budget of around 350 euros per night. Liveaboards often combine Noonu Atoll with Baa, Raa, Lhaviyani, and potentially the Far Northern Atolls. Sometimes, itineraries also add in the Central Atolls.\nMale is one of the Maldives liveaboard departure locations for Noonu Atoll liveaboards, accessible by direct flights from Dubai, Singapore, and Colombo. On liveaboards combining Noonu with the Far Northern Atolls, however, Hanimadhoo or Dharavandhoo may be the port of departure. These destinations can be reached by domestic sea plane from Male. To get to Male from Europe, America, China, India, and Australia, flights often connect through the nearer airports mentioned above.\nDiving Noonu Atoll is possible all year round, but the northeast monsoon from January to May allows the calmest surface conditions. The water temperature usually stays between 27 and 30 C, and visibility between 10 and 20 meters.\nNoonu Atoll Diving Reviews\n- 7.2 Good\n- 1 Verified Reviews"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:8071401b-4472-4069-8ad7-e7a8bd549c53>","<urn:uuid:374459bc-a39b-483d-aae4-47dd58d9d7e1>"],"error":null}
{"question":"How does music therapy support mental health in unequal settings, and what are the challenges in accessing such treatments across different populations?","answer":"Music therapy provides significant benefits for mental health support, particularly for adults with learning disabilities by developing communication, social skills, and relationship building. It helps with emotional development, self-expression, and stress reduction through non-verbal interaction. However, access to mental health care, including therapeutic interventions, faces significant inequality challenges globally. According to UN data, mental health issues disproportionately affect low and middle-income countries, with 79% of global suicides occurring in these regions. Additionally, marginalized communities, including people living in poverty, refugees, and those in conflict situations, face greater barriers to accessing mental health support.","context":["Free music training for one ALD setting with Music as Therapy International\nWe are offering one UK care setting for adults with learning disabilities the opportunity to partner with us for a fully funded music training project.\nDuring the project, a music therapist will train up to four members of staff to be able to deliver their own therapeutic music groups for the people in their care. The training will take place in their place of work, half a day each week for six weeks. All staff will be able to access free ongoing support from the charity’s Motivation Programme once they have completed their training.\nOur projects have dual benefits for staff and service users; practitioners gain skills, confidence and agency, while those in their care access meaningful music and its therapeutic benefits. Take a look at our theory of change, and watch our UK Film, to get a sense of our work.\nThe positive impact of the training for our staff has been increased confidence and a greater satisfaction in their job role, and meaningful time and participation with the children and young people.Mel Burrough, Head of Therapy at The Children’s Trust, July 2021\nWorking with adults with learning disabilities (ALD) has been a key focus of ours since the inception of our UK Programme in 2016. It was clear to us that adults with learning disabilities have a real need for individualized, sensitive, responsive interaction and meaningful relationship building, but that the UK music therapy profession cannot meet this need alone due to its comparative size.\nMusic can change the way we care.Emma, Partner at The Fields (ALD Residential Centre, Sheffield)\nOur Director Alexia explains: “The research us shows that music can be an effective tool for adults with learning disabilities to develop communication and social skills, interpersonal skills and to build relationships. As a non-verbal medium, it can support the emotional development and self-expression of a person with a learning disability, encourage interaction and diffuse stress associated with interacting. Participation can give an individual opportunities to express their preferences, act independently and make choices. And all of the above is proven to increase self-confidence and self-esteem, acceptance and success.”\nTake a look at our Evidence Base to find out more about this research, our ALD partners’ experience, and the alignment of our approach with the NHS Transforming Care recommendations for creating capable environments. You can also read a case study on our first ALD project, with residential home The Fields, back in 2016.\nIn 2019 Darren, an adult with a learning disability and participant of The Montrose Centre’s weekly music group, told us his story about why the music group matters to him.\nWhat I get out of it is that i’m really good at listening… I like that it’s not all about me.Darren, music participant with learning difficulties, attends The Montrose Centre\nSince the advent of Covid and following worrying reports of the pandemic adversely affecting people with disabilities, we are concerned that this need is now greater than ever. Part of our charity’s Covid emergence plan is to ensure we support the provision of the kind of care that is needed right now, to the people who need it most.\nSo, to ensure care settings can access our training regardless of their budget, we have decided to prioritise a training project for one ALD setting this year and offer to fully fund the project in its entirety.\nTo find out more about what a MasT project entails, have a look at our Meaningful Music in Care leaflet. If you’re interested in discussing this project, please get in contact with UK Programme Coordinator Freya at email@example.com/07792783183. Please remember this is limited to one setting, so prospective partners should indicate interest as soon as you are able to.\nWe looked at the training matrix and saw on-going in depth training was planned to support staff members’ continued learning and was updated when required… training included music therapy.2017 CQC Report rated ‘Outstanding,’ The Fields","The World Federation for Mental Health’s World Mental Health Day 2021 falls on October 10th and researchers are being encouraged to share what they know about mental health inequality and ideas about how to tackle this. Many research studies into the treatment and prevention of mental health conditions are taking place, such that ‘Mental and behavioural disorders’ is the most commonly applied condition category for research registered in the ISRCTN registry.\nThe theme of ‘Mental Health in an Unequal World’ aims to raise awareness of the inequality in access to mental health care, both locally and globally, for marginalised people, particularly for people living in poverty. According to UN 2016 data, “nearly 800,000 persons died every year by suicide, and 79 per cent of global suicides occurred in low- and middle-income countries”.\nThe United Nations has set ensuring healthy lives and promoting mental health and well-being for people as one of its sustainable development goals. The UN sustainable development target 3.4 is to reduce premature mortality from non-communicable diseases, such as mental health conditions, by one-third by 2030 through prevention and treatment and the promotion of mental health and well-being.\nOne such study that is investigating methods to tackle mental health inequality is the ongoing ReSHaPe trial. This study aims to develop an online program that will improve recognition, self-help, and help-seeking for depressive and anxiety symptoms among low-socioeconomic households in Malaysia. The intervention was designed in response to the National Health and Morbidity Survey in Malaysia which showed a high level of mental health issues among the low-income population compared to those with higher incomes.\nSimilarly, a National Mental Health Study in Colombia found high levels of mental distress and illness and poor access to treatment in Colombia’s children and adolescents, including high levels of post-traumatic stress symptoms, following a period of armed conflict. A research study has adapted the DIALOG+ mental health intervention for use in Colombian schools to improve the mental health, resilience, and quality of life of adolescents in post-conflict Colombia during the COVID-19 pandemic.\nPeople living in challenged humanitarian settings such as displaced people, refugees, and those living in conflict/post-conflict situations are at greater risk of mental health difficulties. For children in these settings, their caregivers act as their main protective factors.\nThe Strong Families program was developed specifically for use in low resource settings and was piloted in families living in Afghanistan. The results suggested that this program was effective and feasible in a resource-limited setting and improved child mental health, parenting practices, and family adjustment skills. The effectiveness and acceptability of the Strong Families intervention is now also being evaluated in families living in Iran.\nDue to ongoing political and social conflicts, the number of international refugees has been increasing. Refugees are exposed to severe mental challenges and potentially subject to traumatic experiences so the risk of psychiatric disorders is increased. The REMEX study is investigating the effects of an exercise and sport intervention among refugees living in a Greek refugee camp on mental health.\nOlder people and immigrant groups are both thought to be more likely to experience social isolation and loneliness which can cause worse mental wellbeing. A peer-based intervention using home visits and telephone calls from volunteers to provide emotional support, problem-solving support, and community resource sharing was developed to reduce the social isolation of older Chinese immigrants in Canada.\nThe results of this trial suggested a decrease in loneliness and an increase in resilience in the older people who received the intervention as well as fewer barriers to social participation, fewer depressive symptoms, increased life satisfaction, and happiness.\nSocietal discrimination is likely to have an impact on mental health. Interventions that take into account the specific mental health risks that marginalised communities face, and are designed to meet the needs of these groups, are therefore needed. The Rainbow Mind study uses one such intervention of mindfulness and compassion-based self-care which has been designed for the LGBTQIA+ community in the UK. Additionally, cultural background may play a role in a person’s beliefs about mental illness, their experience of mental illness, and the efficacy of treatment. Researchers are investigating approaches that address this, for example in the ECAT-D trial which aims to evaluate a culturally adapted faith-based treatment approach for Muslim clients with depression in Bradford.\nSimilarly, there are significant mental health related inequalities for the UK Black community as people from Black African and Caribbean backgrounds are four times more likely to be detained under the Mental Health Act, and experience poorer treatment and recovery outcomes in comparison to other ethnic groups. The ON TRAC project aims to address this by developing a mental health awareness and stigma reduction intervention for Black faith communities.\nAccess to mental health care and support is as crucial as ever during the COVID-19 pandemic. The COVID-19 pandemic has highlighted the effects of inequality on health outcomes and has brought additional mental health challenges through infection and illness, bereavement, job loss and insecurity, and social isolation due to physical distancing measures. The COVID-19 pandemic has also led to an increase in using remote methods to deliver care which could allow patients greater access to information and additional support between appointments, but in some resource-limited settings may not be accessible to participants.\nA collection of research compiled by Springer Nature to commemorate World Mental Health Day 2021 can be found on our landing page. You can also find out more about the UN’s sustainable development goals and what we are doing at Springer Nature to support these goals."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:eff8b337-ec11-4efb-87aa-081f5fd1dd32>","<urn:uuid:94af8836-63d1-4932-8987-4d1937bc3b3d>"],"error":null}
{"question":"What are the biological mechanisms of lipid degradation in wastewater treatment, and what practical maintenance requirements exist for FOG control devices? 👨‍🔬","answer":"Lipids can be degraded through biological processes, though they can inhibit anaerobic processes by causing sludge flotation and wash-out. The inhibitory effect is attributed to long-chain fatty acids (LCFAs), which are hydrolysis products of lipids. For practical FOG control, maintenance requirements depend on the device type - grease interceptors must be cleaned before reaching 25% capacity of grease and settled solids (recommended monthly, minimum every three months), while under-sink grease traps require cleaning at least every two weeks (recommended daily). For interceptors, only permitted grease haulers can perform cleaning, while grease traps can be cleaned by establishment employees.","context":["Enhancing anaerobic degradation of lipids in wastewater by addition of co-substrate\nKuang, Yunhua (2002) Enhancing anaerobic degradation of lipids in wastewater by addition of co-substrate. PhD thesis, Murdoch University.\nAnaerobic treatment systems are becoming increasingly popular to treat complex organic wastes that contain carbohydrates, proteins and lipids. Lipids are widely found in sewage and industrial wastewaters. Dairy, edible oil, fat refining, slaughterhouse, wool scouring, meat processing plants and grease-trap wastes from restaurants generate wastewater high in lipids. Although it is well known that lipids can be degraded by biological process, they have been reported to inhibit anaerobic processes by causing sludge flotation and wash-out. The inhibitory effect of lipids in anaerobic process has also been attributed to the long-chain fatty acids (LCFAs) which are the hydrolysed products of lipids. It has been shown that LCFA and lipids inhibit the formation of granular sludge in Upflow Anaerobic Sludge Blanket (UASB) reactors and that the adsorption of LCFAs on to the granules can result in its flotation and washout. It was also found that the degradation of LCFA was very poor.\nVarious techniques have been employed to enhance degradation of lipids and these include physico-chemical pre-treatment, application of two stage treatment employing new reactor designs like Expanded Granular Sludge Bed (EGSB). This thesis investigated the influence of co-substrates, both in the form of hydrolysed products and polymeric form, on reducing the toxicity and enhancing the degradation of LCFA and lipids in a single stage and two stage upflow anaerobic sludge blanket (UASB) reactors. The investigations were carried out on both microbiological and physico-chemical aspects. A combination of techniques including the use of light microscopy (LM), confocal laser scanning microscopy (CLSM), transmission electron microscopy (SEM) and Fluorescent In Situ Hybridisation (FISH) was used to study the characteristics of microbial aggregates and to locate microbial populations within these aggregates. The microbial populations visualised using FISH techniques were Bacteria, Archaea, Methanobacteriaceae, Methanomicrobiales and Methanosarcinaceae. The performance of digesters was also monitored by measuring bulk parameters such as concentration of residual substrates, intermediate products (LCFAs, volatile fatty acids), methane (or gas) production rate and chemical oxygen demand of treated effluent.\nInitially batch assays were carried out to determine the effects of glucose (hydrolysis product of carbohydrate) and cysteine (hydrolysis product of protein) on the toxicity of sodium oleate (hydrolysis product of lipid) to methanogenesis. The results showed that glucose and cysteine addition could reduce the toxicity of sodium oleate on the methanogenesis and enhance the degradation of sodium oleate. While the addition of glucose had a better effect than cysteine on decreasing the toxicity of sodium oleate, the combination of glucose and cysteine had the optimal result to stimulate the degradation of sodium oleate.\nSecondly the effect of addition of glucose, cysteine and sodium oleate as co-substrates on the characteristics of granules in an LCFA fed single stage UASB were investigated. It was shown that the addition of glucose produced the best results on the formation of granules while both cysteine and sodium oleate adversely affected the granule formation. In a LCFA inhibited digester glucose and cysteine addition enhanced the recoveries of different anaerobic microbial communities. Although the effects of glucose and cysteine on the various microbial groups were different, the combination of glucose and cysteine had the optimal results on recoveries of all bacterial groups.\nThe next half of the thesis investigated the influence of starch and yeast extract on the hydrolysis and degradation of canola oil by application of one and two stage UASB reactors. The results showed that the combined addition of protein and carbohydrate had an optimal effect on enhancing the hydrolysis of lipid compared to the addition of only protein or carbohydrate by promoting a balanced growth of the microbial groups. It was also demonstrated that a two- stage UASB reactor performed better in terms of extent of lipid hydrolysis and methanogenesis than a one-stage UASB reactor.\n|Publication Type:||Thesis (PhD)|\n|Murdoch Affiliation:||School of Environmental Science|\n|Item Control Page|\nDownloads per month over past year","FOG Control Program\nFOG stands for Fats, Oils and Greases. FOG is animal and vegetable fats, oils and greases as extracted from a wastewater sample by select solvents in a laboratory. Fats, oils and greases are natural by-products of the cooking and food preparation process.\nThe FOG control program is being implemented by the Buena Park Department of Public Works in order to monitor and reduce the amount of Fats, Oils and Grease that Enters our sanitary sewer system.\nFAQs on FOG\nWhy shouldn’t FOG go down the drain?\nWhen FOG is released into the sewer lines in any amounts, it poses a serious threat to the city's sanitary sewer collection system's ability to remove waste from our community. FOG sticks to the sides of pipes decreasing the pipe's capacity and eventually blocking the pipe entirely. This requires our sewer piping to be cleaned more often and equipment replacement due to grease related damages.\nWhat are the sources of FOG? Who produces FOG?\nCommon sources of FOG include meat fats, dairy products, food scraps, cooking oils, baked goods, sauces, dressings, sandwich spreads, gravies, marinades, dairy products, shortening, lard, butter and margarine.\nFOG is produced by restaurants, cafeterias, delis, bakeries, daycares, assisted living, social halls and residential homeowners – basically, anyone who deals with food, especially while cooking.\nWhy is the issue of SSOs (Sanitary Sewer Overflows) important?\nOverflowing sewers release bacteria, viruses and other pathogens that may be hazardous to human health. The sewage may be released into your business or home, or into our waterways, streets and parks. SSOs are unpleasant and expensive to clean up, and if they occur on your property, it is you, the property owner, who is responsible for the clean-up. Having an SSO occur in your establishment may also lower the number of customers.\nIf the City is responsible for a clean-up, manpower and money are wasted on something that could have been avoided. The costs associated with SSOs are not limited to the Public Utilities clean up costs of containment, removal, and disposal of contaminated materials, emergency line cleaning, disinfectants, sampling and testing, record keeping and documentation, public notification, and OCHCA, EPA & RWQCB enforcement actions. The non-direct costs may include media related costs, property damages, public relations, insurance, worker and public exposure to untreated wastewater (pathogens and viruses) and decreased tourism. These costs will, most likely, trickle down into customers’ sewer bills.\nAre there requirements to control my grease output?\nCurrent California Uniform Plumbing Code (CUPC), which the City of Buena Park adheres to, requires any food service establishment that produces grease laden wastes to install a grease control device.\nWhat type of grease control device do I have and where is it located?\nThere are three types of grease removal devices. One is a large outdoor underground grease interceptor. This is generally made out of concrete and located under manholes outside the restaurant. Another is a smaller indoor grease trap. This is a box which is generally located in the sink area, either above ground or in the floor. The third device is an automatic grease recovery device. This device is a box that separates grease from the water coming out of your kitchen fixtures. The grease is then heated, so that it can be pumped easily to another container, which makes it easy to recycle. This device will most likely be located under a sink or table in your kitchen. If you are unsure of what type of device you have, for your establishment or having problems locating your grease control device, you may contact the FOG Program Officer at (714) 562-3653 or email email@example.com.\nWhat is a grease trap verses a grease interceptor?\nA grease trap is an interior small reservoir built into the wastewater piping closed to the grease producing area. This is normally under the sink but also can be located in the floor. The grease trap is used for conditions where space is limited for an external interceptor. Baffles retain the waste water long enough to separate allowing the grease to rise to the surface. The grease and settled solids can be removed and disposed of properly, either in an exterior grease collection tub or in the garbage. The city recommends grease traps to be cleaned nightly but no less than every two weeks.\nA grease interceptor is an exterior in-ground vault. The vault includes minimum of two compartments with floor between each compartment. These are for larger food service establishments. Interceptors have a minimum capacity of 500 gallons but normally consist of 1000 gallons or more. The city recommends grease interceptors be cleaned monthly but no less than every three months. Click here to see illustrations of a typical plumbing layout and grease trap.\nWill my establishment be inspected?\nYes. In addition to the inspector’s initial inspection to ensure that your grease control device is installed and working properly, an inspector may come from the City of Buena Park to observe normal operations. The inspector has the right to come into your establishment at any reasonable hour.\nWhat will an inspector look for?\nDuring an inspection, they may ask for maintenance and manifest records from licensed grease haulers. These records along with assurance that Kitchen Best Management Practices (BMPs) are properly implemented, will verify compliance with proper waste disposal requirements. The inspector will look to make sure that you have a properly sized grease control device. Then, the inspector will check to make sure that the device is installed and working properly. This includes checking to make sure that it has not been installed backwards, that the baffles are in place and that the device is not leaking, etc. The inspector or city contractor may check to see what volume of grease you currently have in your grease control device and will ask to see your records of maintenance.\nWhat is the grease control device registration?\nFor whichever device you end up using (an interceptor or a trap), you must fill out a grease control device registration application. A city building inspector must come inspect the installation of the grease control device and approve it. The registration application is sent to the City so that a record can be made of your compliance.\nHow big does my grease interceptor have to be?\nThe minimum size for a grease interceptor is 500 gallons, in order to allow for a decent retention time (length of time a drop of water will stay in the tank). The maximum size is 2500 gallons, special approval is required for sizes larger than 2500 gallons by the Building Department.\nHow often should I have my outdoor, in-ground grease interceptor cleaned?\nAs often as it takes to keep below 25% of grease and settled solids. A sludge sampler can be used to determine this volume. A recommended time period is monthly, and the minimum time period between cleanings is three months. A grease interceptor won’t do its job if it isn’t properly maintained. All grease interceptors must be cleaned at least every three months, but some establishments may find it necessary to clean their traps more often. If the establishment has to clean its trap too often, the owner should consider installing a large trap or interceptor. Every interceptor should be cleaned as often as is necessary to avoid exceeding its rated capacity.\nHow often should I have my under-sink grease trap cleaned?\nThe frequency of cleaning for an under-sink grease trap depends upon its size. The City of Buena Park FOG regulations state that under-sink grease traps must be cleaned at least every two weeks. A recommended time period to clean grease traps is daily. A grease trap won’t do its job if it isn’t properly maintained. The trap must also be the proper size in order to work properly. Every trap should be cleaned as often as is necessary to avoid exceeding its rated capacity.\nHow do I clean my grease trap/interceptor?\nThe City of Buena Park requires that you hire an approved and permitted grease hauler to clean out your in-ground grease interceptors. After your device has been installed and inspected, you must maintain your grease control device on a regular basis. If you have an in-ground interceptor tank, the tank must be pumped out completely and sprayed down before it is more than 25% full of solids and grease. The grease hauler who cleans your tank will record this volume. Grease haulers may be retained on contract, and may give you a lower cost for cleaning to do so.\nIf you have a grease trap, you may clean it out yourself. Refer to grease control devise maintenance instructions linked from this website.\nCan I clean the grease interceptor at my food service establishment?\nNot the in-ground, large volume grease interceptor. You must hire a permitted grease hauler to clean it out. However, if you have a smaller indoor grease trap, you may have it cleaned by employees. Refer to the link for interior grease trap maintenance.\nHow do I choose a grease hauler?\nTo service your traps and interceptors, the city has provided a list of grease haulers the FSE may contact directly for service.\nYou have the right to watch the grease hauler and make sure that he or she has pumped out your grease tank fully and has sprayed down the sides. If the grease interceptor is cleaned out properly, that means that you will need it cleaned less frequently, and you are always responsible for the state of your grease control device – so make sure that you’re getting what you paid for. Be sure that you receive a manifest noting the volume of the tank pumped out. Keep the manifests and log sheets on site and accessible for periodic inspections by the City or OCHCA inspectors.\nWhat should I do if I experience a sewer blockage or overflow?\nFirst, call the Buena Park Department of Public Works, FOG Control Program (714) 562-3653. They will come and determine whether the blockage is on your property or City property. If the blockage is occurring on City property and cannot be traced exclusively back to you, then they will perform the clean up. If the blockage is on your property and is obviously due to your improper practices, you will have to hire a plumber to fix the problem.\nWhat do I do with the oil used in deep fryers?\nIf you are using deep fryers in your establishment, contact a rendering company to provide a bin or barrel for regular pick up. Refer to the link for fryer/ yellow grease rendering companies.\nWhat is the difference between yellow grease and brown grease?\nBrown grease means floatable fats, oils, greases and settled solids that are recovered from grease control devices. Brown Grease is composed of floatable FOG and settled solids recovered from grease traps and interceptors. Brown grease is difficult to reuse. The greasy content of the interceptor is known as \"brown\" grease and is generally disposed at a wastewater treatment facility but may become part of renewable energy sources in the future.\nYellow grease means fats, oils, and greases that have not been in contact or contaminated with other sources (water, wastewater, solid waste, etc). An example of yellow grease is fryer oil, which can be recycled into products such as animal feed, cosmetics and alternative fuel. Yellow grease is also referred to as render able FOG.\nShould I use large quantities of detergent to wash grease down the drain?\nProducts such as detergents that claim to dissolve grease may pass the grease down the pipeline and cause problems elsewhere. In short, you remove it from your immediate vicinity only to help create a larger problem downstream.\nShould I use additives to wash grease down the drain?\nAdditives are generally prohibited, as many tend to pass grease down the pipeline and cause problems elsewhere."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:f4928d89-1188-4c65-8b5a-beb36a5288a3>","<urn:uuid:a70c7a74-a326-4be0-9660-ce4b00acd271>"],"error":null}
{"question":"How did schizophrenia research evolve between Büchner's neurological work in 'Lenz' and Semon's psychological theories? What were their different approaches to mental processes?","answer":"Both researchers approached mental processes from different angles and time periods. Büchner's novella 'Lenz' represented a landmark study of schizophrenia, approaching the condition from both a scientific and humanistic perspective, using innovative narrative techniques like free indirect speech to portray the internal experience of mental illness. His approach combined scientific knowledge with profound human sympathy. In contrast, Semon, working later in the early 1900s, focused on the mechanical processes of memory and learning, developing concepts like engraphy (encoding), engram (memory trace), and ecphory (retrieval). While both were scientifically trained (Semon also held a medical degree), they approached mental processes differently - Büchner through literary-clinical observation of mental illness, and Semon through theoretical frameworks of memory and learning processes.","context":["Semon, Richard (1859-1918)\nSEMON, RICHARD (1859-1918)\nRichard Wolfgang Semon is a relatively unknown but nevertheless important figure in the history of research on learning and memory. Although little noticed by both his contemporaries and memory researchers today, Semon anticipated numerous modern theories and, perhaps ironically, created one of the best known terms in the memory literature, engram.\nSemon was born in Berlin on August 22, 1859. His father, Simon, was a stockbroker, and the Semon family became part of the upper echelon of Berlin Jewish society during Richard's childhood. Simon's severe losses in the stock market crash of 1873 imposed a much humbler lifestyle on the family. Semon's older brother, Felix, left Germany after receiving a medical degree and practiced in England, where he became a historic pioneer of clinical and scientific laryngology.\nAs a child, Richard Semon expressed a strong interest in biology and zoology. He attended the University of Jena—a major European center of biological research—and received a doctorate in zoological studies in 1883 and a medical degree in 1886. While at Jena, Semon was influenced heavily by the famous evolutionary biologist Ernst Haeckel, whose monistic philosophy stressed the importance of attempting to unify diverse biological phenomena within a single set of theoretical principles.\nSemon's career as an evolutionary biologist developed rapidly during the 1890s. Shortly after assuming an associate professorship at Jena in 1891, he led a major expedition to Australia in search of the \"missing link.\" The expedition was responsible for the discovery of 207 new species and twenty-four new genera. When he returned from Australia in 1893, Semon continued his research at Jena until 1897, when his life changed dramatically. He became involved with Maria Krehl, then wife of an eminent professor of pathology at Jena, Ludolph Krehl. The ensuing scandal in Jena led to Semon's resignation. He and Maria moved to Munich, where he began working as a private scholar, and the pair eventually married.\nSemon wrote two major books on memory during the next twenty years: Die mneme (1904), translated as The Mneme (1921), and Die mnemischen Empfindungen (1909), translated as Mnemic Psychology (1923). His work attracted little attention, and Semon's acute dismay about his lack of recognition is evident in letters written to his colleague and ally, the Swiss psychiatrist August Forel (Schacter, 1982). Depressed over the neglect of his work, troubled by Germany's role in World War I, and shattered by his wife's death from cancer, Semon took his own life on December 27, 1918.\nTheory of Memory\nA full appreciation of Semon's ideas about human memory requires a look at the biological context from which they emerged. His first book, Die mneme, embedded human memory a more global theory that broadened the construct of memory to include more than simple remembering of facts, events, and the like. Semon argued for viewing heredity and reproduction as forms of memory that preserved the effects of experience across generations. He referred to the fundamental process that subserved both heredity and everyday memory with a term of his own creation, \"Mneme.\" According to Semon, Mneme is a fundamental organic plasticity that allows the preservation of effects of experience; it is Mneme \"which in the organic world links the past and present in a living bond\" (1921, p.12).\nSemon distinguished among three aspects of the mnemic process that he believed are crucial to the analysis of both everyday memory and of hereditary memory, and he described them with additional terms of his own invention in order to avoid the potentially misleading connotations of ordinary language: engraphy, engram, and ecphory. Engraphy refers to the encoding of information into memory; engram refers to the change in the nervous system—the \"memory trace\"—that preserves the effects of experience; and ecphory refers to a retrieval process, or \"the influences which awaken the mnemic trace or engram out of its latent state into one of manifested activity\" (Semon, 1921, p.12). In attempting to apply these constructs to the analysis of hereditary memory—that is, to understanding how the experiences of one organism could somehow influence its progeny—Semon encountered a variety of biological phenomena that led him to place great emphasis on ecphory as a crucial determinant of memory.\nSemon's speculative ideas on hereditary memory met with severe criticism because they relied heavily on the discredited doctrine of the inheritance of acquired characteristics, which had been developed by the French biologist Lamarck (Schacter, 2001). Nevertheless, the concern with ecphoric processes that emerged from this analysis enabled Semon to develop new perspectives on human memory that elaborated without any reference to hereditary phenomena in his second book, Die mnemischen empfindungen. At the time that Semon wrote this book, memory researchers paid almost no attention to the ecphoric or retrieval stage of memory; they were caught up almost entirely with processes occurring at the time of encoding or engraphy (Schacter, 2001; Schacter, Eich, and Tulving, 1978). By contrast, Semon developed a detailed theory of ecphoric processes and argued that succssful ecphory requires that the conditions prevailing at the time of engraphy (i.e., encoding) are partially reinstated at the time of ecphory. He laid great emphasis on this latter idea, elevating it to a \"Law of Ecphory.\" This concern with the relation between conditions of engraphy and ecphory anticipated rather closely such modern notions as the encoding-specificity principle and transfer-appropriate processing.\nSemon also developed novel ideas about the beneficial effects of repetition on memory. In contrast to the then widely accepted idea that repetition of a stimulus improves memory by strengthening the preexisting engram of that stimulus, Semon argued that each repetition of a stimulus creates a unique, context-specific engram; at the time of ecphory, the multiple, separate engrams are combined by a resonance process that Semon termed homophony. This multiple-engram approach to repetition effects, with its strong emphasis on ecphoric processes, anticipated a number of recently influential conceptualizations, such as the multiple-trace model developed by Hintzman and colleagues (Schacter et al., 1978).\nNotwithstanding the prescience of many of Semon's ideas, his contemporaries ignored his contributions. This neglect may be due to several factors: his theoretical emphasis on ecphoric processes at a time when few were interested, his social isolation as a private scholar without institutional affiliation, and his discredited Lamarckian approach to hereditary memory. Curiously, the one construct developed by Semon that appropirated by subsequent researchers—the engram—did not represent a novel contribution and was one of the less interesting parts of his otherwise innovative theoretical approach.\nSchacter, D. L. (2001). Forgotten ideas, neglected pioneers: Richard Semon and the story of memory. Philadelphia: Psychology Press.\nSchacter, D. L., Eich, J. E., and Tulving, E. (1978). Richard Semon's theory of memory. Journal of Verbal Learning and Verbal Behavior 17, 721-743.\nSemon, R. (1904). Die Mneme. Leipzig: W. Engelmann.\n—— (1909). Die mnemischen empfindungen. Leipzig: W. Engelmann, Leipzig.\n—— (1921). The mneme. London: Allen and Unwin.\n—— (1923). Mnemic psychology. London: Allen and Unwin.\n\"Semon, Richard (1859-1918).\" Learning and Memory. . Encyclopedia.com. (November 18, 2018). https://www.encyclopedia.com/psychology/encyclopedias-almanacs-transcripts-and-maps/semon-richard-1859-1918\n\"Semon, Richard (1859-1918).\" Learning and Memory. . Retrieved November 18, 2018 from Encyclopedia.com: https://www.encyclopedia.com/psychology/encyclopedias-almanacs-transcripts-and-maps/semon-richard-1859-1918\nEncyclopedia.com gives you the ability to cite reference entries and articles according to common styles from the Modern Language Association (MLA), The Chicago Manual of Style, and the American Psychological Association (APA).\nWithin the “Cite this article” tool, pick a style to see how all available information looks when formatted according to that style. Then, copy and paste the text into your bibliography or works cited list.\nBecause each style has its own formatting nuances that evolve over time and not all information is available for every reference entry or article, Encyclopedia.com cannot guarantee each citation it generates. Therefore, it’s best to use Encyclopedia.com citations as a starting point before checking the style against your school or publication’s requirements and the most-recent information available at these sites:\nModern Language Association\nThe Chicago Manual of Style\nAmerican Psychological Association\n- Most online reference entries and articles do not have page numbers. Therefore, that information is unavailable for most Encyclopedia.com content. However, the date of retrieval is often important. Refer to each style’s convention regarding the best way to format page numbers and retrieval dates.\n- In addition to the MLA, Chicago, and APA styles, your school, university, publication, or institution may have its own requirements for citations. Therefore, be sure to refer to those guidelines when editing your bibliography or works cited list.","Lenz (written 1835, first published 1839)\nThis novella is based on a period of twenty days in the life of the Sturm und Drang playwright Jakob Michael Reinhold Lenz (1751-1792). From 20 January-8 February 1778 Lenz stayed with Pastor Johann Friedrich Oberlin (1740-1826) in Waldersbach in the Steintal. Oberlin wrote a report of Lenz’s twenty-day stay with him. This report became the principle source of Büchner’s novella ‘Lenz’. The full report was not published until after Büchner’s death in 1839, but extracts from the report were published in December 1831 in an essay by Büchner’s friend August Stöber, ‘Der Dichter Lenz’, which appeared in the Morgenblatt für gebildete Stände; The Morning Paper for Educated Classes. In May 1835 Büchner received a handwritten copy of Oberlin’s report from August Stöber. Büchner was also able to draw on Lenz’s own letters and the anecdotal evidence of Oberlin’s friends, e.g. Johann Jakob Jaeglé, the father of Büchner’s fiancée Wilhelmine Jaeglé, who had performed the funeral service for Oberlin in 1826.\nThe novella is a landmark study of schizophrenia, informed by Büchner’s scientific knowledge (he was a neurologist himself). Pastor Oberlin’s attempts to console Lenz with religion fail completely, as Lenz is afflicted by a terrible boredom and ennui. Despite the third person narrative, Lenz’s condition seems to be portrayed from the inside, until it takes on the dimensions of an existential crisis:\ndie Welt, die er hatte nutzen wollen, hatte einen ungeheuern Riß, er hatte keinen Haß, keine Liebe, keine Hoffnung, eine schreckliche Leere und doch eine folternde Unruhe, sie auszufüllen. Er hatte Nichts.\nthe world, which he had wanted to be of use to, had an enormous crack through it, he had no hate, no love, no hope, a terrible emptiness and yet an agonising disquiet, [an urgency] to fill it. He had nothing.\n‘Lenz’ is narrated in the third person, but the narrator is barely evident as an independent voice; most of the narrative is given from Lenz’s own perspective in the form of free indirect speech (in German this is known as erlebte Rede [lived speech]). For a discussion of the use of free indirect speech in ‘Lenz’ see below, Roy Pascal (1977). Like Woyzeck, ‘Lenz’ is also notable for its use of parataxis. Parataxis is the placing together of sentences, clauses or phrases without using conjunctive words. The use of parataxis in ‘Lenz’ gives the impression of a medical report, like a list of occurences. Büchner’s use of free indirect speech combined with parataxis in ‘Lenz’ creates an antilinear, fragmented form of narrative, which anticipates much 20th-century and 21st-century fiction including Franz Kafka, Samuel Beckett and Thomas Bernhard. Peter Schneider’s novel Lenz (1973) is influenced in terms of both content and form by Büchner’s ‘Lenz’. Büchner’s ‘Lenz’ also seems to have had strong influence on East German writers (see Dennis Tate, below).\nThe Kunstgespräch; The Conversation about Art\nLenz is visited by his friend Christoph Kaufmann and the two of them have a conversation about art, the famous Kunstgespräch; Conversation about Art. Kaufmann admires the literature of German idealism, but Lenz disagrees fiercely, saying that those authors who present an idealised, transfigured version of reality are guilty of an arrogant falsification:\nDie Dichter, von denen man sage, sie geben die Wirklichkeit, hätten auch keine Ahnung davon, doch seien sie immer noch erträglicher, als die, welche die Wirklichkeit verklären wollten. […] Dieser Idealismus ist der schmählichste Verachtung der menschlichen Natur.\nThe authors, about whom one says that they depict reality, really have no idea about it, but they still much more bearable than the authors who want to transfigure reality […] This idealism is the most shameful scorn of human nature.\nInstead of this, Lenz argues, one should immerse oneself in the life of the commonest people and things:\nMan versuche es einmal und senke sich in das Leben des Geringsten und gebe es wieder, in den Zuckungen, den Andeutungen, dem ganzen feinen, kaum bemerkten Mienenspiel; er hätte dergleichen versucht im »Hofmeister« und den »Soldaten«. Es sind die prosaischsten Menschen unter der Sonne; aber die Gefühlsader ist in fast allen Menschen gleich, nur ist die Hülle mehr oder weniger dicht, durch die sie brechen muß. Man muß nur Aug und Ohren dafür haben.\nOne should try for once to immerse oneself in the life of the lowest things and people and reproduce it, in the tics, the suggestions, in the play of facial expressions which are very fine, hardly noticed. He had attempted to do this in [his plays] The Tutor and The Soldiers, with the most mediocre people under the sun; but the vein of feeling is the same in almost all people, the only difference is that the outer crust, through which one must break, is more or less thick.\nThese statements can be understood as Büchner’s own artistic manifesto, in ‘Lenz’ he combines a scientific perspective with a profound human sympathy with his subject.\nFurther Reading in English\nJames Crighton, Büchner and Madness: Schizophrenia in Georg Büchner’s Lenz and Woyzeck (Lewiston, NY: Mellen, 1998)\nCarlos Gasperi, ‘Recursive Mindscapes: Noematic Confusion in the Kunstgespräch of Georg Büchner's Lenz’, Germanic Review 87:1 (2012), 35-56\nDavid Horton, ‘Transitivity and Agency in Georg Büchner's Lenz: A Contribution to a Stylistic Analysis’, Orbis Litterarum 45:3 (1990), 236-47\nDennis F. Mahoney, ‘The Sufferings of Young Lenz: The Function of Parody in Büchner's Lenz’, Monatshefte 76:4 (1984), 396-408\nRoy Pascal, ‘Georg Büchner: Lenz’, in Pascal, The Dual Voice: Free Indirect Speech and its functioning in the nineteenth-century European novel (Manchester: Manchester University Press, 1977), pp. 60-66\nRoy Pascal, ‘Büchner’s Lenz – Style and Message’, Oxford German Studies 9 (1978), 68-83\nJohn Reddick, ‘“Man muß nur Aug und Ohren dafür haben”: Lenz and the problems of perception’, Oxford German Studies 24 (1995), 112-44\nErika Swales, ‘Büchner, Lenz’ in Landmarks in German Short Prose, ed. by Peter Hutchinson (Oxford and Bern: Peter Lang, 2003), pp. 79-94\nMartin Swales, ‘Büchner: Lenz’, in Martin Swales, The German Novelle (Princeton, NJ: Princeton University Press, 1977), pp. 99-113\nDennis Tate, ‘“Ewige deutsche Misere?”? GDR Authors and Büchner’s Lenz’, in Culture and Society in the GDR, ed. by Graham Bartram and Anthony Waine, GDR Monitor Special Series 2 (Dundee, 1983), pp. 85-99\nJohn Walker, ‘Büchner and Real Presence: A Reading of the Kunstgespräch in Lenz’, in Georg Büchner: Contemporary Perspectives, ed. by Robert Gillett, Ernest Schonfield and Daniel Steuer (Leiden: Brill, 2017), pp. 281-92\nAndrew Webber, ‘Charting Extraterritorial Identity in the Opening of Lenz’, in Georg Büchner: Contemporary Perspectives, ed. by Robert Gillett, Ernest Schonfield and Daniel Steuer (Leiden: Brill, 2017), pp. 244-60\nFurther Reading in German\nJennifer Clare, ‘“Auf dem Kopf gehen”. Peter Schneiders Lektüre von Büchners Lenz vor dem Horizont der Literatur der deutschen Studentenbewegung’, in Georg Büchner: Contemporary Perspectives, ed. by Robert Gillett, Ernest Schonfield and Daniel Steuer (Leiden: Brill, 2017), pp. 261-80\nChristian Neuhuber, Lenz-Bilder: Bildlichkeit in Büchners Erzählung und ihre Rezeption in der bildenden Kunst (Vienna and Cologne: Böhlau, 2009)\nWeb Link in German\nFree audio download of ‘Lenz’"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"sensitive"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:77e8efd1-a1e8-41cd-abfe-d2667a70512e>","<urn:uuid:34b7ed90-96d6-46b9-8525-84c7b93db2aa>"],"error":null}
{"question":"What specific nutrient enhancement was achieved in golden rice through genetic modification?","answer":"Golden rice was modified to produce beta-carotene, a nutrient that human bodies use to produce vitamin A. This was achieved by identifying and isolating beta-carotene-producing genes from different species including daffodils, bacteria, and corn, and then inserting these genes into traditional rice seeds.","context":["by Art Li\nGMOs are highly contentious for their presumed unhealthiness and danger to humans, and also for their questionable role in sustaining large agri-businesses and the economic frameworks they uphold. What does science say about GMO tech, and how does it intersect with the role of GMOs on the global market?\nMarch 28, 2016\nTranscript and Annotations below:\nGMOs – they’re in our food. They ARE our food. They could cause cancer. But, what impacts could they have on a broader social scale? Let’s find out!\nHello! Art again here to talk about another misunderstood food, or rather, category of foods. We’ll be discussing GMOs in this mini-series – some of the science behind how they are created, their possible effects on the human body, and finally, some of the sociopolitical and economic aspects behind their use.\nOne thing I want to disclose before diving into some of the details is that this video is made operating under the assumption that the genetic modification of living organisms is ethical. While it is (and should be) up for debate whether or not mankind “playing God” and altering DNA, is or is not ethical, this video is intended solely to discuss the effects of GMO research and consumption in addition to the rationale for their use. I am not personally advocating for or against the use of GMOs – i merely hope to provide information for folks to make their own best decisions about the GMOs that are and will likely to continue to be present in our food and stores.\nHowever, we can’t start talking about GMOs without first defining what they are. According to the World Health Organization, GMO stands for Genetically Modified Organism – any organism that has had its genetic material, or DNA, directly altered by biotechnological processes . DNA stands for deoxyribonucleic acid, and is the blueprint for all life on this planet. It is the substance within all living cells that contains instructions for them to self-replicate and organize themselves into the bodies we inhabit. Pretty neat stuff.\nOn a more detailed level, DNA holds instructions for cells on how to create proteins. If DNA is the blueprint, proteins are the building blocks for life. All of our of cells, and a lot of the junk our body produces are comprised of proteins. DNA holds the instructions for which specific proteins should be produced by our bodies at what times, and the minute differences and interactions between these proteins sum up to form our bodily processes and physical forms. The process by which DNA is translated into these proteins is called gene expression.\nWhat GMO technology does is alter the baseline DNA that cells use as a template for gene expression. Researchers first identify a gene or DNA sequence of interest that they wish to engineer into an organism. In agriculture this is commonly a gene that produces a protein which results in herbicide resistance, drought tolerance, or improved nutrient content. This gene could be from the same organism, or it could be from an entirely different species. As an example, “golden rice” is rice that has been modified to produce beta-carotene, a nutrient that our bodies use to produce vitamin A. Genes that produce beta carotene were first identified in various different species (daffodils, bacteria, and corn). The genes were isolated and purified from their native species, and then inserted into traditional rice seeds to produce golden rice plants.\nThis insertion process is done primarily using either high-pressure “gene guns” to force small particles of metal coated with the appropriate DNA into the seed cells, or by using a modified strain of bacteria to infect the seeds and insert the gene. Once the gene insertion is complete, the plant can be grown to maturity and will use its own internal cellular mechanisms to express the gene as proteins. Note that GMO technology does not alter the fundamental nature of gene expression; it merely alters the instructions that the process follows, in the form of DNA.\nPart of the concern around GMO usage is that this technology could be used to engineer crops, deliberately or accidentally, to produce poisonous compounds or unsafe proteins that would then be consumed by humans. However, as in the case of golden rice, many of the modifications done to agricultural crops result in the plant producing proteins that are already ingested by humans. All of the introduced compounds that aren’t normally in people food are tested and controlled per the regulations of the market in which they are sold.\nAnother concern is that in consuming GMO foods, humans will take on some of the genetic changes of the modified organism, resulting in cancer or other health issues. However, as we went over previously, genetic modification normally needs to be very highly targeted and also have a vector for transfer (metal particles or bacteria) in order to succeed. The GMO foods that we consume contain no such vectors – they only contain the products of gene expression. There is a common saying that “you are what you eat”, which implies that the food we eat becomes a part of us. This is only partially true. Our bodies break food down into its component proteins, which are then metabolized. We don’t incorporate DNA by eating, which is why I am not turning into a steak or an eggplant as a result of my diet. In the same way, if I was to consume golden rice, I would not myself start producing beta-carotene and turn orange – I would merely metabolize the beta-carotene present in the rice.\nThe GMO products that are available for consumption currently have all been fairly researched, and do not contain modifications that have a strong likelihood of affecting human consumers. However, it is important to be able to distinguish the science behind GMOs from their implementation in our society. Interpreting the scientific aspects of GMOs in a vacuum is an oversimplification of the debate around GMOs. While the technology itself may be safe, the ways it is used and abused can certainly be harmful. Next time, I’ll attempt to unpack the intent behind GMO usage and the ways that that intent is skewed by various interests and can lead to social harm.\n Stephen O. Duke, ed. Herbicide-Resistant Crops: Agricultural, Economic, Environmental, Regulatory, and Technological Aspects. CRC Press, 1995 p53-80\nArt Li is a Chinese American ex-scientist who alternates between pondering the possibilities for science as a tool of liberation and eating a lot."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:aea2a4d8-4ef6-491e-b120-0278cb7094ca>"],"error":null}