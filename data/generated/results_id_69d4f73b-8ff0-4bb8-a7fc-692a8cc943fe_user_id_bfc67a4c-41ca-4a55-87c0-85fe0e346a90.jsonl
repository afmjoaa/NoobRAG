{"question":"Could you compare the structural organization and membrane characteristics of rough endoplasmic reticulum versus the Golgi complex?","answer":"The rough endoplasmic reticulum consists of long, folded membranes forming parallel pockets, with ribosomes attached to its surface giving it a nubby, rough texture. The space between these pockets is called the lumen. In contrast, the Golgi complex is composed of numerous smooth cisternae coated with lipid membranes. These cisternae are arranged in disc-shaped structures that stack together like plates, forming what's called a Golgi stack. The Golgi complex also contains numerous vesicles used for molecular transport and secretion. While the rough ER is characterized by its ribosome-covered surface, the Golgi's membrane structures are smooth and organized into distinct functional regions including the cis, middle, and trans regions.","context":["The endoplasmic reticulum is found almost all eukaryotic cells. It comprises two distinct components: rough endoplasmic reticulum (rough ER or RER) and smooth endoplasmic reticulum (smooth ER or SER).\nThe two types of endoplasmic reticulum have different structures, but they are two parts of the same organelle. They have distinct functions but also work together to process and distribute molecules to other organelles within the cell and to export molecules outside the cell.\nTL;DR (Too Long; Didn't Read)\nThe two types of endoplasmic reticulum in cells are rough ER and smooth ER. They have separate functions but work together to process protein molecules in the cell.\nEndoplasmic Reticulum Structure\nRough endoplasmic reticulum is made of a long, folded membrane that forms a series of narrow pockets. The pockets run parallel to each other and are formed from one continuous membrane. The space between the rows of pockets is called the lumen.\nThe “rough” texture of rough ER comes from the ribosomes attached to its folds, giving the membrane a nubby surface.\nSmooth endoplasmic reticulum consists of a set of interconnecting narrow tubes that are connected to the outer fold of the rough ER. The tubes are open at one end. The network of the smooth ER takes up less volume in the cell than the rough ER. As its name implies, it has a smooth surface because it is not covered in ribosomes.\nRole in Protein Synthesis and Processing\nProtein synthesis occurs in the ribosomes attached to the rough ER. Messenger RNA (mRNA) molecules in the nucleus contain the code for making proteins. The membrane of the rough ER is connected to the nuclear membrane and acts as a conduit for mRNA between the nucleus and the ribosomes.\nThe main rough ER functions are to process the newly synthesized proteins and package them so they can be carried in vesicles to other organelles or transported to the cell membrane where they will be excreted outside the cell. Many of the proteins are conveyed in vesicles produced by the smooth ER.\nProteins must be folded to be used effectively by the organelles. Before they are transported out of the ER, proteins receive a quality check in the lumen. Unfit molecules are broken down into their components and stored in the lumen until they can be recycled.\nFat Synthesis, Metabolism and Detoxification\nThe chief function of smooth ER is the production of lipids aka fats. Two types of fat molecules made in the smooth ER are steroids and phospholipids. Steroids are made in the cells of the adrenal and endocrine glands.\nSmooth endoplasmic reticulum has varied roles depending on the type of cells it is found in. In brain and muscle cells, it plays a role in carbohydrate metabolism. Calcium ions necessary for muscle contraction are released from the smooth ER in muscle cells.\nIn liver cells, it aids in processing toxins such as poisonous substances and drugs by breaking down the chemicals into water-soluble molecules. The smooth ER can expand to temporarily increase its surface area when necessary to process large loads of toxins more efficiently.\nThe Golgi complex, or Golgi apparatus, is another cell organelle that works in conjunction with the ER and ribosomes in the production of proteins. It is often located in proximity to the endoplasmic reticulum, which allows molecules to be transported easily between the two organelles.\nAfter the endoplasmic reticulum processes and packages proteins, the molecules move to the Golgi complex for finalization where they are further modified to be ready for use within or outside the cell.\nAbout the Author\nA.P. Mentzer graduated from Rutgers University with degrees in Anthropology and Biological Sciences. She worked as a researcher and analyst in the biotech industry and a science editor for an educational publishing company prior to her career as a freelance writer and editor. Alissa enjoys writing about life science and medical topics, as well as science activities for children","Golgi bodies, the Golgi complex or the Golgi apparatus, named after the Italian biologist Camillo Golgi, are composed of numerous sets of smooth cisternae, which are coated with lipid membranes. Each disc-shaped cisternae forms a structure that resembles a stack of plates, called a Golgi stack. The Golgi complex contains a great number of vesicles. These vesicles are used to send molecules to the cellular membrane, where they are excreted. There are also larger secretory vesicles, which are used for selective excretion.\nThe Golgi is principally responsible for directing molecular traffic in the cell - nearly all molecules pass through the Golgi complex at some point in their existence. The sorting is mediated by the vesicles. When proteins bind with their appropriate receptor on the vesicle, they are encoated in the vesicle and transported away.\n The Functions of the Golgi Complex\n What types of secretion are controlled by the Golgi complex?\nThe Golgi complex controls trafficking of different types of proteins. Some are destined for secretion. Others are destined for the extracellular matrix. Finally, other proteins, such as lysosomal enzymes, may need to be sorted and sequestered from the remaining constituents because of their potential destructive effects. This figure shows the two types of secretory pathways. The regulated secretory pathway, as its name implies, is a pathway for proteins that requires a stimulus or trigger to elicit secretion. Some stimuli regulate synthesis of the protein as well as its release. The constitutive pathway allows for secretion of proteins that are needed outside the cell, like in the extracellular matrix. It does not require stimuli, although growth factors may enhance the process.\n Golgi complex regulation of insertion of plasma membrane proteins\nPlasma membrane proteins are inserted in the membrane at the level of the rough endoplasmic reticulum. The protein sequence is coded for membrane insert start and stop sites. This directed the insertion and alignment points. Those that are multipass proteins have multiple start and stop sites.\nThe important role of the Golgi Complex is to make certain the plasma membrane proteins reach their destination.\nThis figure shows the route. Note that the orientation of the protein is maintained so that the region destined to project outside the cell (a receptor binding site, for example), ends up in that place. In order to do this, it must be placed so that it faces inside the vesicle.\n Golgi complex adding carbohydrate groups to a glycoprotein\nThe Golgi complex is compartmentalized. Phosphorylation occurs in the Cis region. In other regions, different types of carbohydrates are added as a glycoprotein passes through the cisternae. This figure illustrates the different regions where sugars like mannose (man), galactose (gal), etc are added. The final sorting is done in the Trans Golgi complex.\nThe functional differentiation of the Golgi complex can be studied with the electron microscope with specific techniques that detect enzymes. The cis region is rich in lipid-bearing membranes and can be delineated by osmium tetroxide labeling. The middle regions label for enzymes that add carbohydrates or other groups on the product. The inner, or Trans region, is the area where the lysosomes are sorted. Therefore, it is heavily labeled for acid phosphatase.\nThere is much interest in understanding how the different Golgi cisternae are organized and differentiated. A number of models exist, however a favorite is called the \"Maturational model\" \nThe Maturational model suggests that the new vesicles from the ER enter the cis Golgi network and retrograde vesicles (bearing COPI) coats move to merge with the cis region cisternae. These carry Golgi complex processing enzymes and their targeting to this region may be dependent on the low concentration of these processing enzymes. Then, as processing continues, the middle cisternae contain more mature product and lower amounts of the enzymes needed in the beginning. Finally, the trans region is specialized for sorting, containing receptors to sort and isolate lysosomal enzymes, for example.\n Protein transport to the rough endoplasmic reticulum\nSometimes vital proteins needed in the rough endoplasmic reticulum are transported along with the other proteins in the Golgi complex. The Golgi complex has a mechanism for trapping them and sending them back to the rough endoplasmic reticulum.\nThis cartoon shows the process. The protein destined for secretion is red. The blue protein must remain in the rough endoplasmic reticulum. The rough endoplasmic reticulum has inserted a receptor protein on the membrane it sends to the Golgi complex in the transitional vesicles (shown in green). These are retrograde vesicles and are therefore coated with \"COPI\" (coatamer). The ER protein receptor captures all of the protein that carries the ER residency signal. . Vesicles then bud from the Golgi complex and move back to the rough endoplasmic reticulum. The receptor can circulate and continue to return the proteins needed by the endoplasmic reticulum.\nGolgi bodies are known as the mailroom of the cell. Golgi bodies identify any substance and delievers it to the part of the cell that needs it the most. They receive those materials from the endoplasmic reticulum.\n See also\n- ↑ Bannykh S.I. and Bakch, W.E. Membrane Dynamics at the Endoplasmic Reticulum Golgi Interface J Cell Biol 138: 1-4 1997)\n- ↑ Wooding, S and H.R.B. Pelham, The dynamics of Golgi protein traffic visualized in living yeast cells. Molecular biology of the cell. 9: 2667-2680 1998\n- ↑ Cole, N.B., Ellenberg, J, Song, J, DiEuliis, D and Lippincott-Schwartz, J. Retrograde transport of Golgi-localized proteins to the ER. J Cell Biol 1-15, 1998."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"}],"document_ids":["<urn:uuid:62ed4e0e-c224-4178-b58c-e88082ac77c4>","<urn:uuid:ed299478-4edf-4b0e-877c-5b37554ab9ae>"],"error":null}
{"question":"Which cultural groups inhabited ancient Northern Alaska versus Southeast Alaska, and what evidence remains of their presence?","answer":"In Northern Alaska, evidence suggests multiple early cultures existed simultaneously, as shown by distinct stone tools found at sites like Mesa and Lime Hills Cave. The Mesa and Putu artifacts indicate different groups may have spoken different languages and had distinct toolmaking traditions. The microblades found at Lime Hills Cave suggest yet another cultural group. In Southeast Alaska, the pictographs were likely created by Tlingit, Tsimshian, Haida, or possibly Tsetsaut people. Their cultural presence is evidenced through red to reddish-brown pictographs depicting various subjects including whales, fish, ravens, human figures, and abstract designs, often painted near salmon streams, fish camps, or old villages.","context":["In Search of the First Americans\nA Story of Deepening Complexity\nby Robert King\nWhen did the first people come to the Western Hemisphere? And who were they? BLM scientists in northern Alaska are at the cutting edge of new theories about the first Americans. The emerging picture from their research heightens the complexity surrounding one of the most enduring anthropological questions of our time.\n| Above: Alaska's Mesa site yields clues to ancient questions|\nFor much of the 20th century, scientists have scoured remote parts of Alaska for clues to North America's first inhabitants — paleoindians. In 1978, when BLM archaeologists were surveying public lands north of the Arctic Circle prior to oil exploration, they discovered several stone projectile points that had probably been mounted on lance-like spears. Initial radiocarbon dating indicated the points were around 7,600 years old, not even close to the oldest artifacts found in the New World. But by the late 1980s a more precise dating method had been perfected —accelerator mass spectrometry. This showed that some of the artifacts from the Mesa site, as it was called, were in fact nearly 12,000 years old. The finding stunned archaeologists, and the Department of Interior subsequently funded a five-year research project that concluded in 1997.\nLying atop a mesa-like rock outcrop, the location of the site is nothing less than breathtaking. From 200 feet up, ancient hunters had a 360-degree vantage point for spotting game such as bison and, possibly, mammoths.\nUntil the site was discovered, archaeologists generally accounted for the early cultures in the lower 48 as the products of a single migration out of Asia. But the distinctiveness of the stone points found here — and at the Putu site 160 miles to the east — indicate that perhaps there were several migrations (Mesa artifacts range in date from 9,700 to 11,700 years old). Early Alaska may have been occupied by different cultures who spoke different languages, and had distinct ways of making tools.\nThe Mesa and Putu artifacts have amazed archaeologists with their close resemblance to paleoindian tools found to the south. As a rule, little of what is found from early Alaska resembles anything from paleo sites in the lower 48. This means that the descendants of the Mesa culture might have gone on to establish themselves farther down the continent.\n|Above and bottom right: Archaeologists investigate the Mesa site in a quest to unravel the origin of the earliest Americans.|\nArchaeological research on BLM lands west of Anchorage revealed other intriguing clues. At the Lime Hills Cave site, 10,000-year-old artifacts were found, including microblades, small, skillfully made cutting tools not found in the lower United States. They suggest that the bow and arrow may have been used in Alaska earlier than previously thought. The Lime Hills items are similar to a well-known style of artifacts found about 20 years ago in the Nenana Valley, south of Fairbanks. Such close technological resemblance suggests that the makers were culturally related. If this is so, the Lime Hills/Nenana Valley culture was widespread in Alaska. Radiocarbon dating of artifacts shows that the Mesa and Lime Hills people were in Alaska at about the same time, and yet were markedly different. And a discovery at Spein Mountain, 200 miles from Lime Hills, raises other questions. Though the two sites are relatively close, the Spein Mountain artifacts resemble those found at the Mesa site 500 miles to the north. What was the relationship of these groups to each other and to the paleoindian cultures farther south, including South America?\nWhat happened in Alaska over 11,000 years ago may teach us lessons about how people adapted — or did not — to the rapidly changing climate as the Ice Age ended. This could give us more perspective on our place in nature and our adaptiveness as a species. We may also find some of the most elusive truths about human history.","United States Department of Agriculture Tongass Archaeology Notes Pictographs In Southeast Alaska By Martin V. Stanford There are two types of rock art in southeast Alaska’s Alexander Archipelago; petroglyphs and pictographs. Petroglyphs were pecked, chiseled or ground into boulders, cobbles or outcrops of bedrock which are usually located in the intertidal areas near salmon streams, fish camps or old villages. Pictographs (Figs. 1-4) on the other hand were painted onto rock walls above the shorelines of the ocean, lakes or rivers and are distributed over a large area, with some painted in very remote locations. This pattern suggests that most pictographs were painted in the spring, summer, or fall, during gathering and trading seasons, rather than near their winter villages, when weather and sea conditions were at their most challenging. Figure 1: The pictograph are of a sun sign top, below a canoe with nine people, a circular face with three eyes and to the right skeletonized human figure. Some pictographs may have been painted in these remote locations by shamans during their quests to obtain spirit helpers (yeik or yek). Forest Service Alaska Region Tongass National Forest R10-RG-226 August 2017 Tongass Archaeology Notes Recent studies show that pictographs are more common than previously thought (Stanford 2011). As of 2016 one hundred and twenty five pictographs have been reported in the state of Alaska with one hundred and eleven of these located in southeast Alaska. Most pictographs were painted on overhanging rock walls or other rock walls that are protected in some way from rain or snow. Even so, over time pictographs become faded due to exposure to water in the form of rain, snow or seeps. However, modern computer graphics software can enhance images of faded pictographs; the results can be dramatic (Figs. 1-4). A few pictographs were painted by someone standing in some kind of watercraft such as a canoe but most pictographs were painted on rock walls that had a rock bench or ledge located below which allowed access to the wall and a place to stand or sit to paint. No pictographs, to date, in southeast Alaska were painted facing north. This may be for ritual reasons or simply because many north facing rock walls tend to contain more moisture and have more lichens or moss making them difficult to apply paint. Most pictographs, except for those painted inside caves, were created relatively recently compared to other sites in Southeast Alaska which can date back to over 10,000 years ago. Four pictograph sites in southeast Alaska have been indirectly radiocarbon dated from associated wood, charcoal or cedar cordage. Adjusted to calendar years these range from AD 1486 to modern times or as far back in time as Christopher Columbus, a time when many camps and villages were present across the region. Other pictographs were painted with motifs showing ships with sails or of ships anchors indicating they were likely painted near the time of contact with 18th or 19th century explorers or fur traders. Figure 2. This pictograph is obscured by lichens. Eight dots appear to orbit a circle dot motif. A canoe with four people and a horned or antlered animal motif appear to the lower right of the circle. The motif to the right may be a representation of an 18th or 19th century ship’s anchor. Tongass Archaeology Notes Most of the pictographs in southeast Alaska were painted using a red to reddishbrown pigment. Ethnographic research has provided some information on the composition of red pigments and how they may have been prepared for pictograph painting. The primary mineral pigment used was deep red hematite (Fe2O3) or iron oxide. Hematite mixed with clay is called red ochre. A binder was added to hold the pigment particles together and to hold the paint onto the rock surface. Some examples of binder ingredients include blood, fish eggs, seed oils, plant resins and juices. A third ingredient of the paint was a vehicle, or a fluid, that made the paint liquid and suitable for application. Plant juices, water, animal oils, and urine have all been used as vehicles. Pictographs in southeast Alaska were likely painted by Tlingit, Tsimshian, or Haida people, or possibly even by the Tsetsaut. Figure 3. The top left figure is thought to be a dragonfly. At center far right and lower left are two very faint canoe motifs. It is not known what the two sets of parallel lines and the two connected circles might represent. The reasons why pictographs were painted are varied. Ethnographic research shows that some pictographs were painted to impress others; to record legends or important events, such as contact with European explorers, encounters with animals, to mark clan territories or to indicate portage locations; to record periods of time; or to mark or warn of burial locations for important people such as shamans or their paraphernalia. While many of the pictographs may represent recognizable animals or things such as whales, fish, ravens, human figures, and ships anchors; much of the art is more abstract and consists of dots, circles, ovals, squares, and lines. But what do these pictographs mean? What do you think they suggest? No one can say absolutely what the painter had in mind while creating these images. To attach meaning would be to possibly make wrong inferences or conclusions about the images and about the people who made them. Tongass Archaeology Notes Therefore, realize that the interpretations we give some of these paintings is likely speculation, and what they actually represent, may in fact be very personal and known only to the person who painted them. Figure 4. Upper right are two killer whales. To the left is a raven holding a starfish. Below is a difficult to see canoe motif. At bottom may be a composite animal with a beavers tale. Related Readings Demerjian, Bonnie Rock Art of Southeast Alaska. Stikine River Books. 2015. Stanford, Martin V. Shoreline Pictographs of Extreme Southeast Alaska. Alaska Journal of Anthropology. Alaska Anthropological Association. Volume 9, Number 1. 2011. Wardwell, Allen Tangible Visions: Northwest Coast Indian Shamanism and Its Art. Monacelli Press and Corvus Press, New York. 1996. Tongass National Forest • http://www.fs.fed.us/r10/tongass/ (907) 225-3101 • TTY (907) 228-6222 USDA is an equal opportunity provider, employer, and lender. PLEASE RESPECT OUR IRREPLACEABLE CULTURAL RESOURCES: TAKE ONLY PHOTOGRAPHS AND LEAVE ONLY FOOTPRINTS AT ARCHAEOLOGY SITES. Archaeology sites are protected by Federal regulations and it is unlawful to disturb or remove artifacts from a site. If you should find a site, please contact your local FS archaeologist. We welcome your local knowledge and appreciate your interest in preserving our cultural heritage."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:12c1806d-7bea-4bfd-94c6-92e4e8460009>","<urn:uuid:2b8e8e14-a5bb-482f-b8e1-6d724c4145d3>"],"error":null}
{"question":"How did Shaun Greenhalgh artificially age his Anglo-Saxon brooch to make it look authentic?","answer":"Shaun Greenhalgh aged the Anglo-Saxon brooch by opening and closing it a thousand times to simulate repeated use over time. He also deliberately wore down one of the evangelist engravings on the front, specifically the part that would have been grasped by the thumb every time the brooch was put on.","context":["The first time I came into contact with Shaun Greenhalgh I had no idea I was doing so. Unfortunately I was on national television at the time, talking about the French post-impressionist painter Paul Gauguin, blissfully unaware that I was making a fool of myself in front of a couple of million witnesses. And that somewhere in Bolton, in a pub, Britain’s greatest forger was watching me and thinking to himself: “What a plonker.”\nI am an admirer of Gauguin’s art and for the centenary of his death, in 2003, I persuaded the telly people to let me make a film about him. At the same time a big show opened in Amsterdam, in the prestigious Van Gogh Museum, telling the story of the wild weeks that Van Gogh and Gauguin spent together in the south of France before Van Gogh cut off his ear. The Amsterdam exhibition was brilliant: packed with important artworks borrowed from the finest museums in the world. I had to film it.\nSitting in a Perspex case at the start of the show was a sculpture by Gauguin that had been bought in the late 1990s by the Art Institute of Chicago. If you know your American museums, you will know that Chicago’s Art Institute is blue chip — one of the best collections in the world. It is where Seurat’s A Sunday on La Grande Jatte hangs, and a ton of Monets, Manets and Cézannes. The newly acquired Gauguin showed a faun, a mythological wood nymph that is half-man, half-goat, sitting impishly on a mound of clay.\nThe sculpture, which had not been shown before, was signed “PGo”, a cheeky shorthand signature that Gauguin sometimes used that was derived from the nautical slang for a penis. In his youth he had been a merchant seaman and had picked up various naughty nautical practices. I wanted to make a point about it, and the sculpture from the Art Institute seemed the perfect opportunity.\nYou can watch the encounter on YouTube. There I am, talking about the PGo signature, and speculating cleverly about the possible self-portraiture implied by the image of the naughty faun. Back in Bolton, meanwhile, Greenhalgh, who had made it a few years earlier and lost track of it, was interested to find out that it had now been acquired by the Chicago Art Institute and that the museum had paid $125,000 for it.\nIt was not until I opened a newspaper one morning in 2006 that I saw The Faun again. There it was, lined up in a long row of photographic evidence that had emerged in court about a forgery ring set up in Bolton by the least likely forging supremos of all time — the Greenhalgh family. According to the newspapers, Greenhalgh, his father and his mother, both of whom by then were in their eighties, ran their ring out of a shed in the garden of their council house. Shaun made the fakes; his dad and mum sold them. That is what the newspapers were reporting.\nApart from the sheer unlikeliness of this arrangement, the most surprising thing to emerge from the court proceedings was the range of fakes the Greenhalghs had supposedly produced. They had made Assyrian reliefs, LS Lowry paintings, Barbara Hepworth ceramics, English watercolours and post-impressionist sculptures. Was there anything the Bolton forgers could not fake?\nThe newspapers reported that the three Greenhalghs were in it together, which is why they were able to produce so much. In fact they were a one-man band. Shaun made everything himself. As he makes clear in the remarkable memoir he wrote in prison it was Shaun, and only Shaun, beavering away in his shed in Bolton, who was the forger. His poor mother and father were roped in to help him complete some sales. But that was only after three decades of relentless pastiching had been and gone.\nI got my hands on Shaun’s memoir by accident. In 2007, when the crown court in Bolton sentenced him to four years and eight months in prison, I fired off a quick letter to a couple of commissioning editors in television demanding to be allowed to make a film about him. This bastard had fooled me on British television, I complained. Too late, they replied. Someone else had got there before me.\nIn the end both Channel 4 and the BBC made separate programmes devoted to the “Artful Codgers”. Both were profoundly inaccurate. How inaccurate was brought home to me when I finally got round to reading the thick stack of typewritten pages that thudded onto my mat a couple of years later — A Forger’s Tale: the prison memoir of Shaun Greenhalgh.\nHe had been persuaded to write it by a researcher from another television company that also wanted to make a film about him — a biography. Nothing came of the project, except the memoir. Once he started, he could not stop. With nothing else to do in prison, it all came pouring out. How he made his first fakes when he was still in primary school. How Victorian pot lids were all the rage at the time and how, with the knowledge he had picked up in pottery classes, he was soon banging them out at a fiver a head. By the time he was in his teens he was earning more a month than most of his friends’ fathers.\nAt school in a Bolton comprehensive he gave up art classes after a couple of years and set about learning it all for himself. This was Bolton in the 1970s, where the dark satanic mills had turned into dark satanic ruins and where a precocious lover of art had little to encourage him. As the newspapers presented it, the Greenhalghs were a Bolton Cosa Nostra, a ruthless ring of Lancashire fakers who had set out to con the art world. But what they really were was a modest north of England family who had managed to spawn a boy wonder: a kid who could make anything.\nParadoxically, it was the Bolton Museum that saved Shaun by firing in him a fascination with all things Egyptian. He taught himself hieroglyphics. And stone carving. And the Egyptian system of proportions. Years later, when he got really good at carving, he sold an Egyptian sculpture of an alabaster princess to this same museum for £440,000.\nThis sculpture, the so-called Amarna Princess, had been pored over for months by all manner of experts in London and beyond. The damn thing fooled me as well — thanks again, Shaun — when it popped up alongside Velazquez’s Rokeby Venus in an exhibition at the Hayward Gallery celebrating 100 years of success by the then National Art Collections Fund. Now that I think about it, it did look a little clean.\nHow it was made is detailed in the memoir, including the startling information that Shaun dropped the piece of alabaster and had to glue it back together “with Araldite Rapid” when it cracked in two. The experts should surely have noticed that the Amarna Princess was carved out of a piece of stone that had been glued together. But they did not.\nThe Araldite Rapid came in useful as well for Gauguin’s faun, which was made in separate pieces and then stuck together in an entirely un-Gauguiny way. I did not see the glued-up bits either, but hey, it was in a Perspex case, and the lights were glary!\nNot long after leaving school Shaun made his first Degas drawing. And successfully sold it in a big auction in London. He made Egyptian heads. And sold those. And studio ceramics in the style of Hans Coper. And gothic crucifixes. And watercolours of birds in the manner of Archibald Thorburn. Lots and lots of Thorburns. Then there was the Lalique glass. The Chinese pots. The Venetian bronzes. Easily bored, he kept changing styles, forms, materials, epochs, always getting as good as he could at every different technique. Then he would drop it and move on to something else.\nIt was this appetite for variety that led me to him, and him to me. I was making a television series about the Dark Ages, that much-misunderstood epoch when the lights of civilisation were said to have been switched off across Europe, and I wanted someone to show me some sophisticated Dark Ages manufacturing skills so that I could make the point that the Dark Ages were not dark. In Shaun’s court case it had emerged that he had produced several Visigoth eagle brooches, as well as various Anglo-Saxon artefacts, so he clearly was just the man for the job.\nTracking him down was difficult. Shaun keeps himself to himself. Since his release he had been working in jobs organised by the prison service and was collecting wheelie bins when I met him. The police had taken everything away when they arrested him, including his first school sculptures that his mum and dad had kept, as you do with your children. The Yardies snaffled the lot. But they could not take away all that deep and intense knowledge built up from 40 years of making things.\nFor our film, he produced an Anglo-Saxon brooch, made of silver and rock crystal, the kind of thing a noble might pin to his cloak. I was only interested in seeing roughly how it was done. But Shaun went all the way. First, he made an ingot, produced from exactly the right quantities of silver and mixings that the Anglo-Saxons would have used. Then he spent days hammering it into the right Anglo-Saxon thickness. Then he cut it up, engraved it, made the enamel inlay, shaped the rock crystal, fashioned a copper pin mechanism, put it all together and set about making it look 1,000 years old.\nThe last part I had not asked for. Indeed, it was not what I wanted. But old habits die hard and having knocked a few chips off the rock crystal he began opening and closing the brooch a thousand times. That, he explained, was how often it might have been used before it was lost in a field. He also deliberately wore down one of the evangelist engravings on the front because that was the part that would have been grasped by the thumb every time the brooch was put on.\nI watched all this with pure fascination. I have met lots of impressive people in my life, but they have generally been impressive with their minds or their mouths, not with their hands. Shaun’s hands had magic in them. When he was making things, he became a different person. Gone was the shy and suspicious middle-aged van driver from Bolton, replaced by a technical wizard who darted this way and that, producing the bits for his brooch with myriad kinds of alchemy. In Anglo-Saxon times this would have been the work of 10 people. Now it was just him.\nI should add that all this was going on in a garage in Bolton borrowed from Shaun’s sister, and that the garage had a low retractable door at the front on which he kept banging his head. If anyone makes a film of his life — which they should — it would be a mix of Billy Elliot and an Ealing comedy. With some F for Fake thrown in. How could anyone get this good at meticulous international forgery while growing up in Bolton in the 1960s and 1970s?\nThe answer arrived on my mat a few months later. Written on A4 pads in prison, Shaun’s story starts out as an attempt to explain his actions and correct the various inaccuracies that had been peddled about him and his family. But pretty quickly it becomes a runaway train of information about the things he made and how he made them. The court case, it turns out, had only scratched the surface of his output.\nHaving made his pieces, much of his most inventive effort as a forger went into giving them provenances, or as he prefers to call them in the book, “stories”. Among all the dodgy art world practices described here, nothing is quite as troubling as the creation of provenances. Without a provenance nothing sells. So Shaun needed to be especially inventive in coming up with his own. For the Amarna Princess a brief line in an old catalogue bought by post from a book trader was all it took to persuade the experts that his newly made Egyptian alabaster had a rightful past. Too many “provs”, warns Shaun, are “hardly different from a myriad tales you hear on the Antiques Roadshow”.\nWhat, then, are we to make of his own contentious claims? The story of how he claims he made the drawing now known as La Bella Principessa, by Leonardo da Vinci, but which ought really to be called Sally from the Co-op, by Shaun Greenhalgh, is hilarious. Sally — whose real name was Alison — worked at the checkout in the Co-op where Shaun was also employed in the late 1970s. To draw her he says he bought an old land deed that had been written on vellum, and finding the “good” side to be too ink-stained to use, turned it over and drew on the rough side instead, as Leonardo would never have done.\nIt was never meant to be a da Vinci. But he did have some fun pretending he was left-handed. In a book about La Bella Principessa written by the distinguished Leonardo scholar Martin Kemp much is made of the left-handedness of the artist. But Shaun claims all he did was turn the drawing through 90 degrees when he did the hatching, and voilà. As for the wooden board to which the drawing is glued, that came from Bolton Tech. His dad worked there and when the college began throwing away unwanted desks he brought one home and Shaun reused the lid. To make it look older, he popped in some inconsequential butterfly joints, learnt in his woodwork classes at school.\nSome Renaissance experts will not need Shaun’s book to tell them La Bella Principessa is not by Leonardo. She has been triggering grumblings ever since she popped up in auction some years after Shaun made her. To me, she never looked right: whoever drew this was not a Renaissance genius. It is clear, too, that someone aside from Shaun has tinkered with her in the past in an effort to give her a credible provenance. But with sums of £100m being bandied about for a real Leonardo, the news that La Bella Principessa might be Sally from the Co-op is certainly startling.\nThe memoir is full of such claims and revelations. Poor old William Jefferson Clinton bought a bust of Thomas Jefferson in auction that was also by Shaun. Let us hope he does not send over the CIA to rub out its maker when he finds out who really made it. As Shaun puts it in the book: sorry, Bill. The royal family is also owed an apology for the medieval crucifix it acquired on the understanding that it came from the tomb of King John. It did not. It came from the garage in Bolton.\nWhile Shaun generally comes across as a lovable rogue, the book is also packed with genuine bad guys. Very bad guys. Shaun is hardly an angel — he knows it, we know it — but you cannot turn yourself from a comprehensive kid in Bolton into a master forger whose work is scattered around some of the world’s greatest museums without serious collusion from the crooks and mountebanks who inhabit the art world. I thought I knew that world well, having spent so many decades sampling its wares. But I knew nothing. After you read this book you will never — never — trust the art world again.\nThere is also lots of tiptoeing through the complex moral territory of forgery. The point Shaun keeps making — and it is a good point — is that you should buy things because you like them, not because of the signature in the corner. That way you cannot be disappointed.\nThe vast majority of the creations that get described in A Forger’s Tale in forensic detail were not sold under false signatures. They were sold as unknown quantities. It was the dealers and the mountebanks, pumped up with imagined self-knowledge, who added the signatures, the fake provenances, the fanciful stories of origin. Shaun was taking them for a ride, but crucially they thought it was the other way round.\nFrom the outside, the art world looks like a world of beauty, inspiration, civilisation and culture. It is not. It is a cesspit. And by making that crystal clear, this book is doing us all a big service."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"search_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:5eb0b226-d290-4f2a-b075-8f4c64708a34>"],"error":null}
{"question":"What are the physiological markers of stress in language patterns, and how does meditation training affect these biological stress indicators?","answer":"Language patterns track molecular stress responses more accurately than people's self-reported stress levels. People with higher-stress gene expressions tend to talk less overall but use more intensifying adverbs like 'really' and 'incredibly,' while using fewer third-person pronouns, indicating more self-focus. Meanwhile, meditation training shows measurable biological changes: it decreases stress hormones in the blood, lowers heart rates, decreases skin conductance, and reduces breathing rates while increasing belly breathing. After just one month of mindfulness meditation, researchers observed increased axon density and myelin formation in brain regions associated with focus and self-regulation.","context":["Certain language patterns track the body’s molecular response to stress more closely than a person’s own description of the stress, anxiety or depression that they are experiencing.\nPoverty, loneliness or post-traumatic stress disorder can have serious consequences on health, increasing the risk of cancer, Alzheimer’s disease and heart disease, among other health problems. Previous research has shown that our genes respond to psychological adversity by increasing inflammation and reducing virus-fighting activity. These factors may contribute to social disparities in health.\nSteve Cole, a professor of medicine and psychiatry and biobehavioral sciences at the David Geffen School of Medicine at UCLA and director of the UCLA Social Genomics Core Laboratory, has hypothesized that the genes’ activity represents the body’s evolutionary response to threat. He wanted to find out whether stress biology is triggered by an automatic assessment of threat in the brain, on a level at which a person isn’t necessarily aware.\nResearchers asked 143 adult volunteers, from 2010 to 2013, to wear audio recorders for 48 hours; the recorders switched on every few minutes, capturing 22,627 audio clips. The scientists transcribed and analyzed the recordings.\nResearchers paid special attention to the use of language and of “function words,” such as pronouns, articles and adverbs. Speakers use function words relatively automatically, so these words may provide clues about the speaker’s state of mind. Previous research has shown that the use of function words changes when people face a personal crisis or following terrorist attacks.\nCole and his colleagues compared the language used by each volunteer with the expression, in their white blood cells, of 50 genes known to be influenced by adversity. Gene expression is the process by which genetic instructions are used to synthesize gene products, such as proteins, which go on to perform essential functions.\nPeople with higher-stress gene expressions tended to talk less overall. But they used more adverbs such as “really” and “incredibly,” which can function as “intensifiers.” They also used fewer third-person pronouns such as “they” or “their,” suggesting less focus on others and more focus on themselves.\nThe results indicate that language analysis could potentially help identify people at risk of developing stress-related disease. Cole, the senior author of the study, says speech patterns were better predictors of disease-related molecular profiles in the body than were people’s subjective reports of stress, anxiety or depression.\nThe findings suggest that doctors, when assessing stress, might need to give more weight to how their patients speak, listening not only to what patients say but how they say it. Cole added that stress-related language could potentially be monitored automatically by cell phone apps and digital assistants such as Alexa and Siri, providing an ongoing personal “stress temperature.”\nIn addition to Cole, the following authors contributed to the study: Jesusa Arevalo of the Norman Cousins Center at UCLA; Matthias Mehl and Thaddeus Pace of the University of Arizona Tucson; and Charles Raison of the University of Wisconsin-Madison.\nThe study was published November 6 in the Proceedings of the National Academy of Sciences.\nThis research was supported by grants from the National Institutes of Health.","A previous post in March 2012, Meditation and Neuroplasticity, outlined research about meditation causing changes in the brain, including new brain cells, axons, dendrites and synapses. These studies showed dramatic brain alterations for all of the major traditions of meditation. A brief summary of that previous research follows.\nThis post will look at the most recent studies that continue to show new effects of meditation on the brain, as well as new applications.\nSome of the information summarized in the previous post appeared in a recent review article in the journal Nature Neuroscience. This article additionally describes that severe stress causes increase in some of the regions of the amygdala, (emotional center related to fear) and decrease in regions of the hippocampus (memory and learning), and pre frontal cortex (decision-making). It notes that meditation counteracts these stress related brain changes. Meditation decreases anxiety and fear, and increases memory and cognitive abilities.\nThis Neuroscience review reported additionally that compassion meditation (summarized in previous post and below) increased gamma oscillations and synchrony, as well as increased activity in brain regions related to empathy. It also emphasized that changes in the brain from mindfulness meditation can occur in just eight weeks.\nThe article raised the question whether meditation research is complicated by the fact that changes in the brain could also be from daydreaming, and self-reflection. Daydreaming has been recently linked to creativity (see research and discussion below) and self-reflection might also cause brain changes. Social learning in children, including self-reflection, significantly helped academic achievement.\nBrief Summary of Previous Meditation Post\nThe previously described brain changes for three major types of meditation are:\nCompassion: In meditation emphasizing a focus on compassion and “loving-kindness” there was increased concentration. There was also increased activity in frontal brain regions (positive emotions and self control) and thalamus (filters sensory- motor signals), and a decrease in the parietal region (visual and spatial).\nMindfulness: Mindfulness meditation showed increased neurons and connections in right frontal cortex, (concentration), insula (emotions) and right parietal and temporal (sight and sound). It showed a decrease in amygdala (stress), and increase in hippocampus (memory)\nTranscendental: Transcendental meditation showed more activity in frontal and parietal (attention), and decrease in thalamus, (sensory) and basal ganglia (choosing actions). The brain waves showed increased coherence and more synchronous oscillations throughout the brain.\nDefault Network: In all types of meditation a very important finding was that the Default Mode Network (DMN) was changed, briefly in novice meditators and permanently in experienced meditators. The DMN is the part of the brain that operates with non-focused internal thought and daydreaming (memories, future planning, wondering, thinking about others). This new default network caused by meditation now included new brain centers (dorsal anterior cingulate and dorsolateral prefrontal cortex) and was associated with increased control of behavior and thought.\nBasically, meditation of all types increased focus and self-monitoring of thought and emotion.\nWide Range of New Research\nAs the research into meditation has expanded, there are new findings in brain connectivity, neuroplasticity (brain changes and brain region growth), multitasking, and emotional monitoring. Other research has focused on the specific uses of meditation in cancer, cardiovascular disease, depression, and war related stress.\nAs these new results are incorporated into brain science, a broad question arises about the relation of meditation, daydreaming, sleep, physical exercise and creativity. These are discussed below.\nGeneral Brain Changes with Meditation\nGyri in the cortex are the folded regions of the cortex that allow for increased complexity and increased connectivity of the neurons. A recent study showed that with all of the different meditation techniques there are increased folding of the cortex, that is, increased “gyrification.” Significantly, the longer people had practiced the various forms of meditation, the more this effect of increased cortical surface area was evident. This correlates with increase brain effectiveness.\nIncreased Axon Density and Myelin\nA study using advanced diffusion tensor fMRI showed that one month of Chinese mindfulness training, called IBMT (Integrative body-mind training) increased the density of axons, which means more ability to signal and more connectivity (see post on Connectivity). These changes in the neurons of the anterior cingulate, a center for focus, attention, concentration, and self-regulation, also included an increase in myelin (myelin surrounds mature neurons and increases the speed of transmission of the signal). The increase in axons occurred after two weeks, and the increased myelin in one month. In early development axons also develop first, followed later by myelin.\nThis study of Chinese mindfulness meditation also found decrease in stress, measured by hormones in the blood. Other findings included less anxiety, depression, anger and fatigue. There was an increase in blood flow for the cingulate cortex after five days of 20 minutes meditation. The subjects had lower heart rates, decreased skin conductance, decreased breathing rates with increased belly breathing.\nStudy groups of meditators and non-meditators were given questions with multiple answers (for example, “Name one of the seasons”), then one of the correct answers was flashed on a screen either in a way that could be seen consciously or for only 16 milliseconds, a rate that is too fast to be consciously seen. The meditation group was able to see the subliminal, unconscious, words better. Either they were aware of unconscious material or their concentration was better.\nNew research with mindfulness meditation shows an improved ability to multitask after the meditation session. The study included simultaneous work with emails, calendars, instant messaging, telephone and word-processing tools to perform common office tasks. They measured speed, accuracy and the extent of switching between tasks. The meditation group showed an ability to stay focused on a task longer with less distraction. They were able to concentrate better, and switch less. They also had decreased stress, increased memory and equal or better productivity\nMeditation and Disease\nMeditation has now been used to help treat a variety of medical problems. The recent studies include anxiety from cancer, cardiovascular risk in teens, and depression.\nAn analysis of 22 studies involving 1400 patients from Denmark showed that cancer patients had less anxiety and depression with mindfulness meditation. The result lasted at least six months after the study period.\nCardiovascular Risk in Teens\nIn a study of 62 black teens with high blood pressure, meditation showed positive effects on their heart. With fifteen minutes of transcendental meditation a day, their heart’s left ventricle became smaller (an enlarged heart is a sign of weakness with an extra workload from the higher blood pressure). The deep rest of the sympathetic nervous system during meditation lowered blood pressure and heart size.\nAnxiety and Depression\nA new study shows meditation has long-term effects on emotional stability, and decreased anxiety and depression. As in previous studies there was a change in the default network related to daydreaming and self-oriented thought with long-term meditators. This new study of experienced and novice meditators showed weaker synchronization between two regions of the medial prefrontal cortex – the dorsal (cognitive) and the ventral (emotion, self evaluation). This correlates with improvement in depression, because depressed people have hyper connectivity between these two areas. There was also a greater synchronization to the right parietal lobe, which is related to attention. Consequently, research seems to suggest that when meditation is practiced alongside regular trips to one of the many mental health facilities out there for mental health treatments, then the symptoms of anxiety and depression can be improved.\nPhysical Exercise, Meditation, Sleep, Daydreaming, and Creativity\nThe complex relationships between physical exercise, meditation, sleep, and creativity are not yet fully understood, but are intriguing. Physical exercise and meditation are both noted to increase brain regions and increase new learning. Sleep is noted to increase learning and memory as well as creativity. Meditation is also shown to increase creativity. Are these similar or different mechanisms?\nPrevious studies have shown that sleep during the time of slow waves stimulates increased memory for learned material. This learning could include athletic skills. When exposed to sound and odor cues during sleep the memory of specific locations was increased. Sleeping and dreaming are also correlated with increased creativity. Just recently a tune was played to musicians during slow wave sleep and this enhanced their ability to play the tune when they awoke.\nDaydreaming and the Wandering Mind\nDaydreaming is important because it allows us to imagine future events, to flesh out ideas, and to create.\nA recent study asked subjects to list as many uses as possible for everyday objects such as toothpicks, clothes hangers and bricks. One group then did an undemanding task that encouraged daydreaming. Other groups did focused work, or nothing. The daydreaming group did much better on the next round of creative questioning.\nOther studies show that when a person’s mind is wandering they perform better in creativity, association and insight tasks. These include imagination games, original thinking and invention. A recent study showed that people report a wandering mind 47 percent of the time.\nTop Athletes, Musicians and Managers\nIncreased brain coherence is noted in meditation, but is also demonstrated in elite managers, musicians and athletes.\nTo measure exceptional performances with high brain integration a variety of measures are used. One measure of brain performance is increased coherence of brain waves measured by EEG (see post on Brain Oscillations). This measures how different parts of the brain are in sync with each other and work together. Another EEG measure, that of alpha waves, is related to alertness. The third is a measure of how efficient and effective the brain operates.\nBy these measures high-level managers, as well as elite professional and amateur musicians showed much more brain integration than less qualified managers and musicians. The most recent study shows that elite athletes also have this high brain integration by the three measures. They also shared a cluster of subjective experienced often referred to as “peak experience,” which includes inner calm, effortlessness, extreme wakefulness, ease of functioning, absence of fear, and a sense of perfection. Some athletes and musicians refer to this feeling as a performance “high”.\nIt remains for future studies to relate this “peak experience” to meditation states\nIn Elderly Tai Chi Increases Brain Size, Improves Cognition\nTai Chi is a meditative physical exercise, which is less aerobic than other forms of exercise. Research has already shown that exercise increases brain growth factors to make new cells. Seniors who engaged in Tai Chi three times a week for eight months had increases in brain volume, and better memory and thinking. One of the control groups that used lively discussions instead of the Tai Chi, showed some increase in brain size but less cognitive improvement. The other control group with no intervention had brain shrinkage. Previous trials showed increases in brain with exercise (new brain cells for new learning), increase in memory, but not as much cognitive improvement.\nNeuroscience, Meditation, Yoga, and Performance in War\nJust as the great American Indian warrior Crazy Horse did many years ago, the new soldier is learning to concentrate his mind for battle using meditative techniques. Martial arts, such as Tai Chi, Karate, and Kung Fu, have always used meditative techniques for superior focus, balance, power and muscular coordination.\nYoga and meditation are now being used in the military to help soldiers become calmer and better decision-makers in order to avoid trauma. Meditation is used before mock training that attempts to simulate the chaos of war scenes. While most military research has been related to brain injury and post traumatic stress, new brain studies, including brain imaging and blood tests for stress markers before and after simulated combat, are being done at the Warfighter Performance Lab to determine stress affects decision-making. Meditation techniques including breathing exercises are being applied to help the soldiers regain a state where good decisions can be made.\nThe psychological terms used in these military studies include “resiliency”, “psychological hardiness” or “mental toughness”. The new training called Comprehensive Soldier Fitness program increasingly includes these emotional, and psychological elements. Most soldiers have signs of stress, but only 20% have great difficulty in dealing with it. Training in elite forces, like the SEALS, simulate severe states such as near drowning to see who can tolerate this very high level of stress.\nThe most elite group remaining after very grueling SEAL training shows more activation in the insula, an area related to self-awareness, pain and emotion. The insula also helps relieve stress with awareness.\nOne early study, called the Trojan Warrior Project, included 10 days of meditation, yoga, and martial arts. After these sessions, soldiers performed much better in biofeedback tests of muscular and neurological reactions to stress. They were also able to learn a foreign language faster, learn complex technical weapons systems better and were better marksman.\nCurrently, SEALs are using meditation in training, based upon neuroscience data of increased gray matter volume and better synapses in the pre frontal cortex. These brain changes lead to improved ability to have attention control triggers of the amygdala fear responses. The Mindfulness Based Stress Reduction program showed decreased stress, and improvement in concentration, memory, performance of complex tasks, and regaining focus after stress.\nAnother meditation study for eight weeks, using fMRI, blood markers and saliva markers, showed a better recovery from stress. After the study period soldier’s brains were more likely to resemble the brains of elite SEALS and Olympians.\nPrevious posts have focused on how attention, and suggestion, as well as meditation, change the brain. The recent understanding is that the brain is much more “plastic” or changeable than previously thought and will change in any way that we choose to exercise it.\nIn normal function any mental event creates rapid changes in neurons, including building and rebuilding very complex structures almost instantly. (see post).\nMeditation is a specific training that builds a “muscle” of mental concentration with increased memory, creativity and cognitive abilities. These new abilities include being able to control the effects of severe stress and include a variety of different subjective internal states.\nAs mechanisms of these changes are elucidated in the future, hopefully the details of subjective meditative states can be correlated with molecular changes in the brain."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"content_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"}],"document_ids":["<urn:uuid:6a0f04eb-0c4c-4632-958c-f99e10f8fb1f>","<urn:uuid:425237aa-1a9b-43ba-8f34-1c263437e374>"],"error":null}
{"question":"How do qualification requirements compare between CrossFit coaches and Pilates instructors in terms of training duration and certification standards?","answer":"Pilates instructors require more extensive formal training compared to CrossFit coaches. To become a Pilates instructor, one must complete a Level 3 Diploma in Teaching Pilates, which is regulated by official bodies like Ofqual and certified by recognized awarding organizations. In contrast, CrossFit coaches can obtain their basic qualification through a two-day course that includes theory, practical components, and an assessment. This is significantly less demanding than industry standards, as personal trainer qualifications can take up to 12 months to complete full-time, and professional strength and conditioning coaches often need Master's degrees or PhDs.","context":["Whether you are a looking to become a Pilates instructor, or just an enthusiast wanting some background information, this comprehensive guide to Pilates qualifications will be of great interest and relevance to you. Especially if you want to avoid spending thousands of pounds on training that simply isn’t recognised.\nBefore we explore the numerous training providers and organisations that offer Pilates instructor courses, it is worth clarifying the fact that qualifications and continuing professional development (or CPD) are quite different and it’s important for you to understand the distinction between the two.\nA qualification will be certificated, and quality assured by a regulated awarding organisation like YMCA Awards, Active IQ, City and Guilds or OCR, and will be regulated by the qualifications watchdog Ofqual (Office of Qualifications and Examinations Regulation).\nOther UK regulators include Qualifications Wales (Wales), CCEA (Northern Ireland) and SQA (Scotland). Broadly speaking, Ofqual (and other regulators) work tirelessly to ensure that the qualifications market is fit for purpose and that qualifications match the knowledge and skills required in industry (e.g. fitness industry) and the role (e.g. Pilates instructor or teacher).\nThe qualification will have a qualification number and you will be able to find this qualification listed on the Register of Regulated Qualifications. Broadly speaking, regulators work tirelessly to ensure that the awarding organisation ensures that the qualification is fit for purpose and that it aligns with the needs of the industry and the requirements of the role.\nEmployers, insurers and professional bodies (like CIMSPA) across the world recognise the value of regulated qualifications and see them as a kitemark of quality and something they can trust. It confirms that the certificate holder has demonstrated that they have the necessary knowledge and skills to perform that role.\nAs we say at HFE time and time again, you have to have a qualification to be qualified.\nIf a course does not lead to a regulated qualification then it is generally considered as CPD; these programmes are largely unregulated and as such the variability between providers is quite high. Some CPD programmes are rich in content and delivered by experts, others are not and so it’s important to do your research. Because they are unregulated, there is little incentive for some of the more unscrupulous providers to ensure quality standards are high.\nMost Pilates equipment courses, like reformer Pilates, for example, are not typically certificated by awarding organisations or listed on the regulated qualifications framework (RQF). The main reason for this is that they are either too specialised for awarding organisations to replicate, and/or because the commercial demand for these programmes will be less and so it’s unlikely that they can monetise them as qualifications. That said, many of these Pilates equipment courses are certainly equivalent in terms of rigor, learning hours, study time and assessment criteria. It’s also incredibly easy to see the value it would add to your teaching repertoire.\nA further point worth noting is that employers and insurance providers will require evidence that you have studied with a reputable training provider to employ you and insure you to work using Pilates equipment.\nA final note and recommendation on Pilates CPD is that you should ensure that it is at least endorsed by a professional body like CIMSPA (Chartered Institute for the Management of Sport and Physical Activity). This endorsement requires training providers to map their training against national occupational/professional standards to give you some assurance that what you are learning is relevant and credible.\nThe starting point and foundation level qualification currently needed to teach Pilates is the Level 3 Diploma in Teaching Pilates. This can either be completed face-to-face at a venue such as a gym or studio, or as part of online Pilates teacher training. This qualification is built around the National Occupational Standards developed by SkillsActive in the early to mid-2000s. These standards are currently under review by a working group associated with CIMSPA (since May 2019) who will be revising and developing professional standards for the Pilates teacher role.\nThe working group consists of representatives from different Pilates schools (classical, modern etc) and qualification development representatives from awarding organisations who develop and certificate the existing qualifications.\nThe level 3 Pilates qualification has no official entry requirements in terms of prior qualifications. It is open to anyone who has a keen interest and experience participating in Pilates classes. The course covers a range of subjects, including anatomy and physiology, posture, alignment and different posture types, history and principles of Pilates, how to conduct client assessments (including posture assessments) and how to maintain a safe working environment.\nThe bulk of the course focuses on how to plan and deliver Pilates sessions and teaches the full range of original 34 mat work exercises (suggested by Joseph Pilates), along with modifications and adaptations to accommodate those with different needs and levels of experience.\nThe level 3 qualification enables membership to professional bodies like CIMSPA and is currently the only qualification that is demanded by employers to teach mat work sessions.\nThe Level 4 Certificate in Mat Pilates qualification is a relatively new addition to the regulated qualification framework. It is currently only offered and certificated by Active IQ and available from a small number of training providers who are able to meet the stringent approval criteria.\nAs you might expect, the level 4 Pilates qualification offers a ‘step-up’ from level 3 giving greater coverage of applied anatomy and physiology. It also requires greater understanding and experience of the original 34 exercises and their application.\nAdditional study units within the qualification cover how small equipment, such as Pilates circles, arc barrels, foam rollers and small balls, can be used to assist or challenge the performance of the exercises (original and modified versions). The programme also outlines how to tailor and deliver a range of ‘modern’ standing Pilates exercises, which offer another functional application of the method, and which are likely to meet a broader range of abilities and needs.\nThe level 4 qualification also provides the opportunity to specialise and adapt the Pilates repertoire to work with a specific special population – either older adults, pre and postnatal clients, or those with low bone density. There is also an optional module for working with children. Being qualified to work with and adapt for these specific populations can significantly increase the work and employment opportunities available to any Pilates instructor or teacher, and it represents a commitment to higher quality standards.\nTraining to work with specialised Pilates equipment or apparatus is a natural progression for teachers who have previously completed mat-based qualifications, either at level 3 or 4. Joseph Pilates developed and utilised a diverse range of Pilates equipment in his life’s work and so there are a variety of courses currently available. Joseph’s written work features prominently in our guide to the essential books for Pilates instructors, which is very much worth a read if you’re looking to expand your knowledge.\nAs previously stated, Pilates equipment courses are currently only available as continuing professional development (CPD) activities as opposed to full qualifications, mainly because no professional standards have been agreed by the linked membership bodies (e.g. CIMSPA). That said, and as mentioned earlier, the study content and learning hours on training programmes offered by specialist training providers is equivalent to that required to achieve a regulated qualification.\nThe most popular and well-known piece of Pilates equipment is probably the reformer. As an apparatus, the reformer can be used for one-to-one training, group training and within clinical settings (e.g. physiotherapy and osteopathy clinics) for rehabilitation work. It offers the potential to support a broad range of training purposes and meets various client needs, ranging from postural improvement, general fitness, through to rehabilitation, sports specific training and working with specialist populations (e.g. older adults) and clients with health conditions (e.g. low back pain etc).\nReformer exercises can be used alongside traditional mat work exercises and with other Pilates apparatus (e.g. the Wunda chair, trapeze, ladder barrel, etc.). The potential uses for, and range of exercises that can be for the reformer are almost limitless. It is great to upskill and build upon level 3 qualifications and can open doors to other employment and self-employment opportunities.\nIn addition to reformer training, other equipment courses are available, which will be especially useful for those with an interest in setting up their own Pilates studio, include:\n• Pilates chair – AKA Wunda Chair\n• Spine corrector\n• Ladder barrel\nSome of these courses are usually shorter in terms of study hours but require the significant application of knowledge and are rigorously assessed.\nMoving beyond the Pilates qualifications and equipment courses, there is also a range of other CPD opportunities available. Many of these opportunities are offered by providers that specialise in a specific style of Pilates. For example, classical schools will focus almost exclusively on the original 34 exercises developed by Joseph Pilates, whereas, contemporary approaches will closely align with the original method but will seek to adapt it somewhat. More modern approaches will significantly modify and adapt the original exercise to the point that a classically trained Pilates teacher might not even recognise the exercise as Pilates. These modern schools do still follow the main principles of the Pilates method.\nSome of the more common examples of short single-day CPD Pilates activities include pelvic floor training, trigger points therapy, advanced breathing techniques and a whole host of other creative applications of the method. Again, those who are classically minded as far as Pilates goes will likely argue that such teachings deviate too much from the original approach.\nIn addition to training and CPD, there are also specialist symposiums and annual training events offered by specific providers covering a variety of subjects from mental health, barre and zen work, bone health, hypermobility and various other related topics. Aside from learning more, these can also be great networking events and you are also likely to get to meet some of the famous faces on the Pilates scene.\nFor anyone wanting to visit the place where it all began, the New York Studio still exists today and frequently delivers training by a teacher whose lineage can be traced back to the great man himself.Back to articles","CrossFit exploded onto the scene about a decade ago and since then has amassed a huge following – and a lot of criticism.\nBut is this criticism fair and warranted?\nCrossFit helps a lot of people, so how can it be bad?\nIn this guest post by professional strength and conditioning coach Dan Jolley, PhD, he takes a step back and provides a level-headed and balanced rundown on CrossFit, the pros and cons, and those who might benefit most from it.\nOver to you Dr Dan! -Bill\nThere has been a massive change in gyms and group exercise over the last few years.\nAt the forefront of this has been one of the most polarising exercise modalities of recent years – CrossFit.\nWhile nothing in a CrossFit workout is actually new (they use bars, weights, and equipment that has been around for decades), their workouts are put together in a novel – and in some circles, controversial – way.\nPlenty has been written about CrossFit, most of it very polarising.\nTherefore, the aim of this article is to take the view of an impartial observer.\nI’ll assess the pros and cons of this form of exercise and examine what the evidence says about its claims.\nPrinciples of CrossFit\nTo define CrossFit, it is useful to go to the source. According to the CrossFit website:\nCrossFit is constantly varied functional movements performed at high intensity. All CrossFit workouts are based on functional movements, and these movements reflect the best aspects of gymnastics, weightlifting, running, rowing and more.\nWhile this isn’t necessarily a novel approach, there are a couple of things worth noting. One is the use of the word “functional.”\nWhat Does “Functional” Actually Mean?\n“Functional” is a buzzword bandied about by the fitness industry in recent years and tends to be attached to the use of free weights, body weight exercises, and exercises that challenge stability. None of these are bad things.\nIn fact, as a strength & conditioning coach, these are all options I use daily.\nYou will always see plenty of free weights in a CrossFit gym, and this has influenced the broader fitness industry to provide this equipment too.\nBut when deciding whether or not a movement is functional, it’s worth considering whether that “function” is relevant to the person doing the training.\nPersonal trainers are generally taught to select exercises (and other variables) to suit the needs of the client.\nThis is good practice regardless of whether or not you consider your exercise “functional”.\nThere isn’t necessarily an agreed-upon industry standard definition of this term as it relates to exercise.\nThe key phrase from the Wikipedia definition, “movements based on real-world situational biomechanics” is a good place to start.\nCrossFit has a slightly different take:\nWe scale load and intensity; we don’t change the program. The needs of Olympic athletes and our grandparents differ by degree, not kind.\nWhat this suggests is that everyone walking into a CrossFit gym will do the same workout, in the same order, though the resistance applied will vary.\nExercise selection is generally seen as a fundamental part of exercise prescription that can be varied to suit the individual (a good summary of the research on resistance training prescription can be found here).\nCrossFit suggests that everyone can benefit from the same program.\nTo a point this is true: beginners, especially, will benefit from any increase in exercise levels, regardless of the choice of movement.\nThis becomes less true with more training experience since the athlete is closer to his/her own physiological ceiling, but more on that later.\nCrossFit and Exercise Intensity\nThe other variable that may be manipulated in a CrossFit workout is intensity:\nThe more work you do in less time, or the higher the power output, the more intense the effort. By employing a constantly varied approach to training, functional movements and intensity lead to dramatic gains in fitness.\nIn this case, the concept of power (i.e. a faster workout) is used synonymously with intensity.\nBut in other modes of exercise, intensity can be changed in other ways.\nIn resistance training, for example, intensity is often measured as a proportion of the maximal weight a person can lift (i.e. their one repetition maximum, or 1RM) that is used for an exercise.\nWhen running, intensity could be the proportion of maximal speed or heart rate, depending on what can be measured at the time.\nFurther, if we look at intensity subjectively, a more intense effort could be anything that the exerciser thinks is harder (the concept of RPE – rate of perceived exertion).\nThis can be influenced not only by the difficulty of the workout, but other social and psychological factors, and their recovery from their previous workout.\nWe can also vary difficulty of a workout by using methods such as repetitions which are slower, or over a longer range of motion, or more repetitions at a lighter weight.\nThe speed of the movement is just one variable that a good trainer can manipulate.\nIn CrossFit however, the emphasis is on completing workouts faster.\nSpeed is characteristic of these workouts, rather than a variable to adjust.\nHow Can You Tell Which is a CrossFit Gym?\nThis can be harder than you think. CrossFit gyms are independently owned, not franchised.\nAs such, there is no common image or corporate branding. And while there are similarities in the types of equipment you will find, the size and layout of gyms will vary significantly.\nSimilarly, they tend to be operated by the owners, and there can be significant differences in the approach of the owners and the instructors they employ.\nThey have a few things in common though.\nThe word “CrossFit” will probably be in the title. When you go into a CrossFit gym you know what you are going to get in terms of exercise.\nYou will lift weights. The exercises will generally be big, compound (multiple joint, multiple muscle group) lifts. You will be challenged to lift heavy.\nThere will be an element of cardiovascular fitness in the workout.\nAnd you will race against a clock, with your time being written up on a board.\nEach gym will have their “workout of the day” or WOD.\nIn keeping with the principles of CrossFit, most people who attend the gym that day will complete this session.\nDepending on the gym they may have other classes or sessions for different levels of ability.\nThe workout may take around 45 minutes, so fits pretty comfortably into a working day.\nOne of the major characteristics of CrossFit is the atmosphere of the gym.\nThough (as mentioned earlier) there is significant variation in gyms, there is an element of teamwork and camaraderie that is missing from most commercial gyms.\nYou don’t see many people training on their own in a corner wearing headphones.\nThis is either a positive or a negative – depending on how you like to train – but it is obvious!\nThere is a genuine social element to attending one of these gyms.\nWho Are CrossFit Coaches?\nAgain, this is a tough one to answer, as the coaches I’ve met come from a variety of backgrounds.\nSome have come from a traditional gym or personal training background, some have sport science degrees, and others have come from sporting or Olympic weightlifting backgrounds.\nAnd some have known nothing but CrossFit in their fitness careers.\nCrossFit qualifications have been a point of discussion in the fitness industry for some time.\nThe basic qualification for a new instructor is a two-day course, which includes theory, practical components, and an assessment.\nThere are other courses an instructor can do to update their knowledge after that but these are not compulsory.\nWhile this is better than nothing, it compares poorly to the rest of the industry.\nIn Australia, the Certificate III and IV qualifications for personal trainers, for example, have recently become much more demanding and can take up to 12 months to complete full time.\nUniversity qualified personal trainers and accredited exercise physiologists have 3 to 4 years of education.\nAnd to work in sport in a professional or semi-professional capacity as a strength and conditioning coach, it’s pretty hard to even get a foot in the door without a Master’s degree or PhD, as well as practical coaching qualifications.\nWhile not everyone needs such a highly qualified coach, it is clear that, in terms of education and depth of scientific understanding, basic CrossFit certifications compare poorly to the industry at large.\nIt’s always useful for the client to know what qualifications their trainer holds and whether they are up to date with ongoing education.\nIs CrossFit Effective?\nThe short answer is: it depends on the individual and level of exercise experience.\nOne of the key tenets of CrossFit – the high effort the workouts consistently call for – means that even someone with a decent exercise history can stand to benefit from the increased effort.\nAll of us have been guilty of coasting in our workouts from time to time, so getting pushed harder can lead to real improvement.\nThe workouts are also conducted in group settings, against the clock, with the encouragement of trainers.\nThe psychological benefits of this environment are huge; most of us will work harder in these conditions.\nIf you have fairly general fitness needs, this could be a great environment for you.\nFor those with more specific needs, CrossFit might not be their best option.\nEarlier in this article, I discussed the need for specificity when designing training programs.\nFor those with a long training history, or those who compete at higher levels of sport, generic programs are comparatively less effective.\nFor example, in my time as a strength and conditioning coach, I have worked at high levels within Australian Football and American Football (gridiron).\nBoth groups of athletes need a degree of aerobic fitness and repeat sprint ability. CrossFit would improve both groups of athletes if they were relatively untrained.\nBut the Australian Football players may need to run hard over relatively long distances with short rest between efforts.\nThe American Football athletes, on the other hand, need to be able to perform high intensity sprints, but get much longer recovery between efforts and cover much shorter distances.\nI spend much more time developing the aerobic capacity of Australian Football players, whereas the gridiron guys have much more of a repeat sprint focus.\nWith CrossFit’s focus on generic programming and timed workouts, and speed as their major marker of intensity, the specific requirements of each sport may not be met.\nAdditionally, differences in the distances covered, types of change of direction and physical contact, and the different body positions in the sports mean the training programs of these players end up looking quite different.\nAnd lastly, the needs of an individual may change over the course of a season.\nMeeting these needs often involves an element of foresight and planning (called “periodisation”).\nThe WOD on any given day may not match these needs.\nHow Safe Is CrossFit\nThe answer to this is, it depends who you are (do you sense a trend here?). It is hard to label CrossFit as “safe” or “unsafe” due to the massive variation in gyms and clientele.\nBut regardless of the gym you are joining or the exercise program you are beginning, there are a few things that should be standard:\n- Did the gym you joined ask you to complete a form outlining your medical and injury history?\n- Did they ask follow up questions based on the answers you provided?\n- If they identified you as a high risk client, did they request a medical clearance?\nIf they didn’t do any of these things, they are breaching their duty of care.\nThere is now an industry standard form and process endorsed by both Fitness Australia (which regulates personal trainers), and Exercise & Sports Science Australia (which regulates exercise physiologists).\nThis level of detail is a good start and clearly a step in the right direction.\n- Did the trainers at this gym assess your ability to perform the exercises required? A movement screening of some sort (for example, the Functional Movement Screening), a fitness test, or a strength test, would provide relevant information here. If everyone is doing the same program, it’s worth making sure everyone is capable!\n- Do they offer introductory courses? Despite the marketing, I know from firsthand experience that not everyone can do the same movements. In particular, CrossFit WODs may involves parts of (or even full) Olympic lifts, which are technically quite challenging. If they run beginner’s classes, sessions where they teach these lifts, or individually adjust the exercises to suit the individual participant’s ability, you can have some confidence that they are looking after their members.\nThere is an inherent risk to performing any exercise under high levels of fatigue, such as CrossFit may encourage.\nAs a general rule, injury rates in CrossFit are comparable to other sports.\nA 2014 study of CrossFit participants found the injury rate to be 20%, though those with more trainer supervision had lower injury rates.\nThis may be a level of risk that someone wishing to compete in CrossFit may be willing to take on, but the recreational exerciser with general goals should make an informed decision about whether this exercise intensity (and risk) is appropriate for them.\nOne of the most well-publicised risks of participating in CrossFit is rhabdomyolysis (or “rhabdo”).\nWhile this condition is not unique to CrossFit, there has been an upsurge in rhabdo cases with the increasing popularity of this type of exercise.\nThe CrossFit brand is also not helped by the casual way that rhabdo is treated by some of its proponents.\nIn an exercise setting, rhabdomyolysis occurs when skeletal muscle breaks down rapidly.\nWhile some muscle damage is an essential part of our adaptation to exercise, a very high volume of demanding resistance exercise using large muscle groups (i.e. squats), can cause an extreme amount of muscle damage.\nAs a result, byproducts of muscle breakdown enter the bloodstream.\nVery dark urine, and unusual swelling in the muscles are obvious signs.\nPreviously this was seen in athlete populations such as triathletes and ultramarathon runners, but those who are relatively untrained and doing CrossFit workouts have a higher risk than other modes of exercise.\nThe incidence of rhabdo in CrossFit is not well documented and the scientific literature to date mostly deals in case studies, so it’s hard to draw conclusion from such a small sample of cases.\nOn top of that, a competent and well-qualified trainer should be able to manage the progression of the client at a safe rate (as discussed above), rather than throwing them off the deep end straight into the full workout.\nThe aim of this article was to remain impartial and present the risks and benefits of CrossFit to someone without a pre-existing opinion, or a lot of exercise knowledge.\nMy own personal experience with CrossFit has been fairly limited, but unusual for someone writing an article about this mode of exercise, I am neither an advocate or a hater.\nI have used CrossFit gyms for testing and training sessions when coaching teams which didn’t have access to gym facilities.\nThis is because they have the weights, lifting platforms, and other equipment we need that not all gyms have.\nThe trainers I’ve met as a result and been welcoming and helpful.\nWhen holidaying in the US a couple of years ago, I was staying with some friends in Denver who train at a CrossFit gym.\nI went along for a workout with them one morning and found it to be a reasonably enjoyable experience.\nWhile it was not a session I would normally select for myself, I was happy to join in.\nThe instructors were degree qualified, did a movement screening with me before the session, and made sure I warmed up properly.\nAnd I got a decent workout (I didn’t perform at my best though – I blame the altitude!). Overall, it was a professionally run operation.\nI’m aware of other CrossFit trainers who are highly experienced and possess good qualifications beyond their CrossFit certifications.\nUnfortunately, I am also aware of trainers who cut a lot of corners and operate outside their scope of practice (by purporting to be able to treat injuries or prescribe diet plans).\nI’m also personally aware of one case of exercise-induced rhabdomyolysis from a CrossFit workout here in Perth.\nThis person was the typical higher risk candidate for the condition (having a poor training history to that point), but was put straight into the main workout by her trainer and ended up hospitalised.\nTake Home Message on CrossFit\nLike all exercise modalities, this CrossFit is not for everyone.\nIf you want a challenge, have a moderate level of fitness, and have lifted weights in the past, go for it.\nIf you want to compete in the sport of CrossFit, by all means go for it.\nIf you have a history of injuries or medical conditions that may affect your ability to exercise, then a group setting, or high intensity exercise, may not be the best choice for you. CrossFit is both of these!\nIf you have very specific needs (such as sports performance), then CrossFit may give you a bit of a boost to your training in the short term, but a more structured long term approach will provide a better benefit."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:30169abd-0139-46f1-babe-2284eb336b90>","<urn:uuid:eb4ce7d3-027c-4150-9ab2-b0cef55e1e42>"],"error":null}
{"question":"Could you explain how child labor conditions in early 1900s America led to reforms, and what role did photography play in exposing these issues?","answer":"In the early 1900s, child labor was widespread during the Industrial Revolution, with children over age 9 expected to work and contribute to family income. Children from poor and immigrant families, some as young as 3, worked in mills and factories for up to 10 hours daily. Photography became a powerful tool for reform as images in magazines and newspapers showed shocking contradictions to the mainstream American view of childhood - the children appeared neither healthy, innocent, nor happy. This photographic evidence helped strengthen reformers' efforts to end child labor, leading to child-protection laws, compulsory education, and the establishment of organizations like the Child Welfare League of America in 1921 and the National Association for the Education of Young Children in 1926.","context":["Changing Versions of Childhood\nThe ambivalence that people feel toward children can be heard in Linda Bird-Davies' voice when she talks about her career.\nShe began a family-child-care program in the mid-1970s so she could be at home with her daughter. Now, more than 20 years later, Bird-Davies is the director of a Los Angeles child-care center--part of an industry that has made it possible for parents to be separated from their children for long hours while they work.\nIt's a setting where young children--currently viewed as resilient and independent--have been forced to adapt to the fast-paced schedules of families in the '90s. But it's one in which Bird-Davies says she sometimes feels sorrow when she knows a child just wants to be with his or her mother.\nThe truth is, Americans' feelings about children and their place in society have always been mixed. In the introduction to his 1982 book The Rise and Fall of Childhood, C. John Sommerville, an associate professor of history at the University of Florida, writes: \"We do not seem to know exactly how we feel about children.\"\nAnd as the end of the 20th century approaches, a confluence of changes--social, economic, technological--has led many authors and child-development experts to warn that the very concept of childhood is in danger. Youngsters are scooted off to daily programs, bombarded by electronic media, and saddled with increasing responsibilities.\n\"Children are much more mature, and their parents treat them that way,\" Bird-Davies says.\nIn the preface to the 1988 revised version of The Hurried Child, David Elkind, a professor of child development at Tufts University, writes: \"Our new conception of children and youth is epitomized in the metaphor of the Superkid. Like Superman, Superkid has spectacular powers and precocious competence even as an infant. This allows us to think that we can hurry the little powerhouse with impunity.\"\nAs the Victorian era was coming to a close in the early 1900s, children were depicted through artwork and advertising as innocent, almost angelic creatures to be pampered and protected from corrupt influences.\nFor the more advantaged classes, that idealistic image often held true, says Robin Love, a child-development professor at San Jose State University who teaches a course on the changing notions of childhood in this century.\nBut the early 1900s were also an era of child labor. Such labor played a major part in the Industrial Revolution, and it was widely assumed that children over the age of 9 should be working and contributing to the family income. Before 1920, children from poor and immigrant families, some as young as 3, worked in mills and factories as long as 10 hours a day.\nUltimately, the increasingly widespread use of a modern medium of communication--photography--helped alert the public to the abuses of child labor and strengthened the hand of reformers who sought to curtail such practices.\n\"The faces staring out from magazines and newspapers were shocking contradictions to what had become the mainstream American definition of childhood. Neither healthy, nor innocent, nor happy, they must have seemed not to be children at all,\" writes Mary Lynn Stevens Heininger in A Century of Childhood: 1820-1920.\nThe end of child labor and the spread of compulsory-education laws were part of a movement to preserve childhood as a special time in life. Organizations devoted to children's issues were founded, among them the Child Welfare League of America in 1921 and the National Association for the Education of Young Children in 1926.\nAs a result of such efforts, a separate justice system for juveniles, child-protection laws, and even playgrounds emerged.\nIronically, at the end of the century, states and communities are again rethinking the way they handle juvenile offenders: Now, the prevailing sentiment is that minors who have committed violent crimes should be subject to the same laws and receive the same punishments as adults.\nA Scientific Approach\nThe early 20th century also saw the beginning of the child-study movement and acceptance of the belief that children should not all be held to one standard of development.\nReligious influences--viewing children as either inherently evil or inherently innocent--gradually were overshadowed by more secular and scientific approaches to childhood, says Martha Minow, a law professor at Harvard University and one of the creators of a course there that examines the role of children in society.\nThroughout the first two decades of the century, a variety of measurements were created to gauge children's development, both physical and psychological. And research on child development rapidly splintered into different schools of thought.\nSigmund Freud, the founder of psychoanalysis, made popular the idea that the problems of adults could be traced to their childhood years.\nOf Freud, Sommerville writes: \"Childhood was not, in his view, simply a convenient time for establishing 'good' behavior patterns; rather, it was the most fateful part of life. The neuroses that troubled his patients in Austria seemed always to go back to their earliest years.\"\nThe increasing prestige accorded what were seen as scientific approaches to child development was reflected, too, in the influence of another school of child-rearing--behaviorism. The belief was that children, almost like Pavlov's dog, could be conditioned to behave a certain way. Parents were advised by psychologists such as John B. Watson to keep their babies on a strict feeding schedule. Early toilet training was encouraged, while affection, rocking, and cuddling were not.\nIn the early decades of the century, the federal government weighed in for the first time with the establishment of the Children's Bureau, which was housed in the U.S. Department of Labor, and the publication of a manual called Infant Care. The 1914 document was intended to provide mothers with practical information on such topics as child health and nutrition, but it also emphasized strict routines and rules.\nGreater attention was being paid to hygiene, sanitation, and routine health examinations. Documents such as the \"Children's Charter,\" from the 1930 White House Conference on Child Health and Protection, spoke of providing children with \"pure food, pure milk, and pure water.\" (\"Children at the White House.\")\nA reaction was building, meanwhile, to the cold and inflexible methods of child-rearing practiced by so many parents early in the century. It was a generation raised on those methods that, as its members became parents themselves, embraced wholeheartedly the much different advice of Dr. Benjamin Spock. His Baby and Child Care, first published in 1946, told parents to eschew rigid methods and trust their own instincts. Spock was later criticized as being too permissive--some even blamed him for the youthful rebelliousness of the 1960s--but today's parents still turn to updated versions of his international best seller for counsel.\nEmbedded in this trend, which Sommerville calls \"the liberation of children,\" was the message that childhood should be fun and that children should be allowed to enjoy it.\nParenting Advice Goes Commercial\nThe publishing success and celebrity status enjoyed by Dr. Spock point out another aspect of child-rearing: While advice for parents has always been available, in the 20th century it became a commercial enterprise. A bewildering array of books and magazines--spouting a variety of opinions on how to \"parent\"--now lines bookstore shelves. Many of the current recommendations on child-rearing, Minow notes, are \"child centered,\" meaning that the child's viewpoint is considered vital.\nBut Kay Hymowitz, a contributing editor of City Journal, a magazine published by the Manhattan Institute, argues that giving children a lot of freedom to make decisions and being concerned about their self-esteem have created in the 1990s what she calls \"egotistical\" children.\nHymowitz is writing a book she says is about \"the end of childhood,\" to be released next fall. She says that what used to be, in the 19th century, an obsession with protecting children began to shift in the 1950s and 1960s to the opposite extreme, with parents being unable to restrain their children.\nWhile \"people don't like bratty kids,\" she says, Americans think that precociousness in young children is cute and often encourage, for example, an early interest in the opposite sex.\nChanges in the structure and well-being of families have had, of course, a significant effect on children. For one, children are simply more likely to live long enough to become adults.\nIn 1900, children had only a 79 percent chance of living past age 15, sociologist Peter Uhlenberg points out. By 1979, those chances had increased to 98 percent.\n\"As infant mortality has declined, childhood has become a more clearly differentiated stage of life, and families have increasingly focused upon children and emphasized the nurturance of children,\" Uhlenberg says in a chapter called \"Death and the Family\" in the 1985 book Growing Up in America: Children in Historical Perspective.\nWith child-labor laws in place, fathers typically became the sole breadwinners. Americans left behind farming jobs and moved to cities for work, writes Donald J. Hernandez in an article on changing demographics published in a 1995 \"Future of Children\" report from the David and Lucile Packard Foundation.\nAnd while oral contraceptives were not available until the 1960s, the family-planning movement grew throughout the century. By 1930, the average number of children in a family had dropped from seven to only two or three.\nBy 1940, most children over the age of 7 were enrolled in public school. But the history of organized programs for younger children is far more complicated.\nDuring the early part of the century, babies and young children were predominantly cared for by their mothers, except in the case of poor mothers who needed to work. Most child-care arrangements were informal.\nBut \"day nurseries,\" operated by charity groups, also were available. Emily D. Cahan, the author of Past Caring: A History of U.S. Preschool Care and Education for the Poor, 1820-1965, estimates that there were 700 day nurseries in the United States by 1916. She also documents the substandard conditions under which many of those programs operated.\nThe nurseries eventually attracted critics, who said that children should not be separated from their mothers. That sentiment contributed to the rise of \"pensions\" that many states paid to lower-income mothers to keep them at home with their children and out of the workforce.\nNursery schools, which served as a type of laboratory for the child-study movement, were developed in the 1920s and 1930s. And kindergartens, developed by the German teacher Friedrich Froebel in the 1830s, began to spread through the United States in the early part of this century.\nWhile such influential figures as Froebel, the Italian physician Maria Montessori, and the Swiss psychologist Jean Piaget are best known for their theories on education, they have also shaped the way society in general views and treats children.\nIt was Froebel who emphasized that children learn through play. He introduced the idea of teachers as \"facilitators,\" instead of authoritarians.\nChild-size tables, chairs, and cups--now common in many homes with young children--can be traced to Montessori in the early 1900s. In the 1920s, Piaget identified stages of development that children go through as they move from exploring the world with their senses to understanding abstract concepts.\nWomen in the Workforce\nExperts often point out that the fields of early-childhood education and child care have developed simultaneously, but with little connection between the two.\nThe United States faced its first major child-care dilemma during the Second World War: With millions of fathers in the military, many mothers confronted the decision of whether to stay home or go to work in defense factories.\nSimply being a mother was patriotic enough, the nation's leaders stressed. Still, tens of thousands of women placed their children in special wartime child-care centers operated by the federal government and went to work.\nWhile most of those centers closed in the years after World War II, the end of the war didn't necessarily mean the end of demands for child-care services.\nBetween 1940 and 1960, Hernandez writes, the number of homes with mothers and fathers both working increased significantly. The economic benefits of being employed, combined with escalating divorce rates and an increase in never-married mothers, led to a greater need for child care, and the demand for organized programs is expected to grow in the 21st century.\nSince 1975, the percentage of working mothers has increased dramatically, according to the Labor Department's Women's Bureau. In 1975, 47.3 percent of mothers with children under 18 were in the labor force. Last year, the figure was 72 percent.\nAnd current U.S. Census Bureau figures show that more than 10 million children under 5--about half the children in that age group--are either in child care or have parents who are seeking child care of some sort.\nIt's a trend that the media, even women's magazines, largely ignored until publications like Working Mother came on the scene in the late 1970s.\nNow, in the last decade of the century, child care and educational programs for young children have become major political issues at the local, state, and federal levels.\nGrowing interest in brain development, combined with changes in welfare policy, have led many states to expand child-care and preschool programs. The issue has also received more attention as women seek more flexible work schedules that allow them to balance their home and job responsibilities.\nIn Images of Childhood, published in 1996, Maris A. Vinovskis notes that movements that focus on children often begin with efforts to address poverty. A 20th-century example is Head Start, the popular federal initiative that began as a summer program for low-income children in 1965 and has grown to a full-year, and in some cases full-day, program serving about 800,000 children.\nWhile research on the effectiveness of Head Start has been mixed, many Americans have come to view early education as an essential part of the childhood experience and a necessity for future success in school and life.\nAnother place youngsters came to spend more and more of their time was at home--in front of the television set. And almost from the time TV was introduced into American households in the late 1940s, the effects of the \"electronic babysitter,\" the \"boob tube,\" the \"vast wasteland\" on children have been a near-constant subject of national worry and debate.\nThroughout the latter part of the century, parents have had to confront such issues as violence, profanity, and sexual explicitness on television as well as the sheer number of hours their children are watching.\nIn the 1993 book Children and Television: Images in a Changing Sociocultural World, TV is described as a part of the American household that competes with traditional means of socialization, such as the family, school, and church.\nAnd concerns have been raised over how children are portrayed on television and through the media in general. Advertising images of teenage girls wearing makeup and dressed in alluring fashions have once again helped create a concept of children as \"miniature adults,\" as they were viewed through much of history.\nCultural and societal changes--not just working mothers, but significant levels of drug use, sexual activity, and violence among children and teenagers--have led many experts and social critics to argue that the lines between childhood and adulthood have been irrevocably blurred.\nBut it's not just negative influences that have robbed children of their special childhood years, says Elkind. The efforts of parents and the practices of schools can also force children to grow up too fast.\nIn The Hurried Child, Elkind writes that pushing children into sports and other activities at a young age, as well as emphasizing reading skills during the preschool years, can create children who are overloaded with adultlike decisions. And schools, by pushing more demanding curricula and testing into lower and lower grades, may actually be harming children, he contends.\nBut children aren't the only ones influenced by technology and the information age. Adults' impressions of children have shifted because of the media, says Cynthia Scheibe, the director of the Center for Research on the Effects of Television at Ithaca College.\nFor one, educational television programs--especially \"Sesame Street\"--have raised expectations of what children should know when they enter kindergarten, Scheibe says.\nAnd news reports--often disturbing accounts of violence and drug use by young people--also shape adults' views of children, says Lillian Brinkley, the principal of the Willard Model Elementary School in Norfolk, Va., and a 38-year veteran of education.\nBut while sensational cases often make it seem as if children are out of control, Brinkley says that hasn't been her experience. Students wind up in her office for the same reasons they did 30 years ago--fighting, name-calling, setting off the fire alarm.\nWhile the society children live in has changed dramatically, \"there is still that line that runs down the middle,\" Brinkley says. \"As filled as their world is with all kinds of things, they still want to know that there is someone there to provide some direction for them.\"\nVol. 18, Issue 24, Page 32-34","Changing Versions of Childhood\nThe ambivalence that people feel toward children can be heard in Linda Bird-Davies' voice when she talks about her career.\nShe began a family-child-care program in the mid-1970s so she could be at home with her daughter. Now, more than 20 years later, Bird-Davies is the director of a Los Angeles child-care center--part of an industry that has made it possible for parents to be separated from their children for long hours while they work.\nIt's a setting where young children--currently viewed as resilient and independent--have been forced to adapt to the fast-paced schedules of families in the '90s. But it's one in which Bird-Davies says she sometimes feels sorrow when she knows a child just wants to be with his or her mother.\nThe truth is, Americans' feelings about children and their place in society have always been mixed. In the introduction to his 1982 book The Rise and Fall of Childhood, C. John Sommerville, an associate professor of history at the University of Florida, writes: \"We do not seem to know exactly how we feel about children.\"\nAnd as the end of the 20th century approaches, a confluence of changes--social, economic, technological--has led many authors and child-development experts to warn that the very concept of childhood is in danger. Youngsters are scooted off to daily programs, bombarded by electronic media, and saddled with increasing responsibilities.\n\"Children are much more mature, and their parents treat them that way,\" Bird-Davies says.\nIn the preface to the 1988 revised version of The Hurried Child, David Elkind, a professor of child development at Tufts University, writes: \"Our new conception of children and youth is epitomized in the metaphor of the Superkid. Like Superman, Superkid has spectacular powers and precocious competence even as an infant. This allows us to think that we can hurry the little powerhouse with impunity.\"\nAs the Victorian era was coming to a close in the early 1900s, children were depicted through artwork and advertising as innocent, almost angelic creatures to be pampered and protected from corrupt influences.\nFor the more advantaged classes, that idealistic image often held true, says Robin Love, a child-development professor at San Jose State University who teaches a course on the changing notions of childhood in this century.\nBut the early 1900s were also an era of child labor. Such labor played a major part in the Industrial Revolution, and it was widely assumed that children over the age of 9 should be working and contributing to the family income. Before 1920, children from poor and immigrant families, some as young as 3, worked in mills and factories as long as 10 hours a day.\nUltimately, the increasingly widespread use of a modern medium of communication--photography--helped alert the public to the abuses of child labor and strengthened the hand of reformers who sought to curtail such practices.\n\"The faces staring out from magazines and newspapers were shocking contradictions to what had become the mainstream American definition of childhood. Neither healthy, nor innocent, nor happy, they must have seemed not to be children at all,\" writes Mary Lynn Stevens Heininger in A Century of Childhood: 1820-1920.\nThe end of child labor and the spread of compulsory-education laws were part of a movement to preserve childhood as a special time in life. Organizations devoted to children's issues were founded, among them the Child Welfare League of America in 1921 and the National Association for the Education of Young Children in 1926.\nAs a result of such efforts, a separate justice system for juveniles, child-protection laws, and even playgrounds emerged.\nIronically, at the end of the century, states and communities are again rethinking the way they handle juvenile offenders: Now, the prevailing sentiment is that minors who have committed violent crimes should be subject to the same laws and receive the same punishments as adults.\nA Scientific Approach\nThe early 20th century also saw the beginning of the child-study movement and acceptance of the belief that children should not all be held to one standard of development.\nReligious influences--viewing children as either inherently evil or inherently innocent--gradually were overshadowed by more secular and scientific approaches to childhood, says Martha Minow, a law professor at Harvard University and one of the creators of a course there that examines the role of children in society.\nThroughout the first two decades of the century, a variety of measurements were created to gauge children's development, both physical and psychological. And research on child development rapidly splintered into different schools of thought.\nSigmund Freud, the founder of psychoanalysis, made popular the idea that the problems of adults could be traced to their childhood years.\nOf Freud, Sommerville writes: \"Childhood was not, in his view, simply a convenient time for establishing 'good' behavior patterns; rather, it was the most fateful part of life. The neuroses that troubled his patients in Austria seemed always to go back to their earliest years.\"\nThe increasing prestige accorded what were seen as scientific approaches to child development was reflected, too, in the influence of another school of child-rearing--behaviorism. The belief was that children, almost like Pavlov's dog, could be conditioned to behave a certain way. Parents were advised by psychologists such as John B. Watson to keep their babies on a strict feeding schedule. Early toilet training was encouraged, while affection, rocking, and cuddling were not.\nIn the early decades of the century, the federal government weighed in for the first time with the establishment of the Children's Bureau, which was housed in the U.S. Department of Labor, and the publication of a manual called Infant Care. The 1914 document was intended to provide mothers with practical information on such topics as child health and nutrition, but it also emphasized strict routines and rules.\nGreater attention was being paid to hygiene, sanitation, and routine health examinations. Documents such as the \"Children's Charter,\" from the 1930 White House Conference on Child Health and Protection, spoke of providing children with \"pure food, pure milk, and pure water.\" (\"Children at the White House.\")\nA reaction was building, meanwhile, to the cold and inflexible methods of child-rearing practiced by so many parents early in the century. It was a generation raised on those methods that, as its members became parents themselves, embraced wholeheartedly the much different advice of Dr. Benjamin Spock. His Baby and Child Care, first published in 1946, told parents to eschew rigid methods and trust their own instincts. Spock was later criticized as being too permissive--some even blamed him for the youthful rebelliousness of the 1960s--but today's parents still turn to updated versions of his international best seller for counsel.\nEmbedded in this trend, which Sommerville calls \"the liberation of children,\" was the message that childhood should be fun and that children should be allowed to enjoy it.\nParenting Advice Goes Commercial\nThe publishing success and celebrity status enjoyed by Dr. Spock point out another aspect of child-rearing: While advice for parents has always been available, in the 20th century it became a commercial enterprise. A bewildering array of books and magazines--spouting a variety of opinions on how to \"parent\"--now lines bookstore shelves. Many of the current recommendations on child-rearing, Minow notes, are \"child centered,\" meaning that the child's viewpoint is considered vital.\nBut Kay Hymowitz, a contributing editor of City Journal, a magazine published by the Manhattan Institute, argues that giving children a lot of freedom to make decisions and being concerned about their self-esteem have created in the 1990s what she calls \"egotistical\" children.\nHymowitz is writing a book she says is about \"the end of childhood,\" to be released next fall. She says that what used to be, in the 19th century, an obsession with protecting children began to shift in the 1950s and 1960s to the opposite extreme, with parents being unable to restrain their children.\nWhile \"people don't like bratty kids,\" she says, Americans think that precociousness in young children is cute and often encourage, for example, an early interest in the opposite sex.\nChanges in the structure and well-being of families have had, of course, a significant effect on children. For one, children are simply more likely to live long enough to become adults.\nIn 1900, children had only a 79 percent chance of living past age 15, sociologist Peter Uhlenberg points out. By 1979, those chances had increased to 98 percent.\n\"As infant mortality has declined, childhood has become a more clearly differentiated stage of life, and families have increasingly focused upon children and emphasized the nurturance of children,\" Uhlenberg says in a chapter called \"Death and the Family\" in the 1985 book Growing Up in America: Children in Historical Perspective.\nWith child-labor laws in place, fathers typically became the sole breadwinners. Americans left behind farming jobs and moved to cities for work, writes Donald J. Hernandez in an article on changing demographics published in a 1995 \"Future of Children\" report from the David and Lucile Packard Foundation.\nAnd while oral contraceptives were not available until the 1960s, the family-planning movement grew throughout the century. By 1930, the average number of children in a family had dropped from seven to only two or three.\nBy 1940, most children over the age of 7 were enrolled in public school. But the history of organized programs for younger children is far more complicated.\nDuring the early part of the century, babies and young children were predominantly cared for by their mothers, except in the case of poor mothers who needed to work. Most child-care arrangements were informal.\nBut \"day nurseries,\" operated by charity groups, also were available. Emily D. Cahan, the author of Past Caring: A History of U.S. Preschool Care and Education for the Poor, 1820-1965, estimates that there were 700 day nurseries in the United States by 1916. She also documents the substandard conditions under which many of those programs operated.\nThe nurseries eventually attracted critics, who said that children should not be separated from their mothers. That sentiment contributed to the rise of \"pensions\" that many states paid to lower-income mothers to keep them at home with their children and out of the workforce.\nNursery schools, which served as a type of laboratory for the child-study movement, were developed in the 1920s and 1930s. And kindergartens, developed by the German teacher Friedrich Froebel in the 1830s, began to spread through the United States in the early part of this century.\nWhile such influential figures as Froebel, the Italian physician Maria Montessori, and the Swiss psychologist Jean Piaget are best known for their theories on education, they have also shaped the way society in general views and treats children.\nIt was Froebel who emphasized that children learn through play. He introduced the idea of teachers as \"facilitators,\" instead of authoritarians.\nChild-size tables, chairs, and cups--now common in many homes with young children--can be traced to Montessori in the early 1900s. In the 1920s, Piaget identified stages of development that children go through as they move from exploring the world with their senses to understanding abstract concepts.\nWomen in the Workforce\nExperts often point out that the fields of early-childhood education and child care have developed simultaneously, but with little connection between the two.\nThe United States faced its first major child-care dilemma during the Second World War: With millions of fathers in the military, many mothers confronted the decision of whether to stay home or go to work in defense factories.\nSimply being a mother was patriotic enough, the nation's leaders stressed. Still, tens of thousands of women placed their children in special wartime child-care centers operated by the federal government and went to work.\nWhile most of those centers closed in the years after World War II, the end of the war didn't necessarily mean the end of demands for child-care services.\nBetween 1940 and 1960, Hernandez writes, the number of homes with mothers and fathers both working increased significantly. The economic benefits of being employed, combined with escalating divorce rates and an increase in never-married mothers, led to a greater need for child care, and the demand for organized programs is expected to grow in the 21st century.\nSince 1975, the percentage of working mothers has increased dramatically, according to the Labor Department's Women's Bureau. In 1975, 47.3 percent of mothers with children under 18 were in the labor force. Last year, the figure was 72 percent.\nAnd current U.S. Census Bureau figures show that more than 10 million children under 5--about half the children in that age group--are either in child care or have parents who are seeking child care of some sort.\nIt's a trend that the media, even women's magazines, largely ignored until publications like Working Mother came on the scene in the late 1970s.\nNow, in the last decade of the century, child care and educational programs for young children have become major political issues at the local, state, and federal levels.\nGrowing interest in brain development, combined with changes in welfare policy, have led many states to expand child-care and preschool programs. The issue has also received more attention as women seek more flexible work schedules that allow them to balance their home and job responsibilities.\nIn Images of Childhood, published in 1996, Maris A. Vinovskis notes that movements that focus on children often begin with efforts to address poverty. A 20th-century example is Head Start, the popular federal initiative that began as a summer program for low-income children in 1965 and has grown to a full-year, and in some cases full-day, program serving about 800,000 children.\nWhile research on the effectiveness of Head Start has been mixed, many Americans have come to view early education as an essential part of the childhood experience and a necessity for future success in school and life.\nAnother place youngsters came to spend more and more of their time was at home--in front of the television set. And almost from the time TV was introduced into American households in the late 1940s, the effects of the \"electronic babysitter,\" the \"boob tube,\" the \"vast wasteland\" on children have been a near-constant subject of national worry and debate.\nThroughout the latter part of the century, parents have had to confront such issues as violence, profanity, and sexual explicitness on television as well as the sheer number of hours their children are watching.\nIn the 1993 book Children and Television: Images in a Changing Sociocultural World, TV is described as a part of the American household that competes with traditional means of socialization, such as the family, school, and church.\nAnd concerns have been raised over how children are portrayed on television and through the media in general. Advertising images of teenage girls wearing makeup and dressed in alluring fashions have once again helped create a concept of children as \"miniature adults,\" as they were viewed through much of history.\nCultural and societal changes--not just working mothers, but significant levels of drug use, sexual activity, and violence among children and teenagers--have led many experts and social critics to argue that the lines between childhood and adulthood have been irrevocably blurred.\nBut it's not just negative influences that have robbed children of their special childhood years, says Elkind. The efforts of parents and the practices of schools can also force children to grow up too fast.\nIn The Hurried Child, Elkind writes that pushing children into sports and other activities at a young age, as well as emphasizing reading skills during the preschool years, can create children who are overloaded with adultlike decisions. And schools, by pushing more demanding curricula and testing into lower and lower grades, may actually be harming children, he contends.\nBut children aren't the only ones influenced by technology and the information age. Adults' impressions of children have shifted because of the media, says Cynthia Scheibe, the director of the Center for Research on the Effects of Television at Ithaca College.\nFor one, educational television programs--especially \"Sesame Street\"--have raised expectations of what children should know when they enter kindergarten, Scheibe says.\nAnd news reports--often disturbing accounts of violence and drug use by young people--also shape adults' views of children, says Lillian Brinkley, the principal of the Willard Model Elementary School in Norfolk, Va., and a 38-year veteran of education.\nBut while sensational cases often make it seem as if children are out of control, Brinkley says that hasn't been her experience. Students wind up in her office for the same reasons they did 30 years ago--fighting, name-calling, setting off the fire alarm.\nWhile the society children live in has changed dramatically, \"there is still that line that runs down the middle,\" Brinkley says. \"As filled as their world is with all kinds of things, they still want to know that there is someone there to provide some direction for them.\"\nVol. 18, Issue 24, Page 32-34"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"content_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:e7605065-71cd-466c-bfcb-86c993e1a3eb>","<urn:uuid:e7605065-71cd-466c-bfcb-86c993e1a3eb>"],"error":null}
{"question":"What's the connection between being precise with details and good health - both in medical treatments and food choices?","answer":"Precision and attention to detail are crucial both in medical treatment and dietary choices. The story of Mr. Pretty Much illustrates how being careless with details can have fatal consequences, as seen when he accepts treatment from a veterinarian instead of a proper doctor. Similarly, in health and cancer prevention, the Mediterranean diet requires specific attention to food choices and preparation techniques to maximize nutrient bioavailability and achieve its protective effects. The diet has precise requirements about types and amounts of foods to include and limit, showing that being 'pretty much' correct about dietary choices is not sufficient for optimal health benefits.","context":["The first-ever Inspire! Toronto International Book Fair took place last week, November 13-16, at the Metro Toronto Convention Centre, eliciting mixed reactions. Linda Leith Publishing was there, in the Discovery Pavillion pod P5, and we enjoyed ourselves.\nMr. Pretty Much, by Hu Shih, translated from Chinese by Jennifer Quist\nMr. Pretty Much\nWho is China’s most celebrated person? You know him, don’t you? Everyone everywhere knows his name. His surname is Pretty, his given name is Much. He is in every province, every county, every village. You’ve certainly seen him, certainly heard it said of him, “Mr. Pretty Much represents all of us in China.” Everyone says it.\nMr. Pretty Much has a face pretty much like yours and mine. He has two eyes, but cannot see clearly; two ears, but cannot hear well. He has a nose and mouth, but isn’t particular about smells or tastes. His mind is not small, but his memory is not very good. He does not have a head for details.\nHe is known to say, “There’s no need to be so fussy. Everything is pretty much fine.”\nWhen he was little, his mother sent him to buy brown sugar, but he brought home white sugar. His mother scolded him, but he shook his head and said, “Brown sugar, white sugar—aren’t they pretty much the same?”\nHe went to school, where the teacher asked him, “Which province borders Hebei to the west?”\nMr. Pretty Much answered, “Shaanxi.”\nThe teacher replied, “Wrong. It’s Shanxi, not Shaanxi.”\nMr. Pretty Much said, “Shaanxi, Shanxi—they’re pretty much the same, aren’t they?”\nLater, he became a clerk in a money lender’s shop. He had learned to write, had learned to work with numbers—it’s just that he was never meticulous about doing either. In printing the character for the number one thousand, he often missed a stroke, making it into the number ten. The lender would get angry, reprimanding him as Mr. Pretty Much smilingly, obsequiously explained, “Between ten and one thousand there’s only one small stroke too many. They’re pretty much the same, aren’t they?”\nHe once needed to make an important business trip, a trip by train to Shanghai. Rambling all the way to the station, he arrived two minutes too late. The train had already left. Wide-eyed, staring into the distance at the trailing coal smoke of the train, shaking his head, Mr. Pretty Much said, “It’s all the same to me if I leave today or tomorrow. It doesn’t matter. But how could the railroad be so exacting? An 8:30 departure and an 8:32 departure—aren’t they pretty much the same?” He slowly, slowly walked home, muttering his disbelief that the train would not linger two minutes.\nWhen Mr. Pretty Much fell suddenly, deathly ill, he sent his family to East Street to fetch Mr. Yang, a doctor who could treat his illness. His family scrambled to help, but after a quick search, Mr. Yang was not found. However, on West Street they did find Mr. Wang. He was not a doctor but a veterinarian, a doctor for cows. They brought him back to their sick loved one all the same. From his sickbed, Mr. Pretty Much knew Mr. Wang was not the man he had called for, but sick, in pain, afraid, unable to wait any longer, he thought, “It’s a good thing Mr. Wang and Mr. Yang are pretty much the same. Let Wang have a go at treating me.”\nCow doctor Wang approached the bed, using veterinary medicines and methods meant to cure Mr. Pretty Much. An hour had not yet passed before Mr. Pretty Much, alas, died. When Mr. Pretty Much was pretty much dead, able to breath only in faint, fleeting gasps, he said, “The living and the dead are pretty-pretty-pretty much the same—if everything is—pretty—pretty—much the same—then—everything is fine. There’s no need—to be too—too fussy—is there?” He spoke his motto one final time, and breathed his last.\nAfter his death, everyone praised Mr. Pretty Much, studied his example, wondered at it. All his life he was never fussy, never exacting. He was truly a man of the finest moral character. He became a saint among the people, known as “Master of Flexibility.” His reputation spread farther and farther, became greater and greater. Countless, countless people studied his model behaviour. From then on, everyone—all of China—became a careless nation full of people like Mr. Pretty Much.\nJennifer Quist's Comments on the Translation\nI began the task without any sense of its irony.\nThe task was my first literary translation of a canonical work of modern Chinese into English, my native language. As a humble beginner, I chose a text that was short and fairly simple. It was Hu Shih’s ?????. Some of my English-speaking classmates called it “Mr. Almost.” I’d seen it rendered in writing as “Mr. Close Enough,” which is a poor translation, and as “Mr. More or Less,” which is the best translation. I suppose I was too vain to give my translation the same name as anyone else’s, and as I sat at the table where I was supposed to be minding the coffee urn at a university conference, I opened my notebook to a blank page and called Hu Shih’s story “Mr. Pretty Much.”\nHu Shih has been called the architect of literary reforms in China in the early twentieth century. His 1917 “Suggestions for a Reform of Literature” validated and promoted Chinese writing, criticism, and scholarship in common rather than Classical language. He called for changes in literature and also in Chinese society. “Mr. Pretty Much” is one of those calls. It’s a fable, a lesson, a warning against the dangers of failing to safeguard details, especially when carelessness becomes widespread, as Hu Shih believed it was in China.\nSee it—the irony of a first-time translator choosing as her text a cautionary tale about the need for precision and exactness? From the translation of Hu Shih’s very first line—the title—precision falters, details slip away, the untranslatable emerges. In this story, the cliché of material becoming lost in translation doesn’t wait one syllable before it disturbs the entire endeavor.\nTranslation may be the most strange and fraught of literary projects. I have never tried to do it between any other pair of languages, but perhaps there is something in the exceptionally vast space between Chinese and English that highlights the problems common to all translation. There is no shared root language here—nothing providing hunches. The Chinese-English translator cannot, like Walter Benjamin, accomplish her task by standing outside a wood, calling into it, listening for the echoing back of her own voice. In translating Chinese into English, she walks into the wood, moss between her toes, leaves in her hair, branches snagging at her clothes, other voices in her ears, feeling and smelling her way forward, opening her mind and heart to what she may come to understand in pure but too often unspeakable language. There may be no shared hunches and very little shared history but there is always shared humanity. Here, it must be made to be enough.\nIt isn’t easy. Hu Shih’s story is written in a jovial, teasing tone, mixing formality with familiarity. I like it, tried to preserve it, but worried it might seem like my voice—the self-conscious translator’s—was inconsistent, not quite invisible enough. In the eight paragraphs of text, untranslatable puzzles come one after another. The foreshadowing in the play on the word ?, inadequacy, vanishes with the translation of the title. A little watered-down Hanyu Pinyin used to romanize the script salvages what would have been lost in a comparison between the pronunciation of the provinces of Shaanxi and Shanxi. But in the next paragraph, there is a distinct loss of elegance with the need to over-explain a plot-point that revolves around a misplaced stroke in the writing of simple numerical characters—the easiness with which the number ten ? could be misspelled in Chinese as ?, one thousand. The most difficult problem yet arises with the question of how to convey a subtle visual difference between the characters ? and ? to readers who know nothing about how either character is pronounced or written or what the words means. I resolved it by degrading it, equating the subtle, sophisticated difference to the rhyming of the names Wang and Yang. Hu Shih’s original story has no Yang in it. I know it. All of China knows it. The Anglophonie does not know—will never know—and I don’t know how to tell them without breaching the story, falling into a footnote, introducing it with an essay like this one, a translator’s commentary like a buzzing fly on the face of the prose.\nThank you for this forbearance—for waiting this long without swatting me away. Please enjoy Hu Shih’s story, or at least, the version I have rewritten—pretty much a translation.\nComments and Translation © 2017, Jennifer Quist\nJennifer Quist is the author of Love Letters of the Angels of Death (LLP 2013) and Sistering (LLP 2015), both of which have been honoured nationally and internationally. LLP will publish her new novel, The Apocalypse of Morgan Turner, in Spring 2018.","Abstract A healthy diet plays an important role in primary and secondary prevention of cancer. The mechanisms responsible for these effects include reductions in inflammation, oxidative damage, metabolic syndrome, and weight. The Mediterranean diet consists primarily of fish, vegetables, legumes, whole grains, potatoes, fruits, extra virgin olive oil EVOO, moderate amounts of wine, and small amounts of red meat. It limits processed foods and refined sugar. Achieving this dietary pattern is a simple and attainable goal. Certain food preparation techniques can improve the bioavailability of important nutrients in the Mediterranean diet. Observational and clinical studies show the Mediterranean diet is effective for primary and possibly secondary prevention of cancer.\nIn regards to alcohol intake and its positive or negative effects on health, there is no unanimity among for A moderate alcohol intake mediterranean 30 g a day could have a protective effect against the onset of kidney cancer, while an excessive intake surely is a risk factor in the onset of many cancers oral cavity cancer, esophagus cancer, breast cancer, mediterranean cancer, stomach cancer and liver cancer [ 2 ]. As emerged in some studies, there are caner kinds of problems producing Gaps diet approved foods list complexity: Pqtients myths diet misconceptions are associated with the traditional Mediterranean diet, and many difficulties are related with cancer correct distinction between Mediterranean foods and healthy, but non-Mediterranean foods for 27 ]. Conflicts of Diet The authors declare no patients of patients. Int J Epidemiol. Free radical damage cancer have direct effects on DNA. Some evidence suggests that not eating red meat is the most important part. A posteriori mesiterranean.\nDiet in diet and especially Mediterranean diet play a crucial for for colorectal cancer since healthy or non-healthy diet patterns are considered among the most cancer risk factors in the of neoplasia so to understand which areas for nutrition should nutrition cancer for global population. The diet and year death rate in the seven countries study onset of this neoplasia patients 15, ]. Quizzes Infographics Videos Activities. Mediterranean Diet and Breast Cancer Risk. Given mediterranean assumptions, the main aim of this narrative review was to understand as Mediterranean diet may contribute to diet cancer mediterranean analyzing the impact of MD on more kinds. patients\n|Remarkable for cancer diet patients mediterranean congratulate seems excellent idea||A growing number of studies do link a Mediterranean pattern of eating with lower cancer risk. Diet alcohol intake and cancer incidence in women. Mediterranean Diet for Cancer Prevention Printer Friendly Page Abstract A healthy diet plays an for role in primary meditwrranean secondary patients of cancer.|\n|Apologise but diet cancer mediterranean patients for seems excellent idea||Heart disease Cancer prevention Weight management Diabetes management Cholesterol management. Considered for the first for by Ancel Keys patients his colleagues as cancer diet patienhs in saturated lipids and able to patients cardiovascular system mediterranean to low cholesterol level in the blood [ for ], in the diet years it cancer identified as a diet pattern composed by foods rich in high protective nutrients able to prevent from several patisnts. Therefore, over the years, it has been necessary to define new research methodologies general description, dietetic mediterranean, a priori or a posteriori scoring systems [ 51 ] able to evaluate the whole diet pattern, tools that, although diet in their estimate methods, aim mediterraneah understand the level of adherence to MD of each individual involved in a specific study. HR arMEDhigh vs.|"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:247d2cd3-d887-458d-87c7-6c099ffe9df1>","<urn:uuid:ad2d0ba7-a25a-4dde-9fe8-4cd9f67e71c8>"],"error":null}
{"question":"Hey folks - got a fam member with cognitive issues post-brain injury. Any life hacks for helping them stay organized?","answer":"There are multiple strategies and life-task shortcuts available for helping individuals with cognitive issues following brain injury. These include using medication alarms, developing systems for locating stored items, implementing memory compensation techniques, using concentration exercises, and utilizing specific communication tools. These approaches are designed to improve brain function and quality of life while helping with organization and daily tasks.","context":["The Brain Injury Survival Kit\n365 Tips, Tools and Tricks to Deal with Cognitive Function Loss\nBy (author) Cheryle Sullivan\nNormal Price: $33.05\nYour Price: $29.75 AUD, inc. GST\nShipping: $7.95 per order\nYou Save: $3.31! (10% off normal price)\nPlus...earn $1.49 in Boomerang Bucks\nAvailability: Available, ships in 8-11 days\nBrain Injury Survival Kit by Cheryle Sullivan\nBook DescriptionOver 1.4 million people sustain a brain injury each year in the United States. Add to that the number of returning Veterans with a brain injury and the numbers are staggering. The Brain Injury Survival Kit: 365 Tips, Tools & Tricks to Deal with Cognitive Function Loss aims to give brain injury survivors, their families and loved ones the strategies they need to improve brain function and quality of life. The book is a compendium of tips, techniques and life-task shortcuts that author Cheryle Sullivan has compiled from her personal experience. Readers will learn successful approaches to:* Balancing a checkbook* Using medication alarms* Compensating for impaired memory function* Locating things that have been put away* Word finding* Concentration exercises* Communication tools* And much more!From basic principles to unique solutions for saving time and energy, this book is packed with helpful information for those coping with the special challenges of a brain injury.\nBuy Brain Injury Survival Kit book by Cheryle Sullivan from Australia's Online Bookstore, Boomerang Books.\nBook DetailsISBN: 9781932603736\n(226mm x 170mm x 10mm)\nImprint: Demos Medical Publishing\nPublisher: Demos Medical Publishing\nPublish Date: 1-Jun-2008\nCountry of Publication: United States\nCustomers who bought this also bought...\n» Have you read this book? We'd like to know what you think about it - write a review about Brain Injury Survival Kit book by Cheryle Sullivan and you'll earn 50c in Boomerang Bucks loyalty dollars (you must be a member - it's free to sign up!)\nAuthor Biography - Cheryle Sullivan\nAs a brain injury survivor and a doctor, Dr. Cheryle Sullivan offers a unique perspective on neurologic damage and the resulting functional impairments.\nBestselling Books: Our Current Bestsellers | Australia's Hottest 1000 Books | Bestselling Fiction | Bestselling Crime Mysteries and Thrillers | Bestselling Non Fiction Books | Bestselling Sport Books | Bestselling Gardening and Handicrafts Books | Bestselling Biographies | Bestselling Food and Drink | Bestselling History | Bestselling Travel Books | Bestselling School Textbooks & Study Guides | Bestselling Children's General Non-Fiction | Bestselling Young Adult Fiction | Bestselling Children's Fiction | Bestselling Picture Books | Top 100 US Bestsellers\nPhone: 1300 36 33 32 (9am-5pm Mon-Fri AEST) - International: +61 2 9960 7998 - Online Form\nAddress: Boomerang Books, 878 Military Road, Mosman Junction, NSW, 2088\n© 2003-2017. All Rights Reserved. Eclipse Commerce Pty Ltd - ACN: 122 110 687 - ABN: 49 122 110 687\nFor every $20 you spend on books, you will receive $1 in Boomerang Bucks loyalty dollars. You can use your Boomerang Bucks as a credit towards a future purchase from Boomerang Books. Note that you must be a Member (free to sign up) and that conditions do apply."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:2b4eb997-dccc-45dd-9e0d-8d39f740e41e>"],"error":null}
{"question":"I need to understand the certification process - what exactly is a Certificate Signing Request (CSR) and how does it relate to Certificate Authorities? Please explain the verification process in detail.","answer":"A Certificate Signing Request (CSR) is an unsigned certificate that is submitted to a Certification Authority (CA) for signing. The CA signs it with the Private Key of their CA Certificate, transforming it into a real certificate. The CA acts as a trusted third party that authenticates network entities through secure means. The resulting certificate contains X.509 information about its owner (the subject), the signing CA (the issuer), the owner's public key, and the CA's signature. Other network entities can verify these signatures to confirm that a CA has authenticated the certificate bearer.","context":["``I know you believe you understand what you think I said, but I am not sure you\nrealize that what you heard is not what I meant.''\n- The positive identification of a network entity such as a server, a\nclient, or a user. In SSL context the server and client\nCertificate verification process.\n- The restriction of access to network realms. In Apache context\nusually the restriction of access to certain URLs.\n- An unambiguous formula or set of rules for solving a problem in a finite\nnumber of steps. Algorithms for encryption are usually called Ciphers.\n- A data record used for authenticating network entities such\nas a server or a client. A certificate contains X.509 information pieces\nabout its owner (called the subject) and the signing Certificate\nAuthority (called the issuer), plus the owner's public key and the\nsignature made by the CA. Network entities verify these signatures using\nCertification Authority (CA)\n- A trusted third party whose purpose is to sign certificates for network\nentities it has authenticated using secure means. Other network entities\ncan check the signature to verify that a CA has authenticated the bearer\nof a certificate.\nCertificate Signing Request (CSR)\n- An unsigned certificate for submission to a Certification Authority,\nwhich signs it with the Private Key of their CA Certificate. Once\nthe CSR is signed, it becomes a real certificate.\n- An algorithm or system for data encryption. Examples are DES, IDEA, RC4, etc.\n- The result after a Plaintext passed a Cipher.\n- A configuration command that controls one or more aspects of a program's\nbehavior. In Apache context these are all the command names in the first\ncolumn of the configuration files.\n- A HTTP command for proxying raw data channels over HTTP. It can be used to\nencapsulate other protocols, such as the SSL protocol.\n- An encrypted text block that validates a certificate or other file. A\nCertification Authority creates a signature by generating a\nhash of the Public Key embedded in a Certificate, then\nencrypting the hash with its own Private Key. Only the CA's\npublic key can decrypt the signature, verifying that the CA has\nauthenticated the network entity that owns the Certificate.\n- Diminished in cryptographic strength (and security) in order to comply\nwith the United States' Export Administration Regulations (EAR).\nExport-crippled cryptographic software is limited to a small key size,\nresulting in Ciphertext which usually can be decrypted by brute\nFully-Qualified Domain-Name (FQDN)\n- The unique name of a network entity, consisting of a hostname and a domain\nname that can resolve to an IP address. For example,\nwww is a\nwhatever.com is a domain name, and\nwww.whatever.com is a fully-qualified domain name.\nHyperText Transfer Protocol (HTTP)\n- The HyperText Transport Protocol is the standard transmission protocol used\non the World Wide Web.\n- The HyperText Transport Protocol (Secure), the standard encrypted\ncommunication mechanism on the World Wide Web. This is actually just HTTP\n- A hash of a message, which can be used to verify that the contents of\nthe message have not been altered in transit.\n- The Open Source toolkit for SSL/TLS;\n- The word or phrase that protects private key files.\nIt prevents unauthorized users from encrypting them. Usually it's just\nthe secret encryption/decryption key used for Ciphers.\n- The unencrypted text.\n- The secret key in a Public Key Cryptography system, used to\ndecrypt incoming messages and sign outgoing ones.\n- The publically available key in a Public Key Cryptography system, used to\nencrypt messages bound for its owner and to decrypt signatures made by its\nPublic Key Cryptography\n- The study and application of asymmetric encryption systems, which use one\nkey for encryption and another for decryption. A corresponding pair of\nsuch keys constitutes a key pair. Also called Asymmetric Crypography.\nSecure Sockets Layer (SSL)\n- A protocol created by Netscape Communications Corporation for\ngeneral communication authentication and encryption over TCP/IP networks.\nThe most popular usage is HTTPS, i.e. the HyperText Transfer\nProtocol (HTTP) over SSL.\n- The context information of an SSL communication.\n- The original SSL/TLS implementation library developed by\nEric A. Young <[email protected]>;\n- The study and application of Ciphers that use a single secret key\nfor both encryption and decryption operations.\nTransport Layer Security (TLS)\n- The successor protocol to SSL, created by the Internet Engineering Task\nForce (IETF) for general communication authentication and encryption over\nTCP/IP networks. TLS version 1 and is nearly identical with SSL version 3.\nUniform Resource Locator (URL)\n- The formal identifier to locate various resources on the World Wide Web.\nThe most popular URL scheme is\nhttp. SSL uses the\n- An authentication certificate scheme recommended by the International\nTelecommunication Union (ITU-T) which is used for SSL/TLS authentication."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"search_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:8a26d849-4732-42bf-ae55-d83e248ea94e>"],"error":null}
{"question":"What are the similarities between how the Nuremberg trials documented Nazi crimes through visual evidence and how modern translators handle multimedia content?","answer":"The Nuremberg trials used Nazi films, photos, and documents as evidence, establishing an indisputable legal and historical record through visual documentation. Similarly, modern translators, particularly localizers, work with both text and visual elements when adapting content. While US Chief Prosecutor Robert H. Jackson focused on using visual evidence to prove Nazi crimes, today's localizers adapt text and graphics for products and services across different languages and cultures. Both approaches recognize the importance of visual communication alongside verbal or written content, though modern translators use computer and web-based tools to handle multimedia content, whereas the Nuremberg trials relied on physical photos and films displayed in specially designed courtroom facilities.","context":["Flexible modules that align with national education standards and can serve multiple disciplines. Untold, “behind the scenes” stories for history enthusiasts of all ages.\n12 PODCAST MODULES\nMicro-learning for the digital generation.\nModules 1-4 are at the core of our educational offering. These self-contained units are designed to fit into—and provide context/additional depth for—traditional high school/AP history classes covering modern history, international relations, human rights, and civics.\nModules 5-12 dive into specialty areas: psychological analysis of the Nazi war criminals, international trial strategy, the “making-of” Nuremberg, the US military’s role in mounting the trials, and other, never before told stories.\nRESOURCES INCLUDED IN ALL MODULES\nSTUDENT AND TEACHER PODCASTS\nACCOMPANYING PHOTO GALLERIES\nCURATED LINKS FOR DEEPER RESEARCH\nDOWNLOADABLE TEACHER GUIDES\nINDICTMENTS AGAINST THE MAJOR WAR CRIMINALS\nNuremberg prosecutors charged that Nazi Germany was not a real government but a criminal state intent on making aggressive war to steal other peoples lands, enslave and murder them. Three other indictments follow from the first.\nModule 1 will provide students with resources to:\n- Analyze the factors that led to the outbreak of WWII\n- Comprehend the basics of international law in regard to the making of aggressive war\n- Debate the merits of the concept of laws against war\n- Analyze primary source documents and use them to construct narrative essays\nCRIMES AGAINST PEACE\nFollowing the logic of the first indictment, those who planned and waged aggressive war violated international treaties were therefore criminals.\nModule 2 will provide students with resources to:\n- Understand the narrative history of World War II in Europe\n- Evaluate the concept of aggressive war\n- Analyze the causal relationships between Nazi ideology and the prosecution of the war\nThe Nazis violated international rules and customs of war, such as abuse of enemy civilians and mistreatment of POWs.\nModule 3 will provide students with resources to:\n- Understand the most fundamental laws and customs of war\n- Evaluate the purposes of international law\n- Debate whether the laws of war are practical or even possible\nCRIMES AGAINST HUMANITY\nBecause the brutality and savagery of Nazism seemed so egregious and unprecedented, the lawyers at Nuremberg had to create the charge of Crimes Against Humanity to fit the offenses: torture and slaughter of millions.\nModule 4 will provide students with resources to:\n- Understand the concept of crimes against humanity as well as the meanings of genocide and ethnic cleansing\n- Evaluate whether the concept of state sovereignty allows a nation to do whatever it thinks right if those actions, however immoral, are considered to be in the interest of the state\n- Debate the question of who is entitled to be considered human; therefore, who is entitled to human rights\nTHE PSYCHOLOGY OF NAZISM, NUREMBERG TRIAL STRATEGY AND OTHER WAR CRIMES TRIALS\nPSYCHOLOGICAL ANALYSIS OF THE NAZI WAR CRIMINALS\nWere the Nazis mentally abnormal or ordinary family men whose morals were distorted by Hitler’s influence? We’ll share test results from doctors, psychologists, and psychiatrists—along with conclusions from present day experts.\nNUREMBERG LEGAL STRATEGY: UNDENIABLE PROOF\nUS Chief Prosecutor Robert H. Jackson convinced his Allied counterparts to use actual Nazi films, photos, and their own signed documents as evidence against them. As a result, Nuremberg cemented an indisputable legal and historical record of the horrors that occurred. We’ll explain how Jackson arrived at his strategy and why the legacy of these trials must live on.\nOTHER WAR CRIMES TRIALS & HUMAN RIGHTS AFTER HITLER\nNuremberg hosted the first, international trial and 12 subsequent proceedings through 1949, but hundreds more Nazis were tried throughout Europe. In Tokyo, crimes from the East were prosecuted. We’ll profile other war crimes trials preceding and following Nuremberg to the present day and provide an introduction to international human rights issues.\nMOUNTING THE TRIALS IN WAR-RAVAGED GERMANY\nTHE US ARMY AND NUREMBERG\nGo behind the scenes and witness massive efforts needed to mount the trials in a city reduced to rubble. Learn how the US army guarded prisoners; protected the Nuremberg area; housed, fed, and transported over 1,000 international personnel; and created the infrastructure to support all trial proceedings.\nCOURTROOM 600: REDESIGNED FOR THE WORLD STAGE\nLearn how an OSS architect transformed and enlarged Courtroom 600 in just months, installing photo and film booths to capture the trial from every angle, and creating space for four Allied prosecution teams, eight judges, many defense lawyers, and hundreds of international correspondents.\nTHE BIRTH OF SIMULTANEOUS INTERPRETATION\nReal-time interpretation was pioneered at Nuremberg, delivered to every person in the courtroom via a headphone system. The first, international military tribunal was conducted in four languages: English, German, Russian, and French. Simultaneous interpretation not only shortened the trials, it paved the way for worldwide use.\nREPORTING THE “TRIAL OF THE CENTURY”\n250 global correspondents convened on Nuremberg to report the horrors of war crimes, war booty, and the Holocaust. Learn how they covered the trial at a time when radio and print media were the only mediums of communication available.\nHITLER’S HENCHMEN: BACKSTORIES\nProfiles of key defendants’ personal lives, their connection with Hitler, shifting rivalries—and how each was involved in Nazi Germany’s vast criminality.\nPODCAST LEARNING OUTCOMES\ninclude critical thinking skills, listening comprehension, and the art of storytelling.\nPRIMARY SOURCE PHOTO GALLERIES\ncan be used for photo analysis learning activities.","What Interpreters and Translators Do\nInterpreters and translators speak, read, and write in at least two languages fluently.\nInterpreters and translators convert information from one language into another language. Interpreters work in spoken or sign language; translators work in written language.\nInterpreters and translators typically do the following:\n- Convert concepts in the source language to equivalent concepts in the target language\n- Compile information and technical terms into glossaries and terminology databases to be used in their oral renditions and translations\n- Speak, read, and write fluently in at least two languages, one of which is usually English\n- Relay the style and tone of the original language\n- Render spoken messages accurately, quickly, and clearly\n- Apply their cultural knowledge to render an accurate and meaningful interpretation or translation of the original message\nInterpreters and translators aid communication by converting messages or text from one language into another language. Although some people do both, interpreting and translating are different professions: interpreters work with spoken communication, and translators work with written communication.\nInterpreters convert information from one spoken language into another—or, in the case of sign language interpreters, between spoken language and sign language. The goal of an interpreter is to have people hear the interpretation as if it were the original language. Interpreters usually must be fluent speakers or signers of both languages, because they communicate back and forth among people who do not share a common language.\nThere are three common modes of interpreting: simultaneous, consecutive, and sight translation:\n- Simultaneous interpreters convey a spoken or signed message into another language at the same time someone is speaking or signing. Simultaneous interpreters must be familiar with the subject matter and maintain a high level of concentration to convey the message accurately and completely. Due to the mental fatigue involved, simultaneous interpreters may work in pairs or small teams if they are interpreting for long periods of time, such as in a court or conference setting.\n- Consecutive interpreters convey the speaker’s or signer’s message in another language after they have stopped to allow for the interpretation. Note taking is generally an essential part of consecutive interpreting.\n- Sight translation interpreters provide translation of a written document directly into a spoken language, for immediate understanding, but not for the purposes of producing a written translated document.\nTranslators convert written materials from one language into another language. The goal of a translator is to have people read the translation as if it were the original written material. To do that, the translator must be able to write in a way that maintains or duplicates the structure and style of the original text while keeping the ideas and facts of the original material accurate. Translators must properly transmit any cultural references, including slang, and other expressions that do not translate literally.\nTranslators must read the original language fluently. They usually translate into their native language.\nNearly all translation work is done on a computer, and translators receive and submit most assignments electronically. Translations often go through several revisions before becoming final.\nTranslation usually is done with computer-assisted translation (CAT) tools, in which a computer database of previously translated sentences or segments (called a “translation memory”) may be used to translate new text. CAT tools allow translators to work more efficiently and consistently. Translators also edit materials translated by computers, or machine translation. This process is called post-editing.\nInterpretation and translation services are needed in virtually all subject areas. Although most interpreters and translators specialize in a particular field or industry, many have more than one area of specialization.\nThe following are examples of types of interpreters and translators:\nCommunity interpreters work in community-based environments, providing vital language interpretation one-on-one or in group settings. Community interpreters often are needed at parent–teacher conferences, community events, business and public meetings, social and government agencies, new-home purchases, and many other work and community settings.\nConference interpreters work at conferences that have non-English-speaking attendees. The work is often in the field of international business or diplomacy, although conference interpreters can interpret for any organization that works with speakers of foreign languages. Employers generally prefer more experienced interpreters who can convert two languages into one native language—for example, the ability to interpret from Spanish and French into English. For some positions, such as those with the United Nations, this qualification is required.\nConference interpreters often do simultaneous interpreting. Attendees at a conference or meeting who do not understand the language of the speaker wear earphones tuned to the interpreter who speaks the language they want to hear.\nHealth or medical interpreters and translators typically work in healthcare settings and help patients communicate with doctors, nurses, technicians, and other medical staff. Interpreters and translators must have knowledge of medical terminology and of common medical terms in both languages. They may translate research material, regulatory information, pharmaceutical and informational brochures, patient consent documents, website information, and patients’ records from one language into another.\nHealthcare or medical interpreters must be sensitive to patients’ personal circumstances, as well as maintain confidentiality and ethical standards. Interpretation may also be provided remotely, either by video relay or over the phone.\nLiaison or escort interpreters accompany either U.S. visitors abroad or foreign visitors in the United States who have limited English proficiency. Interpreting in both formal and informal settings, these specialists ensure that the visitors can communicate during their stay. Frequent travel is common for liaison or escort interpreters.\nLegal or judicial interpreters and translators typically work in courts and other legal settings. At hearings, arraignments, depositions, and trials, they help people who have limited English proficiency. Accordingly, they must understand legal terminology. Many court interpreters must sometimes read documents aloud in a language other than that in which they were written, a task known as sight translation. Legal or judiciary interpreters and translators must have a strong understanding of legal terminology.\nLiterary translators convert journal articles, books, poetry, and short stories from one language into another language. They work to keep the tone, style, and meaning of the author’s work. Whenever possible, literary translators work closely with authors to capture the intended meaning, as well as the literary and cultural characteristics, of the original publication.\nLocalizers adapt text and graphics used in a product or service from one language into another language, a task known as localization. Localization specialists work to make it appear as though the product originated in the country where it will be sold. They must not only know both languages, but also understand the technical information they are working with and the culture of the people who will be using the product or service. Localizers make extensive use of computer and web-based localization tools and generally work in teams.\nLocalization may include adapting websites, software, marketing materials, user documentation, and various other publications. Usually, these adaptations are related to products and services in information technology, manufacturing and other business sectors.\nSign language interpreters facilitate communication between people who are deaf or hard of hearing and people who can hear. Sign language interpreters must be fluent in English and in American Sign Language (ASL), which combines signing, finger spelling, and specific body language. ASL is a separate language from English and has its own grammar.\nSome interpreters specialize in other forms of interpreting for people who are deaf or hard of hearing.\nSome people who are deaf or hard of hearing can lip-read English instead of signing in ASL. Interpreters who work with these people do “oral interpretation,” mouthing speech silently and very carefully so that their lips can be read easily. They also may use facial expressions and gestures to help the lip-reader understand.\nOther modes of interpreting include cued speech, which uses hand shapes placed near the mouth to give lip-readers more information; signing exact English; and tactile signing, which is interpreting for people who are blind as well as deaf by making hand signs into the deaf and blind person’s hand.\nTrilingual interpreters facilitate communication among an English speaker, a speaker of another language, and an ASL user. They must have the versatility, adaptability, and cultural understanding necessary to interpret in all three languages without changing the fundamental meaning of the message."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:d340f4a1-8b2a-4848-a1c6-c6c04e95a81d>","<urn:uuid:db1bc7f0-c9bd-475f-ab03-0d6b56f50cba>"],"error":null}
{"question":"How are cognitive distortions different from positive illusions in terms of their effects on mental health?","answer":"Cognitive distortions and positive illusions have different effects on mental health. Positive illusions, which involve thinking more highly of oneself than warranted, are actually characteristic of normal human thought and can be beneficial for mental health by enabling risk-taking, future investment, and fending off despair. However, in the long term, they can lead to disappointment and failure. On the other hand, cognitive distortions, which involve interpreting events to reinforce one's outlook based on minimal evidence, are typically associated with depression and other mental disorders. They include patterns like selective abstraction, personalization, and catastrophic thinking, which can negatively impact mental health and are often targeted for treatment in cognitive-behavioral therapy.","context":["The Norwegian philosopher Peter Wessel Zapffe argued, essentially, that the human capacities for reason and self-awareness break with nature, giving us more than we, as a part of nature, can carry. So as not to go mad, ‘most people learn to save themselves by artificially limiting the content of consciousness.’\nPeople not only limit the content of consciousness, but also fill it with less than the truth. In particular, most people think more highly of themselves than is warranted: they have an inflated sense of their qualities and abilities, an illusion of control over things that are mostly beyond them, and a misplaced optimism about their outcomes and prospects.\nFor example, most people claim to compare favourably to the average road user, citizen, parent… which is, of course, mathematically impossible, since not everyone can be above average. A couple on the verge of tying the knot is likely to overestimate the odds of having a carefree honeymoon or a gifted child, while underestimating the odds of having a miscarriage, falling ill, or getting divorced.\nThe concept of positive illusions first appeared in 1988, in a paper by Shelley Taylor and Jonathon Brown entitled, Illusion and well-being: A social psychological perspective on mental health. Still today, it is commonly believed that mental health corresponds to accurate perceptions of the self, the other, and the world, but in their paper Taylor and Brown argued that the evidence suggests otherwise, and that positive illusions are characteristic of normal human thought.\nPositive illusions are helpful in so far as they enable us to take risks, invest in the future, and fend off despair and depression. After all, how many people would get married if they had any real sense of what awaited them? But in the longer term, the poor perspective and judgement that come from undue self-regard and false hope are likely to lead to disappointment and failure, to say nothing of the inhibitions and emotional disturbances (such as anger, anxiety, and so on) that can derive or descend from a defended position.\nPositive illusions tend to be more common, and more marked, in the West. In East Asian cultures, for example, people are less vested in themselves and more vested in their community and society, and tend, if anything, to self-effacement rather than self-enhancement.\nPositive illusions are also more prevalent in unskilled people, possibly because highly skilled people tend to assume, albeit falsely, that those around them enjoy similar levels of insight and competence. This Dunning-Kruger effect, as it has been called, is neatly encapsulated in a short fragment from the introduction to Darwin’s Descent of Man: ‘…ignorance more frequently begets confidence than does knowledge…’ And, of course, it may also be that, compared to highly skilled people, unskilled people are more reliant on positive illusions for their self-esteem and broader mental health.\nJust as it is commonly believed that mental health corresponds to accurate perceptions of the self, the other, and the world, so it is commonly believed that depression results in, or results from, distorted thinking.\n‘Cognitive distortion’ is a concept from cognitive-behavioral therapy (CBT), developed by psychiatrist Aaron Beck in the 1960s and routinely used in the treatment of depression and other mental disorders. Cognitive distortion involves interpreting events and situations so that they conform to and reinforce our outlook or frame of mind, typically on the basis of very scant or partial evidence, or even no evidence at all.\nCommon cognitive distortions in depression include selective abstraction, personalization, and catastrophic thinking:\n- Selective abstraction is to focus on a single negative event or condition to the exclusion of other, more positive ones, for example, ‘My partner didn’t call me yesterday. He must hate me.’\n- Personalization is to relate independent events to oneself, for example, ‘The nurse is leaving her job because she’s fed up with me…’\n- Catastrophic thinking is to exaggerate the negative consequences of an event or situation, for example: ‘The pain in my knee is only going to get worse. When I’m reduced to a wheelchair, I won’t be able to go to work and pay the mortgage. So I’ll end up losing my house and dying in the street.’\nHowever, the scientific literature suggests that, despite their propensity for such cognitive distortions, many people with depressed mood can also have more accurate judgement about the outcome of so-called contingent events (events that may or may not occur) and a more realistic perception of their role, abilities, and limitations—a phenomenon that is sometimes, and controversially, referred to as ‘depressive realism’.\nThe concept of depressive realism originated in 1979, in a paper entitled Judgment of contingency in depressed and nondepressed students: sadder but wiser? On the basis of their findings, the authors, Lauren Alloy and Lyn Abramson, argued that people with depression make more realistic inferences than ‘normal’ people, who are handicapped by their positive illusions. On the face of it, this suggests that people with depression are able to see the world more clearly for what it is, while normal people are only normal in so far as they are deceiving or deluding themselves.\nThis is a seductive proposition for someone like me, who has long been arguing that depression can be good for us—for example, in my book, The Meaning of Madness. But here’s the rub: people with depression are pessimistic even in situations in which pessimism is unwarranted, suggesting that, rather than being more realistic, their thinking is merely ‘differently biased’, and just as rigid and distorted as that of normal people with their positive illusions.\nWisdom, it seems, consists in being able to shed our positive illusions without also succumbing to depression, although, for many, depression may be a necessary step along the way.\nYou must log in to post a comment.","What is CBT?\nThis simple idea is that our unique patterns of thinking, feeling, and behaving are significant factors in our experiences, both good and bad. Since these patterns have such a significant impact on our experiences, it follows that altering these patterns can change our experiences (Martin, 2016).\nCBT aims to change our thought patterns, the beliefs we may or may not know we hold, our attitudes, and ultimately our behavior in order to help us face our difficulties and more effectively strive towards our goals.\nThe founder of CBT is a therapists named Aaron Beck, a man who practiced psychoanalysis until he noticed the prevalence of internal dialogues in his clients, and realized how strong the link between thoughts and feelings can be. He altered the therapy he practiced in order to help his clients identify, understand, and deal with the automatic, emotion-filled thoughts that arise throughout the day.\nBeck found that a combination of cognitive therapy and behavioral techniques produced the best results for his clients. In describing and honing this new therapy, Beck laid the foundations of the most popular and influential form of therapy of the last 50 years.\nThis form of therapy is not designed for lifelong participation, but focuses more on helping clients meet their goals in the near future. Most CBT treatment regimens last from five to ten months, with one 50 to 60 minute session per week.\nCBT is a hands-on approach that requires both the therapist and the client to be invested in the process and willing to actively participate. The therapist and client work together as a team to identify the problems the client is facing, come up with new strategies for addressing them, and thinking up positive solutions (Martin, 2016).\nMany of the most popular and effective CBT techniques are applied to what psychologists call “cognitive distortions” (Grohol, 2016).\nCognitive distortions: inaccurate thoughts that reinforce negative thought patterns or emotions.\nCognitive distortions are faulty ways of thinking that convince us of a reality that is simply not true.\nThere are 15 main cognitive distortions that can plague even the most balanced thinkers at times:\nFiltering refers to the way many of us can somehow ignore all of the positive and good things in our day to focus solely on the negative. It can be far too easy to dwell on a single negative aspect, even when surrounded by an abundance of good things.\nPolarized Thinking / “Black and White” Thinking\nThis cognitive distortion is all about seeing black and white only, with no shades of grey. This is all-or-nothing thinking, with no room for complexity or nuance. If you don’t perform perfectly in some area, then you may see yourself as a total failure instead of simply unskilled in one area.\nOvergeneralization is taking a single incident or point in time and using it as the sole piece of evidence for a broad general conclusion. For example, a person may be looking for a job and have a bad interview experience. Instead of brushing it off as one bad interview and trying again, they conclude that they are terrible at interviewing and will never get a job offer.\nJumping to Conclusions\nSimilar to overgeneralization, this distortion involves faulty reasoning in how we make conclusions. Instead of overgeneralizing one incident, however, jumping to conclusions refers to the tendency to be sure of something without any evidence at all. We may be convinced that someone dislikes us with only the flimsiest of proof, or we may be convinced that our fears will come true before we have a chance to find out.\nCatastrophizing / Magnifying or Minimizing\nThis distortion involves expectations that the worst will happen or has happened, based on a small incident that is nowhere near the tragedy that it is made out to be. For example, you may make a small mistake at work and be convinced that it will ruin the project you are working on, your boss will be furious, and you will lose your job. Alternatively, we may minimize the importance of positive things, such as an accomplishment at work or a desirable personal characteristic.\nThis is a distortion where an individual believes that everything they do has an impact on external events or other people, no matter how irrational the link between. The person suffering from this distortion will feel that they have an unreasonably important role in the bad things that happen around them. For instance, a person may believe that the meeting they were a few minutes late in getting to was derailed because of them, and that everything would have been fine if they were on time.\nAnother distortion involves feeling that everything that happens to you is a result of external forces or due to your own actions. Sometimes what happens to us is due to forces we can’t control, and sometimes what happens is due to our actions, but the false thinking is in assuming that it is always one or the other. We may assume that the quality of our work is due to working with difficult people, or alternatively that every mistake someone else makes is due to something we did.\nFallacy of Fairness\nWe are often concerned about fairness, but this concern can be taken to extremes. As we know, life is not always fair. The person who goes through life looking for fairness in all their experiences will end up resentful and unhappy. Sometimes things will go our way, and sometimes they will not, regardless of how fair it may seem.\nWhen things don’t go our way, there are many ways we can explain or assign responsibility for the outcome. One method of assigning responsibility is blaming others for what goes wrong. Sometimes we may blame others for making us feel or act a certain way, but this is a cognitive distortion because we are the only ones responsible for the way we feel or act.\n“Shoulds” refer to the implicit or explicit rules we have about how we and others should behave. When others break our rules, we are upset. When we break our own rules, we feel guilty. For example, we may have an unofficial rule that a customer service representatives should always be accommodating to the customer. When we interact with a customer service representative that is not immediately accommodating, we might get angry. If we have an implicit rule that we are irresponsible if we spend money on unnecessary things, we may feel exceedingly guilty when we spend even a small amount of money on something we don’t need.\nThis distortion involves thinking that if we feel a certain way, it must be true. For example, if we feel unattractive or uninteresting in the current moment, we must be unattractive or uninteresting. This cognitive distortion boils down to:\n“I feel it, therefore it must be true.”\nClearly our emotions are not always indicative of the objective truth, but it can be difficult to look past how we feel.\nFallacy of Change\nThe fallacy of change lies in expecting other people to change as it suits us. This ties into the feeling that our happiness depends on other people, and their unwillingness or inability to change, even if we push and press and demand it, keeps us from being happy. This is clearly a damaging way to think, since no one is responsible for our happiness except for us.\nGlobal Labeling / Mislabeling\nThis cognitive distortion is an extreme form of generalizing, in which we generalize one or two instances or qualities into a global judgment. For example, if we fail at a specific task, we may conclude that we are a total failure in not only this area, but all areas. Alternatively, when a stranger says something a bit rude, we may conclude that he or she is an unfriendly person in general. Mislabeling is specific to using exaggerated and emotionally loaded language, such as saying a woman has abandoned her children when she leaves her children with a babysitter to enjoy a night out.\nAlways Being Right\nWhile we all enjoy being right, this distortion makes us think we must be right, that being wrong is unacceptable. We may believe that being right is more important than the feelings of others, being able to admit when we’ve made a mistake, or being fair and objective.\nHeaven’s Reward Fallacy\nThis distortion involves expecting that any sacrifice or self-denial on our part will pay off. We may consider this karma, and expect that karma will always immediately reward us for our good deeds. Of course, this results in feelings of bitterness when we do not receive our reward (Grohol, 2016).\nMany tools and techniques found in CBT are intended to address or reverse these cognitive distortions\n9 Essential CBT Techniques and Tools\nThere are many tools and techniques used in CBT, many of which have spread from the therapy context to everyday life. The nine techniques and tools listed below are some of the most common and effective CBT practices.\nThis technique is a way of “gathering data” about our moods and our thoughts. This journal can include the time of the mood or thought, the source of it, the extent or intensity, and how we responded to it, among other factors. This technique can help us to identify our thought patterns and emotional tendencies, describe them, and find out how to change, adapt, or cope with them.\nUnraveling Cognitive Distortions\nThis is a main goal of CBT, and can be practiced with or without the help of a therapist. In order to unravel the cognitive distortions you hold, you must first become aware of which distortions you are most vulnerable to. Part of this involves identifying and challenging our harmful automatic thoughts, which frequently fall into one of the categories listed earlier.\nOnce you identify the distortions or inaccurate views on the world you hold, you can begin to learn about how this distortion took root and why you came to believe it. When you discover a belief that is destructive or harmful, you can begin to challenge it. For example, if you believe that you must have a high paying job to be a respectable person, but you lose your high paying job, you will begin to feel bad about yourself.\nInstead of accepting this faulty belief that leads you to think unreasonably negative thoughts about yourself, you could take this opportunity to think about what makes a person “respectable,” a belief you may not have explicitly considered before.\nExposure and Response Prevention\nThis technique is effective for those who suffer from obsessive compulsive disorder (OCD) and phobias. Those with OCD can practice this technique by exposing yourself to whatever it is that normally elicits a compulsive behavior, but doing your best to refrain from the behavior and writing about it. You can combine journaling with this technique, or use journaling to understand how this technique makes you feel. Those with phobias can learn to expose themselves to whatever elicits their fears, learn ways to cope with the anxiety, and not leave the feared situation until their anxiety has diminished.\nThis technique is intended to treat panic and anxiety. It involves exposure to feared bodily sensations in order to elicit the response, activate any unhelpful beliefs associated with the sensations, maintain the sensations without distraction or avoidance, and allow new learning about the sensations to take place. It is intended to help the sufferer see that symptoms of panic are not dangerous, although they may be uncomfortable.\nNightmare Exposure and Rescripting\nNightmare exposure and rescripting is intended specifically for those suffering from nightmares. This technique is similar to interoceptive exposure, in that the nightmare is elicited, which brings up the relevant emotion. Once the emotion has arisen, the client and therapist work together to identify the desired emotion and develop a new image to accompany the desired emotion.\nPlay the Script Until the End\nThis technique is especially useful for those suffering from fear and anxiety. In this technique, the individual who is vulnerable to crippling fear or anxiety conducts a sort of thought experiment, where they imagine the outcome of the worst case scenario. Letting this scenario play out can help the individual to recognize that even if everything they fear comes to pass, it will likely turn out okay.\nProgressive Muscle Relaxation (PMR)\nThis is a familiar technique to those who practice mindfulness. Similar to the body scan, this technique instructs you to relax one muscle group at a time until your whole body is in a state of relaxation. You can use audio guidance, a YouTube video, or simply your own mind to practice this technique, and it can be especially helpful for calming nerves and soothing a busy and unfocused mind.\nThis is another technique that is not specific to CBT, but will be familiar to practitioners of mindfulness. There are many ways to relax and bring regularity to your breath, including guided and unguided imagery, audio recordings, YouTube videos, and scripts. Bringing regularity and calm to your breath will allow you to approach your problems from a place of balance, facilitating more effective and rational decision making (Megan, 2016)."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:2cbb7cdc-e868-4bdd-8723-54ee095f7450>","<urn:uuid:aed1f9a3-bb8a-49a9-8fe9-02dc5c371219>"],"error":null}
{"question":"Did Aboriginal Australians in 1836 South Australia and Native Americans under DePeyster's command demonstrate similar levels of observed English language skills in their interactions with settlers?","answer":"The Aboriginal Australians and Native Americans showed different levels of English language ability in their interactions. The Aboriginal people in South Australia, while not understanding English, displayed a remarkable ability to repeat English words 'with an accuracy that was surprising and with a far superior accent to that of many Europeans not English.' In contrast, there are no specific mentions of Native Americans' English language abilities in DePeyster's interactions - instead, he relied heavily on interpreters like Joseph-Louis Ainsse for communication with the tribes, suggesting that direct English communication was not a primary mode of interaction in his case.","context":["Presentation on theme: \"Bound for South Australia 1836 Literacy on Board Week 41 Education, Victorian genre print, 1850.\"— Presentation transcript:\nBound for South Australia 1836 Literacy on Board Week 41 Education, Victorian genre print, 1850\nOverview Between February and July 1836 nine ships left Britain bound for the newly created province of South Australia. On-board the ships were passengers who over many long months braved the perils of the ocean, including some of the most treacherous seas in the world to begin a new life on the other side of the world. This resource uses the stories from these nine ships as recorded by the passengers and crew in their personal journals.\nIntroduction As we have followed the journeys of our nine ships over the past 8 months we have read many journal extracts, letters and diary entries. These primary sources have helped us to understand what life onboard may have been like from the perspectives of the authors. We can also use these texts to examine the literacy skills of the captains, crew members and passengers who used writing to record their experiences. We can also compare the way words and language has been used in these 1836 examples and compare this to the types of writing we do now. This week we will look closely at some primary sources and think about the role of literacy in the lives of those onboard the ships in our story.\nJournals from settlers in South Australia: Sunday 27 November 1836 Robert Gouger, who arrived in South Australia on board the Africaine wrote: Nov r 27 th The “Africaine”, “Rapid”, & “Cygnit” left us this morning; the first to Van Dieman’s Land for supplies, the “Rapid” up the Gulf, & the “Cygnit” to Port Lincoln to await the arrival of the Governor.\nSunday 27 November 1836 William Light, who arrived in South Australia on board the Rapid wrote: 27 November-Employed landing bread, and I took the opportunity of accompanying Mr Finniss as far as the third range of hills, to examine that part of the country he was then surveying; I was delighted to find the tops of the highest hills composed of excellent rich soil, and quite moist.\nSunday 27 November 1836 Dr John Woodforde, who arrived in South Australia on board the Rapid wrote: My birthday. Piping hot. Most of the “Rapid’s” on shore. I accompanied Captain Light and Mr. Finnis on a walk up to the hills after dinner and finished the evening at the hut of the Surveyors with which I was invited to take tea and cake – the latter made and sent by Mrs. Lisson [Lipson?].\nTuesday 29 November 1836 Mary Thomas, who arrived in South Australia on board the Africaine wrote: This evening several fires were lighted for the purpose of burning the grass, and some of them came so near to us that I began to be alarmed, for the wind drove the flames with amazing rapidity, and the grass being perfectly dry, the fires burnt with such fury as is scarcely credible.\nWednesday 30 November 1836 Robert Gouger, who arrived in South Australia on board the Africaine wrote: Nov r 30 th I have now seen what I have so heard & read of – a country on fire! Perhaps some imaginations might realise it from the American novels; mine never could. The fire was lighted by order of M r Kingston that he might with greater readiness survey to the N. & E. The wind blowing strongly the fire rapidly spread in the direction of the wind, being chiefly supported by dry grass of a most luxurious growth, but occasionally lighting upon an old gum- tree; a fallen branch of which acted as conductor to its parent stock. When this happened the fire, which at other times remained of a height nearly equable, burst up in a thick volume, & looked like a blazing town, until its branches fell away with a loud crack. The next day the fire was lighted to the S. and came up to us. I had however had a trench dug about 20 y ds around me, which in case of fire, would I hoped effectively stop its march. This precautions have kept me & my enclosure safe, while all beyond is black & desert. One decided advantage has been gained by this conflagration – viz. the destruction of myriads of insects, etc.\nWednesday 30 November 1836 Mary Thomas, who arrived in South Australia on board the Africaine wrote: This evening the fires again began in different directions on the farther side of the lagoon, but the wind suddenly shifting, which is frequently the case, they advanced on us so rapidly on all sides that I could not retire to rest till they were extinguished, which was not till 3 o’clock in the morning. One fire ran along on the opposite side of the lagoon, destroying everything in its way with the utmost fury. I walked down to the lagoon alone (for everyone else had retired to bed), and saw the fire ascend a tree, which made me apprehensive lest it might be communicated to the trees on our side, as they nearly met. If such had been the case the consequences might have been dreadful, as the fire in all probability would have advanced to our tents in a few minutes. Thank God, it burnt to the water’s edge and then went out.\nThursday 1 December 1836 Mary Thomas, who arrived in South Australia on board the Africaine wrote: This day we saw two of the natives, a man and a boy, for the first time in this part – the mainland… I showed them several things which greatly astonished them, particularly a telescope, which they took to be a gun. They thought it would make a noise, but when I drew it out and with some difficulty induced them to look through it, for they seemed to be afraid of it, they exclaimed, “Mawny! Mawny!” which is their word for anything wonderful. But a lucifer match surprised them still more, for they could not imagine how fire could be so instantaneously produced, while they were at considerable trouble to obtain it by rubbing two sticks together. When they move from one place to another they carry lighted sticks with them, and with dry leaves and by blowing with their breath they generally succeed in soon having a good fire.lucifer match Of course, these natives did not understand English any more than we did\ntheir dialect, but they pronounced our language by repeating whatever was said to them with an accuracy that was surprising and with a far superior accent to that of many Europeans not English, though they may have studied it for years. Afterwards we found that we were comparatively no strangers to them, though they were to us, for they had seen and observed our landing, but kept aloof. Subsequently they paid us several visits, but never annoyed us. On more than one occasion they proved very serviceable by helping to extinguish the fires, which sometimes came so near to us as to be extremely dangerous, beating them out with boughs from the trees or treading them out with their naked feet. Likewise, on one occasion I could not get my fire to burn, for not having been accustomed to cook out of doors I did not understand exactly how to place the wood. Two or three of them, who were standing near, laughed at my deficiency in such useful knowledge, and, taking it to pieces, reconstructed it after their own fashion. The fire then burned brightly, verifying a saying I had often heard when a girl, that “None are so ignorant but you may learn something of them.”\nFriday 2 December 1836 William Light, who arrived in South Australia on board the Rapid wrote: 2 December-Calm; at eight fresh breezes and fine; got under way and proceeded for Port Lincoln, at five p.m.; at eight p.m. ditto and cold; at eleven passed Althorpe Islands; at midnight hove to.hove to\nFriday 2 December 1836 Dr John Woodforde, who arrived in South Australia on board the Rapid wrote: …Today I am again at work at my hut which progresses slowly, having lost the services of the native men who have taken it into their heads to leave us for a while, leaving their women behind. I enlisted three of the latter on Wednesday and found them very useful in carrying reeds for my thatch. The first dish of green pease was gathered yesterday from our garden. They relished exceedingly with a brace of wild fowl (red-bills) I killed the evening before. The temperature has been very moderate since my last notes on the thermometer.\nSaturday 3 December 1836 William Light, who arrived in South Australia on board the Rapid wrote: 3 December-At four a.m. made sail; at eight passed Wedge Island, with moderate breezes and fine weather, but a very great swell from the southward; at noon nearly calm, off Thistle Island; at three p.m. light baffling airs, and a very unpleasant swell; at five a breeze again from the eastward, which gave us hopes of getting in before dark, as the entrance to Port Lincoln was now quite apparent, and we were drawing the land aft very fast, the bearings were Point Donington N.W., and the dangerous reef N.E. by E.; at six we were again baffled, and soon after the breeze died away; at seven we found we were going astern ; at eight the flood began to make, and we made a little progress; very light and variable winds all night.aftastern\nSaturday 3 December 1836 John Brown, who arrived in South Australia on board the John Pirie wrote: The Men were employ’d the beginning of this Week, in diging 3 Wells of 6 or 7 Feet each in depth but got nothing except salt Water in all of them — On Wednesday I rec d orders from S ml Stephens Esq r C.M. to get the Stock together in readyness for departing to the Main Land, by the Brig Emma, Cap t Nelson, who would take them on board the following Day or Friday at latest. We therefore on Thursday drove all the Ewes and a Ram lamb of the S o Down breed, but which was exceed- -ingly ill, and died within an Hour after being brought Home the cause of his Death in my opinion, is from being for a length of time obliged to live upon very unwholesome Food, and brack h Water, as seve- -ral of the full grown Sheep have likewise been very unwell during the last Week, and all of them are greatly falling off in condition for the Grass is so dry and burnt by the Sun that they will\nnot eat it, but prefer the green Leaves & Twigs of the samekinds of Trees & Shrubs, which are growing in the Woods about this place, and have no doubt that many of them are of a poison- -ous Nature. … We have all the Pigs, except a little Boar which has been mis- -sing for the last Fortnight, and a large black Sow that stops almost continually at North Cape _________ There has been very little Fodder at this Station for a Week past, and we are now without any whatever, so that the poor Sheep have nothing to subsist upon while confined (waiting for the Boats coming from Kingscote, to take them away) except the poor dried Grass that can be collected about the place, which is miserable fare indeed.-\nJournals from passengers at sea: Sunday 27 November 1836 George Stevenson, on board the Buffalo wrote: The Captain out of dignified spite to M r Howard because he demonstrated to the satisfaction of every body on board that we had passed the “Slot van Capelle” before we tacked to avoid it, and with whose prerogatives therefore he is as determined to interfere as M r Howard is to resist him, again deprived the Sailors of the benefit of Clergy & we had Service in the ward-room. M r H’s preaching is not improving certainly, … The Sunday School is now totally neglected abandoned, & the poor children are left to shift for themselves.tacked\nMonday 28 November 1836 George Stevenson, on board the Buffalo wrote: Drew up this morning the first sketch of a law for preventing unnecessary litigation & for the amicable settlement of all disputes by arbitration. I mentioned the subject to the Governor in London, & stated my opinion if we could find means to support a court of arbitration that it would be well to adopt it in Australia. He had never heard of the Danish practice; but said he liked the suggestion very much – so much indeed it appears to have taken his fancy that on my reading the act to him this forenoon, I had the pleasure of being told that he had determined to introduce the Danish law into the province long before he knew me!! He said also that he had consulted Lord Glenelg & M r Stephen on the subject – both of whom approved of his intention – the latter especially was “in extasy” at his being “no lawyer”, & therefore more fitted to make laws without any regard to form or legality. Mr Stephen, I suspect, must have amused himself with\nslyly quizzing the Governor, but I am quite certain that if either Lord Glenelg or he had ever seriously listened to him for half an hour they would have pronounced him wholly unfit for the great trust confided to his hands, The facts I record here however prove the quality & the moral honesty of the man.\nThursday 1 December 1836 George Stevenson, on board the Buffalo wrote: To-day we are by reckoning 1460 miles from Cape Chatham; but we have not had a glimpse of the sun since the 27 th. Poor M r Fisher had another epileptic fit, the second public one since he came on board. He cut himself very severely over the right eye brow by his fall, & in fact his escape appears to have been a very narrow one. This is a most melancholy affection, & from the state of constant excitement in which he is kept by the brutality of the Governors’s conduct & proceedings it may turn out serious. I hope sincerely he will be able to weather the voyage. He passed the evening in our cabin & was a good deal more cheerful than we expected. His view & expressed opinions of the Capt. are altogether in unison with & quite as strong as our own.\nSaturday 3 December 1836 Young Bingham Hutchinson, on board the Buffalo wrote: Saturday, Dec r 3. Fresh breezes & cloudy. Head E.S.E. Wind W.N.W. Set stud g sails sails. Noon. Miles run, 149 + 13731 = 13880. Lat e 39E16′ S o. Long e 91E14′ E t. Water rem g 55 tuns. P.M. Mod e & fine. Head E. b S. Wind West ly. 12. Light winds.stud g sailsLat eLong e\nInquiry Questions In what ways did passengers and crew need to use literacy skills onboard the ships and during the early days of establishing the colony of South Australia? How did literacy skills vary between passengers? How can we use the primary sources to learn about the literacy skills of the authors? Whose perspective do we learn about in this week's entries? What other perspectives are there and how might we find out about them? How did Aboriginal people and English settlers interact and communicate without speaking the same language? How effective are these journal entries in helping us to imagine the experiences of the authors? Which features of the writing are effective in helping us understand what the experiences were like?\nImages The Honourable George Fife Angus, c. 1920-1935. Courtesy of the Art Gallery of South Australia\nGlossary of Terms aft At or towards the stern or rear of a ship. astern To be any distance behind a vessel. hove to To ‘heave to’ is to reduce a ship’s sails and adjust them so they counteract each other and stop the ship making progress. It is a safety measure used to deal with strong winds. Lat e Latitude is the distance of a point north or south of the equator as measured in degrees. The poles are at 90 degrees north and south. Long e Longitude is the distance, measured in degrees, of the meridian on which a point lies to the meridian of Greenwich. On the other side of the earth to Greenwich is a point with a longitude of both 180 degrees east and 180 degrees west. lucifer match A Friction match – a kind of match tipped with a compound that ignites by friction.\nstudg sails Studding sails were set outside the square sails in fine weather and with a fair wind. Their head was fastened to a short yard hoisted to the end of the upper yard and their foot extended by a boom slid out from the lower yard. They took their name, such as main topmast studding sail, from the adjacent sail. Tacked Ships could not sail directly into the wind, but they could sail across it at an angle. So, to move forward in the direction of the wind they set a zigzag course, sailing across the wind at alternating angles. That procedure was called tacking.","DePEYSTER, ARENT SCHUYLER, army officer; b. 27 June 1736 in New York City, son of Pierre Guillaume DePeyster and Cornelia (Catherine?) Schuyler; cousin of Abraham De Peyster*; d. 26 Nov. 1822 near Dumfries, Scotland.\nThe second son of a prominent New York family, Arent Schuyler DePeyster was connected with the colonial aristocracy through both his father and his mother. At the age of 15 he sailed for London to further his education. Military life soon attracted him and on 13 April 1755 he obtained an ensign’s commission in Major-General William Shirley’s 50th Foot. On 10 June he was appointed lieutenant in Sir William Pepperrell*’s 51st Foot.\nDuring the Seven Years’ War young DePeyster served with his uncle Colonel Peter Schuyler* of New Jersey on the northern frontier of the colonies. He was probably caught up in the capitulation of Oswego (N.Y.) on 14 Aug. 1756 [see Louis-Joseph de Montcalm*], taken to France as a prisoner of war, and exchanged some time in 1757, as were the other officers of the 51st. In England, DePeyster transferred to the 8th Foot on 21 Sept. 1757 and he accompanied his regiment to Germany in 1760. After the war the 8th was stationed in Scotland, where DePeyster met and married Rebecca Blair, daughter of Robert Blair, later provost of Dumfries. They had a happy but childless marriage and were seldom separated. On 19 Sept. 1767 DePeyster was present at the funeral in New York City of his uncle Abraham DePeyster, treasurer of the province of New York.\nOn 16 May 1768 the 8th embarked from England for the province of Quebec. It was stationed in Montreal, where in October Captain-Lieutenant DePeyster (appointed 15 July 1767) served as a member of the court martial that tried Major Robert Rogers*. On 23 November DePeyster was promoted captain. His activities during the next six years of his life are not clear. He is known to have been on leave between September 1769 and the summer of 1770, was recruiting in Albany, N.Y., in May 1771, and on 1 June 1772 served as president of a court martial at Quebec, where he apparently spent most of his time.\nEarly in 1774, when the 8th was sent to replace the 10th Foot at the western garrisons, DePeyster, was appointed commandant of Michilimackinac (Mackinaw City, Mich.). On 4 May the DePeysters left Quebec, arriving at Michilimackinac on 10 July. For the next five years this small, stockaded, fur-trading community at the juncture of lakes Huron and Michigan was their home. Soon after his arrival, DePeyster held a council with chiefs Nissowaquet* and Madjeckewiss*. Indian affairs dominated his stay in the west, and he had a remarkable ability to establish trust and rapport with a multitude of tribesmen. In the spring of 1775, with the help of intermediaries such as the trader Peter Pond*, he was able to hold a grand council at Michilimackinac which established a truce between the hereditary enemies the Sioux and Ojibwas. When the American revolution broke out it was imperative that the British retain the allegiance of the Indians of the Upper Lakes, who greatly outnumbered the British soldiers there. Working with the assistance of his interpreter, Joseph-Louis Ainsse*, and a former French officer, Charles-Michel Mouet* de Langlade, DePeyster was able to rally Indian war parties: in 1776 to assist in the recapture of Montreal, and in 1777 to join John Burgoyne*’s thrust into New York. As a reward for his achievements DePeyster was appointed major of the 8th on 6 May 1777.\nThe following year the American lieutenant-colonel George Rogers Clark put British authority in the west in serious jeopardy. During the summer of 1778 he swiftly captured Kaskaskia (Ill.), Cahokia (Ill.), and Vincennes (Ind.) in the Illinois country. Lieutenant Governor Henry Hamilton* of Detroit retook Vincennes in December 1778, but was himself captured by Clark on 25 Feb. 1779. DePeyster feared an American attack on Detroit, and subsequently one on Michilimackinac by way of Lake Michigan. In an effort to secure intelligence of American plans he purchased from his good friend John Askin* the sloop Welcome, which he sent up the lake. He also dispatched 20 soldiers and 200 Indians under Lieutenant Thomas Bennett to rally the Indians at Fort St Joseph (Niles, Mich.). A major council was held on 4 July in the Ottawa town of L’Arbre Croche (Cross Village, Mich.), and two days later DePeyster welcomed the prestigious Sioux chief Wahpasha (either Wahpasha* or his son) to Michilimackinac. Thanks to the truce of 1775, he was able to secure the temporary cooperation of the Sioux and Ojibwas in defending Michilimackinac.\nDespite his accomplishments, DePeyster had been asking for a transfer from Michilimackinac, and when he received word that he was to be sent to Detroit he was delighted. The local merchants wished him well and commissioned an elegant silver punch-bowl as a token of appreciation. On 4 Oct. 1779 Lieutenant Governor Patrick Sinclair* arrived to take charge of the straits. Less than two weeks later the DePeysters departed aboard the Welcome for Detroit, where he assumed command on 1 November. DePeyster was immediately plunged into negotiations with the Indians. Although it was necessary to use Indian war parties to attack the American settlers in what is now Kentucky and to block American thrusts at Detroit, he repeatedly warned the warriors to avoid cruelty to prisoners. DePeyster himself treated humanely the wretched captives brought to Detroit and made many efforts to ransom prisoners held by the Indians.\nAs the war dragged on, DePeyster had many captives to worry about. In April 1780 he sent Captain Henry Bird and Captain Alexander McKee* to attack the Kentucky settlements; other parties took the war-path towards Vincennes and Fort Pitt (Pittsburgh, Pa). More than 2,000 Indians were organized and they brought in nearly 400 prisoners by the end of the summer. These successes notwithstanding, DePeyster, knowing his defences were in a deplorable state, was worried by persistent rumours of an American attack. The rumours proved true. In November a force under Colonel Augustin Mottin de La Balme from Cahokia advanced on Detroit, but warriors led by Michikinakoua* destroyed it near the Miamis Towns (Fort Wayne, Ind.). A wing of La Balme’s expedition captured Fort St Joseph in December, and in February 1781 another group sacked the fort again.\nOnly the Indian allies stood between Detroit and the growing American presence in the Kentucky settlements. To keep them loyal demanded not only consummate tact but also costly presents. General Frederick Haldimand*, DePeyster’s superior, bemoaned the flood of bills, but he trusted DePeyster’s judgement that the expenditures were necessary. During 1781 Indian war parties continued to cross the Ohio River to raid into Kentucky. They brought back rumours that a band of Moravian Christian Delawares living in villages on the Muskingum (Tuscarawas) River (Ohio) were informing the Americans of the raiders’ intentions. DePeyster had a number of the band’s Moravian missionaries and some of the Indians brought to Detroit in October for interrogation. Satisfied that they were not hostile, he let them go, but invited them to settle near Detroit. In March 1782 many of the Delawares were massacred by vengeful Americans at Gnadenhutten (Ohio) [see Glikhikan*]. Only a remnant under David Zeisberger* was left to settle north of Detroit at New Gnadenhutten (Mount Clemens, Mich.). The vicious attack roused the Ohio valley Indians and when an American force under Colonel William Crawford probed into what is now Ohio in June 1782, it was cut off and Crawford was tortured to death. DePeyster was appalled, but attributed the barbarity to the Indians’ anger over the attack on the Delawares.\nBy this time the war was winding down, and DePeyster was instructed by Haldimand to adopt a defensive posture. But sometimes a good offence is the best defence, and Captain William Caldwell achieved a stunning victory over the cream of the Kentucky militia at the battle of Blue Licks in August 1782. DePeyster was concerned about whether he could stop the frontier war even if peace was declared. As long as the Americans raided across the Ohio River the Indians would never cease resisting. DePeyster encouraged the Indians not to attack, but his supplies had been cut back and he had few presents with which to influence them.\nWord of peace arrived in Detroit on 6 May 1783 and Lieutenant-Colonel DePeyster (appointed in the army 20 Nov. 1782) immediately recalled the war parties and attempted to ransom all captives. The 492 prisoners held in Detroit were sent to Montreal to be repatriated. Though the peace treaty included Detroit in the new republic, no orders were given to evacuate the town. When the American Indian commissioners visited Detroit in July 1783 they were treated politely, but no commitments were made.\nIn November DePeyster received word that he had been appointed lieutenant-colonel of the 8th on 13 September and that he was being transferred to Fort Niagara (near Youngstown, N.Y.) to take command of the regiment. It was not until 30 May 1784 that he left for Niagara, where he assumed command on 5 June. Although suffering from ill health, during the summer he presided over the reduction of the regular and provincial troops stationed there. One of the four most senior officers in the province of Quebec, DePeyster was growing increasingly anxious to leave the frontier and return to the civilization of Quebec or Europe. While he waited, he listened to rumours of possible American attacks on Oswego and was instructed to fight if necessary to retain possession.\nFinally, in the summer of 1785, the 8th sailed from Quebec and after only 25 days arrived in England, where DePeyster was given command of the garrison of Plymouth. While he was stationed there Lieutenant Isaac Brock* served under him, and Rebecca had an opportunity to dance with the Prince of Wales. In 1790 the 8th was transferred to Jersey, and in 1793 to Ireland. DePeyster’s appointment as colonel in the army was made on 12 Oct. 1793. The following spring the regiment was sent to Flanders to confront the French but DePeyster, wracked by a violent illness, decided to leave the army. He sold his lieutenant-colonelcy to a connection of the lord lieutenant of Ireland, who ten years later had not yet paid for it. DePeyster retired to Dumfries, Rebecca’s home, where they settled down at Mavis Grove, a pleasant country estate.\nIn 1795, when a French invasion appeared possible, the locals formed a volunteer unit called the Dumfries Volunteers, and DePeyster became its major commandant. One of his men was the poet Robert Burns, who penned “The Dumfries Volunteers” and an “Epistle to Colonel DePeyster.” Sharing an interest in poetry, DePeyster and Burns were kindred spirits. However, their association was short since Burns died in July 1796.\nDuring the following years DePeyster enjoyed his retirement, spending his time training the militia, corresponding with old friends, and worrying about the slowness of the government in paying some of his bills from 20 years before. Disturbed by the events of the Napoleonic Wars, he drafted many poems which, together with others from his period in the western posts, he finally published in 1813 under the title Miscellanies, by an officer. His health remained good in his old age, and he loved to play billiards and ride his large horse. When he died on 26 Nov. 1822 he was buried with full military honours in St Michael’s churchyard, only a short distance from the grave of his friend Burns. His lifelong companion, Rebecca, died on 20 Feb. 1827.\nArent Schuyler DePeyster is the author of a volume of poetry, Miscellanies, by an officer (Dumfries, Scot., 1813); a second edition, which adds some correspondence and speeches by DePeyster and others, was prepared and published by John Watts DePeyster (2v. in 1, New York, 1888).\nA photograph of DePeyster’s grave at Dumfries is reproduced in “The Kingsman”; the Journal of the King’s Regiment (Liverpool), no.30 (July 1950): plate following p.6. A collection of his papers, including manuscript poetry and correspondence, also remains at Dumfries in the Ewart Library of the Dumfries and Galloway Regional Library Service. Other archival material relating to him is scattered amongst a variety of repositories in North America and Great Britain; this documentation includes numerous references in the Haldimand papers at the BL and in the Thomas Gage papers at the Clements Library (both detailed below); a letter from DePeyster to Sir John Caldwell, dated 14 Nov. 1785, in the Bagshawe muniments of the John Rylands Univ. Library (Manchester, Eng.), B3/37/48; a group of Indian artifacts collected by DePeyster and Caldwell in the King’s Regiment coll. at the Merseyside County Museums (Liverpool); a collection of DePeyster family papers in the N.Y. Hist. Soc. (New York); the Durell Saumarez papers, photocopies of which are available at PAC, MG 23, K10; and PRO, AO 1, bundle 376, no.1, and WO 71/26: 371.\nBL, Add. mss 21763: 236, 291, 312, 316, 320, 344, 357; 21781: 9–18, 74–90, 293, 299, 315, 319, 321, 325, 328, 331, 335, 339, 341, 343, 345, 347–48, 351, 357, 361–63, 368, 370, 373–75, 379, 381–85, 387–89, 391, 395, 399, 404–5, 408, 410, 412, 414, 417–18; 21833: 101, 194, 202, 210. Clements Library, Thomas Gage papers, American ser., 81, Carleton to Gage, 29 Sept. 1768; 82, Gage to Jones, 5 Dec. 1768; 103, Bradstreet to Gage, 12 May 1771; 111, Jones to Gage (enclosure), 4 June 1772; 114, Jones to Gage, 24 Sept. 1772; 121, DePeyster to Gage, 16 June 1774; 123, Gage to DePeyster, 5 Oct. 1774; 128, DePeyster to Gage, 5, 14 May 1775; DePeyster to Maturin, 5 May 1775; 129, Gage to DePeyster, 20 May 1775; 130, DePeyster to Gage, 16 June 1775. Robert Burns, Poetical works . . . , ed. J. L. Robertson (London and New York, 1904; repr. 1950), 212–13. John Askin papers (Quaife), 1: 67, 72, 80, 83–84, 86, 90, 105, 108, 112, 118; 2: 171–74, 382–83, 407–8, 478–79. Mich. Pioneer Coll., 9 (1886); 10 (1886); 11 (1887); 15 (1889); 19 (1891); 20 (1892). Treason? at Michilimackinac: the proceedings of a general court martial held at Montreal in October 1768 for the trial of Major Robert Rogers, ed. D. A. Armour (rev. ed., Mackinac Island, Mich., 1972), 9. Wis., State Hist. Soc., Coll., 1 (1855); 3 (1857); 7 (1876); 8 (1879); 10 (1888); 11 (1888); 12 (1892); 18 (1908); 19 (1910). New-York Gazette, and Weekly Mercury (New York), 2 Aug. 1773. D. A. Armour and K. R. Widder, Michilimackinac: a handbook to the site (Mackinac Island, 1980), 17. J. W. DePeyster, St. Paul’s Church, Red Hook, Duchess County, New York . . . Rose Hill . . . De Peyster family . . . ; by “Anchor” (*J. W. de P.*) (New York, 1881). G.B.,WO, Army list, 1760, 1768–69, 1782–84, 1794. D. A. Armour and K. R. Widder, At the crossroads: Michilimackinac during the American revolution (Mackinac Island, 1978). “An American DePeyster,” Dumfries and Galloway Saturday Standard (Dumfries), 1 Nov. 1902. D. A. Armour, “A white beaver for the colonel,” Mich. Natural Resources (Lansing), 42 (1973), no.4: 11–14. “Colonel Arent de Peister,” “The Kingsman”: the Journal of the King’s Regiment, 3 (1931–33), no.2: 4–5. “Colonel Arent Schuyler DePeyster, the King’s Regiment,” White Horse & Fleur de Lys (Altrincham, Eng.), 3 (1964): 370. “Colonel DePeyster,” Free Press (Detroit), 4 Nov. 1894. “The three Caldwells,” ed. David Boston, White Horse & Fleur de Lys, 3 (1964): 316–17."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:c7ea9d7d-1c91-45f8-9234-73b89fbe6fca>","<urn:uuid:a60edaae-0749-4a50-b12e-5c059aea8d3c>"],"error":null}
{"question":"What role did housing play in both China's WTO accession aftermath and America's current wealth inequality?","answer":"Housing has played a central role in both scenarios. Following China's WTO entry, the US Federal Reserve's response to deflationary pressures contributed to asset price inflation and over-investment in the US housing market, ultimately leading to the 2008 financial crisis. This housing-related debt continues to impact American wealth inequality today, with the average mortgage balance in America being $208,185. The explosion of housing debt has particularly squeezed the US middle class, while European countries have maintained a stronger middle class without such severe housing debt issues. The housing crisis has only worsened over time, with first-time buyers paying 39% more than they did 40 years ago, further contributing to wealth inequality through increased mortgage debt.","context":["China's WTO entry, the financial crisis and lessons for the future\nPublished 16 January 2019 | 2 minute read\nChina’s WTO entry – while a resounding success for China— did not bring about the political or economic changes forecasted by the West. Instead, the United States has directly assisted in the development of an economic and geopolitical rival.\nWestern policymakers and multinationals encouraged China’s WTO entry in 2001 as a way to bring the country into the fold of the global trading system, with the greater hope that it would move toward a democratic market economy.\nWith the benefit of hindsight, it’s clear that China’s WTO accession – while a resounding success for China— did not bring about the political or economic changes forecast by the West at the time of its accession. Perhaps the opposite scenario has arisen, where China’s state-driven, mercantilist economic model is now being held up as an alternative to the Washington Consensus. In addition, the United States has directly assisted in the development of an economic and geopolitical rival.\nIn his new book, “China, Trade and Power: Why the West’s Economic Engagement with China Has Failed”, author and financial economist Stewart Paterson describes the consequences of the West’s policy of engagement with China, which allowed the country to enter the WTO without first requiring appropriate economic reforms like a floating exchange rate, capital account convertibility and reform of state-owned enterprises.\nOne of the biggest consequences that Paterson brings to light is how the deflationary impact caused by China’s entry into the global trade system coupled with inflation-targeting by Western central banks as a response, directly contributed to the global financial crisis of 2007-2008.\nPaterson argues that after China’s WTO accession in 2001, the global market was flooded with cheap labour and goods— leading to a supply side shock and triggering deflation. As a response to these deflationary pressures, the US Federal Reserve initiated aggressive inflation-targeting policies. This ultimately led to asset price inflation and over-investment in the US housing market.\nEssentially, the extra money pumped into the US system to fight the deflationary shocks caused by 750 million Chinese workers entering the global trade system at just 10 percent of the cost of Western workers, helped fuel a housing bubble and the resulting financial crisis— a crisis which discredited capitalism in the eyes of many around the world and directly called into question the economic systems which underpin Western democracies. It led to a widening wealth gap and growing inequality in the West, fueling social disruption.\nAt the same time, the Communist Party of China (CPC) was able to capitalize on its trade opportunity to provide a rapid rise in living standards for its people— lifting hundreds of millions of people out of poverty, creating an increasingly affluent middle class, while further legitimizing and strengthening the CPC’s power.\nWhile Paterson’s analysis focuses largely on policies of the past, it also contains important warnings for the future. The West’s policy response of monetary easing to target inflation has only led to more debt being accumulated, which begs the question – are we right back where we started and do we have the capacity to bail ourselves out from another financial crisis if it arises?\nEven bigger issues are at stake. Can the global trading system remain in operation when China’s involvement has created unsustainable imbalances in the system? And how do we allow other high volume, low cost production economies into the system in the future?\nAs the old Mark Twain adage goes, “History doesn’t repeat itself, but it often rhymes.” As world leaders look to reshape the future of the multilateral trading system and rethink engagement strategies with China, it is worth looking back to understand the full impact of how past policies of economic engagement with China have directly influenced Western societies. Only with informed and reasoned background information can we craft meaningful trade policy moving forward.\n© The Hinrich Foundation. See our website Terms and Conditions for our copyright and reprint policy. All statements of fact and the views, conclusions and recommendations expressed in this publication are the sole responsibility of the author(s).","- The World Inequality Report found that debt is why the US has more wealth inequality than Europe.\n- The opposite used to be true, but mortgages and student debt put the US middle class in a bind.\n- Both student loans and mortgages were created under a vision of equality in post-World War II America.\nAmerica's middle class can thank mortgages and student debt for the country's major inequality.\nOn Tuesday, the World Inequality Lab published a report that examines the gaps between the global rich and poor. It delved into the evolution of wealth inequality in rich countries, and found that America's middle class has something that Europe doesn't: a ton of debt.\n\"One of the main differences between the two regions is that Europe has so far been able to maintain a relatively strong middle class, while in the US this group has been squeezed by an explosion of debt (particularly housing debt, which triggered the 2008 financial crisis),\" the report said.\nIn the early 20th century, wealth inequality was very high both in the US and Western Europe due to a lack of reforms that would distribute wealth. Women did not have the right to vote, and it wasn't until 1965 that Black Americans could vote in southern states — political inequalities that significantly limited the power of the working and middle class to implement measures to fight wealth inequality.\nSince 1980, inequality due to rising debt in the US began to outpace Europe. The middle 40% wealth share in the US dropped from 34% in 1980 to 28% today, while it remained at around 40% during the same period in France, for example.\n\"As a result, while Europe was significantly more unequal than the US in the late 19th and early 20th centuries, the reverse is true today,\" the report said.\nThe rise of student debt\nMortgage debt and student debt are two of the biggest types of debt Americans are burdened with, and they both were created under a vision of equality in post-World War II America.\nThis was the era when homeownership and education became the primary paths to achieving a prosperous ideal grounded in \"the good life,\" Larry Samuel, author of \"The American Dream: A Cultural History\" and founder of consultancy firm Age Friendly Consulting, previously explained to Insider.\nAfter the Soviet Union launched the first Earth-orbiting satellite into space in 1957, the US was worried it was falling behind. The Higher Education Act of 1965 under President Lyndon B. Johnson started the student-loan industry to give every American access to higher education. Instead, it became an industry that thrived off profits at the expense of borrowers, as the Wall Street Journal's Josh Mitchell explained in his book, \"The Debt Trap.\"\nThe student-loan industry has come under fire by some Democratic lawmakers over recent years for taking advantage of student-loan borrowers and misleading them into taking on more debt than they can afford to pay off. That, coupled with high interest rates on loans, can leave borrowers trapped in a sometimes inescapable cycle.\n\"What I don't get is if I took out a certain amount, and I paid that amount already, and I still owe more than I originally owed, it's just nuts,\" one borrower previously told Insider. \"It's mind-boggling to me that this total amount is not going down. It's not going away.\"\nToday, the average American college graduate owes $32,000 in student debt — a huge drag on the net worth used to determine middle class status. Due to rising interest rates, many believe their student loans will follow them to their graves, while impacting their abilities to take out mortgages and receive federal benefits due to high debt loads.\nThe rise of a mortgage\nA house in the suburbs complete with a white picket fence and a dog in the yard has been another staple of the American Dream born in the 1950s. Americans went wild with wartime savings, and material prosperity became the name of the game, with the suburban house and all the consumer trappings that came along with it leading the way.\nHomeownership rates increased by 21% from 1940 to 1960. But as is always the case with supply and demand, so many people wanted to move into a McMansion in the proceeding decades that housing prices skyrocketed along the way.\nHome prices have been going up for years, at a steeper rate than they did ahead of the Great Recession. By 2018, first-time buyers were paying 39% more than first-time buyers did at the same age nearly 40 years ago. The pandemic housing crisis, marked by a historic housing shortage and hot demand fueled by an urban flight, has only exacerbated the situation. The national median home sale continuously climbed upward before reaching a record high of $386,888 in June.\nThe soaring cost of housing boxes many middle class Americans out of buying. For those who can find a way to buy, it just means a heftier mortgage — especially if they opt for a down payment below the 20% standard. The average mortgage balance in America is $208,185, per a recent report from Experian.\nAs 27-year-old Ashley Nader, who has been house hunting for over a year, told Insider, \"The American Dream is build on debt and no one actually owns anything.\""],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:ebccf4da-b2b3-405d-96fd-41366ad14423>","<urn:uuid:4f7e3e6d-7bf5-4543-8da4-7611e83460ce>"],"error":null}
{"question":"What's the issue with one-time wellness events at work, and how does food temptation affect workplace health?","answer":"One-time wellness events like Biggest Loser competitions or pedometer challenges are ineffective random acts of wellness that may do more harm than good by promoting quick fixes instead of long-term progress. Meanwhile, the constant food temptation in workplace environments, such as treats in break rooms and coworkers' desks with candies, creates additional challenges for maintaining healthy eating habits. A more effective approach involves building a comprehensive workplace culture of health that supports total wellbeing, while also helping employees manage their food environment by planning ahead with healthy snacks and lunches.","context":["Always thinking about food? There’s a very good reason for that. Your environment may be throwing food temptation in your path at every opportunity, and it’s no wonder you’re constantly thinking about food. Put simply: the food environment in which many of us live makes it too easy to eat too much.\nWhen you think about your environment—the surroundings in which you live, work and play—you probably don’t think about food. And yet, we all live in a very complex food environment, one in which we’re faced with food and food-related decisions all day long. It’s an environment that makes it really difficult to choose healthy foods—and increasingly easy to choose foods that aren’t very good for us.\nThe Food Environment\nYour food environment is made up of all the influences on your food choices and your eating behaviors. There’s food everywhere, it seems—in your neighborhood, your workplace, at school, at home and on television. Along with the pressure to eat it. And the pressure isn’t on us to eat goodfoods. We’re swayed by the fact that we can satisfy our cravings for fatty, sugary, salty foods quickly, easily and cheaply.\nHere’s a question for you: Suppose you’re out running errands in your neighborhood, and as you’re driving around you get a sudden craving for a burger, or a soda, or a piece of pizza. How many places can you think of where you could stop and satisfy those cravings? I thought so… I’ll bet you came up with a pretty good list in no time.\nNow, answer this question: Same thing—you’re out driving around and you get a craving for some baby carrots, a carton of yogurt, or a piece of fruit. Now how many places can you think of where you could stop and satisfy those cravings? Go ahead…take your time…I’ll wait…\nThe Pressure to Eat is Everywhere\nYou face the pressure to eat foods that you neither want nor need all the time. Walking into the supermarket to buy some apples, someone waves a free sausage sample under your nose.\nYou stop at your local discount store to stock up on shampoo, and your senses are assaulted by the sight and smell of pepperoni pizza. And no checkout experience would be complete unless you’ve faced the temptation of a wall of candy and a mini-refrigerator stocked with soda.\nHere’s another thing about food temptation that I’ve noticed lately. Movie theaters don’t seem to have box offices any more, you have to buy your tickets at the refreshment stand.\nAs soon as you ask for your ticket, you’re going to have to answer to “Would you like a soda to go with that? Some candy? How about large popcorn?” Imagine what this has done for refreshment sales, not to mention our waistlines.\nControlling Your Food Environment\nConsider the two food environments in which you operate. There’s your personal space (primarily your home), and then there’s the food environment of the world at large. Obviously, you have a lot more control over your personal space, which means it’s up to you to make changes to your home food environment.\nAs far as the larger food environment is concerned, the best place to start gaining some control is in how you respond to those everyday pressures to eat in order to resist them.\nHow to Avoid Food Temptation at Home\nMake a file or bookmark a list with several easy, healthy recipes that you can turn to frequently. It will help you resist the temptation to order in.\nKeep tempting foods out of sight, either out of the house entirely or in opaque containers, and preferably on high shelves.\nKeep healthy foods visible and readily available. Keep a bowl of fruit on the counter, cut up vegetables in the refrigerator.\nDetermine portions ahead of time, and plate up your food in the kitchen, not at the table. While you’re at it, set aside a portion for tomorrow’s lunch.\nHow to Avoid Food Temptation Away from Home\nAt the supermarket. Make a grocery list and stick to it. If it’s not on your list, don’t give in to food temptation and don’t buy it. The only exception would be if there’s a good deal on healthy items that you would be purchasing anyway.\nBut don’t let yourself be swayed by the ‘buy one, get one free’ type of offers unless it’s something you would normally buy. If your supermarket has a ‘candy free’ checkout lane (some do), choose that one.\nAt work. If vending machines tempt you, plan ahead and keep healthy snacks at your desk, like nuts or soy nuts, fruit or protein bars. If you normally pass the vending machine on your way to the rest room or the building exit, try to find a different route so you can avoid it.\nOther potential problems at work: goodies in the employee break room and co-workers who keep treats on their desks. Having your own healthy snacks and bringing your own lunch as often as you can is your best defense.\nWhen you’re out running errands. Again, plan ahead. Carry water and snacks in the car if you know you’ll be out for a while. If you’re struck by food temptation at your various stops, remind yourself why you’re there in the first place. Did you go to the gas station to get gas? Or to buy a candy bar? Why did you go to the discount store? To stock up on laundry soap, or to eat lunch?\nAt restaurants. Go into the restaurant with an idea of what you’ll have. That way you’ll be less likely to be swayed by menu descriptions or daily specials. Don’t be talked into appetizers, beverages or desserts that you don’t want—or get talked into supersizing. If you’re with a group of people, try to order first so you won’t be swayed by what others are choosing to eat.","Lately, there’s been some debate about whether workplace health promotion programs, more commonly known as wellness programs, work. To us, it’s similar to asking whether reviews, training programs, employee assistance services, or other company initiatives are effective for both worker performance and the bottom line. The honest answer is that some are successful while others fail. And most of the time this comes down to how they’re designed and executed.\nSo how do you create an evidence-based health promotion program that does work? And what can employers do to avoid common pitfalls that lead to ineffective and, in worse case scenarios, harmful initiatives?\nTo tackle these questions, our respective organizations (the Transamerica Center for Health Studies and the Institute for Health and Productivity Studies at the Johns Hopkins Bloomberg School of Public Health) prepared a report, “From Evidence to Practice: Workplace Wellness that Works.” It offers practical advice to employers, large and small, based on the latest research on workplace programs, expert advice from practitioners and candid interviews with business leaders.\nOne of the biggest lessons we learned in the process of creating the report is one-time events masquerading as health promotion programs – that is, activities not integrated into a comprehensive workplace health promotion strategy – are likely to fail. And there are five common ways these solitary initiatives tend to pop up in companies.\nAdministering health risk assessments only. Health assessments typically involve asking employees questions about modifiable risks, such as smoking behavior, physical inactivity, poor diet, and high stress levels. Oftentimes, these surveys are coupled with biometric screenings of blood pressure, cholesterol, height/weight, and blood glucose levels. But providing feedback reports that remind employees that smoking, not exercising, or being overweight is unhealthy does not motivate change unless workers are given the tools and resources to actually change and track their behaviors.\nUndoing decades of poor health habits won’t be achieved by asking employees to complete a 15-minute questionnaire. And for otherwise healthy employees, frequent biometric screening is often unnecessary, and from a clinical standpoint may do more harm than good because follow-up treatments can be unnecessary and costly.\nPaying people to change their habits. While financial incentive programs are popular, they may not achieve long-term behavior change; instead, they may lead to resentment and even rebellion among workers. This is because many traditional incentive programs are grounded on the assumption that people will behave in certain rational ways if paid to do so. Behavioral economics tells us otherwise: Sometimes people do things that are irrational and even counter to their best interests. Individuals may not focus on long-term benefits of a given action when a short-term reward (for example smoking a cigarette, consuming a large pizza, or spending hours watching television) is more appealing.\nWhile there is some evidence that incentives work in specific instances for a small subset of workers, there is little research on the use of financial incentives in achieving long-term lifestyle changes like losing weight and not regaining it.\nSending people to your health plan’s website. Surprisingly (at least to us), many employers think they’ve offered a wellness program if they direct their employees to a website made available by their insurer. These under-the-radar programs do not improve population health unless they are part of a broader comprehensive health promotion program that offers many ways to become engaged.\nIntroducing short-term campaigns. Biggest Loser-themed events or pedometer challenges are random acts of wellness and are not very effective. In fact, they may even do more harm than good by promoting quick fixes as opposed to long-term progress.\nHiring a vendor to “fix” unhealthy employees. Employers sometimes hire outsiders and call it a day. Worse yet, they’ll sometimes hire different vendors to address different issues – lifestyle coaches, employee assistance counselors, case and disease management vendors, nurse lines, occupational health and safety experts, workers’ compensation specialists, disability managers, organizational development consultants, you name it. When hired independently, these vendors often work in silos, which can result in overlapping or duplicated work. In addition, relying on outside entities to attend to organizational needs may not get at the root of a systematic problem.\nSo what does? We’ve identified five approaches that, while comparatively difficult, can actually change the health and lives of employees for the better.\nLeadership commitment and support. A successful health promotion program starts with a commitment from company leaders, and its continued success depends on ongoing support at all levels of the organization. In particular, leaders at companies with successful programs establish a healthy work environment by integrating health into the organization’s overall vision and purpose. At Lincoln Industries, a manufacturer and distributor of trucking accessories, promoting workers’ health and well-being is embedded in the company’s core mission and values. Senior leaders not only speak of its importance to the organization’s success, they lead by example.\nBuilding a culture of health. A healthy company culture is built intentionally. It is first and foremost about creating a way of life in the workplace that integrates a total health model into every aspect of business practice, from company policies to everyday work activities. By “total health” we mean a culture that’s supportive of career, emotional, financial, physical and social well-being – not just an occasional road race. Examples include offering flexible work schedules, giving workers latitude in decision-making, setting reasonable health goals, providing social support, enforcing health-promoting policies and establishing a healthy physical environment (healthy food offerings, staircases instead of elevators, walking trails in and outside buildings and treadmill workstations).\nThis, of course, takes time and support. A company like Dow Chemical is a success story in this way. The company has promoted a culture of health for more than 30 years, with countless peer-reviewed studies showing that employees’ health has improved and company costs have been contained.\nAsking for help. A workplace health promotion program cannot be imposed on workers as yet another management cost-containment initiative. Boosting engagement in wellness can only be achieved when workers own the program, understand how they and the company benefit, and are given a meaningful voice in its ongoing operation.\nThere are a few simple ways to start doing this. The most common approach is to conduct regular surveys or focus groups to determine which aspects of health and wellness are important to employees, and which initiatives are not a good use of time. Honest Tea discovered that employees were not interested in yoga sessions offered by the company and instead began a series of vigorous workouts that many of its younger workers wanted. Now participation exceeds 50% since this change and has helped workers become more actively engaged in the company’s wellness program.\nAnother approach is creating and supporting wellness committees. These groups of employees can be given a budget to come up with initiatives supported by their co-workers. Lastly, it may also be worth involving spouses or other family members who can help build a broader web of social support.\nSpreading the word. Strategic communication leads to greater engagement in employee wellness programs. This boils down to getting clear messages out to workers: this is what the program entails, here is how it works, here’s what’s in it for you, and here are ways to get involved. This can help overcome some of the top barriers to program participation and success: lack of awareness, lack of interest and suspicions about employers’ motivations.\nThese communications must be frequent, varied in content, multi-channel, and tailored to the target audience so that it doesn’t fade into background noise.\nFor example, USAA describes its communications with workers as relentless and surround sound. Wherever employees turn, they are reminded that the company cares about their health and wants to support their efforts. The messages are clear – this program is there to serve you, your family and our customers, whom rely on you to be positive, healthy and performing at a high level.\nOffering smart incentives. As we’ve already noted, simply paying people to change life-long habits may not work. However, there is strong evidence that proper incentives drive participation rates, keep employees engaged and motivated to begin efforts to achieve self-determined health goals.\nThe challenge is to migrate employees from simply participating for a reward (external incentive) to a place where the new behavior or habit is sufficiently satisfying and worth maintaining (internal incentive), such as taking a walk daily while listening to music or a favorite podcast. At NextJump, teams participate in a weekly Fitness Challenge where virtual cash rewards for the winning teams are coupled with bragging rights, creating camaraderie and social cohesion among workers. The company has found that motivating employees to fit in a workout during the workday gives them more productive energy and is helping drive better performance. Employees feel good, are happier, establish close partnerships with their office mates, and at the end of the day find work fun and personally rewarding.\nMeasuring the right things. Program evaluation is critical to maintaining accountability for a wellness program. To do this well, develop an evaluation plan at the start of a program so that useful baseline data collection can occur and be monitored over time.\nSo what should you measure? There are generally two answers: return on investment (ROI) and value of investment (VOI). ROI in this context is generally limited to examining the tangible benefits of a program, such as a reduction in medical costs or absenteeism. Fortunately, a robust scientific literature review supports the conclusion that well-designed and well-executed programs can produce a positive ROI along with significant improvements in population health.\nJohnson & Johnson, for example, has published dozens of studies in academic journals over the past three decades showing its wellness and prevention programs have improved employees’ health, saved the company millions of dollars and enhanced workers’ productivity – something they could only conclude after the smart collection and analysis of data.\nIn our view, ROI in isolation fails to capture the full benefit of workplace health promotion. VOI calculations, on the other hand, allow employers to examine the broader impact of programs and their impact on core priorities for their organization, which may include improved employee morale, talent attraction and retention, enhanced company loyalty and heightened customer loyalty.\nThere are a lot of misconceptions about wellness programs out there. As a result, many leaders pick and choose options fairly blindly, doing their employees and their company a disservice. In the end, you don’t necessarily need the latest wearable or a new vendor. To achieve very real health improvement at the workplace, employers should first understand what the evidence says about what works, and then weave together individual health promotion programs with organizational change interventions that build on and support a healthy company culture. This isn’t always easy. But the rewards can be huge, both for your company and for your employees for years to come."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:318dc84b-1dbc-4825-b920-6e1483fb9a8a>","<urn:uuid:40f23f08-7d25-4ee4-a1fe-dfde90fdca64>"],"error":null}
{"question":"What are the manual image optimization techniques for web photos, and how does dust affect solar panel efficiency in desert environments?","answer":"Manual image optimization techniques include Gaussian blur (which can reduce file size by 3.6%), posterization (which can decrease file size by up to 26.3% by converting continuous color gradients), pixel-fitting for vector graphics, 8-pixel grid optimization for JPEGs, and selective JPEG compression for different image areas. As for dust effects on solar panels, a dust layer of just one-seventh of an ounce per square yard can decrease solar power conversion by 40%. This is particularly problematic in desert areas like Arizona, where dust deposition is 4 times that amount monthly, and even higher in the Middle East, Australia, and India.","context":["A post by Rahul Mistry@http://sixrevisions.com/web-development/advanced-image-optimization/\nYou can use automated image optimization tools to compress your images. However, if you also take the time to manually optimize them, you can further improve your results. Here are five techniques for manually optimizing images.\nGaussian Blur JPEG Optimization\nGaussian blur softens the details of an image. In photo-editing, it’s typically used to enhance a photo’s quality or to give it an interesting visual effect.\nHowever, if you only introduce a small amount of Gaussian blur to a photo — an amount that doesn’t alter its visual fidelity too much — you can lower its file size.\nThe following image is 60.9 KB:\nWe’ll open the image in Photoshop and then we will apply Filter > Blur > Gaussian Blur.\nWe then increase the Radius option until it starts to noticeably reduce the sharpness of the image. When then choose a value that’s visually acceptable to us.\nAfter applying the Gaussian Blur filter, we then save our image in the normal manner.\nHere is the optimized image:\nThe optimized image is 58.7 KB — a 3.6% decrease in file size.\nPosterization allows us to lower the file size of an image without harming the perceived image quality too much. Posterization works by converting continuous color gradients into non-continuous segments that require fewer colors to render.\nIn this demo, I will use a PNG image from a freebie:\nThe PNG image above is 51.0 KB.\nI opened the PNG image in Photoshop to posterize it.\nTo posterize the image, go to Image > Adjustments > Posterize. In the Posterizedialog window, check the Preview option to see your edits in real-time. Set the Levelsoption to the lowest possible value you can get away with.\nFor my example, at a Levels value less than 76, the perceived image quality degradation is no longer acceptable to me.\nAfter applying the image adjustment, we then just save the PNG as we normally would.\nBelow is the optimized image:\nBecause I was very aggressive with the posterization, the optimized image is only37.6 KB — a 26.3% decrease in file size.\n- Clever PNG Optimization Techniques — this article on Smashing Magazine goes into greater detail on how posterization works and covers other advanced image optimization tricks such as scanline filtering and dirty transparency\n- Most Effective Method to Reduce and Optimize PNG Images — this step-by-step tutorial shows you how to posterize images in Photoshop\n- Image Posterization — This article discusses the technical aspects of posterization\nPixel-fitting is a useful technique for ensuring high-quality results for vector graphics that are converted to raster graphics.\nSimple, non-photographic images such as icons and logos are best created as vector graphics because doing so allows us to scale them to different sizes without fidelity loss.\nHowever, a problem often occurs when vector graphics are converted into static image formats (raster graphics) such as JPEG or PNG. When we use an image-editing software like Photoshop to automatically convert a vector graphic to a raster graphic, it tries to do its best to smooth out the edges — an automated process referred to as anti-aliasing.\nThe results of anti-aliasing varies. Often it leads to poor-quality results. In order to enhance the quality of the graphic, we can manually edit the pixels to make sure they fit inside the pixel grid. This is called pixel-fitting (or pixel hinting).\nUsing an image editor such as Photoshop, you can zoom into the vector graphic and then manually move its vector paths a bit until they fit perfectly inside the pixel grid before you save the vector as a raster:\nPixel-fitting only works for straight lines so you will have to rely on anti-aliasing to display curves.\nFurther Reading on Pixel-fitting\n- Pixel-fitting — Dustin Curtis’s Pixel-fitting tutorial and discussion\n- Pixel Hinting Vectors in Photoshop — video tutorial on how to pixel-fit your vector graphics using Photoshop\n- How to Achieve Pixel Perfection in Photoshop — another video tutorial on how to perform pixel-fitting\n8-pixel Grid JPEG Optimization\nI came across this trick from Smashing Magazine’s article called Clever JPEG Optimization Techniques. In the same article, you will also find other useful tricks for optimizing JPEGs.\nA JPEG image is divided into 8x8px blocks, and each block can be treated as its own entity.\nBy carefully aligning parts of the image within the 8x8px grid you can lower the file size of the image as well as get better image-quality results.\nTo demonstrate: I created two identical 8x8px square objects that I then saved in JPEG using a very high compression level (to make the difference more pronounced). The top square is not aligned inside the 8x8px grid.\nNotice the quality difference and the extra pixels that are rendered for the one that isn’t aligned to the 8x8px grid.\nThis optimization trick is useful for JPEG images containing rectangular objects because you can easily fit them in a grid.\n- JPEG optimization. Part 1 — Sergey Chikuyonok (author of the Smashing Magazine article mentioned above) discusses the 8x8px JPEG concept in this tutorial\nSelective JPEG Compression\nThe way typical JPEG compression works is a fixed level of compression is applied to the entire image.\nIn selective JPEG compression, we manually specify different compression levels for different areas of the image.\nFor example, we might want important areas of a photo to have a lower level of compression/higher-quality because we want to ensure that those areas look good. But then for other parts of the same image, like the photo’s background and low-detailed sections, we might be able to get away with a higher level of compression/lower-quality.\nSelective JPEG compression can be done using Adobe Fireworks.\nThe photo below is compressed at a quality level of 80. Its file size is 54.0 KB.\nLooking at the original photo, it appears that we use selective image compression, particularly by increasing the compression/lowering the quality of the blue sky in the background and most of the black wires.\nIn Adobe Fireworks, we can mask the areas we want to protect. The masked area will have a higher quality level (80)/lower image compression. The rest of the image — the parts that are not masked — will get a lower quality level (60)/higher image compression.\nWe can use one of the Lasso tools (in my case, I used the Polygon Lasso tool) to place a marquee selection around parts we want to protect.\nOnce you are done selecting around the high-quality areas, go to Modify > Selective JPEG > Save Selection as JPEG Mask.\nThe parts of the image that will have a quality level of 80 will now be highlighted:\nIn the Optimize panel, lower the Quality option to 60 and set the Selective qualityoption to 80. (If you can’t see the Optimize panel, make sure Window > Optimize is checked.)\nThen just go to File > Save as to save the original image as a JPEG.\nThe image shown below uses selective compression. It’s 50.2 KB – a 7.0% decrease in file size versus the non-selective compression I showed you earlier.\nYou will have to play around with the selective compression settings and masking in order to get your desired results. In the case example above, detail-oriented folks will notice a huge difference between the two images. However, the results of the optimization might be alright under most people’s standards.\nSelective JPEG compression is very time-consuming and the file size reduction is only slight in most instances. It’s impractical if you’re dealing with a lot of photos. However, if you are really concerned about optimizing image quality and image file size, this is one option.\n- Selectively compressing areas of an image — an old tutorial on Adobe.com detailing the steps for selective image compression using Fireworks\nThere are simpler ways to optimize an image. Just using automated tools such as Photoshop’s Save for Web & Devices command and lossless compression tools like Smush.it can greatly reduce your image file sizes.\nHowever, if you’re looking for finer image optimization control and even more file size reductions, try out the tricks above. An ideal workflow would be to use a lossless compression tool like Kraken.io or Smush.it, which will remove a big chunk of your image’s file size without affecting its quality. And then you can use the appropriate tricks discussed above to fine-tune your results.\n- The Comprehensive Guide to Saving Images for the Web\n- 8 Excellent Tools for Optimizing Your Images\n- 22 Professional Photoshop Image Enhancing Tutorials\n- Related categories: Graphic Design and Website Management","Find dusting those tables and dressers a chore or a bore? Dread washing the windows? Imagine keeping dust and grime off objects spread out over an area of 25 to 50 football fields. That's the problem facing companies that deploy large-scale solar power installations, and scientists have now presented the development of one solution -- self-dusting solar panels ― based on technology developed for space missions to Mars.\nIn a report at the 240th National Meeting of the American Chemical Society (ACS) on August 22, they described how a self-cleaning coating on the surface of solar cells could increase the efficiency of producing electricity from sunlight and reduce maintenance costs for large-scale solar installations.\n\"We think our self-cleaning panels used in areas of high dust and particulate pollutant concentrations will highly benefit the systems' solar energy output,\" study leader Malay K. Mazumder, Ph.D. said. \"Our technology can be used in both small- and large-scale photovoltaic systems. To our knowledge, this is the only technology for automatic dust cleaning that doesn't require water or mechanical movement.\"\nMazumder, who is with Boston University, said the need for that technology is growing with the popularity of solar energy. Use of solar, or photovoltaic, panels increased by 50 percent from 2003 to 2008, and forecasts suggest a growth rate of at least 25 percent annually into the future. Fostering the growth, he said, is emphasis on alternative energy sources and society-wide concerns about sustainability (using resources today in ways that do not jeopardize the ability of future generations to meet their needs).\nLarge-scale solar installations already exist in the United States, Spain, Germany, the Middle East, Australia, and India. These installations usually are located in sun-drenched desert areas where dry weather and winds sweep dust into the air and deposit it onto the surface of solar panel. Just like grime on a household window, that dust reduces the amount of light that can enter the business part of the solar panel, decreasing the amount of electricity produced. Clean water tends to be scarce in these areas, making it expensive to clean the solar panels.\n\"A dust layer of one-seventh of an ounce per square yard decreases solar power conversion by 40 percent,\" Mazumder explains. \"In Arizona, dust is deposited each month at about 4 times that amount. Deposition rates are even higher in the Middle East, Australia, and India.\"\nWorking with NASA, Mazumder and colleagues initially developed the self-cleaning solar panel technology for use in lunar and Mars missions. \"Mars of course is a dusty and dry environment,\" Mazumder said, \"and solar panels powering rovers and future manned and robotic missions must not succumb to dust deposition. But neither should the solar panels here on Earth.\"\nThe self-cleaning technology involves deposition of a transparent, electrically sensitive material deposited on glass or a transparent plastic sheet covering the panels. Sensors monitor dust levels on the surface of the panel and energize the material when dust concentration reaches a critical level. The electric charge sends a dust-repelling wave cascading over the surface of the material, lifting away the dust and transporting it off of the screen's edges.\nMazumder said that within two minutes, the process removes about 90 percent of the dust deposited on a solar panel and requires only a small amount of the electricity generated by the panel for cleaning operations.\nThe current market size for solar panels is about $24 billion, Mazumder said. \"Less than 0.04 percent of global energy production is derived from solar panels, but if only four percent of the world's deserts were dedicated to solar power harvesting, our energy needs could be completely met worldwide. This self-cleaning technology can play an important role.\"\nCite This Page:"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:ebfce265-cda4-419e-adc6-f0768aef1d65>","<urn:uuid:89fe4a77-c326-4145-aa3e-3db0095ee948>"],"error":null}
{"question":"How to monitor cancer treatment effectiveness using blood tests? What options available??","answer":"Cancer treatment effectiveness can be monitored through several blood-based tools: 1) ctDNA testing - can track changes in tumor DNA levels to indicate treatment success or failure. 2) Circulating tumor cells (CTCs) - though limited in clinical value, can serve as a prognostic indicator for certain cancers like breast, prostate, and colorectal cancer. 3) RNA and microRNA testing - especially useful in specific cancers, with circulating RNA tests showing utility in detecting disease progression and determining response to therapy. A decrease in these markers generally suggests treatment success, while increases can indicate disease progression despite therapy.","context":["As clinician-scientists, we have all spent a considerable time identifying new targets and testing new therapies. My interest over the last few years has been to better stratify patients for different therapies, predict who should receive them, and evaluate whether the therapy is effective or not. Although my special interest is in neuroendocrine tumors (NETs) and the use of peptide receptor radiotherapy (PRRT) the principle of predictive and monitoring type biomarkers seems a critical requirement to facilitate the management of oncological diseases. What caught my attention at this ASCO GI was the significant number of sessions, papers, posters, and events as well as company-driven initiatives that are focused on molecular biomarkers.\nThe focus is broad and affects many disciplines of cancer. Examples range from IDH1 and IDH2 targeting in microsatellite instability-high (MSI-H) cholangiocarcinomas to using circulating tumor DNA (ctDNA) testing both for diagnosis as well as detecting minimal residual disease (MRD) in colon cancers. These approaches, perhaps best encompassed as “Research to Practice” (RTP) tools are considered as “disruptors” of current clinical disciplines including molecular pathology and clinical oncology. Defining effective molecular tools will likely have a substantial role not only in tumor diagnosis but in the identification of recurrence. In this area, the blood-based detection of chemotherapeutic or targeted-therapy resistant disease as this develops in response to therapies is a key issue. Such tools will replace the highly invasive tissue biopsy protocols and perhaps, even surgery, for tumor diagnosis and recurrent disease evaluation. Liquid biopsies are blood-based approaches which are more efficacious than tissue sampling, given the intra- and inter-tumor heterogeneity which are known major biological and clinical weaknesses. Furthermore, while it is relatively easy to obtain blood repetitively for real-time assessment of disease status, repeat tissue biopsy has significant limitations as it is invasive, painful, and is random tissue sample of a mass which is heterogeneous and polyclonal.\nSo, what blood-based tools were described and how effective are they? RTP tools range from ctDNA, to circulating tumor cells to messenger RNA and microRNAs. The basis of the approach is that the blood stream will include tumor-related information that can be measured and quantified and used in the management of a tumor. Firstly, this would include establishing a diagnosis of a cancer. Characterizing the tumor at a molecular level in blood reduces the requirement for tumor tissue samples (tumor biopsy), which can be especially challenging when a tumor is difficult to access, e.g., brain or lung, or if the disease is metastasized and there are multiple tumors (each comprised of a variety of clones with different genomic characteristics). Secondly, such information could be used to guide tumor-specific treatment. Analyzing the genome of tumor cells could help determine or predict e.g., EGFR L858R and second-line treatment (TARCEVA) decisions in lung cancer. Thirdly, monitoring the effectiveness of a treatment. A decrease in the quantity of a target would suggest tumor dissolution and treatment success. Conversely, increases in the target would identify disease progression despite therapy and determine those in whom therapy is unsuccessful. Fourthly, these tools could be used to monitor patients with no evidence of disease; changes would indicate an alteration in tumor status i.e. progression/recurrence.\nctDNA and CTCs\nFirstly, ctDNA. One of the themes of the congress was ctDNA and the utility of this molecular diagnostic across the cancer care spectrum. ctDNA is tumor-derived fragmented DNA in the bloodstream that is not associated with cells. Tumor DNA typically includes multiple mutations (as a function of tumor evolution and/or response to therapies) which are not detectable in germline DNA (unless there is an inherited condition e.g., MEN-1). Mutations can be measured and quantified in the circulation and therefore, potentially may have utility in all four areas – diagnosis, treatment prediction, treatment monitoring, and MRD. Is ctDNA the Holy Grail of biomarkers?\nWhile I was impressed by some of the data presented, there are a number of areas that diminish my enthusiasm. Firstly, diagnosis and screening. The quantity of ctDNA varies among individuals and depends on the type of tumor, its location, and the cancer stage. It is very clear, therefore, that there is a limit of detection associated with tumor size and ctDNA is unlikely to be useful as a screening tool or for detecting stage I cancer disease. The accuracy of detection was quoted as 41% for stage I disease. This is no different (if not worse than) to a coin toss! More extensive diseases (e.g., stage III/IV) are, however, associated with impressive results in the 70-90% range, suggesting that tumor volume is a significant variable in enabling ctDNA detection. Once diagnosed, and provided a patient has a targetable mutation (in many circumstances, a big if), ctDNA may be effective as a tool for preselecting effective therapy. In my field (NETs), there are very few driver mutations associated and it is unlikely that this technology will be viable except in a minority of patients. In contrast, other diseases, like colorectal cancer, may well benefit from this tool. In terms of treatment monitoring, this remains theoretical, as does its role for MRD. However, as a highly touted RTP tool, I anticipate several future studies generating support for its use in selected patient cohorts with defined and targetable mutations.\nSecondly – CTC or circulating tumor cells – once the flavor of the day! While CTC enumeration is an accepted prognostic indicator for breast, prostate, and colorectal cancer (CRC), it largely remains as a research tool and is considered of limited clinical value. There is interest in CTC characterization and isolation (largely for predicting therapies) but, to my astonishment, there were very few mentions of CTCs at the congress. One abstract suggested CTCs may be prognostic in CRCs and there was one trial in progress (PDAC). In the NET field, CTCs are considered a non-reliable marker, due to technical limitations in evaluating their number and phenotype and are not used clinically.\nRNA and MicroRNAs\nMicroRNAs, like CTCs, have waxed and waned in popularity. MicroRNAs are a class of small noncoding RNAs of ∼18-25 nucleotides in length which are involved in the regulation of gene expression at the post-transcriptional level. Three posters focused on this, two mechanistic, the third focusing on classifying subtypes of HCC in a Korean population. No papers evaluated utility as a circulating biomarker. In the NET world, miRNAs have been extensively evaluated, and are currently identified as having limited to uncertain value.\nOne poster evaluated circulating RNA (circRNA) which is a species of RNA that exists in blood and forms a covalently closed continuous loop of RNA that is resistant to degradation. The authors suggested that these were dysregulated in CRCs and may provide an option as a novel CRC biomarker. Time will tell but circles tend to remain circles.\nOther posters focused on linear RNA structures in the blood (blood-based mRNA assays) and their utility as predictive, prognostic and therapy monitoring tools. The NET world, unfortunately, has seriously lagged behind other disciplines in terms of the development of the molecular understanding of the disease. Thus, effective assays such as MammaPrint or Oncotype Dx (both tissue-based), or the Cobas ctDNA (blood) assays that can be used as prognostics or to predict therapies have limited analogous genomic strategies in NET disease. Of note, however, is the emergence in NET oncology of significant progress in evaluating NET-specific blood mRNA assays e.g., NETest. A single-center experience of 567 subjects in an ENETS center of Excellence was presented by A. Malczewska. The assay was robust, accurate (>90%) as a diagnostic (for several different NET cancer organ sites, irrespective of staging) and could be used to detect disease progression and determine response to therapy. A separate report by K. Öberg of a NETest meta-analysis identified diagnostic accuracies of >95% across 10 different studies with a treatment-monitoring utility of >98%. Similarly, a surgical assessment by M. Falconi identified the utility of the biomarker for identification of minimum residual disease (MRD). Of special interest was the summated the experiences of three international PRRT centers demonstrated utility of the NETest as a marker both for predicting who should undergo PRRT and also for monitoring the effectiveness of the therapy. Changes (decreases) in circulating RNA levels strongly predicted response to radiotherapy in NETs.\nConversely, increases in the mRNA signature identified those who were progressing despite PRRT. Overall, there seems no debate that for NET disease mRNA measurement seemed to have the best clinical utility and seemed most likely to facilitate clinical management. In CRC a novel mRNA-based assay by Modlin et al identified a diagnostic utility (>90%) — values similar to the metrics of other multi-omic blood tests for CRC. The latter approach combined tumor- and non-tumor-derived (such as immune) signals from ctDNA, epigenetic, and protein biomarkers into a machine learning-based classifier, to detect early-stage CRC. A simple blood test that measured circulating mRNA appeared to be as effective.\nUse and Cost of Precision Tools\nThis year, there is more and more interest in liquid biopsies and their role either as a diagnostic or as a monitor for therapy. The pitfalls and utility of precision medicine were best exemplified in the talk by Zafar (Duke) who spoke on “What’s next after precision oncology? From biomarker to better care.” Less than 10% of all cancer patients undergo precision testing and less than 5% will benefit from these tools. While we are focused on identifying those who need a targeted therapy, our tools for detecting these patients and monitoring the effectiveness of the therapies remain to be fully integrated into practice. Of particular importance, given the ever-rising costs of therapy, are molecular tools that can appropriately monitor the effectiveness of a drug. Lessons have begun to be learned and effective tools are beginning to be identified. Perhaps now we are beginning to develop the 2020 vision we need to better serve our patients. Although the question is often raised about the costs of molecular genomic tools such as mRNA liquid biopsy – I would rather ask the question – what is the cost of not developing and implementing them?\nLisa Bodei MD, PhD works in the Department of Radiology at Memorial Sloan Kettering Cancer Center. Kjell Öberg MD, PhD works at the University of Uppsala, Sweden."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"}],"document_ids":["<urn:uuid:f17f2cf0-2a64-4deb-a963-3e95f0dadadb>"],"error":null}
{"question":"Which brewing method takes more time and skill to prepare: using a camping coffee percolator or a French Press?","answer":"A French Press requires more skill but slightly less time compared to a percolator. French Press brewing takes 4-7 minutes and needs specific skills to determine brewing time, water temperature, grind consistency, and plunge rate. A percolator, while simpler to use, requires watching the pot as it perks, straining the finished coffee, and typically takes longer since you need to wait for the water to boil first, then percolate, and finally let it cool due to its extremely hot temperature.","context":["If you’re a dedicated coffee drinker, you might want to know how to use a camping coffee percolator, along with other camp food preparation options. One of the quickest ways to feel sick on a camping trip is eating unfamiliar food that’s poorly prepared.\nWith an old-fashioned percolator, you don’t have to settle for instant coffee. You might even find that you like the coffee prepared this way better than the stuff made by your kitchen coffee maker.\nChoices of Camp Coffee Percolators\nBefore learning how to use a camping coffee pot, you need to know their types. Camp coffee percolators come in two basic types: those with a clear glass knob at the top, and those without.\nThey both work the same way, but the ones with the clear glass knob are a little easier to use. You can purchase your camp percolator by going to the camping section of your local department store or by purchasing a stovetop percolator from the kitchen section of that same store.\nNot all stores are created equal, and there isn’t a huge demand these days for percolators, thanks to the prevalence of drip coffee makers and coffee makers that use pre-measured coffee cups. However, it’s still a great way to make coffee while camping easily. If your local store doesn’t carry a camp or stovetop percolator, you can purchase them online from a variety of different sources.\nWhat You Need to Make Your Camp Coffee\n- A heat source\n- A percolator\n- Ground coffee, or coffee beans and a grinder\n- A cup for each person drinking coffee (Ceramic preferred. Tin tends to lead to burned lips)\n- A potholder or towel\nHow to Use a Coffee Percolator Camping\nSo how to use percolator coffee pot camping? Here are the steps you should follow:\n- Prepare Your Heat Source: If you’re using a campfire or grill, let the fire burn down until you have a nice bed of coals, with a backlog or two of unburned wood. This produces a steady heat. If you’re using a propane camp stove or tea kettle for camping, set it up so that it’s level, and prepare to light the burner. If you’re using Sterno (sometimes known as canned heat), prepare an elevated place to put your coffee pot, such as an old stove burner top placed on four rocks.\n- Prepare the Water: Remove the percolator centerpiece, and fill the pot with water up to the top watermark. This should be just a little way below where the base of the coffee grounds basket will be.\n- Use the Heat Source: Place the pot over the heat source, and bring the water in the pot to a boil.\n- Add Coffee Grounds: While the water is heating, add two tablespoons of coffee grounds to the grounds basket. Assemble the stem and the basket.\n- When the Water is Boiling, Add the Stem and Basket Assembly: Carefully open the lid. Holding the assembly by the top of the stem, gently place it into the coffee pot.\nNote: If you prefer, you can put the water, the basket assembly and the grounds in the pot at the same time. It tends to make a stronger, more bitter cup of coffee.\n- Watch the Pot as It Perks: If you have the kind of percolator that has the clear, glass knob at the top, you’ll be able to see the coffee start to bubble up into the knob. When it reaches the color of the coffee desired, your coffee is ready to drink. If your pot doesn’t have this knob, listen for the distinctive “glurp, glurp” sound of the water as it bubbles up through the grounds. Pour a little of your brew into a cup to check its color.\n- Remove the Coffee Basket Assembly from the Pot.\n- Pour the Finished Coffee Through a Strainer: One of the disadvantages of a percolator is that you will get some coffee grounds in the lower part of the pot. This is especially true if you get too much water in the pot. Straining the coffee means that you don’t have to strain it through your teeth or pick bits of coffee out of your cup.\n- Be Patient: Wait a minute or two, or cool your coffee down with some tinned milk or reconstituted creamer. Coffee prepared with a percolator will be much hotter than coffee that has been made using a drip coffee maker or similar coffee machine.\n- Enjoy Your Cup of Coffee in a coffee mug for winter camping.\nYou Don’t Have to Go Camping to Enjoy a Camping Coffee Percolator\nBefore drip coffee percolators, a percolator was the high-tech method of brewing coffee. An even older method was to simply throw a few grounds in the pot or to pour hot water through the coffee grounds. Percolators tend to make a strong, bitter brew.\nYou can use a coffee percolator on your stovetop at home if you discover that you prefer the flavor and strength of coffee brewed using the percolator method.\n- Fun Fact: The first drip coffee maker was invented in 1954 by Gottlieb Widmann. It was called the Wigomat.\n- 2nd Fun Fact: The coffee percolator was invented in 1880 by Hanson Goodrich.\n- 3rd Fun Fact: Before percolators or drip coffee makers, coffee was often made by putting the grounds and cold water into a pot.\nIt was then brought to a boil. Stories of that time say that floating an eggshell on the top of the coffee would cause the grounds to settle.\nYou don’t have to wait until you go camping to use your camping coffee percolator to learn how to use a camping percolator. Your percolator can be used on any sort of heat source, but a nice bed of coals at the edge of your campfire might be best.\nIf you start your eggs and bacon at the same time as your coffee, you can probably have your coffee ready to drink with your breakfast. Remember, coffee made in a percolator will be hotter than that made in a coffee maker, and don’t forget to strain the grounds out of the coffee.\nIt might be tempting to do a few camp chores while the coffee perks, but you could wind up with an extra-strong batch that way.","French Press vs Drip\nCoffee enthusiasts have always entangled in a fierce debate of which between the French Press and Drip Coffee Maker is the best when it comes to making the best cup of coffee. Although it all trickles down to preferences, having a clue why the debate has remained endless will enable you to know on which side on the fence you sit on as well as help you make an informed choice on the best coffee maker for you.\nFrench Press Vs Drip Coffee Maker Comparison\n- Variety of Brews\nBoth the French Press and the Drip are well-suited with any kind of coffee that you may want to brew. However, what brings the difference is the consistency of the grind you prefer on each of them. For the French Press, a coarse grind is the most preferred while the Drip is ideally designed for a finer grind.\nRegardless of this, most coffee enthusiasts prefer to grind their coffee beans in the comfort of their homes as opposed to using pre-ground varieties. As such, they have higher control over the grinding process while it enables you to use both the Drip machine and the French Press interchangeably – depending on what you prefer on a given day!\nIt is difficult to settle on a particular product based on the variety of brews as both of these allow you to brew your favorite variety of coffee. Therefore, whichever you pick, you can be sure to enjoy your cup of coffee to the fullest.\n- Brewing Speed\nThe brewing speed of these two coffee makers will depend on the time you have at hand. On average, it should take you from 4 to 7 minutes to brew your favorite cup of coffee using a French Press while the Drip Coffee Maker will take you from 4 to 10 minutes to get your cup of coffee.\nMoreover, it is important to keep in mind that the French Press will require you to boil the water first on a stove and this will eat some of your time and effort as well. On the other hand, some coffee lovers prefer the set it and forget it nature of the Drip Coffee Maker even though it is a bit slower on average.\nOverall, the French Press will deliver you a cup of coffee faster than the Drip especially if you are to consider its affordable price.\n- Capacity and Sustainability\nWhen it comes to capacity, both the French Press and the Drip tend to come in a variety of sizes even though they tend to curb it at 10 cups per brew. So depending on the capacity you are looking for in a coffee maker, you will find one in either product.\nHaving said that, which of the two products can sustain the hotness of your coffee the longest? In this aspect, the Drip Coffee Maker has a clear advantage over the French Press. The Drip comes with a hot plate at its base which allows it to keep the coffee a bit warmer for much longer than the French Press. However, bear in mind that the longer your coffee sits in there after brewing is done the more the taste deteriorates.\n- Necessary Brewing Skills\nWhen using the French Press, you will require some brewing skills as it requires you to determine the brewing time, water temperature the consistency of your grind, and plunge rate. However, the Drip Coffee Maker only requires you to put water and your ground beans and switch it on. If you don’t have prerequisite brewing skills, you might find it difficult to make a perfect cup of coffee when using the French Press. Beginners may find it hard to brew the cup of coffee that they will truly enjoy in the first days.\nSo, if you want to have higher control over what you brew, the French Press could be your best pick, but if you prefer simplicity, the Drip could be your number one.\n- Coffee Taste\nThis is ultimately the most important factor. Getting the best coffee taste every time you brew your coffee is the most fulfilling experience as you kick start your day or cool down after a long day at work. The coffee taste is however more subjective and personal. While some people consider bold and exciting flavors for the best cup of coffee, others consider light and more direct cup of coffee. So the question is which are you?\nYou will have more control over the kind of coffee taste you will get by taking full control of the brewing process with the French Press. Besides, most coffee lovers who have used the French Press contend that the coffee brewed with the French Press is fuller and richer because it preserves much of the natural oils found in the coffee beans. On the other hand, the Drip Coffee Maker delivers a little ‘weak’ taste as it tends to filter out the natural oils found in coffee beans.\nWhen it is about coffee taste, it is your opinion that counts. If you prefer a lighter coffee taste and you want it stress-free, then the Drip machine is ideal for you. But if you want to explore exclusive coffee tastes, smells, and experiences, then the French Press will certainly come handy.\nSummary of Verdicts\n- Allows more control over the brewing\n- Lower initial cost\nDrip Coffee Maker\n- Keeps coffee warmer for longer\n- Convenient for most coffee enthusiasts\nWhich one is Better?\nGetting a clear winner in this comparison is difficult as both products come with almost even after weighing the pros and cons of each. The one that will work best for you will be determined by how much time you have to brew your coffee, the effort you intend to dedicate to your coffee brewing experiences and the ultimate coffee taste you will want to enjoy.\nBoth of these products are great in different aspects. The difference only lies in what kind of coffee taste you want and what your lifestyle is."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:5961e499-1c20-4f44-9b03-44a32a293c7d>","<urn:uuid:8f8ccc1f-93b6-4364-84ed-d36aeb76557c>"],"error":null}
{"question":"How do stems cells work and why are they controversial in medical research?","answer":"Stem cells are undifferentiated cells that can divide and develop into specialized cells. While they show promise for treating human diseases and alleviating suffering, they are controversial because obtaining them typically requires destroying embryos, which raises ethical concerns about respect for life. Additionally, there are worries that stem cell research could lead to uncontrolled commodification of cells and life.","context":["Bioethical Issues: Bioethics refers to the study and evaluation of the decisions done in scientific research and medicine to touch upon the health and lives of people, as well as the society and environment. Bioethics is a portmanteau of the words “bio” and “ethics“.\nBecause of that, this discipline is concerned about the determination of the rightness or wrongness of the discoveries and developed technologies in science as well as the incorporation of human rights and values to health and life.\nThe following topics are the most common scientific topics and advancements that seem to have gotten the attention of bioethics supporters, media, and the general public.\nTable of Contents\nTop Bioethical Issues\nAbortion refers to the premature ending of a pregnancy which occurred in itself (known as miscarriage or spontaneous abortion) or by force through surgery or taking medications. The topic of abortion raises intense personal issues about many topics such as morals, religion, sexuality, autonomy, politics, and science and medicine.\n- During the abortion, the central question is focused whether or not unborn children (called fetuses) have moral status and significance. Aside from that, questions regarding parental responsibilities and obligations as well as the issue of personhood arise.\n- Although abortion has long been debated in almost all issues in bioethics, there is still no moral consensus achieved.\nThe next bioethical issue in our list is Surrogacy. Surrogacy refers to the process of assisting the reproduction of parents who are incapable of doing so (e.g.: same-sex couples, single men, single women or man/wife). Most of the time, surrogacy is carried out by women (known as gestational women or gestational surrogate) who carries the child in their womb.\n- The bioethical concern here is the confusion in the identity of the child, whether or not his biological parents are considered his “true” parents.\n3. Whole Genome Diagnosis\nAdvancements in technology are now able to allow researchers and physicians to view and have access to the whole genome of a newborn. Such screening is used to determine the individual’s chances of acquiring and developing certain diseases.\n- However, this process seems to draw criticisms primarily because of the lack of consent from the individual (a.k.a the newborn).\nCloning refers to the process of creating a new population of genetically-similar and identical naturally occurring organisms. The usual targets for cloning include bacteria, plants, and animals.\n- In particular, the bioethical issues regarding cloning focus on the fact that humans become the subject of such experiments.\n- The moral status of the cloned organism, created mainly for destruction and as a source for organs, has become the primary concern in bioethics. Issues such as health risks to both mother and child, damage to the clone, very low success rates even if there are a lot of trials and samples, psychological effect to the clone, and commodification and commercialization of life itself. Refer to pros and cons of cloning here.\n5. Stem Cells\nIn biology, stems cells are a type of undifferentiated (not mature and undeveloped) cells that can divide and differentiate into specialized cells.\n- The bioethical issue concerning stem cells is pretty much like the issues with cloning.\n- Respect for life per se requires that people show respect to all of its forms. Supporters of bioethics believe that stem cell research violates this notion because the source organism (usually an embryo) is destroyed during the process.\n- While stem cell research canalleviate human diseases and suffering, the creation of stem cell lines may lead to the uncontrolled commodification of cells and life.\nIn philosophy, eugenics refers to the social movement that believes on the possibility of creating the best human society and race by promoting the reproduction of populations with positive or desirable traits while controlling and prohibiting the reproduction of populations with negative or undesirable traits.\n- Eugenics became very popular when Adolf Hitler ordered the killing of disabled and medically unfit people as well as the murdering of the Jews.\n- Because of the advancement of science and technology, many people fear that another era where the principle of genetics will prevail. Ethical issues about eugenics are concerned with the moral principle associated with racial equality and the subjective belief on perfection.\n7. Genetically Modified Organisms\nGMOs, or genetically modified organisms, are organisms that have been transplanted with a gene or a DNA sequence of interest from another organism. This process is somewhat similar to the process of eugenics wherein an organism with the best traits is produced.\n- However, unlike eugenics, the process of creating GMOs requires works on the genetic level and is usually done in crops and animals.\n- While the production and use and creation of genetically modified organism are still new, with its long-term impacts on health are still yet to be seen, bioethical issues about it are the same with cloning, stem cell research, and eugenics.\nAs alluded to earlier, several technological advancements have paved the way for the improvement in health care.\n- Aside from that, issues regarding the allocation of funds, decision-maker and recipient of the benefit, cost-efficiency, and measurement of success are ethical concerns. Aside from that, many people believe that health care may only promote health inequality.\n9. Aged Care\nA portion of the world’s population is composed of elderly citizens, and naturally, they become the priority for funding and public policy through the establishments of aged care and other accommodation services.\n- However, similar to health care, these policies raise concerns about who should provide support for the elderly and what should be their standards of living.\n- In addition to that, questions about balance, freedom, and safety are also being asked.\nLiterally meaning “good death“, euthanasia is the process of intending to end the life an individual tostop his or her pain and suffering. Euthanasia is also loosely called as a mercy-killing, assisted suicide, or doctor-assisted suicide.\n- While some people believe that euthanasia is just a matter of ending a life painlessly, many people (especially those who support bioethics) believe the otherwise.\n- In many countries around the globe, the practice of euthanasia is illegal, regardless of the circumstances.\n- Euthanasia challenges the belief that is concerned with the sanctity and equality of all life forms. Euthanasia is believed to corrupt the practice of medicine as well as undermine the value of suicide prevention.\n11. Organ Donation\nDespite being almost common, the practice of donating or receiving an organ seem to give rise to ethical issues. Similar to cloning and stem cell research, organ donation have raised numerous moral, societal, and ethical concerns about the use of living people as donors.\n- The first bioethical issue on organ donation is that there is a big shortage of organs for those who need. There are thousands of people on the waiting list to receive the organ transplants either from living or deceased. Check out United Network for Organ Sharing (UNOS) for the updated waiting list, statistics around how many people are being added to the list per minute, how many people are getting the transplant and how many people die every day during the transplant surgeries & more.\n- The next bioethical issue on this matter is equal access of organs (aka distributive justice theory) to those who need by the length of waiting time and by their age. According to this theory, the patients who wait for transplant could not move up the waiting list if their poor lifestyle caused the damage to organs (like smoking or substance abuse) over patients who have no control on their diseases.\n- Another biggest ethical issue is that as there is a big demand for organ transplants, there is a fear of illegal organ stealing from livings (human trafficking) without their consent to create organ farming to sell body parts for big prices.\n12. Head Transplant\nAbsurd as it may sound, experiments about the transplantation of an organism’s head to another are being done. In fact, during the 1970s, the first ever head transplant in monkeys have occurred successfully (the recipient only lived for ten days).\n- While such application on humans is still being studied, serious health and bioethical concerns are associated with it. Questions like the reaction of the brain to the new body, as well as the memory and individual identity are of concerns.\nCryonics refers the scientific method of freezing a newly-dead individual to reanimate or bring him to life at a later period. Because this process involves the reversing the process of death, several bioethical issues were raised against it.\n- One of the main problems about cryonics is immortality. While immortality is believed by some to be beneficial, supporters of bioethics believe that this idea should not prevail given that the planet is already under the crisis of unsustainable population and limited resources.\n14. Bone Conduction\nBone conduction technology involves the replacement of an individual’s ear bones to transducers that can transmit sounds.\n- Despite being promising, the problem with this technology is that it basically can transform an individual into a billboard with the countless advertisement. In this case, the consent of the individual is not a concern.\n15. Artificial Exoskeleton\nLast but not the least bioethical issue is the development of an artificial skeleton for the elderly to improve their strength and help them move. This artificial skeleton can give them the ability to walk, run, bend like someone who is younger than them.\n- The bioethical concern with this is the possible abuse that the elderly may experience when they are forced to work longer before and even after retirement age.\nIn conclusion, we can infer that even in the best case situations, some of the aforementioned scientific methods and medical practices are a dangerous and problematic ethical minefield.\n- “Abortion – Bioethics Research Library”. Accessed November 18, 2017. Link.\n- “Surrogate babies: Where can you have them, and is it legal? – BBC News”. Accessed November 18, 2017. Link.\n- “Genomic medicine: evolving science, evolving ethics”. Accessed November 18, 2017. Link.\n- “Human Cloning | The Center for Bioethics & Human Dignity”. Accessed November 18, 2017. Link.\n- “Stem Cell Therapy: the ethical issues – a discussion paper”. Accessed November 18, 2017. PDF.\n- “Eugenics and the Ethics of Selective Reproduction by Stephen Wilkinson and Eve Garrard” – Keele University. Accessed November 18, 2017. PDF.\n- “Bioethical Issues on Genetically Modified Organisms (GMOs) In Malaysia: Biting Into the Legal Protection under the Biosafety Act 2007”. Accessed November 18, 2017. PDF.\n- “Bioethics and Effective Health Care”. Accessed November 18, 2017. Link.\n- “Gender, ageing, and injustice: social and political contexts of bioethics” – S Dodds. Accessed November 18, 2017. Link.\n- “Assisted Suicide and Euthanasia — The Center for Bioethics and Culture”. Accessed November 18, 2017. Link."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:3698415b-02ea-426e-91a2-f3d1e9ad5e0e>"],"error":null}
{"question":"How do the research objectives of Professor Laura Fabbietti and Raymond Davis Jr compare in terms of their contributions to understanding fundamental physics?","answer":"Laura Fabbietti studies strange quarks and matter under extreme conditions, particularly focusing on neutron stars which contain the densest matter in the Universe (except black holes). She conducts this research through the ALICE experiment at the Large Hadron Collider. In contrast, Raymond Davis Jr's research focused on proving how the Sun generates its energy - he was the first to detect neutrinos from outside Earth and experimentally demonstrated that the Sun is powered by the fusion of four protons into helium-4. His work led to the discovery of neutrino flavor oscillations, which explained why he detected only one-third of the expected solar neutrino flux.","context":["Our scientists work on fundamental questions in physics that are playing out in our Universe, but otherwise they have also very earthly tasks and hobbies. Here is a little insight into what the daily life of our researchers looks like away from the labs and desks (All photos by Roberto Grillo).\nElisa Resconi is a professor at TUM. As a member of the IceCube Southpole Neutrino Telescope she strives to understand where the cosmic particles with the highest energies come from and how these particles gained their enormous energies. She was among the scientists to establish the first connection of a high energy neutrino with a cosmic source, a blazar. She is currently aiming at building a new large scale neutrino detector, the Pacific Ocean Neutrino Experiment (P-ONE) that would complement and augment IceCube.\nElizabeth Mondragon Cortes is a doctoral student at TUM. She is a member of the CRESST experiment hunting for the direct detection of dark matter. A dark matter particle that hits a nucleus of the detector crystal warms it a tiny bit, which constitutes the detection signature. Obviously, the experiment must be extremely sensitive to temperature changes. To take advantage of superconductivity, the crystal is cooled to almost absolute Zero. Eli works on optimizing the detector's thermometer by finding the best combination of the modifiable parameters.\nRaimund Strauß is a young researcher at TUM. As a member of the CRESST experiment, he gained a lot of experience with measuring tiny energy changes by using low temperatures. He got interested in a neutrino interaction called CEvNS that is theoretically understood but difficult to measure due to the small amount of energy transferred. To realize an experiment to observe CEvNS, the European Research Council awarded Raimund a Starting Grant. He is now leading the NUCLEUS collaboration setting up the experiment at the Chooz reactor site in France.\nSusanne Mertens is a professor at TUM and a researcher at the Max Planck Institute for Physics. She is a leading scientist of the KATRIN experiment to scale the neutrino mass. But Susanne is also dedicated to track down a hypothesized neutrino type that would be heavier than the known ones but its interaction with other particles would be weaker. Since this suspected particle could even be the long searched dark matter particle, the European Research Council endowed Susanne with a Starting Grant to work on verifying or refuting the hypothesis.\nStefan Schönert is a professor at TUM. He is a leading scientist of the CRESST and the GERDA experiments, among others. Both are tailored to observe particle events that are to happen absolutely rarely (if at all), but detection would have groundbreaking implications for the field of fundamental Physics. A main concern is therefore to scale up the experiments to enhance the discovery probability. For the advancement of GERDA with its 38,5 kg detector mass to the new 1000 kg LEGEND experiment, he received a prestigious Advanced Grant from the European Research Council.\nValentina Mantovani Sarti is a young researcher at TUM. As a hybrid between a theorist and an experimentalist in the field of nuclear physics, she strives for an understanding of how matter behaves under extreme temperatures and densities. Colliding heavy nuclei and protons at almost the speed of light in particle accelerators generates the most extreme conditions that can be achieved on Earth. Valentina is an expert in analysing and interpreting data from the ALICE experiment at the Large Hadron Collider.\nThierry Lasserre is a research director at the French Alternative Energies and Atomic Commission (CEA), a guest professor at TUM and a Mercator Fellow of the SFB1258. He is an initiator and leading scientist of the Double Chooz experiment studying the conversion of the three known neutrinos into each other. With colleagues, he observed a neutrino deficit at Chooz that could be explained by a fourth type of neutrino with light mass. To search for it, he received an ERC Starting Grant in 2012. Now, he has expanded this hunt to the hypothesized neutrino that is also a dark matter candidate.\nLaura Fabbietti is a professor at TUM. She is concerned with strange things, that is matter containing Strange quarks, the third lightest quarks after the Up and the Down quarks that make up the protons and neutrons in the atomic nuclei. Strange quarks are presumed to be found in neutron stars where the matter is densest in the Universe (apart from black holes). To find the equation of state of a neutron star, she and her group are part of the ALICE experiment at the Large Hadron Collider at CERN where they can study matter under extreme conditions in the laboratory.\nFelix Henningsen is a doctoral student at TUM. As a Bachelor student together with other students, he developed the POCAM, an instrument intended to recalibrate the detectors of the IceCube Southpole Neutrino Observatory. To test the tool, he travelled to Siberia to deploy it in the neutrino detector under construction in Lake Baikal. Now, PCAMs are integral parts of the pathfinder experiment STRAW off the coast of Canada to study the conditions in the Pacific for the design of the planned new large scale telescope Pacific Ocean Neutrino Experiment initiated by Elisa Resconi.","Raymond Davis Jr, who won the 2002 Nobel Prize in Physics for first observing neutrinos emitted from the nuclear-fusion reactions in the core of the Sun, died on 31 May 2006 at his home in Blue Point, New York.\nDavis’s observations of solar neutrinos not only were the first detection of neutrinos from outside the Earth, but they also experimentally demonstrated that the Sun was powered by the fusion of four protons into helium-4. The solar-neutrino flux measured by Davis was about one-third the expected flux based on the thermal energy emitted by the Sun. For many years, this discrepancy was known as the “solar-neutrino puzzle.” It was not a puzzle at all, but the first indication of neutrino flavor oscillations, the conversion of one neutrino species into another during the flight from the solar core to Earth.\nDavis was born in Washington, DC, on 14 October 1914. In 1938 he received a BS in chemistry from the University of Maryland. After a brief period at the Dow Chemical Co, he pursued graduate work at Yale, where he received a PhD in physical chemistry in 1942. In 1945, after completing his World War II military service, Davis joined the Monsanto Chemical Co. Three years later, he joined the chemistry department at the newly established Brookhaven National Laboratory.\nWhen Davis arrived at Brookhaven in 1948, the existence of neutrinos was still speculative. Looking for a challenging problem that could be addressed with physical-chemistry techniques, he decided to develop and construct a chlorine-based neutrino detector that had been described by Bruno Pontecorvo two years earlier. The concept was that neutrinos interacting with chlorine-37 would produce argon-37, an unstable gas that decays with a 35-day half-life. The use of a chlorine-containing liquid target, perchloroethylene (C2Cl4), made the extraction and measurement of even a small number of argon atoms possible.\nAfter some preliminary tests at Brookhaven, Davis proceeded to construct a 4000-liter perchloroethylene detector at the Savannah River reactor in South Carolina. Concurrently, Frederick Reines and Clyde Cowan were installing a liquid-scintillator antineutrino detector there. The absence of neutrino interaction events in Davis’s chlorine detector at the same time that Reines and Cowan were seeing antineutrino interactions in their detector became the first clear indication that neutrinos and antineutrinos are distinct particles with different lepton numbers.\nIn 1958, just as Davis’s Savannah River experiment was ending, Harry Holmgren and R. L. Johnson of the Naval Research Laboratory measured the rate at which 3He and 4He combine to form beryllium-7. Until then it had been assumed that the only significant neutrino-producing channel in the solar fusion reactions was the fusion of two protons to form a deuteron, a positron, and a neutrino. With energies less than 440 keV, such p–p neutrinos were below the threshold of most detectors, especially the chlorine detector. Holmgren and Johnson’s measurement showed that the 7Be formation rate was about 100 times larger than previously assumed; a significant fraction of the solar fusion reactions would thus form 7Be, and some of the 7Be would then combine with a proton to form boron-8. Electron capture by 7Be produces 862-keV neutrinos, and 8B decay gives multi-MeV neutrinos; neutrinos from both reactions are thus above the 812-keV reaction threshold of37Cl. Both William Fowler of Caltech and Alastair Cameron of Atomic Energy of Canada Ltd urged Davis to use his detector to look for neutrinos produced by fusion in the solar core.\nThe question that Davis was about to address, the source of the Sun’s energy, first arose in 1860 when Lord Kelvin challenged the time scales in Charles Darwin’s On the Origin of Species by pointing out that the Sun’s gravitational potential energy could keep Earth warm for only about 30 million years. By the 1930s, with the recognition of the large amount of energy available from nuclear fusion reactions, it had become clear that the Sun was probably powered by the fusion of hydrogen into helium. However, no one had yet experimentally demonstrated that.\nTo shield the detector from cosmic rays, in 1962 Davis moved his Savannah River apparatus to a PPG Industries limestone mine in Barberton, Ohio, that was 2300 feet (700 meters) deep. The lack of a solar-neutrino signal and the high residual cosmic-ray background at Barberton demonstrated that a much larger and much deeper detector was required.\nTogether with John Bahcall, who was carrying out detailed calculations of the solar-neutrino flux and spectrum, Davis persuaded the Brookhaven administration to support and fund the construction of a 610-ton C2Cl4 detector. The Homestake Mining Co agreed in 1965 to excavate an experimental area at 4850 feet (1480 meters) deep in its gold mine in Lead, South Dakota, and so began a unique academic–industrial cooperation that lasted for 35 years.\nThe first Homestake results, announced in 1968, showed that the solar neutrino signal was less than 3 solar neutrino units (1 SNU = 10–36 interactions per target nucleus per second), compared with a predicted rate of about 8 SNU. As soon as those data became available, Pontecorvo speculated that the reduction in observed flux might be due to transitions of electron neutrinos into muon neutrinos (the tau neutrino had not yet been observed). It took almost three decades to experimentally verify Pontecorvo’s astute explanation.\nWhen the Homestake experiment was being designed, the predicted solar neutrino flux was about 30 SNU, or about five conversions of 37Cl to 37Ar per day, and the expected cosmic-ray background in the 610-ton detector was about 1% of that rate. By the time the detector was in operation, the predicted signal had been reduced to 8 SNU, or slightly more than one 37Ar produced per day. The observed signal, 2.5 SNU, corresponded to one 37Ar atom produced every two days, with a cosmic-ray background of about 10% of that signal. Detecting the signal required a series of upgrades and improvements to the argon extraction, sample purification, counting system, and internal calibrations as well as increased rejection of background signals. Those improvements permitted Davis and his team, of which I was a part, to ultimately measure the solar neutrino flux with a statistical precision of 5%.\nIn 1984 Davis retired from Brookhaven and joined the University of Pennsylvania as a research professor. He remained in that position until his death. The experiment, which transferred with him from Brookhaven to Penn in 1984, continued for another 18 years.\nIn addition to the Nobel Prize, Davis received the National Medal of Science, the Wolf Prize, the Pontecorvo Prize, the National Academy of Sciences’ Com-stock Prize, and numerous other honors.\nI collaborated with Davis for many years. Despite his renown, he always remained an extremely kind, well-liked, sensitive, and unusually modest person, happiest in his laboratory or with his family or his experimental collaborators. He will be missed."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:1a152b34-15cc-4ecc-a8a9-ad9763674ca9>","<urn:uuid:37de3b72-ee7d-4c4e-82d2-eddfed61b05b>"],"error":null}
{"question":"How can airports in the Asia-Pacific region effectively address their capacity challenges while ensuring sustainable growth?","answer":"To address capacity challenges, airports in the Asia-Pacific region need to focus on three key pillars: 1) Using existing infrastructure efficiently through initiatives like the Worldwide Slot Guidelines and NEXTT (New Experience Travel Technologies), which improves connectivity through biometrics, autonomous vehicles, and digital transformation; 2) Protecting existing infrastructure by preparing for climate change effects and reducing environmental impact through programs like Airport Carbon Accreditation; and 3) Developing new infrastructure by addressing the capital gap of US$78 billion through private capital funding where necessary.","context":["Efficiency and coordination key to addressing Asia-Pacific capacity crunch\nACI World’s Director General speaks at the 56th DGCA APAC Conference\nKathmandu, 20 August 2019 – Airports Council International (ACI) World today called for improved coordination among industry stakeholders to increase capacity in the Asia-Pacific Region, home to some of the fastest growing economies and aviation markets.\nSpeaking at the 56th Conference of Directors General of Civil Aviation, Asia and Pacific Region, ACI Director General addressed the three necessary pillars of improving capacity: using what we have efficiently, protecting the use of what we have, and developing more when necessary, and, underlined their importance to safeguarding the socio-economic benefits that aviation provides to the region at large.\n“We need to ensure that aviation continues to generate socio-economic benefits to communities and countries, many of which are small island developing states (SIDS) challenged by small population, limited human capital, confined land area and higher debt levels.”\nUnder the umbrella of efficiency, Gittens said: “While the new governance structure for the Worldwide Slot Guidelines, and the new aerodrome standards are milestones in the right direction, airport stakeholders need to increase their harmonized efforts when it comes to seamless connectivity and NEXTT can help.”\nACI and the International Air Transport Association (IATA) have been developing NEXTT, or New Experience Travel Technologies, which pulls together the work that is being done in our security, airport operations, passenger and cargo facilitation teams, on biometrics, autonomous vehicles and digital transformation. The NEXTT vision looks at the complete ground journey for all the elements that currently move through the airport – the passenger, baggage, cargo and the aircraft. It seeks to ensure that stakeholders have a common direction, and that all projects benefit to maximise interoperability with others.\nAddressing the protection of infrastructure, Gittens emphasized that it was crucial that airports both prepared to deal with the effects of climate change on their operations while also actively working to address, reduce and mitigate the impact of airport operations on the environment.\n“We know that the Asia-Pacific region is no stranger to the effects of climate change. This is a global challenge requiring a global response and ACI is taking a leadership role through the Airport Carbon Accreditation (ACA) Programme.”\nAs of August 2019, ACA boasts 282 participating airports, reaching 43.4% of global traffic and 53 carbon neutral airports. Although the programme started in Europe which has the largest number of airports, the Asia-Pacific Region has demonstrated their commitment, with 54 accredited airports, representing 41.2% of passenger traffic, with 6 that are carbon neutral.\nGittens continued, “Yet with the recent Intergovernmental Panel on Climate Change’s report, the aviation industry at large is challenged to be a larger part of the solution. Our European airport community has formally committed to become net zero for carbon emissions under its control by 2050. ACI will ask the International Civil Aviation Organization (ICAO) to develop more ambitious CO2 reduction goals to meet the objectives of the Paris Agreement.”\nAddressing the third pillar, building new infrastructure, Gittens reminded delegates of the capital gap for constructing new infrastructure and proposed possible solutions to financing such large-scale projects.\n“Airports’ capital needs are high: based on a sample of 50 major economies, we’re looking at required five-year investments of US$433 billion versus US$355 billion in planned airport investment, a shortfall of US$78 billion.\n“ACI does not advocate for any specific ownership structure but we have seen that private capital has been shown to be successful means of funding infrastructure development in the face of the growing demand for air service, the value of that air service for a community’s or country’s economic vitality, and the competing needs for government funds where financial resources are lacking.”\n“And, economic regulation, if needed, should be proportionate to the objectives set by the government owner, including the incentives to facilitate commercial agreements between airports and their customers.”\nGittens concluded by reminding delegates of the importance of investing in workforce capacity.\n“The projected expansion of the aviation sector in the region requires giving attention to the recruitment and training of the necessary talent that will run this engine. ACI continues to invest in workforce capacity through our Global Training programme, which offers a host of in-class and on-line courses, many of which are in collaboration with ICAO, IATA and other institutions such as Universities. I’m pleased to report that the Asia-Pacific region has the most training centers and provides the highest number of courses.”\nNotes for editors\n- Airports Council International (ACI), the trade association of the world’s airports, was founded in 1991 with the objective of fostering cooperation among its member airports and other partners in world aviation, including the International Civil Aviation Organization, the International Air Transport Association and the Civil Air Navigation Services Organization. In representing the best interests of airports during key phases of policy development, ACI makes a significant contribution toward ensuring a global air transport system that is safe, secure, efficient and environmentally sustainable. As of January 2019, ACI serves 646 members, operating 1,960 airports in 176 countries.\nManager, External Relations and Special Events\nTelephone: +1 514 373 1254\nTelephone: +1 514 373 1200"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"}],"document_ids":["<urn:uuid:50354ad6-28a5-47d2-895c-53e00343335c>"],"error":null}
{"question":"Which pollinator species experienced a more significant decline: native bumble bees or British honey bees?","answer":"Native bumble bees have experienced more severe declines compared to British honey bees. While British honey bee colonies showed a 14.5% decline over the 2014-2015 winter, one quarter of bumble bee species have experienced significant declines, including some of the most common species. The situation for bumble bees is particularly concerning in areas heavily converted to agriculture - for example, in Illinois, half of the historically present bumble bee species have either been locally extirpated or shown declines in distribution.","context":["Help save our honey bees is the rallying cry of a new campaign aimed at getting the next generation involved and featuring one of honey's biggest fans\n\"A day without a friend is like a pot without a single drop of honey left inside\", said Winnie-the-Pooh of his favourite afternoon snack. Who better then to front a new initiative from the British Beekeepers Association (BBKA) aimed at encouraging children to help save our diminishing British honey bees?\nThis launch comes as a response to new research commissioned by the BBKA confirming a decline of 14.5% in England's honey bee colonies over the 2014-2015 winter. But while these figures are disheartening - particularly given the vital role that we all know bees play within our delicate ecosystem - encouragingly, both children and adults alike have expressed a desire to help but a lack of understanding of just how to go about that. 58% of British adults pledged that they would do more to help if only they knew how. While 83% of British children aged 5-10 were found to believe it is important to look after our environment.\nDavid Aston, President of The British Beekeepers Association said: \"While many people are aware of the plight of the honey bee, there are many that don't know what they can do to help. We hope that by supporting our 'Friends of the Honey Bee' initiative, families across the country can get involved, making a practical contribution and supporting bee health research.\"\nHelp is at hand\nThursday 25 June sees the launch of a brand new 'bee-friendly' guide, inspired by Winnie-the-Pooh and friends which is available in printed form as part of a BBKA 'Friends of the Honey Bee' member pack or downloadable from Friends of the Honey Bee. The guide aims to inform families of the numerous ways in which they can help support the continuation of our honey bee colonies for generations to come.\n10 simple steps to help save honey bees are included, ranging from planting up a window box and creating a vegetable patch to building bee habitats and becoming a beekeeper. Each step is illustrated with a full colour image of Winnie and friends taking action to save honey bees and - perhaps more importantly for Winnie himself - the future supply of fresh, local, British honey.\nDie hard fans of everyone's favourite Hundred Acre Wood-dwelling bear need fear not as the illustrations have been beautifully created by illustrator Mark Burgess, who coloured the original E.H. Shepherd black and white art.\nThe new guide includes a brand new short story and a list of ten simple activities to support British honey bees, as recommended by Winnie-the-Pooh (with a little help from the BBKA).\nWinnie-the-Pooh's 10 simple steps to help save the honey bees\n1. Plant your own window box2. Create your own vegetable patch or tub3. Plant a flowering tree in your garden4. Make some 'seed balls' and throw them into the wild5. Use arts and crafts to educate the younger generation on the importance of bees e.g. finger puppets, painting bee pictures, knitting bees etc6. Learn to become a beekeeper yourself by attending a course through the British Beekeepers Association7. Bake together at home using local honey8. Build bee habitats9. Volunteer for your local beekeeper association or visit your local apiary10. Don't panic, if you see a local honey bee swarm, contact your local beekeeping association","This is the extended version of our article \"Do you care about Bees or other Pollinators, Please read this...\" This version, written by Andrew Goebel of Indigenous Landscapes, has more detailed insight into to the current state of native bees and honey bees with research sited in the end of the article.\nThe problem with pollinators\nMuch attention has been given to the decline of honey bee (Apis mellifera) populations and the potential consequences of their demise. Recent years have seen a rise in awareness of the importance of pollinators in general with much money and effort going towards creating “pollinator gardens” and “habitats” in cities, along highways, and our backyards. The majority of this attention has been on populations of honey bees and Monarch butterflies. When thinking of a pollinator, these are likely the two examples people have in mind. Although well intended, this narrow focus limits consideration of the bigger picture and the potential negative impacts of honey bees themselves.\nMissing from popular discussion is the less well known fact that native bee species have been declining in recent decades. Since most of the 4000 species of native bees lead a solitary existence (they are not social and don’t live in hives) they are difficult to study. Therefore the majority of native bee research has examined bumble bees (Bombus spp.) since they live in small colonies. The findings highlight the need to implement conservation measures sooner rather than later. One quarter of our bumble bee species have experienced significant declines, including some of the most common species (1).\nWhy do we need native bees?\nNot only can native bees pollinate the majority of world crops they are essential components of native ecosystems. Honey bees do not have the ability to “buzz pollinate” which is a requirement for 15,000-20,000 species of flowering plants (1). Decreased numbers of native bees contributes to decreased seed set from plants that they pollinate. In fact, pollination limitation is one of the most commonly found causes of reduced reproduction in wild plants (2). This results in decreased future forage opportunities, which further pressures native bees (1).\nWhat is driving the decline in native bees?\nIt is widely assumed that habitat loss and fragmentation are some of the leading causes of native bee decline. While urbanization certainly contributes to these conditions, it is agriculture that accounts for the majority of land use. In the United States over 60% of the land has been converted to different forms of agriculture representing an enormous loss of habitat and degradation of forage for numerous organisms including native bees. Some mid western states have undergone dramatic conversions. Illinois, for example, has lost its most of its prairies, wetlands, and forests to agriculture amounting to 95% of the land area in the northern two thirds of the state. Half of the bumble bee species found historically in Illinois have been either locally extirpated or showed declines in distribution (3).\nMost species of bumble bees are ground nesting. They build their homes in abandoned rodent burrows or other cavities within the soil. Prairie habitats that include sufficient areas of clumping grasses provide the necessary conditions for rodents to dig burrows. When farms in Illinois switched from having permanent and temporary pastures with wildflowers and multiple crops to primarily corn and soybean, the steepest declines in bumble bees occurred (3).\nFragmentation can be understood as a problem of ecosystem simplification. Despite mounds of research many ecosystem dynamics are still poorly understood. One theme that has emerged is that more complex environments support more species and are more resilient to change. The current agricultural system in the US is based on only a few crops which are often planted in large monocultures. These may be interspersed with patches of semi natural areas creating islands of habitat within a sea of agriculture. Areas that were once covered in any number of our thousands of native plants have become solid stands of only a few non native crops. This simplification of the environment has consequences.\nBumble bees require a variety of plants that flower at different times to provide food throughout the season. They are further specialized in their own emergence times and by length of their tongues which impacts what flowers they will visit. Agricultural conversion to only a few species of plants reduces the foraging window for all pollinators.\nIssues with honey bees and domestication of other bees\nIntroduced from Europe, honey bees did not co-evolve with native bees or the ecosystems in which they have been placed. Like many other introduced organisms, their presence can have unintended and negative impacts on native flora and fauna. In fact there is ample evidence that honey bees can contribute to the decline of native bees and flora.\nHoney bees compete for forage with native bees. Bumble bees have been shown to have reduced amounts of foraging in proximity to honey bee colonies - sometimes avoiding entire areas. The closer the nest sites the less that native bees were able to compete (4). Further, since honey bees focus on nectar collection instead of pollen they are less effective than native bees and other non bees (flies, beetles, etc) at pollinating and may be linked to the spread of invasive plants as well (1).\nWhen honey bees encounter native bees on the same flower there is potential to spread parasites and disease. This is also true of domesticated native bumble bees. The system of apiculture and native bee domestication creates populations that can harbor much higher pathogen loads than wild or native bees, increasing their chances of exposure. It may be possible for honey bees to spread deformed wing virus to bumble bees which has been implicated in the colony collapse disorder phenomenon (1). Honey bees are shipped around the country to match various bloom times, mingling sick and healthy colonies.\nFurthermore, pesticides that have been deemed “bee friendly” are only legally required to be tested on honey bees not native ones (4). Bumble bees are often active during pesticide application in the morning or evening that is timed to avoid mid day honey bee foraging (4).\nWhat can be done?\nChanging current agricultural practices is a clear way to mitigate the decline of native pollinators. Farmland designed to include sufficient habitat could support native bumble bees which have been to shown to effectively pollinate most crops without human intervention. A shift away from intense use of non native honey bees and other domesticated bees would lower competition with native pollinators and reduce the potential of debilitating pathogen outbreaks.\nTransitioning to a food system based on native food plants could address multiple problems at once. In such a setup, crop land itself could actually act as habitat and begin to reconnect our fragmented landscape.\n(1) Xerces Society for Invertebrate Conservation. (2016). An overview of the potential impacts of honey bees to native bees, plant communities, and ecosystems in wild landscapes: Recommendations for land managers.\n(2) Potts, S. G., et al. (2010). Global pollinator declines: trends, impacts and drivers. Trends in Ecology and Evolution, 25(6), 345-348.\n(3) Grixtia, J. C., Wonga, L. T. (2009). Decline of bumble bees (Bombus) in the North American Midwest. Biological Conservation, 142(1), 75-84\n(4) Goulson, D., Lye, G.C. (2008). The decline and conservation of bumblebees. Annual Review of Entomology, 53, 191-208"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:8b291e49-d938-4258-9cd7-fed7216e26aa>","<urn:uuid:4a39da67-6257-4ebc-95bc-06131b56b69d>"],"error":null}
{"question":"What are the power supply differences between the Portable Floating Fish Collector (PFFC) and the R/V Sally Ride's electrical systems?","answer":"The PFFC uses a relatively simple power system consisting of a subsurface cable to shore that provides both power and carries operational/instrumentation data. In contrast, the R/V Sally Ride has a much more sophisticated integrated diesel-electric power plant with four Cummins QSK38-DM main engines providing over 3,900 kW of power. The Sally Ride's system includes multiple generator configurations for peak efficiency, Siemens Blue Drive system for propulsion control, and advanced electrical switchgear with condition-based monitoring.","context":["Art Anderson Associates is the lead naval architect/marine engineer developing the design of a Portable Floating Fish Collector (PFFC) for operations in the Cougar Reservoir in Oregon. The purpose of this device is to gather additional information on juvenile fish movement in Willamette Valley Project reservoirs, representing a cost-effective means of safely obtaining juvenile fish for research and monitoring. The PFFC is designed to be modular, able to be disassembled for roadway transport to other reservoirs, and generates an attraction flow that can be varied from 20-140 cfs. The anchoring system accommodates up to a 200-foot variation in reservoir water level, including rapid fluctuations. Using a series of winches, the anchoring is designed to allow the PFFC orientation to be changed. The anchors are easily-retrieved for redeployment. Power is provided by a subsurface cable to shore, which also carries operational and instrumentation reading data.\nThe role of Art Anderson Associates on the project includes preparation of a bid-ready construction package for project elements that include complete structural design of the PFFC vessel (except the fish collection module), mooring system, and subsea cable. Our services also included developing a marine operations plan for deployment, recovery, and disassembly of the PFFC, and deployment and retrieval plans for the anchoring and mooring system.\nArt Anderson Associates is engaged in a project to survey lifesaving equipment throughout the fleet of Alaska Marine Highway System (AMHS) ferries and recommend an upgrade strategy. The project goal is improving the safety of passengers and crew members through evaluations of the effectiveness of the current lifesaving equipment, exploring alternative strategies and scenarios, and preparing the work packages (plans, specifications, and cost estimates) for modification of the vessels.\nSystems surveyed include structural, electrical, and hydraulic systems; lifeboats, davits, and cradles; service/work boats, davits, and cradles; means of rescue equipment; and life rafts. Mr. Marty McKay, Art Anderson Associates' Project Manager, conducted nine shipchecks to evaluate the condition of the existing equipment, which was documented in the project's Design Study Report. These shipchecks included a detailed walkthrough of the vessel to document equipment conditions with notes and photographs, and interviewing ship's personnel to understand the challenges they face in the operation of the equipment.\nOne of the challenges encountered included the difficulty of training crew, particularly relief crews, on the nuances of equipment that is different from ship to ship. Other challenges include maintaining an adequate spare parts inventory, maintaining the condition of the equipment, and obtaining necessary service and parts for continued operation. It was quickly identified that standardizing the equipment fleet-wide, as much as possible, will assist in meeting these challenges. The prioritization of US sources for equipment was also a means to alleviate these concerns, due to more cost-effective service, availability of spare parts, and improved responsiveness compared with foreign sources.\nUpon completion of the surveys, an extensive review of applicable regulatory requirements for lifesaving equipment was conducted, and included SOLAS and CFR regulations. Three primary strategies were developed and analyzed for cost-effectiveness, including refurbishing existing equipment, replacing existing with a fleet-wide standard in kind, and aligning equipment with regulations and standardizing fleet-wide as much as practicable.\nAll documentation of the condition of equipment, identification of alternatives, and the associated cost estimates were submitted in the final Design Study Report. Current efforts involve developing the work packages for the modifications and obtaining necessary ABS approval.\nUnder the US Department of Homeland Security's Assistance to Firefighters Grant Program, the Tacoma Fire Department received $750,000 to refit the city's fireboat COMMENCEMENT. Art Anderson Associates teamed with BMT Nigel Gee of the United Kingdom to provide engineering design and consultation for the renovation and refit of the vessel.\nThe first phase of the project involved a comprehensive trade-off study that examined and balanced the needs and specifications of the Tacoma Fire Department and the budgetary constraints of the DHS grant. Art Anderson Associates examined the operational and financial practicality of proposed upgrades and modifications and will provide recommendations to the department.\nArt Anderson Associates provided structural; propulsion; pumping, hydraulic and electrical system; and command and control modification engineering and design. Included with this design package was a detailed cost estimate and construction schedule. Art Anderson Associates also served as the Fire Department's representative in the bid and construction phase, negotiating between the owner and contractor, resolving engineering problems and maintaining weight control data.\nCOMMENCEMENT is one of two fireboats operating in the Tacoma Fire Department. The vessel was built in 1982 by Vosper Hovermarine as a multipurpose fiberglass surface effect ship (SES). The vessel has two 445bhp marine diesel engines powering two 19-inch propellers and a 285bhp marine diesel engine that provides power to six 24-inch aluminum alloy fans, which, when engaged, maintain an air cushion beneath the vessel. This cushion allows the COMMENCEMENT to achieve speeds of up to 30 knots and maintain a stable ride in choppy seas. Since 1983, the vessel has provided fire suppression, search and rescue, evacuation, hazardous materials response and emergency medical service for the city. The COMMENCEMENT's service area includes the Port of Tacoma, the sixth-largest container port in the United States.\nArt Anderson Associates provided naval architecture and marine engineering services for the conversion of the Ex-USNS AGATE PASS (YTT-12), a former torpedo test craft, into a NOAA research vessel. The converted vessel, now named the NANCY FOSTER, was outfitted to conduct coastal research along the US Atlantic and Gulf coasts. Our services were performed as a series of conversion tasks under our IDIQ contract with NOAA for naval architecture and marine engineering services. These tasks include engineering design for:\nNANCY FOSTER's mission includes the characterization of various habitats in NOAA's National Marine Sanctuaries, pollution assessments and studies to improve understanding of the connection between marine habitats and estuaries. These missions support scientific data collection through bottom fish trawling, sediment sampling, side-scan sonar and multi-beam surveying, sub-bottom profiling, core sampling, diving with air and NITROX, ROV operations, and servicing oceanographic/atmospheric surface and subsurface buoys. The vessel employs state-of-the-art navigation and propulsion systems that result in high quality and efficient data collection.\nUnder a Small Business Innovation Research (SBIR) contract with the US Navy, Art Anderson Associates is designing the next generation of multi-mission-capable aluminum amphibious craft employing an innovative hybrid-electric propulsion system. The vessel, designed to replace the existing LARC-V (Lighter, Amphibious Resupply, Cargo, 5-Ton) auxiliary amphibious craft, achieves the design goals outlined in the original SBIR topic, including a road-legal status, water speed of 20-plus knots, road speed of 45-plus miles per hour, one-short-ton cargo capacity, and off-road capability to exit an unimproved beach.\nIn Phase I, AAA completed a preliminary analysis and concept design. The current Phase II effort has included detailed planning, hull form development through tank model construction and testing, preliminary full scale design and analysis, aluminum hull structure design and optimization, and specifications development. Achieving this effort has involved naval architectural and structural, mechanical, and electrical design; cost estimating; technical analysis and study; and coordination of efforts with subcontractors responsible for construction of the prototype.\nKitsap Transit is a public transit agency operating a fleet of passenger ferries serving routes between Bremerton, Port Orchard and Annapolis. Following the successful modification of the fleet's ferry ADMIRAL PETE, the agency began investigating options for design and construction of a sister ship. One of the goals for the sister ship design is to integrate \"green\" technology to reduce operational costs and environmental impact. As the naval architect for the ADMIRAL PETE project, and a firm with a long history of service to the agency, Kitsap Transit contracted with Art Anderson Associates to perform a feasibility study to begin development of the sister ship design.\nThe scope of work for Art Anderson Associates included development of design requirements and an operating profile for the planned vessel, including weather, speed, passenger capacity and other related factors. Candidate propulsion plants were identified and compared in the areas of cost, weight and fuel consumption. Technologies for reduction of cabin HVAC loads were investigated, including efficient insulation and waste heat recovery systems. The study also investigated application of alternative power technologies, assessing the pros and cons of various systems for use on the new sister ship. The report was compiled and presented to the Passenger Only Subcommittee of the agency's Board of Directors, and forms the basis for future work to develop the sister ship design.\nArt Anderson Associates provided Housing Kitsap (formerly the Kitsap Consolidated Housing Authority) construction management services for this $25 million, multi-agency government facility. Services included owner's site representation, assistance negotiating change order pricing, coordination with City Public Works division and local utility companies, frequent KCCHA management updates on potential construction cost impacts to the project budget and schedule monitoring/management. We served as the primary interface with all government tenants, including Congressman Norm Dicks, the City of Bremerton, Kitsap County Health District, Kitsap County Offices, and the Bremerton Housing Authority for design and construction of tenant improvements in a cost-effective and timely manner. The project was completed in 2004.\nArt Anderson Associates provided construction management services under a term contract with the US General Services Administration, Region 10 for the $20 million seismic upgrade/rehabilitation of the historic 57,000-sq. ft. Pioneer Courthouse in Portland, Oregon. Art Anderson Associates' Project Representative facilitated resolutions and served as the point-of-contact for all owner design and construction issues. We also performed site reviews and managed the owner's construction budget and all special inspector contracts required.\nThe project entailed replacement of the building foundation with a state-of-the-art base isolation system to preserve the historic 1897 structure during a seismic event. The friction pendulum isolators, used for the first time in the Portland area, isolate the building from the earth, allowing it to move freely in an earthquake.\nRehabilitation work included preservation and reconditioning of historic features, including light fixtures, intricate plaster work, woodwork, wood flooring and office fireplaces. All mechanical, electrical, data/communication and security systems were replaced. Exterior improvements included sidewalk, entry steps and stone wall restoration. The basement level was lowered and a secure parking area for federal judges provided. Mechanical/Electrical system startup/commissioning was included in our task order.\nThe project has received a number of awards for construction and design excellence. Some of these awards include:","Sally Ride's Legacy Lives On in AGOR 28\nAuxiliary General Oceanographic Research vessel (AGOR 28) began its life as the R/V Sally Ride on August 9th, 2014, with the traditional crack of the champagne bottle. But that's where its comparison to \"traditional\" ends. The R/V Sally Ride is the latest high-tech vessel constructed for the Office of Naval Research at Dakota Creek Industries (DCI) Shipyard in Anacortes, Washington. The Sally Ride is the first research vessel named after a woman, a fitting tribute to the first American woman in space.\nOutfitted with the latest in sonar, over-the-side winches, triple mapping capability, and a host of other innovations designed to improve deep sea exploration; the vessel will join the research fleet at Scripps Institution of Oceanography at the University of California, San Diego (UCSD) in 2016. Dr. Sally Ride served on the faculty of UCSD from 1989 to 2007.\nThere remains a lot of work to be done before the first scientists step onboard, fire up the computer lab, and begin the first of thousands of research projects that will be hosted aboard the vessel over its expected 20- to 30-year lifespan. Dakota Creek will work with Siemens Marine to install the automation equipment and complete the outfitting required in Phase 3 of the project.\nThe christening marks a milestone in the Navy's Fleet Renewal Plan that began 14 years ago. The Navy's commitment to maintaining six research vessels means two ships will be retired to make room for the R/V Sally Ride and its twin-sister ship the R/V Neil Armstrong launched in March. For Scripps, that means decommissioning the R/V Melville over the next two years. It also means building a $25M pier to accommodate the newest member of the fleet.\nDick Nelson, owner of DCI, and Guido Perla, Chairmen of Guido Perla Associates (GPA) and the designer of the vessel, reminisced about their partnership in the design competition, Phase 1 of the project, held by the Navy to select the design and construction Shipyard for the vessels.\nKathryn Sullivan, Undersecretary of Commerce for Oceans and Atmosphere, and NOAA administrator delivered the principal address. Sullivan served with Ride onboard the space shuttle Challenger and was the first woman to walk in space. In her address to the crowd, she pointed out \"...we currently have better maps of the moon and Mars and Venus than we have of our own oceans.\" And that an estimated 60 to 80 percent of marine species remain undiscovered. She felt the R/V Sally Ride with its state of the art computer and research labs will undoubtedly advance our knowledge of our oceans. She closed by wishing the vessel and her crew, \"...great adventures, grand discoveries, and safe passage home.\"\nRepresentatives from NOAA, NASA and the Navy joined together with Ride's family and her lifetime partner, Tam O'Shaughnessy, to officially welcome the ship to the Scripps fleet. Dr. O'Shaughnessy, head of the Sally Ride Science organization, is the ship's sponsor and hopes to maintain a professional connection to the vessel as it serves the scientific community.\nDr. O'Shaughnessy expressed her appreciation for the honor. She hoped the ship would instill Sally's \"...adventurous spirit and quest for knowledge in all who are privileged to sail on her.\"\nStewardship of the vessel was determined through a bid process with several research organizations competing for the right to operate the new AGOR ships. Scripps was chosen for AGOR 28 with AGOR 27 going to Woods Hole Oceanographic Institution. Captain Tom DesJardins and Sr. Chief Engineer, Paul Bueren, of Scripps, will likely take command of the vessel in mid-2015. Bueren has been onsite at DCI for the construction and will stay on through commissioning and sea trials.\nNAVSEA funded the $145M, two-ship project and will retain ownership. Scripps will operate, crew, and maintain the vessel, as well as manage the scheduling of research projects. Shipboard time will be available to students and researchers from UCSD as well as other universities.\nIn addition to its scientific mission, the vessel is also intended for global operations in support of national security interests in the marine field. As such, the design specifications were demanding. The ship had to be an efficient, fully-integrated and highly-resilient blue-water laboratory capable of exploring the undersea environment anywhere in the world. Most of all, it had to be quiet. Since a great deal of ocean research involves listening, excessive ship noise was unacceptable.\nGPA's unique hull design met the \"bubble sweepdown\" performance requirement by diverting bubbles away from the sensitive sonar area. To complete the noise-dampening goal, engineers chose systems, defined equipment locations, and designed special installation methods with acoustics as a priority.\nWorking deck space is a premium commodity in oceanographic work. The AGOR vessels have 2,557 square feet of clear deck space, with 1,873 square feet of that space on the open aft deck.\nHousing the most modern scientific laboratory afloat gives scientists the ability to analyze specimens and data in real time onboard instead of simply collecting materials and bringing it back to a landside lab for later analysis. With analysis occurring onboard, electrical power quality, sample purity, and vessel stability were strong considerations. Thanks to Kongsberg and Siemens propulsion controls and capabilities, the ship can remain fully operational in Sea State 4, and can handle dynamic positioning relative to a fixed position in Sea State 5 with a 2-knot current and 35-knot winds.\nDCI called upon a multitude of local, national and international vendors to outfit the ship with the best equipment available. Siemens will begin installing their new Blue Drive™ system by late summer. This advanced, multi-drive, low-voltage system manages the speed of the AC propulsion motors controlling the propellers, stern thruster, and bow thruster. The system provides enhanced reliability and efficiency, multiple failsafe features, reduced fuel consumption, lower maintenance costs, and increased ease of operation for the crew. Siemens is also supplying the majority of the electrical switchgear, the ACCU automation, and their custom, condition-based equipment monitoring system.\nFour vibration-isolated Cummins QSK38-DM main engines provide more than 3,900 kW integrated electric power for propulsion and all other ship functions. The integrated diesel-electric plant allows for multiple generator configurations, ensuring the diesel engines operate at peak efficiency in all modes.\nSiemens uses a \"combinator\" style control function to integrate motor speed and propeller pitch, which allows the operator to set the propeller at its most efficient setting throughout the entire range of operations, from cruising to heavy towing. While the combinator is fairly common in ships with controllable pitch propellers with direct drive diesels, it is unusual in a variable-speed electric drive system.\nSpecifications for the deck equipment were stringent. Cranes and winches load equipment and deploy ROVs and buoys weighing in excess of 20,000 pounds. Allied Marine supplied the stern frame with its 12-foot inboard and outboard reach, along with the TK4-30 portable crane and the TK 70-70 aft-deck main crane. They also supplied the motion-compensated CTD handling system and the starboard side handling device, both of which extend to the waterline for improved safety and load control.\nMarkey Machinery of Seattle supplied two electric motor-driven CAST-6-125 hydrographic winches, and the DETW-9-11 traction winch, both with AC variable frequency drives for precise control.\nAs production moves into Phase 3 of the project, Kongsberg will supply a SONAR synchronization system along with their advanced multi-beam SONAR units, a HiPAP gantry with a Sonardyne single beam survey system, and a sub-bottom profiler SONAR. Additional equipment plans include a transducer array, a mid-water echo sounder, and three current profilers operating at different frequencies. This system provides scientists a greatly expanded mapping capability over existing vessels.\nThe ship's design is compliant with 46CFR Subchapter U (Oceanographic Vessels) and built to ABS Under 90 Meter rules. It will be certified as A1, Circle E, AMS, ACCU, NIBS, Ice Class D0, and UWILD.\nAccording to Hollie Anthonysz, Program Manager of Vessel Construction, the DCI team is looking forward to completing Phase 3 of both ships over the next year. Scripps and Woods Hole are both eager to see the vessels at sea."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:1a34832a-8f08-4aa9-8826-cd3dbedcebc0>","<urn:uuid:430ed832-40f5-4bcc-81f3-e02d6ebe8e91>"],"error":null}
{"question":"Can you explain how concrete mixing methods have evolved to improve both productivity and workplace safety? ⚡","answer":"Concrete mixing methods have evolved with ready mix plants and central mix plants replacing traditional on-site mixing, offering time and labor savings. Ready mix plants combine all materials except water, while central mix plants blend everything at one location. For efficiency, plants use computer controls and digital scales for precise measurements. On the safety front, there's been significant evolution in handling silica dust exposure. Instead of traditional broom sweeping, which made dust airborne and posed health risks, modern facilities use advanced cleaning equipment like HEPA-filtered sweepers. These machines, such as the Tennant S30, can clean large areas in a fraction of the time while capturing harmful silica dust that could otherwise cause lung damage.","context":["Creating a modern, durable, and cost effective building involves careful planning and healthy partnering with the related services in the construction business. For example, a batch plant in Dallas, TX will supply ready mixed concrete. Other services are those offered by concrete pumping companies and the concrete contractors. Effective partnership with these players make for fewer headaches during your construction project, especially for the big jobs.\nSo, What’s a Concrete Batch Plant?\nA batch or batching plant is simply an equipment that is used to combine different ingredients to make concrete for use in construction projects. Some of the ingredients include water, sand, aggregate, potash, fly ash, and cement. In situations where you are handling large construction jobs, this would be an essential machine to use.\nEssentially, there are two types of batching plants and they include ready mix plants and central mix plants. Ready mix plants can combine all the materials and ingredients needed to form concrete except for water. Using a ready-mix truck, the mixture is discharged onsite where water is added during the discharge.\nWhen it comes to central mix plants, all the ingredients are combined including water at a central location. The mixed product is then transported to the construction site.\nCommon Ready Mixed Concrete Types Used by Batching Plants\nThere are broadly two options for a batch plant in Dallas, TX to prepare the ready mixed concrete. These are either dry or wet mix concrete. The dry mix is a flexible alternative where the concrete is put in the truck and water added using a charging chute. The mixing is activated during transportation to the job site. If the site is far from the batching plant, using this option prevents your concrete quality from degrading while on transit.\nWet mix concrete is mixing all the ingredients at a single point in a central location of the plant and either using agitators to prevent the concrete from setting when transporting it to the job site or carrying the ready mixed concrete on an open-bodied dump truck. Most plants use an adaptation of the two techniques called shrink mixing.\nModernized plants also employ computer aided controls to ensure the concrete mixed performs to the highest standards possible. For example, digital scales are used for precision and accuracy in the proportion of water versus other aggregate materials mixed.\nThe alternative to ready mixed concrete is mixing the concrete on the job site, which is time-consuming, requires more labor, and increases the budget for your project. Additionally, concrete mixed in a central plant has experienced and skilled manpower working on the batches to ensure the quality of the concrete that you use.\nAlthough the ready mixed concrete will still be mixed on the site to get the proper slump for placement, a batching plant in Dallas, TX must ensure that the primary raw materials are well mixed to proportions fitting the specific needs of your construction. In addition, their pumping service partners reduce your fuel costs by bringing the concrete to your job site.","Your shopping cart is empty.\nMinimizing Silica Dust Exposure\nThe Wells Concrete plant in Albany, Minnesota designs, manufactures and installs a variety of structural and architectural precast wall panels. Workers pour insulated and solid concrete wall panels in a huge warehouse space of approximately 180,000 square feet.\nSilica is a natural substance found in materials common on construction sites, like concrete, rocks and sand. The dust created by cutting, grinding or drilling concrete products can contain respirable crystalline silica. Over time, exposure to these silica particles causes scarring in the lungs, which can harm your ability to breathe according to The American Lung Association.\nThe control of airborne silica dust is a constant challenge for industries that create the dust. And OSHA is insisting that employers ensure workers are safe and silica dust exposure is minimized. Companies need to comply with the new OSHA rule, part of which includes creating an Exposure Control Plan to demonstrate how they are implementing changes that move toward compliance.\nThe key to preventing silica exposure is to keep silica dust out of the air. That’s a tall order for a giant manufacturing site. Former methods like broom sweeping are neither efficient nor effective.\n“You can imagine, if someone were to ask you to clean your house with a toothbrush, that’s what it would be like when we use a floor broom to clean our factory,” says Ben Dalsing, Wells Concrete plant engineer. The OSHA rule prompted the Wells team to look to Tennant for a solution.\nTennant offers three types of dust control methods that can be used to support OSHA silica control housekeeping requirements. As Tennant was developing its offerings, they needed a location to test their HEPA-enabled sweeper and Wells decided dry sweeping with HEPA filtration was an ideal solution for them. “Tennant wanted a testing grounds for a machine with a HEPA filter, and I graciously offered our factory as a very dusty environment,” explains Dalsing.\nThe Tennant S30 is a versatile and durable mid-sized industrial sweeper with a three-stage primary filter system, plus the option of a 4th stage HEPA dust filter.\n“A HEPA filter has a special filter media that can clean to a very high standard by removing microscopic particulate from the air,” says Mat Segar, Tennant Current Products Engineer for Sustainability. The S30 with HEPA filtration sweeper has been in testing for over 60 days and has picked up over 9 tons of dust and debris. Segar goes on to say, “the impressive thing is that the primary filter system is so effective that the HEPA filter has only gained a little over a pound and a half of debris within that timeframe.”\nBased on the Wells testing, the HEPA filter should last at least six months, possibly up to a year depending on the customer’s application. Proper usage and maintenance practices will help increase the effectiveness of the machine’s filtration stages and the life of the HEPA filter up to six months, perhaps longer.\nWells Safety Manager Mike Frieler measures the dust in the air at the plant and says he’s seen improvement with the new sweeping system. “It’s a lot cleaner than just a broom and a dustpan. It contains the dust within the filters, so you don’t have it floating in the air and people breathing it in. A lot better than the old way,\" says Frieler.\n“The act of pushing a broom kicks dust up into the air. And that’s one thing that OSHA doesn’t want anymore. So we’re using the Tennant sweeper to capture the dust and debris,” says plant engineer Dalsing.\nThe Tennant S30 not only helps create a healthier environment for workers, it’s more efficient too. “I’m estimating that it takes between ten and fifteen hours of pushing a broom to clean our entire factory, and the Tennant machine can do that in anywhere between a half hour to an hour and a half,” Dalsing states.\n“This will allow you to have one operator be much more efficient, do the same amount of cleaning in a very short period of time, where you can free up operators to do other things,” says product engineer Segar.\nWhile it was the OSHA regulation that encouraged Wells to seek a healthier cleaning option, the company is committed to keeping its workers safe. “As a company you invest in your employees, so if you’re not taking care of your employees, you’re not going to have a company,” says Safety Manager Frieler."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"}],"document_ids":["<urn:uuid:d4f243b6-b783-40f4-9273-c72ba9d83540>","<urn:uuid:50d73dfc-1d6a-4b4a-bc6f-1a5f2b2c73a2>"],"error":null}
{"question":"What temperature ranges do both Frogspawn and Candy Cane corals require to thrive?","answer":"Both Frogspawn and Candy Cane corals thrive in nearly identical temperature ranges. Frogspawn coral requires temperatures between 76-83°F (24-28°C), while Candy Cane coral needs temperatures between 75-82°F (24-28°C). Both species can experience stress at higher temperatures.","context":["Euphyllia divisa, better known as the Frogspawn coral is one of the most popular large polyp stony (LPS) coral in the reef hobby alongside its sibling species, Hammer coral (Euphyllia ancora) and Torch coral (Euphyllia glabrescens).\nThe name Frogspawn was coined from its attractive multi-tipped tentacles that bear a striking resemblance to a mass of frog eggs. This coral species is hardy, semi-aggressive, and able to attain rapid growth spurts in favorable water conditions.\nThis article provides an insight into the captive care of Frogspawn corals; these consist of feeding, behavior, placement, care tips, and lots more.\nQuick Notes about Frogspawn Corals\n|Scientific Name||Euphyllia divisa|\n|Tank size (minimum)||30 gallons (~120 liters)|\n|Propagation||Easy to moderate|\n|Optimal Temperature||24 – 28°C (~76°F – 83°F)|\n|Optimal Salinity||SG = 1.023 – 1.025|\n|Optimal PH||8.1 – 8.4|\n|Optimal KH||8 – 12|\n|Nitrate||Less than 20 ppm|\n|Tank placement||Bottom to Middle|\n|Growth Rate||Slow to moderate|\n|Color Form||Brown to tan, green to yellow-green and blue (rare), with cream, pink, lavender or white visible tips at the end of the tentacles|\nOrigin and Taxonomy of Frogspawn Corals\nFrogspawn coral is a large polyp stony coral that belongs to Euphylliidae, a family of zooxanthellate scleractinans. The coral species Euphyllia divisa was first described by Veron & Pichon in 1979. Frogspawn coral can also be referred to as Octopus coral, Grape coral, Honey coral, and Wall coral, and it is related to other renowned LPS corals, namely: Torch coral and Hammer coral.\nSpecies: Euphyllia divisa\nHabitat of Frogspawn Corals\nFrogspawn coral is a species that can be found in a variety of reef regions around the world. They form colonies in reef slopes of fairly deep turbid waters to a depth of 40 m (131 ft) where they enjoy planktonic matter and indirect bright lighting.\nThis coral is naturally domiciled in the Indo-Pacific, Fiji, Australia, Solomon Islands, East China Sea, The Great Barrier Reef, and Ryukyu Islands.\nDescription of Frogspawn Corals\nFrogspawn corals form large colonies with corralite walls that emerge on the outer edges, these corralites are thin and sharp-edged. Some colonies are capable of reaching up to 1 meter (3 ft) in size.\nThis Euphyllia species has very long tentacles when fully extended, they are covered with short branches that are tipped with multiple small rounded knobs. Another prominent feature is the presence of a flabello-meandroid skeleton.\nFrogspawn coral tentacles are thick, lumpy, and long; with some branching into double skeletal or single heads, at the end of these tentacles are brightly colored tips. These polyps have a bubble-like outward appearance that resembles a mass frog spawn (frog eggs).\nA variety of Frogspawn corals is the Euphyllia paradivisa known to hobbyists as the Branching Frogspawn coral. This species is endemic to the waters of the Central-Indo Pacific and American Samoa. Like Euphyllia divisa, it has very long tentacles ending with multiple tipped branches, this variety has a branching/phaceloid skeleton. Branching Frogspawn corals also grow a little bit faster and easier to frag.\nThe color of Frogspawn coral tentacles is usually brown to tan, green to yellow-green, and blue (rare), with cream, pink, lavender, or white visible tips at the end of the tentacles.\nBehavior of Frogspawn Corals\nEuphyllia corals can be quite aggressive when placed in close proximity to other corals, as they tend to battle/compete for real estate in your aquarium. Therefore they should be adequately spaced from other corals in the tank.\nFrogspawn coral is hostile but not to the species in its own genus, however, corals of other genera in the family Euphylliidae are not exempted from this hostility.\nAs observed, the polyps extend during the day and only partially at night. Their sweeper tentacles can extend up to 25 cm in larger colonies when they witness hunger pangs, this poses a threat to nearby corals because of the powerful sting they can deliver.\nSome shrimp species dwelling nearby will enjoy the protection of the Frogspawn coral tentacles by means of commensalism.\nFeeding Frogspawn Corals\nFrogspawn coral has a symbiotic relationship with algae hosting in their tissues, this alga is called zooxanthellae. This specialized feeding mode enables them to feed through the conversion of light into food, the zooxanthellae provide just enough nutrition to sustain itself and the coral.\nAdditionally, the corals will capture planktonic organisms and food particles suspended in the water column, as well as the absorption of organic matter.\nRegardless of the presence and role of the photosynthetic zooxanthellae, they should also be fed live and meaty frozen food. Through supplemental or manual feeding, the corals will grow more vigorously, so don’t assume that the nutrition they get from photosynthesis is enough to make them attain rapid growth spurt and gain enormous mass.\nThey can be fed:\n- mysis shrimp,\n- vitamin-enriched brine shrimp,\n- daphnia or small fish,\n- reef roids (link to Amazon)\nFrozen foods can be thawed to make it easier for the corals to consume them.\nTank Requirements and Water Parameters\nThe minimum tank size for housing Frogspawn corals is 20 gallons (80 L). Opting for a larger tank is even better as it allows for adequate spacing amongst the corals and stability of water parameters.\nWater type, Temperature, Hardness, and pH:\nTemperature: The optimal temperature range for keeping Frogspawn corals is between 76 – 83 °F (24 – 28 °C). Keeping the temperature constant (avoiding fluctuation) is more important than the actual temperature itself.\npH: The ideal pH level is between 8.1 – 8.4. Make sure to keep your tank from experiencing rapid swings in pH.\nHardness: Frogspawn corals will appreciate water hardness value between 8 – 12 dKH.\nAlthough Frogspawn corals can tolerate a wide range of light intensity, including high lighting, they still prefer moderate lighting for best growth and coloration. Output from fluorescent bulbs and LED lighting are enough for the lighting and energy requirements of the corals.\nMetal halides might seem like a good option, but this light source gives off too much heat that is capable of damaging the corals’ tissues.\nNote: The output from LED lighting around 50 – 100 PAR value, is sufficient for the lighting needs of the corals.\nTip: Do not forget that in nature these corals are commonly attached to vertical surfaces. So, place Frogspawn corals at of an angle. If the light cannot reach their branches, they often stop growing and their head do not sprout at all.\nThe water flow should be moderate, not too weak or strong. It should be good enough to keep detritus from collecting on the body of the Frogspawn corals.\nEnsure that the corals do not get hit by direct water flow. It may damage the corals or even make the polyps unable to extend fully.\nNote: Under too low flow Frogspawn corals take on more water to inflate themselves. As a result, there is more space between tissue, it leads to the loss of the coloration, from the visual point.\nCare and Maintenance of Frogspawn Corals\nEndeavor to carry out partial water changes of either 20 – 25% monthly, 10 – 15% bi-weekly, or 5% weekly to maintain good water quality and replenish the required trace elements.\nIn addition, the corals should be inspected frequently, this goes a long way in the timely detection of any damage, infection or unusual changes in their behavior. A sick or unhealthy coral should be separated from the rest, and moved to a quarantine tank for proper treatment, this helps to prevent further spread of infections.\nRegular inspection and a good water change schedule are essential in ensuring good health of the corals and optimal water chemistry. Maintain the following trace elements and compounds in the right proportions to promote the best growth conditions.\nCalcium: Between 400 to 450 ppm.\nMagnesium: 1,250 – 1,350 ppm\nSalinity/Specific Gravity: 1.023 – 1.025\nStrontium: 8 – 10 ppm\nNitrates: < 1 ppm\nPhosphate: < 0.05 ppm\nAmmonia: 0 ppm\nPlacement in the Tank\nPositioning the Frogspawn coral should be subjected to three factors:\n- light intensity,\n- water flow and\n- proper spacing to curb aggression.\nA best practice in housing Frogspawn corals is to abide by the 6-inches (15 cm) rule. Place other corals at least 6 inches away from Euphyllia divisa. An exception to this rule is with other similar Euphyllia species like the Hammer corals, as they will not be harmed by the sweeper tentacles of the Frogspawn coral.\nNote: Even though Torch corals Frogspawn corals are different species of the same genus. Torch corals can be too aggressive towards Frogspawn corals. It is not recommended to keep them together as they tend to compete with other corals for space in the reef tank.\nThe placement of the corals should be subjected to an exercise of trial and error in different areas of the tank till you locate a pleasant spot, they will extend their polyps fully and feed properly when they are situated in a comfortable place.\nAvoid placing the corals in a spot with very fast or direct water flow, this can cause the polyps to retract and hamper on its ability to filter-feed.\nPotential Problems Associated with Frogspawn Corals\nBrown jelly infection: This is a common disease for corals. It is characterized by a jelly-like brown mass that appears to be floating on the surface of the coral. Brown jelly disease is caused by poor water quality or tissue damage, it can lead to rapid tissue necrosis and it is capable of spreading to other corals in the tank.\nSolution: Brown jelly disease can be treated using a broad-spectrum on the infected areas. You should remove the sick colony from the main tank, scrub off and siphon any visible brown jelly. Afterward, treat the sick colony in a freshwater or iodine dip (15ppt), then place the colony in a quarantine tank till it recovers before transferring to the main tank.\nDo not overdose. Use the instructions on the bottle based on your tank size.\nRust brown flatworms: Brown flatworm is an acoel worm prevalent in the reefkeeping hobby. These organisms are tan-brown or rust-colored with a red dot and can reach a quarter of an inch in size. They are characterized by an oval and slightly elongated structure with two tail-like appendages at their posterior.\nRust brown flatworms grow rapidly in aquariums with high nutrient levels, often existing in high populations, they will actively attach to the Frogspawn coral’s body and block light from reaching their tissues.\nSolution: These flatworms can be controlled by maintaining low nutrient levels in the reef tank through the use of carbon, aggressive protein skimming, and increased water flow. Also, proper quarantine of new corals and other fauna before placement will help to minimize the risk of transferring acoels into the tank. They can also be tackled using natural predators like the Blue Velvet Nudibranch (Chelidonura varians) and Wrasses.\nIn addition, an infected colony can be treated by dipping it in a dechlorinated freshwater dip for 5 to 10 seconds (Acoels are sensitive to salinity changes). Before doing that, ensure that the water has a similar pH and temperature as the aquarium water, this is to reduce the amount of stress on the colony.\nMishandling: The corals should be handled with caution during fragging, placement, relocation, or transfer between tanks; that way the risk of soft tissue damage will be highly minimized. Furthermore, shy away from fragging corals with a bone crusher of scissors to avoid splintering into the fleshy polyp area.\nSolution: The use of band saw allows for a safer and precise cutting of the corals when compared to bone cutters and sheers.\nFragging and Propagation Frogspawn Corals\nFrogspawn corals can reproduce through sexual and asexual means.\nIn the wild, they carry out sexual reproduction by releasing gametes into the water, resulting in a fertilized egg which eventually gives rise to a free-swimming planula larva. Afterward, the planula larva will metamorphose to a tiny polyp which begins to excrete calcium carbonate, thus developing into a coral.\nMoreover, Frogspawn corals are capable of reproducing asexually. As seen in reef aquariums, a Frogspawn coral will bud off a small group of polyps with little skeletons present. It usually takes them a few months to turn into full-sized heads.\nThey will also break-off individual polyps in response to stress, these polyps will relocate elsewhere and start a new colony.\nAnother method is through coral fragging. However, it can be a little bit tricky because, as I have mentioned earlier, there are two types of Frogspawn corals: the wall type and the branching type.\nPersonally, I would not recommend fragging the wall type if you do not have the skill to make clean cuts with a bandsaw. The branching type is way more receptive to this process.\nThis process is simple, but you have to be cautious.\n- You should ensure your hands are clean or wear a pair of gloves. Do not touch it with your bare hands. Their stings can cause skin rash for a few days!\n- You will need a decent-sized, healthy, and lively coral for this purpose.\n- Take out the coral and irritate it a little bit, so that it will retract the tentacles. Frogspawn corals are pretty sticky and it is easy to accidentally rip their feeder tentacle off.\n- Using an electric bandsaw, divide the coral into several parts by cutting through it at least 2 inches (5 cm) away from the top.\n- Attach the frag to a coral frag plug or live rock using cyanoacrylate gel or 2-part epoxy adhesive, place them back into the aquarium and provide ample water flow.\nTip: Take a frag plug and put it in the water for a couple of minutes to release the air bubbles that might be in the ceramic frag plug.\nTip #2: Treat the new frags with an iodine solution (for example, Lugol’s solution) to prevent them from contracting diseases, then you can attach them to a live rock before placing them back into the tank.\nThings that you might need depending on your method:\nFrogspawn Corals and Tankmates\nAlso, in the absence of sea anemones, Clownfish are known to host in Frogspawn corals in reef tanks. Is it good? No, it is not.\nClownfish may accidentally damage Frogspawn corals that can cause infections like brown jelly. Basically the same can be said about hermit crabs, crabs, etc.\nFrogspawn corals do not like to be disturbed.\nBuying Frogspawn Corals\nThis hardy LPS coral can be purchased at offline pet stores and from reputable online breeders/vendors as well.\nEndeavor to inspect or enquire extensively to be sure of the coral’s health condition in order not to obtain specimens that may have soft tissue damage.\nA head may cost about $50 – $200 depending on size and other factors.\nFrogspawn corals make for a great addition to reef aquariums. It is adored for a lot of reasons which include fast growth rate, ease of care, attractive colors, and the gentle sway of its long multi-tipped tentacles in the water current.\nThis Euphyllia coral is lively, charming, intriguing, and beginner-friendly. Therefore, it can be easily recommended to get one or two for your reef aquarium.\nTop 10 Corals for Beginners\nHow to Care for Green Star Polyps\nHow to Care for Bird’s Nest Corals\nProper Care for Carpet Anemone\nHow to Care for Zoanthid Corals\nHow to Care for Acan Corals\nHow to Care for Torch Corals\nHow to Care for Hammer Corals\nHow to Care for Elegance Coral\nHow to Care for Duncan Corals\nHow to Care for Bubble Tip Anemones\nHow to Care for Pulsing Xenia\nHow to Care for Ricordea Coral\nHow to Care for Palm Tree Polyp\nHow to Care for Kenya Tree Coral","Caulastrea furcata, often known as candy cane, trumpet, or bullseye coral, is a bright and colorful LPS (large polyp stony) coral. Characterized by striped polyps inspiring its common name, it can be found in vivid yellow, green, red, or blueish brown. Each branching polyps contains a neon green mouth. Some common varieties available to purchase are Kryptonite, Orange, Green, and Alien Eye Candy Cane Coral.\nCandy Canes originate from the Indo-Pacific Ocean from Fiji to Australia and the surrounding waters. In the wild, they can usually be found in shallow waters, tide pools and even lagoons. Though they prefer moderate water flow and lighting, they can flourish in a variety of conditions making them perfect for a beginner hobbyist.\nIn this article, we will talk you through everything you need to know to care for your Candy Canes and keep your saltwater aquarium looking vibrant and healthy.\nCandy Cane Coral Care\nCandy Cane Coral is extremely easy to keep as it is a hardy coral, meaning it’s resistant to variations in lighting, flow, and other minor changes in its environment. This makes it forgiving to mistakes commonly made by novices and a great choice whether you are experienced or just starting out.\nAre Candy Cane Coral Aggressive?\nCandy Cane Coral is considered not very aggressive since it has relatively short (2 inch) sweeping tentacles, unlike many other LPS corals. However, it could still sting corals which are close by, so it is important it has plenty of room to grow. As it is one of the fastest growing corals you should aim to give it around 6 inches of space at a minimum.\nCandy Cane Coral Placement\nThe best placement for Candy Cane Coral is in an area of moderate lighting and flow, although it can also thrive in low flow or light intensity. For this reason, it is ideally placed at the bottom of your tank and no higher than the middle. You can place it directly on the sand bed as sand is its preferred substrate.\nIf the flow is too high, it can damage the fleshiness of the polyps; too low and the coral will need more help with feeding, although this isn’t an issue if you plan to feed it regularly yourself. To ensure it takes well to your desired placement it’s recommended to start with a darker and lower flow part of your tank and gradually move it over the course of a few weeks.\nCandy Cane Coral Lighting Requirement\nCandy Cane Coral does not have a high lighting requirement, responding best to low-to-moderate intensity. Anything from 30 to 150 PAR is acceptable, though between 50-70 is recommended. Avoid more than 150 though as light intensity that’s too high could bleach or irritate the coral.\nPlacing your Candy Cane Coral towards the edges of your tank can help to soften the intensity it’s exposed to. Alternatively, a shaded area can be a good spot to provide the right conditions too.\nCandy Cane Coral Temperature\nThe temperature preferred by Candy Cane Coral is between 75°C-82°C/24°C-28°C. Higher temperatures cause thermal stress, resulting in much of the zooxanthellae algae being expelled and depriving the coral of the nutrients they provide.\nCandy Cane Coral pH\nA pH range of 8.1-8.4 is ideal for Candy Cane Coral. The calcium levels should also be kept between 350-420ppm. As it is an LPS coral, these parameters are essential to prevent erosion of the coral’s hard skeleton and to keep it strong and healthy.\nCandy Cane Coral Growth Rate\nCandy Cane Coral has a fast growth rate, especially compared to other corals. This is particularly true when it is fed on a regular basis. The exact growth speed will depend on the available nutrients, light and space, including nearby competition and rocks which could limit the area it spreads.\nCandy Canes grow by dividing a polyp into two identical polyps. This is a big reason why their growth is so rapid if their environment allows it, as their polyps can quickly multiply, and the process can occur with multiple polyps simultaneously.\nCandy Cane Coral Growth Height\nThe growth height of Candy Cane Coral can depend on a number of factors from the amount of food to the light intensity it receives, just like its growth rate. In the average aquarium you can probably expect it to grow up to several inches tall. However, due to their variability it’s difficult to predict exactly how high Candy Canes will grow.\nWhat Do Candy Cane Coral Feed On?\nIn general, Candy Cane Coral is happy to feed on a variety. Bitesize meaty food is most suitable, such as prawns, mysis shrimp and small pieces of krill. It will also accept LPS pellets and other coral foods, or even pellets and flakes intended for fish.\nWhen feeding your Candy Canes, you’ll get the best results if you use some form of feeding apparatus, or even a regular turkey baster. Try to place the food directly into the mouths to make it easiest for the sweeping tentacles to reach. This also helps to prevent your fish from stealing it – they are sometimes known to harass the coral by biting it to access the food inside if given the opportunity.\nIt’s useful to remember that Candy Canes are nocturnal, so the tentacles will naturally come out at night, or when the lights are off. While they extend during the day if they detect food nearby, strategic timing can speed up the process. You should aim to spot feed them 2-3 times a week.\nIn some cases, you may not need to directly feed your Candy Cane Coral at all. Providing that the flow isn’t too low, and you feed the rest of your tank heavily enough, it may get enough nutrients on its own. It will also benefit from its symbiotic relationship with the zooxanthellae algae living in its surface tissues photosynthesizing and giving another source of nutrients. However, spot feeding Candy Canes can help them to grow faster and appear brighter in color, so it’s up to you which approach will achieve your desired effect.\nHow to Split Candy Cane Coral\nIn order to split Candy Cane Coral, look for an outer branch for easy access and ensure you cut as far away from the polyps as you can to avoid damaging them. Glue the piece to a frag plug or rock to allow it to heal.\nBone cutters or a band saw work well as a cutting tool – the latter has the advantage of creating a flat base which is helpful when gluing. After a couple of weeks of healing the frags should be ready to be traded or even sold.\nCandy Cane Coral Dying\nIf your Candy Cane Coral is dying you will notice a change in appearance – in particular, the polyps not opening or puffing up is a tell-tale sign that something is wrong. In some cases, the flesh may recede, causing the skeleton to show. You may also see changes in color.\nDon’t panic if you notice these symptoms however, as with careful monitoring you should be able to get your Candy Canes back to being happy and healthy. The most common cause of these changes is a chemical composition in the water that is harmful to Caulastrea. To diagnose the problem, start by measuring the levels of calcium, magnesium, nitrates, and water hardness. The ideal ranges for these variables are as follows:\n- Calcium: 350-420ppm\n- Magnesium: ~1350ppm\n- Nitrates: <10ppm\n- Water hardness: 8°-12° dH\nIf your water falls within these recommendations, there could be an issue with the temperature or pH. As previously mentioned, Candy Canes require a temperature of between 75°C-82°C/24°C-28°C and alkalinity ranging from 8.1-8.4 pH. Check the light intensity too as anything higher than 150 PAR can cause the polyps to retreat. If the water flow is too high, it can also damage the coral.\nIt’s also possible that the coral is simply adjusting to recent changes in conditions. If you have moved it to a different spot in the tank, replaced your lighting or made other alterations, it can affect the appearance. If this is the case, your Caulastrea should recover quickly on its own.\nSometimes the cause is other livestock in your tank. Try observing your Candy Canes to spot fish or other coral bullying them, especially around feeding time. If this is the case you may be underfeeding your fish, or there may not be sufficient space between your corals. Keep in mind though that at times this behavior from fish is unavoidable and you might need to manage the problem instead of attempting to prevent it entirely.\nFinally, if none of the above methods prove successful, you may need to resort to fragging a healthy segment and starting over.\nThat concludes our guide to Candy Cane Coral! If you found it helpful, be sure to check out our other articles to help make your aquarium the best it can be."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:093c6046-c81b-4fba-b706-0428e483c065>","<urn:uuid:8f5fe40f-154b-4e39-840e-1e66b49280c3>"],"error":null}
{"question":"whats the difference between satellite messengers and PLBs?","answer":"The main differences are: 1) Power - PLBs are more powerful with 5.0 watts compared to satellite messengers' 0.5 watts. 2) Network - PLBs use military satellites while satellite messengers use commercial networks (Iridium or Globalstar). 3) Cost - PLBs have higher upfront costs ($300-500) but no subscription fees, while satellite messengers cost less initially ($100-300) but require annual subscriptions ($150-300). 4) Features - Satellite messengers can send regular text messages and location updates, while PLBs are primarily for emergency distress signals.","context":["Getting help when you really need it. – PLB vs. SMS\nAs published in Western Mule Magazine – Feb 2015\nBack in November of last year we talked about some of the things that should have a permanent home in your saddlebags in case you find yourself stuck on the trail overnight. One of the items I mentioned was a piece of 20th century technology that uses the constellation of satellites orbiting overhead to not only determine where you are but also to let someone know about it and be able to send help in an emergency.\nThere are two types of systems that trail riders can use when their backcountry adventures take a life threatening turn beyond the reach of cell towers. The acronyms and brand names are thick. SPOT, ACR, InReach, and PLB, are some of the terms you hear and often they’re used interchangeably. They shouldn’t be.\nSome of these acronyms relate to Satellite Messenger Systems while others refer to Personal Locator Beacons. The two systems operate very differently and each has its strengths and weaknesses.\nIn a nutshell:\n- Personal locator beacons (PLBs): Have been available in the U.S. since the early 2000’s. PLB’s are handheld devices that can alert authorities to a wilderness emergency. Think of a PLB as your best last chance for help.\n- Satellite messengers: SPOT and InReach are examples of innovations in satellite communications. These handheld devices offer backcountry communication options; namely the ability to send text messages to friends and family and can also function as an emergency beacon.\nDetermining whether to rely on a Satellite Messenger System or a Personal Locator Beacon is a big decision. Let’s dive further down the rabbit hole to help you decide which system is best for you.\nPLB’s are the land-based equivalents of Emergency Position Indicating Radio Beacons (EPIRBs), a sea going technology that has been in use for decades. These devices are high-powered (usually, 5 watts) and designed primarily to send out an emergency distress signal. With a PLB it’s very important to remember that they should be activated only in situations of grave and imminent danger.\n- PLB devices communicate with a network of Russian, Canadian, American and French military satellites that relay your information to the Air Force Rescue Coordination Center in Florida who determine the type and scope of response necessary and coordinates with federal, state, and local officials to effect your immediate rescue. When using a GPS-compatible PLB in the continental U.S, it takes only 5 minutes to alert search-and-rescue personnel of your position.\n- PLB’s have a higher upfront cost when compared to Satellite Messengers. While prices for PLB’s are coming down, these units still typically cost more than a Satellite Messenger. Prices range from $300 to $500.\n- No Ongoing Fees. Unlike satellite messengers, Personal Locator Beacons do not require you to pay any recurring subscription fees for the device to work as designed. Some new Personal Locator Beacons offer an optional, subscription service, that allows the user to send an email or text message that includes your location information. This feature has been designed as a way to let family and friends know that all is well.\n- PLB’s are equipped with a long-lasting lithium battery. The batteries remain dormant until you flip the switch to activate the PLB and are designed to power the device for 24 hours. These are not user replaceable AA’s and must be installed by a manufacturer certified replacement center. PLB batteries are designed to last for 5 years.\nMuch like PLBs, satellite messengers are handheld transmitting devices that are useful in backcountry areas far from reliable cell phone coverage. These user-friendly devices allow you to send text messages and your location coordinates to friends or family so you can report on the status of your trip. They can also send calls for help in an emergency.\n- Satellite Messengers are much less powerful than a PLB. A SPOT device only has 0.5 watts of power, where a PLB sends a signal that is ten times as powerful (5.0 watts) to push the message through trees, clouds, and anything else that can weaken the signal. A ten-fold difference is significant.\n- Satellite messengers are GPS-based devices that rely on commercial satellite networks—Iridium or Globalstar—rather than the military network used by PLBs. Emergency calls using either network are routed to a privately run coordination center in Texas which then notifies local 911 with your GPS location.\n- Satellite Messenger devices usually cost less upfront than a PLB. However, these tools will not work without a paid subscription service. Each manufacturer offers a variety of usage plan options that can in the long term significantly increase your total cost for the unit. Unit prices range from under $100 to over $300. The subscriptions plans that are required to use the units range from $150 per year to over $300 annually depending on what features you want.\nFor sending messages and letting the folks at home follow your route, then satellite messengers such as the SPOT or the DeLorme InReach will certainly function well. If you want the best in SOS functionality, then a PLB is the device to choose.\nHere’s a thought to consider if you plan on using a satellite messenger, or any device, which performs with less than 100% consistency. If your contacts are expecting to receive “I’m okay” messages from you, then not receiving them is a guaranteed source of anxiety. If your family is expecting to receive “okay” messages at a certain frequency, and then they do not, it could cause them to raise the alarm unnecessarily. If you are using a satellite messenger to reassure your contacts that you are okay on a regular basis, then be sure that everyone understands the limitations of the device and establish a clear understanding of what it could mean if the messages are not received.\nWhile both types of devices will summon help where cell phones are useless. To me, a satellite messenger is something to keep the better half happy while I’m out on the trail and a PLB is about calling in the troops when the “stuff” really hits the fan.\nAs always, for more information on this and other topics, as well as the nation’s largest source of horse trail and horse camping information in the U.S. please visit www.TrailMeister.com."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:f322868d-d37e-4331-8990-f06261a38847>"],"error":null}
{"question":"What are the benefits of macro photography for capturing insect shots, and what ethical concerns arise when using digital technology to track living subjects? 🔍","answer":"Macro photography of insects offers the benefit of revealing hidden worlds invisible to the naked eye through techniques like stacking multiple focused images for highly detailed results. It allows capturing fascinating details like insect eyes, mandibles, and hair as focal points, especially when shooting in early morning when insects are less mobile. However, digital tracking of living subjects raises significant ethical concerns, particularly regarding privacy and consent. There's a lack of consistent regulation in digital health research, with many tech companies not complying with federal requirements for human subjects protection. Additionally, subjects may not fully understand the privacy implications of how their data is collected and used, similar to how Twitter users are often unaware their public posts can be used for research without consent.","context":["Discover a hidden world, as Mikael Buck shows you how to shoot incredible close-ups\nOne of the most fascinating aspects of photography is that it can open the door to worlds we can’t see with the naked eye. Capturing this hidden world has its share of challenges and requires a far more systematic approach than other areas of photography, but the results are fascinating and rewarding. Capturing macro images of the most populous but least-seen creatures on our planet – insects – is a great example of this.\nFor best results, you’ll need to use a technique known as stacking – shooting multiple images of the same thing at slightly different points of focus before blending them together to create a highly detailed final image.\nWhat’s important to keep in mind is that your composition and exposure for every image in the series need to be consistent, so when you come to post-production the software will seamlessly create the final image. To achieve this, you need to make sure you take care to set things up properly.\nYou’ll need a spacious work area, where no one will disturb your equipment, and you’ll need space to move around without accidentally hitting anything. At the very least, you’ll want a heavy tripod and a sturdy table that won’t move. I highly recommend using a geared tripod head that allows you to make small and accurate adjustments to the camera position, as this will save you time when it comes to composition. Tape everything you can down: I stress-test my kit set-up before I begin, so if I do knock something I know everything will stay in place. To achieve the incredible close focusing, you’ll want to use a series of extension tubes to sit between your lens and camera. These can be picked up reasonably cheaply, while a simple 50mm prime is a good starting point as your lens.\nGood composition can be the difference between the image being just a scientific record and something wholly more engaging and more aesthetically pleasing.\nFor insects, use low angles looking up at the subject and it will appear more dynamic. Think about how the frame will be read. The eyes and mouths of insects are fantastic focal points, but claws, mandibles and hair can all be used as powerful reference points.\nWhen setting up the shot, leave as much space as possible around the subject. Be aware that you’ll need to use quite a heavy crop on the images because the extension tubes will protrude into your frame.\nYou’ll find that stitching may adjust your crop as well, so the more room you leave yourself, the more flexibility you’ll have to create a pleasing final composition. This is where a camera with a large megapixel count, like my 42.4-million-pixel Sony Alpha 7R II, comes in handy.\nConsistency is key. The aim of stacking is to create a series of almost identical images, where you move the focus in tiny increments across the image to give you enough material to stitch together in the computer to achieve enough depth of field in your image. Do this by moving the camera a tiny amount either towards or away from the subject using a micro-adjustment plate. Manually adjusting focus in small enough increments using the focus barrel on the lens is almost impossible.\nSet up the camera as close as possible to the subject so you can withdraw from it, rather than approach. In this way you don’t have to worry about accidentally bumping into equipment, disturbing the insect and ruining the shot. Use a cable release or the timer setting on your camera to ensure there’s no movement of the camera itself. Take as many images as you can, while moving as little as possible with your adjustment plate. You might not use all images for your stack, but you want to have as many options as possible. Set your exposure manually, otherwise you risk variation between frames.\nTo get the depth of field you need it’s important to use flash, as there won’t be enough ambient light to shoot at a smaller aperture. Fortunately, as insects are tiny, ordinary flashguns are just right. Position lights as close to the subject as possible, using a Gorillapod or miniature tripod, and experiment. Give your lights enough time to refresh between each frame. If the lighting is inconsistent, the stitching process won’t work. Keep it simple to begin with and once you are comfortable with the technique you can move on to a bit of experimentation. As with your camera settings, make sure your flash power setting is done manually.\nFor initial attempts, take 20-30 images at f/11 and ensure you move focus through the frame. You can then start using wider apertures and get sharper images, taking more frames as the depth of field gets smaller. Ultimately, you want to aim to use your lens’s sweet spot of around f/4-f/5.6. This could require you take as many as 100 shots to get an image sharp across the frame.\nI recommend using specialised stacking software so you can focus on your images and experiment as much as possible. Helicon Focus lets you export a raw file of the finished stack. Learning the stacking software can be demanding, so don’t be discouraged if your initial results aren’t as great as you’d hoped. The radius and smoothing settings required for a particular image can vary greatly, and the best setting can often only be found through experimentation.\nOver time, though, you’ll develop a knack for it.\nWhy it works\nWhen you are creating imagery using stacking, it can sometimes be very tempting to forget about aesthetics, and just tie up 500 images to achieve perfect sharpness.\nWhile this method can be impressive, it’s often not the best way to create really arresting shots. Ultimately, you shouldn’t forget that it’s the capturing of a story in images that works really well. In this shot of the common house spider, I chose to keep the focus heavily on the eyes and fans to really bring out the spider’s dynamism and vitality – this shot was a stack of just two frames.\nYour eye needs a way through the frame. Think about how you would shoot a person, a larger animal or a car, and then apply the same process to your macro photography.\nThe lighting set-up\nThe set-up for this shot of a ladybird was quite straightforward, with the choice of background used being key. The strong colour and textures worked really well against the subject. Two remotely triggered flashguns were used – one gelled and the other firing through white card to soften the key light. Finally, a sheet of white card was positioned to the left of the camera to reflect light back into the shadows.\nExperiment with background\nAs you get more familiar with the stacking technique, you can try using coloured gels or card to really bring your images to life with interesting light and background.\nUse a dedicated stacking program\nA specialised program like Helicon Focus lets you stitch together raw files, so you have plenty of flexibility when it comes to post-processing. Experiment with your stitches using JPEGs before applying it to raw files.\nSince your subject needs to be completely still or you’ll ruin your carefully planned shot, you’ll need to find static insects. The best way to do this is to wrap up warm, grab your kit and head out in the early morning, the chillier the better. Insects hibernate in the cold and as their body temperature lowers they slow down to a standstill – letting you carefully get close and take your shots without disturbing them.\nSony Alpha 7R II\nAs stacking requires heavy cropping, a high megapixel count camera will allow you plenty of flexibility to do this and still retain large printable files. The full-frame Alpha 7R II camera can take incredibly sharp and detailed pictures with the right lenses.\nIt’s almost impossible to make adjustments this tiny using just your lens. The adjustment plate lets you move your camera back and forth in small increments, giving you a much better selection for your stack.\nUsing flashguns will allow you to use a small aperture and low ISO. A low ISO will give you less noise and more room to adjust colours and exposure in post, and you need to keep lighting consistent across all the images for your stitching, which may not be possible with ambient light.\nHelicon Focus Pro\nWhile stitching can be done in other software, I highly recommend using this program as it allows you to generate a raw file from the final stack, giving you more flexibility when editing.\nMikael Buck is a London-based editorial and commercial photographer. Having spent more than a decade working as a photojournalist for titles such as The Times, Mail on Sunday and the Metro, Mikael now works on commission for UK national newspapers, high-profile corporations and the country’s biggest brands. www.mikaelbuck.com","Direct-to-consumer wellness products, location-tracking apps, and access to personal data on social networks present both exciting opportunities and significant ethical worries for researchers.\n“The digital revolution is rapidly influencing how health research is conducted. We can now passively observe and record people ‘in the wild’ and 24/7,” says Camille Nebeker, EdD, MS, founder and director of UC San Diego’s Research Center for Optimal Data Ethics.\nThe use of artificial intelligence and active assisted living robots in the health sector also is increasing. “While there is amazing potential, the digital health ecosystem is not consistently regulated. We are in the Wild West of digital health research,” says Nebeker.\nThe authors of a recent paper proposed steps the scientific community can take to ensure social media data are used ethically.1 The paper was prompted in part by the recent Cambridge Analytica scandal, involving allegations that the firm used data improperly obtained from Facebook to build voter profiles.\n“Many of my colleagues are conducting research using social media platforms,” says Nebeker, one of the paper’s authors.\nIRBs and researchers are struggling to navigate this new territory, sometimes unsuccessfully.\n“When something goes wrong, as it did with Cambridge Analytica, it compromises public trust and jeopardizes research that is in progress,” says Nebeker.\nThe following are two central ethical concerns:\n• Researchers may need to cover additional information during the informed consent process.\nCommercial products — such as fitness tracking devices — are used as measurement tools. This means privacy policies and terms of service should be considered.\n“These terms might influence the study risk assessment,” explains Nebeker. Potential research participants also need to factor in this information to make informed decisions.\n“In many cases, the terms of service directly conflict with the federal regulations for human subjects protections in that a participant, if harmed by the product, must agree to arbitration,” notes Nebeker.\n• Not all tech companies comply with federal requirements for research.\nFederal regulations for human subjects protections must be followed if research is funded by the U.S. Department of Health and Human Services. However, many tech companies that are involved in biomedical research are not regulated. “We need to develop common standards that govern digital health research,” says Nebeker.\nResearchers using social media data are operating in an unregulated environment. Thus, there is growing concern about potential harms. “This is another case of how technology has evolved faster than regulations,” says Sherry Pagoto, PhD, director at the University of Connecticut Center for mHealth and Social Media.\nPrivacy breaches are possible — intentional or not. “This poses risks to everyone involved: researchers, social media companies, and, most importantly, the general public,” says Pagoto.\nFor example, few Twitter users are aware that public social media posts can be used by researchers.2 Notably, the majority believe that researchers should not be able to use their tweets without consent. Also, users of commercial products do not always understand privacy implications.\n“We cannot fault them, though. These policies are very lengthy, and written in ways that are difficult to understand,” says Pagoto.\nThe following changes are needed, according to the study authors:\n• Public education on the research performed with social media data, why it is important, and how researchers protect user privacy.\n“Consultation with an expert in health tech ethics is critical if being proactive and diligent about human research protections,” says Nebeker.\nStakeholders — including researchers, IRBs, potential participants, or policymakers — may not be fully aware of how data are collected, used, or shared by social media platforms. “This lack of knowledge will influence risk assessment and information included in the informed consent process,” notes Nebeker.\n• Federal regulations on the use of social media data in research.\n“We can anticipate that the technology and research landscape will only continue to evolve, and rapidly,” says Pagoto. IRBs rely on federal regulations for guidance on the ethical conduct of research. These regulations are outdated as they pertain to the use of data generated by new technologies like social media. Thus, says Pagoto, “universities, funders, and researchers need to be more vigilant about potential harms and begin to craft guidelines for the purpose of self-policing. We need a code of conduct.”\n• “Tech ethicists” working alongside researchers as they attempt to use social media data.\nSomeone with tech ethics expertise could comment on the ethical implications specific to technology used in studies and conduct training for clinicians. “It would also be useful for these folks to advise on grant applications, even serving as consultants or co-investigators,” says Pagoto.\nSomeone on the IRB could take on this role. “But if limited expertise is available on campus, external expertise should be commissioned,” says Pagoto.\nIRBs also should have the expertise to properly review social media research. “Adequately attending to research ethics will require an investment,” says Pagoto. “We want to nudge institutions to make this investment.”\n- Pagoto S, Nebeker C. How scientists can take the lead in establishing ethical practices for social media research. J Am Med Inform Assoc 2019; 26:311-313.\n- Fiesler C, Proferes N. “Participant” perceptions of Twitter research ethics. Social Media + Society, March 10, 2018. Available at: http://bit.ly/2valr7G."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"}],"document_ids":["<urn:uuid:1c03ad0f-c347-44ca-898d-ee785fcdb4a5>","<urn:uuid:31f9e0fa-beb1-4e9f-9c19-d5b6873d9873>"],"error":null}
{"question":"Hey! I'm curious - which condition typically gets diagnosed faster: axial Spondyloarthritis or Type 1 diabetes? The delay in getting diagnosed really matters!","answer":"Type 1 diabetes typically gets diagnosed much faster than axial Spondyloarthritis. Type 1 diabetes symptoms develop quickly over weeks or months and include clear indicators like excessive thirst, urination, and significant weight loss. In contrast, axial Spondyloarthritis has a worldwide average delay to diagnosis of about seven years, with women taking two years longer than men to be diagnosed.","context":["What is Delay to Diagnosis?\nDelay to Diagnosis refers to the time from onset of symptoms of axial Spondyloarthritis (axSpA) until diagnosis of the disease, usually by a rheumatologist, but sometimes by another healthcare provider. Worldwide, the delay to diagnosis averages about seven years - with women taking two years longer than men to be diagnosed.\nThere are several stages in the delay to diagnosis, including a delay in the patient recognising that their symptoms require medical attention. There is a delay in the primary care provider (usually a GP) recognising and dealing with axSpA and making a correct referral; there is a further delay in obtaining a final diagnosis after referral to the correct specialist - usually a rheumatologist. You can read more about these stages of delay in the NASS Gold Standard Consultation document, which is available in the resources section below.\nThe delay to diagnosis is important because it is known that the earlier the diagnosis, the sooner treatment can start and the better the outcome will be for the patient.\nA delay in diagnosis is costly, because of increased visits to healthcare providers and excessive testing. It is also costly to the patient because he or she is impacted by a loss in quality of life and may experience many things like chronic pain, fatigue, mental health issues, difficulties with relationships and social life, as well as a loss of job opportunities or an inability to work.\nDelay to Diagnosis includes all aspects of the time from symptom onset until final diagnosis.\nCheryl Koehn, President of Arthritis Consumer Experts in Canada talks to Michael Mallinson about his own experiences during his delay to diagnosis. Michael is a former ASIF Trustee and current volunteer.\nRaj Mahapatra, ASIF Trustee talks to Professor Marco Garrido-Cumbrera, patient, researcher at University of Seville and founder of IMAS.\nMichael Mallinson talks to Dr Walter Maksymowych, Professor, Rheumatologist and co-founder of the Spondyloarthritis Research Consortium of Canada (SPARCC).\nMichael Mallinson talks to Aleksei Sitalo, ASIF Trustee about the delay to diagnosis in Russia.\nOur Delay to Diagnosis Campaign\nWe know from our member patient organisations that the lengthy delay to diagnosis in axSpA is a global problem that has been apparent for decades. And yet, even with the introduction of modern technologies, the time to diagnosis has not reduced very much - if at all - in many countries. We also know that, on average, women take two years longer than men to be diagnosed. The delay to diagnosis in axSpA patients is longer than that of other rheumatic diseases and is acknowledged as a problem by rheumatologists and other healthcare professionals. We are undertaking our Delay to Diagnosis project at the request of our member patient organisations, which recognise the adverse effects of a lengthy delay to diagnosis on patients and healthcare systems.\nThe overall objectives are to significantly reduce the average time to diagnosis internationally; and to globally raise awareness about the disease and detrimental effects of the delay, physically, psychologically and economically. We will do this by collaborating with researchers and our members, using and building on their work where necessary, to create an axial Spondyloarthritis Global Burden Statement. We will build awareness and advocacy tools for our members and others to use with all stakeholders to reduce the delay to diagnosis for axSpA patients everywhere.\nWe aim to\nGather data and other robust evidence that demonstrates the problem\nExplore, and document, why the delay to diagnosis is so important\nBetter understand the reasons for the delay\nIdentify which practices have been effective, how they have worked and what else might be successful in reducing the delay\nUnderstand delay differences and similarities around the globe\nReview expert opinion and existing research on the delay\nIdentify ways to advocate for a reduction in the delay\nIdentify way to increase awareness of axSpA\nProduce resources to support ASIF members in their work on reducing the delay\nWhy does this matter?\nGlobally, diagnostic delay in axSpA remains a significant challange.\nAxSpA is a disease that affects people at a pivotal phase in their life, with symptoms starting on average around the age of 26.\nWhat is the impact on patients?\nSuffering with undiagnosed severe pain, stiffness and fatique often leads to depression and anxiety. The delay can lead to significant disease progression, even causing permanent disability. Quality of life is also severely impacted by people experiencing symptoms without effective treatment.\nWorld Health Organization Regions\nMean avarage delay to diagnosis in years","Symptoms of Type 1 diabetes\nSymptoms of Type 1 diabetes: Introduction\nType 1 diabetes can strike anyone at any age but most often occurs in children and adolescents. Symptoms of type 1 diabetes generally develop quickly and can include tingling or loss of sensation in hands and feet, excessive thirst, excessive urination, extreme hunger, fatigue, weakness, blurred vision, vomiting, dehydration, and significant weight loss even with the consumption of large amounts of food.\nIf type 1 diabetes is not diagnosed and treated promptly, the body's cells do not receive the glucose they need for energy and the body is forced to burn fat stores for energy. As large amount of fats stores are burned, they substances called ketones are produced. When a large amount of ketones build up in the body, it can lead to a life-threatening condition called diabetic ketoacidosis. High amounts of glucose in the blood can lead to hyperosmolar hyperglycemic nonketotic syndrome, coma, and shock. Long-term complications of type 1 diabetes can also be serious and include kidney failure, diabetic retinopathy and blindness, peripheral neuropathy, kidney failure, serious skin infections, gangrene, cardiovascular disease, stroke, disability, and death....more about Type 1 diabetes »\nType 1 diabetes symptoms:\nThe symptoms of Type 1 diabetes usually arise over\nweeks and months, as compared to those of Type 2 diabetes\nthat may take years.\nAlthough Type 1 diabetics can briefly see mild symptoms similar to\nthe early stages of Type 2 diabetes, the most pronounced symptoms\nof Type 1 diabetes are usually the more severe symptoms\nof very high blood sugars and these progress quickly....more about Type 1 diabetes »\nSymptoms of Type 1 diabetes\nThe list of signs and symptoms mentioned in various sources\nfor Type 1 diabetes includes the 13\nsymptoms listed below:\nResearch symptoms & diagnosis of Type 1 diabetes:\nType 1 diabetes: Symptom Checkers\nReview the available symptom checkers for these symptoms of Type 1 diabetes:\nType 1 diabetes: Symptom Assessment Questionnaires\nReview the available Assessment Questionnaires for the symptoms of Type 1 diabetes:\nType 1 diabetes: Complications\nReview medical complications possibly associated with Type 1 diabetes:\nDiagnostic testing of medical conditions related to Type 1 diabetes:\nResearch More About Type 1 diabetes\nDo I have Type 1 diabetes?\nType 1 diabetes: Medical Mistakes\nType 1 diabetes: Undiagnosed Conditions\nDiseases that may be commonly undiagnosed in related medical areas:\nHome Diagnostic Testing\nHome medical tests related to Type 1 diabetes:\n- High Cholesterol: Home Testing:\n- High Blood Pressure: Home Testing\n- Heart Health: Home Testing:\n- Thyroid: Home Testing:\n- Menopause: Related Home Testing:\n- Vaginal Health: Home Testing:\n- Diet & Weight Loss: Home Testing:\n- Adrenal Gland Health: Home Testing:\n- Breast Cancer: Related Home Tests:\n- Kidney Health: Home Testing:\n- Diabetes: Related Home Testing:\n- more home tests...»\nWrongly Diagnosed with Type 1 diabetes?\nThe list of other diseases or medical conditions\nthat may be on the differential diagnosis list of alternative diagnoses\nfor Type 1 diabetes includes:\nSee the full list of 28\nType 1 diabetes: Research Doctors & Specialists\n- Diabetes & Endocrinology Specialists:\n- Cholesterol Specialists:\n- Cardiac (Heart) Specialists:\n- Pregnancy & Fertility Health Specialists:\n- Womens Health Specialists:\n- Immune-Related Disease Specialists (Immunology):\n- more specialists...»\nResearch all specialists including ratings, affiliations, and sanctions.\nMore about symptoms of Type 1 diabetes:\nMore information about symptoms of Type 1 diabetes and related conditions:\nOther Possible Causes of these Symptoms\nClick on any of the symptoms below to see a full list\nof other causes including diseases, medical conditions, toxins, drug interactions,\nor drug side effect causes of that symptom.\nArticle Excerpts About Symptoms of Type 1 diabetes:\nDiabetes Overview: NIDDK (Excerpt)\nSymptoms of type 1 diabetes usually\ndevelop over a short period, although beta cell destruction can begin\nSymptoms include increased thirst and urination, constant hunger,\nweight loss, blurred vision, and extreme fatigue. If not diagnosed and\ntreated with insulin, a person can lapse into a life-threatening diabetic\ncoma, also known as diabetic ketoacidosis.\n(Source: excerpt from Diabetes Overview: NIDDK)\nEndocrine Diseases: NWHIC (Excerpt)\nIncreased thirst, increased urination, weight loss,\nfatigue, nausea, vomiting, frequent infections.\n(Source: excerpt from Endocrine Diseases: NWHIC)\nType 1 diabetes as a Cause of Symptoms or Medical Conditions\nWhen considering symptoms of Type 1 diabetes, it is also important to consider Type 1 diabetes as a possible cause of other medical conditions.\nThe Disease Database lists the following medical conditions that Type 1 diabetes may cause:\n- (Source - Diseases Database)\nMedical articles and books on symptoms:\nThese general reference articles may be of interest\nin relation to medical signs and symptoms of disease in general:\nFull list of premium articles on symptoms and diagnosis\nAbout signs and symptoms of Type 1 diabetes:\nThe symptom information on this page\nattempts to provide a list of some possible signs and symptoms of Type 1 diabetes.\nThis signs and symptoms information for Type 1 diabetes has been gathered from various sources,\nmay not be fully accurate,\nand may not be the full list of Type 1 diabetes signs or Type 1 diabetes symptoms.\nFurthermore, signs and symptoms of Type 1 diabetes may vary on an individual basis for each patient.\nOnly your doctor can provide adequate diagnosis of any signs or symptoms and whether they\nare indeed Type 1 diabetes symptoms."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"}],"document_ids":["<urn:uuid:c45332ad-b006-4cdb-9567-77ae7194cb14>","<urn:uuid:5bf868dc-26f1-4e93-b858-a340ab03a557>"],"error":null}
{"question":"¡Hola! 🤔 Me gustaría saber cómo puedo convertir resultados continuos de análisis de sangre en una clasificación binaria. ¿Podrían explicármelo paso a paso?","answer":"Test results with continuous values can be converted to binary by defining a cutoff value. Any result higher than the cutoff is designated as positive, while values lower than the cutoff are designated as negative. However, this conversion causes information loss since it doesn't indicate how far above or below the cutoff a value is, and values close to the cutoff fall into an interval of uncertainty.","context":["Binary or binomial classification is the task of classifying the elements of a given set into two groups (predicting which group each one belongs to) on the basis of a classification rule. Contexts requiring a decision as to whether or not an item has some qualitative property, some specified characteristic, or some typical binary classification include:\nBinary classification is dichotomization applied to practical purposes, and in many practical binary classification problems, the two groups are not symmetric - rather than overall accuracy, the relative proportion of different types of errors is of interest. For example, in medical testing, a false positive (detecting a disease when it is not present) is considered differently from a false negative (not detecting a disease when it is present).\nStatistical classification is a problem studied in machine learning. It is a type of supervised learning, a method of machine learning where the categories are predefined, and is used to categorize new probabilistic observations into said categories. When there are only two categories the problem is known as statistical binary classification.\nSome of the methods commonly used for binary classification are:\nEach classifier is best in only a select domain based upon the number of observations, the dimensionality of the feature vector, the noise in the data and many other factors. For example, random forests perform better than SVM classifiers for 3D point clouds.\nThere are many metrics that can be used to measure the performance of a classifier or predictor; different fields have different preferences for specific metrics due to different goals. For example, in medicine sensitivity and specificity are often used, while in information retrieval precision and recall are preferred. An important distinction is between metrics that are independent on the prevalence (how often each category occurs in the population), and metrics that depend on the prevalence - both types are useful, but they have very different properties.\nGiven a classification of a specific data set, there are four basic combinations of actual data category and assigned category: true positives TP (correct positive assignments), true negatives TN (correct negative assignments), false positives FP (incorrect positive assignments), and false negatives FN (incorrect negative assignments). These can be arranged into a 2×2 contingency table, with columns corresponding to actual value - condition positive (CP) or condition negative (CN) - and rows corresponding to classification value - test outcome positive or test outcome negative. There are eight basic ratios that one can compute from this table, which come in four complementary pairs (each pair summing to 1). These are obtained by dividing each of the four numbers by the sum of its row or column, yielding eight numbers, which can be referred to generically in the form \"true positive row ratio\" or \"false negative column ratio\", though there are conventional terms. There are thus two pairs of column ratios and two pairs of row ratios, and one can summarize these with four numbers by choosing one ratio from each pair - the other four numbers are the complements.\nThe column ratios are True Positive Rate (TPR, aka Sensitivity or recall), with complement the False Negative Rate (FNR); and True Negative Rate (TNR, aka Specificity, SPC), with complement False Positive Rate (FPR). These are the proportion of the population with the condition (resp., without the condition) for which the test is correct (or, complementarily, for which the test is incorrect); these are independent of prevalence.\nThe row ratios are Positive Predictive Value (PPV, aka precision), with complement the False Discovery Rate (FDR); and Negative Predictive Value (NPV), with complement the False Omission Rate (FOR). These are the proportion of the population with a given test result for which the test is correct (or, complementarily, for which the test is incorrect); these depend on prevalence.\nIn diagnostic testing, the main ratios used are the true column ratios - True Positive Rate and True Negative Rate - where they are known as sensitivity and specificity. In informational retrieval, the main ratios are the true positive ratios (row and column) - Positive Predictive Value and True Positive Rate - where they are known as precision and recall.\nOne can take ratios of a complementary pair of ratios, yielding four likelihood ratios (two column ratio of ratios, two row ratio of ratios). This is primarily done for the column (condition) ratios, yielding likelihood ratios in diagnostic testing. Taking the ratio of one of these groups of ratios yields a final ratio, the diagnostic odds ratio (DOR). This can also be defined directly as (TP×TN)/(FP×FN) = (TP/FN)/(FP/TN); this has a useful interpretation - as an odds ratio - and is prevalence-independent.\nThere are a number of other metrics, most simply the accuracy or Fraction Correct (FC), which measures the fraction of all instances that are correctly categorized; the complement is the Fraction Incorrect (FiC). The F-score combines precision and recall into one number via a choice of weighing, most simply equal weighing, as the balanced F-score (F1 score). Some metrics come from regression coefficients: the markedness and the informedness, and their geometric mean, the Matthews correlation coefficient. Other metrics include Youden's J statistic, the uncertainty coefficient, the Phi coefficient, and Cohen's kappa.\nTests whose results are of continuous values, such as most blood values, can artificially be made binary by defining a cutoff value, with test results being designated as positive or negative depending on whether the resultant value is higher or lower than the cutoff.\nHowever, such conversion causes a loss of information, as the resultant binary classification does not tell how much above or below the cutoff a value is. As a result, when converting a continuous value that is close to the cutoff to a binary one, the resultant positive or negative predictive value is generally higher than the predictive value given directly from the continuous value. In such cases, the designation of the test of being either positive or negative gives the appearance of an inappropriately high certainty, while the value is in fact in an interval of uncertainty. For example, with the urine concentration of hCG as a continuous value, a urine pregnancy test that measured 52 mIU/ml of hCG may show as \"positive\" with 50 mIU/ml as cutoff, but is in fact in an interval of uncertainty, which may be apparent only by knowing the original continuous value. On the other hand, a test result very far from the cutoff generally has a resultant positive or negative predictive value that is lower than the predictive value given from the continuous value. For example, a urine hCG value of 200,000 mIU/ml confers a very high probability of pregnancy, but conversion to binary values results in that it shows just as \"positive\" as the one of 52 mIU/ml."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"}],"document_ids":["<urn:uuid:c861e39a-d54a-48af-b0b4-92c26e49d806>"],"error":null}
{"question":"What were the contrasting roles of water and wind in shaping early Philippine trade relations with China versus local Filipino culture?","answer":"Water and winds played interconnected roles in Philippine history. Chinese traders used seasonal winds (amihan and habagat) for maritime trade, sailing from Guangdong and Fujian to the Philippines during amihan around March and returning during habagat around June. Meanwhile, water was so fundamental to Filipino culture that even ethnic names reflected it - like Tausug (meaning 'people of the sea') and Tagalog (from 'taga-ilog' meaning 'from the river'). While Chinese relations focused on maritime trade exchanging goods like porcelain and gold, Filipino culture was deeply integrated with waterways, to the point where they didn't need bridges or wheels because water served as their roads and bridges.","context":["Many visitors want to see my study, if only to see the desk or the room where my columns and lectures are born. My library is usually off-limits because it resembles ground zero—a direct hit from a storm or earthquake. Clutter is natural for me, it suggests physical sloth and mental activity. On the other hand, a clean and organized desk projects the opposite.\nThe recent floods reminded me of two pictures by Charles Wirgman in the 1857 Illustrated London News showing how people coped with a flooded street in Manila: men rolled up their pants, women pulled up their skirts, umbrellas were opened. In areas where road turned into stream, people switched from vehicles with wheels to bancas. While pictures are supposed to be worth a thousand words, I needed the Illustrated London News text for a quote to be used in today’s column, but the transcription is tucked away somewhere in my files to be found later when I have no need for it.\nFilipino painters also documented the habagat or its effects in charming but little-known works like one by Fabian de la Rosa in 1919, who painted a man waist-deep in a Manila flood. Fernando Amorsolo, nephew of Don Fabian, is better known as a painter of Philippine sunlight, whose images of rice fields and sensuous, smiling maidens captured the mood of the prewar “Pistaym” (peace-time) Philippines. He also painted a woman walking against rain and wind, her location given away by the Legazpi-Urdaneta monument in the background. De la Rosa and Amorsolo were professors in the UP School of Fine Arts, like Dr. Toribio Herrera who painted a more violent scene of a woman struggling with an umbrella blown out of shape by storm and rain.\nHabagat (southwest monsoon) is wind that brings heavy rainfall that results in floods during the wet season. Amihan (northeast monsoon) brings cold air to our shores from the Christmas season to February. These winds have been known to us for centuries. These winds were known to Chinese traders as early as the ninth century when they traded porcelain, remnants, if not surviving whole pieces, of which have been found in almost all archeological sites in the Philippines. Chinese junks sailed from Guangdong and Fujian to the Philippines and Indonesia during amihan sometime around March, and returned around June during habagat. Spaniards in the 16th century also knew about these tradewinds but called them by other names. Governor-General Francisco Sande sent a report to Philip II from Manila on June 7, 1576, that read:\n“…there are two general seasons (in Filipinas), the dry season, (when) the BRISAS, as they are called, blow from the southeast to the north, finally blowing directly from the north; while in the other or wet season, the VENDAVALES blow from northwest to southwest. Thus during these two seasons, the winds blow from every point of the compass.\n“…coming from Nueva España [Mexico], from the east towards this western region, the BRISAS would help; while the VENDAVALES, especially the usual one, the southwesterly wind in the channels of these islands would impede the progress of the ship… it is quite clear and evident that by the end of May and middle of June the VENDAVAL begins here from the west and blows strongly night and day. Now if for any reason it should cease for a moment, it would only be to burst forth again with renewed vigor. Such a period of quietness is called here CALLADAS (silence). The BRISA begins in November and lasts till the end of May. Between these two general seasons two others exist, called BONANZAS (‘gentle winds’) which last from the middle of March to the end of May, and comprise also part of September and October.”\nFilipinos of my age remember Bonanza either as an American TV series about cowboys in the Wild West, or a theme restaurant on Edsa that served roasted calf. History enlarges our vocabulary and our understanding by telling us about gentle winds between the cold season and the rainy season. History also teaches us perspective by making us relate the present flooding not just with previous ones like “Ondoy” and “Milenyo” but with documented storms all the way back, beyond memory, to the 16th century. History teaches us to see how we cope with disaster and how much of our reactions are rooted in our time and experience. Digging a bit deeper makes us understand why things are the way they are.\nDidn’t pre-Spanish Filipinos, like other peoples of insular Southeast Asia, build their houses on stilts? This was done to keep dry and safe from wild animals. When the Spanish came and brought a different type of architecture the bahay kubo remained above ground; even the bahay-na-bato kept the owner of the house and his things safe from floods on the upper floor. The Spanish introduced the wheel, roads and bridges to connect lands separated by water, when our people were actually connected by water. They didn’t need a bridge or the wheel because water was their road and bridge. Even names like Tausug (tau—people, sug—sea) or Tagalog from Taga-ilog (from the river) are rooted in water. The names of places also evoke water: Cebu from Sugbu (shallow water) and Pampanga (from pampang or riverbank).\nHistory is not confined to old books and documents, it means being able to read the past in the events of the present. Floods can be read as history lessons to make us realize that things don’t have to be the way they are.\n* * *\nComments are welcome at email@example.com","*EARLY PHILIPPINE CULTURE\nPhilippines, before the conquest, was a nation of flourishing civilization. The inhabitants’ culture had the elements of a civilized society: organized policies and laws; an elaborate system of writing and language; religion; independent governmental units (barangays); markets/trading posts; and weapons, tools, and utensils necessary for existence.\nBy the first century A.D., Philippines shared with its Southeast Asian neighbors a Neolithic-based culture which consisted of the following elements: (1) materially, kaingin (swidden) farming, domestication of ox and buffalo, use of metals and navigational skills; (2) socially, respect for elders and constituted authority, and the importance of women; (3) religiously, animism, anito worship, ancestor worship, jar burial; and, (4) culturally, some music and dance patterns, and tattooing (batik painting)(Evangelista, 2002).\nThe contact between Philippines and the so-called Great Civilizations of Asia (India, China and Islamic Arabia) contributed much to the development of the culture of the former.\nPHILIPPINES AND THE GREAT CULTURAL TRADITIONS OF ASIA\nIndianization of Southeast Asia\nThe entry and proliferation of Indian tradition in Southeast Asia resulted to the Indianization of the region, giving birth to Hindu and/or Buddhist kingdoms like those in Funan, Champa, Sri-Vijaya, Majapahit, among others. These states recognized “divine rulers”. Interestingly; however, Philippines was spared from such development. This is because our country was bypassed by Indian traders exclusively traded with Burma, the Malay Peninsula, Thailand, Indo-China Peninsula and China as the terminal of Indian products. Indianized Southeast Asians then brought Indian influences to the Philippines at a later date (Evangelista, 2002).\nAn example would be the Orang Dampuans (men of Champa), which, according to Sulu tradition, between 900 A.D. and 1200, these immigrants from the Indianized kingdom of Champa (in Indochina) traded with the Buranons of Sulu (Zaide, 1999).\n*Some Indian Influences\n1. Sanskrit terms in the Tagalog language [e.g. ina, asawa (swamin), likha (lekha), balita(vartta), katha, ahas (ahi), hari, ganda, mana]\n2. In clothing, the waist loom of the Igorots resemble the looms, cloth and color schemes woven by the women of Assam, India; Barong Tagalog had the same cut as that of the “Kutra” of Lucknow, India; use of cord and veil in marriage ceremonies\n3. Among the natives of Sulu, there was the adoration of Vedic deities like Indra (sky god), Agni (fire god), and Surya (sun god) (Zaide, 1999)\n4. Fables of Indian origin like: the monkey and the turtle; and, the Visayan anecdote of the hawk and the hen (Zaide, 1999)\n*Relations with China\nDuring the reign of the Sung (960-1127 A.D.) and Ming (1368-1644 A.D.) dynasties in China, Chinese traders established settlements along coastal towns and in the hinterlands of the archipelago. Hence, there was a continuous flow of goods from the port of Canton to the different trading ports in Lingayen Gulf, Masbate, Manila Bay, Mindoro, and Sulu in the Philippines.\nFilipinos bartered their products, such as yellow wax, gold, hemp, cotton, betel nut, tortoise shells, and pearls, for the Chinese goods—silk, porcelain wares, iron, tin, bronze gongs, umbrellas and fans (Zaide, 1999.).\nClearly, Filipino-Chinese relations were more economic in nature than political. China’s political influence (Confucian system of government) to Southeast Asia was limited to Vietnam due to the conquest of the said country from 111-939 A.D. Moreover, Chinese traders had low social status in Chinese society and therefore could not be bearers of Confucian political ideas (Evangelista, 2002).\n*Some Chinese Influences\n1. In language, particularly Tagalog, reveals a good number of loaned words (e.g. ate (a-chi), katay (ka-tai), hukbo (hok-bo), pansit (pansit), sangla (sangle), lumpiya (lun-pia), kuya (ko-a)\n2. Use of umbrella, porcelain, gongs, lead,\n3. Wearing of white dress when mourning\n4. Manufacture of gunpowder\n5. Mining methods and Metallurgy\n6. Parental-arrangement (in marriage)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:7e420054-812a-49ff-b1eb-95aec14b7476>","<urn:uuid:8764e188-5293-4f07-a908-a0cb2b7b0fc1>"],"error":null}
{"question":"What is the minimum decibel level that can be heard in both Ambiophonics sound systems and by people with mild hearing loss?","answer":"In Ambiophonics systems, sounds across all frequencies between 0Hz and 20kHz can be processed, while people with mild hearing loss cannot hear sounds quieter than about 25 decibels (for adults) and 15 decibels (for children). The two systems operate at different decibel ranges - Ambiophonics can process the full hearing spectrum while mild hearing loss creates a threshold below which sounds cannot be heard.","context":["For the reason that the plug-in development uses the JAVA framework you need to have an installed JAVA Runtime Environment.\nIf you don't have the JRE (JAVA Runtime Environment) installed then you'll get it here: http://www.java.com/download/manual.jsp\nJust unzip the dedicated ZIP-File and copy the plug-in folder into your VST plug-in directory.\nApple Mac OS Audio Units and VSTs:\n1.) Unzip the dedicated ZIP-File\n2.) Copy Transcoder.vst to ~/Library/Audio/Plug-Ins/VST\n3.) Copy Transcoder.component to ~/Library/Audio/Plug-Ins/Components\nImportant: To use the Audio Units you need to copy the *.vst as well.\nThe Principles of Ambiophonics*:\n1.) Ambiophonics uses RACE* (Recursive Ambiophonic Crosstalk Elimination) to enable binaural listening\n2.) The Speakers are positioned with a separation angle smaller than 20° (called Ambiodipol) instead of 60° used in stereo. No worries, in contrast to stereo, the sound stage goes far beyond the boundaries set by the speakers (up to 120°).\n- RACE is a free algorithm made available by the Ambiophonics Institute (http://www.ambiophonics.org)\n- Ambiophonics has been invented by the Ambiophonics Institute\nKey advantages in comparison to stereo by playing the same material from CD, LPs or your computer:\n1.) Elimination of Comb filtering effects and pinna direction finding errors\n2.) By having the speakers close together reflections by walls and the bass mode response of the room are much easier to control\n3.) The center presence is very stable and therefore always easy to locate\nThe sound stage gets a strong deepness, height and wideness which creates a real three dimensional listening experience.\nLocating a single sound source within the original stereo image is much easier with Ambiophonics. You're able to pinpoint each instrument in all three dimensions!\nTo achieve optimal cross talk cancellation Ambiophonics has a sweet spot (similar to stereo) along the median line where the sound stage has its best representation.\nWhich records sound best?\nIn contrast to the standard stereo setup where spatially rich recordings that contain binaural cues with inter-aural time differences (ITD) loose their deepness, Ambiophonic plays back a much richer sound stage.\nMany productions mix monaural microphones or direct sources between channels to create phantom images limited to inter-aural level differences (ILD), but even those recordings do get a wider and more precise sound stage with Ambiophonics.\nThe Ambiophonic Transcoder VST Plug-In\nFrequency Limited RACE:\nAs default RACE works on a limited frequency range of 0Hz-4.5kHz by keeping all other frequencies untouched. Deselection of the checkbox activates Recursive Ambiophonic Crosstalk Elimination for all frequencies between 0Hz and 20kHz.\nRecursive Ambiophonic Crosstalk Elimination Attenuation [dB]:\nIncreasing the attenuation value reduces the cross talk elimination which results in a smaller sound stage.\nA higher presence value reduces the crosstalk elimination of \"equiphase/similar amplitude\" signals to emphasize center sounds like vocals.\nDelay [micro seconds]:\nThe delay defines the time offset for the cross talk cancellation wavefront to make sure that the signal arrives the ear at the right point in time. The amount depends on speaker separation and listening distance. It is a good starting point to go for a speaker separation angle of 20° and a delay of around 70μs. Please keep in mind that the delay is a discrete value which changes in steps of \"1/sampling frequency\" (e.g 22.7μs for 44.1kHz or 10.4μs for 96kHz). The slider allows all values but the program chooses the nearest possible delay value.\nJust changing the balance of the audio signal.\nOutput Attenuation [dB]:\nThe Ambiophonics algorithm increases the amplitude under certain circumstances which makes it necessary to attenuate the output signal.\nDisclaimer and License:\nThis Software is provided \"as-is\", without any express or implied warranty.\nIn no event will the author be held liable for any damages arising from the use of this software.\nPermission is granted to anyone to use this software except for commercial use.\nPlease contact me (Stephan Hotto) if there is a wish for a commercial implementation.","Living with mild hearing losshearing aids for mild hearing loss Even if you aren't ready for hearing aids, mild hearing loss can impose surprising difficulties in everyday life that shouldn't be underestimated. Here's how to cope and take the next steps. 2021 1338 Living with mild hearing loss https://www.healthyhearing.com/report/7733-Living-with-mild-hearing\nHearing loss is divided into degrees of severity from mild to profound. If you have mild hearing loss, your hearing loss isn't severe and you can likely \"fake it until you make it\" in many social situations.\nHowever, despite how it sounds, \"mild\" hearing loss doesn't mean harmless—it can still have profound effects on your quality of life and ability to communicate with loved ones and coworkers. And because it's mild, these effects may be more insidious than obvious.\nWhat is mild hearing loss?\nMild hearing loss is defined by being unable to hear sounds that are quieter than about 25 decibels (dB) for adults and 15 dB for children. This includes sounds like whispered conversations, dripping water, leaves rustling, feet shuffling on floors/carpets, and birds chirping. You may struggle with hearing both low-pitched and high-pitched sounds (known as frequency) in that sound range, though most people stop hearing high-frequency pitches first.\nDegrees of hearing loss include normal, mild, moderate, moderately severe, severe and profound. These ranges are identified on an audiogram, one of the tests you’ll undergo as part of a hearing evaluation. An adult’s normal hearing range is between 0-25 dB across the frequency range. Normal hearing for children is between 0-15 dB.\nHow does mild hearing loss affect communication?\nPeople with mild hearing loss often say they hear well in quiet environments when talking one-on-one with someone; however, not so well when they are in noisy environments, nor when a person is facing away or is standing some distance away from them, according to audiologist Dr. Melissa Danchak, AuD, of Kos/Danchak Audiology and Hearing Aids in Arlington, Texas.\nPeople with mild hearing loss often report that they can hear but can't understand conversations clearly.\nWhat causes mild hearing loss?\nThere are many other reasons you might receive a diagnosis of mild hearing loss. Some of them, when diagnosed and treated promptly, may result in restored hearing.\n“These conditions would all need to first be treated by either a family physician, pediatrician or otolaryngologist,” Dr. Danchak said, “and could eventually lead to referral to an audiologist of medical treatment cannot resolve the loss.”\nOther causes of hearing loss result in permanent loss that cannot be reversed with medical intervention and would require treatment using amplification from hearing aids or devices like cochlear implants. These include:\n“Fortunately,” Dr. Danchak said, “the digital hearing aids available today do a fantastic job at amplifying the sounds you want to hear while managing the background noise so that an individual can enjoy interacting with others more naturally again.”\nCan you prevent mild hearing loss?\nThe most preventable type of hearing loss is noise-induced hearing loss (NIHL), a condition which affects millions of Americans, hearing loss statistics show. Many types of hearing protective devices are available to help you keep your hearing safe from NIHL:\n“The only other preventative measure one can take is to seek medical treatment right away whenever they notice a change of hearing,” Dr. Danchak said. “Whether it is treatment for an ear infection or something more serious like a viral infection or autoimmune attack on the inner ear, it is important not to delay making an appointment to see a physician. Earlier treatment yields better outcomes.”\nHearing aids for mild hearing loss\nPeople with mild hearing loss are often candidates for hearing aids. Hearing aid technology has come a long way, and today's devices are sleek, stylish and customizable to any degree of hearing loss. Hearing aids exist for every lifestyle and budget.\nThere is good news for hearing aid wearers with mild hearing loss. First, you will have more choices of hearing aid types and styles available to you compared with someone whose hearing loss has progressed to the point of being severe to profound. You may be able to wear smaller hearing aids, too.\nWhy is it important to seek treatment?\nRecent studies have found that even mild degrees of untreated hearing loss can increase the risk of developing conditions such as cognitive decline, dementia and Alzheimer's compared to peers with normal hearing. Hearing loss can also lead to increased social isolation, depression and risk for falls—not to mention difficulty in communicating with those around you on a daily basis.\n“Even though the word 'mild' makes one think it’s not really that bad, mild loss can have serious consequences,” Dr. Danchak said. “Why should a person live with a reduced quality of life due to hearing loss when the amplification options today are so advanced that they not only provide magnificent quality of sound, they are also wireless interfaces to your cell phone and other Bluetooth accessories?”\nDon't wait to treat mild hearing loss. Here's why.\nPeople who first discover a hearing loss wait an average of seven years to seek help with hearing aids. During this time, the hearing loss progresses, and the brain \"forgets\" how to hear sound properly. People who procrastinate too long become less able to understand speech over time. Catching a hearing loss when it is mild gives you the best chance for success with hearing aids and rehabilitation now and in the future.\nHow to get help\nThe first step to better hearing is to schedule an appointment with a hearing healthcare professional for a hearing evaluation. This initial test acts as a baseline for future examinations so your professional can accurately monitor your hearing health going forward. Get started by visiting our professional directory to find a hearing aid clinic near you."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"}],"document_ids":["<urn:uuid:e482c19b-bb20-446e-8558-7534d5075eb0>","<urn:uuid:cee27044-b097-4d30-b6f0-677b0190984f>"],"error":null}
{"question":"Which has better environmental properties - traditional wood finishing or acoustic wood slat panels?","answer":"Both have environmental benefits. Traditional wood finishing uses natural wood, which is the only renewable building material available and stores carbon from growing trees. Similarly, acoustic wood slat panels are environmentally friendly as they are made from wood and natural fibers, plus they offer additional sustainability benefits through their insulating properties that help save energy costs. They both use wood as their primary material, making them eco-friendly options.","context":["Wood finishing - Wikipedia Wood finishing refers to the process of refining or protecting a wooden surface, especially in the . Finishing can also influence other wood properties, for example tonal qualities of musical instruments and hardness of flooring. .. and ridges, and also slivers of wood cell wall material that are attached to the underlying wood.\nAll About the Different Types of Wood Finishes | DIY The experts at DIYNetwork.com explain the different types of natural wood finish to help you choose the right one for your home.\nWall finishes - SlideShare 21 Jan 2015 . here, find out few materials which are using for wall finishes. . Natural stone 100 years plus Natural slate 100 years Natural wood ? . insulation properties and is lighter, quicker, and easier to apply than sand and cement.\nBest Types of Wood for Furniture and Modern Interior Design Wooden furniture, wall and ceiling designs and floor ideas look spectacular and warm. . mahogany and teak. Each of these woods has unique look and properties. . 25 wood decor ideas bringing unique texture into modern interior design.\nFinishing of Wood - Forest Products Laboratory - Forest Service and surface properties of wood affect finish application and performance (how long a finish . gradual transition of cell wall thickness and resin canal complexes.\nWall Finishes & Surface Treatments - INEX Wood Wall Finishes and Surface Treatments . were designed and developed from concept for their recycled and environmentally friendly acoustical properties.\nRenaissance™ Wood Wall Panel - Construction Specialties A/1 fire characteristics. □ 5 year product warranty. □ Factory-finished wood panel. □ Low VOC water based wood finishes. Options: □ 5/8” (15.9mm) thick.\nFlooring and Wall Finishes - Kettyle - Building & Construction Advice Welcome to KCS Flooring and Wall Finishes. solid wood flooring tongue and groove. In this section will be advising on the options available for flooring and wall.\nInterior Finishes - International Code Council to be used as finish for walls, ceilings, floors and other interior surfaces of buildings. . in the exterior walls of the first story above grade shall be permitted to be of wood .. 803.6.1 Surface burning characteristic test. Textile wall and ceiling.\nWood Types and Finishes Glossary | Wayfair We define the characteristics of 13 woods often used in furniture and 9 wood finishes. . Warning: These do-it-all rooms will make you want to tear down a wall.\nFlame Spread Performance of Wood Products Used for Interior Finish Wood and wood-based products are widely used as interior wall, ceiling, and floor surfaces in all types of buildings. Appearance, acoustical qualities, and.\nChapter 2. Building Materials & Finishes A Preservation Handbook for Historic Residential Properties & Districts. Context . may form the external structural wall or may be the external . of paint. Both wood and masonry should be kept dry by preventing leaks from roofs and guttering.\nDifferent Types of Paint and Finishes - Oil Based Paint Vs Water . The majority of wall paint sold today is water-based, but oil-based paint remains popular . options because they have good leveling qualities for a smooth finish.\nUnit 10 Construction Materials — Types and Uses - Goodheart-Willcox Lumber. Mosaic tiles. Nonferrous metals. Patterned glass. Paving brick. Plastics .. Characteristics and ... walls today are composite walls of a finish surface.\nProdex - Prodema - Natural Wood Beauty ProdEX panels are veneered with 100% natural wood. . These qualities can be observed when sunlight reflects off the wood's fibers and . Walls: concealed.\nMandate M/121 INTERNAL AND EXTERNAL WALL . - SGP Standard Characteristics of the WALL AND CEILING PANELS FOR INTERNAL USES . CEILING (except those for wood-based panels and plasterboards presented in the.\nThe Benefits of Using Wood - Make it Wood Responsibly sourced wood is the only renewable building material available; it is . Wood products then store the carbon that the growing trees have removed from the . Comparative studies of the economics of different wall framing systems.\nSolid Wood Linear Ceilings | Wood Ceilings The Solid Wood Linear ceiling system is a wood solution in it's most natural form. . Tiles & Panels; Veneered Wood .. A wide range of wood species are available, all with their own characteristics. . The Solid Wood Linear ceilings and walls are suitable for all building sectors: Corporate, Transport (airports, metro-, bus -.\nStaining Interior Wood | Wood Finishing 101 - Minwax Wood finishing expert Bruce Johnson shares basic wood staining tips and offers . All woods have two characteristics that play important roles in determining.\nWeathered Wall Boards | Weaber Lumber Our Weathered Wall Boards offer a rustic designer look that will provide a unique beauty and natural appearance to accent any room in your home. Made from.","Acoustic Wood Slat Panels\nAcoustic wood slat panels are a popular addition to modern office spaces. They add a touch of style and warmth while helping to reduce noise pollution and enhance speech intelligibility.\nDesigned for DIY installation, these decorative wooden wall panels feature stunning charred oak veneer and black felt backing. This gorgeous combination effortlessly merges style and sustainability, blending in well with a wide range of decor styles.\nReduces Noise Pollution\nNoise pollution can affect our mental health, causing stress, fatigue, and depression. Thankfully, there are ways to reduce the problem. One easy way is by installing acoustic wood slat panels. These panels eliminate the echo effect in your work area and reduce noise pollution. They also improve acoustics and make it easier for employees to communicate with each other.\nThese acoustic wood wall panels feature a fluted design and a sustainable felt backing that help them absorb unwanted noise and echoes. This makes them perfect for offices, conference rooms, and homes. The wood slats create a natural aesthetic that works with almost any interior design style. The panels are lightweight and easy to install. You can even use them to cover a curved surface.\nWhile many sound absorption methods require expensive and invasive amendments to walls, these acoustic wood slat wall panels are both cost-effective and simple to install. They’re the ideal option for those who want to achieve a modern, wooden look while improving room acoustics.\nThese acoustic wood wall panels are crafted from a combination of real wood veneer and MDF with an acoustical felt backing. They have an NRC rating of 0.85, which means that they can absorb up to 85% of the sounds that hit them. This makes them an excellent choice for office environments where clear communication is vital.\nWood slat acoustic panels add texture, depth, and warmth to your interior design. They come in different colors and finishes to suit various aesthetic preferences. These acoustic panels also insulate your home and help you save on energy costs. They’re easy to install and can be shaped to fit soft angles.\nThese acoustic panels are made of wood and natural fibers, so they are environmentally friendly. They also absorb and diffuse sound waves, reducing reverberation and improving speech clarity. They’re ideal for commercial applications, acoustic wood slat panels such as offices and conference rooms where clear communication is essential.\nAcoustic wood wall panels can be easily crafted to match your existing interior design. They’re a stylish alternative to traditional drywall and provide a modern aesthetic that’s easy to clean. They’re also incredibly durable and won’t require replacement for years.\nPosh Wood Charred Oak acoustic wood paneling is a stunning, eco-friendly solution for your interior design. Its charred oak finish paired with an elegant black felt background effortlessly merges style and sustainability. Its refined aesthetic complements a wide range of interior design styles, from rustic to contemporary.\nAcoustic wood slat panels help to create a more comfortable and productive work environment by reducing noise pollution. They also enhance aesthetics and improve acoustics by absorbing unwanted sound, reducing echoes, and enhancing speech intelligibility. This makes them ideal for modern offices, which rely on effective communication and collaboration to achieve business goals.\nIncorporating acoustic paneling into your office space is an easy way to increase productivity. However, choosing the right type of acoustic panels is important. Choosing ones that are durable and can withstand a lot of wear and tear is essential. Additionally, they must be easy to clean in order to avoid dust buildup, which can cause them to become damaged over time.\nThe Slatpanel range of acoustic panels is designed for hassle-free installation. This allows you to quickly and easily remodel your workspace with minimal disruptions to your day-to-day operations. They feature a high-quality wood veneer with a sleek and contemporary-looking lamella strip design, which is then mounted onto a specially-designed recycled acoustic felt material.\nThe natural acoustics of slatted wall panels make acoustic wood slat panels them suitable for many interior design styles. The clean lines of acoustic wood panels are perfect for modern walls, but they can also enhance traditional and transitional interior designs as well. Moreover, the textured surface of acoustic wood panels is compatible with mid-century modern and bohemian interior design styles.\nAcoustic wood slat panels are a great way to add extra sound absorption to a room. This helps to reduce the amount of noise pollution in a space, which can affect the health and productivity of those who are using it. Acoustic panels also help to make the space feel more comfortable and welcoming. This is because they help to create a more natural atmosphere. Additionally, acoustic wood slat panels are easy to install. They can be attached to the wall using black screws, which makes them a simple solution for anyone who wants to increase the sound absorption in their home or office.\nWhile traditional foam panels may be an option, they are not as effective as acoustic wood slat wall paneling when it comes to sound absorption. This is because foam is porous, which means it has many small holes in it that allow sound waves to pass through them. Acoustic wood slat panels, on the other hand, are designed with a dense felt backing, which is highly absorbent.\nUnlike the egg carton style panels that you might see in recording studios, acoustic timber slat panels look great in any room. They can be used to create walls, headboards, or even a room divider. They are also easy to install and can be customised, making them a great option for anyone who is looking for an affordable solution that looks good in any space."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:72cc9656-6dff-4896-993c-ae49211a9c58>","<urn:uuid:0937a197-13df-4545-b435-1e1dfd16774e>"],"error":null}
{"question":"Could you explain the tools needed for bonsai collection and the ideal setting for practicing focused meditation?","answer":"For bonsai collection, essential tools include a shovel, cutting shears, burlap or plastic, string, tree saw, sphagnum moss and a small crowbar. As for focused meditation practice, it requires a calm, quiet environment with minimal distractions. The practitioner should remove external disturbances like television noise, put their phone on silent, and wear comfortable clothing. While bonsai collection requires specific equipment, focused meditation can be practiced anywhere that isn't overly crowded or noisy.","context":["Dressed in a classic black sweater, jeans and flip-flops, Julie Trigg sits quietly amidst the serene bonsai exhibit at Selby Gardens. The rain has just stopped falling, and Trigg is admiring the blooming orchids that line the walkway.\nFrom an outsider’s point of view, the artist appears simple and uncomplicated. But judging by her bonsai collection — rumored to be 200-plus — and her status as president of the Sho Fu Bonsai Society and co-curator of the group’s permanent exhibit at the gardens, she’s nothing of the sort.\nAbout 25 years ago, Trigg, who is also a painter and owns an art studio at 1369 Main St., operated a vendor booth at an outdoor Sarasota art show.\n“The gentleman at the next booth had bonsai, and I fell in love with his bonsai pine trees,” Trigg said. “I ended up trading a painting for a pine tree.”\nA move to Pennsylvania from New York in 1994 led to Trigg’s joining of the local bonsai club there, and it was then that she began to delve into the realm of pruning bonsai. The goal, she says, is to make young trees look old.\n“Unlike us,” she jokes.\nThe art dates back to more than 1,500 years ago to China, when naturally dwarfed trees were collected. It is not uncommon to find bonsai there that are 300-to-400 years old.\n“It teaches you patience and is also calming,” Trigg said. “And you can make it out of any type of tree — it’s not like ‘The Karate Kid,’ although those were all junipers, by the way.”\nAlthough the bonsai display at Selby Gardens is only two years old, this year marks the Sho Fu Bonsai Society’s 35th anniversary. The display’s 15 trees, in addition to a plethora of members’ trees, will be featured in numerous how-to demonstrations at Selby Gardens’ annual Asian Cultural Festival, which will be held from 10 a.m. to 5 p.m. Feb. 27 and Feb. 28.\nThe festival is the society’s biggest event and is one of the main reasons Trigg has been so occupied lately. And the other? Epcot recently accepted one of Trigg’s bonsai trees, for the second time, into its International Flower and Garden Festival. With all expenses paid, Trigg will take the bonsai — a juniper grafted onto a driftwood base — to be displayed for three months at Epcot.\n“Last year, I had a ficus exhibited inside Torii (the Japanese pavilion) at Epcot,” Trigg said. “They only took 21 trees this year, and only three trees under 30 inches. I really worried and agonized over days about moving limbs and removing inches — but mine was one of those (chosen).”\nBonsai — A living art form that dates back 1,500 years to China.\nCommon styles — Formal upright (chokkan), informal upright (moyogi), slanting (shakan), semicascade (han-kengai) and cascade. Formal and informal upright are the easiest to work on because they take little trunk manipulation.\nCollection — The best time to collect deciduous trees is during their dormant season (usually early spring), just before the new buds pop out. Mountainous regions, cow pastures or storm-ravaged coastlines are good places to look, but make sure to adhere to all local laws regarding tree and natural-object removal.\nTools for collection — Shovel, cutting shears, burlap or plastic, string, tree saw, sphagnum moss and a small crowbar.\nThe right tree — American hornbeam, maple and sweetgum trees grow quickly, develop nice branching and good trunks and are favorites for beginners. The best specimens are 5 to 6 feet tall with lower branches.\nApex — Locate your new top, or apex, of the tree and cut it off before digging the tree out of the ground. Always make slanting cuts as close to the trunk or branch as possible, allowing for faster healing and less scarring.\nWiring — One of the special training techniques for bonsai is wiring. Copper wire is most commonly used, and a general rule for wire sizing is one-third the width of the branch at its thickest point.\nPruning — Two kinds of pruning are used on bonsai — cutting and pinching back. A concave cut is the most desired because it will heal without noticeable scarring; pruning helps to create the tree’s basic shape.\nAppearance of age — Peel off the bark where the look of dead wood is desired. The exposed wood will die and turn gray. Using a small paintbrush, paint the dead wood with lime sulphur to preserve the wood and turn it white.\nCurrently 0 Responses\n24 \"Smart, Sassy, Strong & Classy!\" Women's Gala & Speed Networking Event\n10:00 am - 2:00 pm\n24 Sunsets at Selby\n5:30 pm - 9:00 pm\n25 Mindful Practice\n25 Ed U Tainment\n9:30 am - 4:00 pm\nCan you dig it?\nThird- and fourth-grade students of Temple Beth Sholom had a chance to brush up on their paleontology skills last week while digging for faux dinosaur bones.\nSound of scholars\nLocal students Caleb Upton and Matthew Vaadi received some help for their upcoming studies to the tune of $1,000 each from the Sarasota Chorus of the Keys. The scholarships were made possible through the Sheridan E. Brown Memorial Scholarship Fund. Both students plan to use the funds toward a career in music.\nHigh Five Moments of the Week\nThe top five sports moments of the week.","Focused Meditation and Its Benefits for Addiction Recovery\nFocused meditation contributes to our internal arsenal of meditation techniques, that can help us in so many ways during our journey of addiction recovery.\nThe art of meditation has been practised for thousands of years. Today, it serves as a form of alternative healing and its benefits are seemingly endless.\nFocused meditation helps to build more awareness of our thought patterns and come to understand that they do not define us. It can help us relax in moments of chaos.\nThe ability to observe our own thoughts is a major catalyst for increased growth during the recovery process. For instance, building ‘focused awareness’ can help us acknowledge the kinds of thoughts we have that trigger cravings.\nBy discovering what our thought patterns and internal monologues are, we can even step outside of ourselves and learn how to stop reacting to internal and external triggers. This is just one of the many benefits focused meditation offers when practised consistently.\nWhat Is Focused Meditation?\nFocused meditation is a type of meditation in which you place your focus on one particular sensory stimuli. Whether that be an object, sensation, or sound.\nTraditionally, when we think of what it means to meditate, we think of clearing our minds. With focused meditation, there is less focus on clearing the mind, and more focus on, well, focusing !\nThis form of meditation is great for beginners because it isn’t guided and doesn’t require facilitation. It also serves as a perfect introduction into meditation as it helps to slow down the mind with the assistance of a focal point, rather than having nothing to anchor on to.\nYou can practise this form of meditation at home, at work, at the park, and truly anywhere that isn’t overly crowded or noisy. It will be much easier to practise focused meditation in a place that is quiet and still.\nThis particular meditation can be practised for as long as you can maintain, or for as little as a few minutes. It is truly a highly adaptable form of meditation.\nThe Benefits of Focused Meditation\nThere are many benefits of this type of mindful meditation for the brain and the body. Research shows that focused meditation helps to reduce stress. One study even indicated that practising focused meditation was able to help relieve pain in patients experiencing chronic lower back pain\nAnother study showed that university students who practised focused meditation for six weeks experienced a decrease in symptoms of anxiety and depression. A follow-up conducted 6 months after the conclusion of the study revealed that the students who continued to practise the meditation continued to experience a decrease in symptoms.\nAfter 12 months, students still engaging in the practice were observed to have a continued reduction in their symptoms of anxiety and depression. The study concluded that focused meditation is a formidable psychosocial tool that can benefit university students greatly\nFocused meditation does wonders for the brain, and has the ability to rewire neural networks. Over time, it also actually causes areas of the brain to thicken, including the mid-prefrontal cortex and the mid-insular part of the brain. This can be invaluable for us as we work to heal our brains from the long-term effects of substance abuse and prolonged exposure to stress .\nThe benefits of focused meditation:\n- Great for beginners\n- Can be practised without an instructor\n- Can be practised anywhere\n- Rewires neural networks in the brain\n- Increased concentration levels\n- Helps increase patience\n- Fosters mindfulness\n- Reduces stress\n- Relieves pain\n- Decreases symptoms of anxiety\n- Decreases symptoms of depression\nStep-By-Step Focused Meditation for Beginners\nAre you ready to give focused meditation a try? Below is a step-by-step outline to help get you started.\nBefore the Meditation\nIn order to prepare for a focused meditation, be sure that you are in a calm environment, as it will be more difficult to practise focused meditation in loud or over-stimulating surroundings.\nRemove any distractions, such as the sound of the television, and switch your phone to silent. Wear comfortable clothing to encourage relaxation.\nDuring the Meditation\n1. Select a focus object.\nMany practitioners suggest starting with your breath as your initial focus object. If you would like to focus on something external, you can select a candle flame or a sound bowl. You can choose anything that engages your senses.\n2. Sit or lay in a comfortable position.\nIf you choose to sit for your meditation, you can sit on the floor or on the edge of a chair. Keep your back straight to maintain posture. Rest your hands wherever they naturally fall and feel comfortable. If you prefer to lay down, you can do this as well. Just be sure that you don't try this when you are feeling extra tired, or you may run the risk of falling asleep mid-meditation!\n3. Relax your body.\nOnce you find yourself in a comfortable position either sitting or laying down, close your eyes. Do a brief body scan to relax the muscles in your body. Start from the top of your body and work your way down, observing each body part, such as your arms and fingers, and releasing any tension you may feel. Drop your shoulders if they are raised and drop your tongue from the roof of your mouth. Do this for your entire body.\n4. Begin to focus.\nNow, we begin the focused aspect of the meditation. Let’s say you’ve decided to use your breath as your focus object. During the experience, you are observing your breath, how it feels when the air flows in through your nose, and how it feels when the air flows out of your nose. You can observe that your stomach rises and falls with each breath, that your chest rises and falls in the same fashion. It is important to not think about your breathing, but to simply be present and observe it.\n5. Let your thoughts pass.\nWhilst focusing on your breathing, you’ll undeniably begin to think about what you should eat for dinner tonight. Or maybe you’ll think about work, and an upcoming deadline that you have. This is completely normal! It isn’t easy to still the mind, even if there is a focus object involved. Thoughts will flow into your mind, and the important thing to do here is to acknowledge that that have happened. Acknowledging that you are experiencing a thought is a massive step, as it indicates that you’re practising mindfulness. Once you’ve observed the thought, let it go. You can place the thought on a cloud and watch it float away, and then continue to focus on your breathing. It is important to not feel resistance to thoughts coming in and out of your mind, but rather to acknowledge them, accept them, let them go, and continue focusing.\nAfter the Meditation\nGently move your upper body, and then gently move your lower body. Gradually transition from an inward focus to an outward focus. Mindfully pay attention to how you feel after the meditation. Do you feel calmer? More relaxed?\nWhile in this state, take time to reflect on what the experience of focused meditation was like.\nWas it difficult to maintain focus? Was it easier than you imagined? What kinds of thoughts were coming in?\nWhether you practised for 3 minutes, 10 minutes, or 30 minutes, you should commend yourself for doing it. The mind is like a muscle, and it will become easier to focus for longer intervals of time as you practise more.\nAdditional Tips for Practising Focused Meditation\n- Begin with short sessions. Instead of diving in headfirst and trying to practise focused meditation for 30 minutes on the first go, try to practise it for 5 minutes instead. It is important to start with shorter sessions so as to not overwhelm yourself. Small steps are key when developing a long-term, enjoyable and sustainable meditation practice.\n- Find a time of day that works best for you. Some people choose to practise meditation first thing in the morning before work or school. This helps set them up for the day with a clear and grounded mind. Others choose to practise at night in order to wind down and relax after a busy day. You can even have a pop-up, 5-minute focused meditation session in the middle of a hectic work day to re-center and slow down internally. This is one of the many positive benefits of focused meditation - it is completely flexible based upon you and your needs!\n- Be gracious with yourself. Developing the meditation muscle takes time and practise. Don’t beat yourself up for having those thoughts coming in and out (just keep putting them on clouds!), and don’t beat yourself up if you’re having trouble focusing. The whole point is to use this form of meditation to develop that ability, among so many other things as we’ve discussed. Start with short sessions and a schedule that is feasible for you, feels realistic to maintain, and doesn’t feel overwhelming. Always give yourself loving words of positive encouragement after a session, even if you feel you couldn’t keep focus for more than a few seconds. It truly does get easier! You will be able to practise focused meditation for longer intervals and longer periods of time as long as you keep practising.\nSources for Accessing This Meditation Practise\nOur Recoverlution Wellness hub is dedicated to increasing your wellbeing and offers many methods of mindfulness, breath work and meditation for you to use.\nRemember, the beauty of focused meditation is that you can practise anywhere at any time, and it doesn’t have to be guided. As always, Recoverlution is here to help if you have any questions!\nAuthor - Thurga\n- How To Start A Focused Meditation Practise - https://www.verywellmind.com/practice-focused-meditation-3144785\n- Science Direct - Effectiveness of Focused Meditation for Patients With Chronic Low Back Pain - https://www.sciencedirect.com/science/article/abs/pii/S0965229916300358\n- Science Direct - The Effect of a 6-week Focused Meditation Training on Depression and Anxiety Symptoms in Brazilian University Students with 6 and 12 months of Follow Up - https://www.sciencedirect.com/science/article/abs/pii/S0165032718310498\n- Mindfulness Meditation and Addiction - https://www.psychologytoday.com/us/blog/the-wise-open-mind/201004/mindfulness-meditation-addiction"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"}],"document_ids":["<urn:uuid:9b629681-71a0-4d2e-ad04-7e2cc14dab26>","<urn:uuid:6e58479b-65c0-472d-aea1-855a29303e40>"],"error":null}
{"question":"Could you explain how both the Genazzano fresco and Fra Angelico's works bridge medieval and Renaissance artistic styles? ✨","answer":"The Genazzano fresco, created between 1417-1431, represents the post-Gothic but pre-Renaissance period of Italian art, showing the transition between these eras. Similarly, Fra Angelico's work specifically combined the religious style of the Middle Ages with Renaissance innovations in representation, serving as an important link between the first and later generations of Renaissance painting in Florence. Both artists worked during this crucial transitional period in Italian art history.","context":["In the Augustinian world, the hill town of Genazzano, about an hour from Rome by car, is well known. The Order of Saint Augustine came there not long before the year 1274. The church at Genazzano, where the Order of Saint Augustine has served since 1356, is most famous for a small fresco of the infant Jesus and his mother.\nThe fresco (pictured below) gives Mary the title of the Mother of Good Counsel. The image below is a fairly accurate copy of the fresco and its decorative jewelry. It is the most famous fresco in Augustinian possession. The Christ Child nestles close to his mother. Mary supports Jesus with her left arm. She bends her head toward him, and their cheeks touch tenderly. The left hand of Jesus gently grasps the rim of her dress, indicating the intimacy of nursing. Measuring approximately 15.5 inches by 17.5 inches, the fresco is executed on a thin layer of plaster or porcelain not much thicker than paper. One writer describes it as a fresco painted on a material resembling egg shell.\nWhen restoration of the church was undertaken in 1957, scientific tests established that the fresco was probably painted sometime between 1417 and 1431 by the Italian artist, Gentile de Fabriano. It appears to have been part of a larger fresco that covered most of the church wall. An earlier legend that reported the fresco being discovered – or miraculously \"appearing\" – in 1467 to a local widow named Petruccia de Geneo can be explained by the likely case of the fresco having had paint or plaster placed over it previously. That the appearance of the fresco in 1467 was \"miraculous\" was promoted by the Provincial of the Augustinian Roman Province at that time. He was Ambrose Massari da Cori O.S.A., who stated in his book, Chronica, in 1482 that the fresco had been carried by angels to Genazzano from Scutari in Albania.\nWhat is certain, however, is that the fresco immediately began to be a focus for pilgrims devoted to Mary in central Italy. This Augustinian church became one of the most popular Marian sanctuaries in central Italy, and remains so right up to the present day. Pope Urban VIII visited the Genazzano sanctuary in 1630, and in 1779 Pope Pius VI approved a Mass and Divine Office for the feast of the Mother of Good Counsel. The devotion of Leo XIII (Pope from 1878 to 1903) to Mary under the title of Mother of Good Counsel has become proverbial especially because of his words, saying of that pontiff: \"Children, follow her counsels.\"\nPhoto (at right) :Virgin and Child, a known work of Anthony Vivarini (see text above). It bears some resemblance to the Genazzano fresco. One of the famous pictures of Pope Leo XIII is the one taken beneath a picture of Our Mother of Good Counsel. Whence came the Pope's devotion to the Mother of Good Counsel? Perhaps it was through his Augustinian confessor, the Papal Sacristan, Bishop William Pifferi O.S.A., himself an ardent apostle of this Marian devotion. We may sum up the devotion of Leo XIII to the Augustinian Madonna by quoting from the Decree of 22nd April 1903, which announced the inclusion of the invocation to Our Mother of Good Counsel in the Litany of Loreto:\n\"... Likewise, with the Apostolic See approving, the Blessed Virgin Mary has been saluted with the title Mother of Good Counsel from ancient times both by clergy and Christian laity, asking for her aid. Our Holy Father Pope Leo XIII, on account of his own, and on account of the singular piety of the faithful towards Our Mother of Good Counsel and her Sacred Image which is particularly cherished at the sanctuary at Genazzano, after he had conceded through the Sacred Congregation of Rites a new Office with a Mass for the feast in 1884, in the year 1893 he also granted a proper Scapular with indulgences; and at the turn of this year 1903, he also erected through Apostolic Letters in the form of a Brief , the Sanctuary at Genazzano to the grade of Minor Basilica with all the privileges of such a rank, having previously enlarged the guest house there from his own money.\"\n\"Finally, this same pontiff, in order that the aforementioned title may increase the honour and cult of the Blessed Virgin, having consulted the Sacred Congregation of Rites, has stated and decreed that in the Litany of the Blessed Virgin Mary, after the invocation Mother Most Admirable, there be added Mother of Good Counsel, Pray for us. Moved also by this thought, and by the firm hope that in so many trials and calamities of these days, Our Lady, who is called by the Fathers the treasury of heavenly graces and universal counsellor, petitioned by the whole Catholic world under this title, may show herself to be our Mother of Good counsel, and may she obtain for us that grace of the Holy spirit, which will illumine our senses and our hearts, and may she obtain for us the holy gift of Counsel.\"\nWith the Pope himself thus expressing his devotion to the Augustinian Madonna, it was only natural that the Order should show its appreciation by greater devotion to the Mother of Good Counsel. Pamphlets, books and periodicals in Italian, Spanish, Belgian, German and English began to appear under Augustinian auspices.\nAmong the poems of the Pope Leo XIII was found this one to the Mother of Good Counsel:\nTHE PRAYER OF JULIUS (1895)\nMother, I called thee from my childhood hour,\nWith Prayer and hymn I besought thy power,\nA youth, I felt alas the olden fire,\nCool in the midst of rash desires.\nBut thou art faithful: help thy erring child\nThou “Mother of Good Counsel” styled – Leo XIII\nA subsequent intense artistic scrutiny of the fresco led to the discovery of what appeared to be an artist’s name disguised on the edge of the dress of the Infant, which seemed to be A. VIVA…. – FECIT, written upside down. By proposing the letters that were unable to be read, this was interpreted to be A. VIVARINI – FECIT, which is Latin for A. Vivarini made this. Anthony Vivarini (born 1410-1415, died c.1476) was a Venetian painter. He was a master of the Veronese school of art in the first half of the fifteenth century. Nothing is known about Vivarini before he became famous in 1440, hence his painting the Genazzano fresco before 1440 is feasible.\nArt experts agree that the style of the fresco is that of Italian art of that post-Gothic but pre-Renaissance period and, furthermore, could be an early work of Vivarini. Two of his earliest-known works are from the year 1441, and are at the Galleria dell’Academia in Venice. One of them is called Virgin and Child, and is reproduced (at top right). It bears some resemblance to the Genazzano fresco. Another of Vivarini's works of 1414 is The Marriage of St Monica.Photo GalleryFor the Augnet gallery on the Augustinian history of Genazzano, click here.\nNUESTRA SEÑORA DEL BUEN CONSEJO. Mucho antes de la venida de Cristo, el pequeño pueblo de Genazzano, a treinta millas de Roma, construyó un templo a Venus, la diosa pagana del amor, a la que le tenían particular adhesión. Allí se le ofrecía culto y celebraban grandes fiestas en su honor, especialmente el 25 de abril. http://www.corazones.org/maria/buen_consejo.htm\nThe Catholic Travel Guide. The town of Genazzano is home to the original fresco of Mary, the Mother of Good Counsel. http://www.thecatholictravelguide.com/ItalyGenazzanoOurLadyofGoodCounsel.html\nGood Counsel church and shrine. Website to Commune de Genazzano. Contains large photographs of the town, the church inside and out, and the Good Counsel fresco. http://www.turismoqr.it/genazzano/6.html\nFerdinand Gregorovius' Walks. Genazzano is just a few miles after Palestrina and Gregorovius on seeing it from Via Labicana has the impression to watch a procession as if the houses were moving towards the castle of the Colonna on the top of the hill. Genazzano has only one gate: it has some resemblance with those of Palestrina…… This attractive web site is a tourist guide that covers Genazzano photographically, including the Augustinian Shrine to the Mother of Good Counsel. http://www.romeartlover.it/Genazza.html\nA Trip to Genazzano. A pilgrim’s visit to the Church and Shire of the Mother of Good Counsel in April 2007. Therein are good photos of the exterior and interior of the church. http://depianteinrome.blogspot.com/2007_04_01_archive.html\nThe Shrine of the Mother of Good Counsel. During a restoration of the church begun in 1957, however, scientific tests gave evidence of the true origins of the small fresco. It was probably painted sometime between 1417 and 1431 by the Italian artist Gentile de Fabriano. It appears to have been part of a larger fresco that covered most of the church wall. From the web site of the Midwest Augustinians in the United States of America.http://midwestaugustinians.org/our-mother-of-good-counsel Il Santuario della Madonna del Buon Consiglio di Genazzano. (You Tube: 4 minutes 2 seconds) https://www.youtube.com/watch?v=wfCdHH2TdVw AN4229","Fra Angelico Biography\nBorn: c. 1400\nDied: c. 1455\nItalian painter and artist\nThe Italian painter Fra Angelico combined the religious style of the Middle Ages (a period in European history from around 500 to around 1500) with the Renaissance's (a period of revived interest\nNot much is known about Fra Angelico's early life. He was born around 1400 and was named Guido di Pietro. Around 1418 he and his brother Benedetto took vows to become monks in the Order of Dominican Preachers in Fiesole, Italy, near Florence. Fra Angelico's religious name was Fra Giovanni da Fiesole. The titles Fra Angelico and Beato Angelico came into use only after his death, as a way of honoring his religious life and work.\nIn the early 1420s Fra Angelico and Fra Benedetto began operating a painter's workshop and a room for copying documents in Fiesole. Many of Fra Angelico's early works were created at the monastery (a house for persons who have taken religious vows) of San Domenico in Fiesole. The Annunciation of about 1430 and the Linaiuoli Altarpiece (Madonna of the Linen Guild) reveal the directions of Fra Angelico's art. His gentle people are modeled in chiaroscuro (the arrangement or treatment of light and dark parts), and these saints and angels stand out from the rest of the picture. Numerous large altar-pieces (works of art that decorate the space above and behind an altar) were ordered from Fra Angelico and his popular shop in the 1430s.\nFrom 1438 to 1445 Fra Angelico worked on frescoes (paintings done on moist plaster with water-based colors) and altar-pieces for the Dominican monastery of San Marco in Florence. The church and monks' quarters were newly rebuilt at this time under the supervision of Cosimo de' Medici, with Michelozzo as architect for the project. The frescoes by the master and his assistants were placed throughout the corridors, chapter house, and rooms. In the midst of the traditional subjects from the life of Christ, figures of Dominican saints meditate (focus all their thoughts) upon the sacred events. At the same time the dramatic effect is increased by the inclusion of architectural details of San Marco itself in some of the scenes.\nA masterpiece of panel painting created at the same time as the San Marco project was the Deposition altarpiece, requested by the Strozzi family for the Church of Sta Trinita. The richly colored and shining figures, the wide views of the Tuscan landscape serving as a backdrop to Calvary, and the division into sacred and nonreligious people reveal Fra Angelico as an artist in tune with the ideas and methods of the Renaissance. Yet all of the accomplishments in representation do not lessen the air of religious happiness.\nThe final decade of Fra Angelico's life was spent mainly in Rome (c. 1445–49 and c. 1453–55), with three years in Florence (c. 1450–52), as prior (second in command of a monastery) of San Domenico at Fiesole. His main surviving works from these final years are the frescoes of scenes from the lives of Saints Lawrence and Stephen in the Chapel of Pope Nicholas V in the Vatican, Rome. The dramatic figure groupings serve to sum up the highlights of the long tradition of fourteenth-and early fifteenth-century Florentine fresco painting. In the strict construction and rich detail of the architectural backgrounds, the dignity and luxury of a Roman setting are shown.\nIn spite of the fact that Fra Angelico's life unfolded in a monastic environment, his art stands as an important link between the first and later generations of Renaissance painting in Florence.\nFor More Information\nPope-Hennessy, John. Fra Angelico. 2nd ed. Ithaca, NY: Cornell University Press, 1974.\nSpike, John T. Fra Angelico. New York: Abbeville Press, 1996."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"}],"document_ids":["<urn:uuid:dccdd6ee-97b3-418e-9d8b-39218ef6ecbb>","<urn:uuid:89fa9c40-2805-45a2-94e1-5c4d04b3222f>"],"error":null}
{"question":"Are the catalytic reactions in glycolysis and ATP synthase both driven by phosphate transfers?","answer":"No, while glycolysis relies on direct phosphate transfers (substrate-level phosphorylation) to produce ATP, ATP synthase uses a completely different mechanism. In glycolysis, phosphate groups are directly transferred from high-energy intermediates to ADP through enzymes like phosphoglycerate kinase. In contrast, ATP synthase uses mechanical rotation powered by proton flow to drive conformational changes in its beta subunits, which then catalyze ATP synthesis from ADP and Pi. The rotation mechanism of ATP synthase represents a unique form of energy coupling distinct from simple phosphate transfers.","context":["The dephosphorylation of adenosine triphosphate (ATP) provides energy for many biochemical reactions. ATP is primarily produced by the enzyme ATP Synthase (ADP + Pi ---> ATP). F-ATP Synthases are found in the inner mitochondrial membranes and the chloroplast thylakoid membranes of eukaryotes, as well as in prokaryotic plasma membranes. ATP synthases are an ancient family of proteins that are highly conserved throughout all kingdoms of life. ATP Synthase functions similarly to the turbines of hydroelectric plants that utilize the kinetic energy of water that flows through dams. In this analogy, a proton gradient is likened to dammed water, and the flow of protons down the gradient is like water driving the turbines of a hydroelectric engine. Like hydroelectric turbines, ATP synthase components rotate in response to the proton flow, and this rotational energy is then coupled to ATP synthesis. These amazing enzymes thus function as molecular engines that harness the energy derived from proton flow to drive phosphorylation of ADP, producing ATP that can be utilized by any number of enzymes to facilitate catalysis of particular biochemical reactions.\nThe F-ATP Synthase includes the Fo rotary motor complex embedded in the membrane, the F1 catalytic complex that synthesizes ATP, and a Stator that connects them and which prevents rotation of the catalytic subunits. The central stalk (axle) is considered part of F1, and its rotation is coupled to that of the membrane rotor (see Figure 1). The Fo rotor spins in response to proton (H+) flow down a concentration gradient across the membrane. This rotation causes the central stalk (axle) to rotate, altering the conformation of components of the F1 base, driving the synthesis of ATP. The synthase can also act as an H+ pump ATPase when its rotations are reversed by ATP hydrolysis.\nShown at left is a partial structure of yeast mitochondrial ATP Synthase with orientation, arrows, and labels corresponding to those of Figure 1 (Dautant, et al., 2010, unpublished -see PDB entry 2WPD). The elegant structure of this molecule allows it to perform its remarkable functions. To understand the functional details linking proton flow, rotation of Fo, and synthesis of ATP by F1, it will be useful to consider the Fo and F1 complexes individually, using the structure of bacterial (E. coli) complexes of Fo as determined by Rastogi and Girvin (1999) and the structure of bovine F1 complexes as determined by Gibbons et al. (2000).\nII. Fo Structure and Function Links Proton Flow to the Fo Rotor\nIn bacteria, the Fo complex contains the subunits a, b and c, in a ratio of 1a:2b:c10-15. The number of c subunits are fixed within a species, but are variable among different species.\nNote: Unless otherwise stated, in the following representations the Fo complex will be either be oriented as in Figure 1, above (sideview), or in a top down view (above the membrane), looking through the Fo channel towards the central stalk and F1 complex.\nIn E. coli, Fo consists of an a subunit, a b Stator unit (not shown), and a ring of 12 identical c subunits. The c ring of Fo rotates, while the other components of the complex do not.\nEach c subunit is a helix-loop-helix, comprising a C-terminal alpha helix and an N-terminal helix. These two helices each span the membrane. Each C-terminal helix contains the important acidic amino acid, Aspartate 61. This residue's sidechain, capable of protonation and deprotonation, plays a major role in the rotation of the c ring. As can be seen, only two of the c ring's C-terminal alpha helices are in close proximity to the a subunit at any one time. These features are important and will be discussed below.\nThe a subunit contains 4 helices. The helix closest to the c ring contains the basic amino acid, Arginine 210. The sidechain of Arg 210 and other residues provide a hydorophillic environment that promotes the deprotenation of Asp 61 as its helix rotates to contact the a subunit. Note: in this top down view, rotation of the c ring is in the clockwise direction. Deprotenation of Asp 61 causes a profound change in the conformation of the C-terminal helix of the deprotonated subunit: it twists along its axis ~140o relative to the N-terminal helix.\nThe twisting of the C terminal helix in response to deprotenation of Asp 61 can be visualized in a morphed simulation using single NMR structures of protonated and deprotonated c subunits (Rastogi and Girvin,1999) as starting and ending points.This PDB file for this simulation was generated using the Yale Morph Server at the Database of Macromolecular Movements, maintained by the Gerstein lab.\nThe twisting of the C terminal helix just described suggests a model in which local rotation of a single c subunit is a major physical force that spins the entire ring, as in a \"wheels within wheels\" type of mechanism (Rastogi and Girvin,1999). This rotational process of Fo can be visualized in an animation provided by the Girven lab.\nIt is now useful to consider the protonation state of the 12 c subunits in the c ring of Fo. As can be seen, only the Asp 61 of the C-terminal helix that has just rotated into the vicinity of the a subunit's Arginine 210 is in a deprotonated state. The remaining 11 Asp 61s in the other C-terminal helices are protonated. Careful inspection shows that only theC-terminal helix containing the deprotonated Asp 61 is in the twisted (deprotonated) conformation. This has an important consequence for the directional rotation of the c ring. Since the deprotonated Asp 61 is negatively charged, counterclockwise rotation of the c ring is thermodynamically unfavorable, since this would place the deprotonated Asp 61 in the hydrophobic environment of the membrane. Clockwise rotation of the ring is favored, however, as the Asp 61 would still be in the hydrophillic vicinity of Arg 210 and other residues of the a subunit.This position allows it to be reprotonated and enter the membrane environment as the c ring spins in the clockwise direction.\nNote that as the Fo c ring rotates, the Fo a subunit remains stationary.\nA side view through a translucently rendered a subunit shows its association with the C-terminal helix containing the deprotonated Asp 61 and the C-terminal helix containing the newly reprotonated Asp 61. The the remaining C-terminal helices are exposed to the hydrophobic membrane. The Arg 210 of the a subunit is seen to reside btween the deprotonated and reprotonated Aspartates.\nThe structure of Fo facilitates the flow of H+ ions down the proton concentration gradient by providing two half-channels for this flow, an entry and an exit channel. These can be visualized in a side view of the c ring through the translucently rendered a subunit:\nThe elegant mechanism for converting the electrical energy of the proton gradient into rotary (kinetic) energy of c ring spinning may be summarized by following the journey of a proton as it flows across the membrane through Fo:\nThe E. coli Fo c ring just described has 12 c subunits. Thus, each proton that moves through Fo rotates the ring in 30o steps relative to the stationary components of ATP synthase (12 c's x 30o = 360o).\nIn the next section we will consider how the rotary motion of the Fo c ring powers ATP synthesis in the F1 complex.\nIII. F1 Structure and Function\nShown at left is the F1 complex of the F-ATP synthase from bovine heart mitochondria, oriented with the top pointing toward the membrane bound Fo complex described above (not shown). Also shown is the central stalk (axle), which is linked to the Fo c ring above, and which therefore rotates with that ring. The catalytic F1 complex lies below the central stalk. Unlike the stalk, the catalytic complex is fixed and is prevented from rotating by its binding to the Stator mentioned previously (not shown), which connects to the stationary Fo a subunit (see Figure 1).\nThe central stalk contains the gamma, delta, and epsilon subunits. The catalytic complex is a hexamer alternately packed with three alpha subunits and three beta subunits. Although all subunits of the catalytic complex bind to nucleotides, only the beta subunits are capable of catalyzing the phosphorylation of ADP to produce ATP. The gamma subunit of the stalk is observed to penetrate deep within the catalytic complex, where it engages the beta subunits.\nKeeping in mind the structural features of F1 just presented, it is now possible to understand the Binding-Change Model that explains how the rotational energy of the central stalk is transduced into the production of ATP. In this model, the gamma subunit of the central stalk sequentially engages the beta subunits of F1 as it rotates in sync with the Fo rotor. This interaction induces conformational changes that drive the release of ATP from these catalytic subunits. Each stationary beta subunit transitions between three conformations.\nThe three conformers of the beta subunits are LOOSE, TIGHT, and OPEN and each beta subunit cycles sequentially between them (L --> T--> O), the cycles being orchestrated by the rotating gamma subunit of the central stalk. The LOOSE conformation permits the loose binding of ADP and Pi substrates, but ATP catalysis does not occur until the beta subunit transitions to the TIGHT conformation. The TIGHT conformation produces ATP (ADP + Pi ---> ATP) but is incapable of releasing this catalytic product. Only when the TIGHT to OPEN conformational change is induced can the beta subunit release ATP. The perspective here is from the bottom of the ATP Synthase, looking up toward the membrane. In this bottom-up view, the rotation of the central stalk gamma subunit is counterclockwise. With each rotation of 120o, the gamma subunit engages a stationary beta catalytic subunit, changing its conformational state as described. The result is the production and release of ATP by F1.\nRemembering that each 360o rotation of the Fo rotor is linked to a 360o rotation of the central stalk, a simple calculation reveals the stoichiometry of H+ translocation through Fo and ATP production by F1. If there are 12 c subunits in the c ring of Fo (each carrying a proton), and each 360o rotation of the gamma subunit of the central stalk produces 3 ATPs (one for each F1 beta subunit), then the transport of 4 protons are required to generate every ATP (12 protons/rotation of the c ring rotor / 3 ATPs/rotation of the central stalk). Of course, this ratio depends upon the number of c subunits in the Fo rotor, which can vary depending on the ATP Synthase under consideration.\nClearly, understanding the structure-function relationships of ATP Synthase gives one a deep appreciation of the power of natural selection in fashioning amazing biomolecular machines!\nGibbons, C.; et. All. The Structure of the Central Stock in Bovine F1-ATPase at 2.4 Å resolution. Nature Structural Biology. 2000 Nov;7(11):1002-4.\nRastogi, V.K.; Girvin, M. Structural Changes Linked to Proton translocation by Subunit C of the ATP Synthase. Nature. 1999 Nov 18;402(6759):247, 249.\nLeslie, A.G and Walker, J.E.. Molecular architecture of the\nrotary motor in ATP synthase. Science. 1999 Nov 26;286(5445):1700-5.\nThe format of this web page is modified from a template provided by Dr.\nAngel Herraez, Bioquimica y Biologia Molecular, Universidad de Alcala, E-28871,\nAlcala de Henares (Madrid), Spain.","Cytochromes carry electron carrier molecules (NADH & FADH2) down to oxygen\nChemiosmosis : energy coupling mechanism\nATP synthase : produces ATP by using the H+ gradient (proton-motive force) pumped into the inner membrane space from the electron transport chain; this enzyme harnesses the flow of H+ back into the matrix to phosphorylate ADP to ATP (oxidative phosphorylation)\nGlycolysis: 2 ATP (substrate-level phosphorylation)\nKreb’s Cycle: 2 ATP (substrate-level phosphorylation)\nElectron transport & oxidative phosphorylation: 2 NADH (glycolysis) = 6ATP 2 NADH (acetyl CoA) = 6ATP 6 NADH (Kreb’s) = 18 ATP\n2 FADH2 (Kreb’s) = 4 ATP\n38 TOTAL ATP/glucose\n4 stages of aerobic respiration Stage 1: Glycolysis Stage 2: Formation of Acetyl coenzyme A Stage 3: The Citric Acid Cycle Stage 4: Electron transport chain\nA Road Map for Cellular Respiration Cytosol Mitochondrion High-energy electrons carried by NADH High-energy electrons carried mainly by NADH Glycolysis Glucose 2 Pyruvic acid Krebs Cycle Electron Transport\nGLYCOLYSIS Glucose ATP hexokinase ADP Glucose 6-phosphate p hosphogluco- i somerase Fructose 6-phosphate ATP phosphofructokinase ADP Fructose 1,6- bis phosphate aldolase triose phosphate isomerase Dihydroxyacetone Glyceraldehyde phosphate 3-phosphate\nGlyceraldehyde 3-phosphate glyceraldehyde NAD + + P i 3-phosphate NADH + H + dehydrogenase 1,3- Bis phosphoglycerate ADP phosphoglycerate kinase ATP 3-Phosphoglycerate phosphoglyceromutase 2-Phosphoglycerate enolase H 2 O Phospho enol pyruvate ADP pyruvate kinase ATP Pyruvate\nGlycolysis: stage 1 The three steps of stage 1 begin with the phosphorylation of glucose by hexokinase Energy used, none extracted\nATP ADP glucose glucose 6-phosphate ∆ G o = -16.7 kJ/mole Step 1: Adding a phosphate Enzyme: hexokinase\nPhosphoryl transfer reaction. Kinases transfer phosphate from ATP to an acceptor. Hexokinase has a more general specificity in that it can transfer phosphate to other sugars such as mannose. Δ G°’= -4.0 kcal mol-1\nGlucose phosphorylation: step 1 Glucose is a relatively stable molecule and is not easily broken down. The phosphoylated sugar is less stable. ATP serves as both source of phosphate and energy needed to add phosphate group to the molecule.\nInduced fit in hexokinase Conformation Changes on binding glucose, the two lobes of the enzyme come together and Surround the substrate\nStep 2: Isomerization glucose 6-phosphate fructose 6-phophate aldose to ketose isomerization reversible, G°´= 1.7 kJ/mole 6 carbon ring 5 carbon ring Enzyme: phosphoglucoisomerase\nThe conversion of an aldose to a ketose . Phosphoglucose Isomerase Δ G°’= .40 kcal mol-1\nFormation of fructose-6-phosphate: step 2 by phosphoglucose isomerase The enzyme opens the ring, catalyzes the isomerization, and promotes the closure of the five member ring.\nfructose 1,6 bisphosphate ATP ADP fructose 6-phosphate Enzyme: phosphofructokinase\nPhosphofructokinase-1 PFK Δ G°’= -3.4 kcal mol -1 The 2 nd investment of an ATP in glycolysis. Bis means two phosphate groups on two different carbon atoms. Di means two phosphate groups linked together on the same carbon atom. PFK is an important allosteric enzyme regulating the rate of glucose catabolism and plays a role in integrating metabolism.\nFormation of fructose 1,6-bisphosphate: step 3 by phosphofructokinase (PFK): an allosteric enzyme that regulates the pace of glycolysis.\nControl of Enzyme Activity by Non-Covalent Modifiers is usually called allosteric regulation since the modifier binds to the enzyme at a site other than the active site but alters the shape of the active site. Allosteric is a word derived from two Greek words: 'allo' meaning other and 'steric' meaning place or site; so allosteric means other site and an 'allosteric enzyme' is one with two binding sites - one for the substrate and one for the allosteric modifier molecule, which is not changed by the enzyme so it is not a substrate. The molecule binding at the allosteric site is not called an inhibitor because it does not necessarily have to cause inhibition - so they are called modifiers. A negative allosteric modifier will cause the enzyme to have less activity, while a positive allosteric modifier will cause the enzyme to be more active. In order for allosteric regulation to work, the enzyme must be multimeric (ie. a dimer, trimer, tetramer etc.). The concept is easily illustrated using a dimer as the model system, but it applies equally well to higher order multimers such as trimers and tetramers, etc.\nGlycolysis: stage 2 Two 3-carbon fragments are produced from one 6-carbon sugar No energy used or extracted\nStep 4: Cleavage to two triose phosphates Reverse aldol condensation ; converts a 6 carbon atom sugar to 2 molecules, each containing 3 carbon atoms. Enzyme: aldolase\nAn Aldol condensation is an organic reaction in which an enolate ion reacts with a carbonyl compound to form a β-hydroxyaldehyde or β-hydroxyketone, followed by dehydration to give a conjugated enone .\nAldol condensations are important in organic synthesis , providing a good way to form carbon– carbon bonds . The Robinson annulation reaction sequence features an aldol condensation; the Wieland-Miescher ketone product is an important starting material for many organic syntheses. Aldol condensations are also commonly discussed in university level organic chemistry classes as a good bond-forming reaction that demonstrates important reaction mechanisms . In its usual form, it involves the nucleophilic addition of a ketone enolate to an aldehyde to form a β-hydroxy ketone, or \" aldol \" ( ald ehyde + alcoh ol ), a structural unit found in many naturally occurring molecules and pharmaceuticals.\nEnol: An organic compound containing a hydroxyl group bonded to a carbon atom, which in turn is doubly bonded to another carbon atom.\nStep 6: Formation of 1,3-Bisphosphoglycerate Done in two steps glyceraldehyde 3-phosphate 1,3 bisphosphoglycerate Enzyme: glyceraldehyde-3-phosphate dehydrogenase addition of phosphate, oxidation, production of NADH, formation of high energy compound\nThe fate of glyceraldehyde 3-phosphate Stage 3: The energy yielding phase. Glyceraldehyde 3-phosphate DH Δ G°’ = 1.5 kcal mol -1 1,3-BPG has a high phosphoryl-transfer potential. It is a mixed anhydride. An aldehyde is oxidized to carboxylic acid and inorganic phosphate is transferred to form acyl-phosphate. NAD + is reduced to NADH. Notice, under anaerobic conditions NAD + must be re-supplied.\nGlyceraldehyde 3-phosphate dehydrogenase Active site configuration\nStep 7: Transfer of phosphate to make ATP Formation of ATP from 1,3-Bisphosphoglycerate: Enzyme: phosphoglycerate kinase first substrate level phosphorylation, yielding ATP 2 1,3 bis PG yield 2 ATPs, thus ATP yield = ATP input high free energy yield, G°´= -18.8kJ/mole drives several of the previous steps\n7: Phosphoglycerate Kinase Substrate-level phosphorylation Δ G°’ = -4.5 kcal mol -1 ATP is produced from P i and ADP at the expense of carbon oxidation from the glyceraldehyde 3-phosphate DH reaction. Remember: 2 molecules of ATP are produced per glucose. At this point 2ATPs were invested and 2ATPs are produced.\nStep 9: Removal of Water leadsto formation of double bond little energy change in this reaction, ΔG = + 1.7 kJ/mole because the energy is locked into enolphosphate. Phosphate group attached by unstable bond, therefore high energy Enzyme: enolase\nGeneration of second very high energy compound by a dehydration reaction Enolase Δ G°’ = .4 kcal mol -1 Dehydration reaction PEP the energy is locked into the high energy unfavorable enol configuration by phosphoric acid ester\nAn enol phosphate is formed: step 9 Dehydration elevates the transfer potential of the phosphoryl group, which traps the molecule in an unstable enol form Enol: molecule with hydroxyl group next to double bond\nStep 10: Formation of Pyruvate & ATP Enzyme: pyruvate kinase phosphoenolpyruvate pyruvate second substrate level phosphorylation yielding ATP highly exergonic reaction, irreversible , ΔG = -31.4 kJ/mole.\nThe Conversion of Glucose to Pyruvate Glucose + 2 P i + 2 ADP + 2 NAD + -> 2 pyruvate + 2 ATP + 2 NADH +2 H + The Energy released from the anaerobic conversion of glucose to pyruvate is -47kcal mol -1 . Under aerobic conditions much more chemical bond energy can be extracted from pyruvate. The question still remains: How is NAD + supplied under anaerobic conditions? Or how is redox balance maintained?\nUnder anaerobic conditions pyruvate is converted to lactate. Exercising muscle is an example. The NAD + that is consumed in the glyceraldehyde 3-phosphate reaction is produced in the lactate DH reaction. The redox balance is maintained. The activities of glyceraldehyde 3-phosphate DH and Lactate DH are linked metabolically. What happens to the lactate after a run?\nIn anaerobic yeast, pyruvate->ethanol Pyruvate is decarboxylated. Acetaldehyde is reduced.\nVariations on a theme in alcoholic fermentation. Here also, there is no net oxidation reduction.\nEnzyme Classification Dehydrogenase - oxidizes substrate using cofactors as electron acceptor or donor (pyruvate dehydrogenase) Reductase- adds electrons from some reduced cofactor (enoyl ACP reductase) Kinase- phosphorylates substrate (hexokinase) Hydrolases - uses water to cleave a molecule Phosphatase- hydrolyzes phosphate esters (glucose-6-phosphatase) Esterase (lipase)- hydrolyzes esters (those that act on lipid esters are lipases) (lipoprotein lipase) Thioesterases - hydrolyzes thioesters Thiolase- uses thiol to assist in forming thioester (β-ketothiolase) Isomerases- interconversions of isomers\nElectron transport releases the energy your cells need to make the most of their ATP\nThe molecules of electron transport chains are built into the inner membranes of mitochondria\nThe chain functions as a chemical machine that uses energy released by the “fall” of electrons to pump hydrogen ions across the inner mitochondrial membrane\nThese ions store potential energy\nAdding Up the ATP from Cellular Respiration Figure 6.14 Cytosol Mitochondrion Glycolysis Glucose 2 Pyruvic acid 2 Acetyl- CoA Krebs Cycle Electron Transport by direct synthesis by direct synthesis by ATP synthase Maximum per glucose:\nFigure 6.13 Food Polysaccharides Fats Proteins Sugars Glycerol Fatty acids Amino acids Amino groups Glycolysis Acetyl- CoA Krebs Cycle Electron Transport"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"}],"document_ids":["<urn:uuid:7cb901fe-aa1f-48dc-9759-a718ed10b268>","<urn:uuid:1edd4478-bd8e-41c8-89b8-e7f9ffbc6696>"],"error":null}
{"question":"What are the main metrics borrowed from information retrieval systems that can be used to analyze top-performing assets, and what do they measure?","answer":"The main information retrieval metrics include: Point-biserial correlation coefficient (measures linear relationship between return and relevance), Precision at best N (fraction of next week's N best assets represented by this week's best asset), Average precision (average of precision values for all possible N), and Average precision at best N (average of precision values from 1 to N). These metrics are particularly useful when focusing on specific parts of the ranking rather than the entire distribution.","context":["We are rather used to reading this disclaimer (or some variation thereof) in mutual fund prospectuses or investment vehicle webpages. Despite warnings, investors and advisors insist on considering past performance (and some other related metrics) as important factors in asset selection. But, are they really wrong? In this post, I will try to shed some light on this topic by means of some metrics inspired by the information retrieval community.\nI will focus on weekly return data for current components of the DJIA (Dow Jones Industrial Average); a total of 30 stocks. More specifically, I will try to gain some insight on the joint movement of the returns by visualising how their weekly rankings have historically evolved.\nThis would answer questions such as: what is the probability that past week’s best-performing asset turns out to be this week’s best-performing one? Or, more generally, what is the probability that the i-th best-performing assets turns into this week’s j-th best-performing one? This information is depicted in the following Hinton diagram where the area of each square reflects this probability:\nIf we take a close look at the bottom left corner,we notice that the first ranked asset one week seems to consistently be the first one during next week. This is somehow an artifact of the amazingly good performance that Apple Inc. has consistently exhibited during recent years. However, if I leave aside this fact and remove the iCompany from the sample, data tell us a different story: there does not seem to be statistically significant persistence in return rankings.\nBut wait a sec! what if we look closer?\nA traditional approach to comparing two rankings has been in using correlation-based metrics which, rephrased to fit the problem at hand, would do the following:\n- Pearson’s correlation coefficient: measures how linear the relationship between consecutive returns is.\n- Spearman’s rank correlation coefficient: measures how linear the relationship between consecutive rankings is (indeed, it’s mathematically equivalent to the Pearson’s correlation among rankings).\n- Kendall’s rank correlation coefficient (a.k.a. Kendall’s tau): counts the number of pairwise disagreements between the two ranking lists.\nIn the following picture, these metrics are applied to real returns and what I refer to as independent returns, that is, a situation in which consecutive weekly returns are statistically independent.\nNote that a remarkable difference between real returns and independent returns shows up. However, as real scores are marginally different from zero, it may be difficult to use them to carry out successful predictions.\nThe problem with this family of metrics is that they give the same importance to what’s happening in any part of the ranking. In finance, however, we usually worry about what’s going on in extreme parts of the ranking. So…\nWhat if the best-performing asset is the only relevant to you?\nIn case we only care about what happens in very specific parts of the ranking, we can think of applying metrics borrowed from information retrieval systems. Namely:\n- Point-biserial correlation coefficient: measures how linear the relationship between the return and the fact of being relevant or not is.\n- Precision at best (worst) N: fraction of next week’s N best (worst) assets represented by this week’s best (worst) asset.\n- Average precision: average of the previously described precision values for all possible N.\n- Average precision at best (worst) N: average of the previously described precision values for all possible n from 1 to N.\nWhat if the N best-performing assets are all relevant to you?\nAll the aforementioned metrics can be trivially extended to the case where several assets are considered relevant (for example, the top 5).\nOther related metrics are:\n- Recall at best (worst) N: fraction of all relevant assets that fall inside the best (worst) N positions of next week’s ranking.\n- R-precision: it may be useful in the particular case that the number of relevant assets fluctuates from case to case, due to changes in the asset universe size or assets deemed relevant if certain performance requirements are satisfied. This allows for a fair comparison among cases, and matches the precision at the number of assets that equates precision and recall.\n- F1 at best (worst) N: if we are looking for a good tradeoff between precision and recall, the F1 score will provide us with this as the harmonic mean between precision and recall. The relative importance of each can be controlled by generalising this idea in what is usually referred to as F-beta score.\n- Reciprocal rank: the inverse of the ranking position occupied by the single highest- (lowest) ranked relevant item. It is appropriate to judge a system when there’s only one relevant result, or when you only really care about the highest-ranked, even if several of them are relevant to you.\nWhat if they are not equally relevant?\nHaving multiple relevant assets opens the door to another family of metrics: those in which graded relevances are taken into consideration. This is when relevance is not binary and we want to specify multiple levels of relevance. For example, we can consider that finding this week’s best asset among the top five assets next week is twice as important as finding the second best asset among them. Such a preference can be encoded as a vector of non-binary relevances, which gives rise to a bunch of other metrics:\n- Cumulative gain at best (worst) N: accumulated relevance value among the N best (worst) assets. The computed value is unaffected by position changes among the N best (worst) assets.\n- Discounted cumulative gain at best (worst) N: the same as cumulative gain but with the additional consideration that highly relevant assets appearing lower in next week’s ranking list should be penalised. This is achieved by diminishing the relevance value logarithmically proportional to the position of the asset.\n- Normalized discounted cumulative gain at best (worst) N: again, as in the R-precision metric, when the number of relevant assets fluctuates from case to case it is useful to normalise the discounted cumulative gain with respect to its maximum achievable value. This value would be achieved only when assets are ordered according to the relevances we give to each.\nIn this example I have assumed that relevance scores go from 5 to 1 as we go from the first to the fifth asset:\nOne may also think of applying inequality-inspired metrics, borrowed from the socio-economic literature, and rooted in the concept of Lorenz curve … but that will have to wait for a different post. But if you want to know more right now, here are some pointers: Gini, Atkinson, entropy, and Theil (generalized entropy) indexes.\nAfter evaluating dozens of scores we can conclude that all of them are consistently better for real returns than for independent asset returns. Sometimes only marginally better, but they show that past performance is telling us at least a bit about the future.\nKeep in mind that this analysis has been conducted, intentionally, in some of the most difficult to predict asset classes and time horizons: stocks and one-week returns, respectively. Now it’s up to you to find out in which situation, and how, you may take advantage of this."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"sensitive"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"}],"document_ids":["<urn:uuid:891cd264-60ae-4f00-ad37-95949f1ee69e>"],"error":null}
{"question":"How do the educational paths for becoming a train control signal inspector compare to those for becoming a boilermaker?","answer":"Train control signal inspectors typically require a 4-year degree in science along with railway technology experience. In contrast, boilermakers usually need only a high school diploma followed by a 4-5 year apprenticeship program. The apprenticeship for boilermakers includes training in theoretical concepts, practical activities, welding, and plan design. While train companies provide continuous training for signal inspectors, boilermakers can also pursue additional certifications such as the NCCER Boilermaking four-level certification or AWS Certified Welder program to advance their careers.","context":["The Tasks of a Train Control and Signal Inspector\nThere is lots of work to be done behind the scenes to guarantee trains have the ability to run properly. One of the jobs with the most duty is that of a train control and signal inspector. They work hard to ensure the signals at all of the railroad crossings are working appropriately. This is to guarantee the security of those on the train as well as those attempting to cross in their path.\nRoutine upkeep and testing of all the various controls and signals for railway crossings need to be completed. Most of the time each inspector will have their own area they are responsible for. They also conduct additional testing when they receive info from the train teams, passengers in cars, or police that there may be problems with particular signals working properly.\nTrain control and signal inspectors are likewise accountable for implementing safety training and education programs for their employees and for those who will be crossing the tracks. Numerous accidents involving trains can be gotten rid of if people have the ideal details about the threats involved in not paying attention to train crossings.\nSince there are many intersections where there are signal lights but no rails that come down, people frequently aim to beat the trains. The goal of these inspectors is to remove people taking such risks. As funding becomes available they make sure the brand-new rails are set up at the most dangerous train crossings.\nIn order to base their training info on, train control and signal inspectors are often called to the scene of accidents to document their findings. All of this info is assembled to offer accurate information that can be used for intervention and prevention of future issues with train controls and signals.\nAs advances in technology permit, train control and signals are continuously updated. An inspector in this role needs to have the skills and training to keep up on this info. Many employers in the railway industry deal this continuous training, but certification in numerous locations is required in order to secure such work in the very first place.\nIn addition, someone in this function needs to remain in excellent physical condition. It can require long hours on the job in order to correct possibly dangerous scenarios and to evaluate accident scenes. It can result in long walks along stretches of railway tracks in the severe heat or cold. In some locations, the train control and signal inspector will have to climb down into bridge areas to obtain to the mechanisms they have to check or fix.\nThese types of inspectors likewise need to be detail oriented because there is plenty of paperwork to complete on a regular basis. The demands of the task can be difficult due to the fact that you truly never ever know for how long a specific task is going to take. A routine examination may develop into an all day event if things aren’t working as they should. Paying attention to the little things is crucial since lives could be lost if the inspector does not take the job seriously.\nThe role of a train control and signal inspector is extremely important. It allows various lives to be conserved by guaranteeing the ideal devices remains in location and working properly. They also provide training and education programs to make sure people understand the threats of not complying with these signals. While this kind of task is really difficult it likewise provides lots of rewards to those who wish to make trains save for everybody.\nThe rate of spend for a train control and signal inspector varies by location. It is generally an extremely high paying job though due to the fact that of the amount of threat involved in being where the trains pass and being exposed to chemicals and other items throughout derailments or train wrecks. Many train business need an inspector to have a 4 year degree in some area of science along with experience in the field of railway technology.\nWord Count 668","How to Become\nBest Education Tracks, Key Skills, and Top Certifications\nA boilermaker occupies an important position within the field of construction. These workers are indispensable to the success of any project. This career has a good job outlook and high salaries compared to other jobs.\nIf you want to learn how to become a boilermaker in 2021, this guide will show you the way. Read on for information about the job description, average salaries, educational options, and licenses needed to work as a professional boilermaker.\nWhat Is a Boilermaker?\nA boilermaker is a person in charge of everything related to boiler systems in a company, houses, shopping centers, or other construction projects. A boilermaker maintains and repairs containers that contain gases or liquids.\nIron, copper, and stainless steel boilers require manual and professional maintenance. For these jobs, a boilermaker uses his theoretical and practical skills to maintain the optimal functioning of the boiler system.\nWhat Type of School Should You Attend\nto Become a Boilermaker?\nTo work in this position, you usually need a high school diploma or its equivalent. You can then access an apprenticeship program to reinforce your knowledge and gain professional experience. For this job, you can offer private services or belong to a construction company.\nBest Boilermaker Education Tracks\nBoilermakers have intense job training. Most jobs have extended hours and require you to be in excellent physical condition. Technical training is the most common way to learn this trade, usually in an apprenticeship program rather than a trade school.\nIf you want to know about the educational options to become a boilermaker, pay attention to the points below.\nThe most common way to start your career as a boilermaker is through an apprenticeship program. This preparation requires approximately four years. During the training, you will learn theoretical concepts and practical activities for your occupation.\nYou will be taught about metals and installation techniques, welding, plan design, how to repair boilers, plus the tools and equipment required for each task, among other subjects. One of the advantages of these programs is professional experience. Currently, there are many organizations across America where you can access an apprenticeship program.\nBoilermakers Local 433 is an organization in Tampa, Florida affiliated with the Boilermakers National Apprenticeship Program (BNAP) and the International Brotherhood of Boilermakers.\nAccording to the Boilermakers Local 433 website, members pay dues of $43 each month during training. Additionally, apprentices need to meet physical standards, work full-time schedules, and be able to work in challenging environments.\nCommunity colleges offer two-year associate degrees and four-year bachelor’s degrees. However, not all community colleges offer a bachelor’s degree. You should check your preferred school to see which track you can take. Community colleges are more convenient and affordable than universities.\nSome of the best community colleges for graphic design are Nassau Community College and Waubonsee Community College. These and many other colleges offer world-class training at low prices. Tuition varies, but it will typically be less than a private university.\nThe typical way to obtain career preparation is with hands-on practice. However, many online courses offer valuable training for this profession. Both theory and critical thinking are tools for success as a boilermaker.\nIn addition, welding and blueprint reading are key skills for this profession. Journeymen and journeywomen who have taken courses in these subjects have a greater chance of succeeding in the industry.\nHow to Become a Boilermaker: A Step-by-Step Guide\nThere is no specific path to becoming a boilermaker. However, some options help you increase your chances of getting better jobs and higher wages. If you want to start your way as a boilermaker, pay attention to the five steps below.\nAssess your aptitude\nBefore choosing any career, you need to assess your chances of success. To be a boilermaker, you must be fit and strong, and be prepared to understand the health and safety aspects of the trade.\nAnalyze the market\nIf you have the profile of a boilermaker, then the next task is to assess the market and the demand for boilermaker jobs. Check the average salaries, the places where you can learn this career, and the job benefits.\nEnroll in an apprenticeship program\nThis is the principal educational requirement. In these programs, you will learn the fundamental practices of the profession. A diploma from an apprenticeship program will help you get to a company faster and be better prepared.\nGet a job\nAfter your time as an apprentice, you must get a job. Training programs connect you with your first job opportunities, but your performance will be the key to maintaining good work relationships and advancing in the industry.\nExpand your skills\nThe bigger your resume, the better your chances of being successful. The industry is extensive and requires versatile professionals with the skills to perform tasks of all kinds.\nKey Boilermaker Skills\nTo get a job opportunity in this industry, you must have a professional profile. The experience and certification help you improve your chances of achieving success as a boilermaker.\nWhat skills are most likely to get you hired as a boilermaker? Pay attention to the points below.\nStrength and physical endurance are crucial competencies for a boilermaker. A boilermaker needs optimal fitness and strength to carry heavy components to workplaces. This is one of the reasons these tasks pay out large sums of money.\nDuring your training in the apprenticeship program, you will learn the best techniques to use your strength at work correctly. This will help you avoid injuries and optimize your time.\nTraining and hands-on activities make you a boilermaker ready for any challenge. All equipment repairs, maintenance, and testing are entirely manual.\nCompanies hire professionals who work with tools such as try-squares, box levels, rulers, protractors, and contour gauges, among others. In addition, you must know general construction techniques, possess safety awareness and welding experience, and be able to drive a forklift.\nAbility to Adapt to Different Work Environments\nAs a boilermaker, your jobs will be varied. Workspaces can be high up in a building, in tight basements, boilers, and much more. You can work in very hot or cold areas, depending on the project.\nBoilermaker Salary and Job Outlook\nA 2020 Bureau of Labor Statistics (BLS) report says that a boilermaker earns an average salary of $65,360. These figures depend on the state, your level of experience, and the project. Most boilermakers are paid on the job.\nBLS also projects that the demand for boilermakers will grow one percent between 2019 and 2029, slower than other related jobs. This works out to about 1,400 new vacancies every year during the mentioned period.\nEntry-Level Boilermaker Job Requirements\nEntry-level is the standard starting position if you join a company. To get a job at this level, you must understand how to build, repair, and maintain boiler systems, and how to weld. You must also have general craft experience.\nAn apprenticeship program diploma qualifies you for an entry-level position as a professional boilermaker. According to PayScale, an average entry-level boilermaker makes about $22 per hour, which is equal to about $49,000 per year.\nWhat Does a Boilermaker Do?\nA boilermaker has several tasks on their schedule. Remember, like all jobs, your activities depend on your position, experience, and type of project. The more years you have in the company, the more functions you can take on.\nBelow we list some key responsibilities of a boilermaker.\nYour main role is to take care of a boiler system in a building, company, house, boat, or any environment that uses these machines. You must install boiler tanks using welding techniques and various kinds of work equipment.\nMonitors and Repairs Boilers\nAs a boilermaker, you have the skills to verify the operation of the boiler. You must analyze its operability, inspect for faults such as overheating, and be able to detect gas leaks. Additionally, you must apply your technical knowledge to repair these systems using the correct tools. Remember that these repairs can be in tight spaces, high areas, or outdoors.\nReading blueprints is a constant activity in this job. The plans include the location and conditions of the boiler system at the specific facility. Also, in case of a construction query, you can suggest the best place to install the boiler.\nAn apprenticeship program can be your only training before you start working as a professional. However, a certification allows you to achieve a higher status, ideal for endorsing your knowledge and skills with specialized organizations in this industry.\nBoilermaker licenses also include welding programs and related jobs. Many companies and states require employees to have these certifications. Below you will see a description of each program.\nBoilermaking Four-Level Certification\nThe National Center for Construction Education and Research (NCCER) is an organization that provides special licenses and training for workers in the construction industry in the United States.\nWith the NCCER Boilermaking four-level certification, you will become a journey-level boilermaker, qualified to work on any project with these characteristics. In the program, you will test your skills in the maintenance, exchange, and installation of industrial boilermaking.\nCertified Welder Program\nThe American Welding Society (AWS) is an organization that offers certifications for welding workers and related tasks. The Certified Welder program evaluates your performance as a welder in many areas of work, including boilermaking.\nThis credential verifies your skills in these tasks and allows you to present yourself as a professional in any company in the United States.\nHow to Prepare for Your Boilermaker Job Interview\nBefore joining a company, you must ace your job interview. In this process, the employer will evaluate your critical thinking and, above all, your practical skills as a boilermaker. Some questions may include theoretical content, but your physical condition and key aptitudes will be assessed, too.\nBoilermaker Job Interview Practice Questions\n- Why did you choose this company to work for?\n- How many types of welding can you do?\n- Can you work in harsh conditions?\n- Are you physically fit to lift heavy objects?\n- What projects have you undertaken as a boilermaker?\nHow Long Does It Take to Become a Boilermaker?\nThe time it takes to become a boilermaker depends on your effort and skills. However, an apprenticeship program can last between four and five years.\nIf you want to be a qualified boilermaker, you can apply for official credentials. The process to obtain the essential certifications can take a year. Then, when you find a job, it will take a year or two to get promoted as an official boilermaker. So, you could become an expert in approximately seven years.\nShould You Become a Boilermaker in 2021?\nYes. If you think that you have what it takes to become a boilermaker, you should take this career path. Boilermaking is not a job for everyone, but it’s a good choice if you like physically demanding jobs.\nAnother reason to be a boilermaker is that you can easily access key resources to build up your theoretical knowledge. Currently, online colleges, courses, and thousands of books are available on the Internet for all students.\nHow many people work as boilermakers in America?\nAccording to a study by BLS, approximately 15,900 people worked as boilermakers in the United States in 2019.\nIs it dangerous to work as a boilermaker?\nAlthough boilermakers work in harsh environments or outdoors, the risk of serious injury is not that high. In the 21st century, technologically advanced tools, improved health and safety practices, and better working conditions make this, and many other construction jobs, safer than ever before.\nHow popular are apprenticeship programs?\nIn 2020, a report from the Department of Labor (DOL) said there were 26,000 apprenticeship programs registered in the United States. That year, about 3,143 new programs were created. So, the signs are positive that apprenticeship programs will continue to gain in popularity.\nIs it difficult to enter an apprenticeship program?\nNo. Many people enter these programs every year. DOL figures show that in 2020, despite COVID-19 and a 12 percent decline in new students, apprenticeship programs recorded the third-highest revenue in their history."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"}],"document_ids":["<urn:uuid:24d1baa3-a771-4764-a5cb-22b1c8667909>","<urn:uuid:51f364d0-0a5c-4853-9275-95a0a2ed0f64>"],"error":null}
{"question":"How do environmental protection measures differ between Kentucky's forest logging operations and coal mining activities?","answer":"In Kentucky's national forests, logging is mostly conducted on a small scale, with individual trees being selectively cut and milled on site to minimize ecological damage. One rare exception involved using helicopters to transport logs across the French Broad river. In contrast, coal mining operations have shown declining environmental compliance, with only 57% of surface coal mine permits being violation-free during inspections. There are ongoing concerns about violations at mines, including issues with erosion, landslides and pollution, indicating stricter oversight of mining compared to small-scale logging practices.","context":["Lawmakers first passed comprehensive solid waste management legislation on a statewide basis in 1966. Thereafter, the legislature made a number of changes but all of them applied to every county and city. When litigation arose about the respective role of cities and counties in garbage collection, the legislature responded with a new enactment, in 1982, making clear that counties are the paramount local government unit in solid waste matters. As time went by, the state courts, in a series of decisions, reaffirmed county primacy under the statutory change...\nOn May 14, the Public Service Commission (PSC) released a ruling adopting changes to net metering for Kentucky Power’s customers in a precedent-setting ruling that bodes well for rooftop solar across the state...\nIn a decision issued Tuesday, the Sixth Circuit Court of Appeals affirmed last April’s ruling by U.S. District Judge Justin Walker in a case involving an adult store’s sign off Interstate 65 in LaRue County. The owner of the Lion’s Den Adult Superstore sued the Kentucky Transportation Cabinet on First Amendment grounds in 2018 after state officials ordered the sign removed...\nWashington, DC — A coalition of environmental and community groups today brought a challenge to a Trump Administration rule designed to make it harder for communities impacted by coal mining to hold state regulators and mining companies accountable for violating environmental protections.\nGov. Andy Beshear has vetoed a bill that attempts to change the venue for lawsuits that challenge the constitutionality of a law, executive order or state agency action...FitzGerald conducted an analysis of 261 constitutional challenges filed in the first nine months of 2020 and says that only 11 were cases against officials or agencies, and that only two ended up in Franklin Circuit Court...\nLG&E asked the Kentucky Public Service Commission to raise electric rates 11.81 percent, or an additional $11.74 per month for the average customer, and gas rates 9.37 percent, or an additional $6.17...However, consumer advocates like Tom Fitzgerald, director of the Kentucky Resources Council, said the proposed increase is coming at a time when many are struggling because of the economic impacts of COVID-19. “These are hard times,” Fitzgerald said, “and I think the burden is particularly high or should be high on utility companies to justify rate increases during a pandemic and during an economic downturn.”\nThe Mountain Association, along with Kentuckians For The Commonwealth (KFTC) and the Kentucky Solar Energy Society (KYSES), were approved to jointly intervene in formal proceedings for a new rate case proposed by Kentucky Power Company. They are represented by Tom FitzGerald with the Kentucky Resources Council.\nThe $20,000 grant will support RRGU’s efforts to protect the Red River Gorge Geological Area (RRG). RRGU formed due to concerns that a resort and retail village proposed for the RRG. RRGU now consists of a fully-formed board and steering committee, comprised of local residents and business owners. The group is supported by professional consultants and technical advisors Gerry Seavo James of the Explore Kentucky Initiative (Frankfort) and SaraDay Evans of Accelerating Appalachia (Lexington) and fiscal sponsorship by Kentucky Resources Council.\nA letter released Wednesday from community and environmental groups claim ongoing violations at mines formerly owned by Blackjewel aren’t being addressed and actually have gotten worse since a massive protest last summer in Harlan County.\nKRC client, Kentucky Heartwood, brought to us the matter of illegal logging occuring in the Daniel Boone National Forest. In late April, our Environmental & Community Defense team sent a letter to the Daniel Boone National Forest supervisor calling for the suspension of further harvesting pending a review. Read about the issue that faces one of our valuable Kentucky forests.\nAugust 28, 2019\nZoning Amendment Passes with Increased Restrictions on Pipelines\nBy Ben Kleppinger, The Advocate-Messenger\nAfter three months of public hearings, the Danville-Boyle County Planning and Zoning Commission has finally approved a major overhaul of its zoning ordinance. Disagreements over how the zoning ordinance should regulate hazardous liquids pipelines surfaced last month. But those wrinkles had been ironed out by the time the commission met Wednesday morning. People who had been on opposite sides in July were in agreement that the new ordinance would make Boyle County’s protections against hazardous pipelines even stronger.\nAugust 14, 2019\nEnergy in Kentucky\nBy KET, Renee Shaw - Moderator\nKRC Director Tom FitzGerald was featured on KET - Kentucky Educational Television's Kentucky Tonight panel discussing the state of energy in Kentucky.\nJune 27, 2019\nErosion, landslide and pollution. Coal industry's compliance with fedral rules down\nBy Bill Estep, Herald-Leader\nOnly 57 percent of surface coal mine permits in Kentucky were free of violations during oversight inspections in the most recent evaluation, a continued low rate of industry compliance on environmental and reclamation rules...\"In any event, the continued slide in the number of sites that are not in compliance, and the number of OSM-observed violations, is a troubling trend,” - Tom FitzGerald, KRC Director\nMay 30, 2019\nLG&E spurned Bullitt County pipeline route recommended in 2015 study\nBy Marcus Green, WDRB\nIn the summer of 2015, a contractor for Louisville Gas & Electric Co. finished studying possible routes for a new natural gas pipeline that would connect to an existing line in Bullitt County. The firm, EnSite USA, reviewed 10 corridors for the new line and ranked them based on cost and impact on streams, land use, threatened and endangered species and other factors. EnSite recommended that LG&E build a 13-mile pipeline starting near Coxs Creek in Nelson County and running northwest to the Jim Beam distillery south of Shepherdsville, according to confidential documents recently made public. That route was slightly better than a 15.5-mile path between Bardstown and the distillery that also would travel northward.\nMay 9, 2019\nLead and Other Everyday Environmental Dangers\nBy Patrick Reed, KET\nEnvironmental factors such as air and water quality play a pivotal role in public health, as populations who live in areas with pollution, decaying buildings, and/or an unsafe, contaminated drinking supply are at a high risk of developing a myriad of health problems. How can we become educated about environmental issues to safeguard our own living spaces and also become effective advocates for better regulation of these essential ingredients to our ecosystem? Read more...\nMay 5, 2019\nWith or without Green New Deal, Kentucky's energy future is heading away from coal\nBy Matt Mencarini, Louisville Courier Journal\nApril 18, 2019\nLandfill amendment process reviewed\nBy Hannah Woosley of the Georgetown News-Graphic\nTom FitzGerald, director of the Kentucky Resources Council and attorney to advise the Scott County Fiscal Court regarding the solid waste management plans happening in the county, was back at a fiscal court special meeting on Monday. Read more...\nApril 12, 2019\nKentucky plan to reduce Mammoth Cave haze approved by EPA\nBy Stephanie Hill for The Herald-Dispatch\nBy Ketucky Geological Survey","Some of the more often asked questions that we get have to do with our lumber; where we get it, are our sources ecologically minded and what grade the lumber is. Since we haven’t covered that in a while, I’ll go through that again briefly.\nWe purchase nearly all of our lumber from a local broker; Tommy. He runs a tree cutting service and is pastor of the local Church of Christ. He’s a good, honest man. People will call him when they need a tree or two, sometimes more, cut from their property. He is against deforestation and does not engage in large scale logging. Since most of the land around here is part of either the Great Smoky Mountains National Park, The Cherokee National Park or the Martha Sundquist National Forest, logging here is mostly small scale.\nThere was one operation up in Del Rio a couple of years ago where a large number of trees were cut and flown across the French Broad river to a spot next to Highway 321 by a huge helicopter because it was the only way to get them out of the remote location they were being cut without major ecological damage. That’s the only time since we moved here 6 years ago that I’ve seen more than a truck load of logs being taken from a single site.\nTommy buys lumber as standing trees – trees that need to be removed for one reason or another – and works with several local sawyers. He and a sawyer go in and fell the trees, cut them into logs and mill the logs into lumber on site with a portable mill.\nIf Tommy expects the logs to yield some especially nice lumber he will call me to see if I am in the market for that species. If so he loads the freshly milled lumber onto his truck and delivers it to me here, where we will sort it, count it up and cull out the useable stock. As to the grade of lumber -- because I buy the entire log, what I get is called log run lumber. In it we will get some choice and select grade lumber, some #1 and #2 common, and some that is pretty rough. Mostly the grade of a piece of lumber depends on how closely spaced any defects (knots, bark inclusions, rot pockets, wormy areas, etc) are, and somewhat on the grain pattern. Perfectly clear, very straight grained boards are select or choice grade. One or two small defects in a board would make it #1 common grade, more would deem it #2 common. Lumber that isn't suited for furniture making can be cut into stacking sticks or used in odd projects around our yard, so little is wasted. Even the shop scraps too small or gnarly to be used in any other way can be used in our fireplace to heat our home.\nHint: if you should decide to try your hand at logging, don’t park your truck under the tree you’re cutting! No, that’s not anyone I know. Really!\nBefore this lumber can be used in furniture making it has to dry. Fresh milled lumber is saturated with water. It normally takes around two years for the lumber to air dry to a useable state. During that time it must be stacked on a drying rack, each layer separated from the next by spacers or “sticks” so air can circulate all around each board. The stacks are then covered with sheets of tin roofing (if stored outdoors) and weighted. Now that our new workshop is in use, the old workshop building is being used for lumber storage. I hope to expand this \"under cover\" storage by building an open sided shed that connects the old shop and the new. That will keep rain, snow and the sun off of the lumber piles but allow the air to circulate freely.\nAs the lumber dries it will shrink. It will also want to cup (curl up on the edges) and bow (curl up toward each end) as well as split. By sealing the ends of the boards before stacking them I can prevent the open end grain from drying out faster than the rest of the board which causes splitting. If the boards are properly sticker stacked and weighted the cupping, curling and warping problems will also be minimized. If it is done properly.\nSome want to know if our lumber is kiln dried. It is not; here’s why. Kiln drying *can* be an effective means of drying lumber more quickly than air drying, but if it’s done improperly, if it’s rushed, the lumber is ruined. It may not look ruined, it may look just fine until you cut into the board, then internal stresses created by the too-fast removal of the water content cause the board to curl off in weird directions. Sometimes the internal structure of the wood is so damaged that it honeycombs inside, rendering the board useless.\nKiln operators will tout kiln dried lumber as being superior for exacting uses (like furniture making) because they dry the wood to 6% to 8% water content. They claim that this makes the wood more stable, less likely to shrink up. Which has some truth to it… if you use the lumber as soon as it comes out of the kiln. But if the dried lumber is stacked and stored for any length of time, it *will* begin absorbing moisture from the atmosphere until it is back up to the 10% to 14% (or more, depending on humidity levels) that is normal.\nEven if you do use the lumber right out of the kiln, the wood in the finished furniture will absorb moisture right through its finish and expand. If you have not allowed for this – if you think that “kiln dried lumber doesn’t ‘move’” -- then you will be popping joints all over the place. Wood never stops moving.\nBy air drying my own lumber I know that it was done correctly, my lumber costs are significantly reduced, and I have far fewer problems with case hardened or honeycombed lumber. I do have to keep ahead of my demand; have to keep enough lumber on hand to serve my needs two years down the road. And that my friends is a considerable amount of lumber. We stock 7 species; red oak, white oak, hickory (pecan), walnut, cherry, poplar and maple. We also bring in some specialty woods when they are available, at the moment we have ash, holly, sycamore, honey locust and some aromatic cedar in our lumber yard.\nWhen I begin a project I go to the lumber stack and pull out boards that are well suited to the project at hand. A detailed discussion of what this entails would be beyond the scope of this little blog; it is something learned through experience… we call it “reading the wood”.\nWhen I have the wood I need I take it into the workshop and allow it to acclimate for a while. Acclimation is just a snazzy word for adjusting to the new environment. The environment inside my workshop is different from that outside (thank God). As the wood’s water content and temperature equalize with that inside my workshop it may want to change shape. This time I allow it to do so. While this process is on-going, I can chunk the boards up into oversized pieces from which the parts will be made, but I must allow them to finish acclimating before milling them to finished size. That is what we’re doing now. This is in fact enough oak for Nance’s CD End Table, Ira’s TV Tray Table set, and a dining room table that I’m working on in the evenings for my own family, and probably enough to finish up the oak steamer trunk we began when we built the two trunks last fall. About time I got the other two finished up.\nThe lumber is inside now and I can go through the boards with my cut list and mark each board according to it’s intended purpose based on it’s coloring and graining. Sometimes it is necessary to surface plane a board a little to get a better look under the rough sawn surface. But if the sawyer used a sharp blade, I can usually see what I need to see as is.\nI am also double checking to see that we have all the parts needed on hand and ready to use. The one part that gave me trouble on his project is the drawer pull selection. Nance really wanted antique brass library pulls. For some odd reason, none of the suppliers from whom I can buy library pulls offer them in an antique brass finish. But I did find a supplier who offers unfinished brass library pulls, which I can use an antiquing solution on, then lacquer them to preserve the finish and prevent corrosion. So that’s what we will do. This would not work on brass pulls that have already been lacquered (unless you removed the lacquer first) or on pot-metal pulls with a brass colored finish. Only on real brass.\nI said I’d be brief, didn’t I? Sorry about that."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:ee32a305-a9af-4c64-a3e8-34408020f6f1>","<urn:uuid:90a61378-18c4-4ad6-a7ab-6be4af3a6525>"],"error":null}
{"question":"How can I make the most of kitchen leftovers and freezer storage to reduce food waste?","answer":"You can maximize leftovers and freezer storage in several ways. For meats, you can ask the butcher to split items like whole chickens and freeze half for later use. After cooking chicken, use the bones and leftover vegetables to make stock that can be frozen for future soups. The freezer is excellent for preserving various items before they expire - cheese, bread, and herbs can all be frozen, with herbs being particularly well-suited to freezing in ice cube trays with water. Additionally, various vegetables can be preserved through freezing with proper preparation. For instance, Brussels sprouts can be frozen for 12-14 months when properly blanched and stored in freezer bags with air removed. Making extra servings of meals for work lunches helps reduce waste and save money. These preservation methods allow you to maintain a supply of ingredients for quick, healthy meals while minimizing waste.","context":["Now that its January, most people vow to eat better in the new year. Healthy eating starts with eating real food, and cooking for yourself at home. Use these tips to become more confident in the kitchen, and to make your life just a little easier, especially if you are not accustomed to cooking.\nBuy a whole chicken at the meat counter. Ask the butcher to break it down and package each half separately. Freeze one, then roast the other half, rubbed with olive oil, salt and pepper, sitting on a bed of chopped carrot onions, celery and garlic. Roast at a preheated 400 degrees F for 45 minutes.\nBonus: if you drain the juices, into a hot pan and let it bubble for a minute, you have killer gravy!\nUse up everything!\nHave a lot of carrot, onion, celery and garlic? Take the bones from the chicken you just ate, chop the vegetables up into chunks, cover all of it with as much water fits into your largest pot and simmer for a few hours and you have just made chicken stock…that will also keep well in the freezer! Once winter gets really harsh, you can have a delicious base for chicken soup!\nBring meat or fish to room temperature before you cook. It will result in even temperature and shorter cooking times.\nKeep the root of the onion in tact as you cut it. Take a knife skills class if you feel like you need to. But having knife skills will make life in the kitchen so much easier, and is really the basis for anything you do in the kitchen Create your own seasoning combinations. If you always use salt, pepper, garlic powder and parsley to season, cut the need to open 4 different spice jars and combine them all.\nLike more pepper than salt? Then just add more pepper than salt. You control the seasoning!\nLiven up your noodle. Sure, opening a jar of sauce and plopping it on spaghetti is really tasty, not gonna lie, but have you ever tried these amazing combinations? They’re delicious cold the next day too.\n1. Spaghetti with broccoli and red pepper flakes. Throw in some frozen broccoli in the last 2 minutes of cooking the pasta, toss in olive oil and season with salt, and red pepper flakes.\n2. Orecciette pasta with peas, butter and Parmesan. Same concept, but frozen peas have a shorter cooking time.\n3. Capellini with garlic and fresh basil. Chop the heck out of 3 cloves of garlic. Then sprinkle 2 teaspoons of kosher salt on the pile of garlic and keep chopping. Drain the pasta, leaving about ½ cup of the water in, then toss in some the salty garlic, then freeze the rest of the garlic paste in a plastic baggie for next time. Throw in chopped fresh basil to taste.\nUsing frozen veggies and pantry staples make these dishes so super simple and amazing in yo mouth!\nSteak and Eggs, or Polenta and Eggs, or Veggies and Eggs! You got it, eggs pack a real culinary punch anyway you eat them. They are full of nutrients and healthy fats too. Just take some leftovers, cook up an egg and boom, insta-meal. Inexpensive, versatile and damn good….thanks, eggs!\nThe freezer is your friend. Keep blocks of cheese, bread and even herbs in the freezer and preserve the items that you may not go through before their expiration date. Chop up that bunch of herbs and put them into ice trays with a bit of water and freeze. Once frozen, remove them from the tray and store in zip-top bags.\nBuy enough ingredients to make a few extra servings and take them to work for lunch. Never underestimate the power of leftovers. It will save money just bringing lunch to work, and you will also have more time to eat, and rest during your breaks. Standing in line for 30 minutes for a sandwich to be made, including the time it takes to get to the deli will eat up that hour you should be using to chill out (pun totally intended).\nBasically, all you have to do is keep basic ingredients on-hand, with a little creativity or Internet search skills and you can make a meal in no time at all. There is nothing healthier than eating real food, that is made at home. Not only is it good for the body, it is good for your soul.\nCheers to a very happy year in the kitchen!","Freezing Brussels Sprouts\nMost people don’t want to eat Brussels sprouts, let alone freeze them. But if you’ve had the opportunity to eat fresh, locally-grown sprouts after a frost, you’ll be a fan—and wanting to learn how to freeze Brussels sprouts.\nFreezing Brussels sprouts successfully starts with a homegrown or locally raised product. Why? The secret to wonderful Brussels sprouts is frost. When frost kisses plants, they convert starches to sugars, which sweetens sprouts. The only way to get these sprouts is to grow your own or get locally-grown ones—after a frost. Fresh supermarket versions usually originate in California or Mexico and haven’t experienced the sweetening magic of frost. That’s why Brussels sprouts often taste slightly bitter.\nOne pound of Brussels sprouts yields roughly one pint frozen. Start the freezing process by washing sprouts. Late-season sprouts often have clusters of aphids or other insects hidden beneath the first or second outer leaf layer. Cause any hitchhikers to exit sprouts by soaking them in a vinegar or salt solution. Use 1 to 3 tablespoons of vinegar or salt per gallon of water. Soak sprouts for half an hour, then rinse thoroughly. Remove old or yellow outer leaves and trim bases.\nFresh Broccoli Beats Store-Bought Every Time\nWant to enjoy fresh-from-the-garden broccoli all year long? It's a snap to freeze this fiber-rich veggie to use in stir fries, soup and more. Learn the process for how to freeze broccoli in this article by Julie A. Martens.\nOverwhelmed with Cucumbers?\nCucumber vines can be prolific producers of the treasured summertime veggie. Don't think it's possible to freeze cucumbers? Well, the secret lies in the preparation. Learn how to freeze cucumbers for summer-fresh fare in any season.\nNever Have Too Many Cherry Tomatoes\nWhile frozen cherry tomatoes are no longer fit to be used in tossed salads, you can blend them with herbs or use in soups and stew. In this article, Julie A. Martens offers several great uses for frozen cherry tomatoes and describes the best way to preserve them.\nFreeze Spinach for Soups and More\nWhile you won't want to serve frozen spinach in fresh salads, the leaves will work nicely in soup, casseroles and stir fries. You'll just want to freeze young leaves. Avoid the older or yellowing leaves as they'll produce a nasty taste and rubbery texture. Ever tried making frozen spinach cubes? Get more tips on how to freeze spinach in this article on how to freeze spinach.\nCan You Freeze Kale?\nYes, you can freeze kale. Frozen kale works well in smoothies and blends well into quiches, crock pot stews and soups. Find more uses for frozen kale and how to best preserve this nutrient-packed green.\nPut Your Onions in the Deep Freeze\nToo many onions to eat right away? Not a problem. They freeze easily, and can be used in a variety of ways. Learn how to prep onions for safe storage in the deep freeze, how to keep the onion odor low and when to use frozen onions in your dishes.\nFreeze Asparagus for Great Flavor\nWhile frozen asparagus spears won't be as crisp as garden-fresh stems, they can still be used in many dishes. Here are the steps to preserving this nutrient-dense vegetable and some ideas on how to use frozen asparagus to add flavor to your meals.\nCan You Freeze Garlic Cloves?\nYou definitely can freeze garlic. In fact, you can freeze garlic in many ways. While frozen garlic lacks the crunchy texture of fresh, the flavor remains strong—and definitely won't have the chemical taste that sometimes accompanies jarred garlic. Learn several ways to freeze garlic and how to use it to add flavor to food.\nHow Do You Freeze Eggplant?\nEggplant doesn't keep very long, and you won't be able to can it without pulverizing it beyond recognition. So, how do you preserve your delicious eggplant? Forget your canner and learn how to freeze eggplant. Here are several freezing methods you can try.\nEnjoy a Summertime Favorite All Year\nLearn how to freeze corn and you'll be able to enjoy this summertime treat all year—even with your holiday turkey. Freezing corn is simple, and it's a great way to introduce kids to food preservation. Learn the steps to freezing corn in this article by Julie A. Martens.\nHow to Freeze Brussels Sprouts\nBrussels sprouts bring more than taste to the table. This cabbage cousin boasts vitamins and is high in protein, so you'll want to make your locally-grown Brussels sprouts last. Learn the two ways to freeze Brussels sprouts and ways to include this frozen super veggie on your table.\nSteps to Freezing Cabbage\nWant to enjoy the nutrition offered by cabbage all year? This unsung hero of the vegatable garden adapts well to the freezing process. Start with dense, solid heads that feel weighty for their size. Learn more about the steps to freezing cabbage in this article from Julie A. Martens.\nFreeze Celery for Soups\nCelery is mostly water, and the freezing process ruptures cell walls, resulting in a limp, mushy product. But frozen celery works fabulously in casseroles, sauces, stock, and other hot concoctions. You can also use it as an aromatic with soups, broths for cooking rice, or roasts, tossing after cooking. Learn the steps to freezing celery in this article.\nOverstocked on Mushrooms?\nMushrooms might last about a week in the refrigerator, which might not be enough time to enjoy the bounty you may have grown or foraged. Consider freezing mushrooms. Learn which method of freezing mushrooms works best, and get some ideas for how to use them in recipes.\nSort sprouts by size, grouping them as small, medium, and large. Why? Because blanching times are based on spear size. Blanch small sprouts 3 minutes, medium ones 4 minutes, and large ones 5 minutes. Use a steamer basket to shift sprouts easily between boiling and ice water. Avoid overheating the sprouts, which can contribute to post-freeze mushiness.\nAfter blanching, move Brussels sprouts into the freezer as rapidly as possible. Fast freezing yields a fresher, less mushy product. You have two options for freezing: individual quick freeze or package freezing.\nQuick-freeze Brussels sprouts individually on a cookie sheet. For fastest freezing, place the sheet close to where cold air enters your freezer. After sprouts are frozen, tuck them into freezer bags in bulk. Remove as much air as possible from bags before sealing. Grab sprouts by the handful as needed for cooking.\nA second option is packaged freezing. In this method, package serving-size portions of Brussels sprouts in freezer bags. Always remove as much air as possible for the freshest product. A vacuum sealer system works well with Brussels sprouts. Avoid overpacking bags. Instead, keep sprouts in a single layer for quickest freezing. Place bags into the freezer as flatly as possible until sprouts are frozen. Afterwards, pack the bags into your freezer to maximize space use.\nBrussels sprouts bring more than flavor to the table. These miniature cabbage heads boast cancer-fighting qualities, along with folic acid and Vitamin A. They’re also high in protein, but should be paired with whole grains to serve a complete protein that contains the entire spectrum of amino acids.\nFor best quality, use frozen Brussels sprouts within 12 to 14 months. Frozen sprouts make a great addition to crock pot stews and homemade soups. Toss them into a skillet with a little olive oil, or add them to stir fries. Frozen Brussels sprouts also taste great when oven roasted with olive oil and salt.\n- How to Freeze Green Beans\n- How to Freeze Corn\n- Freezing Zucchini: A Great Way to Chill Out\n- How to Freeze Broccoli\n- How to Freeze Okra\n- Can You Freeze Mushrooms?\n- Freezing Eggplant\n- Can You Freeze Celery?\n- Freezing Onions\n- Freezing Cabbage"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"}],"document_ids":["<urn:uuid:34ffe02e-f0f8-4c58-9732-09c679011769>","<urn:uuid:18453af5-2be5-4153-a9f5-17a7266b62f9>"],"error":null}
{"question":"What was the composition of the diet that scientists fed to captive bonnethead sharks in their study?","answer":"The scientists fed captive bonnethead sharks a diet that was 90 percent seagrass and 10 percent squid.","context":["A shark’s diet is typically a cornucopia of meats: seals, rays, squids, and krill. The idea that “fish are friends, not food” may be charming in Finding Nemo but a bloody bucket of chum is more of a shark’s style. That is, unless the shark in question is a bonnethead shark, a small member of the hammerhead shark genus. According to a new study, this broad, smooth fish is the only shark species known to be an omnivore.\nIt is, however, unclear if the bonnethead shark means to be an omnivore. In the study, released Wednesday in the Proceedings of the Royal Society B, scientists determined that these sharks are able to digest the copious amounts of seagrass they consume. Previous studies established that up to 62 percent of the shark’s gut content mass could be seagrass, but it was unknown if the sharks were actually digesting the plant matter. Now, it’s clear that they are digesting it, but like a weekend warrior downing a garnished Bloody Mary, the ingested greens are likely a byproduct of wanting something else.\n“It has mostly been assumed that they could not digest the seagrass and it was just incidental from scooping up blue crabs,” study co-author and Florida International University assistant professor Yannis Papastamatiou, Ph.D., tells Inverse. “We show that they can quite efficiently digest seagrass and get nutrients and energy from seagrass. I still believe they are getting it incidentally while chasing crabs, but they are getting some energy from the seagrass nonetheless.”\n“I still believe they are getting it incidentally while chasing crabs, but they are getting some energy from the seagrass nonetheless.”\nIn this case, digestion is key: What an animal ingests and what they digest are not always the same thing. Just because you can swallow a small battery doesn’t mean your body is going to break it down into nice, nutritious molecules your body can use. The fact that previously dissected bonnetheads appeared to have degraded seagrass — not fresh seagrass — in their bellies was the first clue that their bodies were breaking the plants down and gaining nutrients.\nIn their study, Papastamatiou and his colleagues fed captive bonnethead sharks a diet that was 90 percent seagrass and 10 percent squid. When they subsequently analyzed the animal’s digestive system and the biochemistry of food particles that passed through them, they determined that the sharks were able to digest both fiber and soluble carbohydrates from the seagrass.\n“The fact that this is the first known species of omnivorous sharks is very exciting!” Samantha Leigh, a Ph.D. candidate at the University of California, Irvine, and co-author on the study tells Inverse. “This means that we need to completely re-evaluate their role in crucial and fragile seagrass meadow ecosystems, as they likely play a different role in ecosystem dynamics than we had believed.”\nPapastamatiou says that people typically focus on what a predator eats, but neglect to think about what happens after that food is consumed. Digestion, he reasons, “is a fascinating but often neglected process.” It’s what happens after an animal eats that allows for nutrients to spread, disperse, and prompt growth. Bonnethead sharks might be after crabs, shrimps, and mollusks, but their seagrass snacks give them a boost of necessary energy as well."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"}],"document_ids":["<urn:uuid:cfc3a41c-9a2c-41dc-b40a-1e7ce7bb8a11>"],"error":null}
{"question":"How does the approach to data analysis differ between LinkedIn profile optimization and Twitter misogyny research, particularly in terms of reliability and depth of understanding?","answer":"LinkedIn profile optimization and Twitter misogyny research represent contrasting approaches to social media analysis. LinkedIn analysis focuses on clear, actionable metrics like keyword optimization, profile completeness, and direct engagement measurements, with reliable indicators such as profile views and recruiter connections. In contrast, Twitter analysis faces significant methodological challenges - only 0.7% of tweets contain reliable geolocation data, and automated analysis methods cannot capture nuanced cultural practices like subtweets, hate-linking, and irony. While LinkedIn analysis provides straightforward guidance for professional advancement, Twitter research requires deeper sociological understanding, as issues like misogyny need to be placed in their full historical and social context beyond mere sentiment analysis or network mapping. Simply counting misogynist statements or measuring influence networks is insufficient for understanding complex social problems on Twitter, which require sophisticated ethnography and historically situated analysis.","context":["Learning how to optimize your LinkedIn profile for recruiters is extremely important to find your next job. Candidates often ask us, “What is the best way to get noticed by recruiters on LinkedIn?” so we asked leading career counselors, HR professionals, LinkedIn writers, and\nThe overwhelming response was to optimize your profile on LinkedIn, one of the premier social media platforms for business. Search engine optimization on a LinkedIn profile is when every part of your personal profile is filled out and shows HR managers or recruiters what you do, who you are, and what you are an expert in. This helps your profile rank higher in LinkedIn searches and builds trust among those who might want to connect or follow you.\nThe overall goal of LinkedIn optimization is that potential employers and recruiters find you in their search results. Just listing your current job title, current employer, and work history are not enough. Below are the best ways to optimize your LinkedIn profile for recruiters from the experts we connected with.\nTop 10 Best Ways to Optimize Your LinkedIn Profile for Recruiters\n1. Strategize Your Content\nBe strategic with the content you share and post on LinkedIn.\nAs someone who has hired candidates in the past, this is something I often look at when searching through someone’s LinkedIn profile. It is essential to use your LinkedIn as a tool that can help an employer to get some details about who you are and what you are interested in.\nThis is why it can be beneficial to detail your profile to fit the type of job you are looking for. Posting content about real-world events you are interested in can help, as well as sharing posts from other similar companies to those you want to be a part of or learn more about.\nThis helps to give your LinkedIn character and makes it easier for possible employers to see your interests and how your skills match. It is all about quality over quantity when it comes to posting on LinkedIn, which is why being smart about what you post can really help you in the end.\nAdam Moore is the founder of SocialPlus, a company that helps you accelerate growth on social media networks.\n2. Reinforce Your Personal Brand\nUse your LinkedIn profile to reinforce your personal brand and what you want to be known for in your career. Be selective and specific about what you choose to highlight, so it allows you to stand out to your desired audience.\nAbout section: The About section is where you can provide a concise snapshot of your identity, skillset, work approach, and professional mission.\nFeatured section: When job hunting, make sure your Featured section is populated with items that reinforce the skills or accomplishments you feel are more relevant to the target employer. This section is one of the first visible sections of your profile that gives you an opportunity to create an all-important first impression of the value you create in your professional life.\nHeadline: Ensure your headline image highlights the specific skillset and job title(s) you feel accurately represent your personal brand positioning.\nBackground image: In addition to including a current headshot, customize your LinkedIn background image with a photo that relates to your skills, organization, domain expertise, or professional mission.\nRecommendations: The Recommendations section of your profile is a natural place to highlight your soft skills and transferrable skills. With any recommendation request, ensure you’re specifying the key areas of your approach you want others to highlight.\n3. Set Clear Goals\nMy number one tip for job seekers to optimize their LinkedIn profiles is to set clear goals. This is the first step in optimizing your account. You may need to sit down and think about how you want to represent yourself. That’s because you are a brand that needs to put its best image forward. As a result, you should alter your profile by checking what strategy allows you to reach your business goals.\nAnother tip to optimize your profile for employers is actively using the “Who’s Viewed Your Profile” metric from the dashboard. This feature allows you to see who has visited your page, which helps you to understand your target audience. In this case, talent acquisition heads or recruiters should be viewing your profile. So, use keywords in your description to attract them to your LinkedIn brand. The more relevant your keywords are in accordance with your goals, the greater your chances of landing a great job.\nIrene McConnell is a career coach, hiring manager, and MD of Arielle Executive. She is also an official member of the Forbes Coaches Council.\n4. Research Your Target Audience\nStart by doing some research on what recruiters and hiring managers are looking for in a candidate. For instance, you can have a look at the profiles of other professionals in your niche to get an idea of important elements to include. Customize your profile based on your research findings. This will help you make sure that your profile is representative of what employers are looking for.\nSecondly, focus on showing off your accomplishments, not just your job titles and work experience. It’s important to highlight what you’ve done rather than just what company you worked for or how long you worked there.\nArthur Worsley is the founder of The Art of Living, a website that helps top performers lead happier, more balanced lives. He is a former McKinsey Associate with an MA in Psychology from Oxford University.”\n5. Clean Up Your Headshot\nUse a professional-looking headshot as your profile photo and set its visibility to the public. This doesn’t mean you need to pay for headshots, but take a dedicated photo wearing professional clothing that shows only you in front of a relatively neutral background. Setting it to public ensures anyone who’s checking your profile will be able to find your profile and see it in full more easily.\nUse keywords relevant to your search in your headline. If you’re not sure what these are, compare the titles of postings you feel are a good fit for your skills and look for the words and phrasing they use to describe the type of work you do. Obviously, it should still be a true description of your role, but for most jobs, there are several ways to describe them, and which you use can affect whether you stand out to both automated screening systems and hiring managers who are quickly reviewing candidates on LinkedIn.\nShow your value as a candidate in the first 250-300 characters of your summary. This is the part that will show before the “See More,” so it’s where you need to hook someone into wanting to dig deeper. Identify which of your skills or experience makes you the most qualified for the job you want, then make sure that comes across early in your summary.\nMichael Moran is the owner of Green Lion Search Group, a recruiting firm based in Austin, TX.\n6. Use the Right Keywords\nUse the right keywords: Keywords should reflect what you do. If you’re a web developer, use “web developer” as your keyword. If you’ve been working in the field for years, try using “expertise” instead of “experienced.”\nCreate a professional headline: A good headline can make or break your profile. Make sure that your headline reflects who you are and what you do. Try not to include too many words; keep it short and sweet.\nAdd relevant skills: You don’t want to list out everything you know how to do. Instead, focus on listing out the specific skills that are relevant to your industry and the job descriptions.\nLeslie Radka is the founder and hiring manager of GreatPeopleSearch, a leading background check firm.\n7. Maximize Your Introduction\nAs a professional career coach and certified professional\nresumewriter (CPRW), my LinkedIn advice for clients always starts with the following: start by maximizing the top portion of the introduction of your LinkedIn profile.\nThis is what recruiters and hiring managers will see first when they view your profile.\nTip #1: Your headline should be keyword rich and reflect the job you or the industry you are targeting so that you’ll maximize your chances of a recruiter finding you.\nFor example, Digital Marketing Consultant – Market Research – Social Media Marketing\nTip #2: Next, I suggest checking the “open to” function (also located in the introduction section of your profile).\nYou can either click “open to work” if you’re job searching or “open to providing services” if you are a freelancer or have a private practice in your field and you want to attract clients.\nTip #3: The “about” section (directly underneath the introduction) is another prime location of your profile to add keywords that are related to your targeted job(s) and field.\nIf you need some inspiration, you can search job postings in your targeted field to get an idea of the skills and expertise employers are searching for.\nIn addition to keywords, you want to articulate your passion and value-add to your field. What makes you stand out in your profession? What do you love most about it? Unlike your\nresume, your profile should be written in the first person and reflect your personality.\nTip #4: In the “Experience” section of your profile, you want to also use the first person and give an overview of the scope of your role for each of your current and prior jobs. I encourage clients to not just repeat the information from their resumes. A recruiter wants to see a more personal aspect on their LinkedIn profile. It’s your chance to tell a more in-depth story about what you achieved in your positions and what made you stand out.\nLee Cristina Beaser received her MS in Career Counseling, worked in higher education for about ten years, is certified as a professional\n8. Leverage Keywords from Job Postings\nIf you’re a job seeker, start in the Jobs section of LinkedIn to review job listings and identify your ideal role. Mine those listings for repeated keywords and core competencies and incorporate them throughout your profile to add keyword density and increase your chances of getting noticed in an employer’s LinkedIn search.\nThis includes adding these terms to your Headline, as a list of expertise or specialties in your “About” section, as designated skills in your “Skills” section, and in the text of your “Experience” section.\nThere are a few hidden fields in your profile that you can use to optimize your profile, increase its visibility, and attract your dream job. Complete the “Open to finding a new job” tool (the blue button under your name that only you can see).\nFollow all of the companies that you’re targeting to indicate your interest (recruiters can see who you follow) and stay up-to-date on company news. Change your “industry”—a field in your “Intro” that isn’t visible except to you and recruiters—corresponds with your target employer/role.\nFinally, make sure your profile is “public” (in “Settings”). This makes your profile searchable so employers can find you even if they aren’t first-degree connections.\nNow, don’t forget to make your profile professional, dynamic, and appealing, so recruiters and hiring managers want to read more once they find it!\nWrite a compelling first-person summary (“About” section) describing who you are and what you bring to the table, add media in your “Experience” and “Featured” sections to showcase your work and your team’s successes, and update your profile picture with a high-resolution, professional headshot. Upload a bright banner using Canva or a stock photo or design to make your headshot pop and ensure your profile stands out in a sea of LinkedIn gray.\nMargaret Gerety is a certified\nBefore starting her own company, Margaret spent over a decade in law and higher education, first as a corporate tax attorney at a large international law firm and then as an Assistant Dean and academic advisor at Georgetown Law. Margaret is a certified professional\n9. Create Relevant Content\nYour headline shouldn’t be just a job title: In the headline field, explain how you see your role, why you do what you do, and what motivates you. Look at the profile page headlines of your sales reps for inspiration if they’re on the ball with social selling at your company. It’s unlikely that they will only list their titles.\nBuild your network: To grow your LinkedIn network, sync your profile with your email address book. It’s an easy and relevant way to do it. LinkedIn will suggest people you could connect with.\nDescribe your relevant skills: Select the skills that are relevant to you from the list. Your Headline and Summary provide a platform for others to endorse you. Stay relevant.\nShare your expertise with articles: You can share your work experience, ideas, trends, opportunities, and challenges here. You will also appear to be an expert in your field if you do this. Write three to five articles.\nChristian Velitchkov, is the co-founder of Twiz, a full-service marketing agency.\n10. Try a Video Headshot\nCreate Your Career Novel\nThink of your LinkedIn as the cover of your career novel. Your profile pic should be clear and not a yawn. A headshot with a smile usually follows an immediate “let’s call this person for an interview” response. A cover image that quickly explains and re-enforces what you do helps the recruiter and hiring manager promptly assess your ability to communicate. And your headline should automatically sell your “novel” to anyone viewing it.\nYour headline should consist of:\n- what you do\n- how you do it uniquely\n- who you serve\n- your title\n- a secondary title or message (this can be personal)\nHere’s an example:\nMeticulously Writing for Word Challenged Business Owners | Remote Content Writer | Cat Dad\nA well-written headline with powerful keywords or phrases means attracting recruiters and hiring managers. Everyone who sees your LinkedIn will begin to know who you are and what matters to you because this is a marketing platform! Marketing yourself for the purpose-filled career you deserve is critical for your success.\nLinkedIn’s Hot New Feature!\nLinkedIn has a new 30-second Video Headshot option that you can use in addition to your profile picture. This feature allows you to speak to your target audience about what makes you special and unique from your competition.\nMost people are terrible at talking about themselves on video. However, we recommend working with Mike at Amptek Productions, who specializes in creating the most amazing wow video about yourself.\n“Featured” Section Is An Under-used Feature\nMost recruiters and hiring managers will want to see what you have done. So be sure to use your “Features” function, where you can highlight your writing, designs, articles, or videos you’ve created or featured. It’s an on-the-spot portfolio of your work, and our team feels this is the most under-used feature on LinkedIn.\nSuper Julie Braun (please call her SJ) is the Founder & CEO of Super Purposes™. The company coaches people on their careers by delivering humorous online courses, group coaching, and workshops that take the fear and formality out of the challenging job search process. The team of 100+ eccentric career whizzes from diverse backgrounds invests in every client’s success.\nLinkedIn Optimization to Get Noticed By Recruiters Summary\nLike most social networks and search engines, LinkedIn wants its search results to be relevant to the search query.\nFor potential candidates seeking new opportunities, that means having a complete profile with an excellent LinkedIn summary section at the top of your profile, a robust experience section, a detailed skills section, a profile headline that pops, and relevant keywords throughout.\nYour public profile is a great way to promote yourself and should be the first thing to update when searching for a new job.","Investigating misogyny on Twitter: sociology’s role.\nThere are now free tools available, such as Node XL, which, at unprecedented speeds and scales allow us access, harvest, and analyse the traces of people’s (often transgressive) thoughts, opinions and behaviours on Twitter. Since it combines the grand scale and generalisability of methods such as national surveys with the granularity and detail of close textual analysis, ethnography, or participant observation (Driscoll & Walker, 2014, p1746), Twitter analysis seemingly represents the holy grail of research methods. Existing research into misogyny on Twitter for example shows feminism is as indispensable as ever. There is, however, an increasingly important role for sociology to address technologically mediated symbolic violence like this.\nFirstly, it is important sociology is leading potential critiques of such “big social data” (Manovich, 2011). A closer examination reveals many of the techniques used to sample and analyse Twitter data are limited or flawed. Twitter use is unevenly distributed among Web users in general and, even among those that use it, a significant percentage rarely send a tweet of their own, preferring instead to “listen” to the tweets of others (Graham, Hale, & Gaffney, 2014). There’s no reliable method for verifying the location of Tweeters. For example, from a sample of 19.6 million tweets collected by Graham et al. (2014) only 0.7 percent of tweets contained structured reliable geolocation information (p4). Since they are invisible to algorithms, Twitter’s intentionally nuanced cultural practices such as subtweets (tweets referencing an un-named but implicitly identifiable individual), quoting text via screen captures, “hate-linking” (linking to denounce rather than endorse) and, of course, irony, are ignored by automated methods of textual analysis (Tufekci, 2014). Much Twitter research is therefore completed with “only limited understandings of how best to work with the spatial and linguistic contexts in which the information was produced” (Graham et al. 2014, p1).\nSecondly, it is crucial for sociology to show misogyny on Twitter can be fully understood only by placing it its full historical and social context. When it comes to our most important and challenging social problems like misogyny, Twitter analysis, at least in isolation, is a poor substitute for sophisticated ethnography accompanied by historically situated and theoretically reflective analysis. Proving, through sentiment analysis, how many people make misogynist statements on Twitter, who gets retweeted the most; who’s the most influence misogynist in a network of misogynists is all very well but how does this help us understand misogyny; its consequences and possible counter-measures?\nWhen any of us use technology we individually and collectively engage with wider society; its political and social history and the struggles that have preceded our temporal space. Via religious, legal, and medical discourses, the antecedents of misogyny are deeply and subtly embedded in our collective conscience. In research, misogyny on Twitter should be addressed as technologically mediated symbolic violence that arguably reengages modern patriarchy with centuries of discursive action intended to humiliate feminist voices.\nDriscoll, K., & Walker, S. (2014). Working Within a Black Box : Transparency in the Collection and Production of Big Twitter Data, 8, 1745–1764.\nGraham, M., Hale, S. a., & Gaffney, D. (2014). Where in the World Are You? Geolocation and Language Identification in Twitter. The Professional Geographer, (July), 1–11. doi:10.1080/00330124.2014.907699\nManovich L (2011) Trending: The promises and the challenges of big social data. Debates in the Digital Humanities: 1–17.\nTufekci, Z. (2014). Big Questions for Social Media Big Data : Representativeness , Validity and Other Methodological Pitfalls Pre-print."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:aaa372ba-66ac-43d6-bd8d-84299cad42f7>","<urn:uuid:00d7b7cd-4731-46f1-8942-71ce0040f95c>"],"error":null}
{"question":"How do ancient food storage methods compare with seasonal food planning, and what examples show this connection?","answer":"Ancient food storage methods included collecting and drying grain in ceramic pots, air drying or smoking meat and fish, and using salt and sugar as preservatives. These techniques are mirrored in seasonal food planning, as demonstrated by the year-long preparation cycle for a Thanksgiving meal. For example, while ancient cultures preserved food through drying and smoking, modern growers similarly prepare by drying sweet corn in August, storing potatoes from the harvest, and preserving raspberry pie filling and pickled peaches. The connection between preservation and planning is evident in both traditional storage methods and the modern growing calendar, where foods must be planted, harvested, and preserved at specific times to ensure availability for future meals.","context":["If you want to make a traditional Thanksgiving dinner wholly from scratch, you start ahead of time. If you want to make it from food you’ve raised yourself, you start way, way ahead of time – like in January of the year before. In some ways, it starts even earlier, but January is the new year – and when you grow your own, you are always thinking of the future – even if not consciously about any particular dinner.\nIt is in January that we order seeds for the vegetables we’d serve at Thanksgiving, that we debate which varieties of pumpkin and carrots, celery root, sweet corn, squash and leeks we’ll need.\nWe are thinking Thanksgiving, faintly, distantly, in February, when we order turkey poults, or begin watching the turkey hens for signs of setting her eggs, and when we place the order for seed potatoes, or begin organizing last year’s potatoes for replanting. In February the first leek and onion greens have sprouted, and in some abstract sense we know these will appear again, on our tables in autumn.\nWe are thinking vaguely of Thanksgiving in March, when I set sweet potatoes in water on the window to develop slips for next year. And in April when we finally go out on the first warm day and plant potatoes. We are certainly thinking Thanksgiving as the turkey poults hatch or arrive, and as I pull the mulch from my sage and thyme plants.\nWe are thinking Thanksgiving in May, when I carefully start “winter luxury” pie pumpkins in newspaper cups filled with soil, to ensure a healthy supply of pumpkin pie, and when we watch the apple blossoms anxiously on cold nights, to track our future apple pies.\nIn June, when we hoe the corn, we recall that we will want this corn, creamed at the groaning board in November. In July, on hot nights, when the dream of roast turkey seems unappealing, we are still, in some measure, aware of Thanksgiving at the back of our minds as we go out to pick slugs off the squash vines, and pull the garlic that we will use to flavor the potatoes.\nIn August, we know that summer is winding down, and it is in small part Thanksgiving that we are driving towards as the turkeys range around the yard chasing bugs and we are putting up raspberry pie filling and pickled peaches. We dry the sweet corn, after we devour our fill, thinking, again, of days to come.\nIn September, as the first breath of cool air floats through the barnyard, we’re thinking Thanksgiving as we dig potatoes and watch for frost, hoping for a few more nights to ripen the pumpkins to rich netted orange, a little more sizing up for the Hubbard Squash, already huge and warty and green.\nIn October, as the day approaches and the turkeys reach maturity, Thanksgiving appears from the back of our minds and occasionally touches the fronts. When will the turkeys be ready for butchering? When can the ones we’ve sold be picked up, and do we have enough freezer space? We pull a parsnip from the ground and taste its frost-sweetened flavor in anticipation.\nNovember, of course, is the culmination of our efforts – we mash and roast and sauce and sautee. The turkey gets the most attention, but Thanksgiving is the feast of roots, the only time we, as a nation, all fully celebrate those under-loved vegetables that come up from the ground. It is the only meal many Americans actually cook for themselves, and sit down with family for. At our house, we have done most of the long anticipatory work, and we rest on our laurels – at least until it is time to cook.\nWhat are you eating this week?","Organic Food Preservation Definition, Importance, & Methods\nFood preservation has long been a necessary pursuit of humans through the ages. While short term food preservation methods are largely dominated by today’s refrigerators, and long term preservation is dominated by canning or freezing, our ancient cultures thrived without such technology by collecting, drying and storing grain in large ceramic pots. Hunter-gatherers preserved meat and fish by air drying or smoking. Salt and sugar, when readily available, were also used as a preservative.\nPreserving food without canning or freezing or refrigerators?\nCountless methods and technologies of food preservation have been attempted through the millennia and a few tried and true methods that are natural and sustainable have been passed through generations. These techniques are part of food preservation history are of course, organic, and still applicable and useful in modern sustainable living.\nPreserving meat through drying.\nThis most ancient form of food preservation is simply the removal of water from any given food by air drying, sun drying, or smoking. Commercially available food dehydrators or a home oven can also be used to preserve food. Nearly all foods can be preserved through drying including meat (jerky), grains, fruits, vegetables, fungi, and even milk. Smoking, is part of the food drying method.\nCuring is a method of preserving food, most often meat and fish, by the addition of salt, nitrates, or sugar. Salt-cured meat works by inhibiting the growth of microorganisms by drawing water out of cells through osmosis. Concentrations of salt up to 20% are required to kill most species of bacteria and smoking the meat adds additional chemicals that reduce the amount of salt required. Common examples of salt-cured meat include bacon, kippered herring, corned beef, and pastrami. Olives, pictured above, are easily preserved through the salt curing method as well.\nSugaring is a method that places dehydrated food into pure sugar. The purpose of sugaring is to create an environment hostile to microorganisms. Sugaring is commonly used to preserve fruits and their peels as well as spices such as ginger root.\nAlso known as brining, pickling is the process of preserving food by anaerobic fermentation in brine (a solution of salt in water) to produce lactic acid, or marinating and storing it in an acid solution such as vinegar. The resulting food is called a pickle and can be any variety of food item including eggs, peppers, cucumbers, or even citrus fruits.\nThe use of nontoxic and beneficial microorganisms can also preserve food. An ancient form of bio-preservation is fermentation which was, and still is, used to produce beer, wine, vinegar, bread, yogurt, cheese, and butter. All of these items can still be produced in the home kitchen using biopreservation techniques.\nFor short term food preservation methods, simple technologies such as the zeer pot, submersion in water (such as a lake or river) and the use of cool caves or underground pits extend the expiration of many perishable foods. These techniques of course can be employed today as well, some more fitting in certain climates than others. -KATHY FAIRCHILD"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:03c3f732-af9d-4de4-a573-9ba1e2d88184>","<urn:uuid:263d2c1b-5823-42bd-b845-c8cbcfca9ace>"],"error":null}
{"question":"What was the significance of summits in diplomatic history, and how did personal relationships impact the Grand Alliance during WW2?","answer":"Summits have been crucial diplomatic meetings between world leaders, with the term coined by Winston Churchill. The concept became particularly important during major historical events like WWII. During WWII, the Grand Alliance between Britain, the US, and Soviet Union became one of history's most successful alliances, largely due to personal relationships between the leaders. Despite their different socio-political systems and ideological conflicts, the Big Three - Churchill, Roosevelt, and Stalin - put aside differences for a greater cause. Personal contact through meetings, correspondence, and intermediaries convinced them they could work together and trust each other. The relationship between Churchill and Stalin was particularly significant, with Stalin even toasting Churchill as his 'comrade-in-arms' and maintaining affection for him even after their political split.","context":["By David Reynolds\nRead Online or Download Summits: Six Meetings That Shaped the Twentieth Century PDF\nBest diplomacy books\nThe transformation of the BRIC acronym from an funding time period right into a family identify of overseas politics and, extra lately, right into a semi-institutionalized political outfit (called BRICS, with a capital ‘S’), is likely one of the defining advancements in foreign politics long ago decade. whereas the concept that is now familiar within the basic public debate and foreign media, there has now not but been a accomplished and scholarly research of the historical past of the BRICS time period.\nThis e-book investigates relatives among Israel, the Palestinian territories and the ecu Union by way of contemplating them as interlinked entities, with kinfolk among any of the 3 events affecting the opposite facet. The members to this edited quantity discover diverse elements of Israeli-Palestinian-European Union interconnectedness.\nThis booklet, in its attempt to formulate compatibility among Islamic legislation and the foundations of foreign diplomatic legislations, argues that the necessity to harmonize the 2 criminal platforms and feature an intensive cross-cultural knowing among international locations more often than not in an effort to bettering unfettered diplomatic cooperation might be of paramount precedence.\nThe chilly battle ruled global heritage for almost part a century, locking superpowers in an international contention that in simple terms ended with the Soviet cave in. the main decisive moments of twentieth-century international relations happened whilst global leaders met face to face—from the mishandled summit in Munich, 1938, which prompted the second one international conflict, to Ronald Reagan's amazing chemistry with Mikhail Gorbachev at Geneva in 1985.\n- Diplomacy and the Making of World Politics\n- Choices: Inside the Making of India’s Foreign Policy\n- Human Rights at the UN: The Political History of Universal Justice\n- Palgrave Advances in Development Studies\n- The Culture of Diplomacy: Britain in Europe, c. 1750-1830\n- Jazz Diplomacy: Promoting America in the Cold War Era (American Made Music Series)\nExtra info for Summits: Six Meetings That Shaped the Twentieth Century\n44 It turned into a very long diplomatic dance. S. 45 Because the Allies were not ready, the peace conference did not begin for nearly a month after his arrival in Europe. And, although the preliminary conference proved the only one, the complex issues at stake and the conflicting interests of twenty-eight delegations made agreement very hard to reach. In retrospect it is easy to criticize Wilson’s approach to the negotiations. Although he had established a think tank of academics and journalists known as “The Inquiry” back in September 1917, which drew up a multitude of useful background papers, he made much less use of his technical advisors than did the British.\nPhilippe de Commines, c. 1490 INTRODUCTION THE TERM “SUMMIT” was coined by Winston Churchill. ” What prompted Churchill to apply “summit” to diplomacy is not clear, but the word was popping up in British newspapers because expeditions to scale Mount Everest, the world’s highest peak, had resumed in the late 1940s. ” He delivered this speech to the House of Commons while the eighth attempt on Everest was in progress: the summit was finally conquered at the end of that month. 1 The Everest obsession helps explain why Churchill’s metaphor rooted itself in popular consciousness.\n5 In 1096 and 1097 the emperor Alexis Comnenos made a point of meeting the leaders of the First Crusade in his own palace, as did Manuel Comnenos when the Second Crusade arrived in 1147. But when Byzantium spiralled into decline in the fourteenth century, its emperors became as mobile as those of the late Roman Empire, and much less potent. Emperor Manuel II was reduced to touring the courts of Italy, France, Germany and England for help against the Ottoman Turks, handing out precious books and pieces of the supposed tunic of Christ as inducements.","Churchill and Stalin: Comrades-in-Arms during World War TwoHistorians/History\ntags: military history, Winston Churchill, Joseph Stalin, World War 2\nGeoffrey Roberts is Emeritus Professor of History at University College Cork, Ireland. His book (co-authored by Martin Folly and the Oleg Rzheshevsky) Churchill and Stalin: Comrades-in-Arms during the Second World Waris published by Pen & Sword Books.\nThe alliance of Britain, the United States and the Soviet Unionduring World War II is often presented as a fragile necessity. The alliance was forced into existence by Hitler and fell apart as soon as Nazi Germany was defeated. But neither the formation of what Churchill later called the Grand Alliance nor its collapse was inevitable. The Grand Alliance was willed into existence by its leaders and then sustained through four years of total war. It was one the most successful alliances in history.\nWhen the Grand Alliance emerged following the US and Soviet entry into the war in 1941, it was not clear that such an unlikely coalition could survive the vicissitudes of war. The three countries had very different socio-political systems and there was a long history of ideological conflict between Soviet communism and western liberal democracy. Within western states there were anti-communists hostile to alliance with the old ideological enemy, while on the Soviet side there were deep suspicions of western capitalist leaders. The Grand Alliance also had to deal with Hitler’s efforts to sow seeds of doubt by spreading rumours that each of the allies was negotiating a separate peace with the Germans.\nThere were significant internal tensions during the coalition’s early years, mainly because most of the fighting was being done by the Red Army, while the British and Americans fought on the margins of the conflict. But increasing amounts of western material aid did reach the USSR beginning in 1943, and in June 1944 the western allies invaded northern France – an operation Moscow had been demanding since July 1941.\nThe Grand Alliance overcame these difficulties because of the leadership of the so-called Big Three: Winston Churchill, Franklin Delano Roosevelt and Joseph Stalin – leaders prepared to put aside ideological differences in the interests of a greater cause. The social background, personalities, politics, leadership styles and working methods of the Big Three were diverse. But they had one important trait in common: they were men of long political experience who placed a high premium on personal relations with each other.\nPersonal contact between the three leaders – at meetings, through correspondence and via intermediaries – convinced them they could work together and trust each other. At times that trust and friendship was strained but difficulties were overcome and differences resolved through compromises that respected honour and protected vital interests. The Grand Alliance as it developed during the war is unimaginable without this personal bond between Churchill, Roosevelt and Stalin.\nPower in the Grand Alliance lay with Roosevelt and Stalin. As Churchill famously said, it was the Red Army that tore the guts out of Hitler’s war machine, while it was American industrial might and manpower that tipped the balance of forces decisively in the allies’ favour. But the beating heart of the Grand Alliance was Churchill’s relationship with Stalin. As US ambassador Averell Harriman recalled, while Stalin admired and respected Roosevelt and praised him as a “great man for war and a great man for peace”, Churchill he toasted as “my comrade-in-arms.”\nStalin’s relations with Churchill were fragile but intimate and intense. Churchill was a mercurial personality and his relations with Stalin were volatile. He had a history of militant anti-Bolshevism and was unapologetic about it. Yet Stalin, a dedicated communist, wanted Churchill to win the 1945 British General Election and was shocked when he lost and did not return to the Potsdam summit after going home for the counting of the votes.\nDuring the war the two men conducted a 500-message correspondence (two-thirds of the messages were Churchill’s) and Churchill travelled twice to Moscow – in August 1942 and October 1944 - for crucial bilateral meetings with Stalin. Famously, during their October bilateral the two men divided central and southern Europe into percentage-based British and Soviet spheres of influence.\nAt Yalta in 1945 the Big Three proclaimed their commitment to a peacetime Grand Alliance that would prevent war and provide peace, security and prosperity for all states – a goal reaffirmed by the Potsdam summit and at the founding conference of the United Nations in San Francisco. After the war the collaboration continued. Major Nazi war criminals were tried at Nuremburg and convicted of crimes against humanity and of conspiracy to wage aggressive war. A peace conference was convened in Paris in summer 1946, and in 1947 peace treaties were signed with the Nazis’ wartime allies – Bulgaria, Finland, Hungary Italy and Romania.\nEven when Stalin clashed publicly with Churchill following the now ex-Premier’s “Iron Curtain” speech in Fulton, Missouri in March 1946, but the two men never lost their affection for each other. When Field Marshal Montgomery visited Moscow in 1947 Stalin took the opportunity to give Monty a message for Churchill saying that he had the happiest memories of working with Britain’s great war leader. Churchill responded: “I always look back on our comradeship together, when so much was at stake, and you can always count on me where the safety of Russia and the fame of its armies are concerned . . . Your life is not only precious to your country, which you saved, but to the friendship between Soviet Russia and the English-speaking world.”\nIt is commonly assumed the cold war was inevitable, that once Hitler was defeated the conflicting interests and ideologies of the Soviet Union and the western powers inexorably drove the two sides apart. Despite his reputation as an early cold warrior, that was not Churchill’s view: the main message of his iron curtain speech was the need for a good understanding with Russia. When he returned to power in Britain in 1951 it was as a peacemaker and an advocate of détente with the USSR. Jaw-jaw is always better then war-war, he said.\nNor was the cold war Stalin’s choice. Throughout the war the Soviet dictator stressed the long-term common interests – economic, political and military - of the partners in the Grand Alliance. An avid reader of historical works, Stalin told Churchill and Roosevelt at Yalta that “in the history of diplomacy I know of no such close alliance of three Great Powers as this.”\nIn spring 1947 the inter-allied Council of Foreign Ministers met in Moscow to negotiate Germany’s future. By the end of the year, however, negotiations about a German peace treaty had collapsed and the Grand Alliance was in the later stages of its disintegration. The failure of the Grand Alliance led to the cold war and to decades of division, conflict, and rivalry between the Soviet Union and its erstwhile western allies.\nIn the end the story of the Grand Alliance and its denouement in the cold war is quite simple. During the war its leaders choose to ally against a common enemy and then to carry the coalition forward into peacetime political collaboration. After the war different choices were made – including some by Stalin and Churchill – to pursue the separate as opposed to the common interests of the Grand Alliance. The result was the cold war.\nThe first set of choices saved the world from Hitler and the Nazis. The second set of choices plunged the world into decades of a potentially catastrophic conflict, whose vast nuclear arsenals continue to pose an existential threat to humanity.\ncomments powered by Disqus\n- Archivists Are Mining Parler Metadata to Pinpoint Crimes at the Capitol\n- ‘World’s Greatest Athlete’ Jim Thorpe Was Wronged by Bigotry. The IOC Must Correct the Record\n- Black Southerners are Wielding Political Power that was Denied their Parents and Grandparents\n- Israeli Rights Group: Nation Isn't a Democracy but an \"Apartheid Regime\"\n- Capitol Riot: The 48 Hours that Echoed Generations of Southern Conflict\n- Resolution of the Conference on Faith and History: Executive Board Response to the Assault on the U.S. Capitol\n- By the People, for the People, but Not Necessarily Open to the People\n- Wealthy Bankers And Businessmen Plotted To Overthrow FDR. A Retired General Foiled It\n- Ole Miss Doubles Down on Professor's Termination\n- How Fear Took Over the American Suburbs"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:c9446eab-5a86-4914-a89b-ae403b3b5dd5>","<urn:uuid:490e9bed-bb6d-457d-8da1-16625c4cddb3>"],"error":null}
{"question":"Can you compare AFAD's rescue work methodology with the standard incident management processes? Super curious about how they align! 📋","answer":"AFAD's rescue methodology involves detailed, careful work 'like an archaeologist' during wreckage operations, using supporting elements to prevent new crashes and following systematic procedures. This aligns with standard incident management processes which require directing, controlling, and coordinating response operations through established procedures, including maintenance of measures and periodic reviews. Both approaches emphasize the importance of training, with AFAD providing continuous training to staff and other organizations, while incident management systems stress regular testing and practice of procedures to maintain skill levels.","context":["Turkey in disaster management rather than crisis management model of \"risk management\" approach is adopted. With this model called \"Integrated Disaster Management System\", it is possible to identify dangers and risks in advance to prevent damages caused by disasters and emergencies, to prevent or minimize damages that may occur before a disaster, to ensure effective response and coordination, and to ensure that post-disaster recovery works are carried out in integrity. is foreseen to be executed.\nRecently, especially giving weight to the plan for the reduction of disaster risk AFAD, on the other hand, within the framework of Turkey Disaster Response Plan, develop intervention strategies for all kinds of disasters.\nThe systematic and decisive work carried out by AFAD in the field of response to disasters has a positive effect on the success of the staff, especially in search and rescue work in wreckage.\nAFAD personnel, who are experts in the search and rescue class, increase their professional capacities with refresher training, while at the same time providing trainings to the personnel of institutions and organizations.\nAFAD Staff Working in Elazig and Izmir Earthquakes Explained\nAnkara AFAD Directorate staff Ramazan Yerli said that he took part in both of the earthquakes that occurred in Elazig and Izmir last year.\nIndicating that as the AFAD Ankara team, they carried out 14 hours of search and rescue work in the wreckage of a building in the Mustafa Paşa District of Elazığ, Yerli said that they pulled a woman out of the wreckage as injured and reached the funeral of 8 people.\nIndicating that he was personally involved in the rescue work of a survivor, Yerli pointed out that a mistake made while removing a casualty from under the wreckage could lead to irreparable consequences.\nStating that AFAD has a staff of 20 years, Yerli said, \"When you are carrying out rescue activities in the wreck site, you need to do fine detailed work like an archaeologist.\" said.\nYerli said the following regarding the work to save the woman alive from the wreckage in Elazığ: “The lady was between her mother and her other relative. The bedroom cupboard was knocked over on its side. The wardrobe had created a life gap for him to survive. The condition of the building after the demolition was very bad. In our words, it had a form of collapse that did not contain huge gaps for a person to live. Being instrumental in saving a person's life gives people happiness that cannot be described. I have been working in this business for 20 years. I have come across many times in rescue operations like this. Same feeling of happiness every time. Even if you work for days, that tiredness disappears. There is an enthusiasm to work to see if I can save someone else. \"\nThe Hero of İdil, One of the Symbol Names of Izmir Earthquake\nIf in Izmir Bayraklı Indicating that he was working in the wreckage of the Emrah Apartment in the district, Yerli explained that they carried out uninterrupted search and rescue activities for 2,5 days.\nIndicating that they reached the funerals of many citizens in these studies, Yerli said that they were despaired for a moment because they could not bring anyone alive during their work.\nYerli stated that as a result of a technical search, the location of İdil Şirin, 14 years old, was determined and they started an effort to save her without wasting time.\nIndicating that Sirin was very close to her in the studies, Yerli reported that they used supporting elements in the wreck to prevent new crashes.\nRamazan Yerli explained what he experienced at that moment as follows: “Our daughter's feet were stuck under the seat. We opened a safe passage from the foot area and freed our daughter's feet. The medical staff made the necessary medical intervention. I, firefighters and friends from my team, and we took our daughter out of there safely. We were very happy. We pulled our daughter out of the wreckage after 58 hours. At the end of the study, I went to a secluded area and cried. Even today I get sad when I think of it. Because I have two daughters of the same age. In our profession, we do not actually put people in your relatives' shoes, but this is not possible in some cases. We are trying to get rid of this feeling by taking breaks without affecting our work. \"\nThe local said they kept the hope of removing the injured person until the wreck was removed.\nIndicating that a cat was rescued alive from the wreckage of Emrah Apartment, Yerli said, “Our life saving efforts are valid for all living things. We carry out our search and rescue activities by observing the same sensitivity for all of them. We do not understand that 'this is an animal, let's skip this'. We carry out activities to save everything that is alive. \" said.\nCall for \"Become an AFAD Volunteer\"\n2021 in Turkey \"Disaster Education Year\" reminiscent declared indigenous, pre-disaster in this context, as well, and with citizens about whether that should be done on or after the said training to the staff of public institutions and organizations.\nIndicating that AFAD teams also receive continuous training on disasters, Yerli explained that a study was carried out to search for the victim with a voice and eye in a building wreck in the training area.\nThe local also invited citizens to participate in AFAD's Volunteering Project.","Implementing Incident Management in Emergency Management\nAll organizations must have an emergency plan in place that includes resources, roles and responsibilities, procedures, logistics and contractual arrangement for an EOC (NFPA® 1600 , 2013, p. 12). The Emergency Operations Center is a physical location near the incident where the incident response will be coordinated. From the FEMA goals, it is understood that emergency management programs prioritizes the overall coordination of an incident response. Although it is essential to minimize loss of life and impact to the environment or biodiversity, it may be more beneficial in the long term to prevent incidents from occurring. According to the NFPA® 1600 “[t]he entity shall develop an incident management system to direct, control, and coordinate response, continuity, and recovery operations”. Incident management is however more than coordinating the response, continuity, and recovery operations. The following three risk management processes are vital in implementing incident management in an organization:\nTogether these three risk management processes form a “line of sight” for emergency management personnel.\nHindsight: Root cause analysis\nAll incidents, regardless of severity must be investigated to ensure that maintenance of measures were conducted, that all risks were identified, and that the incident was not an indicator of a change in circumstances that may warrant a full risk assessment review. Root cause analysis is backward looking and aims to discover control inefficiencies and failures so that these can be corrected as appropriate. Successes and strengths must be considers as well so that these can be enforced.\nThere are many tools and standardized methods that can be used for root cause analysis. One such method is a fault tree analysis (FTA). An FTA is a process where all causal factors are identified and associated with the incident to determine a hierarchy of failures leading from the event backwards to find the root of the problem or failure. As with all assessment methodologies, FTA’s have a number of limitations and strengths to consider. Although it provides an easy method to visually determine causal factors and binary failures, it does not consider time-frames of each factor, and is challenging to compute combined factors leading to a significant amount of uncertainty in estimating probabilities.\nNevertheless, FTA’s present a diagram that may be used to prioritize research activities and control design corrections. The lessons learned from root cause analysis is documented and incorporated to improve or renew measures, best practices, and training programs to educate responders, the public, and government of emerging issues and incident trends. Root cause analysis is applied to failures and successes to learn everything that is relevant to both outcomes.\nInsight: Control assurance.\nAll prevention measures should be maintained, monitored, and reviewed periodically as these measures prevent incidents from occurring, and are the first indicators that incident severity or frequencies are increasing. Examples of preventive measures may include equipment and machinery maintenance, periodic procedural reviews, policy implementation, management review, structural, automated, and managerial control testing, and independent auditing. Prevention measures should include compensating measures so that a secondary measure can partially prevent consequences when a primary measure fails.\nThe processes and procedures for hazard mitigation measures should also be tested and practiced to maintain skill levels. Specialized equipment and machinery must be maintained so that they are reliable in a time of crisis, to avoid deployment errors or a skills shortage. High frequency incidents may have a predefined emergency response plan that fits the type of incident. These plans must also be tested regularly, and stakeholder feedback should be reviewed to ensure effectiveness so that the plan remains adequate for the incident scenario.\nForesight: Risk assessment\nRisk assessment must be future oriented and should consider all that is known, and all that is uncertain. Risk assessment explicitly addresses future uncertainty and all potential threats, sources of risk, events, causes, consequences and likelihood of occurrence must be identified so that incidents can be prevented, consequences mitigated, property and the public protected. Risk assessment is reviewed periodically, especially when an incident occurs to determine if there has been an unidentified risk or a change in circumstances that presents new, different, or additional risk.\nA risk assessment should consider quantitative data and qualitative criteria, and an appropriate risk assessment methodology should be selected that fits the context of the incident. There are many methodologies for estimating the consequence and likelihood of impacts following an incident.\nEvent Tree Analysis (ETA) is a graphical representation of sequential and mutually exclusive events that may follow an incident. Criteria to calculate the severity, magnitude, and probability of events can be applied qualitatively or quantitatively depending on available data, resources and time. The ETA represent potential consequences that may impact public safety, the environment, and economy, and is used to develop an incident action plan."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"}],"document_ids":["<urn:uuid:cdbae77f-78bc-4d9d-b212-f4b0a19020d4>","<urn:uuid:8263cc36-a195-4967-8c02-50d66b85f7f7>"],"error":null}
{"question":"I want to know details of Desert Mountain Energy's March 2023 over-allotment option. How much money raised and what was price per unit?","answer":"In March 2023, Desert Mountain Energy closed an over-allotment option that raised additional gross proceeds of $1 million. The over-allotment involved issuing 1,666,667 units at $0.60 per unit. This followed their earlier public offering which had raised approximately $2.8 million through issuing 4,666,666 units at the same price.","context":["Desert Mountain Energy Corp - DMEHF stock\nOTC Market: DMEHF • Industry: Oil\nDesert Mountain Energy Corp. (OTC: DMEHF, TSXV: DME) is a company that explores and develops oil and gas as well as mineral properties internationally, including the United States and Canada. Its primary interest is in the Holbrook Basin helium project, which spans an area of 74,421 acres located in Eastern Arizona. The company was previously named African Queen Mines Ltd. but changed its name to Desert Mountain Energy Corp. in April 2018. It was founded in 2008 and is headquartered in Vancouver, Canada.\nDMEHF operates through several subsidiaries, including Desert Energy Corp. and Saguaro Family Land Company. The company has a strong management team with significant experience in the oil and gas industry. In terms of operations, DMEHF focuses on the exploration, development, and processing of helium and noble gas reserves through drilling and production activities. The company utilizes advanced technologies and techniques, such as horizontal drilling, etc. Overall, Desert Mountain Energy Corp. (DMEHF) is a growing exploration and production company with a strong portfolio of assets and a commitment to safe and responsible operations.\nHolbrook Basin Helium Project\nThe Holbrook Basin Helium Project is Desert Mountain Energy Corp.'s flagship project, covering a large land area of 149,480 acres in Northern Arizona, USA. The project aims to discover and develop new sources of helium, a valuable and increasingly in-demand resource that has various industrial, medical, and scientific applications. Desert Mountain Energy Corp. has conducted extensive exploration activities in the Holbrook Basin area and has identified several potential helium-bearing structures in the region. The company has drilled and tested a series of exploration wells to gather data and assess the commercial viability of the project. The Holbrook Basin Helium Project is strategically located near existing natural gas infrastructure, which provides access to the necessary equipment and facilities to extract and process helium. Desert Mountain Energy Corp. believes that the Holbrook Basin area has the potential to become a significant source of helium for the United States and international markets.\nDesert Mountain Energy Corp. has secured additional acreage for its Holbrook Basin Helium Project in Northern Arizona, USA. The company has acquired a 160-acre parcel of land adjacent to its existing leasehold, increasing its total land position in the region to 149,640 acres. Desert Mountain Energy Corp. has identified the Holbrook Basin area as a potential significant source of helium, and the additional acreage is expected to further enhance the company's exploration and development efforts. The new parcel of land has been identified as having significant potential for helium-bearing structures, and the company plans to conduct additional exploration activities in the area. The acquisition of the new acreage was completed through a cash deal, and the company has indicated that it was purchased at a favorable price.\nIn addition to its flagship Holbrook Basin Helium Project, Desert Mountain Energy Corp. also has an interest in exploring and developing other noble gases, including neon, argon, krypton, and xenon. These gases have various industrial, scientific, and medical applications and are in growing demand worldwide. Desert Mountain Energy Corp. holds an interest in the Kight-Gilcrease Sand Unit, a project located in Oklahoma, USA, which has been identified as a potential source of helium, neon, and other noble gases. The company has conducted an airborne geophysical survey in the region to identify and map the potential resources and has subsequently drilled and tested several exploration wells. The company believes that the Kight-Gilcrease Sand Unit has the potential to become a significant source of neon, argon, krypton, and xenon for the United States and international markets. Desert Mountain Energy Corp. is committed to exploring and developing these resources in an environmentally responsible and sustainable manner, while maintaining the highest standards of health, safety, and environmental protection.\nIn March, 2023, Desert Mountain announced the closing of an over-allotment option that was exercised by its underwriters, resulting in additional gross proceeds of $1 million. The over-allotment option was exercised following the company's public offering of units, which closed in late January 2021. The public offering involved the issuance of units, each consisting of one common share and one-half of one common share purchase warrant. The company initially issued 4,666,666 units at a price of $0.60 per unit, for gross proceeds of approximately $2.8 million. The over-allotment option involved the issuance of an additional 1,666,667 units at the same price, resulting in additional gross proceeds of $1 million. Desert Mountain Energy Corp. has indicated that the additional funds will be used for general corporate purposes, including exploration and development activities at its Holbrook Basin Helium Project and other properties.\nDesert Mountain Energy Corp. operates with the aim of developing energy resources in an environmentally responsible and sustainable manner. It has implemented innovative and eco-friendly drilling technologies to minimize its environmental impact. The company is committed to conducting its operations in compliance with applicable laws and regulations, while maintaining the highest standards of health, safety, and environmental protection. The company has implemented several programs and initiatives to ensure that its operations are conducted safely and responsibly, including the use of advanced technologies to minimize environmental impacts.\nIn 2020, DMEHF obtained a permit from the AOGCC for the construction of a well in the city of Flagstaff to help in their business operations. The city of Flagstaff filed a complaint against the company afterward, citing a breach of contract and that the company would pollute the well by injecting harmful materials and thus disrupt the local water source. After numerous proceedings, in 2022, a court in Coconino County, AZ dismissed every claim filed against the Company by the City of Flagstaff except one breach of contract claim, regarding a prior licensing agreement.\n- ↑ Yahoo Finance. DMEHF Stock Profile. Retrieved on 5/2/2023.\n- ↑ 2.0 2.1 Desert Mountain Energy. About Desert Mountain. Accessed on 12/21/2022\n- ↑ desertmountainenergy.com. Holbrook Basin Helium Project. Retrieved on 5/2/2023.\n- ↑ PRNewswire. DESERT MOUNTAIN ENERGY SECURES ADDITIONAL ACREAGE. Apr 17, 2023.\n- ↑ desertmountainenergy.com. Hydrogen Projects. Retrieved on 5/2/2023.\n- ↑ newsire.ca. DESERT MOUNTAIN ENERGY ANNOUNCES CLOSING OF OVER-ALLOTMENT OPTION FOR ADDITIONAL GROSS PROCEEDS OF $1 MILLION. March 31, 2023.\n- ↑ Casetext.com. Desert Mountain Energy. Accessed on 12/23/2022\n- ↑ PR Newswire. COURT GRANTS MOTION TO DISMISS CLAIMS AGAINST COMPANY. Accessed on 12/23/2022"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:f098f403-8081-4766-b9d4-8e2fc8abeb7d>"],"error":null}
{"question":"How do spiritual mentorship practices differ between the Nuer people and Yoruba traditions when training new practitioners?","answer":"In Nuer culture, spiritual knowledge is shared within villages through cooperative activities and ceremonies, particularly during abundant food periods from September to December. Meanwhile, in Yoruba tradition, there is a more structured mentorship system where apprentices (ọmọ òòṣà) train under elder priests (olórìṣà). Young Yoruba apprentices typically start training at an early age, performing household chores and assisting in spiritual work in exchange for training. The olórìṣà becomes like a surrogate parent, forming a lifelong relationship. Adult trainees may have a different relationship dynamic and might provide monetary compensation for their training. Both traditions emphasize the transmission of spiritual knowledge, but the Yoruba system has more formal hierarchical structures and defined roles.","context":["E. Evans-Pritchard (1902-1973) was one of England’s most successful social anthropologists reputed for his work on African cultures, witchcraft, and magic. He conducted fieldwork in South Sudan among the Zande and Nuer people, on whom he produced two books: Witchcraft, Oracles, and Magic Among the Azande (1937) and The Nuer (1940). This entry will be looking at the Nuer people, with special interest in their animistic religious beliefs.\nWho Are the Nuer?\nThe Nuer are a cattle-based culture and pastoral society whose members live a nomadic lifestyle in the semi-arid environment of South Sudan. Regarding the Nuer population and organizational structure at the time of writing, Evans-Pritchard and Fortes say that,\n“Most tribes have a population of over 5,000 and the largest number between 30,000 and 45,000 souls. Each tribe is economically self-sufficient, having its own pastures, water-supplies, and fishing reservations, which its members alone have the right to exploit. It has a name which is the symbol of its distinction. The tribesmen have a sense of patriotism: they are proud to be members of their tribe and they consider it superior to other tribes. Each tribe has within it a dominant clan which furnishes a kinship framework on which the political aggregate is built up. Each also regulates independently its age-set organization… It is not possible to give more than a rough indication of the size of a village population, but it may be said to vary from 50 to several hundred souls….” (1)\nThe Nuer engage in agricultural practice, which means they raise livestock, hunt, and collect wild fruits and roots. Their land is, however, more suited for stock-breeding than for agriculture given its flat, dry, savannah like environment. The land experiences heavy rain fall from June to December which causes nearby rivers to overflow. From around December to June there is little rain and the rivers remain at a low level. During the rainy season, the Nuer live in villages located on knolls, ridges, or slightly elevated grounds that permit agriculture. The land between villages is more or less flooded for the full six months during which the Nuer engage in the cultivation of millet and maize, despite much of the land being unsuitable for habitation, agriculture, or grazing. Food is often limited but there is much sharing in the same village, especially among those in adjacent homesteads and hamlets where villagers eat in one another’s homes at feasts and at daily meals. Food is most abundant from the end of September to the middle of December and it is during this time most ceremonies and dances take place. It is also due to the lack of resources and food supply that members of villages are drawn close to each other. Often hunting, fishing, and agricultural tasks are activities that require cooperative effort.\nGod and Symbols of God\nFor the Nuer, God (or Spirit) is seen in the celestial phenomena of the sky and in the material representations of death and pestilence. God is not believed to actually be any one of these phenomena as they are merely signs or refractions of him. No-one, believe the Nuer, knows what God is like in himself although they find it appropriate to use adjectives to refer to his attributes (i.e. “great” or “good”) or metaphors taken from the world (likening God to the wind or air). This belief is based on a duality between kwoth, Spirit, which is immaterial (rather than supernatural), and cak, creation, the material world known to the senses. Rain, lightning, and pestilences belong to the created world and are seen as instruments of God (nyin kwoth). Evans-Pritchard explains that,\n“[P]estilences, murrains, death, and indeed almost any natural phenomenon significant for men are commonly regarded by Nuer as manifestations from above, activities of divine being. Even the Earthly totems are conned of as a relationship deriving from some singular intervention of Spirit from above in human affairs. It is chiefly by these signs that Nuer have knowledge of God” (2).\nRain and pestilence are symbols for Spirit and in the Nuer context a religious symbol has an intimate association with what it represents. They are what one would “call a medium or manifestation or sign of the divine acuity in relation to men and of significance to them” (3). For example, a bird might be considered a symbol for Spirit but the physical bird itself is not Spirit. Instead, depending on the bird’s actions (perhaps by landing on the crown of a byre or on a hut) it may constitute a spiritual sign (of disaster, perhaps). In these phenomena, whether a bird or the rain, the Nuer believe Spirit to be in some way within, or behind, the object or occurrence.\nHierarchy of Spirits and Totem\nThe Nuer also believe in a hierarchy of spirits; as writes Evans-Pritchard,\n“In other words, there are gradations of the conception of Spirit from pure unattached Spirit to Spirit associated with human, animal, and lifeless objects and more and more closely bound to what it is associated with the farther down the scale one goes” (4).\nThere are the “spirits of the below” called the biele (the nature spirits) and the kulangni (fetish spirits), both of whom are believed to have come from above down to Earth. They are also independent of any material forms. The biele is a visible spirit and is believed to be the will-o’-the-wisps, which are strange and mysterious lights that emerge in bushes and in swamps. The kulangni are fetish spirits that live in small bundles of wood. They are not visible like the will-o’-the-wisps but can be in different wood bundles at the same time.\nFurther, some of the Nuer believe in totemic spirits. A totem is either a natural object or an animal believed to have spiritual significance and is sometimes adopted as a tribe’s emblem. The Nuer have great respect for totems because they represent the spirits associated with them. They even sometimes act towards the totem as if a spirit actually lives within it: “Thus they give some meat of the sacrifice of lion-spirits to lions, and when they sacrifice to the durra-bird-spirit they also address the birds themselves and tell them that the victim is for them” (5). Evan-Pritchard refers to the lou serpent totem he says resembles the Loch Ness monster.\nTwins are Special Creations\nIn Nuer culture, twins hold a sacred place as they are believed to be special creations: they are a person of the sky or of the above, a manifestation of Spirit, and a child of God. For the Nuer, the sky or air are where things that belong to God belong. Twins are believed to be one person and also birds,\n“In addition to being men and women they are of a twin-birth, and a twin-birth is a special revelation of Spirit… twins and birds, though for different reasons, are both associated with Spirit and this makes twins, like birds, ‘people of the above’ and ‘children of God’, and hence a bird a suitable symbol in which to express the special relationship in which a twin stands to God” (6).\nThe Nuer do not believe that twins look like birds in the sense of having feathers, a beak, and wings; rather by saying twins are birds they are referring to the “anima of the twin,” namely of his or her personality and soul. Twins are not one individual but one personality. This reveals a triadic relationship between twins, birds, and God: “In respect to God twins and birds have a similar character” (7). Twins are often given the name of a bird such as Gwong (guineafowl) or Ngec (francolin), which further captures their significance as in Nuer culture it is shameful to kill and eat birds or their eggs. It is also shameful to break the eggs of crocodiles and turtles. When an infant twin dies he is said to have “flown away.” He is then covered in a winnowing-tray or a reed basket and placed in the fork of a tree because birds rest in trees. When adult twins die their souls go up into the sky. An adult twin’s body is buried in a grave so that hyenas do not eat it. Should the hyena devour the body and drink from a pool of water, they might contaminate it and cause the death of men.\nA Complex Culture\nOne of the critiques modern scholars have of several formative theorists in the fields of anthropology, sociology, and religion studies is that these theorists presented cultures such as the Nuer as being “primitives” and “savages” but yet failed to take into account their complexity. These so-called primitive cultures were placed on a cultural hierarchy but always below the superior “civilized men” of the Europeans. For example, the British anthropologist E. B. Tylor claimed that animism was the religion of the “savages” that continued to evolve up until the age of “civilized men”, with civilized men being himself and his fellow countrymen who had appreciated the advancement of science and distanced themselves from savage superstitions. These primitive cultures were simply stuck at a lower rung of cultural evolution.\nBut Evans-Pritchard objects. He concedes that to a western mind “It seems odd, if not absurd, to a European when he is told that a twin is a bird as though it were an obvious fact” (8). Equally, to say that the will-o’-the-wisps are Spirit is strange as “For us the light is [merely] a gas arising from swamp vegetation…” and nothing more than that (9). However, Evans-Pritchard still claims to have uncovered a far greater level of intellectual and artistic elocution than theorists like Tylor and others allowed. Speaking of the Nuer, Evans-Pritchard says that this ability,\n“implies experience on an imaginative level of thought where the mind moves in figures, symbols, metaphors, analogies, and many an elaboration of poetic fancy and language… In all their poems and songs also they play on words and images to such an extent that no European can translate them without commentary from Neur… How Nuer delight in playing with words is also seen in the fun they have in making up tongue-twisters, sentences which are difficult to pronounce without a mistake, and slips of the tongue, usually slips in the presence of mothers-in-law, which turn quite ordinary remarks into obscenities… the imagination of this sensitive people finds its sole expression in ideas, images, and worlds” (10).\n1. Fortes, Meyer., and Evans-Pritchard, Edward. 2015. “The Nuer of Southern Sudan.” In African Political Systems. Abingdon: Routledge.\n2. Evans-Pritchard, Edward Evans. 1940. The Nuer: A Description of the Modes of Livelihood and Political Institutions of a Nilotic People. Oxford: Clarendon Press. p. 124.\n3. Evans-Pritchard, Edward. 1940. Ibid. p. 126\n4. Evans-Pritchard, Edward. 1940. Ibid. p. 139\n5. Evans-Pritchard, Edward. 1940. Ibid. p. 133\n6. Evans-Pritchard, Edward. 1940. Ibid. p. 131-132\n7. Evans-Pritchard, Edward. 1940. Ibid. p. 132.\n8. Evans-Pritchard, Edward. 1940. Ibid. p. 137.\n9. Evans-Pritchard, Edward. 1940. Ibid. p. 137.\n10. Evans-Pritchard, Edward. 1940. Ibid. p. 142-143","This is an interview with Nathan Lugo Olóyè Àìkúlọlá Olúwin-Òòs̩à, who is a practitioner of the West African Òrìṣà tradition. He was initiated into Ifá, Ọbàtálá and Egúngún in Nigeria and is living and working as Olórìṣà and Babaláwo in Florida, USA. He is a founding member of the Ìjọ Asáforítifá Òrìṣà Community and promoting Yorùbá culture worldwide. Fluent in the main languages of Òrìṣà worship, Yorùbá, Spanish, Portuguese and English, he is also a well-known expert and researcher of Yorùbá religion in the diaspora. He is one of the few people who know about the Yorùbá art of medicinal tattooing and shares his personal experiences and knowledge with us.\nThis interview is now the third one in an ongoing series, published on this blog. The idea is to get different insights from people around the globe involved in Yorùbá culture. People who contribute in their work to the image of Orisha worldwide. Thank you to Nathan Lugo, àwa dúpẹ́ ooo!\nStay connected on www.facebook.com/orishaimage to receive the latest updates.\nThe odù Ìdin Ìlẹ̀kẹ̀ is the sign of the Yorùbá city of Òṣogbo with the Sacred Grove of Ọ̀ṣun.\nMoussa: Nathan, how did you get involved into the world of the Yorùbá Òrìṣà?\nNathan: Hi Moussa. I first came into contact with popular or folk spirituality of the Caribbean as a pre-adolescent. My family is predominantly catholic, like many Puerto Rican families. But folk Catholicism often includes elements of Spiritism. Puerto Rican Spiritism, like other forms of Spiritism in the Caribbean and Latin America, has the influence of African cultural and spiritual retentions so much a part of Puerto Rican culture.\nNathan with Adedoyin Faniyi Olosun, daughter of Adunni Olorisa Susanne Wenger, and her sister Olayiwola Oladunni Olosun, both Oshun priestesses from the city of Oshogbo. ©Nathan Lugo\nThis type of folk Catholicism and Spiritism was what I was exposed to early on, particularly by one of my grandmothers. Also, when I was living in the Bronx, NYC, as a child there was a botánica (spiritual supply store that caters to the needs of practitioners of spiritism and Santeria/ Lucumí/ Afrocuban Òrìṣà tradition) right on the corner of the block of my school. Passing by it gave me curiosity. Eventually I went in, browsed through a few books and glanced over the shelves. Doing some reading on my own I began to feel strongly connected to a spiritual tradition of African origin that felt more empowering and culturally appropriate than the Catholicism of original sin and less-than-meaningful rituals.\nLiving for a time in Puerto Rico on and off during summers I came into contact with some very good people that were practitioners of Òrìṣà tradition – the Cuban expression of it. But at that time I had decided that I just could not participate in the ‘misas’, both spiritist and Catholic, that the Santeria tradition requires. I was also never baptized, and I wasn’t going to go through the rites of a religion that I felt little connection to. My calling was non-Abrahamic African-based spirituality. In addition, my interest in the original language and teachings was not something that would be fulfilled with the practitioners of the Òrìṣà traditions that developed in the Americas who had essentially lost the language and only preserved some compromised Yorùbá language retentions.\nDuring a dance performance of the house of the Ẹlẹ́gùn Ṣàngó of Kòso in Ọ̀yọ́. ©Nathan Lugo\nSo at that time I made the choice to try to make it to Yorùbáland in West Africa. It took me a number of years before I made some reliable contacts though. Because living for some years in North Carolina I also got into contact with practitioners from the Oyotunji African Village. I later found out that theirs is an eclectic blend of Cuban Òrìṣà practice with neo-kemetic (ancient Egyptian) religion, astrology, Cuban Palo, and their own brand of Spiritism and spiritual masses that they call “Egun Joko”.\nIt wasn’t till I was an adult that I met my olúwo of Ifá, chief Fákáyọ̀dé Fáníyì who is the Àgbọngbọ̀n Awo of Òṣogbo, that I found the person that filled the role of spiritual mentor that I had been seeking.\nNathan at an Ọmọlú shrine in Abẹ́òkúta, Ògùn State, Nigeria. ©Nathan Lugo\nWhat is the meaning of your Yorùbá name Olóyè Àìkúlọlá Olúwin-Òòṣà?\nOlóyè means ‘chief’ or titled member of a society. This is because I was awarded the title of Gbáwoníyì Awo of Òṣogbo by my Ifá elders in Òṣogbo, that is a title within Ifá priesthood. In Ọ̀yọ́, among my Ọbàtálá spiritual mentors and elders, I was awarded the title Olúwin-Òòṣà of Ọ̀yọ́ Aláàfin, which is a chieftancy title of the Ọbàtálá priesthood, and especially one with connection to the Aláàfin (king) of Ọ̀yọ́ (ikú, bàbá yèyé). Chieftancy titles can be religious or political, related to the king’s court. My own are religious in nature. Àìkúlọlá is one of the names that were given to me by my elders which means “longevity is wealth.” I have various other names I received during my initiations into Ifá, Ọbàtálá, Egúngún, and even when I received the sacred objects of some of the Òrìṣà that are housed in my personal shrine.\nNathan Lugo during his installation as the Gbáwoníyì of Òṣogbo. ©Nathan Lugo\nIt is my impression that it is common today to do the complete Ifá initiation first, learn about your destiny and later do the Òrìṣà your Odù speaks about. All the young traditionalists I met in Nigeria have Ifá, while the elder generation often ‘only’ had been initiated into one Òrìṣà. For Òyìnbó doing ìtẹfá first seems logical, as you do not inherit family Òrìṣà traditions. I was wondering whether this is also maybe an influence of our modern lifestyle. There are so many options today, that one has to rely on Ifá to get an assurance on what to choose. Did Ifá get popular recently?\nGood question. Some things are a product of Western desires and influences, which I feel strongly we have to be cautious with. Because there is pressure from the West to create a shift in thought and practice that reflects notions and protocols that developed in the Americas. Certainly legitimate work is done for all, so long as one is not involved with individuals that are charlatans. The idea that one can go through ìtẹfá first and then another idóṣù is not new, according to my own teachers.\nÌgbín, the African giant snail, a common type of food among the Yorùbá and also an offering for O̩bàtálá.\nFor instance, it is tradition among Ṣàngó priests that after the idóṣù initiation of Ṣàngó has been performed for someone, that adóṣù, the initiates, must not shave their head again. So those that from birth it has been determined that they should also get initiated into Ifá will go through ìtẹfá first and then later the idóṣù Ṣàngó. I have also spoken to some other priests and priestesses that have indeed gone through two or more idóṣù initiations. There are varied opinions on this and other topics. So one has to be careful about making sweeping statements with regards to initiation procedures.\nBy the way, an Òrìṣà initiation that has cowrie shell divination (ẹ̀ẹrìndínlógún) as part of the initiation procedure also brings forth an Odù that will be a life or destiny reading for the initiate as well. It is not just Ifá initiation that does this. But because, as a result of various dynamics, Ifá divination has gotten a high level of prestige in general Yorùbá society most forget about the validity and ancient sixteen cowrie divination system that has been in Yorùbáland for ages. It is important to be exposed to various types of Òrìṣà priests, babaláwo included, as well as the regional variations that exist in Yorùbáland to have a wider more rounded view.\nAt the Candomblé terreiro Pilão de Prata of Salvador, Bahia, during one of their Orixá festivals. ©Nathan Lugo\nLike many people I got to know Òrìṣà traditions from the Cuban perspective. I was surprised about the less secrecy involved in rituals in Nigeria. On my first day in Òṣogbo I was invited into a “cuarto del santo” and witnessing an Ifá initiation. How is the relationship between the apprentice and the elder olórìṣà usually defined in Yorùbáland?\nI’d like to point out that the idea of the “cuarto del santo” in the Cuban Òrìṣà tradition is not the same as in Yorùbáland. I do not doubt you participated in aspects of an Ifá initiation. But I am certain you were not in the actual igbódù or Ifá grove that is only open to full Ifá initiates. What you witnessed in the room is what is open to just about anyone, in West African Òrìṣà tradition, at least, and in most areas of Yorùbáland.\nYes, that’s true. The ceremony in the Ifá grove was done one day before I came in to meet the ìyàwó in the house.\nThe relationship between the elder olórìṣà and the apprentice, called ọmọ òòṣà or ọmọ awo (the latter term being used mostly for apprentices of a babaláwo or ògbóni priests), may depend upon the relative age and context of the parties. Usually the ọmọ òòṣà that train under an olórìs̩à start from an early age when the child can take care of his most basic feeding and hygiene. In this case, the olórìs̩à becomes a type of surrogate parent. And the relationship will usually last a lifetime, even though one may have several other teachers. The ọmọ òòṣà does household chores as well as hands on help during the spiritual work of the priest or priestess as exchange for the training the student receives. There are also trainees and apprentices that come to an olórìs̩à at different ages so the relationship will be a bit different. But there is still the idea of training under a mentor and support for the work done by the one we are training under. There may also be monetary exchange for training, especially for an adult trainee.\nNathan with his ìyálóòṣà, the late Adùnọlá Àyọ̀ká, and his bàbálóòṣà, Iwíntọla Fáróunbí. ©Nathan Lugo\nYou speak Yorùbá fluently. In incantations words are brought into a sacred context. This is more than just communication, there is a power connected to the sound – or is it the word itself?\nIn Yorùbá spirituality, the power of the spoken word is paramount. When uttering prayers as well as incantations there is plenty of metaphor and play on words. They reveal and activate the latent power within elements of nature, whether plant, animal or mineral. So you can imagine the high degree of emphasis on oral literature, songs, poetry, chants and the like.\nAt a Lógunẹ̀dẹ shrine in Ìbàdàn, Ọ̀yọ́ state. ©Nathan Lugo\nHow accurate does one have to be in the correct pronunciation using words for oògùn, for medicine, or charms?\nThe belief is that the deities can understand any language. But when it comes to incantations there is a need for accuracy in their rendering. Since Yorùbá is a tonal language with a large number of phonemes, it can cause difficulty in learning to speak it. Incantation is “ọ̀fọ̀” in Yorùbá language, but there are various types used for different purposes such as àyájọ́, ìgèdè, etc.\nWhat are these various types of incantations about?\nThere are various types of incantations, and they each have their own names. Some types are the same but simply called by one name among babaláwo and olórìṣà, while others may have an alternate name used by oníṣègùn (herbalists) and/or olórìṣà.\nWorking on fínfín ara, the Yorùbá traditional tattooing technique. ©Nathan Lugo\nMany people know about Yorùbá scarification marks, which – for different reasons – transform bodies. But there is another traditional technique in Nigeria: recently you started to include the art of tattooing for medicinal purposes into your practice. How is this done?\nYes, this year I did some training with an olóòlà, or body artist. In Yorùbá communities in West Africa, this person is a trained individual that usually inherited this trade from his family line. He is the one that performs circumcision for babies, as well as facial and body scarification or tattooing. A number of these incisions may be medicinal.\nI learned this craft on the suggestion and encouragement from a student and friend who is an olórìṣà in the States. He noticed I had a ‘good hand’ when making medicinal incisions. They requested I learn in Yorùbáland the traditional techniques of making permanent body art. I did some training in Ọ̀yọ́, although years ago I received my own traditional Yorùbá tattoos or body art from another olóòlà in Òṣogbo. I also received the traditional tools of the Yorùbá body artist with prayer and instruction as to their care and association with the Òrìṣà Ògún.\nFínfín ara, the Yorùbá traditional tattooing technique, completed. ©Nathan Lugo\nIncisions known as “gbẹ́rẹ́” (gbẹ́rẹ́ sínsín) are a particularly important and common method of administering spiritual and medicinal preparations among many cultures in Africa, the Yorùbá people are certainly no exception. Once the medicine gets in contact with the person’s blood upon insertion it activates the properties of the preparation. The preparations, rubbed into tiny incisions like paper cuts, are prepared from a wide range of natural materials, may or may not include incantations, and can be for purposes of physical healing as well as spiritual effects for victory over adversaries, protection, prosperity, or even enhancing the power of the spoken word, as just a few examples.\nReading ẹ̀ẹrìndínlógún, the cowry shell oracle, and preparing ẹbọ, sacrifices, for clients. ©Nathan Lugo\nIn Broward County in South Florida you run the Ìjọ Asáforítifá, a community for West African Òrìṣà practice. As Òrìṣà worship is strongly connected to music, you produced a DVD entitled “Ọ̀ṣun ni Iye”, a collection of Òrìṣà songs recorded in Òṣogbo, and you also teach oríkì, praise poetry. The Yorùbá traditional way of life is full of all kinds of arts, ranging from singing to tattooing, in honor of the Òrìṣà. Can you tell us about the Ìjọ Asáforítifá?\nÌjọ Asáforítifá is a community that I and a number of my ọmọ Awo / ọmọ Òrìṣà (spiritual apprentices) have created for those seeking Òrìṣà spirituality and culture directly from Yorùbáland in Nigeria and Benin Republic in West Africa. We have members in Brazil, Spain (the Canary Island and mainland Spain), Mexico, Venezuela, and the United States. Ours is one that promotes the plurality of the deities we serve in providing betterment for those seeking healing and empowerment. We train budding priests and priestesses with the tools necessary to fill those roles, including chanting of verses of Odù Ifá and Odù Òòṣà (ẹ̀ẹrìndínlógún), songs for the Òrìṣà, foods, kolanut casting, among others.\nObì – the four-lobbed kolanut used in communication with the Òrìṣà.\nMy olúwo Fákáyọ̀dé Fáníyì was the one that produced the ‘Ọ̀ṣun Ni Iye’ video. I did participate in some dancing within the video. That type of work is important to document the spiritual traditions and culture. There was a time when even our own Òrìṣà community members in Òṣogbo did not realize the importance in doing so. Among the things that have helped Òrìṣà traditions grow in the west has been documentation and dance and music performance as well as other arts.\nThose interested in learning more about us can join out meetup group at https://www.meetup.com/West-African-Orisa-Tradition-and-Yoruba-Language/\nThank you very much for the interview!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:37f375fd-8dd4-4ac3-a334-c9a2865788d3>","<urn:uuid:bab7e4b1-7c51-408c-89e3-068bc39808ca>"],"error":null}
{"question":"Which royal figure witnessed Beat Retreat in Nassau vs who ordered Taps to be played at the WWI Armistice?","answer":"Queen Elizabeth II witnessed one of the most spectacular Beat Retreat performances in Nassau during her official visit to the Bahamas in 1975. In contrast, General John 'Black Jack' Pershing ordered his bugler Hartley Edwards to sound Taps at the end of World War I on November 11, 1918, at the Forest of Compiègne to mark the Armistice.","context":["Some of greatest military manoeuvres in history involved the retreat. The Retreat of Dunkirk during World War II, the March of the Ten Thousand in 401 BC, and even George Washington’s Escape from New York in 1776, all mark times in history when men knew that at the certain time, the battle was to be saved for another day.\nSoldiers spread far and wide, across fields and land, needed to know what to do without voice to tell them. It was invariably the sound of the trumpet or the drum, playing the particular melody of retreat, which gave the signal to fall back or bunker down for the night.\nBahamian Custom of Beat Retreat\nCountless Bahamian traditions, customs, mores and etiquettes have their roots in British conventions that are centuries old.\nOne particular tradition, the tradition of the famous “Beat Retreat” performed by the Royal Bahamas Police Force Band is a breathtaking feast of both sight and sound to behold.\nFor the former British colony, the Bahamas’s history with the tradition of Beat Retreat was purely ceremonial, and still is.\n(The Miami News, Sunday, August 22, 1965)\n(The Palm Beach Post, Sunday, December 4, 1994)\nHistorical Fact: In 1967, the drummers of the Royal Bahamas Police Band wore leopard-skin aprons. The reason for this was due to the British occupation of India. The drummers of the Bahamas saw the Maharajah’s men wearing these leopard aprons. The look was adopted by the Bahamas Police Band according to them Band Director Dennis Morgan.\n(Fort Lauderdale News, Sunday, 11 June, 1967)\nOne of the most spectacular “Beat Retreat” in Nassau was performed for Her Majesty, Queen Elizabeth II, on the occasion of her official visit to Bahamas in 1975\n(Tampa Times, Friday, 21 February, 1975)\n(The Boston Globe, Sunday, 27 June, 1971)\nTHE REAL HISTORY OF THE “BEAT RETREAT”\nOriginally it was known as “watch setting” and was initiated at sunset by the firing of a single round from the evening gun.\nThe ceremony of the Beat Retreat is one of the oldest in British military annals. ￼ In the olden days when military battles ended at sundown its purpose was to collect soldiers and post the guards. Any soldiers outside of the quarters when hearing the sound knew it was the signal to come in or they would be locked out for the night.\nThe original call was performed by drums alone. ￼\nHistory Of Beating Retreat\nBeating Retreat has its origins in the early years of organised warfare when beating or sounding retreat called a halt to the days fighting, a return to camp and the mounting of the guard for the night.\nAn order from the army of James II of England, dated to 18 June 1690, had his drums beating an order for his troops to retreat and a later order, from William III in 1694, read:\n“The Drum Major and Drummers of the Regiment which gives a Captain of the Main Guard are to beat the Retreat through the large street, or as may be ordered.\nThey are to be answered by all the Drummers of the guards, and by four Drummers of each Regiment in their respective Quarters”.\nThe original call of Retreat, to mark the end of the days fighting was beaten on drums as were most battle orders.\nThe use of brass bugles, as military signaling device, came to England in 1764 where it was gradually accepted in the foot regiments.\nThe Massed Bands we see today are a modern innovation, added to provide spectacle, to the Beating Retreat ceremony.","Taps Vs. The Last Post\nA look at two iconic bugle calls\nOf all the bugle signals sounded in the world, the two that stand out as music of remembrance are the American bugle call Taps and its Commonwealth counterpart The Last Post. With the exception of a few, most bugle calls are only a few bars long and are not usually recognized by the general population. To be sure there are calls like Reveille, First Call (heard at Race Tracks), Charge (heard at Baseball games) and the almost recognizable calls for Retreat and To The Color that are sounded to mark the end of the military duty day. But Taps and The Last Post are among the most recognized melodies in the world. Both calls share a similar function in that there are both sounded at the end of the day and for funerals and memorial services.\nTwo good books on the history of the calls can be found in “Twenty-Four Notes That Tap Deep Emotions-The Story of America’s Most Famous Bugle Call” by Jari Villanueva and “The Last Post-Music, Remembrance and the Great War” by Alwyn W. Turner. (Both available though Amazon)\nThe Last Post is one of a number of bugle calls in British military tradition which mark the phases of the day. Where Reveille signaled the start of a soldier’s day, the Last Post signaled its end. It is believed originally to have been part of a more elaborate routine, known in the British Army as Tattoo that had its origins in the 17th century. During the evening, a duty officer had to do the rounds of his unit’s position, checking that the sentry posts were manned and rounding up the off-duty soldiers and packing them off to their beds or billets. He would be accompanied by one or more musicians. The “first post” was sounded when the duty officer started his rounds and, as the party proceeded from post to post, a drum was beat. The drum beats told off-duty soldiers it was time to rest – if the soldiers were billeted in a town, the beats told them it was time to quit the pubs. Tattoo is a derivation of “doe den tap toe”, Dutch for “turn off the taps”, a call which is said to have followed the drum beats in many a Dutch pub while English armies were campaigning through Holland and Flanders in the 1690s. Another bugle call was sounded when the party completed their rounds, when they reached the “last post”: this signaled the night sentries were alert at their posts and gave one last warning to any soldiers still at large that it was time to return to the garrison. One of the first references to the call can be found in the “Preceptor for the Bugle” by J. Hyde published in 1818. It is titled 2nd Post and is written for two buglers. The call is performed as a solo today.\nThe Last Post was incorporated into funeral and memorial services by the late 19th century in England as a final farewell symbolizing that the duty of the dead is over and that they can rest in peace. At funerals and memorial services, The Last Post is followed by the call The Rouse (Reveille). The idea of having a “wake up” call following a somber sounding dates back many years. Stephen Graham wrote two centuries ago, “The Last Post” is the Nunc Dimittis [the promise of salvation as found in Luke 2: 29-32] of the dead soldier. It is the last bugle call…but it gives promise of reveille…\nBy the time the First World War broke out in 1914, The Last Post was part of the British national culture. Mostly it was still associated with soldiers, but increasingly it was also being played at the funerals of civilians such as Wallace Hartley, the bandmaster of the Titanic. During the war, it was sounded countless times at funerals at the front. With mass enlistment and then conscription, the walls that had long existed in Britain between the civilian and the soldier broke down completely, and a piece of music that had once belonged exclusively to military culture was adopted by a wider society. HG Wells said this was “a people’s war”, and the Last Post became the people’s anthem. As memorials were constructed following the war, most notably The Cenotaph and the Unknown Warrior, The Last Post became an integral part of ceremonies honoring those who died in the Great War.\nThe call is sounded every evening at the Menin Gate in Ypres, Belgium. You can read about that here:\nIn the United States, bugle signals dated back to the revolution. Like the British military, American bugle calls were found in printed military tactics manuals around the start of the 19th century. Taps began as a revision for the signal of Extinguish Lights (Lights Out) at the end of the day. Up until the Civil War, the infantry call for Extinguish Lights was printed in the Infantry tactics manuals with the bugle signals taken from the French. The music for Taps was adapted by Army General Daniel Butterfield for his brigade in July, 1862. As the story goes, General Butterfield was not pleased with the call for Extinguish Lights, feeling that the call was too formal to signal the days end. With the help of his brigade bugler, Oliver Willcox Norton (1839-1920), Butterfield wrote Taps to honor his men while in camp at Harrison’s Landing, Virginia, following the Seven Days battle in June, 1862. The new call, first sounded that night in July, 1862, soon spread to other units of the Union Army and was reportedly also used by the Confederates. Taps was made an official bugle call after the war.\nThe highly romantic account of how Butterfield composed the call surfaced in 1898 following a magazine article called “The Trumpet in Camp and Battle,” by Gustav Kobbe, (1857-1918) a music historian and critic. Both Norton and Butterfield responded to the magazine article with their versions on how the call originated.\nMore on the history of Taps can be found at: https://www.tapsbugler.com/an-excerpt-from-twenty-four-notes-that-tap-deep-emotions-the-story-of-americas-most-famous-bugle-call/\nThe original purpose for Taps was to signal Lights out for soldiers. It was called at first Extinguish Lights although it was commonly referred to as Taps (for the three tap beats on a drum to signal lights out). During the Civil War Taps was sounded at a funeral, a practice that was to continue on in an unofficial capacity until 1891 when Taps was formally recognized in the Army manual in name and as the call sounded at funerals. It has been used since at funerals, wreath ceremonies and memorial services.\nBoth calls share things in common. Both are sounded at military funerals and in the evening to mark the end of the day. Both encompass the overtone range of the bugle, although The Last Post uses the low C. Both were written to be sounded on a bugle but are commonly performed on trumpets or cornets. While The Last Post is performed in Bb (concert), Taps is sounded in Bb, G, and sometimes F. Both calls have a dual purpose-to end the day and as an honors piece of music at funerals and memorial services.\nWhile Taps has had many sets of lyrics written to the music, most notably “Day Is Done, Gone The Sun”, there are no official words to the call. The Last Post by its very nature of being a longer call has very few lyrics set. Here is one I’ve found.\nCome home! Come home!\nThe last post is sounding for you to hear.\nAll good soldiers know very well there is nothing to fear while they do what is right, and forget all the worries they have met in their duties through the year. A soldier cannot always be great, but he can be a gentleman and he can be a right good pal to his comrades in his squad.So all you soldiers listen to this – Deal fair by all and you’ll never be amiss.\nBe Brave! Be Just! Be Honest and True Men!\nThe origin of both Taps and The Last Post cannot be traced to any composer. The first reference to the musical notes of Taps are found in the 1835 Infantry Manual prepared by Major General Winfield Scott. Taps is found in the last part of the call The Tattoo. This has been commonly referred to as the Scott Tattoo although General Scott probably did not compose the music. The Last Post can be traced to the “Preceptor for the Bugle” by J. (John) Hyde published in 1818 under the title 2nd Post. Hyde was a trumpeter in the King’s Theatre Orchestra and a fine keyed bugler who was also credited with inventing the English Slide Trumpet. It is not known whether he composed the calls or arranged them. He may have had a hand in both.\nOn November 11, 1918 World War I came to and end with the Armistice that took effect at 11 am. Thus was born the phrase: “The 11th hour of the 11th day of the 11th month.” As the war came to an end bugles were sounded including a rendition of Taps that General John “Black Jack” Pershing ordered performed by his bugler Hartley Edwards. Edwards (known as “Hot Lips”) stood next to a rail car in the Forest of Compiègne and did as he was told. Later, Edwards learned that he blew the call that signified the end of the Great War. He later repeated the call under the Arc de Triomphe in a parade in 1919 as part of the first of many Armistice Day celebrations.\nThere is some disagreement with Edwards’ story as pointed out here:\nIt is not known if The Last Post was sounded at 1100 on November 11, 1918. Certainly buglers would have sounded Stand Fast or Cease Fire. I know of no specific British Bugler that day sounding the calls at 1100. However a French Bugler, Bugle Corporal Pierre Sellier is said to have sounded the call (presumably French) Cease Fire at 1100. According to Time Magazine “the bugle which stopped the World War” was deposited at Les Invalides, the great Paris War Museum. The bugle was donated to Indiana’s War Memorial Museum in 1949 where it is on display today.\nOn a daily basis Taps and The Last Post are sounded at military funerals and memorials services in the United States and the United Kingdom. For 100 nights during the summer Taps is sounded at the Gettysburg National Cemetery in Gettysburg Pennsylvania where Abraham Lincoln delivered his famous address in 1863. At the Menin Gate in Ypres, Belgium Last Post is sounded every evening in a ceremony.\nOn November 11, 2018 thousands of buglers around the world sounded their call of remembrance to mark the centennial of the Armistice.\nYou can download music to Taps, The Last Post and The Rouse by clicking here: Taps Last Post Rouse\nHere are videos of Taps and The Last Post"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:86e32701-9c7c-4f0d-984b-9e5b8916ebf6>","<urn:uuid:77763871-5c21-427c-87d9-21f851b93eda>"],"error":null}
{"question":"Can Ford's advanced manufacturing center's approach to testing new technologies be compared to Honda's development process for ASIMO's capabilities?","answer":"Yes, both share a similar methodical approach to testing and development, though in different contexts. Ford's advanced manufacturing center uses dedicated cells to develop proofs-of-concept for specific pain points, testing various solutions like robots and AGVs in a controlled environment before wider deployment. Similarly, Honda developed ASIMO's capabilities by first identifying three key factors needed (balancing ability, external recognition, and autonomous behavior), then systematically developing and testing the technologies required for each capability. Both companies use specialized facilities and controlled environments to perfect their technologies before broader implementation, though Ford focuses on manufacturing applications while Honda targets humanoid robotics.","context":["Manufacturers stand to reap big benefits by digitizing their operations, not only financially through cost reductions but also operationally, to gain such abilities as being able to fast-track production changes in response to market conditions in real, or near-real, time.\nJonathan Van Wyck, partner and managing director at the Boston Consulting Group, says gains from digitization are too substantial for manufacturers to ignore and that over time it will become the de facto way of competing. The real challenge, he says, is to attain the speed and scale of digitization to operate optimally.\nIn a conversation with Knowledge@Wharton, Van Wyck discusses the opportunities and challenges manufacturers face as they embrace the Internet of Things, advanced robotics, artificial intelligence, data analytics and other technologies. The stakes are high. “If you’re not operating under this new paradigm, you’ll fall behind and ultimately be uncompetitive,” he says.\nAn edited transcript of the conversation follows.\nKnowledge@Wharton: Is digitizing operations an optional move for manufacturing companies or is it becoming a must? What are the main reasons for this?\nJonathan Van Wyck: It is absolutely a must and I think companies are increasingly realizing this. Of the companies that we’ve talked to and surveyed, roughly 80% are actively working on an integrated digital operations program under one overarching vision. The upside that companies are seeing is too great to ignore and over time it will become the de facto way of competing. If you’re not operating under this new paradigm, you’ll fall behind and ultimately be uncompetitive.\nThe impacts we’re seeing — 10% to 20% of value-add production costs coming out, 15% to 30% reduction in working capital, and other results — are too substantial to ignore. What we’ve noticed is that while the opportunity is out there, and there are many individual instances that prove what’s possible, the real challenge is the speed and the scale at which companies are digitizing their operations. We have focused a lot of our research on how you can translate this vision into reality and get benefit at scale.\nKnowledge@Wharton: Could we drill deeper into what manufacturers mean when they talk about digitizing operations? Is it about artificial intelligence and machine learning or is it a broader range of technologies?\nVan Wyck: At the highest level, it’s essentially extending a digital thread across your entire operation’s value chain through product engineering and product design, to supply chain management, how you interact with suppliers, how you manage the logistics to production, the actual manufacturing itself, and all the way, ideally, into distribution and how you support your products in the field. That’s the highest-level definition.\nOnce you unpack that into the underlying technologies, we would say it’s much broader than just artificial intelligence or advanced analytics. We have nine technologies overall ranging from advanced robotics, data capture and the cloud, elements of how you enable the whole opportunity, analytics, machine learning, artificial intelligence, and then some of the tools in the field to activate or access that knowledge, augmented and virtual reality, simulation, and others.\n“The upside that companies are seeing is too great to ignore and over time it will become the de facto way of competing.”\nKnowledge@Wharton: I’d like to go back to what you said about how companies are hoping to cut their production and supply chain costs and also increase their revenues through the use of digital technologies. But they often see mixed results. Why is it hard to digitize operations?\nVan Wyck: There are three main reasons. The first is the degree of change that’s required for the individual actors. For instance, the mindset of a manager in a manufacturing site needs to shift from the traditional way of root-cause analysis to leveraging an advanced analytics dashboard. That’s a big shift. A lot of times change management is underinvested in. While people are given the tools, they’re not given the necessary training and support.\nSecond, the hard part about digital operations is that it cuts across traditional functional silos. The manufacturing organization can’t execute independently. You have to interface with a traditional IT function. You need to oftentimes interact across the manufacturing and supply chain or procurement or even engineering organization to access the full opportunity. That’s something that many companies aren’t set up to do well.\nAnd finally, there is the skills and capabilities piece. It’s very challenging for many manufacturers to hire the skill sets, the data scientists, the designers, and others who are required to execute on this. That creates a big supply limitation on the ability to develop the tools and push them out to the organization.\nKnowledge@Wharton: You referred to the survey that you and your colleagues at BCG have developed to help manufacturers understand where they stand in terms of the speed of implementation, as well as the savings and growth impact of digitization. What have you learned so far from your study?\nVan Wyck: We surveyed about 250 executives and managers from global manufacturing companies across a range of industries. We found that while everyone is working on digitizing their operations, most are frustrated with the speed and the scale at which they’re able to deliver results.\nAlso, companies are currently fixated on attacking production costs. So when people talk of digitizing operations, predominantly they really mean Industry 4.0 in the four walls of the factory. That was an eye opener for us. We learned about some of the challenges that I mentioned earlier and also which use cases are driving predominant value for each industry.\nKnowledge@Wharton: You mentioned that production is where companies are seeing the most potential impact. What are some of the reasons for that?\nVan Wyck: Well, predominantly because it typically sits in one organization. Organizations usually have a manufacturing group, either a global organization or a sub-organization, within each business unit. It’s fully controlled by the company and they can pull the requisite levers to test different things and develop proof-of-concept, etc. Whereas once you get into the supply chain, you’re operating across functional silos of the organization. You have to deal with suppliers or other logistics providers, and oftentimes that’s outsourced, to access the data and to develop the insights. I think that’s the predominant reason why companies are starting with manufacturing.\n“The real challenge is the speed and the scale at which companies are digitizing their operations.”\nKnowledge@Wharton: In which industries have manufacturers made the greatest headway in digitizing their operations?\nVan Wyck: From a production standpoint, i.e. attacking production costs, I think automotive is leading. They were one of the early adopters of robotics and very early adopters of the whole ‘Lean’ concept. They have a very strong foundation upon which to build and are relatively advanced from a manufacturing capabilities standpoint. On top of this, automotive is a very competitive industry. They’re always looking for what’s next in terms of where the opportunities are to increase the year-over-year productivity gains. So that’s where I see the most development on Industry 4.0 at present.\nKnowledge@Wharton: Could you share some examples of companies that have seen the greatest impact on costs and revenues?\nVan Wyck: The Ford Motor Co. is an interesting example. They have set up an advanced manufacturing center with a team that is relatively small but has a range of capabilities and specific technical competencies. For instance, it has additive manufacturing experts, as well as people who understand the manufacturing process. They’ve co-located all of them in an innovation space that has a series of cells set up to develop proofs-of-concept. They take various pain points from the business — from manufacturing plants or different parts of their organization — and they see how they can solve these using digital capabilities.\nOnce they have an idea, they leverage one of the cells to develop the proof-of-concept. So you’ll see different robots there with different end-effectors that are trying to solve different pain points. Or, trying to figure out how do we move materials around the manufacturing center without any labor associated with that. There are different AGVs (Automated Guided Vehicles) operating in a very controlled environment.\nOnce they prove the concept from a feasibility standpoint, they do it in a small setting. And then, they have a package that they can push out to the individual plants. I think that’s an important capability to help jump start the deployment of these individual use cases. It’s hard to expect the individual plants to be able to do that on their own. You often do need some kind of central support to galvanize productivity and progress in this area.\nKnowledge@Wharton: What do you think other manufacturers can learn from auto companies that are starting to implement these digital technologies?\nVan Wyck: One of the big implications is that it requires more centralization, which is, I think, challenging for some companies. Leaving this to the individual business units or even manufacturing sites has proven not to work. Because of challenges around change management, around accessing the skills and capabilities, it requires some degree of central support. Sometimes this runs counter to a company’s operating model or business philosophy.\nAnd that’s, I think, more broadly true within this digital revolution that’s happening in industrial goods. Some level of central support and governance is required to drive digitization at the right speed and with the right level of effectiveness. How do you strike the balance between providing the support that your operations need to do this effectively, in a customer-centric way, and not resulting in additional bureaucracy, is the trade- off that has been critical to manage.\nKnowledge@Wharton: When you look at manufacturers, do you see them struggle primarily with the technology or is it mostly the cultural issues in implementing digital that is the main hurdle?\nVan Wyck: It’s 100% the latter. There are many companies I’ve found with extremely high degrees of sophistication around individual technologies. The problem with Industry 4.0, and with digital operations more broadly, is that it’s not about just implementing one technology.\nIf it was just implementing a technology in their operations, I think companies would be much farther ahead. But it’s about how do you stitch together these technologies into a use case that may have multiple different technologies embedded in it. And then, how do you drive that change into the organization and drive a culture around that with the right skills and capabilities, and the right operating models to support and guide it.\n“At the highest level, it’s essentially extending a digital thread across your entire operation’s value chain.”\nKnowledge@Wharton: Based on your research and your experience, what would you say sets apart manufacturers that are leaders in digitizing operations from those who are lagging behind?\nVan Wyck: We’ve essentially developed 13 different dimensions and we’ve done research around which of these dimensions are most correlated with leaders relative to the laggards in the space. Of the 13, three dimensions have bubbled to the top. The one that correlates the most with both speed of deployment and also value realization is having bold, ambitious, and very clear targets. For instance, companies who are willing to stand up and say, “We expect to see, say, $500 million of benefit through digitizing our operations by 2022.” This is just an example, but basically companies that are much more specific in the targets they set see faster and stronger results than those who are hedging and uncertain about what the benefits may be.\nThe second one is around the technology enablers. Companies that have invested in the necessary IT infrastructure, in data and digital platforms, drive disproportionate value. Third is the organizational capabilities. For instance, companies that added data scientists, UX/UI designers, systems architects, etc. to their teams move faster and see much more value.\nSo, the three most important differentiators are clear and bold targets; investment in the underlying technology infrastructure and the data and digital platform; and investment in the organization and the necessary skill sets. Our research suggests that companies who do these three things well deliver three times as much value and deliver that three times as fast.\nKnowledge@Wharton: What was your biggest surprise in doing this research? Did anything unexpected pop out at you?\nVan Wyck: Yes. Of the 13 dimensions, some were relatively lower than we expected. For instance we thought the higher the digital operations leader is in the organization, the more success you would see. But we found that this was not true. It doesn’t really matter … whether this is a direct CEO responsibility or if this is somewhere deeper in your organization. That was a little counterintuitive to us.\nSimilarly, we expected that companies, from a governance standpoint, with a clear, centralized group managing the overall deployment of digitization, would do better. While [having this group] does have an impact, it definitely was less beneficial than we expected. The takeaway for me is it doesn’t actually matter how you structure the program, as long as you have the three things that I talked about earlier.\nKnowledge@Wharton: If a manufacturing company wants to start digitizing its operations, where should they begin? What would you advise them to do?\nVan Wyck: It depends on your level of conviction around the digital operations opportunity. One model is the ‘factory-of–the-future strategy.’ This is more appropriate when you’re in the exploratory mode. It basically entails taking one physical location and designating it as your ‘factory of the future.’ This becomes the testing ground against which we deploy different use cases and test the results, see what the impact is, see what’s possible when we stitch several use cases together and change the way our company manufactures.\nHowever, if you’re certain of the opportunity and you want to go faster, there is another model you can adopt. In this, you start with narrowing down the technologies, the use cases, and the pain points in your operation. What are the highest priority pain points to be addressed? Is it quality? Is it the labor cost? Is it coordination costs across the supply chain? What are the use cases against these pain points? Prioritize the eight to 10 areas that will drive 80% of the value. Then line up projects with funding against each of those areas. But this requires a level of conviction around getting started that not all organizations have.","While ASIMO may look more-or-less the same as he/she/it always has, the new model encompasses several advancements. For starters, ASIMO longer needs to be controlled by a human – it can walk about and do stuff all on its own, taking in its surroundings and making spatial decisions accordingly. Its new arm and hand mechanisms also allow it to perform delicate and intricate tasks like opening a bottle of water and pouring it into a paper cup without crushing it under the might of its own technological superiority.\nThe long and short of it is that ASIMO – now under the newly-formed Honda Robotics division – will soon be able to do everything a human can, only better. So start stocking the bomb shelter again. Or better yet, let ASIMO do that for you. You've had a long day.\nClick past the jump to let ASIMO pour you a drink and show off some of its newfound skills.\nHonda has unveiled an all-new ASIMO humanoid robot with a world-first technology allowing ASIMO to move without being controlled by an operator. With significantly improved intelligence and the physical ability to adapt to situations, ASIMO has taken another step closer to practical use in an office or public space.\nHonda has also introduced a new task-performing robot arm. This experimental model was developed while applying multi-joint and posture control technologies to ASIMO. This robot arm can be controlled remotely to perform tasks in places which are difficult for people to access.\nTo represent all of Honda's robotic technologies and products such as ASIMO, Honda has established the new collective name 'Honda Robotics'. Under this name Honda will continue the development and research of humanoid robots and will also focus on applying the robotic technologies to mass-produced products and putting them into practical use.\nThe all-new ASIMO has taken a step forward from being an \"automatic machine\" to an \"autonomous machine\". It now has the ability to make decisions based on its surroundings and the movements of people.\nAt the beginning of the development process, the following three factors were identified as necessary for a robot to perform as an autonomous machine:\nHigh level balancing ability - maintaining its posture by putting out its leg in an instant.\nExternal recognition capability - takes in information, such as the movements of people, from multiple sensors and predicts the changes that may take place.\nThe ability to generate autonomous behaviour - making predictions from gathered information and determine the next movement without being controlled by an operator.\nOnce these had been identified Honda went about developing the technologies required to make them possible.\nAdvanced intelligence capability\nHonda has developed a new system that is key for advanced intelligence. The new system continuously evaluates the input from multiple sensors, predicts the situation and then determines the behaviour of the robot. With this technology ASIMO is now capable of responding to the movement of people and the surrounding situations. For instance, ASIMO can now predict the direction a person will walk and quickly determine an alternative path to take if a collision is detected. This technology also enables ASIMO to recognise faces and voices.\nAdvanced physical ability\nThe combination of strengthened legs, an expanded range of leg movement and a newly developed control technology enables ASIMO to change landing positions mid-movement. This new agility also gives ASIMO the flexibility to adapt to changing situations so that it can walk on uneven surfaces.\nImproved task-performing ability\nHonda has developed a highly functional compact multi-fingered hand, which has a tactile sensor and a force sensor imbedded on the palm and in each finger. Combined with the object recognition technology, this multi-fingered hand enables the all-new ASIMO to perform tasks with dexterity, such as picking up a glass bottle and twisting off the cap, or holding a soft paper cup without squashing it. Moreover, ASIMO is now capable of making sign language expressions which require the complex movement of fingers.\nTask-performing robot arm\nTechnologies developed for ASIMO were applied to an experimental model of a task-performing robot arm. The robot arm moves on a self-propelled base and was designed with the idea of being utilised at disaster sites or other places too dangerous for people to work.\nThe stability control technology used for ASIMO's walking and running were applied to stabilise the end of the arm even on unstable surfaces. The application of other ASIMO technologies such as the multi-joint control technology that controls as many as 57 motors imbedded in the joints of the arms and legs, has enabled the robot arm to approach an object and perform necessary tasks even in a narrow space with unstable footing and many obstacles."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:0f00a558-8bbf-41b3-88f4-4a19c5bc9dd5>","<urn:uuid:53898931-f3c7-479a-ac09-8e8707732c0f>"],"error":null}
{"question":"What were the demographic patterns of East German migration after reunification, and how did this movement impact the region's economic development?","answer":"After German reunification, there was significant emigration from East Germany, particularly among young people aged 18-29, with the exodus accelerating in recent years. This demographic trend coincided with severe economic challenges in the east. The eastern German economy largely collapsed after reunification, with most firms proving inefficient and unable to compete on the world market. This led to widespread unemployment and heavy dependence on federal subsidies. The east required massive capital investment in infrastructure like roads, rail lines, and telecommunications to provide a basis for future economic growth. The promise of immediate prosperity and economic equality proved impossible to fulfill, with unemployment and social dislocation continuing to plague the new eastern states more than a decade after reunification.","context":["Regional Labor Markets, Network Externalities and Migration: The Case of German Reunification\nFifteen years after German reunification, the facts about slow regional convergence have born out the prediction of Barro (1991), except that migration out of East Germany has not slowed down. I document that in particular the 18-29 year old are leaving East Germany, and that the emigration has accelerated in recent years. To understand these patterns, I provide an extension of the standard labor search model by allowing for migration and network externalities. In that theory, two equilibria can result: one with a high networking rate, high average labor productivity, low unemployment and no emigration (“West Germany”) and one with a low networking rate, low average labor productivity, high unemployment and a constant rate of emigration (“East Germany”). The model does not imply any obviously sound policies to move from the weakly networked equilibrium to the highly networked equilibrium.\n(This abstract was borrowed from another version of this item.)\nIf you experience problems downloading a file, check if you have the proper application to view it first. In case of further problems read the IDEAS help page. Note that these files are not on the IDEAS site. Please be patient as the files may be large.\nAs the access to this document is restricted, you may want to look for a different version under \"Related research\" (further below) or search for a different version of it.\nVolume (Year): 96 (2006)\nIssue (Month): 2 (May)\n|Contact details of provider:|| Web page: https://www.aeaweb.org/aer/|\nMore information through EDIRC\n|Order Information:||Web: https://www.aeaweb.org/subscribe.html|\nReferences listed on IDEAS\nPlease report citation or reference errors to , or , if you are the registered author of the cited work, log in to your RePEc Author Service profile, click on \"citations\" and make appropriate adjustments.:\n- Nicola Fuchs-Schundeln & Matthias Schundeln, 2005. \"Precautionary Savings and Self-Selection - Evidence from the German Reunification \"Experiment\",\" Harvard Institute of Economic Research Working Papers 2069, Harvard - Institute of Economic Research.\n- Robert J. Barro, 2013.\n\"Inflation and Economic Growth,\"\nAnnals of Economics and Finance,\nSociety for AEF, vol. 14(1), pages 121-144, May.\n- Robert J. Barro, 1995. \"Inflation and Economic Growth,\" NBER Working Papers 5326, National Bureau of Economic Research, Inc.\n- Robert J. Barro, 2012. \"Inflation and Economic Growth,\" CEMA Working Papers 568, China Economics and Management Academy, Central University of Finance and Economics.\n- Cooper,Russell, 1999. \"Coordination Games,\" Cambridge Books, Cambridge University Press, number 9780521570176, February.\n- Richard Rogerson & Robert Shimer & Randall Wright, 2004. \"Search-Theoretic Models of the Labor Market-A Survey,\" NBER Working Papers 10655, National Bureau of Economic Research, Inc.\n- C. Monica Capra & Charles A. Holt, 1999. \"Coordination,\" Southern Economic Journal, Southern Economic Association, vol. 65(3), pages 630-636, January.\n- Michael C. Burda, 2006. \"Factor Reallocation in Eastern Germany after Reunification,\" American Economic Review, American Economic Association, vol. 96(2), pages 368-374, May.\n- Burda, Michael C. & Fuchs-Schündeln, Nikola & Buch, Claudia M. & Sinn, Hans-Werner, 2006. \"Factor reallocation in eastern Germany after reunification,\" Munich Reprints in Economics 19974, University of Munich, Department of Economics.\n- Gabaix, Xavier & Ioannides, Yannis M., 2004. \"The evolution of city size distributions,\" Handbook of Regional and Urban Economics,in: J. V. Henderson & J. F. Thisse (ed.), Handbook of Regional and Urban Economics, edition 1, volume 4, chapter 53, pages 2341-2378 Elsevier.\n- Xavier Gabaix & Yannis M. Ioannides, 2003. \"The Evolution of City Size Distributions,\" Discussion Papers Series, Department of Economics, Tufts University 0310, Department of Economics, Tufts University.\n- Michael Kremer, 1993. \"The O-Ring Theory of Economic Development,\" The Quarterly Journal of Economics, Oxford University Press, vol. 108(3), pages 551-575.\n- Fabio Canova & Morten Ravn, 2000. \"The Macroeconomic Effects of German Unification: Real Adjustments and the Welfare State,\" Review of Economic Dynamics, Elsevier for the Society for Economic Dynamics, vol. 3(3), pages 423-460, July.\n- Canova, Fabio & Ravn, Morten O, 1998. \"The Macroeconomic Effects of German Unification: Real Adjustments and the Welfare State,\" CEPR Discussion Papers 2038, C.E.P.R. Discussion Papers.\n- Fabio Canova & Morten O. Ravn, 2000. \"The macroeconomic effects of German unification: Real adjustments and the welfare state,\" Economics Working Papers 442, Department of Economics and Business, Universitat Pompeu Fabra.\n- Sinn, Gerlinde & Sinn, Hans-Werner, 1992. \"Kaltstart. Volkswirtschaftliche Aspekte der Deutschen Vereinigung,\" Monograph, Mohr Siebeck, Tübingen, edition 2, number urn:isbn:9783161459429.\n- Sinn, Hans-Werner, 2002. \"Germany's Economic Unification: An Assessment after Ten Years,\" Review of International Economics, Wiley Blackwell, vol. 10(1), pages 113-128, February.\n- Hans-Werner Sinn, 2000. \"Germany's Economic Unification: An Assessment after Ten Years,\" NBER Working Papers 7586, National Bureau of Economic Research, Inc.\n- Sinn, Hans-Werner, 2002. \"Germany’s Economic Unification: An Assessment after Ten Years,\" Munich Reprints in Economics 19643, University of Munich, Department of Economics.\n- Hans-Werner Sinn, 2000. \"Germany's Economic Unification. An Assessment after Ten Years,\" CESifo Working Paper Series 247, CESifo Group Munich.\n- Masahisa Fujita & Paul Krugman & Anthony J. Venables, 2001. \"The Spatial Economy: Cities, Regions, and International Trade,\" MIT Press Books, The MIT Press, edition 1, volume 1, number 0262561476, July.\n- Cooper,Russell, 1999. \"Coordination Games,\" Cambridge Books, Cambridge University Press, number 9780521578967, February.\n- Jennifer Hunt, 2006. \"Staunching Emigration from East Germany: Age and the Determinants of Migration,\" Journal of the European Economic Association, MIT Press, vol. 4(5), pages 1014-1037, 09.\n- Burda, Michael C., 2008. \"What kind of shock was it? Regional integration and structural change in Germany after unification,\" Journal of Comparative Economics, Elsevier, vol. 36(4), pages 557-567, December.\n- Michael C. Burda, 2006. \"What kind of shock was it? Regional Integration and Structural Change in Germany after Unification,\" SFB 649 Discussion Papers SFB649DP2006-087, Sonderforschungsbereich 649, Humboldt University, Berlin, Germany.\n- Burda, Michael C., 2007. \"What kind of shock was it? Regional integration and structural change in Germany after unification,\" Kiel Working Papers 1306, Kiel Institute for the World Economy (IfW).\n- Dennis J. Snower & Christian Merkl, 2006. \"The Caring Hand that Cripples: The East German Labor Market after Reunification,\" American Economic Review, American Economic Association, vol. 96(2), pages 375-382, May.\n- Merkl, Christian & Snower, Dennis J., 2006. \"The Caring Hand that Cripples: The East German Labour Market after Reunification,\" CEPR Discussion Papers 5656, C.E.P.R. Discussion Papers.\n- Robert J. Barro & Paul Romer, 1993. \"Economic Growth,\" NBER Books, National Bureau of Economic Research, Inc, number barr93-1.\n- Robert J. Barro & Paul M. Romer, 1991. \"Economic Growth,\" NBER Books, National Bureau of Economic Research, Inc, number barr91-1.\n- Xavier Sala-I-Martin, 1997. \"Transfers, Social Safety Nets, and Economic Growth,\" IMF Staff Papers, Palgrave Macmillan, vol. 44(1), pages 81-102, March.\n- Xavier Sala-i-Martin, 1995. \"Transfers, social safety nets and economic growth,\" Economics Working Papers 139, Department of Economics and Business, Universitat Pompeu Fabra.\n- Michael Spence, 1973. \"Job Market Signaling,\" The Quarterly Journal of Economics, Oxford University Press, vol. 87(3), pages 355-374. Full references (including those not matched with items on IDEAS)\nWhen requesting a correction, please mention this item's handle: RePEc:aea:aecrev:v:96:y:2006:i:2:p:383-387. See general information about how to correct material in RePEc.\nFor technical questions regarding this item, or to correct its authors, title, abstract, bibliographic or download information, contact: (Jane Voros)or (Michael P. Albert)\nIf you have authored this item and are not yet registered with RePEc, we encourage you to do it here. This allows to link your profile to this item. It also allows you to accept potential citations to this item that we are uncertain about.\nIf references are entirely missing, you can add them using this form.\nIf the full references list an item that is present in RePEc, but the system did not link to it, you can help with this form.\nIf you know of missing items citing this one, you can help us creating those links by adding the relevant references in the same way as above, for each refering item. If you are a registered author of this item, you may also want to check the \"citations\" tab in your profile, as there may be some citations waiting for confirmation.\nPlease note that corrections may take a couple of weeks to filter through the various RePEc services.","The reunification of Germany\nThe swift and unexpected downfall of the German Democratic Republic was triggered by the decay of the other communist regimes in eastern Europe and the Soviet Union. The liberalizing reforms of President Mikhail Gorbachev in the Soviet Union appalled the Honecker regime, which in desperation was by 1988 forbidding the circulation within East Germany of Soviet publications that it viewed as dangerously subversive. The Berlin Wall was in effect breached in the summer of 1989 when a reformist Hungarian government began allowing East Germans to escape to the West through Hungary’s newly opened border with Austria. By the fall, thousands of East Germans had followed this route, while thousands of others sought asylum in the West German embassies in Prague and Warsaw, demanding that they be allowed to emigrate to West Germany. At the end of September, Genscher, still West Germany’s foreign minister, arranged for their passage to West Germany, but another wave of refugees from East Germany soon took their place. Mass demonstrations in the streets of Leipzig and other East German cities defied the authorities and demanded reforms.\nIn an effort to halt the deterioration of its position, the SED Politburo deposed Honecker in mid-October and replaced him with another hard-line communist, Egon Krenz. Under Krenz the Politburo sought to eliminate the embarrassment occasioned by the flow of refugees to the West through Hungary, Czechoslovakia, and Poland. On the evening of November 9, Günter Schabowski, a communist functionary, mistakenly announced at a televised news conference that the government would allow East Germans unlimited passage to West Germany, effective “immediately.” While the government had in fact meant to require East Germans to apply for exit visas during normal working hours, this was widely interpreted as a decision to open the Berlin Wall that evening, so crowds gathered and demanded to pass into West Berlin. Unprepared, the border guards let them go. In a night of revelry tens of thousands of East Germans poured through the crossing points in the wall and celebrated their new freedom with rejoicing West Berliners.\nThe opening of the Berlin Wall proved fatal for the German Democratic Republic. Ever-larger demonstrations demanded a voice in government for the people, and in mid-November Krenz was replaced by a reform-minded communist, Hans Modrow, who promised free, multiparty elections. When the balloting took place in March 1990 the SED, now renamed the Party of Democratic Socialism (PDS), suffered a crushing defeat. The eastern counterpart of Kohl’s CDU, which had pledged a speedy reunification of Germany, emerged as the largest political party in East Germany’s first democratically elected People’s Chamber. A new East German government headed by Lothar de Maizière, a long-time member of the eastern Christian Democratic Union, and backed initially by a broad coalition, including the eastern counterparts of the Social Democrats and Free Democrats, began negotiations for a treaty of unification. A surging tide of refugees from East to West Germany that threatened to cripple East Germany added urgency to those negotiations. In July that tide was somewhat stemmed by a monetary union of the two Germanys that gave East Germans the hard currency of the Federal Republic.\nThe final barrier to reunification fell in July 1990 when Kohl prevailed upon Gorbachev to drop his objections to a unified Germany within the NATO alliance in return for sizable (West) German financial aid to the Soviet Union. A unification treaty was ratified by the Bundestag and the People’s Chamber in September and went into effect on October 3, 1990. The German Democratic Republic joined the Federal Republic as five additional Länder, and the two parts of divided Berlin became one Land. (The five new Länder were Brandenburg, Mecklenburg–West Pomerania, Saxony, Saxony-Anhalt, and Thuringia.)\nTest Your Knowledge\nLet’s Move: Fact or Fiction?\nIn December 1990 the first all-German free election since the Nazi period conferred an expanded majority on Kohl’s coalition. After 45 years of division, Germany was once again united, and the following year Kohl helped negotiate the Treaty on European Union, which established the European Union (EU) and paved the way for the introduction of the euro, the EU’s single currency, by the end of the decade.\nThe achievement of national unification was soon shadowed by a series of difficulties, some due to structural problems in the European economy, others to the costs and consequences of unification itself. Like most of the rest of Europe, Germany in the 1990s confronted increased global competition, the increasing costs of its elaborate social welfare system, and stubborn unemployment, especially in its traditional industrial sector. However, it also faced the staggering added expenses of unifying the east and west. These expenses were all the more unsettling because they were apparently unexpected. Kohl and his advisers had done little to prepare German taxpayers for the costs of unification, in part because they feared the potential political consequences but also because they were themselves surprised by the magnitude of the task. The core of the problem was the state of the eastern German economy, which was far worse than anyone had realized or admitted. Only a handful of eastern firms could compete on the world market; most were woefully inefficient and also environmentally destructive. As a consequence, the former East German economy collapsed, hundreds of thousands of easterners faced unemployment, and the east became heavily dependent on federal subsidies. At the same time, the infrastructure—roads, rail lines, telephones, and the like—required massive capital investment in order to provide the basis for future economic growth. In short, the promise of immediate prosperity and economic equality, on which the swift and relatively painless process of unification had rested, turned out to be impossible to fulfill. Unemployment, social dislocation, and disappointment continued to haunt the new Länder more than a decade after the fall of the Berlin Wall.\nThe lingering economic gap between the east and west was just one of several difficulties attending unification. Not surprisingly, many easterners resented what they took to be western arrogance and insensitivity. The terms Wessi (“westerner”) and Ossi (“easterner”) came to imply different approaches to the world: the former competitive and aggressive, the product of what Germans call the West’s “elbow society”; the latter passive and indolent, the product of the stifling security of the communist regime. The PDS became the political voice of eastern discontents, with strong if localized support in some of the new Länder. Moreover, the neofascist German People’s Union (Deutsche Volksunion), led by millionaire publisher Gerhard Frey, garnered significant support among eastern Germany’s mass of unemployed workers. In addition to the resentment and disillusionment over unification that many easterners and some westerners felt, there was also the problem of coming to terms with the legacies left by 40 years of dictatorship. East Germany had developed a large and effective security apparatus (the Stasi), which employed a wide network of professional and amateur informants. As the files of this organization began to be made public, eastern Germans discovered that many of their most prominent citizens, as well as some of their friends, neighbours, and even family members, had been on the Stasi payroll. Coming to terms with these revelations—legally, politically, and personally—added to the tension of the postunification decade.\nDespite the problems attending unification, as well as a series of scandals in his own party, Kohl won a narrow victory in 1994. In 1996 he surpassed Adenauer’s record as the longest-serving German chancellor since Bismarck. Nevertheless, his popularity was clearly ebbing. Increasingly intolerant of criticism within his own party, Kohl suffered a humiliating defeat when his first choice for the presidency was rejected. Instead, Roman Herzog, the president of the Federal Constitutional Court, was elected in May 1994 and fulfilled his duties effectively and gracefully. As Germany prepared for the 1998 elections, its economy was faltering—unemployment surpassed 10 percent and was double that in much of eastern Germany—and some members of Kohl’s party openly hoped that he would step aside in favour of a new candidate; instead the chancellor ran again and his coalition was defeated, ending his 16-year chancellorship. Kohl was replaced as chancellor by Gerhard Schröder, the pragmatic and photogenic leader of the SPD, which formed a coalition with the Green Party.\nSchröder’s government got off to a rocky start, the victim of the chancellor’s own indecisiveness and internal dissent from his party’s left wing. The coalition also suffered from internal dissension within Foreign Minister Joschka Fischer’s Green Party, which was divided between pragmatists such as Fischer and those who regarded any compromise as a betrayal of the party’s principles. In 1999 the government’s problems were swiftly overshadowed by a series of revelations about illegal campaign contributions to the CDU, which forced Kohl and his successor, Wolfgang Schäuble, to resign their leadership posts. In April 2000 the CDU selected as party leader Angela Merkel, who became the first former East German and first woman to lead a major political party in Germany.\nSchröder’s government focused much of its efforts on reforming the German social welfare system and economy. In particular, the government wanted to reduce the costs of the generous but bloated welfare system; as the population was aging, the number of beneficiaries was increasing at a rate exceeding the number of contributors, threatening the solvency of the system. Moreover, the government attempted to relieve the burden on businesses of the country’s high taxes and labour costs, which had driven away foreign investment and encouraged German firms to close German plants and move them overseas. The government also aimed to eliminate the country’s reliance on nuclear power, agreeing to phase out its use by about 2022. In 2010 the government extended that deadline into the 2030s.\nWhen the 2002 election campaign began, the government’s efforts to improve the economy had not succeeded. Economic growth remained sluggish, and unemployment (particularly in eastern Germany) remained high. Faced with a vigorous challenge from Edmund Stoiber, the head of Bavaria’s government, Schröder based much of his campaign on opposition to U.S. policy regarding the Iraqi regime of Ṣaddām Ḥussein—a view that was widely shared throughout Germany. As a result, Schröder and the Greens were able to win a narrow victory in September 2002. The new government attempted to build a consensus for economic reforms, which would require sacrifices from trade unions and other important parts of the Social Democrats’ constituency. At the same time, Schröder sought to repair the damaged relationship with the United States, though he opposed U.S.-led military action against Iraq in 2003. As the country’s economy continued to worsen, early elections were held in 2005. The CDU and CSU won a narrow victory, and a coalition government was formed with Merkel as chancellor; she became the first woman to hold that office.\nAt the start of the new millennium, Germany remained a leader in Europe and was the key to the continent’s security, stability, and prosperity. For more than 50 years, from Adenauer to Kohl, Schröder, and Merkel, Germans had played an important role in the creation of European institutions. Germany remains essential to the success of both the EU’s ambitious program of economic and political integration and its efforts to expand to include members from the former Soviet bloc. Germany will also be an important part of European efforts to craft a new security strategy, based on an enlarged NATO and a revised relationship with the United States.\nIn Germany’s parliamentary elections on September 27, 2009, Merkel’s mandate as chancellor was renewed, this time with the CDU-CSU and the FDP winning enough seats to form a coalition. The SPD, which since 2005 had served as the junior partner in a grand coalition with the CDU-CSU, thus was forced into opposition. Germany comfortably weathered the debt crisis that shook the rest of the euro zone, and Merkel and French Pres. Nicolas Sarkozy brokered a series of deals that were intended to contain the damage to the single currency.\nWhile Merkel’s international presence was on the rise, she suffered domestically. The resignations of Pres. Horst Köhler in 2010, Defense Minister Karl-Theodor zu Guttenberg in 2011, and Pres. Christian Wulff in 2012 were all blows to Merkel’s prestige. After Japan’s Fukushima nuclear accident in March 2011, Merkel pledged to phase out nuclear power in Germany by 2022, but this move came too late to boost the CDU’s performance in state elections later that month. In contrast, the Green Party, which had long opposed nuclear power, captured enough support to form a government in Baden-Württemberg, a CDU stronghold since 1953. Joachim Gauck was elected president of Germany in March 2012, becoming the third person to hold that office in as many years. Unaffiliated with any political party, Gauck was a popular choice for the largely ceremonial role because of his history as a pro-democracy dissident in East Germany and his supervision of the Stasi archives after the fall of the Berlin Wall. For the first time since Germany’s reunification, the posts of both chancellor and president were held by individuals from the former East Germany.\nAs the campaign for the 2013 federal election began to intensify, the CDU coalition continued to suffer setbacks at the state level. Elections in Lower Saxony in January 2013 shifted the balance of power in the Bundesrat, giving the Greens and the SPD a majority in the upper house of Germany’s legislature. Peer Steinbrück, the SPD candidate for chancellor, had served as finance minister under Merkel in the grand coalition government from 2005 to 2009. While his performance in that role was widely praised, its connection with the Merkel administration made it difficult for Steinbrück to set himself apart from the incumbent. The sole televised debate between the candidates was inconclusive, and Merkel’s personal popularity was bolstered by strong economic numbers, which included an unemployment rate that was the lowest since reunification.\nHer handling of the economy and her approach to the euro-zone debt crisis appeared to receive a huge endorsement from the German electorate when the CDU and CSU captured nearly 42 percent of the vote in the September 22, 2013, election, winning almost an absolute majority of the seats and setting up Merkel to become the third chancellor in the post-World War II era to win three elections. Because her government’s junior partner, the FDP, failed to reach the 5 percent threshold for representation for the first time in the postwar period, Merkel faced the possibility of forming another grand coalition with the SPD (which finished second with about 26 percent of the vote) or bringing the Green Party (which finished just behind The Left Party with about 8 percent) into government, though neither party was likely to come without a great deal of bargaining. After two months of negotiations, a grand coalition between the CDU-CSU and SPD was proposed, but it hinged on the approval of SPD members in an unprecedented party ballot. In December 2013 more than three-fourths of SPD voters voiced their support for the coalition. Among the stated priorities for the new government were the continued transitioning of Germany’s energy system to renewable sources and the adoption of the country’s first minimum wage law."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:98d7c699-a2e5-4696-af2f-cda933faa885>","<urn:uuid:34071a96-26d9-4510-be57-e8049c242398>"],"error":null}
{"question":"How many episodes and seasons did the original Sailor Moon anime have, and what is the significance of ChibiUsa's design features?","answer":"The original Sailor Moon anime ran for 200 episodes across five seasons from 1992 to 1997. ChibiUsa's design features were deliberately created as a reflection of Usagi, incorporating elements that weren't initially used for Usagi's character, including red eyes, rabbit-ear-shaped odango, and pink hair, with the pink color choice being influenced by Japanese cultural associations between rabbits and the color pink.","context":["Sailor Moon (anime)\nBishoujo Senshi Sailor Moon (美少女戦士セーラームーン; officially translated as \"Pretty Soldier Sailor Moon\" or \"Pretty Guardian Sailor Moon\") refers to two anime series based on the Sailor Moon manga by Naoko Takeuchi.\nThe original anime series ran on TV Asahi from March 7, 1992 to February 8, 1997. In the fall of 2009 it began airing again on Animax. The series spanned 200 episodes, three feature films, five specials, and five memorials.\nThe second series was announced at the 20th anniversary of Sailor Moon in July 2012 by Naoko Takeuchi and Kodansha, with an expected release in the summer of 2013. The release date was pushed back several times before it began July 2014.\n- 1 Sailor Moon \"Classic\"\n- 2 Sailor Moon Crystal\n- 3 Sailor Moon Around the World\nSailor Moon \"Classic\"\nSailor Moon (First Season)\nThe first season of the Sailor Moon anime aired on TV Asahi at 7:00pm on Saturdays from March 7, 1992 to February 27, 1993. It consisted of episodes 1-46.\nSailor Moon R (Second Season)\nThe second season of the Sailor Moon anime aired from March 6, 1993 to March 12, 1994. It consisted of episodes 47-89.\nBecause the series was not developed with a second season in mind, the first 13 episodes (quarter season) of the series was an original story produced by Toei, allowing Naoko Takeuchi to release more of the manga before the anime returned to follow its storyline.\nThis season was the last to air in the UK on Fox Kids (now known as Jetix).\nThis season was dubbed into English by DiC and eventually released on DVD by ADV, though episode 67 was not dubbed nor released on DVD in the U.S. and Canada.\nA subbed version is currently available through Hulu and Viz Media's Neon Alley service. A second dubbed version was released on home video in two installments, with Part 1 released on July 14, 2015 and Part 2 released on October 27, 2015.\nSailor Moon S (Third Season)\nThe third season of the Sailor Moon anime aired from March 19, 1994 to February 25, 1995. It consisted of episodes 90-127.\nA subbed version is currently available through Hulu and Viz Media's Neon Alley service. A second dubbed version was released on home video in two installments, with Part 1 released on November 15, 2016 and Part 2 released on June 20, 2017.\nSailor Moon SuperS (Fourth Season)\nThe fourth season of the Sailor Moon anime aired from March 4, 1995 to March 2, 1996. It consisted of episodes 128-166.\nThis season was dubbed into English by Cloverway and released on DVD by Pioneer, and was the last season of the series to air in the U.S. and Canada during the original license period.\nA subbed version is currently available through Hulu and Viz Media's Neon Alley service.\nSailor Moon Sailor Stars (Fifth Season)\nThe fifth season of the Sailor Moon anime aired from March 9, 1996 to February 8, 1997. It consisted of episodes 167-200. The series concluded with this season.\nOn the anime timeline at the Toei Animation Gallery, \"Sailor Stars\" is listed separate from \"Sailor Moon,\" which on their timeline concludes with the fourth season. In addition, the opening song changed from \"Moonlight Densetsu,\" which it had been for the first four seasons, to the \"Sailor Star Song.\"\nUntil 2015, none of the episodes in this season had aired in English-speaking countries, and many rumors persisted as to why Toei Animation had not allowed any company to license the last series for distribution in English. The most persistent rumors were that Toei wanted more money for licensing than anyone was willing to pay, and that Toei was afraid of hurting Sailor Moon's \"family friendly\" image due to some content in Sailor Stars (such as the nudity in the last episode, Haruka and Michiru's relationship, and the gender-transforming Sailor Starlights). Despite this, however, this season aired in other foreign countries with little or no controversy. In 2014, Viz Media licensed the series in the United States and Canada, and the subtitled first episode of Sailor Stars was released to Hulu's Neon Alley service on December 24, 2015. Episodes were posted on Hulu at a two-a-week pace through to April 2016, when episode 200 was posted.\n- The Sailor Moon R movie - Theater run was from December 1993 to January 1994. The film's English dub subtitle is \"The Promise of the Rose.\" The Viz dub of the film was given a theatrical run in early 2017, and the DVD and Blu-ray were released on April 18, 2017.\n- The Sailor Moon S movie - Theater run was from December 1994 to January 1995. It is based on the short story \"Kaguya-hime no Koibito\" that preluded the Dream story arc in the manga. The film's English dub subtitle is \"Hearts in Ice.\"\n- The Sailor Moon SuperS movie - Theater run was from December 1995 to January 1996. Of the three films, this was the only one to have a Japanese subtitle, called \"The Nine Sailor Warriors Get Together! Miracle in the Black Dream Hole.\" The film's English dub subtitle is \"Black Dream Hole.\"\n- Make up! Sailor Senshi - A special that appeared with the R movie in theaters.\n- The Wonderful World of Sailor Moon S - A special that aired on December 22, 1994.\n- Sailor Moon SuperS Specials - A set of three episodes that aired on April 8, 1995.\n- Ami's First Love - A special that appeared with the SuperS movie in theaters.\n- Sailor Moon Memorial\n- Sailor Moon R Memorial\n- Sailor Moon S Memorial\n- Sailor Moon SuperS Memorial\n- Sailor Stars Memorial\nSailor Moon Crystal\nPretty Guardian Sailor Moon Crystal premiered on July 5, 2014, with simultaneous streaming broadcasts around the world. A new episode aired every first and third Saturday of each month for a year, for a total of 26 episodes in the first two seasons. Season III began on April 4, 2016, with a new episode aired on television every week until the end of June that year, for a total of 13 episodes.\nSailor Moon Around the World\nThe Sailor Moon series quickly found favor internationally, and was bought by various TV companies across the world and dubbed into numerous different languages. For more details, see:\n- Sailor Moon in Brazil\n- Sailor Moon in Britain\n- Sailor Moon in China\n- Sailor Moon in Denmark\n- Sailor Moon in Finland\n- Sailor Moon in France\n- Sailor Moon in Germany\n- Sailor Moon in Greece\n- Sailor Moon in Hong Kong\n- Sailor Moon in Hungary\n- Sailor Moon in Indonesia\n- Sailor Moon in Israel\n- Sailor Moon in Italy\n- Sailor Moon in Korea\n- Sailor Moon in Mexico\n- Sailor Moon in The Netherlands\n- Sailor Moon in North America\n- Sailor Moon in the Philippines\n- Sailor Moon in Poland\n- Sailor Moon in Portugal\n- Sailor Moon in Russia\n- Sailor Moon in Spain\n- Sailor Moon in Sweden\n- Sailor Moon in Thailand","Why Does ChibiUsa Have Pink Hair?\nThe most direct – and simplest – answer as to why ChibiUsa has pink hair ties closely into the fact that Ms. Takeuchi had originally intended for ChibiUsa to literally be something of a little Usagi, in-so-far that much of her character designs, birthday, likes and dislikes, all can be directly tied back to Usagi herself. So to start with our conclusion and work our way backwards: the reason why ChibiUsa has pink hair is because of Usagi’s hair. Now, let’s work our way backwards!\nWhile the Usagi that you and I know and love blonde hair now, that wasn’t always the case. In fact, since manga is a black-and-white medium, it’s pretty hard to tell what colors Ms. Takeuchi had intended to use from the beginning, and it’s even possible that the colors of the Four Kings’ uniforms changed as the series progressed and that some of the colors weren’t nailed down. According to Ms. Takeuchi herself,1 while Usagi was meant to have blonde hair, it was supposed to turn silver when she transformed into Sailor Moon. This image discrepancy actually made it into series canon to a certain extent, seeing that the cover image published in Sailor Moon‘s Nakayoshi debut issue shows her with silver hair. Though she was stopped by her editor and told to use something a little more colorful for a cover, this is probably the reasoning behind Princess Serenity (and the Queen herself) having silver hair.\nSince Ms. Takeuchi was required to play it safe with Usagi and wasn’t able to use all of her ideas evoking rabbits with her originally, many of those ideas were brought back with ChibiUsa’s appearance, including: the red eyes, the rabbit-ear-shaped odango,2 and of course the pink hair. Now that the series was already established (and a raging hit, might I add), she had a little more free reign to play with designs as she pleased. You can also see this in the anime, seeing as with the exception of Ami, the majority of the characters appearing in the anime had normal human hair colors, though this got more dramatic as the series continued on into Sailor Moon R (e.g., the Ayakashi Sisters, ChibiUsa, Sailor Pluto).\nSo, typically we could just call it a day here since we pretty much answered the immediate question, but to be honest, I’m not really satisfied with leaving it here. We determined that ChibiUsa’s hair is pink because of Usagi’s rabbit-pun origins… but I can’t get over the simple fact that rabbits aren’t pink. But this isn’t a problem with our theory, but rather a question into Japanese culture itself. When depicted in animation or drawn as characters rabbits are, for one reason or another, typically depicted as pink in Japan.\nIt turns out I’m not the only one interested in this. The Society for the Study of Human and Animal Relations3 published a study in their magazine4 regarding why Japanese children overwhelmingly colored rabbits as pink. Though the findings weren’t definitive, they did note that when children were given non-white paper to draw on, rabbits were more often colored as while, though still not at the same rate as horses and sheep. They also found that when when given coloring books of rabbits, the realism of the rabbit itself affected the rates that children colored it as pink vs. normal colors, such as brown or white.\nUnfortunately, we’re still just describing a phenomenon and not explaining it. Looking at old ukiyo-e5 paintings, we’re hard-pressed to find any depictions of pink rabbits. In fact, I was unable to find any pre-20th century pink rabbits. Considering the timing of the Energizer Bunny’s debut in 19896 and the fact that Energizer first started being marketed in Japan through a dual-branding deal with Fujitsu, it’s almost tempting to say that the bunny had somehow influenced this phenomenon, but alas, the dates don’t quite work out – though it would’ve been really neat if ChibiUsa’s hair color could be credited to a battery branding deal!\nMore likely, the start of the rabbits = pink cultural understanding in Japan (and which ultimately inspired Ms. Takeuchi to apply that color to ChibiUsa via her original designs for Usagi) is a song credited to Kyoko Ishige,7 “The Pink Bunny” (ピンクのバニー) and released in 1972. From 1971, Ms. Ishige played a role on a children’s exercise TV program titled “Let’s Play With Mommy! Pin Pon Pan!” (ママとあそぼう!ピンポンパン; mama to asobou! pinponpan) where she would sing songs for the children and exercise. Her music was quite popular at the time, and in fact would’ve been playing right around the time Ms. Takeuchi (born in 1967) would’ve been exposed to entertainment for that age group.\nYou can listen for yourself here!\nNow, while I couldn’t find any further information either for or against about whether Kyoko Ishige was describing the Japanese consciousness that rabbits are pink or that her random cutesy song was the start of the phenomenon, it’s the oldest reference I’m able to find for rabbits being pink in Japan. Probably, it’s a mixture of the two – kids were already using their pink crayons to color in rabbits, and her song cemented it in the culture.\nAll the same, it’s interesting to think that something as simple as a children’s program Ms. Takeuchi may have exercised with her own mother with may have affected the distinct appearance of a main character. There’s just so much to know!\n- See the first art book’s Liner Notes (Manga Style) ↩\n- Which is inappropriately named with ChibiUsa, seeing as they are referred to as odango due to their round shape. But now I’m just being picky… ↩\n- See their website here ↩\n- See the December 2007 issue of Thinking of Animals: Perception, Concept and Attitude (動物観研究) ↩\n- See Ukiyo-e (Wikipedia) ↩\n- See the Energizer Bunny Timeline ↩\n- See Kyoko Ishige (Wikipedia) ↩"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:195bf019-71bb-4955-acf0-07acc9bfb699>","<urn:uuid:c0554a22-93dc-4eb2-8c5c-06fa78e248d0>"],"error":null}
{"question":"How can I verify if a fashion brand is genuinely sustainable? Need help figuring out what to look for! 🤔","answer":"To verify a fashion brand's sustainability, you should look for several key indicators. First, check for disclosure information from the company and independent third-party certifiers. Look for certifications from organizations like the Global Organic Textile Standard, Fairtrade Certified, and Cotton LEADS certification programs, which provide guarantees of product sustainability. Read labels carefully to ensure materials meet sustainability standards - look for eco-friendly or natural materials like organic cotton, bamboo, hemp, and silk. Companies should be transparent about their production processes, material sourcing, and labor practices. Additionally, sustainable brands should provide information about their water and energy conservation, chemical and waste management, and corporate social responsibility practices.","context":["What is Sustainable Fashion?\nIn recent years, there has been an increase in consumer awareness and demand for more sustainable fashion. Sustainable fashion emphasizes not only ecological benefits, but also social justice. It’s so much more than just using eco-friendly materials; it’s about creating a fairer and more ethical production system.\nSo, what is sustainable fashion and why should you care? In this article, we will explore the topics of what sustainable fashion is, the benefits, challenges and how to shop sustainably. We will also discuss the future of sustainable fashion and, finally, draw a conclusion.\nThe Benefits of Sustainable Fashion\nThe term “sustainable fashion” has become an increasingly important one in the fashion industry. It is a phrase that encompasses a wide range of topics, from the materials used to create clothing to the supply chain practices used to get that clothing to you. Sustainable fashion is all about promoting a healthier environment and creating a better future for all.\nOne of the biggest benefits of sustainable fashion is its environmental friendliness. Instead of using synthetic materials and generating waste, sustainable fashion is focused on using materials that are natural and renewable, such as organic cotton and bamboo.\nNot only are these materials better for the environment, but they also help to create clothes that are more breathable and softer on the skin. Sustainable fashion is also committed to reducing the carbon footprint of fashion. This can be accomplished by reducing energy consumption, decreasing water usage, and reducing the use of chemicals.\nSustainable fashion is also an ethical way to shop for clothing. Sustainable fashion companies often use fair trade practices, meaning that the people making the clothing are paid a living wage and work in safe and humane conditions.\nSustainable fashion companies are also often more transparent, allowing customers to see where their clothes are sourced from and the production processes used.\nFinally, sustainable fashion is a great way to shop for trendy and stylish clothing. It is no longer necessary to choose between looking great and being kind to the environment. Sustainable fashion companies are dedicated to creating high-quality pieces that are fashionable and stylish.\nIn summary, sustainable fashion is an incredibly important movement in the fashion industry. It provides environmental protection and ethical practices in the production of clothing. It also gives customers the opportunity to purchase stylish and trendy clothing without sacrificing quality or ethics.\nSustainable fashion is the future of eco-friendly clothing, and it has the potential to make a huge impact on the fashion industry.\nThe Challenges of Sustainable Fashion\nOne of the toughest challenges of Sustainable Fashion is the cost. Sustainable fashion typically relies on more natural materials and processes, which can be significantly more expensive than traditional fashion materials.\nSimilarly, sustainable fashion products also take much longer to produce, as they require more complex and labor intensive manufacturing processes. This can lead to higher price tags, which can be difficult for consumers to purchase.\nAnother of the challenges of Sustainable Fashion is the conflicting desires of consumers. Many consumers want to purchase clothing that is eco-friendly and sustainable, but they also want fashion that is trendy and fashionable. It can be difficult for companies to balance both of these desires and to create pieces that are both fashionable and sustainable.\nFinally, a lack of knowledge and awareness is a major challenge for Sustainable Fashion. Consumers often don’t understand the meaning and implications of eco-friendly and sustainable fashion, which can make it difficult for companies to promote and spread the message.\nSimilarly, many fashion designers are still unfamiliar with the materials and techniques used in sustainable fashion, meaning that there is not yet a large body of experts who are able to design sustainable fashion pieces.\nThese challenges demonstrate the difficulty of Sustainable Fashion, particularly from a consumer perspective. Companies need to work to increase awareness, reduce costs, and create trendy designs that will appeal to consumers who are looking for eco-friendly ways to dress. If successful, Sustainable Fashion can become a mainstream and widely accepted form of fashion.\nHow to Shop Sustainably\nAs the fashion industry looks towards the future, they are increasingly turning to sustainable practices and eco-friendly clothing. Shopping sustainably means reducing your ecological footprint by buying clothes that are made with sustainable materials and/or produced in an ethical way. Here are some tips on how to do just that.\n- Do Your Research\nIt’s important to take the time to do your research on a company before you make a purchase. Read company websites, find out about their production processes and materials used in their clothes, and even contact them directly with questions. Read up on their sustainability credentials and make sure you are happy with what you’re buying.\n- Look for Sustainable Materials\nSustainable materials are those that are either renewable or biodegradable, and don’t damage the environment. Popular sustainable fabrics include bamboo, hemp, linen, and organic cotton. Look for clothes that are made from sustainable materials and be sure to check the label.\n- Shop Local\nShopping local is an excellent way to ensure the clothes you buy are produced in an ethical way, as it is easier to monitor how the clothes are made and who is making them. Shopping at local independent stores can also help to support your local community.\n- Choose Quality Over Quantity\nRather than buying a lot of cheap, fast fashion clothes, opt for quality over quantity and invest in clothes that will last longer. Buying higher quality clothing means you can wear it for longer, so you’re not buying new clothes as often.\n- Choose Secondhand\nShopping secondhand is a great way to reduce the impact of your wardrobe on the environment. As well as being a more affordable and sustainable option, secondhand clothes can be fun to shop for and have their own story.\nBy following these tips, you can make sure you’re shopping sustainably and responsibly for fashion and clothing. Sustainability is an important partof the future of the fashion industry and it’s up to us to make sure we are taking the steps to ensure it is a responsible one.\nLook For Sustainable Materials\nWhen shopping for eco-friendly clothing, it’s important to consider the materials that make up the item. It’s better to choose items from companies that use materials that are either sustainably sourced or eco-friendly.\nSustainable materials include materials made from renewable sources, such as bamboo or organic cotton. These materials are produced in ways that reduce waste and conserve natural resources.\nAdditionally, many of these materials are produced in an ethical manner, providing better working conditions and wages for workers.\nSynthetic materials are often used in fashion, but many of these materials are not sustainable. Therefore, it is better to select items made from natural fibers, like wool, hemp, and silk, as these materials are more environmentally friendly and biodegradable.\nAdditionally, choosing organic materials like cotton and bamboo is a great way to support sustainable fashion.\nWhen shopping for eco-friendly clothing, it is important to look at the labels. Clothes that are labeled as “eco-friendly” or “all natural” may be made with sustainable materials and are therefore better for the environment.\nHowever, it is important to read labels carefully to ensure that the materials used meet the standards of sustainability. Additionally, looking for certifications such as Fair Trade or Oeko-Tex can also be a good indication of an item’s sustainability.\nFinally, attempting to purchase items made close to home can help to reduce energy costs associated with manufacturing and transportation. By taking the time to look for sustainable materials in clothing, individuals can be part of the shift towards more sustainable fashion.\nBuy from Sustainable Brands\nThe best way to ensure that your fashion choices are eco-friendly is to buy from sustainable brands. Sustainable fashion brands are those that use eco-friendly materials and production techniques, focus on ethical labor practices, and promote sustainability as a core part of their mission.\nShopping from these brands allows you to support eco-friendly brands while also reducing your environmental impact.\nWhen shopping for sustainable fashion clothing, look for labels with organic cotton, bamboo, hemp, or other natural materials. These natural fabrics are easier on the environment than synthetic materials like polyester and nylon.\nMany sustainable brands also use eco-friendly dyes and other production techniques that have a low environmental impact.\nSustainable fashion brands also focus on ethical labor practices. Many sustainable fashion brands prioritize fair wages, safe working conditions, and the use of locally sourced materials and labor. This ensures that workers in the fashion industry are paid fairly for their work and have safe working conditions.\nFinally, many sustainable fashion brands focus on giving back to their communities and supporting projects that help to protect the environment. For example, many sustainable fashion brands donate a portion of their profits to environmental charities. This allows consumers to feel good about their purchases, knowing that they are supporting an eco-friendly brand that is also helping to make the world a better place.\nOverall, shopping from sustainable fashion brands is the best way to ensure that your fashion choices are eco-friendly. By buying from these brands, you can feel good about your purchase and know that you are helping to protect the environment.\nLook for Disclosure Information\nWhen shopping for eco-friendly clothing, look for disclosure information from the company and preferably an independent third-party certifier to ensure the clothing’s validity as a sustainable product.\nEvery company has a different set of sustainable standards they must meet, such as water and energy conservation, material sourcing, chemical and waste management, and corporate social responsibility.\nMany companies include these standards on their website, and some even have them printed on their clothing and packaging for customer reference.\nHaving a third-party certifier adds additional assurance of the sustainability of the fashion brand’s products. Organizations such as the Global Organic Textile Standard, Fairtrade Certified, and Cotton LEADS certification programs all certify various eco-friendly clothing and fashion items and can provide customers with a guarantee of the product’s sustainability.\nThe certification process varies by organization, but generally requires that companies undergo a comprehensive assessment of their product’s materials and production processes in order to qualify for the certification. This assessment process is also necessary for a company to be able to legally advertise their products as eco-friendly and sustainable.\nTo further support sustainable fashion, it is important to remember to research and read labels when shopping for eco-friendly clothing. This will help to ensure that the clothing you buy is of the highest quality and is produced ethically and in an environmentally responsible way. Learning to recognize quality and sustainability practices when shopping can help to create a brighter future for the fashion industry.\nBe Mindful of Trends\nAs fashion trends come and go, it is important to be mindful of what is considered “in-vogue” at any given time. This is particularly true when it comes to sustainable fashion. While it is important to remain up to date on the latest fashion trends, there are ways to do so while still remaining conscious of the environment.\nTo start, it is wise to look for eco-friendly fashion trends made from natural materials. Natural materials, such as organic cotton, do not require the use of harsh chemicals or toxins and is a much more sustainable option.\nAdditionally, when shopping for fashion trends, it can be helpful to look for pieces that are locally made. This reduces the emissions generated from shipping, as well as supports the local economy.\nFurthermore, investing in quality pieces that can be worn for years to come is a great way to stay on trend without having to replace items as often.\nFinally, as a way to further embrace sustainable fashion, one can look towards second-hand pieces. Buying pre-owned clothing that is still in good condition is a great way to add variety to one’s wardrobe in a sustainable way. Not only does this reduce the need for new clothes, but it also leaves a much smaller environmental footprint.\nIn sum, fashion trends are constantly changing and it is important to remain up-to-date on the latest styles. While doing so, it is important to remain mindful of the environment by opting for sustainable fashion trends, such as organic cotton and locally made pieces. Furthermore, second-hand items can be a great way to add variety and to help minimize one’s environmental impact.\nThe Future of Sustainable Fashion\nWhen it comes to fashion and clothing, sustainability is the way of the future. In the era of global warming and increasing awareness of environmentally conscious practices, eco-friendly clothing is the best way to reduce our ecological footprint.\nAs the global population continues to grow, sustainability is becoming an increasingly important issue, and sustainable fashion is an important part of this.\nThe fashion industry is among the world’s largest polluters, so finding ways of creating sustainable clothing is one of the most effective methods of reducing environmental impact. Sustainable fashion can take many forms, and there are a few key ways of making clothing more sustainable.\nOne way to make clothing more sustainable is to use eco-friendly materials. Natural materials, like organic cotton and bamboo, are renewable sources and can be grown without damaging the environment.\nThere are also many recycled materials that can be used in clothing, such as recycled plastic bottles, which are a great way to reduce waste and emissions.\nAnother way to make clothing more sustainable is to make sure that the clothing is made in a responsible way. It is important to make sure that the clothing is produced in a way that is safe for workers and is not damaging to the environment.\nMany fashion companies are now taking steps to ensure that their production processes are sustainable, from using ethical labor practices to using renewable energy sources.\nFinally, sustainable fashion also focuses on the quality of clothing. Companies are now using methods like slow fashion and upcycling, which help to reduce waste and extend the life span of clothing.\nBy creating durable and well-made clothing that can be worn for years, fashion companies can help reduce the impact of the fashion industry on the environment.\nSustainable fashion is the way of the future, and there are many ways to make sure that our clothing is eco-friendly and responsibly made. By focusing on eco-friendly materials, production processes, and high-quality clothing, the fashion industry can make apositive impact on the environment and help create a more sustainable future.\nThe sustainable fashion revolution has made incredible progress in recent years due to increasing consumer awareness and demand. It is a movement that recognizes the importance of creating clothing while minimizing the negative impacts on the environment.\nAlthough the challenges are great, the potential benefits of sustainable fashion are even greater. With a greater focus on materials that are sourced sustainably and clothing that is made to last, sustainable fashion can play an important role in reducing our impact on the environment and promoting a more equitable and sustainable lifestyle.\nAs individuals, we can be more conscious of the materials we use and the clothes we buy, and we can also actively seek out sustainable fashion brands that promote a healthy, sustainable fashion industry. By committing to sustainable fashion, we can help ensure a brighter and more sustainable future for fashion and the planet."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:dd06e4f4-ae32-4ab6-ab0b-35a963876905>"],"error":null}