{"question":"How do modern scientific techniques help understand ancient life, and what evidence types are used?","answer":"Modern scientific techniques include remote sensing methods like ground penetrating radar and LIDAR for site discovery, as well as chemical analyses and data correlation for dating. The evidence used to understand ancient life comes from multiple sources: the fossil record provides physical remains of organisms, archaeological excavations reveal artifacts and cultural materials, and soil analysis helps determine formation conditions. Scientists examine these using laboratory activities, create evolutionary trees based on morphology, and study both artifacts and fossils in their geological context to reconstruct past life.","context":["Fossil Record Teacher Resources\nFind Fossil Record educational ideas and activities\nShowing 1 - 20 of 301 resources\nWatch how paleontologists scour the Gobi Desert to find fossils that fill in a gap in the fossil record. How big did dinosaurs get during the Jurassic period? Get your class thinking about these questions and more with this short clip. Tip: Have your students use what they know to come up with a theory of their own, explaining how dinosaurs grew to be the biggest animals on the planet.\nYoung scholars create mock fossil records based on current scientific theories about prehistory. By learning about what fossil records teach us about different prehistoric time periods, students gain a greater understanding of theories of prehistory in general.\nStudents compare the three theories used tp interpret fossil records. In this earth science lesson, students create a production of a televised debate. They collaborate with group members to generate relevant questions about the topic.\nStudents ask questions about the nature of science as they experience a 'Fossil Hunt'. They reconstruct a book that has been literally destroyed, just as the fossil record has been changed by billions of years of geological processes.\nEngage young biologists with four laboratory activities that explore the fossil record. Learners examine fossil images, a fossil kit, the rock record, and geologic time scale. They even experiment with the oxygen production of an Elodea plant as an example of how the ancient atmosphere might have developed. Not only are activities provided, suggestions for comprehensive assessment questions are available as well. Use this resource as a complete mini-unit on evolutionary processes.\nLearners create an evolutionary tree based on fossil morphology and their ages. In this fossil record lesson plan, students are given 23 pictures of fossil. They study their morphology and arrange the fossils by age and structures on a chart with time periods. Learners tape the fossils in place and analyze their results to form a phylogenic tree.\nThe objective of this set of slides is to present four types of evidence for evolution: the fossil record, embryology, molecular biology, and comparative anatomy. Each facet of the argument is explored. This can be used in a high school biology course.\nWhile this is not the traditional, step-by-step lesson plan, it is chock-full of material that you can easily incorporate into your earth history unit. Its main purpose is to serve as a guide to using a three-part film, The Day the Mesozoic Died, which uncovers evidence in the fossil record for the mass extinction at the end of the Cretaceous period. Key concepts, background information, discussion points, and quiz questions are provided. There are also several links to related resources such as video lectures, slide presentations, and posters.\nLearners explore how to read fossil range charts. They develop an knowledge of the strengths and weaknesses of the fossil record. Students become familiar with the concepts index fossil and fossil range. Learners use bar graphs to plot fossil ranges. They develop an knowledge of 'relative time' using fossil range charts.\nStudents acquire a general knowledge of fossils and paleontology, the study of evidence of life in the past and identify the major invertebrate groups (phyla) commonly found in the fossil record.\nWalk your junior biologists through the evidence that supports evolution. The fossil record, anatomical record, and molecular record are explained and supported by colorful graphs and pictures. Extensive notes are provided for some of the slides.\nSummarize a unit on evolutionary evidence. Learners recount information about the fossil record, molecular record, homologous structures, convergent evolution. This worksheet provides plenty of room for high schoolers to write out responses, and it makes a succinct review of the topic.\nStudents investigate the fossil record, beginning the fossil formation process and delving into evolution.\nTake a close-up look at the evolution of hyenas in South Africa. Natural historians read about the five hyena species found in the fossil record and examine four statements that summarize the theory of evolution. As a culminating activity, pupils form groups and design a fact sheet about any modern member from the hyena family. This is an uncomplicated assignment to do with biology classes. You will appreciate the teacher's notes and grading rubric that are provided alongside.\nIn this history of life instructional activity, students will explore how mass extinctions have occurred on Earth, the different periods of the geological time scale, and scientists' use of fossil records. Students will complete 3 fill in the blank questions and 5 short answer questions.\nStudents practice sequencing cards that represent different rock layers based on alphabetical characters. In this fossil instructional activity, students discuss how paleontologists, biologists, and geologists use the fossil record to learn about the Earth. Students view examples of dinosaurs and fossils. Students complete a sequencing activity and name three organisms that could not be used as index fossils.\nStudents research about the animals found in Burgess Shale. In this earth science lesson, students evaluate the significance of fossils in human history. They create models of their chosen animal.\nNew Review The Rock and Fossil Record\nGo deep in your paleontology unit with this spectacular set of slides! It introduces viewers to the types of fossils, a few famous fossils, and the geologic eras. This is done with easy-to-read text, diagrams, photos, and even videos.\nStudents write an essay about evolution. They summarize Darwin's Theory and discuss its strength and weakness of evolutionary theory. Students discuss the struggle of existence and survival of the fittest. They discuss the evidence of evolution, the fossil record, and the homology in structure and embryos.\nStudents explore types of fossils and discover how sediment affects fossil preservation. They focus their study on trace fossils and create their own using sediment, water, and a small organism such as a snail or lizard. Students use plaster of Paris to make casts of the fossil to mimic the preservation of fossil records.","Engaged Archaeology. The first step in an archaeological excavation is surveying the area. This can be done either with remote sensing or direct visual observation. Archaeologists conducting a survey. Archaeologists also use non-invasive techniques to survey sites known as remote sensing. There are many methods including aerial photography which is simply taking pictures from an airplane, hot air balloon or even a remote controlled drone; ground penetrating radar which is used to locate artifacts hidden below ground, and LIDAR, which uses lasers to scan the surface from the air through vegetation.\nWhat Is Chronometric Dating?\nArchaeology is a branch of Anthropology. Archaeologists accomplish heir task mainly through excavation. Excavation is the process of finding sites that may contain artifacts. Artifacts are relics of the past. They are anything created or influenced by man.\nWhen used as a prefix or suffix of a date, it indicates the number of As various types of soil form under different conditions, soil analysis at an.\nThis page has been archived and is no longer updated. Despite seeming like a relatively stable place, the Earth’s surface has changed dramatically over the past 4. Mountains have been built and eroded, continents and oceans have moved great distances, and the Earth has fluctuated from being extremely cold and almost completely covered with ice to being very warm and ice-free. These changes typically occur so slowly that they are barely detectable over the span of a human life, yet even at this instant, the Earth’s surface is moving and changing.\nAs these changes have occurred, organisms have evolved, and remnants of some have been preserved as fossils. A fossil can be studied to determine what kind of organism it represents, how the organism lived, and how it was preserved. However, by itself a fossil has little meaning unless it is placed within some context. The age of the fossil must be determined so it can be compared to other fossil species from the same time period.\nUnderstanding the ages of related fossil species helps scientists piece together the evolutionary history of a group of organisms. For example, based on the primate fossil record, scientists know that living primates evolved from fossil primates and that this evolutionary history took tens of millions of years. By comparing fossils of different primate species, scientists can examine how features changed and how primates evolved through time. However, the age of each fossil primate needs to be determined so that fossils of the same age found in different parts of the world and fossils of different ages can be compared.\nThere are three general approaches that allow scientists to date geological materials and answer the question: “How old is this fossil?\nIn academic, historical, and archaeological circles, A. Dates are determined by a variety of processes, including chemical analyses as in radiocarbon dating and thermoluminescence , data correlation as in dendrochronology , and a variety of other tests. See Relative Dating. Acheulean — A stone tool industry, in use from about 1. It was characterized by large bifaces, particularly hand axes.\n10, B.C. to A.D. Historic artifacts and features in Indiana date after this time and refer to peoples of many ethnic and cultural backgrounds. These include.\nHaving an accurate time scale is a crucial aspect of reconstructing how anatomical and behavioral characteristics of early hominids evolved. Relative dating methods allow one to determine if an object is earlier than, later than, or contemporary with some other object. It does not, however, allow one to independently assign an accurate estimation of the age of an object as expressed in years. The most common relative dating method is stratigraphy. Other methods include fluorine dating, nitrogen dating, association with bones of extinct fauna, association with certain pollen profiles, association with geological features such as beaches, terraces and river meanders, and the establishment of cultural seriations.\nCultural seriations are based on typologies, in which artifacts that are numerous across a wide variety of sites and over time, like pottery or stone tools. If archaeologists know how pottery styles, glazes, and techniques have changed over time they can date sites based on the ratio of different kinds of pottery. This also works with stone tools which are found abundantly at different sites and across long periods of time.\nCity of Alexandria, Virginia\nWithout the ability to date archaeological sites and specific contexts within them, archaeologists would be unable to study cultural change and continuity over time. No wonder, then, that so much effort has been devoted to developing increasingly sophisticated and precise methods for determining when events happened in the past. Chronometric dating techniques produce a specific chronological date or date range for some event in the past.\nFor example, the results of dendrochronology tree-ring analysis may tell us that a particular roof beam was from a tree chopped down in A. Relative dating techniques , on the other hand, provide only the relative order in which events took place.\nThe following is a list of some archaeological terms that are used on our website. Please note that this is not an exhaustive list. For further terminology, please see the publication of the Historic Resources Branch of the Department of Culture, Heritage and Tourism of the Government of Manitoba, now hosted by the University of Manitoba.\nAbbreviation of the Latin anno Domini , meaning “in the year of our Lord. The study of humankind in all times and in all places. It takes a comprehensive approach to the study of the origin, behaviour and evolution of humans, looking at their biological, linguistic, cultural, social and economic characteristics and at their variability.\nDating Techniques In Archaeology\nThe Archiving the Archaeologists series is an oral history project of video interviews of archaeologists near retirement or already retired. Listen to real archaeologists reflect on their careers, how and why they became archaeologists, and their contributions to the discipline on the SAA YouTube channel.\nThe methods used by archaeologists to gather data can apply to any time period, including the recent past. One archaeologist in the U. This “garbology” project proved that even recent artifacts can reveal a lot about the people who used and discarded them.\nWhile historians and archaeologists both use written documents to learn about the past, The methods used to find sites will depend on the kind of research questions that the In the American Southwest, tree ring dating goes back to 59 BC.\nDating techniques are procedures used by scientists to determine the age of rocks, fossils, or artifacts. Relative dating methods tell only if one sample is older or younger than another; absolute dating methods provide an approximate date in years. The latter have generally been available only since Many absolute dating techniques take advantage of radioactive decay , whereby a radioactive form of an element decays into a non-radioactive product at a regular rate. Others, such as amino acid racimization and cation-ratio dating, are based on chemical changes in the organic or inorganic composition of a sample.\nIn recent years, a few of these methods have come under close scrutiny as scientists strive to develop the most accurate dating techniques possible. Relative dating methods determine whether one sample is older or younger than another.\nDating Rocks and Fossils Using Geologic Methods\nWhen the last excavated trench is backfilled with dirt and when survey is completed for another season, one is left with only the records, drawings, photographs, and cultural material to make sense of what everything means. The processing and interpretation of those material remains, in conjunction with the records, is the essential final step in completing the picture of past human activities occurring in an area over time. Artifacts, ecofacts, and features say little themselves, but researchers can make meaningful inferences about these when they are studied closely and in detail.\nAnalysis is the examination, description, classification, and identification of that material, as well as consideration of its broader meaning.\nDating in archaeology is the process of assigning a chronological value to an event in the past. Determining the hydration rate has been done in two ways.\nAll rights reserved. Relative techniques were developed earlier in the history of archaeology as a profession and are considered less trustworthy than absolute ones. There are several different methods. In stratigraphy , archaeologists assume that sites undergo stratification over time, leaving older layers beneath newer ones.\nArchaeologists use that assumption, called the law of superposition, to help determine a relative chronology for the site itself. Then, they use contextual clues and absolute dating techniques to help point to the age of the artifacts found in each layer. Learn how archaeologists dated the earliest metal body part in Europe.\nDating in Archaeology\nHe is affiliated with Cornell University. Columbus famously reached the Americas in Other Europeans had made the journey before , but the century from then until marks the creation of the modern globalized world.\nIn Alexandria, archaeological sites are discovered in a variety of ways. City Archaeologists consult maps, deeds, census, tax and other records. Historic and Native American sites can also be located through field surveys walking across the ground looking for artifacts. Sometimes sites are discovered by chance by home-owners who find artifacts, building foundations, abandoned wells or privies in basements and backyards. Such discoveries are visited by the City Archaeologists and are recorded with notes and photographs.\nInformation is then added to Alexandria Archaeology’s register of sites in the City. The City of Alexandria has laws that protect archaeological sites so that information may be recovered before they are destroyed by development. Planning dockets and construction applications are reviewed to see if proposed commercial projects could disturb sites.\nARCHAEOLOGY, TOOLS, METHODS AND ANALYSIS\nTwo systems of archaeological dating are used: absolute and relative chronology. Absolute chronology dates events in terms of the generally accepted calendar; relative chronology determines only the sequence of events. Relative dates are established by stratigraphy and by the typological method. The stratigraphic method, which observes the sequence of earth strata containing artifacts, makes it possible to attribute each stratum to a definite epoch.\nUsually, the deeper the stratum, the older it is.\nUsing relative and radiometric dating methods, geologists are able to answer the By comparing fossils of different primate species, scientists can examine how To establish the age of a rock or a fossil, researchers use some type of clock to P.R., Swisher, C.C. 40Ar/39Ar dating in paleoanthropology and archaeology.\nOpening King Tut’s tomb Archaeology is the study of historic or prehistoric people and their culture through the study of their artifacts, monuments and other items they left behind. Many archaeological sites are discovered accidently, often during construction projects. How they have new, almost forensic-like science to collect pollen and understand the vegetation. They do things that are unprecedented, in a way, and it’s very beautiful to see that.\nI’m really intrigued by modern-day archaeology. For example, a square foot in one of the caves in the filmit took five months to remove half a centimeter of sediment. Every single grain of sand was picked up with a pair of pincers and documented with laser measurements."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:52b1620f-44c1-40c1-b2bb-aeab4ff7ab00>","<urn:uuid:192d7cf2-cd61-4c6c-838c-86fb64e41eb7>"],"error":null}
{"question":"What is the optimal timing and composition of pre-workout nutrition for maximizing muscle growth?","answer":"According to a 2001 University of Texas study, consuming a shake containing amino acids and carbohydrates before working out increases protein synthesis more than consuming it after exercise. The ideal pre-workout nutrition should include 20 grams of protein and 35 grams of carbohydrates, taken 30 to 60 minutes before exercise. This can be achieved through a protein shake or alternatively through a sandwich made with 4 ounces of deli turkey and American cheese on whole wheat bread.","context":["Maximise Muscle Building\nAs you've probably heard from any muscle-bound behemoth you've ever encountered, protein is the key to building muscle. Just because the shake-pounding meathead has become a trope, however, doesn't mean they're wrong; protein really is the fuel your muscles need to grow. That's real capital-S Science, not just bro-science manufactured by supplements companies.\nBut your body is constantly draining its protein reserves for other uses, like making hormones. The result is less protein available for muscle building. To counteract that, you need to \"build and store new proteins faster than your body breaks down old proteins,\" said Michael Houston, Ph.D., a professor of nutrition at Virginia Tech University.\nThe conventional wisdom says if you're trying to gain muscle, you need to take in one gram of protein per pound of bodyweight, although updated research from McMaster University suggests you may not need that much.\nBy that logic, an 80kg man should consume around 160 grams of protein a day—the amount he'd get from an 8-ounce chicken breast, 1 cup of cottage cheese, a roast-beef sandwich, two eggs, a glass of milk, and 2 ounces of peanuts.) If you don't eat meat for ethical or religious reasons, don't worry — you can count on other sources, too. Soy, almonds, lentils, spinach, peas, and beans are packed with protein.\nSplit the rest of your daily calories between the other two types of macronutrients, carbohydrates and fats. You'll want about 12 to 15 percent of your daily caloric intake from protein, 55 to 60 percent from carbs, and 25 to 30 percent from fats, according to National Strength and Conditioning Association (NSCA) guidelines.\nQuit Cutting Calories\nIn addition to adequate protein, you need more calories (your protein intake contributes to your total caloric intake, so these two go hand in hand). Use the following formula to calculate the number you need to take in daily to gain one pound a week, and break down your diet using the macro guidelines listed above. (Give yourself two weeks for results to show up on the scale. If you haven't gained by then, increase your calories by 500 a day.)\nA. Your weight in pounds.\nB. Multiply A by 12 to get your basic calorie needs.\nC. Multiply B by 1.6 to estimate your resting metabolic rate (calorie burn without factoring in exercise).\nD. Strength training: Multiply the number of minutes you lift weights per week by 5.\nE. Aerobic training: Multiply the number of minutes per week that you run, cycle, and play sports by 8.\nF. Add D and E, and divide by 7.\nG. Add C and F to get your daily calorie needs.\nH. Add 500 to G. This is your estimated daily calorie needs to gain 1 pound a week.\nWork Your Biggest Muscles\nIf you're a beginner, just about any workout will be intense enough to increase protein synthesis. But if you've been lifting for a while, you'll build the most muscle quickest if you focus on the large muscle groups, like the chest, back, and legs. Add compound lifts like squats, deadlifts, pullups, bent-over rows, bench presses, dips, and military presses to your workout to work them the most efficiently.\nYou're aiming to kick start muscle hypertrophy, the cellular process that spurs growth. Researchers have found that the best way to initiate that process is by performing two or three sets of an exercise for six to 12 repetitions, with about 30 to 60 seconds' rest between sets. You're damaging the muscles with the work — then the protein you've been consuming will help build them back up even bigger.\nAnother way to help with muscle gain is to cut back on the cardio. If you run every day, you're going to have a hard time packing on the pounds — so keep your aerobically stimulating workouts to the days you're not in the gym.\nMake Sure to Pregame Properly\nA 2001 study at the University of Texas found that lifters who drank a shake containing amino acids and carbohydrates before working out increased their protein synthesis more than lifters who drank the same shake after exercising. The shake contained 6 grams of essential amino acids — the muscle-building blocks of protein — and 35 grams of carbohydrates.\n\"Since exercise increases bloodflow to your working tissues, drinking a carbohydrate-protein mixture before your workout may lead to greater uptake of the amino acids in your muscles,\" Kevin Tipton, Ph.D., an exercise and nutrition researcher at the University of Texas in Galveston, told Men's Health.\nFor your shake, you'll need about 20 grams of protein — usually about one scoop of a whey-protein powder.\nCan't stomach protein drinks? You can get the same nutrients from a sandwich made with 4 ounces of deli turkey and a slice of American cheese on whole wheat bread. Just make sure to hit your macros — 20 grams of protein, 35 grams of carbs — no matter what.\nAt the end of the day, though, the drink is better. \"Liquid meals are absorbed faster,\" Kalman said. So tough it out. Drink one 30 to 60 minutes before your workout.\nRest for Gains\nTry a full-body workout, followed by a day of rest. Studies show that a challenging resistance training workout increases protein synthesis for up to 48 hours immediately after your exercise session.\n\"Your muscles grow when you're resting, not when you're working out,\" says Michael Mejia, C.S.C.S., former Men's Health exercise advisor and skinny guy who packed on 40 pounds of muscle using this very program.\nDown Carbs After Your Workout\nResearch shows that you'll rebuild muscle faster on your rest days if you feed your body carbohydrates. \"Post-workout meals with carbs increase your insulin levels,\" which, in turn, slows the rate of protein breakdown, said Kalman. Have a banana, a sports drink, and a peanut-butter sandwich.\nEat Every 3 Hours\n\"If you don't eat often enough, you can limit the rate at which your body builds new proteins,\" said Houston. Take the number of calories you need in a day and divide by six. That's roughly the number you should eat at each meal. Make sure you consume some protein — around 20 grams — every three hours.\nGet Built Before Bed\nEat a combination of carbohydrates and protein 30 minutes before you go to bed. The calories are more likely to stick with you during sleep and reduce protein breakdown in your muscles, Kalman said. Try a cup of raisin bran with a cup of skim milk or a cup of cottage cheese and a small bowl of fruit.\nYou can also try a pre-bedtime shake made with casein, a type of protein that breaks down more slowly than the better-known whey variety. Casein stays in the body longer and can act as a key component to muscle building while you snooze.\nEat again as soon as you wake up. \"The more diligent you are, the better results you'll get,\" said Kalman."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:aaafa81b-9c50-43d8-92b9-999a5178ad0a>"],"error":null}
{"question":"Hey, what are the main differences between how Clinical Governance and compliance programs handle documentation and reporting?","answer":"Clinical Governance and compliance programs have distinct approaches to documentation and reporting. Under Clinical Governance, documentation focuses on accurate patient records and transparent care plans as part of the duty of candour, requiring openness when things go wrong. In contrast, compliance programs require more extensive documentation including employee training records, compliance policies, investigation reports, and specific billing documentation to prevent fraud. While Clinical Governance emphasizes clinical quality assurance and patient safety reporting, compliance programs mandate systematic reporting mechanisms for regulatory violations with explicit non-retaliation protections and formal investigation procedures for addressing detected violations.","context":["Why Clinical Governance?\nClinical Governance was introduced in response to a series of high-profile failures in care that were highlighted in the UK during the 1990s. Incidents like the Bristol heart scandal, where substandard practices led to the deaths of numerous children, underscored the need for a structured framework to oversee clinical excellence and patient safety.\nWhat is Clinical Governance: A Definition\nClinical Governance is a framework through which healthcare organizations are accountable for continuously improving the quality of their services and safeguarding high standards of care. It integrates fundamental principles that ensure patient safety, effective clinical practice, and high-quality healthcare.\nKey Components of Clinical Governance\n- A Strategic Framework: Aims to create an environment where excellence in clinical care will flourish.\n- Quality Assurance: Involves systematic review, monitoring, and improvement of all aspects of patient care.\n- Patient-Centric: Focuses on delivering care that is patient-focused and driven by patient needs and outcomes.\nThe Five Pillars of Clinical Governance\n- Involving patients in their own care decisions, like having input into treatment options.\n- Ensuring patient rights and providing access to information, exemplified by transparent care plans and open communication channels.\n- Delivering care based on the best available evidence, such as adhering to research-backed protocols for disease management.\n- Utilising clinical guidelines, like using standardised stroke care pathways to ensure best practices are followed.\n- Identifying potential risks to patient safety and implementing strategies to prevent harm.\n- Performing regular risk assessments and learning from incidents.\n- Identifying potential risks to patient safety, such as assessing the risks of falls in elderly patients and implementing preventative measures.\n- Performing regular risk assessments and learning from incidents, like reviewing medication errors to enhance pharmacy practices.\n- Ensuring all healthcare staff have the necessary qualifications and skills through credentialing processes and competency assessments.\n- Fostering a culture of continuous learning and professional development, like providing regular clinical skills workshops.\n- Continuously assessing and improving healthcare processes, such as streamlining patient admission workflows to reduce wait times.\n- Encouraging innovation and embracing changes that enhance patient care, like adopting telehealth services for remote monitoring.\nImplementing Clinical Governance\n- Leadership and Culture: Strong leadership is vital to foster a culture of quality and safety.\n- Education and Training: Regular training programs to update staff on the latest guidelines and practices.\n- Audit and Feedback: Regular audits to assess performance, followed by constructive feedback and action plans.\nThe Role of Clinical Governance in Radiography\n- Enhancing Diagnostic Accuracy: Ensuring protocols are followed, like double-checking patient IDs to improve the accuracy of diagnostic imaging.\n- Radiation Safety: Implementing strict protocols, such as ALARA (As Low As Reasonably Achievable) principles, to minimise patient exposure to radiation.\n- Continual Professional Development: Keeping radiographers up-to-date with the latest techniques and safety measures through annual certifications and training.\nAccountability and Transparency\n- Duty of Candour: Being open and honest when things go wrong, such as disclosing adverse events to patients and families.\n- Record-Keeping: Accurate documentation, like maintaining detailed patient records, is a legal requirement and facilitates quality assurance activities.\nClinical Governance is not just about policies and procedures; it’s about creating a culture where quality care and patient safety are at the heart of healthcare delivery. It involves everyone within the organisation, from frontline staff to senior management, all working together towards a common goal of excellence in patient care. It’s a commitment to continuous improvement, transparency, and a holistic approach to healthcare that benefits patients and providers alike.","Continuing Education (CE) for Orthodontists\nThe continuing education article below is available at no cost to orthodontists and general dental practitioners who perform orthodontics.\nIn order to earn continuing education credits, you must be a paid subscriber of Orthodontic Practice US and complete a short quiz about the content of the article.\nEarn up to 24 online dental CE credits per year! Purchase a subscription now.\nEducational aims and objectives\nThis article aims to discuss the importance of creating and operating effective internal compliance programs in dental and orthodontic practices.\nOrthodontic Practice US subscribers can answer the CE questions by taking the quiz to earn 2 hours of CE from reading this article. Correctly answering the questions will demonstrate the reader can:\n- Define systematic compliance programs.\n- Realize the potential for serious penalties for health care reimbursement fraud and abuse.\n- Recognize the structure of a compliance program necessary to minimize potential regulatory risk.\n- Recognize the importance of compliance training.\n- Realize the need for consistency in compliance policies.\nHealth care regulatory lawyer John Fisher shares his insights into an effective compliance program for orthodontic practices.\nJohn Fisher, JD, CHC, CCEP, discusses the elements needed to implement an effective compliance program\nSystematic compliance programs have become a necessary mechanism to reduce the risk of potential regulatory penalties. Providers are putting more and more resources into formal programs and processes aimed at proactively identifying areas of regulatory risk and using self-audits to self-police for overpayments, potential abuse, and even health care fraud. This article identifies the importance of creating and operating effective internal compliance programs in dental and orthodontic practices and identifies the basic elements that should be present to assure that a compliance program is effective.\nReimbursement risks and compliance focus\nThe primary force necessitating pro-active compliance efforts are the potentially serious penalties for health care reimbursement fraud and abuse.1 Providers are subject to potential program exclusion, civil monetary penalties, False Claims Act penalties, and even criminal exposure for failure to follow complicated reimbursement rules.2 Dental and orthodontic practices receive significant governmental reimbursement, especially through the Medicaid program. In fact, the Affordable Care Act resulted in an expansion in orthodontic coverage for children whose medical necessity criteria are met in situations involving medical issues such as malocclusions that are caused by trauma. As reimbursement opportunities have expanded, we have seen an upswing in fraud enforcement actions in the dental area. Claims audits, overpayment demands, governmental investigations, and even fraud prosecutions are becoming more common in the dental industry.\nRecent dental fraud cases\nYou can open virtually any dental industry trade publication and find current examples of fraud prosecutions involving providers in the dental industry. A few recent fraud cases illustrate that dentistry is not immune from fraud and abuse scrutiny.\n- In 2014, a large national pediatric dental chain was excluded from participation in the Medicare and Medicaid programs following allegations of overbilling resulting from the provision of medically unnecessary services.3\n- In 2019, North Carolina prosecutors reached a $728,450 settlement with a dentist following allegations that the provider performed and billed for medically unnecessary services.4\n- A New York dentist, office manager, and dental assistant were accused of paying Medicaid recipients $25.00 to undergo minimal dental procedures and billing Medicaid for additional dental services that were not provided. According to the DOJ press release, the dentist was sentenced to a prison term of up to 10 years.5\n- A West Virginian dentist was sentenced to 5 years in jail and agreed to repay $2.2 million for falsely billing Medicaid more than $700,000 for services that were improperly upcoded from simple extractions to extractions of impacted teeth.6\nMore typical compliance issues\nWhile the reported cases are illustrative, the typical dentist does not normally engage in systematic health care fraud. Yet even the most honest provider can fail to adequately document a service in a manner that supports the code under which the service is billed. The more common situation occurs, for example, when a provider knows that he/she actually provided a medically necessary service, but the documentation does not sufficiently support the medical necessity of the service or a more complex service. For example, a dentist might extract a wisdom tooth, but not properly document that a more complex extraction was necessary because the tooth was impacted. Documentation deficiencies tend to be repeated if they are not monitored or audited. The end result can be a significant overpayment obligation over time. Although these cases might not amount to intentional fraud, they can still result in significant penalties if not handled appropriately.\nIn the worst circumstance, the resulting overpayment is not discovered by the provider but is investigated by the government when it is identified by a government audit, by whistleblower complaint, or through statistical analysis of the provider’s claims data. The more favorable set of circumstances occurs when the provider discovers the pattern of mistaken documentation and resulting incorrect billing through self-auditing performed as part of an effective compliance program. Discovering the problem internally permits the provider to correct the situation going forward and repay the overpayment that occurred through past incorrect billing. Self-disclosure never permits the provider to avoid the obligation to repay the overpaid amount. In fact, failing to promptly repay a discovered overpayment can result in very serious penalties or even criminal charges for deliberate fraud.7 However, providers will normally not incur serious penalties if they bring the error to the attention of regulators and promptly repay any resulting overpayment. This is where a systematic compliance program comes into play. The compliance program operates to identify the most critical areas of risk to the provider and focuses resources on identifying and preventing regulatory violations in the identified risk areas. Where past infractions are discovered, the compliance program requires prompt identification, repayment, and possible use of the self-disclosure protocols when necessary to mitigate further regulatory exposure.\nCompliance program structure\nConsistently operated compliance programs are the single best way to minimize potential regulatory risk. A compliance program creates a living and breathing process to continually assess the risks that are present in a specific organization. Large organizations will have broad compliance program coverage to reflect the risk profile of a large and diversified organization. A smaller and more operationally focused organization will have a smaller risk profile, and the scope and depth of compliance coverage will necessarily be more modest. What is important is that each organization focuses on the specific risk that applies to the nature and scope of its operations. Each organization should have a process to identify and rank the most significant areas of risk. Based on a prioritized list of compliance risks, the organization can make decisions about allocation of resources in furtherance of proactive auditing, monitoring, or other processes to determine compliance and to take corrective action where necessary. That is a compliance program in a nutshell.\nThe seven elements of a compliance program\nThere are numerous details that should be present to assure compliance effectiveness, many of which should be reflected in policy and in practice. The compliance industry has developed standard compliance program elements and the detailed requirements within each of these requirements.8 For the most part, these compliance program elements emanated from the Federal Sentencing Guidelines, which give cooperation credit based on the existence of an effectively operated compliance program.9 Seven core elements of compliance can be distilled from the sentencing guidelines. These basic elements have been brought forward into more recent regulations that mandate compliance program operation in certain areas of health care, as well as compliance program guidance documents that have been issued by the Office of Inspector General and the United States Department of Justice over the years.10 Every compliance program, large or small, should contain each of the following core seven elements of compliance.\n- Compliance officer\nA high-ranking member of management must be appointed to act as compliance officer. In a smaller practice, a compliance-responsible individual can be used rather than a full-blown compliance officer. Compliance program structure can be scalable to the size and resources of the provider and the nature and complexity of the business. Larger organizations will require a dedicated compliance officer and even a developed compliance department with a range of compliance support staff. Smaller organizations can get by with a compliance individual who holds other roles within the organization. Be careful about relying too much on concepts of scalability. The central requirement is that the individual who is responsible for compliance has sufficient time and resources to properly conduct the necessary compliance activities at a level that is appropriate for the size and nature of the provider organization.\n- Compliance policies\nCompliance policies should be put in place that describe the process to be used to conduct ongoing compliance activities. Compliance policies will define compliance operations and will also outline requirements in risk areas that are specific to the nature of the practice. Every program should have certain core areas of policy coverage such as establishment of a continually functioning process, definition of the seven key elements, and other areas that are central to the core requirements of compliance. Each organization should also develop specific policies covering areas of identified risk within the organization. For example, an organization that takes government reimbursement will want to have reimbursement policies. There can be general reimbursement policies, but there should also be policies covering the requirements for common areas of billing that take place within the organization. For example, an orthodontic practice that provides medically necessary services to children and receives Medicaid reimbursement should have a specific policy addressing the requirements for receiving reimbursement, including appropriate documentation of medical necessity.\n- Compliance training\nEmployees, contractors, and others must be trained on basic compliance program elements and risk areas that are applicable to their job functions. Compliance training requirements should be described in training policies. All staff should be required by policy to take core compliance training and periodic refresher training. Staff should also be required to take more detailed or specialized training in areas required by the nature of their position. For example, billing staff will need to undergo more detailed and specific training on the billing process and rules that they are likely to encounter. Health information staff may require more detailed training on HIPAA and patient privacy issues. The bottom line is that each employee should receive the training that they need to assure that they perform their job tasks without running afoul of regulatory requirements. All training must be adequately documented with employee rosters, coverage material, employee training acknowledgment, and other details. Assume that you will be in the position in the future to have to prove that your employees received the training that they need. You should also be certain to follow up to assure that employees comply with training requirements. Discipline should be issued if necessary to assure compliance.\n- Compliance reporting and nonretaliation\nA compliance reporting system and protection of individuals reporting potential compliance issues is a critical element of any compliance program. It is much better to learn about potential problems internally before they ripen into situations that are difficult or expensive to solve. Your compliance program must continually emphasize the importance of reporting potential issues. Systems should be set up to encourage reporting, protect confidentiality, and assure that those reporting potential issues are protected from retribution. Every employee must know that they are encouraged to report concerns without fear of retaliation. Protection against retaliation must be enforced even if the report turns out to be incorrect, as long as the report is made in good faith.\n- Disciplinary standards\nPolicies mean very little if employees think that nothing will happen to them if they do not follow them. There needs to be policy coverage that ties compliance requirements to the employee discipline process. The discipline process should be used where appropriate to enforce standards. There cannot be selective enforcement. It should be clear that everyone in the organization — from the newest, lowest level support worker through the most productive licensed provider, owner, and most senior executive — is subject to discipline if they fail to abide by the compliance program.\n- Compliance risk identification\nA compliance program must include a system to continually identify areas of potential compliance risk. The areas of most significant risk should be ranked by priority. Prioritized risk should be integrated into regular compliance work plans. Even if a risk area is not scheduled for auditing, a record should be created to indicate that it was considered, and a reasonable judgment was made that other issues were higher priorities. Although resources must be allocated to compliance in order to make an effective program, the level of available resources will not be infinite. Reasonable choices about relative importance of compliance risk areas are appropriate. Even if a compliance infraction occurs in an area of less critical risk, the documentation of a reasonable risk identification and prioritization process will help reduce the risk of penalties.\n- Systematic investigation and response to detected violations\nA compliance program must include a system of appropriately responding to identified compliance problems through creation of appropriate corrective action. Policies should include requirements for investigating and addressing reported compliance issues. Where appropriate, repayment, self-disclosure, and other appropriate corrective action should be mandated by compliance policies. These policies define the standards and requirements to audit against to assure that standard processes are followed when issues are reported. Based on your assessment of adherence to investigation and corrective action standards, enhancements can be identified and implemented through additional policies or revision of current policy.\nThe “living and breathing” ongoing process of compliance\nPerhaps most importantly, a compliance program should create a “living and breathing” process of continual operation of improvement. It is not adequate to adopt a set of compliance policies, put them on the shelf, and watch them collect dust over the years. In order to mean anything, a compliance program must be effectively operated to detect and address compliance issues. In order to meet effectiveness requirements, a compliance program must continually operate to identify new risk areas, address these areas in policy, continually assess compliance and operational requirements, identify enhancements, and integrate those enhancements by adopting new or revised standards. The compliance system is cyclical in nature, always assessing itself, always improving, always detecting new risks, and always measuring ongoing performance. If you are able to create this type of “living and breathing” compliance organism, you can be rest assured that you have an effective compliance program.or-patient-relationship.\nA compliance program in regulatory aspects differs from the challenges faced in clinical compliance. Read Dr. Laurance Jerrold’s article on legal-aspects of terminating a dentist-patient connection.\n- Billing-related fraud is not the only driver of compliance activities. The dental industry is subject to a variety of regulations, including Health Insurance Portability and Accountability Act (HIPAA), OSHA regulations, and various regulations promulgated under the Affordable Care Act such as translation requirements and prohibitions against a variety of discriminatory activities. Reimbursement issues carry potentially catastrophic fines and penalties and have been a primary force driving proactive compliance program development.\n- For example, the Federal False Claims Act imposes penalties of three times the amount of an overpayment plus between $11,000 and $22,000 per claim. Under federal law, a simple overpayment becomes a False Claim if not repaid within 60 days after the overpayment is identified. Final regulations were published in the Federal Register on February 12, 2016 in 81 Federal Register 7653. https://www.federalregister.gov/documents/2016/02/12/2016-02789/medicare-program-reporting-and-returning-of-overpayments\n- OIG Excludes Pediatric Dental Management Chain from Participation in Federal Health Care Programs, Office of Inspector General Newsroom, April 3, 2014; https://oig.hhs.gov/newsroom/news-releases/2014/cshm.asp\n- Attorney General Reaches $728k Settlement in Medicaid Fraud Case, Dentistry Today, June 3, 2019; https://www.dentistrytoday.com/news/industrynews/item/4908-attorney-general-reaches-728k-settlement-in-medicaid- fraud-case\n- Unlicensed Dentist Convicted of Healthcare Fraud, Conspiracy to Commit Healthcare Fraud, And Conspiracy to Violate the Anti-Kickback Statute, Press Release from the Department of Justice, U.S. Attorney’s Office, Southern District of New York, December 10, 2018; https://www.justice.gov/usao-sdny/pr/unlicensed-dentist-convicted-healthcare-fraud-conspiracy-commit-healthcare-fraud-and\n- The dentist was sentenced to 5 years and agreed to repay approximately $2.2 million; https://www.wvgazettemail.com/news/legal_affairs/ex-charleston-dentist-sentenced-to-federal-prison-for-medicaid-fraud/article_af48c947-83fc-5478-b0d3-9eab4b7178ff.html\n- Repayment and Self Disclosure of Known Overpayments, John H. Fisher, Blue Ink Blog, May 3, 2017; https://\n- The Office of Inspector General of the Department of Health and Human Services has issued a series of compliance program guidance documents covering a variety of segments of the health care industry. The most helpful guidance documents to dental and orthodontic practices follow: The Compliance Program Guidance for Individual and Small Group Physician Practices (65 Fed. Reg. 59434; October 5, 2000) and the Compliance Program Guidance for Third-Party Medical Billing Companies (63 Fed. Reg. 70138; December 18, 1998). These documents can be accessed on the OIG’s Compliance Guidance web page located at https://oig.hhs.gov/compliance/compliance-guidance/index.asp\n- The United States Federal Sentencing Guidelines offer incentives to organizations to reduce and ultimately eliminate criminal conduct by providing a structural foundation from which an organization may self-police its own conduct through an effective compliance and ethics program. §8B2.1 of the Federal Sentencing Guidelines identifies various factors that are indicative of an effective compliance and ethics program. https://www.ussc.gov/guidelines/2015-guidelines-manual/2015-chapter-8\n- On April 30, 2019, the United States Department of Justice released its Evaluation of Corporate Compliance Programs. The document provides detailed guidance on compliance program structure. See Criminal Division Announces Publication of Guidance on Evaluating Corporate Compliance Programs, April 30,2019; https://www.justice.gov/criminal-fraud/page/file/937501/download"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:f958f413-97d2-4957-8764-b0085a4328c3>","<urn:uuid:d41fde8d-4c38-4cda-a550-09f822ab3146>"],"error":null}
{"question":"What are the key differences between RapidSOS and Firza in their approaches to improving healthcare efficiency through digital technology?","answer":"RapidSOS and Firza take different approaches to healthcare efficiency. RapidSOS focuses on emergency response by updating the 911 system, providing better location services and additional data from IoT devices to emergency call centers. The platform can share vital information like vehicle details and patient vital signs with first responders. In contrast, Firza aims to reduce primary healthcare workload by using Robotic Process Automation (RPA) and Artificial Intelligence to optimize medication management through centralized workforce solutions.","context":["5 IoT Healthcare Devices and Platforms for Digital Care\nTable of contents\nThere are some trends out there that are hard to explain. Consider that the music video Gangnam Style has gotten more than 3.2 billion views on YouTube, probably making more money than the top-10 AI startups in South Korea combined. Some are much easier to explain, like everyone suddenly wanting to be a ganjapreneur and investing in pot stocks before the green rush is over. And some trends actually make financial sense. That’s what we’re starting to see when it comes to the so-called digitization of healthcare. After all, who wouldn’t want a piece of a $3.5 trillion market? In particular, the role of the Internet of Things – and, by default, Big Data and Artificial Intelligence – is poised to grow exponentially, as IoT healthcare devices find their way into everything from smart pills and smart inhalers to smart thermometers and nicotine patches.\nWhy IoT in Healthcare Could be Big Business\nYou don’t have to take our word for it. At this year’s IoT Evolution Expo in Fort Lauderdale, the program featured 10 sessions on IoT in healthcare. The opening discussion was hosted by a couple of representatives from SAS, a private data analytics company that’s been around since 1976. Healthcare analytics through AI and IoT is one of its key competencies, and the company is pushing hard for analytics as the best path toward what is called value-based healthcare. Value-based healthcare providers get paid to make you better rather than for throwing every blood test short of leeches at you. (A few PPOs still cover blood-letting, we’re told.) Such analytics require data from IoT healthcare devices to find that value:\nA few fun facts from the presentation: Ye olde experts believe there will be some 20 billion IoT healthcare devices by 2020, up from a mere five million today. That equates to a $158 billion market by 2022, with healthcare startups raising some $1.5 billion in 2017, according to SAS. A variety of factors is driving the trend of IoT in healthcare, according to SAS, from advancements in sensors and machine learning to the anticipation of 5G connectivity to the popularity of wearables. Our recent coverage of Qolty shows how useful that data can be for medical research, something underscored by SAS and some local Florida universities that studied the benefits of IoT healthcare devices on the outcomes for pre-diabetic patients, for example.\nAnd Why IoT in Healthcare can be Risky Business\nDuring the course of our research, we came across a San Diego-based startup called Awarepoint thanks to an old market map (circa 2016) on IoT healthcare startups from the big brains at CB Insights, who used to offer more pro bono data before putting it all behind their high-priced paywall. Awarepoint developed Real-Time Location Systems (RTLS) for tracking medical equipment and people in medical settings. RTLS is kind of an indoor GPS – or a more sophisticated WiFi motion sensor – that uses sensors and a variety of technology platforms like WiFi and Bluetooth low energy to track people and assets. Awarepoint had taken in about $98 million since it was founded way back in 2002, according to Xconomy, before the startup suddenly shuttered some time last year. Of course, the collapse of a startup is nothing new, but we found more than one failed startup in this category, often being redirected to a site hawking derelict URLs, like a pawn shop for websites.\nHowever, the Awarepoint story doesn’t quite end there. Another company, CenTrak, with a similar business in RLTS, bought some of Awarepoint’s assets last year. That’s cool, we thought, let’s cover CenTrak. Except the Philadelphia company was snatched up in 2016 for $140 million by UK-based Halma (LN:HLMA), which owns a bunch of health, safety, and medical technology companies, many of which build sensors and other IoT devices. But we’ll save them for another day and focus on IoT healthcare devices.\nRTLS Tracking in Hospitals\nTurns out there are a few companies offering IoT healthcare devices and platforms for indoor tracking, including a 22-year-old Norwegian company called Sonitor that has only raised one recorded, single round of venture capital – $9.5 million in 2016. Its Real Time Location System (RTLS) solution is based on ultrasound technology, using acoustic waves to track people and stuff in hospitals and medical clinics using different hardware and software packages. The main platform, Forkbeard (named after famed Norwegian navigator Sweyn Forkbeard, who dethroned his father, King Bluetooth – true story), is reputedly 100 times more accurate than Bluetooth low-energy systems, getting location accuracy down to inches. (Sounds like a whole new way to define the term “digital twin“.)\nRLTS isn’t just useful for knowing where the bodies are, so to speak. Sonitor notes that its tags and receivers are now being used to track behaviors that can lead to infections. It can track the movement of people and equipment, such as wheelchairs and mattresses, to determine the time and exact location of when the zombie apocalypse began.\nMedication adherence is a big problem in the United States, and we’re not just talking about the opioid crisis. Patients only take chronic medications properly about half the time, according to research, and nonadherence accounts for up to 50% of treatment failures, around 125,000 deaths, and up to 25% of hospitalizations each year in the United States. No wonder it’s become a focus in IoT healthcare. One of the leading startups in this space must be Proteus Digital Health, which has developed a sensor system for tracking medication. We first covered them way back in 2013. Today, the company has raised nearly a half-billion dollars, and in 2017 received the first FDA approval of a digital medicine system using its ingestible sensor, wearable patch, and app.\nSuch smart pills aren’t the only way to track medication adherence. There are also smart pill bottles from startups like New York-based AdhereTech. Founded in 2011, the company has raised $3.8 million in disclosed funding, including an undisclosed “significant strategic investment” from Argentum, a growth equity firm that focuses on “bootstrapped companies seeking $5 to $15 million of capital.” GE is a previous investor. Here’s basically how it works:\nThe company claims its customers include most of the major specialty pharmacies. No wonder: AdhereTech says its smart bottles can generate one to two additional fills of specialty (i.e., expensive) medications, per patient per year. It also claims its smart pill bottles improve duration on therapy by 26%, fill rates by 9%, and dose-level adherence by 15%.\nOne could say wearable sensors are responsible for really driving the IoT healthcare device trend in the first place. The space has certainly evolved beyond Fitbit and Apple Watch, with all sorts of smart wearables for athletes to improve their performance or sensors that help you keep the 20th promise to your spouse that you’ll quit smoking. Other types of wearables could save lives in a different way.\nFounded in 2015, Flosonics Medical out of Canada raised $5 million last year for its smart bandage system called FloPatch, a wearable sensor that adheres to a patient’s neck and detects blood flow following clinical interventions. Targeted for ambulances, the emergency room, and intensive care units, FloPatch provides caregivers “physiological feedback on the effectiveness of their resuscitation, especially in the early stages of care.”\nUpdate 02/03/2021: Flosonics Medical has raised $14 million in Series B funding for their commercial launch in North America and new product development. This brings the company’s total funding to $20 million to date.\nSmart beds sound like one of those First World solutions in search of a problem, but who are we to judge. Based in the city that never sleeps, New York startup Eight bills itself as the first sleep fitness company. It has raised about $30 million in disclosed funding since it was founded in 2014, including a $14 million Series B about a year ago led by Khosla Ventures. Crunchbase says the $15 billion mattress market is ripe for disruption from companies like Eight, which uses sensors embedded into its line of mattresses to collect data. Then algorithms go to work to provide insights on sleep patterns such as how to improve REM and Tinder scores.\nUpdate 11/06/2019: Eight has raised $40 million in funding to invest heavily in research and development as well as workforce and retail growth. This brings the company’s total funding to $70.1 million to date.\nOne of our favorite Nicolas Cage movies is Bring Out the Dead, in which he plays a paramedic going off the deep end. Just imagine a drug-addled Hunter S. Thompson showing up at your door to save your life, and you have the basic film plot. New York-based RapidSOS is helping keep these emergency responders sane by updating our antiquated 911 emergency system. The company, founded in 2013, has raised $65 million toward that goal, including $46 million over two rounds within the last year. It has partnered with both tech giants like Google and Apple, as well as major public safety software companies like Motorola and Raytheon.\nRapidSOS is first and foremost about location, location, location. It turns out that the 6,500 call centers in the United States are still geared toward landline communications, despite the fact that up to 80% of emergency calls now come from cell phones, according to an article in Wired. While we might think that our GPS-enabled smartphone would make it easy to find us, the signal only gets you so close, though both Apple and Google have added emergency location services to device software to improve the results.\nRapidSOS closes the gap further through its software. It provides not just better location, but additional information to call centers, such as make, model, and color of an Uber vehicle. The platform can also pull in other data, from wearables and other IoT healthcare devices that might be pertinent for first responders, such as vital signs from a smartwatch or whether the user was on a fatal Tinder date.\nUpdate 06/09/2020: RapidSOS has raised $21 million in funding to continue expanding its data platform for first responders. This brings the company’s total funding to $119.7 million to date.\nThere are few emerging technologies with so many use cases as IoT, with the healthcare market coming to the forefront. As we collect more data about ourselves, the more we can improve our health and well-being. At least that’s the theory, and plenty of companies are buying into it. From GE buying a fetal sensor startup called Monica to Apple acquiring a sleep tracking startup named Beddit, the future of healthcare is in data and analytics. IoT healthcare devices and platforms will serve as the infrastructure of that transformation.\nBecome a premium member and get access to hundreds of premium articles, reports and additional content.\nNanalyze Premium is your comprehensive guide to investing in disruptive technologies. Read by the top investment banks, management consultancies, VCs, and research houses. Trusted by over 100,000 institutional and retail investors. Covering disruptive technologies for nearly two decades.","RYSE provides major funding boost for digital health start-ups\nPioneering digital health start-ups receive major funding boost to transform COVID-19 patient care\nAt a time when investment and funding prospects for the health tech and life science industry have dried up, and some investors have reneged on deals due to COVID-19: LiveSmart, Knok Healthcare, Log My Care, Firza, and MediShout are among the few start-ups to receive funding.\nPatients will benefit from enhanced care delivery thanks to innovations made possible by investments from RYSE Asset Management and other investors. These companies have raised a total of £4.5 million.\nBusy clinical working environments are faced with logistical issues that can create delays and increase the cost of care delivery. This has been particularly apparent during the pandemic where efficient redeployment of resources is paramount.\nVirtual consultations, workforce optimisation solutions for primary healthcare providers, platforms for digital virus tracking and care home digitalisation, and reporting solutions for logistical and medical supply issues for helpdesk prioritisation are just some of the innovations to receive investment.\nThe innovations and some of the jobs created include:\n- Firza is on a mission to reduce the overbearing workload on primary healthcare by using a centralised workforce with Robotic Process Automation (RPA) and Artificial Intelligence (AI) technology to emulate the actions of a human interacting with healthcare systems to optimise medication management. The company plans to employ an additional 45 people over the next year.\n- Knok Healthcare, a global telehealth and SaaS start-up, has an integrated solution for remote consultations through a combination of AI triage, scheduling, video-consultation, health records, and integration with hospitals and clinics. The company plans to employ an additional 19 people over the next year.\n- Log My Care has developed care management software and offers a free COVID-19 symptom tracking tool to support care homes in overcoming challenges in early symptom detection in this high risk population. The company plans to employ an additional 6 people over the next year.\n- MediShout has developed communication software that allows clinical staff to flag non clinical issues such as out of service facilities and reduced levels of PPE. This has allowed key healthcare workers to focus on delivering patient care. The company plans to employ an additional 15 people over the next year.\n- LiveSmart provides health assessments and reacted quickly to the new situation. The team sourced and supplied antibody tests via their well-established platform; supporting both small businesses and large corporate clients. The company plans to employ an additional 36 people over the next year.\nAll of the companies have been awarded seed funding as a result of their successful applications to the RYSE digital health funding programme. The programme invited early stage digital health and medtech companies to apply for funding with the opportunity to work alongside RYSE, DigitalHealth.London (DH.L), and MedCity.\nAshish Kalraiya, CEO at MediShout, said: “We are proud of our ability to innovate in direct response to the needs on the frontline, and during the COVID-19 pandemic it has been critical to ensure that the needs of patients affected by conditions other than COVID-19 continue to be met. The connections we have forged through working with RYSE, MedCity, and DigitalHealth.London mean we can devise creative solutions we know will best meet the needs of the NHS staff and patients. RYSE’s funding has transformed our innovation into a reality that benefits patients and our crucial NHS staff.”\nClaudio D’Angelo, Managing Partner at RYSE Asset Management LLP, said: “We are delighted to have seeded much-needed investment in these health tech start-ups who are transforming patient care through innovation. We are well aware of the funding gap for early-stage digital health innovations, even outside of COVID-19, and are passionate about plugging the gap to support the growth of this industry – and, critically, through public-private collaborations as we know this will have the greatest impact. The innovations developed with our funding demonstrate the huge return on investment investors stand to gain when they fund health tech start-ups.”\nSarah Haywood, Executive Director of MedCity, said: “Securing funding for early-stage health tech companies has always been a challenge; thrown into the unprecedented times of COVID-19 the challenge is even greater, particularly for companies not eligible for the Government’s Future Fund and for companies raising money for the first time. Now is innovation’s time to shine – demonstrating how it can meet patients’ needs as we unite across the globe to tackle this deadly virus.\n“We are immensely grateful to RYSE for their generous investment and for their recognition of the critical role these companies play. The innovations coming out of our partnership with RYSE and DigitalHealth.London bear testament to the profound contribution health tech start-ups make to our health systems and patients, and to what we stand to lose if the UK’s digital health sector is not supported to thrive. We also recognise the important role that early stage investors, like RYSE, play in supporting companies beyond investment. Mentoring, advice, guidance, and connections are equally important to the success of our next generation of innovators.”\nAnna King, Commercial Director, Health Innovation Network, a founder partner of DigitalHealth.London said: “We set up DigitalHealth.London to help encourage and support the development of digital health businesses working with the NHS. Investment from RYSE in these high potential companies has been vital to enable them to develop high quality products that meet patient needs in the NHS and internationally. We are delighted to see investors like RYSE supporting more companies in this exciting sector.”\nRYSE Asset Management LLP (RYSE), is a London based FCA authorised and regulated investment manager, tailored for high net worth individuals, family offices, and institutions. In partnership with DigitalHealth.London (DH.L) and MedCity to identify, support, and invest in early-stage digital health and MedTech companies, to commercialise and scale within the NHS and other healthcare delivery systems.\n- LiveSmart (health assessments): A PHE approved #COVID19 antibody test (Abbott).\n- Knok healthcare (virtual consultations): A check-up from the comfort of home provides social impact and safety.\n- Log my Care (care management): A free symptom tracking tool to help care homes detect early symptoms of #COVID19.\n- Firza health (medication management): Delivering technology and digital services for modern day primary care.\n- MediShout (healthcare reporting): Improving healthcare reporting logistics and supply chain issues during #COVID19 – improving the quality of care and reducing error.\nIn 20018, we also invested in:\nSkin Analytics (AI cancer screening): A new skin cancer community assessment service to reduce delays during #COVID19.\nDigitalHealth.London is helping health tech entrepreneurs and healthcare professionals turn the idea of digital innovation into tangible improvements for staff and patients.\nTheir iniatives bring together health and care stakeholders across London to collaborate and solve some of the biggest challenges in the NHS:\nDigital Pioneer Fellowship: The NHS Digital Pioneer Fellowship supports up to 30 digital change makers employed by NHS organisations in London to design and lead transformation projects underpinned by digital innovation.\nDigitalHealth.London accelerator: Each year, the Accelerator programme works with up to 20 high potential SMEs, giving bespoke support and advice, a programme of expert-led workshops and events, and brokering meaningful connections between innovators and NHS organisations with specific challenges"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:7edd8859-7a0d-4759-9681-d9eebd2fadae>","<urn:uuid:5d0272f0-6be7-481e-b33e-b9bf6c4fbd8f>"],"error":null}
{"question":"How do fake images and gun sanctuary resolutions both reflect recent political divisions? Can you compare their impact on public discourse and community response? 🤔","answer":"Both phenomena demonstrate how modern political divisions manifest, but in different ways. Fake images, like the manipulated Father's Day protest photo, can rapidly spread misinformation on social media and inflame emotions, as noted by the Pulitzer Center's managing director. Meanwhile, gun sanctuary resolutions have emerged as a direct response to Democratic victories in Virginia, with at least seven counties passing these symbolic measures to oppose anticipated gun control legislation. While fake images can instantly reach wide audiences online, gun sanctuary resolutions represent a more formal, community-level protest. The gun sanctuary movement has generated large turnouts at county meetings, like in Amherst where over 300 people attended, while fake images spread more quietly but potentially to millions through social media. Both reflect deep political divisions, though gun sanctuaries represent organized local resistance while manipulated images represent more diffuse attempts to shape narratives.","context":["Written by Emily Whalen\nEarlier this year, I scrolled through Facebook and I happened upon a photo of two women at a protest holding signs declaring “Fathers don’t deserve a day,” and “End Fathers (sic) Day.” A quick inspection and you can see that colors don’t quite match up, lines don’t either, and sure enough one of the Fs is printed over the sign holders gloved hand. It’s not even a good photoshop job. But here it is, on my feed, shared by an angry friend who didn’t see what I did.\nWhile this example seems almost silly, the ramifications of this image being shared with a simple click across all of Facebook and the internet can be frightening. “People take images as truth much more than words, and images can be manipulated. They can be used by someone with a vested interest to frame things in a certain way,” says Nathalie Applewhite, the managing director of the Pulitzer Center on Crisis Reporting.\nSo what is the role of photojournalism in the age of Facebook and Fake News?\nI don’t have to tell you the old adage that a picture is worth a thousand words. A sailor dips a nurse in a deep kiss in Times Square. Che Guevara stares defiantly into the distance in a close-up shot. A peaceful monk sets himself ablaze. Earthrise from the surface of the moon. One stark naked child running from an unplanned napalm explosion. A lone man staring down a line of tanks in Tiananmen Square. Bodies falling from the burning Twin Towers. The body of a dead child on the shores of a Syrian beach. A black woman defiantly walking into a group of police officers in riot gear. Photojournalism has shaped our world for decades.\nBut what if these pictures weren’t what they seem? Would they lose their value? Though “fake news” our current buzzword, the concept of fake news isn’t new. Photos have been manipulated for years thanks to photo editing software. It’s what has made models and celebrities look flawless for years, hiding imperfection and making colors pop. In fact, photo manipulation has been around almost as long as the camera.\nRecently RadioLab discussed Roger Fenton’s photo “The Valley of the Shadow of Death,” which just may be the first fake news photo in history. In 1855, during the Crimean War, Fenton took two photos from the exact same spot. “The Valley of the Shadow of Death” shows a winding road and rolling hills littered with cannonballs while the other, unnamed photo shows the road completely clear. Documentarian Errol Morris became obsessed with the photos, trying desperately to figure out which photo came first. Were the cannonballs placed on the road, or cleared from the road? It was optical engineer Dennis Purcell who looked in the distance and saw that a few rocks had shifted position, tumbling down the hill indicating that the photo of the clear road came first and Fenton placed all of the cannonballs himself. Is Fenton’s photo fake news, or is it simply an artistic interpretation of the Crimean War?\nA recent example of fake news vs. artistic interpretation comes from National Geographic, a magazine known not only for its epic photojournalism, but also for its journalistic integrity. Just hours after the total solar eclipse on August 21st, National Geographic posted Ken Geiger’s photo of the eclipse to their Instagram feed. Though the photo’s beauty is undeniable, showing various phases of the eclipse over the Grand Tetons, it is a composite of several images including one of sunrise over the Grand Tetons. However, the eclipse was never positioned over the Grand Tetons as the picture depicts. Though National Geographic does mention in the caption that the shot is a composite, it does still have one asking why they would use the composite, and not the actual photos of the eclipse.\nWith a camera phone in every pocket, and easy access to photoshop, it’s highly unlikely that fake photos will go away anytime soon. That doesn’t mean that photojournalism is any less valuable. Those photos not only reflect the world, but who we are in it. So many of the aforementioned images are seared into our brains, you still feel the emotions years, if not decades later: the hope of the end of war, the strength of a leader, the power of sacrifice, the awe of a new horizon, the fear of a child, the courage of one, the desperation of people trapped, the loss of a life barely lived, the resolution of a woman who won’t back down. But this doesn’t discount that we need to look at each new photo with a critical eye; sure it’s worth 1,000 words, but whose words are they and what story are they telling?","After Democratic victories, rural Virginia counties rush to declare themselves gun sanctuaries\nAmherst County residents raise their hands to show support for their county’s “Second Amendment Sanctuary” resolution. November 19, 2019. (Graham Moomaw/Virginia Mercury)\nAMHERST — In an overflowing meeting room, speakers repeatedly invoked the Virginia-born Founding Fathers who saw fit to enshrine firearms in the U.S. Constitution.\nOne man said the impeachment inquiry against President Donald Trump — which he suggested could be a “coup” — shows the need for an armed citizenry capable of standing up to tyranny. Another raised the possibility that, if Americans can’t keep their guns, they may one day have to “do like in Hong Kong,” where pro-democracy protesters are using improvised weapons like bows, firebombs and catapults to resist authorities.\n“The time is coming,” said Jeff Wade, an assistant pastor at a Baptist church in Madison Heights. “I’m mighty afraid that we’re going to have to defend ourselves because of what we believe in. Not only on the Second Amendment, but on any other issue that the government declares to be right, but God declares to be wrong.”\nThough the spirit of rebellion was running high among the crowd of well over 300 that packed the Amherst County Board of Supervisors meeting Tuesday night, the paper before the board was comparatively mild.\nAmherst — a rural county of almost 32,000 people north of Lynchburg — was set to declare itself a “Second Amendment Sanctuary,” following a mostly symbolic trend sweeping the countryside after Democrats triumphed in this month’s General Assembly elections while promising to enact tougher gun laws. With legislative majorities taking power for the session that begins in January, Democrats are expected to push for universal background checks, red flag laws that would allow authorities to take guns from people deemed to be a threat, bans on assault-style weapons and high-capacity magazines and other measures.\nCo-opting language some progressive cities have used to signal their immigrant-friendliness, Amherst officials were preparing to vote on a draft that declared gun rights “part of the fabric” of their county, something to be “respected and celebrated.”\nThough the concept is new to Virginia, conservative localities in several other states have already branded themselves Second Amendment sanctuaries, declaring that they support gun rights and oppose laws that could infringe upon them.\nOn Tuesday, Amherst’s leaders told the crowd they were prepared to pass the resolution, but they wanted to take a few days to fine-tune it for a future meeting.\nBoard Chairman Jimmy Ayers, a former sheriff, said no laws will be able to keep guns away from criminals who want them and suggested gun violence is caused by bad parenting.\n“We’ve become a society now that folks are not made to be accountable and responsible for their actions. That is the problem,” Ayers said.\nAt least seven counties — Carroll, Charlotte, Campbell, Appomattox, Patrick, Pittsylvania and Dinwiddie — have passed gun sanctuary resolutions, according to the Virginia Citizens Defense League, a pro-gun lobbying group helping to organize the effort.\nBy the time lawmakers return to Richmond in January, dozens more could follow.\nPhilip Van Cleave, the president of VCDL, predicted a “tsunami” of gun sanctuary resolutions.\n“I’ve never seen anything like this,” Van Cleave said. “Not with Virginia Tech. Not with any of these other things that have come up with Obama and everything else.”\nAsked if he’s concerned that stoking defiance of soon-to-be-enacted laws could contradict the notion that his group is made up of responsible, law-abiding gun owners, Van Cleave said “you’re not required to obey an unconstitutional law.”\n“That’s where the question is. Is it unconstitutional or not,” he said. “And some of that will be settled in the courts.”\nThe wave of local resolutions are a sign of the conservative backlash the new Democratic majorities can expect next year as they work to pass their gun proposals. But, on their own, the resolutions have little real-world impact beyond the message they send about where a particular community stands.\nIn a statement, Attorney General Mark Herring’s office said the resolutions “appear to be nothing more than symbolic.”\n“It’s not clear what a Second Amendment sanctuary is, what its proponents are hoping to accomplish, or what authority they think they have to preemptively opt out of gun safety laws, but if the Virginia Citizens Defense League is circulating it you can bet it’s a bad idea,” said Herring spokeswoman Charlotte Gomer. “If the General Assembly passes new gun safety laws, as Virginia voters demanded just two weeks ago, we expect that everyone will follow the law and keep their citizens safe.”\nA spokeswoman for Gov. Ralph Northam said Northam’s gun proposals are “basic, commonsense measures that any responsible gun owner should support.”\n“Let’s be clear, as the results of this election prove, Virginians are demanding their legislators take real action to combat gun violence and save lives,” said Northam spokeswoman Alena Yarmosky.\nReached by phone Wednesday, Sen. Dick Saslaw, the Fairfax Democrat will will retake his post as majority leader come January, didn’t mince words about those pushing the idea of gun sanctuaries.\n“They’re delusional,” Saslaw said.\nOutgoing House Majority Leader Todd Gilbert, R-Shenandoah, who will continue to lead the House GOP as minority leader next year, said the resolutions were an understandable show of opposition by people displeased with the elections and what the results will bring.\n“They are rightly up in arms about the notion that they would be made to be criminals overnight,” Gilbert said.\nBefore the Amherst supervisors discussed the resolution, Ayers asked everyone in the room who supported the resolution to raise their hand. The support appeared to be unanimous, but only because the lone voice of dissent was waiting in the hallway because she couldn’t get in.\nWhen her name was called to speak, Gloria Witt, a representative from the Amherst NAACP, took the lectern in front of the overwhelmingly white crowd and asked: “What are you afraid of?”\n“It’s not about taking your guns,” Witt said. “And the fact that all of Amherst County would show up in an outcry to stand against what might happen … What does that say about all these little counties?”\nDescribing herself as a “country girl,” Witt said all the men in her family have guns, but she sees no reason to oppose universal background checks and bans on military-style weapons.\n“As an African-American female, it’s quite interesting that you can get this kind of energy around something like this when we’re killing people with guns that were designed for military use,” Witt said as some in the crowd murmured disapproval. “Shooting an animal is one thing. Target practicing is another one. Having a gun that will shoot 50 rounds in 30 seconds, I argue, is not necessary.”\nSupporters of the sanctuary resolution in Amherst portrayed gun control as a threat to rural traditions, something that would punish people in places like Amherst for violence happening elsewhere.\nLowell Bowling Jr., a contractor, said he’s worried Virginia’s gun laws will soon be written by city-dwellers who aren’t used to shooting their own food or having to kill predators to protect a farm.\n“Around here, it’s a way of life,” Bowling said. “Most people were raised with ‘em. Our children are raised with ‘em.”\nBenny F. Woody Jr., who described himself as a 76-year Amherst resident, said he was concerned about the hunting ramifications of a bill that would prevent anyone under 18 from handling a firearm without adult supervision. Under current state law, it’s illegal for adults to let children under the age of 12 handle a gun without supervision.\n“My grandsons have been hunting since they were 9 and 10 years old. They know what’s right and know what’s wrong. They know gun safety,” Woody said. “And it’s unfair to them to take away something they’ve loved for all these years.”\nThough some supporters acknowledge the resolutions are symbolic, Van Cleave suggested counties could go a step further once new gun laws are enacted.\n“The county can direct its employees not to enforce unconstitutional gun laws,” Van Cleave said.\nRegardless of action by county boards, rural sheriffs, elected officials who serve as the chief law enforcement officers for their communities, could also wade into the gun debate.\nIn Southwest Virginia’s Lee County, Sheriff Gary Parsons already has.\n“I want to assure the citizens of Lee County that me and my officers will stand up to any federal or state agency that attempts to infringe upon our gun rights,” the sheriff’s office said in a Nov. 18 Facebook post.\nIn an interview, Parsons struck a more nuanced tone, saying he sees “some viability” in the idea of red flag laws, as long as there’s due process involved and it’s not used as a “weapon against people.” He said the post was meant to convey that his office would not participate in any effort to seize newly banned guns that were once legal.\n“I can’t affect what guns are allowed to be sold in the future,” Parsons said. “And I don’t know if we’re even looking at that.”\nMercury reporter Ned Oliver contributed to this report.\nOur stories may be republished online or in print under Creative Commons license CC BY-NC-ND 4.0. We ask that you edit only for style or to shorten, provide proper attribution and link to our web site. Please see our republishing guidelines for use of photos and graphics."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:ad041b5f-47b0-40ac-92c5-4f69445a5836>","<urn:uuid:26088b5f-fdd4-4184-9290-663827a5cb9d>"],"error":null}
{"question":"Hey project management experts! What's the key difference between getting certified through APMG vs PMI when it comes to career benefits? 💼","answer":"APMG and PMI certifications offer different career benefits. APMG certification focuses on Agile-specific skills, teaching practitioners how to deliver faster, cost-effective changes and implement Agile principles in project management. It provides knowledge about Agile practices, methodology, and DSDM approach. On the other hand, PMI's PMP certification offers broader career advantages, with PMP-certified professionals earning 23% higher salaries on average across 37 countries. PMP certification also provides better job opportunities, with 80% of high-performing projects using PMP credentialed project managers. The PMP certification is applicable across multiple industries including IT, telecom, business processing, commerce, and finance, and offers greater visibility to recruiters globally.","context":["Many people, nowadays, are looking to become Agile project managers. However, in order to do so, you must get properly certified, at least in most cases. Certification is simply the proof that you're skilled and experienced enough to manage the Agile projects and help your team(s). One of the best ways to get the proper certification is through APMG (Agile Project Management Group) International.\nThe APM group provides various certifications and training courses for both individuals and companies alike. Their own accreditation is proved by the United Kingdom Accreditation Service (UKAS), which is in turn accredited by the International Accreditation Forum (IAF). In turn, the APM Group is considered a global accreditation body and examination institute for Agile project management certifications.\nThis article will go into more detail about APMG agile project management and other stuff that you can get from this organization.\nThe APMG provides candidates with various different certification programs. You can attend different courses for different aspects of the Agile methodology and not just for project management. As an example, here are a few certifications you can acquire with the APM Group.\nSource: APMG International\n- Agile Digital Services (AgileDS) - This certification is for practicing project managers and Agile team members who wish to learn or improve their skills in the Agile digital service environment. You can learn about various Agile principles and how to implement those principles in the digital service environment. This certification consists of AgileDS Foundation and AgileDS Practitioner certificate.\n- Agile Business Analyst (AgileBA) - Anyone who wishes to become a business analyst in the Agile environment should consider this certification. A few of the things you'll be able to learn is how to help both the teams and the organization transition from traditional to Agile methods, how to play an integral part in successful project delivery, how to use a wide range of agile business analytics and how to use techniques for effective business analytics in the Agile collaborative environment. This certification consists of AgileBA Foundation and AgileBA Practitioner.\n- Agile Project Management (AgilePM) - Finally, you can get properly certified as an Agile project manager. You'll be able to learn how to understand and adopt the practical methodology of Agile practices and how to implement them in your project management activities. You'll also be able to comprehend what the Agile methodology is all about and how to utilize your newly found knowledge. As before, this certification consists of AgilePM Foundation and AgilePM Practitioner certificates.\nAside from providing you with certification, the APMG also provides you with proper training courses so that you can adequately prepare yourself for the exams. These training courses are also quite flexible. For instance, you can choose between various training courses accredited by the APMG or you can choose a self-study as an option.\nHowever, not all certification options allow self-study as a viable training method. In other words, depending on the certification you've chosen, you might have to take a training course, in order to qualify for the exam. As far as the exam goes, there's also a certain level of flexibility included here, as well. As an example, you can choose to take the exam online and from the comfort of your own home or you can choose to take an exam at a classroom or a public center.\nTaking an exam from home is based on the online proctoring system and you can take an exam 24/7 while taking a paper exam has to be scheduled either through one of the APMG's public centers or through one of the ATO's (Accredited Training Organization) that provide exams as part of their training programs.\nIf you worry about learning material you should know that APMG provides you with the proper books and learning material required to pass the exam. You can browse through their collection of study material, as well as opt for their recommended books on a specific subject. This is particularly useful if you choose a self-study option when you don't have the time to take an entire training course. Even if you do, in fact, attend a training course, these books can be beneficial as additional learning material for your exam preparations.\nWhy choose APMG in the first place?\nSource: APMG International\nFirst of all, the APMG is a reliable and accredited body for examination and certification of Agile project management courses. They provide you with vast knowledge about Agile practices and methodology. Some of the things you'll be able to learn are:\n- The foundation of principles and philosophy of Agile methodology.\n- Agile project's lifecycle, as well as the alternative configurations.\n- The process and the purpose of developed products within the Agile project.\n- The benefits and limitations of Agile techniques.\n- The responsibilities and roles within an Agile project.\nMore specifically for Agile project management, you'll be able to learn:\n- How to deliver faster, cost-effective and low-risk changes by implementing a proven approach to agile project management.\n- You'll be able to understand how agile in project management differs from traditional approaches.\n- Utilize different management styles needed for successful Agile projects.\n- Equip yourself with the core principles, concepts and processes that are required to ensure a successful Agile project.\n- You'll be able to learn how to apply the DSDM (Dynamic System Development Method) approach to projects and everyday activities, as well as adopt an evolutionary development approach, in order to ensure more effective solutions.\n- You'll be able to boost communication and stakeholder engagement skills that are crucial for the success of the project.\n- Help an organization deliver results effectively, with lower risks and costs by repeatedly validating project milestones against business objectives.\nIn other words, you'll be able to learn everything that you need, in order to become a successful Agile project manager. What's more, the only requirement is to pass the exams in the correct order starting from the Foundation level then passing the Practitioner level exam to get certified as the Agile project manager. This might seem easier than it actually is but it is well worth it in the end.\nIf you're looking to get certified as an Agile project manager, in order to find a better employment or familiarize yourself with the Agile concept, you don't have to look further than the APMG because they can provide you with the right knowledge and the right skills that will enrich your project management career.","Project Management Professional (PMP)\nWhat is PMP?\nProject management Professional is a globally acknowledged professional certification that validates a professional’s education and experience in Project Management Professional (PMP®) certification is a qualification program overseen by the Project Management Institute (PMI).\nProject Management Professional (PMP) is an internationally recognized professional designation offered by the Project Management Institute (PMI). As of March 2018, there are 833,025 active PMP certified individuals and 286 chartered chapters across 210 countries and territories worldwide.\nAdvantages of PMP\n- PMI Salary Survey Reveals That Project Management Professionals with the PMP Certification Earn 23% higher on average across the 37 countries.\n- Better Job Opportunities: PMP Certification opens up better career avenues and provides professionals with greater job opportunities in the project management world. According to a Price waterhouse Coopers survey, 80% of high-performing projects use PMP credentialed project managers; according to the PMI Pulse of the Profession study, organizations with more than 35% PMP certified project managers demonstrated much better project performance than those without a certification.\n- Applicable to Most Industries: The PMP certification is an ideal bet for all project managers in various professional fields, including IT, telecom, business processing, commerce, finance, research, and more.\n- Enhance Your Skills: It’s not easy to get the PMP certification and you need to undergo rigorous training for the same. There is a also a significant amount of coursework involved. You get trained and educated in in five project management processes—planning, initiating, implementing, monitoring and controlling, and finally closing. In short, you learn A-Z of project management which you can implement in your company projects for better project execution.\n- Earn More: PMP certified project managers earn more than the non-certified ones. As soon as you get your PMP degree, you can command a higher pay and you can expect an immediate hike. Many surveys have shown that PMP certified project managers earn at least 20 percent more than the non-certified counterparts. Also PMP certified professionals have the capability to earn a six figure income.\n- Greater Visibility To Recruiters: Research across industries suggests that organizations prefer hiring PMP certified project managers rather their non-credentialed peers. The PMP certification is a standard that demonstrates a professional’s expertise in project management and it immediately catches a recruiter’s eye during profile evaluation.\n- Expand Your Marketability: A PMP certification can help reach to global organizations working in different parts of the world. It enhances your professional marketability to a great extent and legitimize your experience as a project manager. You’d also be in touch with individuals aspiring to take up the course and PMP certified professionals as already mentioned, through project management forums and discussion boards, helping you to master your expertise with their tips and knowledge.\n|Eligibility Requirement||Four-Year Degree||Secondary Degree*|\n|Years of Project Management Experience||3 Years (36 Months)||5 Years (60 Months)|\n|Hours Leading & Directing Projects||4,500 Hours||7,500|\n|Hours of Project Management Education||35 Hours||35 Hour|\n- Indicate whether you have secondary diploma or a degree. You will need the name of the institution, the year you graduated, and your major.\nProject Management Experience\n- The experience must be leading or directing projects that are non-overlapping, cumulative across all process groups, and within the last 8 years to be counted on the PMI PMP application. Refer to the above table for full experience requirements.\nProject Management Education\n- You will need to show 35 contact hours of project management education, preferably covering initiating, planning, executing, monitoring and controlling, and closing. PMTI plans ahead for our students and provides an inclusive online course so you qualify for this requirement even prior to attend the class.\nWho should apply?\nAn experienced project manager who meets the following requirements:\n- Perform their duties under general supervision and are responsible for all aspects of the project for the life of the project.\n- Lead and direct cross-functional teams to deliver projects within the constraints of schedule, budget and resources.\n- Demonstrate sufficient knowledge and experience to appropriately apply a methodology to projects that have reasonably well-defined project requirements and deliverables.\nIf you are considering working toward your PMP exam, Process exam offers a variety of project management practice exam that will help you pass, including the PMP Certification practice exam. This Practice exam are conducted by certified, highly experienced professionals with at least ten years of experience.\nRead the following article:Tips and Tricks to pass PMP Certification in first attempt"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:2d7531a2-6324-441a-adef-0b73f7cc9cb8>","<urn:uuid:093b25ae-2272-46c9-a759-a39636b35c2d>"],"error":null}
{"question":"How does the U.S. naturalization process address language requirements, and what support systems exist to help immigrants overcome language barriers?","answer":"The U.S. naturalization process requires applicants to demonstrate English language proficiency during the interview/naturalization test, where they must show ability to communicate and write in English. To help immigrants meet these requirements, support systems like the HUG program promote English language acquisition as a tool for integration. They provide ESL instruction and literacy support, even helping illiterate clients learn to read and write from scratch. The program emphasizes that learning English is the first step in the citizenship process, with participants required to commit to language learning before being accepted into citizenship preparation programs.","context":["Carmen Myers epitomizes ‘the power of one’\nBy MARY JO WINTER / Cloverdale TOWNS correspondent\nBorn and raised in Guatemala, 67-year-old Carmen Myers is passionately proud of her American citizenship, so much so that for the last 27 years she has been helping other immigrants achieve the American dream of citizenship through a program she founded entitled HUG “For The Making Of New Americans.”\nThe primary goals of HUG, which stands for “Humanity Unity Group,” are:\n• Promote the acquisition of United States Citizenship by immigrants of any country who are living legally in the USA.\n• Promote and teach the English language as a tool to integration and understanding of United States History, culture and its way of life.\n• Promote Family Literacy with emphasis on Early Literacy teachings for parents to help their children to be successful in school, graduate from High School and go to trade schools or college if they choose it and have the ability to do so.\n“I was fortunate to have good parents,” Myers said. “My father instilled in me that knowledge is power. There was not money to buy books or a public library to borrow books from, so he would go to the city garbage dump to find books for me and my sister to read.”\nWhen she was 23, her friend and Anthropology professor helped her secure a visa to come to America to study the language. She arrived in Los Angeles not knowing a word of English. A mix-up in plans resulted in a 22-hour bus trip to Utah, where she lived for the next five months.\nMyers taught herself English by watching television for 12 hours every day for three months while her host family was at work. Afterwards, she moved to Southern California for 13 months where she took adult education classes to polish her new-found skills before returning to Guatemala.\n“Coming to the United States, I felt overwhelmed with the freedom and opportunities. It was a life-changing event for me.\nMyers met and married her American husband in Guatemala. After the devastating earthquake of 1976, they returned to the U.S. with their young son, settling in Southern California’s San Gabriel Valley.\nCommuting long hours for several weeks, and riding three different buses to the National Immigrants Law Center in downtown Los Angeles, she earned her Special National Immigration Paralegal Training certificate. The course was created to be able to meet the demand for Immigration services during President Reagan’s 1986 Amnesty Program.\nArmed with that training, Myers worked and volunteered as an immigration counselor and advisor for several churches before moving to Cloverdale in 1992. Initially, she volunteered as an ESL instructor and worked for Goodwill as an employment specialist, facilitating initial and post-employment workshops.\nAs part of SonomaWorks’ “Welfare to Work” program, she provided individual and group job search services to limited-English language participants, helping them better understand the American work culture. She continues that work with HUG, a grassroots program personally funded by Myers and her husband. For more information about HUG, call 894-2174 or email firstname.lastname@example.org.\nMany of her clients are illiterate, and many never went to school. She starts by teaching them to read and write. “Everything goes back to literacy,” she says, “everything.”\nBefore Myers accepts them, clients must be willing to meet her strict requirements.\n“They need to have a personal investment in the citizenship process,” she says. “They have to prove to me they are making a commitment to become a citizen, and the first step is for them to learn English.”\nMyers believes education has watered down history. “America was not created by an act of magic. It was built in another time and we cannot take that for granted. Even Americans seem to have forgotten our forefathers came here for freedom and a better life.”\nOne student, a 36-year-old man, made her especially proud when he became a citizen. He had never been to school and needed help learning to hold a pencil and sign his name. He spent three years completing the HUG program and learning English.\nCloverdale City Manager Paul Cayler, who studies Spanish with her each Friday, describes Myers as a catalyst for positive activity and action. “She likes to make things happen. Her perspective on our liberty and freedom in America is humbling.”\nAll of the citizenship preparation services offered by Myers through the HUG program are free. Participants pay only for their books and other learning materials, and for the citizenship fees that go directly to the U.S. Citizenship and Immigration Services.\nTo date, she has helped 438 people become US citizens through her program.\n“I am very happy that these people will embrace and celebrate our country,” she says. “Citizenship is both a gift and a privilege. It should not be taken lightly.”","The 6 Requirements For Naturalization\nU.S citizenship comes with notable advantages ranging from voting rights and government protection to access to some jobs, employment, the right to occupy public positions, the right to receive government assistance, and more!\nU.S Foreigners who want to get U.S Citizenship must go through a process known as naturalization. This process has several requirements, the most notable discussed below.\n6 Requirements Of Naturalization\nI. Establish Eligibility\nBefore you think of becoming naturalized or applying for a green card, you must be eligible. For instance, naturalization is preserved for adults only (18 years & above). You also need to be a current permanent resident, have a good moral character, and meet other USCIS eligibility requirements.\nII. Maintain Physical, Legal Presence In The U.S\nYou must have entered America legally i.e., via a valid visa and then maintained physical presence for a specified period of time (usually 5 years) before you are eligible to apply for naturalization. There may be exceptions to this requirement i.e., if you must travel outside the U.S for work.\nHowever, you must inform the USCIS. Applicants are also expected to meet physical location requirements i.e., live within a certain USCIS district or state. The USCIS website highlights a complete list of continuous residence requirements to consider.\nIII. Fill-In Form N-400\nAfter meeting the continuous residence requirements, you need to apply for naturalization via a special form (N-400). The USCIS, alongside other government agencies, assist in verifying information provided in the form. The form should be filled completely and truthfully to avoid rejection.\nSome of the information required include personal information like your name, country of birth, date of birth, employment history, criminal record, etc. Other information like family history is also required. If you have problems filling in anything, consult a lawyer.\nIV. Biometrics Screening\nThe USCIS collects biometric information as a requirement for naturalization. Your fingerprints will be collected, among other information like height, eye color, etc. Biometric screening is done at local USCIS offices near you. The essence of this requirement is to do a background check on applicants.\nV. Interview/Naturalization Test\nYou must pass a naturalization test before you become a U.S citizen. Applicants are given appointments with USCIS officers who review submitted N-400 forms and ask questions related to answers provided in the form. Interviews also assess an applicant’s ability to communicate and write in English.\nNaturalization may also include civics – Information about American history, government, allegiance to the U.S, and related information. Some applicants may be exempted from naturalization tests i.e., children and elderly. If you fail this test, you will be given one more chance, after which your application for naturalization will be rejected. To meet this requirement, it’s advisable to prepare thoroughly before sitting for a naturalization interview.\nVI. Oath Ceremony\nIf you pass the naturalization test, your application will be approved shortly after your interview. Before you become a U.S citizen, you must take part in a public oath ceremony aimed at giving applicants the opportunity to swear allegiance to the U.S. After the oath ceremony, individuals receive a naturalization certificate that acts as proof of U.S citizenship.\nTo increase your odds of successful naturalization, understand the naturalization process beforehand. For instance, you need a green card to become a permanent U.S resident. What’s more, you can only seek naturalization as a permanent resident. If you meet any hurdles when pursuing naturalization, consult a lawyer.\nGet Help From An U.S Immigration Attorney\nHow To Find Us\n1005 E 40th St\nAustin, TX 78751\n1616 Austin Avenue, Suite A\nWaco, TX 76701\nBy Appointment Only\nAustin & Waco\nCall or Text: (855) 502-0555\nFax: (512) 323-9351"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:d35e4d05-a023-4419-932a-0d63e1e7bf21>","<urn:uuid:ccb92a01-71a0-46e6-85e7-ae932e415909>"],"error":null}
{"question":"How is gallbladder cancer typically diagnosed? Could you explain the diagnostic process?","answer":"The diagnosis of gallbladder cancer typically begins with a visit to a family doctor who will ask about symptoms and conduct a physical exam. The diagnostic process includes several steps: First, doctors perform blood chemistry tests to measure certain chemicals and check organ function. Then, imaging tests like ultrasound (often the first imaging test), CT scans, and MRI are used to view the gallbladder and check for tumors. Tumor marker tests may be conducted to measure substances like CA19-9 and CEA levels. In some cases, a biopsy might be performed during an ERCP, laparoscopy, or through fine needle aspiration, though this isn't always necessary if imaging tests provide sufficient information. The cancer is often found in later stages since it usually doesn't cause early symptoms, and is sometimes discovered after gallbladder removal for other conditions.","context":["Your gift will be matched today.\nDiagnosis of gallbladder cancer\nDiagnosis is the process of finding out the cause of a health problem. Diagnosing gallbladder cancer may begin with a visit to your family doctor. Your doctor will ask you about any symptoms you have and may do a physical exam. Based on this information, your doctor will refer you to a specialist or order tests to check for gallbladder cancer or other health problems.\nGallbladder cancer is often found in the later stages because it usually does not cause any symptoms earlier.\nIt is sometimes found after the gallbladder is removed for other reasons such as gallstones or chronic cholecystitis (long-term inflammation of the gallbladder).\nThe process of diagnosis may seem long and frustrating. It’s normal to worry, but try to remember that other health conditions can cause similar symptoms as gallbladder cancer. It’s important for the healthcare team to rule out other reasons for a health problem before making a diagnosis of gallbladder cancer.\nThe following tests are commonly used to rule out or diagnose gallbladder cancer. Many of the same tests used to diagnose cancer are used to find out the stage (how far the cancer has progressed). Your doctor may also order other tests to check your general health and to help plan your treatment.\nHealth history and physical exam\nYour health history is a record of your symptoms, risk factors and all the medical events and problems you have had in the past. Your doctor will ask questions about your history of:\n- symptoms that suggest gallbladder cancer\n- non-cancerous conditions of the gallbladder such as gallstones or chronic cholecystitis\nYour doctor may also ask about a family history of gallbladder cancer.\nA physical exam allows your doctor to look for any signs of gallbladder cancer. During a physical exam, your doctor may:\n- feel the abdomen for any lumps, tenderness, swelling or fluid\n- look at the whites of the eyes and skin for yellowing (a sign of jaundice)\n- feel the lymph nodes in the groin\nFind out more about physical exam.\nBlood chemistry tests\nBlood chemistry tests measure certain chemicals in the blood. They show how well certain organs are functioning and can help find abnormalities. They may be used to diagnose gallbladder problems or gallbladder cancer.\n- An increased amount of bilirubin (a chemical in bile) may be a sign of a blockage of the bile ducts or a problem with the liver because of a gallbladder tumour.\n- An increased amount of alkaline phosphatase, alanine aminotransferase (ALT) and aspartate transaminase (AST) may be a sign that the cancer has spread to the liver.\nFind out more about blood chemistry tests.\nAn ultrasound uses high-frequency sound waves to make images of parts of the body. It is used to view the gallbladder and check for problems or cancer in people with abdominal pain or jaundice.\nAn abdominal ultrasound is often the first imaging test done when doctors suspect gallbladder cancer. It can confirm if the wall of the gallbladder is thicker than normal and provide information about the size of a tumour.\nAn ultrasound is also used to see if the cancer has spread to the liver.\nFind out more about an ultrasound.\nA computed tomography (CT) scan uses special x-ray equipment to make 3-D and cross-sectional images of organs, tissues, bones and blood vessels inside the body. A computer turns the images into detailed pictures.\nA CT scan is used to:\n- check for cancer in the gallbladder\n- find out where the cancer is in the gallbladder\n- see if cancer has spread outside the gallbladder to nearby lymph nodes, the liver or other places in the abdomen\nFind out more about a CT scan.\nTumour marker tests\nTumour markers are substances found in the blood, tissues or fluids removed from the body. An abnormal amount of a tumour marker may mean that a person has gallbladder cancer.\nTumour marker tests are generally used to check your response to cancer treatment. They can also be used to help diagnose gallbladder cancer.\nThe following tumour markers may be measured for gallbladder cancer:\nCarbohydrate antigen 19-9 (CA19-9) levels may be higher with gallbladder cancer or other conditions. It is more likely to be high if the gallbladder cancer is at an advanced stage.\nCarcinoembryonic antigen (CEA) levels may be higher with gallbladder cancer and other conditions.\nFind out more about tumour marker tests.\nDuring a biopsy, the doctor removes tissues or cells from the body so they can be tested in a lab. A report from the pathologist will confirm whether or not cancer cells are found in the sample.\nBut often imaging tests, such as an ultrasound and a CT scan, provide enough information to confirm that there is a gallbladder tumour, and a biopsy doesn’t need to be done. There is concern that when tissue is removed in a biopsy the cancer can spread in the abdomen.\nA biopsy for gallbladder cancer can be done during an ERCP (endoscopic retrograde cholangiopancreatography), a laparoscopy or a fine needle aspiration (FNA).\nWith an FNA, the doctor inserts a very fine needle through the skin of the abdomen and into the gallbladder. An ultrasound or CT scan is used to guide the needle during the procedure. An FNA may be used to confirm the diagnosis of gallbladder cancer if other tests have shown that the cancer has already spread to other organs or cannot be completely removed with surgery.\nFind out more about a biopsy.\nERCP (endoscopic retrograde cholangiopancreatography)\nAn ERCP (endoscopic retrograde cholangiopancreatography) uses a flexible tube with a light and lens on the end (an endoscope) to help determine if the cystic, pancreatic or bile ducts are blocked.\nAn ERCP may be used to:\n- determine if there is a gallbladder tumour and if it can be removed\n- take samples of bile or the bile duct to look for cancer cells\n- help plan surgery\n- place a small tube (stent) into the bile duct to relieve a blockage\nPTC (percutaneous transhepatic cholangiography)\nA PTC (percutaneous transhepatic cholangiography) is an x-ray of the bile ducts, liver and gallbladder. A thin needle is inserted through the skin into the gallbladder area. A special dye is injected into the bile ducts to enhance the pictures.\nA PTC may be used to:\n- see if a gallbladder tumour is blocking the bile ducts\n- take a sample of the bile to check for cancer cells\n- show if a gallbladder tumour has spread to the liver\nA PTC may be done for tumours that cannot be removed by surgery or when doctors cannot get a sample of the tumour with a fine needle aspiration.\nMagnetic resonance imaging (MRI) uses powerful magnetic forces and radiofrequency waves to make cross-sectional images of organs, tissues, bones and blood vessels. A computer turns the images into 3-D pictures.\nAn MRI may be used to see if the cancer has spread to nearby bile ducts and other organs.\nA special type of MRI called an MRCP (magnetic resonance cholangiopancreatography) can provide detailed information about the bile ducts, gallbladder, liver and pancreas.\nFind out more about an MRI.\nA laparoscopy uses an endoscope inserted through a small cut in the abdomen. The doctor examines the gallbladder, bile ducts and liver during this procedure. A laparoscopy may be used to:\n- take samples of the tumour to confirm a diagnosis of gallbladder cancer\n- see how far the cancer has spread\n- plan further surgery and other treatments\nAn angiography is an x-ray of blood vessels. A dye is injected into an artery. The x-ray images show the blood flow in the area. An angiography may be used to see if the gallbladder tumour has grown into nearby blood vessels. This can help the doctor decide whether the cancer can be safely removed and can help plan surgery.\nQuestions to ask your healthcare team\nA condition in which the skin and whites of the eyes become yellow and urine is dark yellow.\nJaundice may be caused by high levels of bilirubin (a substance formed when red blood cells break down) in the blood. It can also result from liver problems or a blocked bile duct."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:fe11458c-16ee-4642-8751-9eafeb3faa27>"],"error":null}
{"question":"I'm a textile history buff - can you compare the different ways Donegal Tweed and Sion Mills protected their traditional textile manufacturing heritage against modernization and foreign competition?","answer":"Donegal Tweed and Sion Mills had very different approaches to preserving their textile heritage. Donegal Tweed lacked trade protections, unlike Harris Tweed, which meant anyone could call anything 'Donegal Tweed.' This led to cheap Chinese and Italian knock-offs pushing the industry nearly to extinction, leaving only two commercial tweed mills in Donegal. In contrast, Sion Mills built long-term sustainability through community development - the Herdmans created a model village with schools, churches, and recreational facilities, establishing a strong local workforce and community that sustained the linen industry for over 170 years through 5 generations of family management.","context":["Our friends Shawn & Kieran Molloy, of Molloy & Sons, are featured in this very short, very lovely piece by filmmakers Jamie Delaney and Keith Nally. This is what happens when you send a professional instead of a dumb blogger with a camera phone.\nDonegal Tweed at Molloy & Sons\nI just got back from a visit to the UK and Ireland, and one of the highlights was a sidetrip to Donegal, and the two-man woolen mill operated by Shaun Molloy and his son Kieran.\nDonegal’s in the northwest corner of the Emerald Isle, and it’s known for its distinctive tweed. Donegal tweed is easy to pick out from other styles - its hallmark is the nubby flecks of color in the weave. Fabrics that may look like one color on the surface reveal a rainbow when you get in closer. It’s a look that’s been sought after for a couple hundred years now.\nShaun and Kieran come from generations of weavers. Shaun’s father, John, founded a woolen mill in the mid-20th century, but over the years that mill has gone from making tweed to making knits almost exclusively.\nA couple of years ago, Kieran brought an industrial design degree back home, and he and his father decided to take the tweed-making equipment out of mothballs and start up a tiny artisinal weaving company. They called it Molloy & Sons.\nThe Molloy archive of patterns stretches back into the 60s, and the pattern has to be transformed from a swatch on the page into a pallette and a set of instructions.\nThe process of making tweed starts with dyed wool. It’s processed into yarn in Donegal, according to the Molloy’s specifications.\nThen, that yarn is taken from its spools to a huge de-spooling machine, which sets it up to be woven. (All of these machines, by the way, are forty-plus years old.) When I was there, they were working on a fabric with a pretty simple color scheme (for a company whose name rhymes with “day shoe”), but for more colorful fabrics, every color has to be in exactly the right place.\nOnce the yarn’s unspooled, the Molloys program the weaving pattern into the big mechanical loom. Believe it or not, they do it with punchcards.\nThe long threads that go through the machine are called the warp. The machine’s job is to lift these up and down while shuttling through the weft yarn, which weaves over and under, back and forth, so fast you it doesn’t even show up in video.\nThe flecks, which you can see even in this black-and-white pattern, come from wool that’s been washed and felted before it’s spun into yarn. Because little bits of color are felted and don’t stretch out, they just glob onto the yarn like bubble gum on a piano string.\nThe flecks are a built in defect, in a way. Because they’re so unpredictable, the machine runs at a quarter the speed it would if it were weaving a plain worsted wool, like you might see in a suit at Macy’s. Shaun and Kieran have to keep a constant eye on things, tending to these imperfections as they come along.\nOnce the fabric comes out of the machine, they load it onto a huge roller, and run it through to check for problems. Their goal is to make a product that’s perfectly imperfect.\nWeaving used to be one of Donegal’s largest industries, but today it’s almost gone. Unlike Harris & Lewis, where Harris Tweed is made, there are no trade protections for Donegal Tweed. Anyone can call anything “Donegal Tweed.” If you see a tweed in the store in a Donegal style, it was most likely woven on the cheap in China or Italy.\nWhen Shaun and Kieran started making tweed again, there was only one tweed mill left in Donegal. Their factory, if you can call it that, sits just a few steps from the house where Kieran grew up… and where his father Shaun was raised. Something like half a dozen generations of weavers have lived there, in fact.\nThese guys aren’t quaint, and they’re not museum pieces for tourists to gawk at. They’re two sharp businessmen determined to develop a craft that has helped define who they were, who their families were, and what their home is. I think that’s pretty spectacular.\nA few photos from my recent trip to Molloy & Sons, a father-son tweed mill in Ardara, County Donegal, Ireland. I put together a little video slideshow deal that you’ll find here tomorrow morning.\nThis is Sean and Kieran Molloy, two generations of a Donegal tweed weaving tradition that goes back many more. Kieran’s grandfather (Sean’s father) John Molloy started a tweed mill in Donegal, on the west coast of the northernmost part of the Republic of Ireland, fifty or so years ago. John was already a fourth- or fifth-generation weaver.\nOver the years, John Molloy’s business moved further and further away from weaving and towards knits, so Sean and Kieran started Molloy & Sons to make the traditional Donegal tweeds that the family had always woven. The factory sits in two barns, one new and one old, on land that has been used by Molloys for weaving for more than a century, a few steps from the house where both Sean and Kieran were reared. Above, Sean and Kieran are standing in front of their warehouse, a converted community theater.\nI spent a wonderful morning with the Molloys today, touring their modest two-man operation and learning about how tweed is made. Donegal tweed is a distinctive and remarkable form of the fabric, but it isn’t protected by trade law as Harris Tweed is. This has meant that cheap Chinese and Italian knock-offs have pushed the industry in Donegal to the brink of disappearance. There are only two commercial tweed mills left in Donegal - the venerable (and sizable) Magee and these two fellas: Molloy & Sons. There’s a recession bordering on depression in Ireland at the moment, and these two gifted craftsmen (and sharp businessmen) are fighting for a future for a textile tradition that their family has guarded for hundreds of years.\nI’ll have a fuller writeup of my visit to Kieran and Sean’s shop when I’m back in the States, but for now, check out these brave guys and their wonderful firm.\nHere’s how it works: you send us a picture of some Irish farmers looking fresh to death. We post it.","Historic Linen Village of International Significance\nSion Stables Museum is housed within the period horse stalls which were fabricated in the late 19th century by Musgraves of Belfast. The exhibitions in the museum tell the story of this historic linen village and cover the themes of Family, Mill and Village.\nHerdmans Flax-Spinning Mill was built in 1835 by the brothers James, John & George Herdman from Belfast. Sion Mills was chosen as a rural area of high employment and with enormous waterpower. The Herdmans’ vision was to create a moral, God-fearing, temperate, educated, non-sectarian community around a flax-spinning business in the northwest of Ireland which was a prolific flax-growing area. They built a model village, a school, churches, recreational and sporting facilities and succeeding in creating a community where everyone, of both religious traditions, has lived, gone to school and worked together happily over the past 170 years and 5 generations of the Herdman family.\nThe museum exhibitions bring alive the stories of the mill-owners, the mill-workers and the production of Irish Linen. Take time to marvel at the sample of the first flax spun in the Mill on 15th November 1835 or explore our extensive collection of linen including the famous William & Mary table cloth. Learn about lesser known uses of linen such as its use in aeroplane wings during WWI.\nVillage life plays a key role in our exhibition. Sion Mills has a proud sporting heritage with cricket, bowls, football and tennis all being a part of daily life. The Holme field famously saw Ireland beat the West Indies in 1969 and holds the world record for the longest match ball hit when a cricket ball landed in a trains goods wagon and was transported to Derry…\nThis is a non-guided facility with an opportunity to view the exhibits at your leisure. Recommended time for the facility is approximately sixty minutes. Before you visit sample our Masters Of Linen Film which immerses you in the last 150 years of life in Sion Mills.\nA key part of the mission of the Sion Mills Buildings Preservation Trust is to collect, record, conserve and curate archive material related to the Herdman Family, the Mill and the Village and to make these collections and research available to the public. Creating opportunities for learning and broadening the sense of this ownership of the important heritage is at the heart of everything we do.\nThe collections provide a comprehensive record of significant genealogical and socio-economic development within the Village from the mid 19th century to the present day. The extensive archive collection consists of ledgers, minute books, legal documents, architectural drawings and plans and private collections. This material ranges from business collections, and items relating to industry, linen production, railways, political movements and social history to personal collections such as James Herdmans personal diary collection, Carricklee Races, Strabane Harriers Hunt. The genealogical collections includes a database detailing personnel records for individuals, details on house rentals, contributions to health cover provided by the Mill, contributions to Sion Mills sports et.\nThe collection is in the process of being catalogued and digitised and key selections will eventually be available online. Until this is achieved, if you have a specific enquiry please contact the Museum Coordinator direct on\n- Mob: 078 9453 4553\n- Email: email@example.com\nMonday – Saturday 9am – 5pm\nSunday 12.00am – 5pm"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:30e01dad-58d9-4fb5-af62-234e179f98a2>","<urn:uuid:147fce66-458d-45d7-aa12-3f1448e38246>"],"error":null}
{"question":"What are the cost implications of high water pressure versus water-saving technologies when it comes to water consumption?","answer":"High water pressure (above 80 psi) leads to increased water consumption, with reducing pressure from 100 psi to 50 psi resulting in approximately 1/3 less water flow and corresponding cost savings of $50 to $150 per year for an average family. Meanwhile, water-saving technologies like the No-Mix Vacuum Toilet can reduce water consumption by up to 90%, potentially saving 160,000 liters of water per year per hundred flushes in public restrooms. Both approaches not only save water but also reduce energy costs associated with water treatment and pumping.","context":["Most national and local plumbing codes require that a water pressure reducing valve is installed in buildings where water supply pressures\nexceed 80 psi.\nExcessive water pressures can burst pipes, cause dripping faucets, and can even cause rupture and explosion of both cold water pressure tanks\nand hot water storage tanks\n- What is a Water Pressure Regulator?\nAlso called water pressure reducing valves, they are compact, inexpensive regulators that perform two functions:\n(1) they automatically reduce the high incoming water pressure from the city mains to provide a lower, more functional\npressure for distribution in the home; (2) they “regulate” by maintaining a set pressure in the home usually 50 lbs. –thereby\ninsuring that the home piping and appliances operate under a safe, more moderate, but satisfactory pressure.\n- What is water pressure?\nWhen a fixture in a home is opened and water flows from it, it is because the water is “pushed.”\nThis “push” is pressure. The speed at which water flows from the opened outlet depends on the amount of “push” or pressure,\nwhich exists at that time in the system. In short, the higher the pressure, the stronger the “push” behind the water.\n- What is wrong with high water pressure?\nHigh water pressure, which is generally considered anything above 60 lbs., has some advantage, such as in fire fighting\nsystems. However, in the home plumbing system, it can be damaging because water, with a strong “push” behind it, can\nerode or wear away many materials and cause leaking water heaters, banging water pipes, dripping faucets, dishwasher\nand clothes washer noise and breakdown, and leaking water pipes. Therefore, water flowing at a rate in excess of that\nnecessary to satisfy normal fixture or appliance demands becomes damaging, wasteful and reduces the life expectancy of\nequipment in the system. But, probably most important to the average homeowner is that it can add to the cost of water,\nenergy and waste water bills.\n- Does high water pressure cause “water hammer”?\nYes, and water hammer is very simply the noise generated by the shocks of high-speed water flowing in a pipe when\na fixture is suddenly closed. The sudden stoppage causes a “bounce-back” of the water and is called water hammer,\ncausing banging pipes, noise systems and damage to appliances. It might be compared to driving your car at slow speed into\na wall where the effect is negligible. However, if you drove the car at a much higher speed, the impact would be greater and,\nconsequently, so would the bounce-back or shock. Another description of the water hammer effect of high water pressure can be\neasily demonstrated. First, walk around a sharp corner and then run around the same corner. We can equate walking around\nthe corner to a lower, more functional, controlled water pressure. However, when you run around the corner, the momentum\nforces your body to swing in a wider, uncontrolled arc. This principle is based on the fact that moving objects, and this includes\nwater, tend to move in a straight line. They resist changes in direction. Therefore, in a home where the piping has many changes in\ndirection, water hammer shock can be limited by reducing the water pressure.\n- What is the difference in water flow from\na fixture when the pressure is at 100 lbs. vs. a pressure of 50 lbs.?\nReducing the pressure from 100 lbs. to 50 lbs. will result in a saving of approximately 1/3\nbecause 1/3 less water flows. At this lower pressure remember, there is more “push” behind the water at 100 lbs. than at 50 lbs., and most of\nthis water is wasted. A moderate savings would result if your supply pressure was 65 lbs. However, even at this lower pressure,\nsavings with a regulator would be 20%.\n- Are there any studies to support this savings figure?\nYes, in 1971 the Washington Suburban Sanitary Commission conducted a test program in 2,400 dwelling units\nthat has attracted widespread interest from more than 40 states and various foreign countries. One of the devices\nused in their conservation study was a water pressure regulator. It is interesting to note that their report concluded\nthat in test locations using regulators, there was a water consumption reduction of 30% in October and November and 37%\n- Where are Water Pressure Regulators most commonly used?\nWater pressure regulators are commonly installed at the mater in residential, commercial and industrial buildings.\nThis location is desirable because it then controls the water pressure flowing to all appliances and outlets within\nthe building and provides an inexpensive means of supplying lower, more functional water pressure to outlets and appliances.\n- Why do we now call Regulators “Primary Conservation Controls”?\nMost people have considered regulators as pressure controls because, as described in the foregoing, they are used to\nprotect appliances and piping from the effects of high water pressure. However, because of water and energy shortage\nand cost problems, regulators have become increasingly more important because they automatically provide the advantage\nof conserving water and energy.\n- How do Regulators save water?\nAs mentioned before, 1/3 less water flows at 50 lbs. than at 100 lbs. Therefore, when you reduce the city main pressure\nto a more moderate pressure of 50 lbs., you can look forward to conserving up to 1/3, or more, of the water previously consumed\nand this will be reflected on your water bills.\n- How much does a typical family of four use?\nA typical family of four uses an average of 255 gallons of water each day for interior plumbing. This is broken down\nby: dish washing – 15 gallons; cooking/drinking – 12 gallons; utility sink – 5 gallons; laundry –35 gallons; bathing – 80 gallons;\nbathroom sink – 8 gallons; toilet – 100 gallons. When you multiply this by a year, typical family usage totals 93,000 gallons of water.\nYour family, particularly if it includes teenagers, would undoubtedly use more than the above averages.\n- How do Regulators affect the wastewater system?\nWhen we can save 1/3 of the water previously consumed, this also represents a similar saving of water, which will not\nbe going into the sewer system where it has to be treated. Water does not evaporate after we use it and it has to be\npiped to the wastewater system. Many sewer bill taxes or surcharges are based on the amount of water you use, with the\nassumption that this water is going into the wastewater system. This is billed to you as sewer surcharge and, in many cases,\nthe sewer tax can equal the water cost. Therefore, when pressure regulators\nsave 1/3 of the metered water, they also contribute\nto saving up to 1/3 of the wastewater load and this is extremely important because it benefits both the user, by a lower sewer bill,\nand the community, as this is water they do not have to treat.\n- How do Water Pressure Regulators save on energy?\nThe Environmental Protection Agency estimates that 30% of the water used in households is heated and, in order to heat this\nwater, it takes energy. Logically, therefore, if a pressure regulator can reduce consumption by 1/3, we automatically cut down on\nthe amount of hot water we’re using in lavatories and showers and, therefore, it follows that we automatically reduce the amount of\nenergy required to heat that load. Thus, it can be easily seen that water conservation has a direct relationship to energy\nconservation. An average shower, for example, costs approximately 17 cents in energy and a shave with the faucet running cost 10\ncents in energy.\n- How do these savings benefit the water and energy utilities?\nA high rise office building in Chicago was designed using water conservation products which resulted in savings of more than\n3,000,000 gallons of water per year. This is significant in that the municipal water utility did not have to pump that extra\ngallonage, the water purification plant didn’t have to treat it, the building itself saved on pumping of 3,000,000 gallons, and\nthere must have been significant savings in energy by conserving hot water. Also, there were further savings by the fact that\n3,000,000 gallons of water, or the normal portion thereof, did not have to be distributed to the wastewater system and consequently\nthe water treatment plant did not have to retreat this water. The heating of water takes energy and it should also be remembered that\n“pumping” water from one place to another also requires a considerable amount of energy.\n- How do Regulators save on maintenance?\nWe have previously described the effects of high water pressure on piping and appliances. By having these appliances work under\na lower pressure, their life expectancy will be much longer and will also cut down on service calls caused by problems with dish\nwashers and clothes washers, leaky water heaters, leaking water pipes and the potential water damage which could be resulting.\n- Do codes require Water Pressure Reducing Valves?\nYes. They are required by the Federal Housing Administration, the regional plumbing codes such as IAPMO, Southern Building Code,\nand BOCA, and numerous city and state codes. The requirement is that whenever the city main water pressure exceeds 80 lbs.,\na regulator must be installed. However, because of the recently acknowledged advantages of regulators\nconservation wise, regulators\ncould be economically installed even where supply pressures are in the vicinity of 60 lbs. Because of the water and energy saving\nbenefits they can provide.\n- How long will a Regulator last?\nRegulators have been described as “life-of-mortgage” products, because historically a malfunctioning pressure regulator\nis not replaced but simply cleaned or repaired via an inexpensive service kit.\nDesign wise, it is similar to the kitchen\nfaucet in that dirt or foreign matter on the seating area can cause problems and actually it is no more difficult to repair a\nregulator than it is to fix the kitchen faucet.\n- If I install a Pressure Regulator, what savings can I expect?\nAn average savings would be from $50 to $150 per year, probably much higher.\nBased on the fact that 1/3 less water flows at 50 lbs. than 100 lbs., you can expect to save up to 1/3 of the\nwater previously consumed. As a typical family of four uses 90,000 gallons per year, that would mean a savings\nof approximately 30,000 gallons of water. The higher the pressure, the higher the savings. Lower pressures result in less\nsavings. (Your water Co. can provide the rate.)\nRemember also, however, that 1/3 of the water used in homes is heated; so 1/3 of\nthe 30,000 gallons of water saved divided by 2 to reflect a cold water mixing factor would mean a savings in heating up to 5,000\ngallons of hot water per year. If you figure 4 cents to heat gallon of water, the savings would be $200.00.\nYou can also figure on a savings in your sewer surcharge bill, since most of the 30,000 gallons of water saved will not be\ngoing into the wastewater system, therefore, you will not be assessed on that. (Contact your local authority for any assessment charges.)\nYou would also have to figure the savings generated by not having to have appliances repaired or replaced more frequently.\nThis is a nebulous figure but, based on your own experience over the past years, you could look for a reduction in the\nfrequency of maintenance and certainly for an improved performance by these appliances.\n- Should we consider using other water and energy conservation devices?\nCertainly, The water pressure regulator we’re talking about today is the nub of a conservation program; but you should also\nconsider flow control devices, low-flush toilets, improved water heating equipment and better disciplined habits by the user.\nHowever, if none of these devices were installed, the water pressure regulator would still serve to contribute important and\nsignificant savings in energy and water, resulting in average savings of anywhere from $50 to $150 per year, or more depending\non your local rates.\n- Do flow-restricting devices actually save water?\nYes, and they can effectively be installed on showerheads, fixtures and\ntank less heaters in boilers. Many showerheads,\nfor example, supply water at a rate of 6 pm. Applying a 3 pm flow restrictor will cut the flow in half providing savings\nin water and energy . It should be remembered however that their capacity is based on a “fixed” supply pressure like 50 lbs.\nand operating under a higher pressure will permit greater flow. That’s why we say a water regulator is the “hub” of a program\nbecause it maintains a constant pressure throughout the home, thereby even improving the performance of flow-restricting devices.\n- What are some tips the user can employ to save water and energy?\nPut a stopper in your sink or use a dishpan when you wash dishes. Washing with running water uses 30 gallons per meal.\nKeep a bottle of drinking water in the refrigerator – running the water from the faucet until cold will waste a gallon.\nWait until you have a full nine-pound wash before you run your washing machine. The average machine uses 50 gallons per load.\nTurn the hot water off while you shave, and turn the cold water off while you brush your teeth. Shaving with a running faucet\nuses about 20 gallons.\nTake showers instead of baths. The usual bath requires 36 gallons, the usual shower, only 25. Ten gallons is enough for a shower\nif you turn it off while you lather.\nDon’t use the toilet bowl to dispose of cigarette ashes, facial tissues, and other materials. A normal flush requires 5-8 gallons.\nUse dishwasher only when completely full.\nFix dripping faucets promptly. Nearly two gallons can be wasted per day of dripping.\nRunning toilets can waste four gallons per hour. Keep them in good repair.\nTHINK before you turn on the tap.\n- What does a Water Pressure Regulator cost?\nEvery water system is different.\nThe best way to determine the right regulator for your specific needs, and it’s cost, is to\ncontact us here at Suburban Water Heater Company.\nWe’ll recommend the right regulator for your application and provide a written estimate.\nTo determine how much you might saving, it would be necessary to consider the factors in question 17, in comparing with your current water and energy bills.\n- How do I know if I have high water pressure?\nA rule of thumb is: If you hear banging pipes in your home or observe water splashing in your sink,\nyou probably have excessive pressure. For a precise reading, contact Suburban Water Heater Company and we can come out and\ntest your pressure with a gauge.\n- How can I get a Water Pressure Regulator installed?\nThe easiest way would be to contact us here at Suburban Water Heater Company.\nWe can provide you with an estimate, advise of the various type regulators available and install the one best suited for your situation.\n| About us\n| Contact Us\n| Do it yourself\n| Hot Water Heaters\nQ/A and Info\n| Water Treatment\n| Q/A and Info\n| Thermal Expansion Tanks\nWater Pressure Regulators\nSuburban Water Heater Company. PA HIC# 066680\nCopyright 2013 All Rights Reserved","After a year and half of research, scientists from Nanyang Technological University (NTU) have found a way to reduce the amount of water needed for flushing and reuse human waste. Their invention involves a new toilet system (dubbed the No-Mix Vacuum Toilet) that can turn human waste into electricity and fertilizers while reducing the amount of water needed to flush by up to 90 percent – in comparison to the currently used toilet systems in Singapore.\nHow does this innovative system reduce the amount of water used? By using vacuum suction technology – which is used in airplane lavatories–which would only require 0.2 liters of water to flush liquids and one liter to flush solids. This is a significant reduction from the currently existing conventional toilet which uses 4 to 6 liters of water with each flush. Estimates have speculated that if this system were to be installed in a public restroom, they would save 160,000 liters of water each year per hundred flushes!\nCurrently the scientists are trying to conduct a trial by installing the prototypes of this toilet in two NTU restrooms, and then to share this technology with the world in the next three years. But as Associate Professor Wang Jing-Yuan, Director of the Residues and Resource Reclamation Centre (R3C) at NTU points out, conserving water is not the only benefit and goal of this system – the goal is to “have a complete recovery of resources so that none will be wasted in resource-scarce Singapore.”\nProfessor Wang shares:\n“Having the human waste separated at source and processed on-site would lower costs needed in recovering resources, as treating mixed waste is energy intensive and not cost-effective. With our innovative toilet system, we can use simpler and cheaper methods of harvesting the useful chemicals and even produce fuel and energy from waste.”\nThe No-Mix Vacuum Toilet has two separate chambers that separate the liquid waste and the solid waste. The liquid waste would then get diverted to a processing facility where nitrogen, phospherous and potassium can be recovered and reused for fertilizer. The solid waste would be sent to a bioreactor where it would be digested to release a bio-gas containing methane–methane is odorless and can be used to replace natural gas used in stoves for cooking, and can be converted to electricity.\nIf this new toilet is functional and lives up to its claims, then this could help save water around the world. Flushing the toilet is one of the top uses of water in a home: It has been estimated that the average toilet can use up to 3.5 to 5 gallons of water per flush. Jack Sim, the founder of the World Toilet Organization, told Time Magazine that “chances are you’re dumping up to 22 liters of drinkable water every day, one three- to six-liter flush at a time.”\nBut that’s not the only problem. After flushing, a lot of resources are spent to clean flushed water and thereby, increases the carbon footprint of toilets. Rose George, author of The Big Necessity: The Unmentionable World of Human Waste and Why it Matters shares that “the sewage system uses as much energy as what the largest coal fire station in the [country] produces.”"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:0511197a-98e9-4f85-92fa-13223af6b700>","<urn:uuid:3e0e2c99-3a4a-4317-a87a-eb9c0a23fa3d>"],"error":null}
{"question":"How did the British military presence at the Suez Canal compare to the occupancy of the Eden Palace Hotel in Cairo during World War I?","answer":"During World War I, both locations saw significant military activity, but in different ways. The Eden Palace Hotel became notorious for housing Commonwealth soldiers, with accounts of rowdy behavior - including an incident where Australian soldiers had to be dragged out by military police after being AWOL for three days. The hotel's business suffered as a result of this military presence. Meanwhile, at the Suez Canal, there was a much larger and more organized military presence, with 70,000 British troops stationed in Egypt by January 1915, including Indian Army units. 30,000 of these troops were specifically placed on Suez defenses to protect this strategically critical waterway from Turkish attacks.","context":["Although it was hotel for only around 20 years, and the last guests checked out 93 years ago, the name of the Eden Palace lingers in Cairo – it’s there in large letters on the pediment of a corner building on modern Khazindar Square, across from the Sednaoui department store. It’s passed every day by thousands of people but likely noticed only by a very few.\nThe hotel opened around 1900 in a grand new building raised on the site formerly occupied by the original Hotel d’Angleterre, the first hotel run by George Nungovich (see earlier post). It was a good site, overlooking the Ezbekiyya Gardens; guests in the better rooms would wake to birdsong, and a view of trees and greenery when they opened the shutters. It had 145 rooms, with a lift and steam heating. Shepheard’s, the epicentre of the city’s social scene was just a stone’s throw away. Unlike Shepheard’s, which attracted a fashionable crowd, the Eden Palace catered to businessmen and long-term residents, who would sacrifice a little glamour for cheaper room rates – the 1914 edition of Baedekers gives Shepheard’s charging 80 piastres per night, same as the nearby Continental, while the Semiramis charged 90 pias and the Savoy 90-120 pias; by comparison, the Eden Palace was just 50 pias.\nAn insight into the kind of person who stayed at the Eden Palace comes from a letter held by the Albany Institute of History and Art in upstate New York. Dated March 1909, it’s from Samuel W. Brown, a noted local businessman in the coffee, spice and mustard trade who was also on the board of trustees of the Institute. It’s addressed to Cuyler Reynolds, the curator of the Institute, and it concerns the attempt to acquire a pair of Egyptian mummies on the cheap:\nMy Dear Mr. Reynolds\nI received your letter with enclosures as stated I called at the U.S. Consulate several times but did not find Mr. Berry; later on learned that he was not connected with the Consulate but was a “Judge” of the Tribunal Court here. I called at his hotel then but did not see him there. He called on me at my hotel last evening. He did not hesitate to inform me that he could do little to assist me as he was not acquainted with the Director of the Museum. I am at a loss to understand why you should expect to get any of the Museum Curios for nothing. The Museum is a Government affair and everything going out of the Museum must be paid for at a fixed price whether for a museum or private collection. These people are not in the Museum business for their health, and I fully learned of that fact when I was in Cairo four years ago.\nI called on the Director the following day and made my wants Known to him and have secured two Mummy’s [sic] which I am having packed for shipment. I have written to Mr. Ten Eyck the details of the transaction and I hope that they will be in Albany before I reach home.\nWe are having a delightful time Bright warm weather.\nSamuel W. Brown\nWhatever his frustrations, Brown was successful and the pair of mummies he brought back form the centerpiece of the Institute’s Ancient Egypt collection until today.\nWhile the front entrance of the Eden Palace was on Sharia al-Genaineh, facing the Ezbekiyya, the back door let out onto Wagh al-Birket, which at this time was notoriously a street full of brothels. This can’t have done much for the hotel’s reputation. And when Cairo became flooded with British and Commonwealth soldiers following the outbreak of World War I, it seems the Eden Palace might have taken on the character of some sort of Wild West saloon:\n“We had our first pay day on Christmas Eve and leave was general and everybody went straight into Cairo. Our own party of four really disgraced outselves, AWOL for three days, finally and very ignominiously dragged out of the Eden Palace Hotel in the early hours of the morning by the picket and made to walk it home into the guard tent.”\nLetter from an Australian soldier quoted in Peter Hart’s Gallipolli\nThe hotel seemingly never quite recovered, and trade post-World War I was sufficiently bad that when, in 1920, British Army HQ decided to vacate the Savoy for budgetary reasons, the owners of the Eden Palace made them an attractive offer. The army didn’t stay long in residence but after the uniforms left the place never returned to use as a hotel.\nThe building today is in a wretched state, but with its arcaded pavements and low-rise, Italianate architecture, if your imagination can dust things off a little, then this dilapidated corner still gives a good impression of what the city once looked like when the Ezbekiyya was a pleasure garden and birds still sang in Cairo squares.","The first Turkish attack on the Suez Canal\n3 February 1915\nThe position of Egypt in 1914 was rather complex. Formally part of Turkish Empire, it actually operated as a British protectorate (formally announced in December 1914). On 5 August 1914, Egypt was declared to be at war with the enemies of Britain. For the British and Egyptian leaders, there were at that time two chief concerns: one was the Turkish Army, believed to be intent on an attack from Palestine. The other was internal security, for many Arabs including the nominal head of state Abbas Il Helmi were known to be anti-British. Muslim Turks soon proclaimed a jihad, in an effort to rouse anti-British, anti-Western sentiment in the Middle East, and they generally maneouvred to foment an internal Arab revolt against the British. Britain in turn manoeuvred to remove Helmi and replaced him with Prince Hussein Kamel. The Turks planned to invade Egypt, and began to build up a force of 20,000 men under the command of Fourth Turkish Army. Djemal Pasha was both Commander-in-Chief of this Army and Governor of the Ottoman Empire in Palestine.\nBritish forces in the Suez Canal zone\norder to maintain security, look after British interests in\nthe protectorate and to defend the strategically critical Suez\nCanal, there were 70,000 British troops in Egypt by January 1915.\nMany of these were in units of the Indian Army. Commander-in-Chief was\nMajor-General Sir John Maxwell, who had been appointed in August\n1914, a veteran of many years service in Egypt and Sudan. British\nformations involved at this time included:\nEast Lancashire Division TF (later redesignated 42nd (East Lancashire) Division)\n10th Indian Division\n11th Indian Division\nIndian Imperial Service Cavalry Brigade\nBikanir Camel Corps\nIndian and Egyptian artillery.\n30,000 of the troops were placed on the Suez defences. The 1st Australian and New Zealand Army Corps arrived in December 1914, for training en-route to the European theatre of war.\nLocation of this engagement\nThe Suez Canal is 101 miles long, connecting the Red Sea and the Mediterranean. It was a vital route for Britain, allowing shipping to go the shorter route from India and other Asian and African parts of Empire rather than south round the Cape of Good Hope. The canal connects a number of lakes and is nearly 150 feet wide. On the western bank runs the so-called Sweet Water Canal with main controls at Ismailia, the only large-scale source of drinking water for the area. Main defences were created on the west bank, with outposts on the east. Supply to the troops along the Canal was by railway running from Ismailia to Cairo. There were no metalled roads. To the east lay the inhospitable Sinai desert, with little water. Turkish forward positions were established at El Arish and Nekhl. There were only three possible routes for them across the expanse of the Sinai desert: by the coast (advantage of this being water and tracks, but it was within fire of British ships); a southern track from El Kossaima to Suez (quickly discarded by the Turks); and finally the central track from Beersheba to Ismailia. Once the Canal had been crossed, Turkish troops could follow better-developed tracks to Cairo.\nThe British and Turkish forces clash\nThe first clash occurred on 20 November 1914 when a patrol of the Bikanir Camel Corps met 200 Turk-controlled mounted Bedouin east of Kantara. there were also small raids at Alexandretta (now Iskunderun) on the Syrian coast.\nThe main Turkish attack develops ...\nOn 28 January 1915 British observers identified a large column of Turkish troops on the central route across the Sinai. British and French ships entered the canal and opened fire, while defensive positions were manned by infantry. Patrols clashed on 2 February, but a sandstorm halted any further action until next day.\n... and is defeated\nCarrying pontoons and rafts, the Turkish infantry approached the east bank in the early hours of 3 February 1915. Indian machine-gunners cut swathes through those on the water, and through men now massing in the gullies on the east bank. Much panic began, and many Arab troops on the Turk side surrendered. The attack was renewed at dawn, with additional diversions launched at Kantara and near Ismailia. Shelling from the ships, and continued staunch resistance by troops in the defensive posts, caused it be halted in the early afternoon. The entire Turk force withdrew, unmolested by the British who did not follow them in any force, back across the Sinai towards Beersheba. The Turks lost 1,500 troops in this action. There was no sign of Arab insurrection.\nLessons were quickly learned on both sides: for the British, it was clear that allowing the enemy to approach the canal - indeed to use it as the defence line - was a risky business, although they formed an unfortunate opinion that their opponents were not good fighting material. For the Turks, they knew that a larger force, better supplied, would be need to dislodge the sizeable British force in Egypt.\nNuisance raids continue to harass British force\nA small Turkish force under a German commander, General Friedrich Kress von Kressenstein, remained in the Sinai and carried out several nuisance raids at points along the canal. Whilst these raids maintained pressure on the British and kept them guessing about another attack, they were insufficient to halt the movement of troops away from the canal defences to Gallipoli throughout the summer of 1915, with another force also going defeat a rising of the Senussi faction on the western frontier of Egypt later in the year.\nThe British force in Egypt grows - and then diminishes\nIntelligence of building Turkish forces in Palestine, together with their extension of a supply railway to Beersheba, encouraged the British to increase forces at the canal in late 1915. In early 1916 as Gallipoli was evacuated (and the Mediterranean Expeditionary Force command and staff was merged into the Egyptian Expeditionary Force) there were 14 complete British Divisions of infantry and some Yeomanry Brigades in the area, although for most of these Egypt proved only a holding station before they were deployed elsewhere. As the months dragged by, the demand for troops for Mesopotamia and the Western Front brought the canal garrison back down to smaller numbers.\nBritish stance in Egypt changes from defensive to cautiously offensive\nIn December 1915 there was a change of plan on the British side. A Commission under Major-General Sir Henry Horne recommended that the defensive line should be moved forward from the west bank on to the east, and far enough away from the canal for it to be beyond the range of the enemy's heaviest guns. Three new defensive lines were constructed and the supply railways from Cairo doubled in capacity. This construction effort was largely undertaken by locally-recruited workers, organised as the Egyptian Labour Corps. It was stated that 12 Divisions would be required to defend the canal from the quarter of a million Turks believed to be massing in Palestine (although this proved to be a gross over-estimate: the railways and water supplies in Palestine could not support that size of a force). The Egyptian theatre was placed under the command of Lieut-General Sir Archibald Murray, recently arrived after being Chief of General Staff to Sir John French on the Western Front. Murray proposed to the War Office to undertake limited offensive action to be able to control the area of El Arish. While it would require major construction of railways and water supplies, this would effectively prohibit the Turks from the coastal route to the canal, and also put British troops in striking distance of the cenral route, well away from the canal. CIGS Sir William Robertson gave a cautious approval in March 1916."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:d2fcde37-6927-4575-a442-9646d6b3ee9f>","<urn:uuid:b7eb8a04-c035-4b4f-8365-53cdfe46a31e>"],"error":null}
{"question":"What are the environmental impacts and internal governance structures of the chemical industry's Responsible Care initiative?","answer":"Research indicates negative environmental impacts, with evidence showing RC participating plants increased their pollution intensity by 15.1% compared to non-participating plants. Regarding governance, the initiative operates through a management system comprising a Responsible Care Pledge, Guiding Principles, procedures, and policies. It includes corporate oversight through a Global Environmental Affairs team, documented processes for incident prevention, and Community Advisory Panels that provide local citizen input. The system requires regular third-party auditing and certification to verify compliance with standards.","context":["Does industry self-regulation reduce pollution? Responsible Care in the chemical industry\n- 731 Downloads\nSelf-regulation programs, in which industry associations set membership codes beyond government regulations, are prevalent despite scarce evidence on their effectiveness. We examine Responsible Care (RC) in the US chemical manufacturing sub-sector, whose membership codes include pollution prevention, using our author-constructed panel database of 3,278 plants owned by 1,759 firms between 1988 and 2001. We apply two sets of instrumental variables to address a plant’s parent firm’s self-selection into the program, using: (i) the characteristics of other plants belonging to the same firm in our multi-plant sample; and (ii) firm participation in the industry association before the establishment of RC and industry-level RC participation in our full sample. We find that on average, plants owned by RC participating firms raise their toxicity-weighted pollution by 15.9% relative to statistically-equivalent plants owned by non-RC participating firms. This estimated increase is large relative to the yearly 4% reduction in pollution among all plants in our sample between 1988 and 2001. Moreover, RC raises plant-level pollution intensity by 15.1%. These results caution against reliance on self-regulation programs modeled on the pre-2002 RC program that did not require third party certification and in those sectors that lack independent third party certification.\nKeywordsCorporate Social Responsibility Self-regulation Voluntary programs Self-selection Greenwash Chemical industry\nJEL ClassificationQ53 Q58 L51 L65 D21\nUnable to display preview. Download preview PDF.\n- American Chemistry Council (ACC) [formerly known as the Chemical Manufacturers’ Association.] (1990). Responsible Care: Codes of management practices. Archived at the International Labor Organization Corporate Codes of Conduct. Retrieved from http://actrav.itcilo.org/actrav-english/telearn/global/ilo/code/responsi.htm.\n- American Petroleum Institute (API). (2005). Toxic release inventory burden reduction proposed rule; TRI-2005-0073; RFL-7532-8;70 federal register 57822-57847, October 4. Washington DC: Office of Environmental Information Docket, U.S. Environmental Protection Agency, Docket ID No. TRI-2005-0073.Google Scholar\n- Baron D. P. (2001) Private politics, corporate social responsibility, and integrated strategy. Journal of Economics and Management Strategy 10(v): 7–45Google Scholar\n- Cohen, M. A., Gottlieb, M., Linn, J., Richardson, N. (2011). Deepwater drilling: Law, policy, and economics of firm organization and safety. Resources for the Future Discussion Paper 10–65.Google Scholar\n- Dawson N. L., Segerson K. (2008) Voluntary agreements with industries: Participation incentives with industry-wide targets. Land Economics 84(1): 97–114Google Scholar\n- Dlouhy, J. A. (2011). Safety plans could clash, offshore drillers pressured to form watchdog. Houston Chronicle, January 9.Google Scholar\n- Environmental Protection Agency (EPA). (2007). Green book: The green book nonattainment areas for critical pollutants. Retrieved from http://www.epa.gov/oar/oaqps/greenbk\n- Environmental Protection Agency (EPA). (2009). EPA’s risk screening environmental indicators (RSEI), February. Methodology Office of Pollution Prevention and Toxics.Google Scholar\n- General Accounting Office (GAO). (2011). Private fund advisers: Although a self-regulatory organization could supplement sec oversight, it would present challenges and trade-offs. Report to Congressional Committees, GAO-11-623.Google Scholar\n- Hamilton J. T. (2005) Regulation through revelation: The origin, politics, and impacts of the toxics release inventory program. Cambridge University Press, Cambridge, UKGoogle Scholar\n- Hoffman A. (2000) Competitive environmental strategy: A guide to the changing business landscape. Island Press, Washington, DCGoogle Scholar\n- International Council of Chemical Associations (ICCA). (2008). Responsible Care Status Report 2008. Retrieved from http://www.icca-chem.org/ICCADocs/Status_Report_2008.pdf.\n- Lange, I. (2009) Evaluating voluntary measures with treatment spillovers: The case of coal combustion products partnership. B.E. Journal of Economic Analysis & Policy, 9(1), article 36.Google Scholar\n- Levinson, A. (2004). Review of new tools for environmental protection: Education, information, and voluntary measures. In T. Dietz & P. C. Stern (Eds.). March 24. Journal of Economic Literature, 42(1), 171–231.Google Scholar\n- Moffet, J., Bregha, F., & Middelkoop, M. J. (2004). Responsible Care: A case study of a voluntary environmental initiative. In K. Webb (Ed.), Voluntary codes: Private governance, the public interest and innovation (pp. 177–208). Ottawa, Canada: Carleton Research Unit for Innovation, Science and Environment.Google Scholar\n- Morgenstern, R., & Pizer, W. A. (2007) Reality check: The nature and performance of voluntary environmental programs in the United States, Europe, and Japan. Washington DC: RFF Press.Google Scholar\n- National Academy of Engineering; National Research Council. (2010). Interim report on causes of the deepwater horizon oil rig blowout and ways to prevent such events. Committee for the Analysis of Causes of the Deepwater Horizon Explosion, Fire, and Oil Spill to Identify Measures to Prevent Similar Accidents in the FutureGoogle Scholar\n- National Commission on the BP Deepwater Horizon Oil Spill and Offshore Drilling (NCBP). (2011). Deep water: The gulf oil disaster and the future of offshore drilling. Part I: Report to the President, Part II Recommendations.Google Scholar\n- Oehlert G. W. (1992) A note on the delta method. The American Statistician 46(1): 27–29Google Scholar\n- Pettit, D. (2010). The more things change at MMS .... David Pettit’s blog at the Natural Resources Defense Council, June 14, 2010. Retrieved from http://switchboard.nrdc.org/blogs/dpettit/the_more_things_change_at_mms.html.\n- Pizer, W. A., Morgenstern, R., & Shih, J.-S. (2011). The Performance of industrial sector voluntary climate programs: Climate wise and 1605 (b). Energy Policy Google Scholar\n- Roodman, D. (2008). How to do xtabond2: An introduction to “difference” and “system” GMM in stata. Center for Global Development working paper, Washington DCGoogle Scholar\n- Rosenthal, I., & Kunreuther H. (2010). Roles for third parties in implementing usda food safety and inspection service (FSIS)’s food safety process management programs. Risk Management and Decision Processes Center, The Wharton School of the University of PennsylvaniaGoogle Scholar\n- Van Asten M., Martinson C. (2005) MON MACT impact. Products Finishing 70(3): 54–59Google Scholar\n- Wooldridge J. (2010) Econometric analysis of cross section and panel data. MIT Press, CambridgeGoogle Scholar","?Responsible Care? is the chemical industry’s unique global initiative that drives continual improvement in health, safety and environmental (HSE) performance, together with open and transparent communication with stakeholders. Responsible Care was launched in 1985 by the Canadian Chemical Producer’s Association and is now implemented globally through international, national and regional associations such as the International Council of Chemical Associations, American Chemistry Council, European Chemical Industry Council (CEFIC), Association of International Chemical Manufacturers (AICM) and\nEastman adheres to the Responsible Care? Gl?obal Charter, which goes beyond the original elements of Responsible Care?. The Charter focuses on new and important challenges facing the chemical industry and global society. It includes the growing public dialogue over sustainable development and public health issues related to the use of chemical products. The Charter also addresses the need for greater industry transparency and the opportunity to achieve greater harmonization and consistency among the national Responsible Care? programs currently implemented.\nEastman was a leader in the development of the American Chemistry Council’s Responsible Care Codes of Management Practices. We built our Responsible Care Management System on the Codes of Management Practices and our HSES management system. Our management system is comprised of our Responsible Care Pledge, Guiding Principles, procedures, policies and documents that govern our activities, operations and the way we conduct business. Core elements of our system:\nEastman maintains a rigorous product safety review process, including a dedicated Global Product Stewardship and Regulatory Affairs team, which leads intensive product safety reviews to ensure that our products are among the safest and most effective materials on the market.\nEastman is committed to ensuring the highest sustainability and safety standards possible throughout our global operations and supply chain, including transportation safety and logistics optimization across all sites.\nHealth and Safety\nWe continually strive to improve our workplace safety, with an ultimate goal of zero injuries and incidents.\nOur commitment to protecting the environment and our communities start with operational safety. Eastman has extensive documented processes and procedures to prevent potential incidents from occurring and it they do occur, to reduce their impact.\nEastman has an unparalleled commitment to ensure safety both on and off our plant facilities. Through careful planning and diligent practice, our trained emergency responders employ specialized knowledge and equipment to help prevent incidents.\nEastman maintains performance-oriented security programs designed to protect Company facilities, products, intellectual property, information, people on Company property and the public. These programs are consistent with applicable regulations and with sound, industry-accepted security practices.\nEastman’s Global Environmental Affairs team leads the charge for Eastman’s environmental focus. The men and women of Eastman take environmental stewardship to heart.\nWe regularly seek input and openly communicate with citizens and community leaders. In 1990, we developed Community Advisory Panels (CAPs) as part of our Responsible Care? initiative.\nCommunity Advisory Panels\nFor nearly three decades, Eastman has organized Community Advisory Panels in its plant locations. These are committees made up of local citizens and leaders who meet several times annually with Eastman representatives. Our Community Advisory Panel (CAP) members help us ensure we’re keeping the community’s best interests in mind. Currently, we have 12 panels in place globally, representing about 22 percent of Eastman’s total manufacturing locations.\nA key part of HSES management systems is certification by an independent, accredited auditor. As part of our Corporate RCMS certificate, our Corporate Headquarters is annually audited by an accredited, 3rd party auditors."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:d77feb47-4e58-4bd4-9d31-84c26334b6d6>","<urn:uuid:2de7af33-77e4-4499-8311-7333c6265f22>"],"error":null}
{"question":"How does Kashmir wool compare to Alpaca fiber in terms of softness and characteristics?","answer":"Kashmir wool (pashmina) and Alpaca fiber have distinct characteristics. Kashmir wool comes from goats in Tibet and Central Asia, specifically from the fine fleece underneath their rough outer hair. Alpaca fiber is warmer than sheep's wool, lighter in weight, and characterized as soft, fine, glossy, and luxurious. Quality alpaca fiber has a thickness between 12-29 micrometers, with the softest fiber coming from younger animals (called 'cria'). The best alpaca fiber comes from the 'blanket' area of the animal and has a silky feel. Unlike sheep's wool, alpaca fiber doesn't have scales, making it less likely to cause itchiness.","context":["Shawl, tapestry woven, embroidered and pieced, wool, Kashmir, 1850-1870\nShawl designed by Montaz Allaie (written in Persian script at one edge).\nWoven and embroidered wool shawl from Kashmir, in the \"patchwork\" pattern. Shawls of this type are comprised of several sections that had been woven on different looms, and then handsewn together by the rafugar, or shawl tailor. In the early nineteenth century when demand was high and designs had become increasingly elaborate, a new practise of dividing up the work amongst several looms was implemented in order to speed up production. The resulting pieces were sometimes referred to as \"patchwork shawls\".\nTraditionally, women spun the yarn whilst the weaving was done by men, who began learning their trade from about the age of ten. Despite the high levels of skills involved and the large prices such shawls commanded, Kashmiri weavers were extremely poor and often suffered appalling working conditions.\nPredominantly red and black with polychrome work, the border is embroidered which is quite usual for this type of shawl. The swirling boteh design which surrounds the central medallion draws on the motif most popularly associated with the Kashmir shawl. Also known as 'paisley', 'pine cone' and 'mango', the boteh (or 'buta' in Hindi-Urdu meaning flower) evolved from its early depiction of a flowering plant during the Mughal period, gradually taking on a more abstracted form of foliage and flowers compacted in a long oval shape. By the mid-eighteenth century, the distinctive top curved hook had started to emerge, becoming more pronounced by the middle of the nineteenth century when a very stylised, curvilinear boteh appeared, owing little obvious debt to its original, representational form.\nThe English word \"shawl\" is derived from the Persian \"shal\", originally denoting a class of woven fabric rather than a particular article of dress. In traditional Indo-Persion usage shal could equally well apply to a scarf, a turban, a mantle or even a coverlet, the distinguishing feature being that the material was fine wool or some other kind of animal fleece.\nThe finest brocaded woollen shawls of the modern era are synonymous with the name of Kashmir. Traditionally, the wool used in Kashmir shawls (known as cashmere or pashmina) came from goats found in Tibet and Central Asia. This fine wool comes from the fleece underneath the rough outer hair, which is grown as protection against the harsh cold of the region and shed with the onset of summer. The comparative rarity and expense of this type of wool led to experimentations with other materials, which contributed to a decline in standards.\nKashmir shawls became increasingly popular in Europe during the late 18th century when travellers, East India Company employees and civil servants began bringing them home. Although in India shawls were part of the man's dress, in Europe they quickly became a sought after accessory for women. In France, Empress Josephine became an avid collector after receiving a gift of Indian shawls from Napoleon upon his return from his Egyptian campaign of 1798. Images of the Empress and other French society ladies wearing these richly coloured shawls helped popularise the fashion in France and England. Demand soon outstripped supply, despite the high prices such shawls commanded.\nKashmir shawl weavers practised what is known as the twill-tapestry technique (so named because of its similarity to the tapestry weaving technique of western Europe), where a single shawl could take eighteen months or more to complete. During the nineteenth century, in response to foreign demand and increasingly complicated patterns, the idea of the 'patchwork shawl' was born. By dividing up the weaving between several looms and joining the pieces together, even shawls with complex patterns could be finished in a significantly shorter time.\nBy the mid 1860s, the decline of the shawl's popularity had begun, although production continued for some years. By 1885, shawls were no longer fashionable, destroyed by an over-supply of much cheaper European versions made on the newly introduced jacquard loom, and later printed shawls.\n[see 'From Kashmir to Paisley: the shawl trade and the hundred year fashion' by Christina Sumner in \"The Australian Antique Collection\" , Jan-June 1993 and \"The Kashmir Shawl\" by John Irwin, Victoria and Albert Museum, 1973]","|Infobox on Animal fibers|\n|Example of Animal fibers|\n|Stowage factor (in m3/t)||2,55/3,66 m3/t (well pressed bales)|\n|Humidity / moisture||See text|\n|Risk factors||See text|\nAnimal fibers are natural fibers that consist largely of particular proteins. Instances are silk, hair/fur (including wool) and feathers. The animal fibers used most commonly both in the manufacturing world as well as by the hand spinners are wool from domestic sheep and silk. Also very popular are alpaca fiber and mohair from Angora goats. Unusual fibers such as Angora wool from rabbits and Chiengora from dogs also exist, but are rarely used for mass production.\nNot all animal fibers have the same properties, and even within a species the fiber is not consistent. Merino is a very soft, fine wool, while Costwold is coarser, and yet both merino and Cotswold are types of sheep. This comparison can be continued on the microscopic level, comparing the diameter and structure of the fiber. With animal fibers, and natural fibers in general, the individual fibers look different, whereas all synthetic fibers look the same. This provides an easy way to differentiate between natural and synthetic fibers under a microscope.\nSilk is a \"natural\" protein fiber, some forms of which can be woven into textiles. The best-known type of silk is obtained from cocoons made by the larvae of the silkworm Bombyx mori reared in captivity (sericulture). Degummed fibers from B. mori are 5-10 μm in diameter. The shimmering appearance for which silk is prized comes from the fibers' triangular prism-like cross-sectional structure which allows silk cloth to refract incoming light at different angles. Silk is also the strongest natural fiber known.\nThe length of the silk fiber depends on how it has been prepared. Since the cocoon is made of one strand, if the cocoon is unwound carefully the fibers can be very long.\nWool is the fiber derived from the fur of animals of the Caprinae family, principally sheep, but the hair of certain species of other mammals such as goats, alpacas, and rabbits may also be called wool.\nAlpaca fiber is that of an alpaca. It is warmer than sheep's wool and lighter in weight. It is soft, fine, glossy, and luxurious. The thickness of quality fiber is between 12-29 micrometers. Most alpaca fiber is white, but it also comes in various shades of brown and black.\nAngora wool or Angora fiber refers to the down coat produced by the Angora rabbit. There are many types of Angora rabbits - English, French, German and Giant. Angora is prized for its softness, thin fibers of around 12-16 micrometers for quality fiber, and what knitters refer to as a halo (fluffiness). The fiber felts very easily. Angora fiber comes in white, black, and various shades of brown.\nBison Down is the soft undercoat of the American Bison. The coat of the bison contains two different types of fiber. The main coat is made up of coarse fibers (average 59 micrometers) called guard hairs, and the downy undercoat (average 18.5 micrometers). This undercoat is shed annually and consists of fine, soft fibers which are very warm and protect the animal from harsh winter conditions.\nCashmere wool is wool obtained from the Cashmere goat. Cashmere is characterized by its luxuriously soft fibers, with high napability and loft. In order for a natural goat fiber to be considered Cashmere, it must be under 18.5 micrometers in diameter and be at least 3,175 centimeters long. It is noted as providing a natural light-weight insulation without bulk. Fibers are highly adaptable and are easily constructed into fine or thick yarns, and light to heavy-weight fabrics.\nMohair is a silk-like fabric or yarn made from the hair of the Angora goat. It is both durable and resilient. It is notable for its high luster and sheen, and is often used in fiber blends to add these qualities to a textile. Mohair also takes dye exceptionally well.\nWool has two qualities that distinguish it from hair or fur: it has scales which overlap like shingles on a roof and it is crimped; in some fleeces the wool fibers have more than 20 bends per inch. Wool varies in diameter from below 17 micrometers to over 35 micrometers. The finer the wool, the softer it will be, while coarser grades are more durable and less prone to pilling.\nQiviut is the fine underwool of the muskox. Qiviut fibers are long (about 5 to 8 cm), fine (between 15 and 20 micrometers in diameter), and relatively smooth. It is approximately eight times warmer than sheep's wool and does not felt or shrink.\nFiber from other animals\nHand spinners also use fiber from animals such as llamas, camels, yak, and possums. These fibers are generally used in clothing.\nHair from animals such as horses is also an animal fiber. Horsehair is used for brushes, the bows of musical instruments and many other things. Chiengora is dog hair.\nWool from a wide range of animals can be used for handicrafts and garments.\nMost animal fiber will felt but some felt much better than others. Sheep’s wool is one of the more versatile types of fiber to use in a felting project. Other types of fiber that felt fairly easily are Alpaca, Angora, Mohair, and Llama. There are many different breeds of sheep and the wool from each breed has different qualities and characteristics. Learning about the various differences will be a great help when determining which type of wool should be used for which individual project.\nFibre from Alpacas and Angora goats is softer the younger the animal. Alpaca fibre described as ‘cria’ – the name for baby camelids, will be the softest fibre. The softness of the fibre also depends where on the animal it was sheared from. The ‘blanket’ is the best part, it is soft and long. Fibre from the neck and upper legs is soft, but shorter, this is usually called ‘seconds’ and fibres from the lower legs and belly has lots of guard hair, and is coarser and usually quite dirty. Alpaca fibre is very soft and has a silky feel. Because it doesn’t have scales like sheep wool, it is less likely to cause the ‘itchy’ feeling some people get from wool.”\nFibre from Angora goats is known as Mohair. Kid mohair is from the youngest goats and is softer and more curly. Fibre from slightly older goats known as ‘Yearling’ is courser and more wavy than curly, and fleece from older animals is known as Adult mohair’ or ‘grown mohair’. Mohair is very shiny. The micron count for cria alpaca and kid mohair is around 20 for both, increasing with the age of the animal.\nOther micron counts are Cashmere 14-19, Angora rabbit 10-16, Vicuna 10-13, Camel 15-23.\nSheep’s wool is a renewable resource and a multipurpose fiber. Wool has characteristics that have made it a desirable fiber for many thousands of years.\n- Wool can absorb up to 30% of its own weight in moisture. Therefore, when worn as clothing, it can wick sweat from the body and enhance the body’s own cooling system. It prevents the clammy, cold feeling found when wearing synthetic clothing.\n- Wool is an insulator as opposed to trapping heat. As an insulator, it keeps you warm in cold weather and cool in hot weather.\n- The moisture in each wool fiber means that it is fire resistant. Wool will char in an open flame but is self extinguishing and stops burning after being removed from the flame.\n- The waviness or crimp of wool fiber gives it a natural elasticity. This elastic quality allows the wool to retain its shape better and makes it very durable as the fiber can be bent multiple times without breaking.\n- Wool is resistant to dirt because the small scales on the surface of the fiber hold the dirt near the surface, making the dirt easier to remove. Wool also repels odors.\n- Like most fabrics, wool is a good sound absorber.\n- Due to its moisture content, wool is resistant to static electricity.\n- Saving the best for last, wool has the ability to felt. Due to the small scales on the surface of the wool fiber as well as other factors such as the crimp, wool when combined with warm water, soap and a little agitation will matt together in an irreversible process called felting.\nWool is graded to determine its quality. The quality can be determined by fiber diameter, crimp, colour, staple length, staple strength, yield and remaining vegetable matter. The most important factor though is the fiber diameter. The fineness or coarseness of the wool will determine its end use. The diameter is measured either by the Bradford System or by microns.\nThe Bradford System is a way to measure the fineness of a wool breed. The Bradford Count is the number of hanks of yarn (a hank being 560 yards long) that can be spun from a pound of wool tops. The finer the wool, the more hanks could be spun. Wool with higher Bradford counts are finer and therefore can be spun into longer yarn.\nMicron count is the diameter of the fibre in microns, a micron is 1,000th of a millimetre. The lower the micron count the finer the wool.\nShipment / Storage / Risk factors\nUsually shipped in bales. Argentine dressed horse hair has a natural moisture content varying between 6% and 10%, according to the season in which it is packed. Subject to loss in weight due to drying out.\nHorse hair deteriorates when wet, either from external causes or as a result of damp packing, which causes the material to become brittle and rot. Similarly mohair and other animal fibres also react to the presence of any excess moisture.\nThe product is liable to ignite spontaneously according to oil/moisture content.\nCheck the IMDG (International Maritime Dangerous Goods) Code for transport advice."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:86ae6bdf-44dc-476a-a062-4cb7e229896c>","<urn:uuid:823bb02f-ebbc-4f3a-923a-0817281db4ab>"],"error":null}
{"question":"What are the key differences between managing perennial plants and creating a Conservation Area?","answer":"Perennial plants and Conservation Areas involve very different management approaches. Perennials are plants that live for several years, with some being short-lived (three years) while others live much longer. Their management focuses on horticultural care and planning. In contrast, establishing a Conservation Area is a complex legal and administrative process. Local Authorities must conduct extensive research, consult with property owners within the area's bounds, and may implement specific restrictions on development rights. Conservation Areas require ongoing management by Local Authorities to preserve areas of special architectural or historic interest, which can include various elements like parks, gardens, and even abstract concepts like historical land use.","context":["Self-seeding annuals and biennials scatter copious amounts of seed across the garden and can be relied upon to appear year-after-year without help from the gardener.\nIf you have a border that doesn’t receive much light, this is the perfect spot for a shade garden!\nA garden without a view can seem too confining and insular so consider how your garden might connect to the surrounding landscape. If your garden is enclosed by high walls or fences, think about creating openings in them to give views onto the world outside.\nThink about what you want your garden to do. It should reflect your lifestyle, the people who will be enjoying it and the time you plan to spend in it, whether it is relaxing, playing or tending the plants.\nA tree preservation order (TPO) prohibits the removal or cutting down of trees. TPOs are usually applied to individual trees.\nEdinburgh Garden School offer accredited online courses for students wishing to prepare for the RHS Level 2 or Level 3 exams. The RHS certificates are widely recognised within the industry and well-regarding.\nYou can have a pleasant resting spot beneath a shady tree even if space in your garden is limited. Many attractive trees are suitable for the smaller garden, achieving just a few feet in height even when fully grown.\nIn spots where nothing seems to grow except weeds, hoeing and weeding may not be enough to keep the quick, unwanted growth at bay. You can achieve an attractive, low-maintenance display with shrubs that have a naturally low habit of growth.\nA Profusion of Blooms A well-planned, colourful herbaceous border can be a focal point in the garden. With a sequence of perennials coming into flower, the border can be an ever-changing spectrum of beautiful...\nIf you lack the space for a formal rock garden, but long for a display of alpine plants and flowers, a dry stone wall is the ideal solution. The combination of natural stone and colourful mountain flowers brings out the best of both.\nYou can recreate the beauty of natural heather landscapes on a smaller scale in your garden. Heathers have the advantage of needing a minimum of care. With careful planning you can achieve a beautiful mixture of subtle shades.\nOnce the soil has started to warm up, apply a mulch to borders to prevent weeds growing and conserve moisture. Don’t do this too quickly, however, as if the soil is still cold the mulch will stop it warming up and, as a result, inhibit plant growth. Apply the mulch after rain so that the soil is also moist.\nWith a little careful planning and some imagination you can create an uplifting spring border that begins to flower before the end of winter and provides a constant display of cheerful colour until early summer.\nAn espalier is any plant that is trained to grow against a wall or along a framework, so that instead of developing a naturally rounded form, it grows into a flattened, two-dimensional shape. Creating an espalier takes time and a certain amount of skill.\nA pergola should not normally stand by itself in the garden, but should form a link between different man-made features, or to connect man-made structures and planting.\nThorough preparation is key to creating a healthy, attractive and long-lasting border.\nPlanting plans are used to show the detail of planting within a design. Unless the garden is very small, the garden designer will usually produce a separate planting plan for each border and key area of the design.\nPerennials are plants that live for several years. Most live for many years, although some, short-lived perennials, may live for as few as three years.","The story of Conservation Areas\nThe idea of Conservation Areas first became codified in law in 1967 as part of the Civic Amenities Act. The first area to be designated was the town of Stamford in Lincolnshire which appears in several films.\nImprovements to the law were made in The Town and Country Planning Act of 1971 and a specific act for Conservation Areas was passed in 1990: The Planning (Listed Buildings and Conservation Areas) Act.\nAccording to the 1990 Act, a Conservation Area is ‘an area of special architectural or historic interest, the character of which it is desirable to preserve or enhance.’ While there are many such areas across the country, the Act also seeks to protect the integrity of conservation by asking Local Authorities to take care in choosing appropriate areas to designate.\nLocal Authorities also have the responsibility of managing the Conservation Areas they designate. You will find detailed Conservation Area appraisals for each area on your Local Authority’s website. Every LA has at least one Conservation Area under their protection.\nThere are now around 10,000 Conservation Areas in England with a combined area that exceeds that of Luxembourg. The largest Conservation Area is Swaledale and Arkengarthdale in Yorkshire which itself is larger than some small countries!\nThe south west has an abundance of Conservation Areas. Wiltshire (246) and Cornwall (146) have more designations than any other county while Devon has its fair share too, divided between its Local Authorities.\nWhen an area is first designated as a Conservation Area, the Local Authority will conductive extensive research and consult widely with the people who live and own property within its bounds. Some LAs may decide to place restrictions on the permitted development rights that would otherwise apply.\nConservation Areas, Listed Buildings and Tree Preservation Orders (TPOs)\nConservation Areas, Listed Building status and TPOs are all ways to protect England’s history and culture. But whereas TPOs and listed buildings apply to specific trees and buildings respectively, a Conservation Areas can cover anything from parks and gardens to stone walls, town centres and street layouts. It can even cover abstract concepts such as the historical way in which a plot of land has been used.\nA Conservation Area applies to everything within a designated area, including trees and buildings, but every area is subject to different rules and processes.\nCan Conservation Area home or business owners control trees on their land?\nEach LA manages its Conservation Areas in a unique way so there is no ‘one size fits all’ rule.\nTherefore, whether or not a tree currently has a TPO, home and business owners in Conservation Areas should always contact the LA’s planning office for permission to fell or change the appearance of all but the smallest of trees.\nIf you do need to fell or prune a large tree in a Conservation Area you don’t want to risk calling out the cowboys. You are ultimately responsible for any trees on your land and if a mistake is made to a tree that is eligible for a TPO, you could be fined thousands of pounds (or an unlimited amount if that tree later dies).\nFor your peace of mind, we strongly recommend you contact a professional, accredited tree specialist like Arborcure. We will carry out a professional tree survey and manage your tree in line with TPO legislation and any other Conservation Area protections."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:b3dd9b36-1250-44b8-9d44-95a8798b2a47>","<urn:uuid:693a5a8c-ef9d-4e1c-aaa1-9442f9ef8879>"],"error":null}
{"question":"What teaching roles have Joern Meissner and Allan Dahl Andersen held?","answer":"Joern Meissner has taught the MBA Core course in Operations Management and created three MBA Electives (Advanced Decision Models, Supply Chain Management, and Revenue Management) at Lancaster University Management School. He has also lectured at the University of Hamburg, Leipzig Graduate School of Management, and the University of Mannheim, and offers Executive Education courses. Allan Dahl Andersen teaches the module 'Innovation and sustainability transitions' within the Master-level course 'Innovation and Global Challenges' (TIK4021).","context":["Joern Meissner is Professor of Supply Chain Management & Pricing Strategy at Kühne Logistics University. Meissner holds a PhD and a Master’s Degree in Management Science from the Graduate School of Business at Columbia University (Columbia Business School) in New York City and a Diploma in Business from the University of Hamburg. His research spans a wide field of study, including the areas of Supply Chain Management (SCM), Pricing Strategy and Revenue Management. His work has been published in various prestigious journals including Operations Research, Manufacturing and Service Operation Management (MSOM), European Journal of Operational Research, International Journal of Production Research, International Journal of Production Economics and Naval Research Logistics.\nMeissner’s main research focus is the area of stochastic and dynamic decision-making, and in particular applications to logistics, manufacturing, supply chain management, and pricing strategy. The aim of his research is to develop and implement robust and efficient techniques to business problems in those domains. A common theme within his research is the use of mathematical optimization techniques such as dynamic programming to guide managers to make better business decisions. Currently, Meissner pursues the following research streams:\n- Global Supply Chain Optimization\nThis research focuses on how to efficiently integrate suppliers, producers, and warehouses to produce and distribute the right quantity, at the right time and in the right place while maximizing the total supply chain profit and guaranteeing an appropriate service level. Research questions often focus on incentives for the business partners to align their individual behavior with the goals of the total supply chain.\n- Improvements in Inventory Control\nControl of inventory is a complex task, in particular if it involves a large number of SKUs (stock-keeping units) with intermittent demand patterns, which make forecasting and inventory control very difficult. Due to the large amount of spare part SKUs held in many companies, it is often not possible to configure an inventory system manually for each part separately. Our research evaluates, for example, a sub-grouping of intermittent demand patterns by a categorization scheme and the quality of the resulting inventory control policies.\n- Operations & Service Management\nService management is integrated into supply chain management as the interface between sales/after-sales and the customer. The aim of high performance service management is to optimize the service-intensive supply chains, which are usually more complex than supply chains concerned exclusively with finished goods. Companies often must accommodate inconsistent and uncertain demand by establishing more advanced information. A typical research question within this context is staffing of call centers or teller stations, for example.\n- Pricing Strategy & Revenue Management\nRecent advances in pricing and revenue management have rapidly changed the environment in which firms operate. The Internet, the adoption of new information technologies, and other market forces are driving the need for more sophisticated pricing methodologies and techniques. Given the tremendous upside of better pricing strategies, more and more industries are adapting mathematical pricing models to their needs. Promising research directions include sophisticated models of consumer behavior, models including competition between different providers, and the evaluation of pricing mechanisms such as auctions. These are very important issues for today's managers and research in this area is promising from both a theoretical and empirical perspective.\nAs a leading expert in the development of optimization algorithms for a variety of logistics, supply chain management and pricing problems, Joern Meissner is often consulted by industry professionals and helps firms apply his cutting-edge mathematical techniques to their current business problems. He frequently advises companies, ranging from Fortune 500 companies to emerging start-ups, on issues such as supply chain planning and pricing strategy. His current and past clients include British Telecom (BT), British Airways, Apple Europe, Pernod Ricard, Promethean, TUI, The Co-Operative, Littlewoods, Virgin Trains, Virgin Cargo and SAP Germany, among others.\nMeissner is a passionate and enthusiastic teacher. He believes that grasping an idea is only half of the fun; conveying it to others makes it whole. At his previous position at Lancaster University Management School, he taught the MBA Core course in Operations Management and originated three new MBA Electives: Advanced Decision Models, Supply Chain Management, and Revenue Management. He has also lectured at the University of Hamburg, the Leipzig Graduate School of Management (HHL), and the University of Mannheim. Meissner offers a variety of Executive Education courses aimed at business professionals, managers, leaders, and executives who strive for professional and personal growth.\nIn the past, Meissner has also been a successful entrepreneur. He founded Manhattan Review, a global test preparation and admissions consultancy, during his time at Columbia Business School. More recently, he established Lancaster Executive, a provider of executive education programs for senior managers.\nFor more details about Joern Meissner, including downloads of research articles and white papers, please visit his academic homepage at http://www.meiss.com.\nUp Close & Personal\n“I think KLU is special because you can study logistics in a space, where logistics really happens.”\n– Prof. Jörn Meissner, Ph.D.\nTurrini, Laura and Joern Meissner (2019): Spare parts inventory management: New evidence from distribution fitting, European Journal of Operational Research, 273 (1): 118-130.\nAbstract: Spare parts are necessary for ensuring the functioning of the critical equipment of many companies, and as such, they play a central role in these companies’ operations. Inventory control of spare parts is particularly challenging due to the nature of their demand, which is usually slow-moving, erratic and lumpy. As inventory policies rely on the forecasted lead-time demand distribution and this choice impacts the performance of the system, an ill-suited hypothesized distribution may result in high preventable costs. In this study, we contribute to the empirical literature by analyzing what distributions best fit spare parts demand. We use the Kolmogorov Smirnov (K–S) goodness-of-fit test to find the best-fitting distributions to our data and compare our results to those in the literature. Furthermore, we implement a slightly modified K–S test that places greater emphasis on differences in the right tail of the distribution, mirroring real-world inventory applications, and less emphasis on the left tail. Finally, we link the goodness-of-fit of the distributions to their inventory performance. Our first dataset comes from the German renewable energy industry and is composed of the weekly demand for more than 4000 items over the period 2011–2013. The second dataset comes from the Royal Air Force. It is composed of monthly demand for 5000 items over the period 1996–2002.\nMeissner, Joern and Olga V. Senicheva (2018): Approximate dynamic programming for lateral transshipment problems in multi-location inventory systems, European Journal of Operational Research, 265 (1): 49-64.\nAbstract: Companies commonly allocate their inventories across multiple locations based on their historical sales rates. However, random fluctuations in customer purchases, such as those caused by weather conditions and other external factors, might cause significant deviations from expected demand, leading to excess stock in some locations and stockouts in others. To fix this mismatch, companies often turn to lateral transshipments, e.g., the movement of stock between locations of the same echelon. In this paper, we examine multi-location inventory systems under periodic review with multiple opportunities for proactive transshipments within one order cycle. If stockouts occur, demand is lost with no opportunity to backorder. The objective of our model is to find an optimal policy that indicates the sources and the destinations of transshipments as well as the number of units, to maximise the profit of the network. We create a dynamic program that can, in principal, be solved to optimality using Bellman’s equation. However, the size of the state and decision spaces makes it impossible to find the optimal policy for real-world sized problem instances. Thereby, we use forward approximate dynamic programming to find a near-optimal transshipment policy. Finally, we conduct an extensive numerical study to gauge the performance of our transshipment policy. For small size instances, we compare our policy to the optimal one. For larger scale instances, we consider other practically oriented heuristics. Our numerical experiments show that our proposed algorithm performs very well compared to state-of-the-art methods in the literature.\nMeissner, Joern and Arne K. Strauss (2012): Network revenue management with inventory-sensitive bid prices and customer choice, European Journal of Operational Research, 216 (2): 459-468.\nAbstract: We develop an approximate dynamic programming approach to network revenue management models with customer choice that approximates the value function of the Markov decision process with a non-linear function which is separable across resource inventory levels. This approximation can exhibit significantly improved accuracy compared to currently available methods. It further allows for arbitrary aggregation of inventory units and thereby reduction of computational workload, yields upper bounds on the optimal expected revenue that are provably at least as tight as those obtained from previous approaches. Computational experiments for the multinomial logit choice model with distinct consideration sets show that policies derived from our approach can outperform some recently proposed alternatives, and we demonstrate how aggregation can be used to balance solution quality and runtime.\nFedergruen, Awi, Joern Meissner and Michal Tzur (2007): Progressive Interval Heuristics for the Multi-Item Capacitated Lot Sizing Problems, Operations Research, 55 (3): 490-502.\nAbstract: We consider a family of N items which are produced in or obtained from the same production facility. Demands are deterministic for each item and each period within a given horizon of T periods. If in a given period an order is placed, setup costs are incurred. The aggregate order size is constrained by a capacity limit. The objective is to find a lot-sizing strategy that satisfies the demands for all items over the entire horizon without backlogging, and which minimizes the sum of inventory carrying, fixed and variable order costs. All demands, cost parameters and capacity limits may be time-dependent. In the basic (JS)-model, the setup cost of an order does not depend on the composition of the order. The (JIS)-model allows for item-dependent setup costs in addition to the joint setup costs. We develop and analyze a class of so-called progressive interval heuristics. A progessive interval heuristic solves a (JS) or (JIS) problem over a progressively larger time-interval, always starting with period 1, but fixing the setup variables of a progressively larger number of periods at their optimal values in earlier iterations. Different variants in this class of heuristics allow for different degrees of flexibility in adjusting continuous variables determined in earlier iterations of the algorithm. For the (JS)-model and the two basic implementations of the progressive interval heuristics, we show under some mild parameter conditions, that the heuristics can be designed to be epsilon-optimal for any desired value of epsilon > 0 with a running time that is polynomially bounded in the size of the problem. They can also be designed to be simultaneously asymptotically optimal and polynomially bounded. A numerical study covering both the (JS) and the (JIS) model, shows that a progressive interval heuristic generates close-to-optimal solutions with modest computational effort and that it can be effectively used to solve large-scale problems.\nMaglaras, Constantinos and Joern Meissner (2006): Dynamic Pricing Strategies for Multi-Product Revenue Management Problems, Manufacturing & Service Operations Management, 8 (2): 136-148.\nAbstract: This chapter reviews multi-product dynamic pricing models for a revenue maximizing monopolist firm. The baseline model studied in this chapter is of a seller that owns a fixed capacity of a resource that is consumed in the production or delivery of some type of product. The seller selects a dynamic pricing strategy for the offered product so as to maximize its total expected revenues over a finite time horizon. We then review how this model can be extended to settings where the firm is selling multiple products that consume this firm's capacity, and finally highlight a connection between these dynamic pricing models and the closely related model where prices are fixed, and the seller dynamically controls how to allocate capacity to requests for the different products. Methodologically, this chapter reviews the dynamic programming formulations of the above problems, as well as their associated deterministic (fluid) analogues. It highlights some of the key insights and pricing heuristics that are known for these problems, and briefly mentions possible extensions and areas of current interest.\nNo content available yet.\nProfessor of Supply Chain Management & Pricing Strategy at Kühne Logistics University\n|2005 - 2011|\nLecturer in Management Science, Lancaster University Management School.\nPh.D., Columbia University, Graduate School of Business, New York. Thesis: Multi-Item Supply Chain and Revenue Management Problems. Advisors: Professors Awi Federgruen and Costis Maglaras.\nMaster of Philosophy, Columbia University, Graduate School of Business, New York.\nDiplom-Kaufmann (Diploma in Business), University of Hamburg.\n2015 - Best paper award of the POMS 26th Annual Conference for the Humanitarian Operations and Crisis Management track\nJoern Meissner received the best paper award of the POMS 26th Annual Conference for the Humanitarian Operations and Crisis Management track for his article (together with Maria Besiou and Laura Turrini) \"Understanding Fundraising in Humanitarian Supply Chains\".\n- Prof. Dr. Dr. Matthias Koenig (Fachhochschule Bielefeld)\n- Prof. Dr. Hongyan Li (Aarhus Business School, DK)\n- Dr. Jochen Schurr (Germany)\n- Dr. Olga Senicheva (Lecturer, Purdue University, Krannert School of Managment, USA)\n- Prof. Dr. Laura Turrini (EBS University, Germany)\n- Prof. Dr. Arne K. Strauss (Warwick Business School, UK)","Allan Dahl Andersen\nIn his work, Allan studies innovation and industrial change processes associated with broader societal challenges with particular attention to sustainability transitions. Allan focuses on the interaction of technology, actor strategies, policy, politics, society and culture. This concerns both the emergence of new technological fields as well as the transformation of established technological systems.\nAllan Dahl Andersen has a bachelor in economics from Aalborg University. From the same university he has a master degree in Innovation, Knowledge and Economic dynamics (MIKE). He has an additional master degree (cum laude) in economics from Universiteit van Amsterdam with a major in development economics and a minor in institutional economics. Allan did his PhD in Economics of Innovation with the IKE-group at Aalborg University. His PhD work centered around the role of natural resources in economic development, theoretical issues of building and transforming systems of innovation, and analyzing the evolution of the sugarcane-biofuel industry in Brazil as a (sectoral) natural-resource based innovation system.\nWithin the Master-level course “Innovation and Global Challenges” (TIK4021) Allan teaches on the module “Innovation and sustainability transitions\".\nAndersen, A. D., Steen, M., Mäkitie, T., Hanson, J., Thune, T. M., & Soppe, B. (2020). The role of inter-sectoral dynamics in sustainability transitions: A comment on the transitions research agenda. Environmental Innovation and Societal Transitions, 34, 348-351. doi:https://doi.org/10.1016/j.eist.2019.11.009\nAndersen, A. D., & Gulbrandsen, M. (2020). The innovation and industry dynamics of technology phase-out in sustainability transitions: Insights from diversifying petroleum technology suppliers in Norway. Energy Research & Social Science, 64(June). doi:https://doi.org/10.1016/j.erss.2020.101447\nAndersen, A. D., & Wicken, O. (2020). Making sense of how the natural environment shapes innovation and industry dynamics: Implications for policy, sustainability challenges, and research. Innovation and Development. doi:10.1080/2157930X.2020.1770975\nAndersen, A. D., & Markard, J. (2020). Multi-technology interaction in socio-technical transitions: How recent dynamics in HVDC technology can inform transition theories. Technological Forecasting & Social Change.\nLindberg, M. B., Markard, J., & Andersen, A. D. (2019). Policies, actors and sustainability transition pathways: A study of the EU’s energy policy mix. Research Policy, 48(10), 103668. doi:https://doi.org/10.1016/j.respol.2018.09.003\nMäkitie, T., Andersen, A.D., Hanson, J., Norman, H., and Thune, T. (2018). “Established sectors expediting clean technology industries? The Norwegian oil and gas sector's influence on offshore wind power”. Journal of Cleaner Production 177.\nAndersen, A.D., Marìn, A., and Simensen, E. O. (2018). “Innovation in natural resource-based industries: a pathway to development? Introduction to special issue”. Innovation and Development, 8(1).\nSchlaile, M.; Urmetzer, S.; Blok, V.; Andersen, A. D.; Timmermans, J.; Mueller, M.; Fagerberg, J.; and Pyka, A. (2017). “Innovation Systems for Transformations towards Sustainability? Taking the Normative Dimension Seriously”. Sustainability 9(12).\nAndersen, A. D. and Johnson, Björn (2015). “Low-carbon development and inclusive innovation systems”. Innovation and Development, 5(2).\nAndersen, A.D. (2015). “A functions approach to Innovation System building in the ‘South’ – the pre-proalcool evolution of the sugarcane and biofuel industry in Brazil”. Innovation and Development, 5(1).\nAndersen, A. D. (2014). “No transition without transmission: HVDC electricity infrastructure as an enabler for renewable energy?” Environmental Innovation and Societal Transitions.\nAndersen, A.D. and Andersen, P. D. (2014). \"Innovation System Foresight\", Technological Forecasting and Social Change, 88.\nAndersen, A.D. (2012). ”Towards a new approach to natural resources and development: the role of learning, innovation and linkage dynamics”, International Journal of Technological Learning, Innovation and Development, Vol. 5, No. 3, pp.291–324."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:d4f178db-082a-4819-a95f-a514536631de>","<urn:uuid:196f401a-062b-44af-8360-7f8f7c2d30d6>"],"error":null}
{"question":"Looking to buy property and add solar panels later. What's involved in property due diligence, and what should I know about solar-ready construction?","answer":"Property due diligence typically takes 30-60 days and includes several key steps: property inspection (examining physical aspects like heating and plumbing), title search (revealing unpaid taxes, judgments, mortgages), environmental inspections if needed, and property survey to check boundary lines and encroachments. For solar installation preparation, new construction can incorporate 'Solar Ready Trusses' that are pre-engineered to handle solar panel loads and attachment methods. These trusses are designed according to standards agreed upon by engineering stakeholders specifically for structures intended to have solar installations, ensuring the roof can safely support the system without compromising structural integrity.","context":["Latest feature on PropertyShark…\nIt can take buyers a long time to find the perfect home. Then, once they find it, it’s common to be eager to close the deal and make the purchase as quickly as possible. But, it’s vital to do some research prior to signing the contract to avoid entering into a risky deal.\nBefore the contract signing is the most important period, known as the due diligence phase. Due diligence is a legal term that can be defined simply as “doing your homework.” There are several things to do prior to signing the contract of sale, as well as other due diligence searches that are done after you have a fully executed contract of sale.\nOverall, due diligence is a thorough search of any information that could possibly be a warning sign regarding the property. From start to finish, the process can last as long as 30 to 60 days, and, while it can require considerable initial effort, it does lessen the amount of uncertainty for buyers in the long run. In the case of co-op and condo purchases, there are additional due diligence steps.\n1. Property Inspection\nWalking the actual property is extremely helpful. As opposed to a written description, this is the buyer’s opportunity to examine the physical aspects of the property – from heating and plumbing to structural appearance and even grass.\nThe property inspection is done prior to signing the contract of sale, especially when purchasing a single-family home in Queens, Brooklyn or Long Island. A certified inspector will check for issues such as plumbing, electrical and more.\n2. Title Search\nAfter the contract of sale is signed, this is essentially a search on the seller, the buyer and the property itself to reveal any obstacles. A title search can reveal anything, including unpaid taxes, judgments, mortgages, special assessments and the legal owner of the property.\nBuyers should be aware of current zoning regulations they will need to comply with; it’s crucial to check if the buyer’s intended use of the property is legal under the zoning codes and regulations.\nThis is especially important for commercial deals or the purchase of empty land. In these cases, you need to be sure that any building plans are acceptable and will be approved.\n4. Environmental Inspections\nSometimes, environmental analyses will include a Phase I. Phase I Environmental Reports can expose any contamination of a property by hazardous materials. If necessary, a Phase II can be set in place to attain more information.\nSimilar to zoning, this is usually for commercial deals or empty land.\nAfter the title search, someone comes to measure the boundary lines of the property to ensure no one is encroaching on the land.\nA licensed surveyor can be hired to conduct a property survey that will inform the buyer on any encroachments on the property or the adjacent property. The survey can also inform the buyer of any easements. Learn more about encroachment and easements here.\n6. Property Appraisal\nIn this step, the lending institution verifies that the property’s worth matches the price the buyer is paying. They do this because they are giving a loan on the property based on the value of the house. This does not happen until after you have a fully executed contract of sale.\nAfter the initial inspection, buyers have options: if they feel confident, continue the purchasing process, or they can be glad they haven’t signed yet, and pull out of the deal. The initial inspection is really about gathering information that can help a buyer make the best decision possible.","Author: Graham Morfitt, BSc (Physics)\nIn this posting, I’d like to draw your attention to an issue that somehow gets avoided in our industry… the roof attachment.\nIn this case, I am not talking about the mechanical pieces that protect your roof from leaks when installing your solar system. Plenty of attention gets paid to things like flashings for L-feet, tile roof hooks, stand offs with hoods, EPDM seals, etc. What I’m wanting you to know about is the actual way in which the hanger bolts or lag screws that go through your roofing material attach to the substructure below.\nHitting The Target…\nA quick search through installation manuals for rooftop rail systems for PV solar, plus most industry publications, will point to the need to drive the lag screws & hanger bolts into your rafters or trusses. There are various methods outlined for doing this, but basically they involve drilling pilot holes up from the attic beside a rafter, measuring the distances between rafters, creating a “rafter map”, and then transferring this to the topside in the form of chalk lines.\nBut, as you might imagine, it is easier to create such a map for the purposes of missing a rafter than hitting one. It is recommended that a lag screw of hanger bolt penetrates a rafter or truss at least 1.5x it’s diameter from the edge of the rafter. This means that for a 1/4″ screw, you have a 3/8″ “no screw” border on each side of the top chord of the rafter or truss, leaving you with a 3/4″ target in the middle. Even with pilot holes, and super accurate mapping of the attic, are you confident that your roofer or solar installer will be able to hit that target, exactly perpendicular to the roof, in potentially dozens of locations on your roof?\nThe odds don’t fill me with confidence.\nWhat’s at stake?\nSo, what happens if you miss a rafter?\nWell, if you miss it entirely, you will not have the correct pull-out strength for that attachment. You would be anchored to roof plywood sheeting, and/or maybe a 1×4 strapping board.\nIf you hit the rafter, but are too close to the edge of it, or blow-out the side of it, you have now damaged that rafter or truss chord, and should repair it by pinning a sister board down the side of it.\nIs your roofer or solar installer crawling around in your attic making sure that none of your rafters are damaged, or attachments not even attached?\nHopefully. And now that you know, you should ask.\nWhat Do The Truss Manufacturer’s Think About Solar?\nIn brief “Don’t punch holes in the top chord of our trusses!”\nHere is a letter that says exactly that…\nWestern Wood Truss Association Letter 2013\nThe problem is one of engineering.\nTrusses & rafters have been engineered to provide strength for your roof. They are designed to handle wind loads & snow loads, and roofers walking around on it, etc. Understandably, they don’t want you messing with their calculations by drilling holes into the top chord. If you do, you are likely to void your warranty. Which would have an effect on your home insurance, resale value, etc.\nSolar engineering tries to override the fears of truss manufacturers by pointing out that the top chord of any truss or rafter is under compression, and therefore adding steel lag screws or hanger bolts will only improve the strength of the wood involved. This might be true, but all the calculations done in the original design of your home did NOT include these factors, and if the truss engineers didn’t include them in their original calculations, they are unlikely going to take your word for it that you put all 48 screws in nice & straight in the centre of each.\nAnother reason for truss manufacturers’ unwillingness to sign-off on your attachments: What if you ever need to remove the solar system? That’s right! Now you have a truss system with dozens of holes in the top chord. The strength of the roof is now compromised. The original designer/engineer won’t want their name on your swiss cheese.\nOne Last Problem with Rafter Attachments…\nUnless you stagger your attachments between different rafters, you run the risk of putting the load of the solar array onto only a few of the rafters in your attic. For example, the top rail in your solar array would be attached to rafter 2, 4, 6, 8, etc (for 4′ spans), and your bottom rail would be attached to rafter 3, 5, 7, 9, etc. Putting all the attachments on rafters 2, 4, 6, 8, etc, will very likely result in your roof taking on a wave-like appearance in a few years, as the pressure of the array, plus snow loads, will compress the rafters.\nThis is also one of the reasons why we are told not to run solar mounting rails in a vertical pattern on the roof when installing solar modules in a landscape orientation… it would mean loading every other rafter (having the rafter spacing meet with the solar module’s desired mounting locations is another reason).\nFortunately, there are ways to install solar that protect your trusses or rafters, add strength to your roof, and won’t cause you to get angry emails from truss engineers.\nThis is the process of adding 4×4″ wood struts either between your rafters, or alongside them. The blocks are attached to the sides of the rafters or truss members.\nThe benefits of doing this are…\n1. No holes in the top chord to compromise your truss strength.\n2. You have a bigger target to hit. Simply drill a pilot hole for your flashing/L-Bracket location, drop a flag down the hole into the attic, then place your blocking in that exact spot.\n3. Dispersed load – now your attachments can be placed in between the trusses/rafters, and the array load is shared between the two of them. You also no longer have to stagger your attachments & fumble with meeting long rail cantilever specifications.\nHere’s a brief video from Quick Mount PV on the subject\n(Quick Mount is our choice of flashed attachment for west coast roofs! See their equipment)\nThis is a fantastic product that attaches to your roof’s underlay plywood sheeting with multiple screws, and has been engineered to provide code-compliant pull-out strength.\nHere it is: Talon Roof Attachment\nThis is also the attachment you want if you do not have an accessible attic, have vaulted ceilings, low-slope roofs where the rail location is too difficult to get at from the attic, etc. Simply anchor the foot where you want it, cover & seal with the flashing, bolt-on your L-Foot bracket & carry on with the rail installation. Works with any rail system.\nWhat About New Construction?\nThere are things such as “Solar Ready Trusses”. These are based on standards that have been agreed upon by all the engineering stakeholders for building homes & structures that intend to have solar installed on them. Therefore, they have been pre-engineered to handle the loads & attachment methods.\nI encourage you to read-up on the latest options & standards available in your province.\nStart here for Solar Ready Truss Design\nThat’s all for this post. I hope it helps guide your solar PV installation. Solar should enhance your home energetically, aesthetically, financially, and physically, so it’s important that things be done correctly, without cutting corners.\nPlease be sure to contact me with any questions or comments."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:2510550c-1f55-4fa5-9c13-195eabf3cac7>","<urn:uuid:c1f2d4d7-c6da-4979-a9ec-111b9e8217db>"],"error":null}
{"question":"Hi! I read that some countries excel in certain sports. Is this because of genetics, and how does this compare to ancient athletic traditions?","answer":"While ancient athletic traditions were often class-based (with Egyptians and Mesopotamians limiting athletics to nobility), modern national sporting success isn't simply due to genetics. For example, the dominance of East African runners or Jamaican sprinters isn't due to spontaneous genetic mutations. Similarly, British middle-distance running excellence in the 1980s wasn't genetic. Instead, sporting success results from complex bio-social interactions including training, facilities, funding, and support systems. The ancient Greeks demonstrated a similar understanding by developing organized athletic institutions through their city-states, showing that success comes from systematic development rather than pure genetic inheritance.","context":["Hippias of Elis, a sophist of the fifth century BC, was the first to compile\nthe initial victor list of the Olympic games. From him we learn that the\nfirst athletic contest, the foot race, was held at the sacred place of\nOlympia, in western Peloponnese, for the first time in\nWas the athletic competition always organized?\nAnd what did athletic competition mean to the earlier cultures of the Mediterranean?\nAncient Egyptians and the people of Mesopotamia had a long tradition in athletic activities, as shown by the reliefs depicting athletic scenes carved on the tombs of their kings and their nobles. They did not hold regular festivals, however, and when they did, it seems that these were only attended by kings and the higher class.\nThe Minoans showed special concern in gymnastics. Bull-leaping and tumbling became their favorite sports, as indicated by the frescoes decorating their palaces. Other Minoan sports included some track-contests, wrestling and boxing. From what we can tell, such activities were practiced in places near the palace, probably by members of the noble class.\nThe Myceneans adopted all Minoan games, and introduced chariot-racing and more track contests. The Myceneans used the chariot not only for hunting and war purposes, but for religious and funerary ceremonies too.\nThe Homeric poems comprise the first written evidence of athletic contests in the Greek world. In his great poems, Homer gives vivid descriptions of the athletic contests held as part of the funerary ceremonies in honor of the dead hero, Patroclus, or in other occasions.\nThe emergence of the first city-states caused a rapid development in athletism: a number of local contests were set up in these cities, held in festivals of religious character. Athletism became an institution, providing vehicles for recurring competition among the members of the polis.\nOlympia soon became an important religious place, where a series of athletic contests were held. Modern research focuses on understanding the origins of this great religious celebration that became the symbol of political and cultural unity of Greeks in the historical period. Were the Olympics always a big festival, and was Olympia always a sacred place? Why did the games develop as a Panhellenic institution at this particular part of the western Peloponnese, and how did this institution change throughout the course of the years? Ancient Greeks and later writers describe their myths for the origins of the first games at Olympia, whereas archaeologists spend great efforts in reconstructing the history of the festival through finds in excavations.\nDespite the considerable amount of academic work devoted to the investigation of the above issues, the modern reader would be surprised by the number of different opinions, rooted often in the contradictory nature of the available archaeological and literary evidence. The following text, a full index of athletism and its origins, is dedicated to the anonymous reader who wants to explore further the origins of athletism and understand its various meanings in different times.\nHomeric Age | Athletism & Polis | Why Olympia?\nNote: Click on the images to see a brief description.","Although sporting world records continue to be set, the improvements are getting smaller, suggesting that human athletic performance is reaching its limit. As athletes move ever closer to this performance ceiling, the search for ways of identifying and developing future champions grows increasingly frenetic, and debate returns, inevitably, to the perennial question of whether winners are born or made.\nDo winners possess innate traits from birth, gifted to them through their genes, or is the development of talent more important in success? Opinion is polarised: in one camp, those preaching the necessity of \"superhuman\" performance genes; in the other, those who believe nurturing is the key to excellence. Somewhere along this continuum, perhaps, are the unique circumstances that create champions.\nElite performance represents a complex bio-social interaction across a spectrum of influences. Since the mapping of the human genome, and the development of technologies to sequence individual genes, the search for factors underpinning athletic performance has focused on nature (genetic inheritance) as the principal determinant. There is little doubt that the genes we are born with are a crucial piece in the performance jigsaw. Certain genetically inherited traits are directly linked to strong performance in a particular sport, such as height in high jumping. However, the influence of these genetic factors is often simply responsible for the choice of sport or event that an individual selects – a choice that elite athletes make at an early age.\nBeyond this point – where we start to examine the direct influence of genes on performance – is where the controversy starts. Recent studies have highlighted an \"association\" between the presence of certain gene variants and high-quality performance in large numbers of athletes. But the results are not conclusive: many elite athletes without the identified gene still manage to become world leading; and, conversely, many people carrying the \"performance gene\" have no obvious athletic ability.\nA complex question\nGiven the huge number of variables that affect athletic performance, it's not surprising that a performance gene – a single gene sequence possessed exclusively by elite athletes – does not exist. Countless studies seeking to find such a gene have, between them, identified more than 300 genes associated with performance. But this does not rule out the importance of inheritance from the performance equation, it merely articulates the complex interaction of genes and their products in determining athletic prowess. Genes have also been linked to other critical elements in determining success, suggesting, for example, a link between genes and injury. Similarly, an athlete's response to training appears to be influenced by their genes – explaining, in part, why some athletes progress up the rankings faster than others, despite an identical training environment.\nDespite the certain influence of genes on performance, their importance is often overstated. One irrefutable fact exists within the nature versus nurture debate: training is a critical element of the nurture algorithm, a key plank in the optimising of physical, psychological and technical performance. But training is not everything. A complex bio-social interaction exists including factors such as family, coaching, facilities, wealth, sports structure, sports science and medicine. These factors are far more potent in the development of elite performers than training or DNA polymorphisms alone.\nThe pro-nature riposte tends to draw upon a particular nation's dominance in certain athletic events, such as East African runners' dominance in middle- and long-distance running or Jamaican athletes' dominance in sprinting. But this is a flawed argument. On closer examination, it's clear certain nations were not born excelling, but, rather, have been developed by their environment. Do we really believe British middle-distance runners' dominance in the 1980s – with the likes of Coe, Ovett, Cram, Elliot and McKean – was due to a spate of spontaneous genetic mutations that were neither present before nor since? And have East African women suddenly begun to bear genetically modified children predisposed to endurance running? Of course not. This excellence is the result of a complex interaction of bio-social events.\nThe simplistic approach of scientists to base their pro-nature argument on relationships between genes and athletic performance fails woefully in its demonstration of cause and effect. Furthermore, if it were simply about genetic inheritance, we would not expect to observe the direct correlation between investment and performance that characterises the Olympic/Paralympic medal tables. Investment in sport has its greatest impact on environment and does not alter individuals' genes. The professionalisation of sport through funding has provided a platform for full-time training. Furthermore, comprehensive systems of support now exist in sport to cater for everything from diet to technology. No stone is left unturned in the pursuit of excellence. These are the fruits of nurture.\nIn everyday life\nAlthough the nature versus nurture debate is invariably targeted at elite sport, it resonates through many spheres of life. Think of things you may consider yourself to have been born with – intelligence, musicianship, the ability to draw, or business acumen – and then consider whether nurture hasn't played a part in how those attributes flourished (or otherwise). The debate can also be applied to inanimate objects. Does a new idea or concept get born at a single moment in time or does it evolve from earlier iterations, combined with industrious development and support? The concept of a motorised vehicle to transport people, for example, may have been born, but it has taken decades of nurturing across multiple industries to deliver the Formula 1 car of today. Certainly, both nature and nurture are critical to that highly specialised car's continued success.\nOur genes may be instrumental in determining elite performance, but evolution is not simply the product of spontaneous mutations in the DNA helix. The environment plays a key role in evolution, not merely as a test bed for survival of the fittest, but also in directly affecting the way genes evolve through interaction with their environment.\nNature may provide us with the initial foundations, but it is the quality of the nurturing that generates the potential to stretch the limits of human performance. So, it would appear winners are born, then made!\nGreg Whyte shares five of the most memorable human achievements he has witnessed\nDavid Walliams swimming the channel\n\"A non-swimmer completing this blue ribbon event proves that anything is possible.\"\nMeeting \"Current Mohan\" aka \"Electric Man\" in Kerala, India\n\"No one can explain how he conducts electricity through his body.\"\nCoaching James Woods, a paraplegic, to swim the channel\n\"James's achievement was all about the human spirit.\"\nWatching Michael Johnson break the 200m world record at the Olympic Games in Atlanta, 1996\n\"The atmosphere in the stadium was unbelievable.\"\nMeeting a colon cancer patient given weeks to live – and working with him for the next two years\n\"He wanted to engage with his kids; thanks to a programme of intervention and his determination, he enjoyed two physically active years with them.\"\nProfessor Greg Whyte\nA leading authority on exercise physiology, sports performance and rehabilitation, former Olympic modern pentathlete Professor Greg Whyte is committed to helping people \"achieve what they, and others, think is unachievable\". He says he uses many of the same strategies to train sportspeople, cancer patients and celebrities: \"It's all about preparing the body and mind. Today there's real synergy between sports coaching and science. We can see exactly what our bodies need to go through to meet our physical targets."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:047c61c8-15f6-4467-97db-0768bc2fb7cb>","<urn:uuid:166f5a02-5677-4389-a22d-609123370a32>"],"error":null}
{"question":"What specific actions are African governments advised to take to improve their agricultural research systems?","answer":"African governments are advised to take three main actions: 1) Increase overall public disbursements to agriculture and raise the share going to NARES organizations, 2) Incentivize private sector collaboration with African NARES by providing favorable policy environment and effective accountability frameworks, and 3) Ensure that approved budget lines to NARES organizations are fully disbursed each year.","context":["By Thomas S. Jayne, Shamie Zingore, Amadou Ibra Niang, Cheryl Palm, and Pedro Sanchez\nKey findings are summarized from a study detailing how international donors and research organizations can more effectively strengthen the capacities of African national agricultural research and extension systems (NARES). International efforts are 0more successful in building the capacities of individuals than in strengthening the NARES institutions. Successful implementation of the Africa Fertilizer and Soil Health Summit and similar initiatives will require stronger national, regional and continental agricultural research systems that can lead and drive these initiatives. The authors identify actions required to strengthen these African systems and effectively implement African-led agricultural initiatives.\nSustainable soil health and fertilizer use in Africa – as well as many other important goals of Africa’s governments and people – depend on building dedicated local scientific expertise to support its agricultural sectors. The challenge is essentially how to build the research, development, and extension (R&D&E) capacity to generate a continuous stream of productivity- and resilience-enhancing technical innovation that can be scaled-out to millions of farm households facing highly varied agro-ecologies and resource constraints.\nNational capacity boils down to the skills of its people and the performance of its institutions. While there are many national institutions responsible for generating sustainable farm technical innovation, the national agricultural research and extension systems (NARES) are the centerpiece. Without strong NARES, African countries cannot provide technical guidance to their farmers and therefore become dependent on international agricultural research systems (IARS) for achieving national goals related to fertilizer and soil health sustainability. IARS are crucial allies for supporting African agriculture, but they are generally not well-suited to scale-out technical innovations on their own, nor do they have the resources to do so, hence strong NARES on the ground are required to adapt technologies and policies in collaboration with millions of African farmers. Countries that were once relatively poor, but which were able to build strong NARES (e.g., Brazil and many Asian countries), generally achieved impressive agricultural productivity growth, broader agri-food systems development, and rapid increases in living standards (Fuglie et al., 2020; Goyal and Nash, 2016; Pardey et al., 2016).\nTable 1 presents the levels and trends in agricultural R&D expenditures over time for sub-Saharan Africa (SSA) and other developing regions. Trends are reported for R&D expenditures in relation to agricultural gross domestic product (GDP), hectares of cropland, and the number of agricultural laborers in the country. For all the metrics, funding for agricultural R&D in SSA has been lower than in other regions for many decades. This is consistent with Goyal and Nash (2019), Fuglie et al. (2020), and Stads et al. (2021).\nThe slow rate of crop yield growth in Africa over the past four decades attests to the need to better understand the actions that African governments and development partners can take to enable their NARES to perform better and contribute to the achievement of resilient, inclusive, and productive agri-food systems. This article takes the premise that strong NARES are at the heart of Africa’s efforts to achieve sustainable agricultural systems, which include soil health and much greater and more efficient use of fertilizers.\nThis article also addresses how African countries can build the capacity of their NARES to achieve these goals, summarizing key findings and conclusions from a forthcoming study on African NARES (Jayne et al., 2023). The objectives of the report were to pinpoint the reasons for the slow development of African NARES and highlight actions that African governments can take to build the capacity and performance of their NARES.\nWhat exactly are NARES and what do they do that leads to improved soil health and agricultural productivity?\nNARES are the system of national institutions that generate and adapt farm technical innovation to be taken up by millions of African farmers. They include the national agricultural research institutions that undertake crop and animal science research, and the national extension systems that work with farmers to adapt and adopt new technologies and practices that lead to improved yields, resilience, and sustainable agricultural intensification. They also include national agricultural universities that ideally create a steady stream of trained professionals to take up positions in the NARES and in the private sector to achieve bi-directional learning between farmers and scientists in support of more resilient, sustainable, and inclusive agricultural performance. NARES include the national policy analysis institutes that guide African governments in identifying broader systemic change necessary to promote sustainable, inclusive, and resilient agricultural growth. Currently, few African NARES conform to this idealized definition. The challenge is how to enhance the effectiveness of NARES.\nFour main findings can be highlighted from the study.\nFirst, building strong NARES will require a regional approach at first for many countries. Today, only a few African countries have viable NARES; at least 25 African countries have historically devoted a small fraction of their limited public expenditure to agriculture and their NARES. As a result, they lack a viable national agricultural R&D program or university system required to develop the in-country professionals needed for effective operation of a NARES. Hence delivering soil heath and fertilizer sustainability to farmers in many African countries will require starting with a regional approach. Stads et al. (2021) propose organizing agricultural R&D investment by agro-ecological zones rather than political boundaries, at least for relatively small African countries. Integration of agricultural R&D at the subregional and regional level, through joint research programs and regional centers of excellence, may be the most effective way to allow countries with lagging agricultural research systems to benefit from the gains made in countries with similar agro-ecological conditions that have more advanced systems. Better coordination and a clear articulation of mandates and responsibilities among national, subregional, regional, and global R&D players are essential to ensuring that scarce financial, human, and infrastructure resources are optimized, duplications minimized, and synergies and complementarities enhanced. This is not just a policy consideration for African governments but for continental and regional African development organizations as well.\nBetter coordination and a clear articulation of mandates and responsibilities among national, subregional, regional, and global R&D players are essential to ensuring that scarce financial, human, and infrastructure resources are optimized, duplications minimized, and synergies and complementarities enhanced.\nSecond, sustained commitment and funding from African governments is a precondition for building strong NARES and regional and continental agricultural R&D&E systems. Through their Maputo Declaration commitments,\nAfrican leaders recognize that agriculture is a critical engine for economic development, job creation, and poverty reduction. Yet by most metrics, SSA governments spend very little on agricultural R&D (Stads et al., 2021). African leaders must become convinced that greater commitment to their NARES organizations will help them achieve many of their most valued national policy objectives. Sustained political commitment could be galvanized by respected champions of African agriculture who compellingly demonstrate to political leaders how the performance of their NARES affects, in various direct and indirect ways, many of their most cherished policy goals. Leaders would then need to be guided regarding what greater commitment means in practice: sustained funding at greater levels, serious performance monitoring, and accountability. The national and international research community may also do more to demonstrate to African leaders how and why most of their national policy goals, including sustainable soil heath and fertilizer use, depend on improving the capabilities of African tertiary education systems to generate a continuous stream of well-trained agricultural scientists needed to sustainably operate African NARES. Effective NARES require skilled people.\nThird, international donors and research organizations can and must do more to build the capacity of African NARES and regional R&D organizations. A serious stocktaking by international partners, including donors, the CGIAR, and international universities, is warranted to develop a greater appreciation of how their own effectiveness (i.e., impact generated per dollar of donor funds allocated to international research systems) depends on the performance of NARES, and that, by extension, efforts to build the capacities of these partners should be prioritized more seriously. The fact that much improved genetic materials developed by international research fail to be commercially distributed and adopted by farmers demonstrates how impact of the CGIAR and other international partners is constrained by severe weaknesses and challenges faced by NARES. System performance is constrained by its weakest link in the system. Support for building strong NARES needs to be pursued with much greater commitment by international donor organizations; impacts from their own grants and projects in fact depends upon it.\nDonor commitment to supporting African agriculture requires direct engagement with the NARES. After the African governments, international and African funding organizations hold the key to strengthening African R&D&E systems by the grants that they make. We encourage donors to consider ensuring that grants related to African agricultural technical innovation require including organizations in the NARES at the design stage, supporting nationally led priority setting agendas, and ensuring that NARES interests and priorities are reflected in proposal and budget development. Grants with co-directors from NARES organizations would enable these organizations to feel greater ownership and commitment to achieving the objectives of the grant. Donor and development bank funding should be consistent with priorities set by national stakeholder processes, which can draw upon the expertise of international, African continental, and regional partners.\nIn many cases, these proposals for consideration may entail (a) putting host-country institutions in the lead, supported by international expertise; (b) the priority agenda being defined by national governments to build local ownership; and (c) taking a systems approach to NARES development, which requires socio-economic/policy analysis units to be integrated into the NARES.\nFourth, confront the issue of “work-arounds”: Some donor organizations are reluctant to directly partner with public sector entities and often create parallel structures to the NARES that carry out activities that duplicate the mandates of the NARES. While donors may ensure greater accountability for their funding by creating their own partners working on the ground, the long-term impacts are unclear, as they may weaken or marginalize organizations in the NARES that African governments rely upon to carry out the public goods role of agricultural R&D&E in their countries. Resentment, lack of cooperation, missed opportunities, and limited long-term impact are common outcomes when donors create and fund new organizations to carry out tasks that overlap with the mandate of existing national entities. n\nSummary: Who needs to do what?\nActions by African governments\nThe most crucial step to improving the performance of NARES is for national governments to increase their funding and commitment to supporting their own NARES, to monitoring performance, and to demand greater accountability for results.\n• Increase overall public disbursements to agriculture and raise the share of public agricultural expenditures going to organizations in the NARES. Rather than relying too much on donor contributions and development bank loans to fund critical areas of research, governments need to determine their own long-term national priorities and design relevant, focused, and coherent agricultural R&D&E programs accordingly.\n• Incentivize the private sector to collaborate more with African NARES. Governments’ calls for the private sector to step up and support African farmers often fall on deaf ears unless governments provide the necessary incentives. Many private agribusiness firms are already heavily involved in supporting farm technical innovation in Africa, including soil health and fertilizer use. But African governments could leverage much greater support from the private sector by making it attractive for the private sector to invest in, and collaborate with, African NARES, by providing a favorable policy and enabling environment, effective accountability frameworks, and by stepping up to support their own NARES.\n• Ensure that budget lines to organizations in the NARES are fully disbursed each year. Stads et al. (2021) found that in many cases, governments did not fully disburse approved budgets to their NARES.\nActions by African university leadership\n• Prioritize improving post-graduate training in faculties of agriculture, including sandwich programs at qualified universities. The University of Pretoria Collaborative Masters in Agricultural Economics and Extension provides a useful model for consideration. This program allowed MSc students to take courses both at their home university and at the University of Pretoria for a year, where international faculty and UP faculty taught and mentored them, guided their thesis work, and supported their efforts to be placed in suitable organizations on the African continent after graduation. External reviews considered the program highly effective in raising the supply of well-trained MSc agricultural economists and could be considered to build African capacity in other agricultural disciplines.\n• The senior management of many African universities tend to regard their resources and budget limits as being exogenously determined by budget allocations from their central governments. But African universities could potentially expand their budgets by proactively competing for international donor resources. They could form partnerships with CGIAR organizations, international universities, and/or relevant organizations in the global south to prepare proposals for funding new activities or expanding the funding for existing activities.\nActions by international donors and research systems\n• Encourage donor grants targeted to CGIAR or international universities to include organizations in the NARES at the design stage, ensuring that NARES interests and priorities are reflected in proposal and budget development. Donors could do more to ensure that their grants are co-led by organizations in the CGIAR and the NARES, starting from project design, so that NARES or regional R&D&E systems are brought in from the beginning.\n• Explore opportunities to leverage the formidable R&D&E systems of the private sector. The private sector is currently the least developed source of sustainable financing for agricultural R&D&E in Africa.\n• Donor and development bank grants in support of sustainable fertilizer use and soil health should be consistent with priorities set by national governments.\n• Donors that can afford to take a long-term time horizon for impact, should see the necessity of long-term support to the NARES, extension, and agricultural universities with long-term commitments, moving away from grants that focus on low-hanging fruit with short-term impact.\nDr. Jayne (e-mail: email@example.com) is University Foundation Professor Emeritus, Michigan State University, East Lansing, USA. Dr. Zingore is APNI Director of Research & Development, Benguérir, Morocco. Dr. Ibra Niang is CEO, Afrik Innovations, Dakar, Senegal. Dr. Palm is Professor, University of Florida, Gainesville, USA. Dr. Sanchez is Professor Emeritus, University of Florida, Gainesville.\nCite this article\nJayne, T.S., Zingore, S.Z., Ibra Niang, A. Palm, C., Sanchez, P. 2023. Building Research, Development, and Extension Capacity for Sustainable Fertilizer Use and Soil Health in Africa, Growing Africa 2(1), 10-14. https://doi.org/10.55693/ga21.BELW4471\nFuglie, K., et al. 2020. Harvesting Prosperity: Technology and Productivity Growth in Agriculture, Washington, D.C., World Bank.\nGoyal, A., Nash, J. 2016. Reaping Richer Returns, Preliminary Overview: Public spending priorities for African agriculture productivity growth. Washington, DC: World Bank. © World Bank. https://openknowledge.worldbank.org/handle/10986/25782\nJayne, T.S., et al. 2023. (forthcoming). Building 21st Century National Agricultural Research and Extension Systems in Africa. Report. The Breakthrough Institute, San Francisco.\nPardey, P., et al. 2016. Returns to food and agricultural R&D investments in Sub-Saharan Africa, 1975–2014. Food Policy, 65 (Dec.), 1-8.\nStads, G.-J., Nin-Pratt, A., Beintema, N. 2021. Boosting Investment in Agriculture research in Africa: Building a case for increased investment in agricultural research in Africa. Report prepared for the African Union Fourth Ordinary Session of the Specialized Technical Committee on Agriculture, Rural Development, Water, and Environment to be held during 13–15 Dec. 2021. Africa Science and Technology Indicators (ASTI)."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:42f82ad1-8ebc-43bf-9415-ae587d1cf235>"],"error":null}
{"question":"¿Cómo se comparan las estrategias de almacenamiento entre Apple y las empresas farmacéuticas? ¡Me interesa saber! 📦","answer":"Apple and pharmaceutical companies employ distinct storage strategies. Apple maintains centralized warehouses in specific locations like Elk Grove, California, and international distribution centers in countries like China, Czech Republic, Japan, Singapore, and the UK, using the FIFO method to ensure older models are sold before new ones. Pharmaceutical companies, on the other hand, traditionally invest in large regional manufacturing facilities with extended storage capabilities to meet product lifecycles. However, pharmaceutical companies are now exploring partnerships with local manufacturers who have underutilized capacity, particularly for complex specialty products like biologics, to avoid navigating complex local tax and investment regulations while maintaining adequate storage and distribution capabilities.","context":["OR WAIT null SECS\nCustomer-focused supply-chain capabilities are becoming a more important part of a company's competitive advantage.\nAdmit it. When most pharmaceutical executives think about the pharmaceutical supply chain, their eyes start to glaze over. Traditionally, the supply chain has been considered, at best, a back-room function that reports in to operations and is responsible for delivering a reliable supply of product to meet forecasted demand.\nIn fact, the supply chain is a deep and widely underutilized strategic resource for companies seeking to focus their organizations on the changing healthcare environment. New customers with different needs are emerging in every sector of the healthcare market—from tech-savvy consumers that expect instant informational gratification, to newly integrated healthcare delivery systems with access to vast stores of information about how and by whom pharmaceutical products are being used. And pharmaceutical supply-chain executives are seeking new ways to understand the central question of how they can deliver greater value to their organization by helping to improve the customer experience.\nTraditionally, pharmaceutical supply-chain management has been defined as managing the network of suppliers, resources, and manufacturing capabilities that are needed to supply product demand or sales targets. This role is, by nature, somewhat static and reactive rather than proactive, and its ability to be responsive is further limited by the highly regulated nature of the pharmaceutical industry. In general, pharmaceutical supply-chain capabilities lag behind those of the technology and consumer packaged goods (CPG) sectors. In the technology sector, for example, Dell has built a global reputation for its ability to deliver custom-configured products of high quality and reliability, and has built a nimble and flexible supply chain that lets them consistently meet their customer needs and wants. Consider what it would take for a pharmaceutical company to deliver custom-configured products to its millions of customers worldwide. Yet this type of customer need is becoming increasingly possible as science continues to unveil the possibilities of personalized medicine and individualized therapies.\nAlthough the challenges of personalized medicine are likely a few years out, there are ways in which the pharmaceutical supply chain can be more effectively engaged to address current customer unmet needs. Customers in emerging countries, for example, may have substantially different wants and preferences in terms of pharmaceutical product taste, texture, package size, unit dosing, or services. All of these aspects of the product can be addressed through the supply chain, and could have a large impact on local acceptance and usage.\nDecisions about how to build or engage local manufacturing are another area where strategic supply-chain decision-making can come into play. Traditionally, many pharmaceutical companies have invested in regional manufacturing, building large facilities to meet demand during products' extended lifecycles. Today, however, companies are exploring partnerships with local manufacturers that have underutilized capacity, and are teaching these local resources the skills needed to manufacture and distribute more complex specialty products, such as biologics or other large molecules. Such arrangements may save capital, but perhaps more importantly, prevent the company from having to navigate complex local tax and investment regulations.\nToday's healthcare customer is more complex than ever before. The new healthcare ecosystem encompasses payers and healthcare organizations as well as their preferred service providers, physicians, and a large number and variety of other healthcare providers that interact with patients, either directly or indirectly, during the course of a healthcare transaction. Creating a customer-centric pharmaceutical supply chain requires that information about customer needs, wants, and even desires be communicated throughout the organization. Executives responsible for supply-chain management should have opportunities to engage one-on-one with their customers in the locations where products actually are stored or used. For example, a recent conversation with an infusion nurse uncovered that the packaging for an IV product was stiff and hard to handle, and that nurses were getting paper-cuts. The supply-chain team collaborated with marketing and key customers to change the packaging to recycled paperboard and to improve ease of opening for nurses—a simple, low-cost modification that made the product more customer-oriented and eco-friendly.\nThe key to successfully harnessing pharmaceutical supply-chain innovation is a re-imagining of how product and supply-chain attributes can become customer value levers (Figure 1). This 360-degree view of value drivers that can be impacted by the supply chain illustrates the various supply-chain touch-points that can make an enormous difference in addressing customer needs.\nFigure 1: Customer value levers.\nConsider the following scenarios:\n» The manufacturer of an oral solution for treatment of infections in immuno-compromised patients received customer feedback that the product was extremely irritating for patients with oral mucositis, a frequent complication of some cancer therapies. This information led to reformulation of the product into two additional formulations that will address the needs of the full complement of patient types.\n» Responding to requests from a large national managed care organization (MCO) for ways to increase member adherence with chronic-care medications, a manufacturer challenges its supply-chain management team to devise low-cost adherence packaging solutions for several of its best-selling chronic medications. The plan is to test packaging alternatives within the MCO's current population to determine which approach delivers the desired outcomes.\n» A supply-chain manager visiting rural pharmacies in an emerging Latin American market learns that access to refrigeration is not commonplace, leading to a re-assessment of the formulation for a new pediatric product.\nThe key to creating a customer-focused supply chain is providing supply-chain managers direct access to customers and integrating key customer information in operations. For example, the supply-chain team could \"follow the product\" from the time it leaves the company until it reaches and is administered to a patient. Experiencing every aspect of the product flow and customer experience provides significant insights to unmet customer needs. This learning experience should be a part of a multi-layer approach to learning about customers, including the extensive prelaunch research with prescribers and end-users that is done in partnership with commercial teams, or the wealth of customer qualitative or focus-group research that is done to support product configuration and distribution channels.\nOnce supply-chain management is engaged in and focused on identification and resolution of customer needs and desires, their focus will shift to the identification of supply-chain solutions: how to design, plan for, source, produce, and deliver and service the product that satisfies customer needs and desires (Figure 2). By shifting the focus from internal customers, including R&D or commercial operations, to the larger customer ecosystem, pharmaceutical supply-chain management can become a dynamic contributor to 21st century healthcare delivery.\nFigure 2: The customer-focused approach to identifying supply chain solutions.\nStrategic management of the supply chain is vital to winning with customers. Cost and quality are important, but they are not the only things customers care about: new services, flexibility in relationships, reliability of supply, and ability to creatively overcome obstacles in delivery of product are also core values. Pharmaceutical product portfolios and customers are becoming more complex. In order to stay ahead of this trend, customer-focused supply-chain capabilities will become a more important part of a company's competitive advantage.\nTom Reynolds is Director, Global Strategy, Janssen Supply Chain, and has comprehensive commercial, business development, and operations global experience across pharmaceutical, medical device, biotechnology, and consumer healthcare segments at leading Johnson & Johnson companies. He can be reached at email@example.com.","What inventory system does Apple use? Inventory Management.\nThe company also uses the first in, first out (FIFO) method, which ensures that most old-model units are sold before new Apple product models are released to the market. Apple Store managers also handle the inventory management of their respective stores.\nWhat kind of inventory system does Apple use? The inventory record keeping method used by the company (FIFO / LIFO).\nHow does Apple handle their inventory? After the launch, the company makes the demand forecast for the next 150 days. Quarterly reviews. During the quarterly reviews, the company checks the inventory levels, analyzes the product life-cycles, adjusts the demand forecasts and monitors the current sales levels and costs trends.\nDoes Apple have inventory? Apple annual inventory peaked in 2017, with a value of $4.8 billion. In 2018, the company saw a 18.52% decline year-over-year but they bounced back quickly and they had $3.8 billion in inventory in 2019, a 3.79% increase vs. 2018.\nWhat inventory system does Apple use? – Related Questions\nIs Apple Inc managing their inventories well?\nApple is the current market leader in the way it manages its inventory. Two indicators of apple’s dominance are inventory turnover and days in inventory.\nIs Apple LIFO or FIFO?\nDoes Apple use LIFO or FIFO? AAPL: Apple Inc. The inventory record keeping method used by the company (FIFO / LIFO). Apple’s operated at median inventory method of 0.005 thousand from fiscal years ending September 2015 to 2019.\nWhy does Apple use FIFO?\nIn this decision area of operations management, Apple Inc. The company also uses the first in, first out (FIFO) method, which ensures that most old-model units are sold before new Apple product models are released to the market. Apple Store managers also handle the inventory management of their respective stores.\nIs Apple supply chain really the No 1?\nEverything about Apple Inc is the talk of the town, for example, the new iPad, iPhone 5, Apple Map or even environmental and labor issues at its suppliers’ facilities. Surprisingly, IT research firm Gartner ranks Apple Supply Chain as the best supply chain in the world for 3 years in a row.\nIs Apple having supply issues?\nApple Warns Of Product Shortage Due To Supply Chain Issue : NPR. Apple Warns Of Product Shortage Due To Supply Chain Issue Apple says it can’t make enough MacBooks and iPads to meet demand over the next few months because there aren’t enough semiconductor computer chips for all the manufacturers who rely on them.\nWhy is Apple’s supply chain so good?\nApple has a number of exclusive long-term agreements with its key suppliers and uses prepayments to negotiate favourable pricing terms, secure strategic raw materials and guarantee high volumes of production. Apple has also diversified its supply chain to include new manufacturing partners in China and Taiwan.\nIs Apple’s supply chain sustainable?\nWith a strong supplier code of conduct, the company holds both itself and its suppliers to the highest standards, protecting not only the planet and the environment, but every single member at every point of the supply chain.\nHow does Walmart manage their inventory?\nIn inventory management, Walmart uses a system that allows suppliers to access data on the inventory levels of their products. This system supports the company’s vendor-managed inventory model, which helps minimize operating costs and enables the business to offer low selling prices.\nWhere are Apple products stored?\nWhen all iPhones are completed in assembling process and packaged, they will wait to be shipped to the US Apple warehouse, located in Elk Grove, California, and some other distribution centers located around the world, including China, the Czech Republic, Japan, Singapore and the U.K.\nWho is the boss of Apple now?\nApple chief executive Tim Cook has received more than five million shares in the technology giant, as he marks ten years in the job.\nWhat is Apple’s operations strategy?\nThe core elements of its strategy are: Innovative products. Ease of use and sleek design giving an aesthetic appeal. Superior experience by bundling networking and graphics, in-store experience. Marketing effort to guide customer behavior.\nWhy did Apple choose to carry inventory at its stores?\nApple decided to carry inventory to their stores so that they are able to fulfill the demand of the customer according to their needs.\nDoes Amazon use LIFO or FIFO?\nAmazon Uses the FIFO Method to Determine Storage Fees\nIt uses the First In, First Out (FIFO) method.\nWhat depreciation method does Apple use for property plant & equipment?\nAs long as straight-line depreciation is used, this is an accurate estimate of asset age as a percentage of depreciable life.\nHow does Apple measure employee performance?\nApple measure’s it’s employee performance in to 3 categories: Teamwork, innovation and results. There are 3 levels of performance: Needs improvement, Met expectations, Exceeded expectations.\nHow does Apple use strategic planning?\nApple’s generic strategy of broad differentiation adds competitive advantage by making the business stand out. Differentiation in product function and design supports the firm’s goal of leading the market through technological innovation.\nHow does Apple manage quality?\nApple Inc. uses the system of Total Quality Management (TQM) to keep the employees satisfied and motivated. The company uses four basic tools of TQM as – Control chart, Pareto chart, cause and effect diagram, and Histogram. TQM enables the company to bring all the stakeholders together.\nHow can Apple supply chain be improved?\nApple can also improve its supply chain network by adding digital technologies such as incorporating IOT and big data analytics to manage the big data and get new insights and run the business effectively.\nIs Apple ethically responsible?\nApple believes all workers in our supply chain deserve a fair and ethical workplace. Workers must be treated with the utmost dignity and respect, and Apple suppliers shall uphold the highest standards of human rights. Supplier shall commit to a workplace free of harassment and abuse.\nWhy is there a shortage of iPhones?\nWhile it’s fighting over the same limited supply of parts as many of its competitors, Apple also said that some of its struggles are self-inflicted. Apple executives said it has also faced shortages as a result of stronger than forecast demand for its hardware.\nWhat is Apple’s carbon footprint?\nMost of the electronics company’s emissions fall under scope 3 – indirect emissions occurring across the value chain. Apple’s carbon emissions fell to 22.6 million metric tons that same year."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:d06a21f5-3128-4e5c-9b30-9dadc31fce68>","<urn:uuid:0cbf8336-cc66-49d7-93dd-72ebb63708cd>"],"error":null}
{"question":"Como estudiante de arte, me gustaría saber si el estudio del color en marketing y diseño tiene alguna relación con el uso del color en el desarrollo de videojuegos? 🎨","answer":"Yes, there are significant connections between color studies in marketing/design and game development. In marketing and design, the focus is on understanding the diverse dimensions of color derived from physical and emotional aspects, and how colors influence humans, often unconsciously. This aligns with game development's visual design principles, which include color theory as a fundamental component. Both fields emphasize the effective use of colors to create impact, though games specifically apply these principles to enhance interactive experiences and user interfaces within the gaming environment.","context":["Information Technology 108\nITEC 108: Introduction to Game Development.\nCredit Hours: (3) Two hours lecture; two hours laboratory\nAn introduction to problem solving and programming in the context of game development. Topics follow the framework laid out by the International Game Developers Association (IDGA) and will touch on each of the core topics: Games and Society, Game Design, Game Programming, Visual Design, Audio Design, Interactive Storytelling, Game Production, and Business of Gaming.\nDetailed Description of Content of Course\n1. Critical Game Studies - Criticism, Analysis & History of electronic and non-electronic games.\n2. Games and Society - Understanding how games reflect and construct individuals and groups, as well as how games reflect and are constructed by individuals and groups.\n3. Game Design - Principles and methodologies behind the rules and play of games.\n4. Game Programming - Aspects of traditional computer science and software engineering – modified to address the technical aspects of gaming.\n5. Visual Design - Designing, creating and analyzing the visual components of games.\n6. Audio Design - Designing and creating sound and sound environments.\n7. Interactive Storytelling - Traditional storytelling and the challenges of interactive narrative.\n8. Game Production - Practical challenges of managing the development of games.\n9. Business of Gaming - Economic, legal and policy aspects of games.\nDetailed Description of Conduct of Course\nConcepts of game development are covered in the lecture portion of the course. These concepts are reinforced by the programs and critiques that the students write. A significant portion of the lab time is spent in the microcomputer lab. This provides the opportunity for close contact between the student and the instructor while the student is designing and implementing games and writing critiques. The lab time may also be used to cover specific design details.\nGoals and Objectives of the Course\nStudents who complete the course will be able to:\n1. Articulate a brief history of video games, covering the evolution of the major genres, platforms, publishers, and developers of the last several decades.\n2. Describe the sociology of games, including audience demographics, societal reactions to sex and violence, and the emergence of online communities.\n3. Explain ludology – the academic study of games – including the issues and individuals central to this rapidly growing field.\n4. Explain the theories, processes, and design considerations that form the foundation of game creation.\n5. Describe the nature of fun, including ideas such as game structure, game flow, and the role of choice in generating an entertaining interactive experience.\n6. Discuss the specifics of actually designing a game, from high-level conceptualization and design documentation, to specific topics such as interface design, play mechanics, platform modifications, and performance testing.\n7. Explain programming teams and processes, and common game programming languages.\n8. Explain fundamental concepts in computer programming including variables, looping, and branching.\n9. Describe how to debug games and explore their use of system resources.\n10. Articulate the basics of math and physics used in game development – geometry, applied trigonometry, vectors and matrices, transformations, general physical concepts, real-time game physics, rigid body simulations, and particle systems.\n11. Explain general visual design principles, such as graphic design, color theory, and user interfaces.\n12. Describe the “real-world” aspects of the game industry, including the domains of producers, attorneys, and game business professionals.\nCourse will include both individual and group development assignments as well as individual game critique assignments. Multiple exams will also be used to assess student progress.\nOther Course Information\nReview and Approval\nFebruary 2010 Initial Course Approval Art Carter, Chair\nRevised: June 1, 2012","ART W10 Color Image, Marketing and Design. Colors are everywhere. Humans are surrounded by uncountable numbers of colors and influenced by those colors, often unconsciously. This course is designed to help students understand the diverse dimensions of color that are derived from color’s physical and emotional aspects. This course also investigates the effective use of colors for marketing and design, as well as for works of art. Fee: $150. Y. Ahn. 8:30 a.m. to noon.\nART W40 Artist Book Production . This course will introduce the design, production, and publication of Artist Books, concentrating on the book as an aesthetic object and a medium for content. Physical and conceptual elements of the artist book unfold through time and space. Aesthetic problem solving in bookmaking involves organizing conceptual, visual, physical, kinetic, and chronological transitions. Students will engage in developing content, three-dimensional construction and the integration of image and text. Course problems and solutions will result in the production of visually effective Artist Books. The study of hand made books from illustrated manuscripts to contemporary book art will introduce students to both traditional as well as innovative materials and binding techniques. Students will investigate both high and low technologies of reproducing imagery for the purpose of execution and publication. Bookmaking will occur both individually and collaboratively. The class will produce several limited edition publications. The majority of class time is spent in studio activity generating a minimum of eight artist books. Teaching methodology includes illustrated lectures, demonstrating materials and techniques, readings, critiques and field trips. An exhibition of works completed is anticipated. This course may fulfill an advance studio art course for Studio Art, BFA, & Art Education majors. This course may fulfill an elective for Art & Art History minors. Prerequisite: Arts 250 or permission of the instructor. Fee: $175. A. Greidanus. 10:30 a.m. to noon and 2:00 p.m. to 5:00 p.m.\nART W41 Art and Fashion. Art and Fashion explores the points of overlap between the history of art and the history of fashion from the Renaissance to the present. Class readings and discussions will be centered around five major themes: the mediation of the body, gender representations, style, the history of taste, and performance. This course may fulfill an elective for the Art History program. C. Hanson. 2:00 p.m. to 5:00 p.m.\nART W42 African American Art. This course surveys the history of African American art. While this history is too broad and rich to be treated conclusively during Interim, we will cover four main historical periods: Slavery/Reconstruction; The Harlem Renaissance; the Evolution of a Modern Black Aesthetic in the 1960s and 70s; and Contemporary Concerns. Beginning with the arrival of Africans in the Americas through the trans-Atlantic Slave Trade and continuing to the present, we will examine the intersection of folk and fine art traditions, continuities from Africa, appropriations of new materials, techniques, and forms, and the influence of events and movements like the Great Migration, the Civil Rights movement, and Pan-African Independence. Above all the course engages the role of the visual arts in constructing a vital, although by no means homogenous, cultural and politically resistant, voice and identity. This course may fulfill an elective in the Art History major. Fee: $20. E. Van Arragon. 8:30 a.m. to noon.\nART W60 Photography in New York . As an international center for contemporary art, New York City offers a unique educational opportunity to study visual art. Through discussions and visits with contemporary photographers, museum curators, collectors, and critics, students will learn about the production, display, collection, and promotion of contemporary photography. This course will focus on photography as an art commodity in contemporary culture. For ten days, students will visit various photography professionals. The class will visit the studios of working photographers in the city and have the privilege of touring facilities and observing work in progress. Talks with photography critics such as A. D. Coleman and museum curators at the International Center for Photography and the Museum of Modern Art will complement the photographer studio visits. Meetings will also be arranged with galleries specializing in photography and photography collectors. Students will be required to read selected writings from curators and critics and keep a journal of their experiences. Students will also study photographers who have focused on New York as their subject matter. New York City has inspired and fascinated many artists, and students will have ample opportunity to explore, discover and study this great American city. In addition to providing a tour of the city, students will tour historical and contemporary New York via the wonderful collection of photographic imagery from various photographers at the Museum of the City of New York. In response to their New York experience, students will produce a body of photographic images. The instructor will provide individual critiques of both artwork and journal. Prerequisite: ARTS 256 or permission of the instructor. Course dates: January 7-27. Fee: $2441. J. Steensma Hoag. Off campus.\nART W61 Problems & Solutions. The task of all creative visual communications is to interpret problems in a personal way while meeting the needs of other people. Using Adobe Illustrator's vector graphics in the classroom, innovative problems that dictate challenging solutions help students achieve this goal. Problems & Solutions consists of original visual communication problems which emphasize developing a conceptual approach to problem solving. The problems in this course encourage students to carefully examine the transition from conceptualization to execution. Emphasis will be on concept rather than on software dexterity with the intent of developing genuine interest in one’s craft. These problems also encourage students to believe in their ability to successfully communicate with images in a rapidly changing technological context. Problems represent opportunities that allow for growth. Solutions represent an interpretation of a problem from an individual point of view at a particular stage of one’s development. Focus will be on the integration of online resources, framal reference, positive/negative relationships and cropping techniques in order to engender innovative visual communication skills. Prerequisite: ENGL 101. F. Speyers. 8:30 a.m. to noon."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:56f5f24b-4be7-4ec9-812f-b5f25458a148>","<urn:uuid:bf82918e-b5ce-4ac2-86ef-74f6b3114f7e>"],"error":null}
{"question":"What was the outcome of the 1964 meeting between Robert F. Kennedy and James Baldwin?","answer":"The private meeting between Attorney General Robert F. Kennedy and James Baldwin in New York on May 23, 1964, ended without reaching any progressive conclusion. Though the meeting itself was unsuccessful and left both sides angry, it contributed to President Kennedy's Civil Rights Address and ultimately the Civil Rights Act of 1964, which ended segregation in public spaces and made discrimination illegal.","context":["It was 1983 and blues musician Daryl Davis was performing at a bar in Maryland. This wasn’t just any bar, it was a “whites only” bar and if you’re unfamiliar with Mr. Davis, he’s a black man. But by the end of the night, Davis had formed an unlikely friendship with one specific audience member—a Klansmen.\nThe Klansman had told Daryl he’d never heard a black man play the piano as good as Jerry Lee Lewis. Davis replied, “Who do you think taught Jerry Lee Lewis to play that way?” In any other case with a different black musician, the exchange might’ve been more abrasive and confrontational but Daryl chose the contrarian approach.\nAfter a night of conversation, the Klansmen would hand Daryl contact info for one of the Grand Dragons. This would plant a seed in Davis’ mind that maybe he could form a friendship with one of the Grand Dragons. Regardless of their glaring differences, Davis realized that if both sides find a mutual connection—such as music—it lends the opportunity for the two to bond. Ultimately, this bond would encourage Klansmen to be more open to discussion about race. It was a lot to bank on but Daryl’s experience that night in Maryland motivated him to go all in.\nI had one guy from an NAACP branch chew me up one side and down the other, saying, you know, we’ve worked hard to get ten steps forward. Here you are sitting down with the enemy having dinner, you’re putting us twenty steps back. I pull out my robes and hoods and say, look, this is what I’ve done to put a dent in racism. I’ve got robes and hoods hanging in my closet by people who’ve given up that belief because of my conversations sitting down to dinner. They gave it up. How many robes and hoods have you collected?\nI Like America and America Likes Me – Joseph Beuys\nDavis’ approach draws a parallel to performance artist Joseph Beuys when he locked himself in a room with a live coyote for three consecutive straight days. The purpose of the piece was to focus on the 1970’s America and the oppression of Native Americans.\nThe coyote was a representation of America at that time; feral and wild. To put it more simply, the byproduct of the cynical history of America and whites’ mistreatment of minorities. Joseph saw the coyote as America’s “spirit animal” and Beuys being a representation of “us”. Beuys rode on the concept of America being a melting pot and a land of opportunity where a foreigner like him could come to this country and live in harmony with other races and creeds.\nYou could say that a reckoning has to be made with the coyote, and only then can this trauma be lifted.\nDuring those three days, Beuys performed various gestures at the coyote who would shift between hostile and calm. The coyote uncertain of Beuys’ intentions and Beuys unsure of the coyote’s. There were moments in which the coyote snapped at him and other times in which the two embraced.\nAt the end of the three days, Beuys emerged from the room unharmed. The lesson from Beuys’s strange performance was direct: in order for America to heal its social wounds, it can only do so through direct communication and willingness connect with all its varied populations.\nWe were a little shocked at the extent of his naivete. – James Baldwin\nOn May 23, 1964, James Baldwin and several cultural leaders attended a private, unpublicized meeting with Attorney General Robert F. Kennedy at a New York apartment. The purpose of the meeting was to address and formulate resolutions towards race relations in America. Ultimately, the meeting itself did not reach any progressive conclusion.\nBaldwin would express that Kennedy was naïve about how serious the conflicts and issues of race were in America. In one instance, Kennedy claimed the Justice Department was a key supporter of the Civil Rights movement. Jerome Smith, an attendee, refuted that claim and detailed stories of the Justice Department allowing violence against black citizens. The meeting peaked when attendees began to walk out, which left both sides angered and bitter towards one another.\nKennedy would later admit that he wasn’t prepared for such a confrontation. When met with the realities of oppression that existed in America, he became defensive and in denial. Despite the meeting’s disheartened conclusion, the residual effect was a step in the right direction. A month after the meeting, President John F. Kennedy would give his Civil Rights Address where he would publicly acknowledge the need to confront racial inequality in America. This would lead to the Civil Rights Act of 1964 coming into legislation, considered to be a landmark achievement in American politics. The act ended segregation in public spaces and made it illegal to discriminate based on race, sex, color, religion, or nationality.\nThe irony of it all? The individual who pushed for the legislation the most was none other than Attorney General Robert F. Kennedy.\nFind someone who disagrees and invite them to your table. – Daryl Davis\nProgress stands the best chance when opposing sides can confront their issues head-on. That’s not to say that meeting with like-minds won’t produce positive results. President Obama’s meeting with prominent black figures in April 2016 resulted in 58 federal prisoners being pardoned by the President. On the opposite end of the spectrum, Trump’s meeting with Kim Kardashian-West led to the commute and release of Alice Marie Johnson who was serving a life sentence for drug trafficking conviction. The latter meeting strikes closer to Daryl Davis’ philosophy.\nKim Kardashian-West has been vocal about her opposition to Trump and his policies. She could use her differing beliefs as an excuse to reject interaction with Trump at all costs. Instead, she met with the President and convinced him to commute Johson’s sentence. Something that might have never happened had she chosen to be more closed-minded.\nThough Kanye’s approach—whether his intentions are selfish, genuine, or an odd combination of both—may not be immediately effective, history has shown us that the long-term effects are paramount to progress. But the main issue isn’t so much the approach but that Kanye just might not be the best candidate to spearhead this endeavor.\nImagine for a moment Colin Kaepernick, Obama, Oprah, John Stewart, Bill Gates, and even the likes of Ben Shapiro meeting with Donald Trump to have a dialogue about all that troubles America. If dozens of Klansmen can befriend Davis and leave the Klan, and a disastrous meeting with Kennedy could result in the Civil Rights Act, there’s definitely hope for Trump. And for those who may deem it an utter waste of time, I encourage you to look to South Africa.\nAfter decades of the apartheid, the country was able to reset race relations by realizing that the true culprit of these crimes against humanity was the system, not the people. Perpetrators were allowed confession and amnesty, the victims given rehabilitation and resolution, and the country was allowed to start over and heal.\nNo matter how difficult our current times may be, America has overcome hostile eras time and time again. The Civil War, two world wars, the Great Depression, the Civil Rights Movement, Vietnam, The Cold War—the peaks and valleys of America’s trials, failures, and triumphs speak for themselves. America is capable of resolution over destruction but for what it’s worth, James Baldwin said it best:"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:834338c8-8681-4ed7-95bc-92d56be7afc7>"],"error":null}
{"question":"How do modern approaches to Native American cultural preservation combine digital technology with community involvement?","answer":"Modern approaches integrate digital preservation tools with community-led stewardship. The Sustainable Heritage Network provides training and resources for tribal representatives to manage their own digitization efforts, while respecting cultural protocols through systems like Mukurtu that enable tribe-determined access restrictions. This technological approach is part of a larger shift in research practices, where Native communities are actively involved in preservation efforts. For example, in Alaska, archaeological projects now feature close cooperation between Native organizations and various institutions, and museums work with tribal groups on initiatives like repatriation and collaborative exhibition development.","context":["This series on tribal collections highlights three projects from across the libraries, archives, and museums space that focus on Native American communities and culture, using best practices set forth by the First Archivists Circle’s Protocols for Native American Archival Materials. (Post 1: The Indigenous Digital Archive, Post 2: Warm Springs Sound Archives Preservation Project)\nPost 3 of 3: Sustainable Heritage Network\nSeveral partners are involved in the SHN in addition to Washington State University, including:The Sustainable Heritage Network (SHN) is a grant-funded, “Collaborative Stewardship” program that invests in training and equipping tribal representatives (especially archivists, librarians, and museum specialists) to manage their own digitization efforts instead of outsourcing to non-tribal service providers, an approach known as the “indigitization” model.\nThe SHN is managed by the Center for Digital Scholarship and Curation at Washington State University. A 2012 report by the Association of Tribal Archives, Libraries and Museums (ATALM), titled “Sustaining Indigenous Culture,” revealed a need among tribal memory institutions for easily accessible and online training materials for digitization and digital preservation of cultural heritage assets (see About SHN). In response to this need, the SHN was formed to provide open access online tutorials, articles, and other educational web resources, as well as both virtual and in-person workshops dedicated to the digital stewardship lifecycle, including digital tools and digital preservation. The main purpose of the Sustainable Heritage Network is to “… bring together communities, institutions, and professionals to support each other by sharing knowledge, educational resources, and technology necessary for the responsible digitization and preservation of cultural heritage.” (About SHN)\n- Association of Tribal Archives, Libraries and Museums\n- Center for Digital Archaeology\n- University of Oregon Libraries\n- Alaska Native Language Archives\n- California Indian Museum and Cultural Center\n- Native American Archives Roundtable\n- Society of American Archivists\nA team of expert advisors to the SHN include representatives from:\n- California Digital Library\n- Association of Tribal Archives, Libraries, and Museums\n- Alaska Native Heritage Archive at the University of Alaska, Fairbanks\n- Dalhouse University\n- Western Washington University\n- California Indian Museum and Cultural Center\n- University of Oregon\n- Smithsonian Institution’s National Museum of the American Indian\n- University of Texas\n- Library of Congress\nAll of the resources compiled by the SHN are made freely available to the public online at their website. Resources are organized by area of focus, providing materials such as slides, checklists, guides, how-tos, case studies, blogs, and recommended best practices for digitizing and preserving photographs and images, audio recordings, artifacts and objects, books and documents, general processing, language documentation, and GIS, CMS, and Databases. The site also provides information about all of the different communities involved, providing a platform for connecting people as well as resources and information.\nThe indigitization model and programs like the SHN contribute to information reliability, access, and social justice because they entrust the stewardship of cultural heritage resources in the digital age to the people who belong to the culture from which the materials were produced, and thus have the highest stake in their preservation as well as how and by whom materials can be accessed. The digitization of indigenous cultural heritage materials and documents not only helps to preserve the data about the artifacts, it also can make items more accessible for the people who need access. With software solutions such as Mukurtu, which enables access restrictions that are determined by the tribes, cultural protocols can be respected when certain materials should not be made widely accessible.\nThe SHN spreads knowledge and expertise in these areas, with repatriation of cultural materials in the form of knowledge about how to best preserve and provide access to these materials. In general, the program is broadening awareness of cultural heritage, and empowering people to take ownership of their cultural heritage, bringing Native perspectives and reclaiming language and culture in the digital world (A Visit to the CIMCC).\nLearn more about the Sustainable Heritage Network:\n- Sustainable Heritage Network website: https://sustainableheritagenetwork.org/\n- Indigitization: Toolkit for the Digitization of First Nations Knowledge: http://www.indigitization.ca/\n- Miriam Jorgensen, 2012. Sustaining Indigenous Culture: The Structure, Activities, and Needs of Tribal Archives, Libraries, and Museums. Oklahoma City, OK: Association of Tribal Archives, Libraries, and Museums: http://www.atalm.org/sites/default/files/sustaining_indigenous_culture.pdf\n- Center for Digital Archaeology interview (2013) with Nikki Myers-Lim, executive director of the California Indian Museum & Cultural Center (CIMCC) in Santa Rosa, CA: https://youtu.be/PQ_bfccX8tI","New Dynamics of Cultural Research and Representation in Alaska\nAron L. Crowell\nAlaska Natives number more than 90,000 people and speak 20 indigenous languages. This cultural diversity exists against an historical background of cultural repression as well as the contemporary resurgence of indigenous rights, resource ownership, political autonomy and cultural voice. Within this context, the relationship between Alaska Native peoples and cultural researchers from outside their communities has undergone a fundamental transformation. Anthropologists, archaeologists, historians, economists and other social scientists, as well as the universities, museums, agencies and foundations that employ and support them, all stand on a far different footing with respect to Native communities than was the case until even the last decade.\nToday, researchers seek permissions, collaboration and communication as a matter of course. Information is shared with communities and ethical standards of informed consent, indigenous participation, data sharing and respect for privacy are pre-conditions for project approval and funding (see Guidelines for Research, Alaska Federation of Natives; Principles for the Conduct of Research in the Arctic, U. S. Interagency Arctic Research Policy Committee and the National Science Foundation; Draft Principles for an Arctic Policy, Inuit Circumpolar Conference.) Alaska Native communities have also prioritized self-representation of their cultures in books, media and museums.\nIn the long history of arctic research, these principles and responsibilities were often unrecognized or ignored. The indigenous critique of traditional social science practice indicts researchers for lack of community review and access to publications, disrespect for cultural values, disregard for restrictions on the use of oral traditions, removal of objects without proper permission, disturbance of burials and removal of human remains for study, failure to reciprocate village cooperation, lack of credit and financial return to Native colleagues and other offenses.\nThe U. S. National Science Foundation (NSF), the leading source of northern social science funding (almost $2 million in fiscal year 2000 through its Arctic Social Sciences division in the Office of Polar Programs), has been highly influential by directing its support toward projects that actively involve the cooperation and participation of local communities (Arctic Social Sciences: Opportunities in Arctic Research, ARCUS 1999). Federal agencies that conduct social science research in the north have also adopted goals and standards that reflect the new priorities. Agency work is coordinated by the U. S. Arctic Research Commission and the Interagency Arctic Research Policy Committee (IARPC).\nIn recent years, the NSF supported creation of the Alaska Native Science Commission to encourage collaborative project design in such areas as northern contaminants research and the incorporation of traditional ecological knowledge into environmental and climate change studies. NSF also provides support for the Alaska Rural Systemic Initiative, a statewide effort with the University of Alaska and Alaska Federation of Natives to develop culturally integrated science and mathematics curricula for Alaskan schools. The emphasis is on incorporating local knowledge and Native worldviews into science teaching. The Smithsonian Institution's Arctic Studies Center (National Museum of Natural History) has played a role in establishing new working relationships for research and education with indigenous communities in Alaska, Canada and Russia.\nA few specific areas of active collaborative research may be highlighted in the present context. For example, human interactions with the changing arctic environment are an important focus of interdisciplinary and cross-cultural study. With NSF support, Henry Huntington and the Inuit Circumpolar Conference worked with North Alaskan coastal communities to document traditional ecological knowledge of beluga whales and their migrations. The Marine Mammal Commission (with Caleb Pongawi) has compiled hunters' observations of shifts in whale, walrus, caribou and seabird behavior. Anthropologists with the Alaska Department of Fish and Game cooperated with the University of Alaska and communities in Prince William Sound and Cook Inlet to develop educational films and interactive CD-ROMs about local subsistence practices and traditional knowledge. The U.S. Fish and Wildlife Service, National Park Service, Alaska Nanuuq Commission and Union of Marine Mammal Hunters of Chukotka recently collaborated on an international study of polar bears that relied heavily on indigenous observations. A recent workshop by the Marine Mammal Commission, National Oceanic and Atmospheric Administration, and National Marine Fisheries Service focused on linking climate change observations by scientists and Native communities.\nArchaeology provides a window into cultural history and human-environmental interactions in the past. Archaeological sites can be ideal opportunities for collaborative study and community involvement because they are often located near contemporary villages and are easily linked to school programs, training opportunities, local cultural heritage efforts and tribal museums. The National Science Foundation and the Kodiak Area Native Association co-sponsored excavations by Bryn Mawr College at the Karluk 1 site on Kodiak Island, leading to a wide range of educational efforts and foundation of the Alutiiq Museum in 1995. The Utqiagvik Archaeology Project in Barrow (State University of New York, North Slope Borough, National Park Service, Bureau of Indian Affairs) was another landmark project. Research was carried out jointly, including studies made of human remains recovered at the site. Over the past 15 years, many excavations and field schools have featured close cooperation between Native organizations and the National Park Service (especially its Shared Beringian Heritage Program), University of Alaska, U. S. Fish and Wildlife Service, Arctic Studies Center and other agencies and universities.\nThe on-going process of repatriation under NAGPRA, which requires extensive consultation between outside museums and tribal groups, has created a new awareness of the wealth of Alaskan collections in U. S. museums and around the world. The Smithsonian Institution's National Museum of Natural History alone holds more than 18,000 ethnological objects from Alaska, of which some portion will eventually go back to the state through repatriation. Others will return through exhibits developed by the Arctic Studies Center (ASC) in coordination with Alaska Native organizations, the Anchorage Museum of History and Art and other partners. An example is ASC's Looking Both Ways: Heritage and Identity of the Alutiiq People, co-developed by the Alutiiq Museum using information provided by Alutiiq Elders and scholars. ASC offers on-going student internships and community scholar opportunities, and over the next two years will work on a major project with Alaska Native consultants to document Smithsonian collections and to produce new exhibits, publications and a web site. The Anchorage Museum's Living Tradition of Yup'ik Masks is another prominent example of community-based exhibition development, and has been followed by further NSF-sponsored study of European museum collections by Yup'ik elders (with curator Ann Fienup-Riordan).\nInformation may be returned in other ways. For example, ASC's Beringian Yup'ik Heritage Project (led by Igor Krupnik, Willis Walunga, Vera Metcalf, and Lyudmilla Ainana) has assembled historical documentary records, notes, maps and genealogical data from the past century of anthropological research on St. Lawrence Island to create a community sourcebook of Yup'ik heritage and history.\nIt is clear that a new paradigm of U. S. arctic social science has emerged in response to broad political, legal and intellectual trends. The opportunities and challenges are both large. Joining local and scientific knowledge in the area of environmental observation is difficult and requires the construction of new interpretive frameworks. An increasingly important issue in cultural research is intellectual property. Research protocols signed with indigenous entities now often call for restricted access to the information gathered, in line with cultural values and fears that it will be misused or misrepresented. To what extent will researchers agree to restrictions on publication? Repatriation entails other unresolved matters that may undermine the collaborative efforts of Native communities and museums, including disagreement over what objects can be defined under the law as sacred or as inalienable because of cultural patrimony. In general, and across all aspects of social and cultural research, collaboration with indigenous communities requires time, willingness to listen, and a commitment to share control and to work toward alternative goals."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:ec555cdf-32c3-44eb-a69b-ce37b331ea29>","<urn:uuid:04be6ee0-29a2-4a4a-bc21-73b0ba919b86>"],"error":null}
{"question":"What's the key difference between trademark symbols (™) and patent drawings when it comes to their requirements for registration?","answer":"Trademark symbols and patent drawings have different registration requirements. For trademarks, you can use the ™ symbol without registration, though it only provides state-level protection under common law. However, patent drawings have strict mandatory requirements - they must be included in nonprovisional patent applications (except for chemical compounds), follow specific format rules like being in black ink on white paper with precise margins, and include proper identification and numbering. Additionally, patent drawings must include multiple views and detailed illustrations to explain the invention, while trademarks simply need a distinctive mark or symbol.","context":["What is a Trademark in the Marketing Industry?\nTrademarks are a type of intellectual property consisting of a word, name, symbol, or device that distinguishes products or services from a specific source from the products and services of others. Trademarks (™) are typically used to identify products, while service marks (℠) are used to identify services.\nTrademarks and service marks are essential in the world of marketing because they help customers identify those trademarked slogans and designs with a specific brand. Not only does this help the brand build recognition with their target audience but it also helps customers ensure they’re using a brand they trust. Trademarks and service marks protect the rights of owners and the safety of consumers.\nThat said, how do you go about creating a trademark or service mark for your brand? How do you register for one? Let’s take a closer look at the different trademark symbols and how you use them.\nEstablish and Register Your Trademark\nYou can establish a trademark without registering for one, although it is not recommended. Legally registering your trademark helps to protect your business. To register, you’ll need to file with the United States Patent and Trademark Office (USPTO). It’s best to hire an attorney well-versed in trademark law and protection for this process because of the strict guidelines, deadlines, and fees associated with it.\nA business with an unregistered trademark will use the ™ symbol over their brand name. A business with a registered trademark will use the Ⓡ symbol over their brand name. The difference between an unregistered and registered brand name is the legal protection behind each trademark.\nUnregistered trademarks only give you protection in the state where your business is registered and it’s only protected by common law. Registered trademarks have federal protections that the USPTO provides and your trademark is protected in all 50 states.\nWhat’s the Process for Registering a Trademark?\nBefore you register your trademark with the USPTO, the organization recommends that you ask two questions first: How difficult will it be to protect your trademark based on its strength and is your trademark capable of being registered?\nReferring to the first question, your trademark needs to be distinctive enough from other marks or products. You can use the public search database the USPTO maintains to search for similar logos, names, designs, phrases, and more to ensure your trademark is truly unique.\nThe second question refers to whether you’re applying to register for your brand or if you’re filing a patent for some other form of intellectual property. Trademarks protect words, symbols, designs, logos, or other parts of your brand. If you’re not registering a good, but a service, you’ll need to use a service mark.\nA patent is different from a trademark or service mark. Patents are limited duration property rights that relate to an invention.\nA copyright is also different from trademarks, service marks, and patents. Copyright is used for creative works and protects the authorship of those works. Copyrights aren’t handled by the USPTO, but by the U.S. Copyright Office.\nHow Do Trademarks Protect Your Brand?\nTrademarks have no expiration date, only maintenance fees. You pay these maintenance fees between the fifth and sixth year after you’ve filed for your trademark registration and then at the 10-year mark. After that mark, you only have to pay a fee every 10 years.\nWhen your trademark is officially registered, your brand is protected against trademark infringement. Trademark infringement is the unauthorized use of your trademark in a manner that causes deception or confusion about the source of specific goods or services. For instance, a ride-sharing service named Guber would be infringing on the Uber trademark.\nIf your trademark has been infringed upon, you’ll need to file a civil suit in federal court. The court considers the evidence including whether the defendant’s goods or services are sufficiently related to your trademark.\nThe penalties for the offending parties if you win your case include an injunction to stop using the mark and monetary relief. While marketers may be intimidated by the legal process of registering for a trademark, the legal benefits far outweigh the fees.","Patent Drawing Rules: Everything You Need to KnowPatent Law ResourcesHow to Patent an Idea\nPatent drawing rules are requirements by the U.S. Patent and Trademark Office for drawings, pictures, flowsheets, and diagrams submitted in patent applications.7 min read\n2. Color Drawings\n3. Graphic Forms in Drawings\n4. Why Is It Important to Follow Patent Drawing Rules?\n5. Guidelines to Follow for Patent Drawings\n6. What Views Do I Need?\n7. Other Considerations\n8. On Your Own vs. Trained Professionals\n9. Common Mistakes\n10. Steps to File a Patent With Correct Patent Drawings\nWhat Are Patent Drawing Rules?\nPatent drawing rules are the requirements set by the U.S. Patent and Trademark Office for drawings, pictures, flowsheets, and diagrams that go with a patent application. Most patent applications contain drawings. In fact, for a nonprovisional patent, a drawing must be provided to explain better and outline the subject matter associated with the patent request. To increase the likelihood of having a patent request accepted, it's important to follow the patent drawing rules outlined by the USPTO.\nWhen you want to submit a patent to the U.S. Patent and Trademark Office, it's not as easy as filling out a patent application, paying a fee, and waiting for a response. Though provisional patents don't need drawings, a nonprovisional patent needs at least one drawing to show how the invention works.\nWhen creating your drawings, stay within the rules described in the Manual of Patent Examining Procedures, such as:\n- Draw in black and white unless color is the only way to show a part of the invention.\n- Use India ink on all drawings.\n- Make sure drawing is to scale when the illustration is reduced to two-thirds the size.\n- Include identification above each drawing, including the invention name, name of inventor, and application number.\n- Submit all drawings on 11-inch by 8.5-inch white paper or A4 paper. This paper must:\n- Be non-shiny, flexible, free of creases or folds, durable, and white.\n- Be free of erasures, alterations, overwritings, and interlineations.\n- Make the margins at least 1 inch on the top and left sides, 3/8 inch on the right, and 5/8 inch on the bottom.\n- Include scan target points (cross-hairs) on two catercorner margin corners.\n- Never superimpose one drawing over another.\n- Use symbols and a legend if necessary to describe the invention.\n- Avoid solid black shading except on bar graphs or to represent color.\n- Use lead lines that guide the reader from the drawing to the associated symbol in the description.\n- Number each page and view in order with Arabic numerals.\n- Avoid holes in the paper.\n- Photographs must follow the same rules regarding the type, size, and margins of the drawing.\nA complete list can be found in Title 37 of the Code of Federal Regulations (CFR), specifically § 1.84. Remember that drawings aren't limited to illustrations and can also include charts and diagrams. In some instances, a photograph may work better than a drawing. However, the U.S. Patent and Trademark Office only allows photos for utility patents and design patents. Photographs must be in high definition to show the details of the invention.\nChemical compounds are the only type of non-provisional patent that doesn't require any drawings.\nColor drawings are rare among patent applications, and they are only allowed for design and utility patents. If you think color drawings are necessary, you must file a petition and pay the specified fee of $130 under Title 37 (CFR) 1.17(h) for permission to use them.\nIf you send your petition in the mail, be sure to include two sets of color drawings and one photocopy that shows the same subject matter in black and white. If you are filing online, only one set of drawings is needed. You also need to add the following language to your patent's specification (the written description of the invention): \"The file of this patent contains a least one drawing executed in color. Copies of this patent with color drawings will be provided by the United States Patent and Trademark Office upon request and payment of the necessary fee.\"\nWhen creating your color drawings, make sure the quality is high enough that they can be reproduced in black and white on the printed patent without losing any details.\nGraphic Forms in Drawings\nTables, formulas of a mathematical or chemical nature, and waveforms are subject to the same rules as any other type of drawing. Formulas and waveforms also have specific requirements:\n- Formulas: Each formula must be labeled as a separate figure and include brackets to show any necessary information.\n- Waveforms: Waveforms must be presented in a single figure that uses a vertical axis and a horizontal axis that shows time. Each individual waveform must have a letter designation adjacent to the vertical access for identification.\nWhy Is It Important to Follow Patent Drawing Rules?\nIf you don't include patent drawings or don't follow the patent drawing rules, your application is incomplete. Because it's incomplete, the date of filing will be delayed. This could end up costing you a patent, especially if competitors are trying to patent the same type of invention. Photographs and color drawings have their own rules, so take care to follow those, too.\nFollowing the patent drawing rules will also help the patent officer determine whether the invention is non-obvious and novel. These standards are two of the main hurdles to getting a patent.\nFiling with quality patent drawings also helps establish priority of invention with an earlier filing date, which is important in a first-to-file country like the United Staes. To fully benefit from an earlier filing date, the patent application must cover the invention and all of its permutations, and quality drawings make this process easier. The United States Court of Appeals for the Federal Circuit has frequently used patent drawings to help determine what a skilled person would have considered disclosed at the time of application.\nIn addition, a patent drawing may save you if you leave something out of the written description. For this reason, a quality drawing is often the norm, and a professional patent illustrator to draft the drawing is a valuable asset.\nGuidelines to Follow for Patent Drawings\nProcesses, machines, and designs are three of the most popular patent types. Each follows the same general patent drawing guidelines:\n- Clearly show features, including text and illustration.\n- Keep the drawing neat with no signs of erasure or errors.\n- Maintain legibility throughout.\n- Always use the metric system, as it is the preferred measurement throughout the world.\n- Make the drawing visually appealing to grab attention.\nAlthough these guidelines aren't strict rules, following them will help the patent officer better understand your invention. At the application stage, you don't need to fit all the requirements of a formal patent drawing. However, less technical components still apply, such as the correct font to label aspects of the drawing, as well as the margins of the drawing.\nWhat Views Do I Need?\nTo show how your product looks and works, use several viewpoints in your drawings. If applicable, include the following views of your invention:\n- The standard six views (front, back, right, left, top, and bottom). Unornamented surfaces can be omitted.\n- Perspective views with three dimensions.\n- Only the front and back views of a flat object.\n- Sectional views to show function.\n- Exploded views to show how a single part works during operation of the invention.\nShading is another key part of patent drawings. It shows depth, contour, and texture. To do this, you can use dots, lines, and distinctive patterns.\nArrows and lead lines are also important in the patent draw. There are three times to use arrows:\n- On a lead line, a freestanding arrow shows the entire section which it points to.\n- On a lead line, an arrow touching a line shows the surface indicated by the line.\n- To show movement direction.\nEven with all these rules, there are also considerations you should be aware of. Some of these include:\n- Copyright or Mask Work Notices: These can be placed in the drawing directly below the portion they pertain to. However, they must only be 1/8 inch by 1/4 inch. These are only to be used in cases applicable to law and must be included in the specification.\n- Numbering of Sheets: Drawings must be numbered in Arabic numerals in the middle of the top of the sheet, but not in the margin. Numbers can be moved to the top right if they interfere with the drawing. Numbering must also include two numerals separated by a line to show the page out of the total number of pages. Make sure that numerals are also larger than the numbers used to identify portions of the drawing.\n- Numbering of Views: Views must also be numbered with consecutive Arabic numerals, independent of sheet numbering. Partial views must also use Arabic numerals, followed by a capital letter. Numbers and letters must also be clear and not used with brackets, circles, or inverted commas. These numbers must also be preceded by \"FIG.\" When there's only a single view, \"FIG\" is unnecessary.\n- Security Markings: Security markings can be used but must be in the center of the top margin.\n- Corrections: All corrections submitted with the patent drawing must be permanent and durable.\nOn Your Own vs. Trained Professionals\nAs long as you follow the patent drawing rules, making professional charts, illustrations, and diagrams isn't as hard as you may think. You can stick with a pen and paper, or you can use patent drawing software. Options range from free but limited software to expensive, versatile programs. The quality of each depends on your skill in using it.\nIf you don't have the patience to draw, don't have the skill, or don't want the added pressure of making complex drawings, a professional patent illustrator is a great choice. These highly trained professionals will make each page for around $100 to $125. Although this may seem expensive, it's a fair price to pay for the most important part of your patent application.\nMany inventors don't take enough time or care with their drawings. This could result in an incomplete patent application, or the patent office may not have enough information to make a decision. That's why it's always important to include as many drawings as are needed to fully explain the invention.\nOther inventors don't want to shell out the extra cash to hire a draftsman or patent illustrator. Instead, they rely on their own hand. For moderate to strong artists, this isn't a terrible idea. However, poor drawers may be denied a patent without the help of a trained expert.\nSteps to File a Patent With Correct Patent Drawings\nOnce you've filled out the basic patent application and written a full description of the product, it's time to add the drawings. Remember that only provisional and chemical formulas can be submitted without a drawing. For all other patents, include as many drawings as possible to show how the product works.\nIf you need help with patent drawing rules, you can post your question or concern on UpCounsel's marketplace. UpCounsel accepts only the top 5 percent of lawyers to its site. Lawyers on UpCounsel come from law schools such as Harvard Law and Yale Law and average 14 years of legal experience, including work with or on behalf of companies like Google, Menlo Ventures, and Airbnb."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:ee30f7eb-fe2e-40e4-91f2-ca7a95196ac9>","<urn:uuid:28554294-fc9f-47d7-ac9d-07f175cd8cae>"],"error":null}
{"question":"What's the difference between how refrigerated store-bought eggs and unwashed farm eggs maintain their freshness?","answer":"Store-bought refrigerated eggs and unwashed farm eggs maintain freshness through different mechanisms. Unwashed farm eggs are protected by a natural 'bloom' or 'cuticle,' a gelatinous covering that seals the shell's pores, reducing moisture loss and bacterial penetration. These naturally protected eggs can keep well for many weeks even without refrigeration. In contrast, store-bought eggs have been washed and chemically sanitized, removing this protective bloom, and must be kept refrigerated at a consistent temperature of at least 45℉ and consumed within a month.","context":["Many natural barriers help prevent bacteria from entering eggs. The “bloom” or “cuticle,” a gelatinous covering that dries after the egg emerges from the hen, helps seal the pores in the shell, reducing moisture loss and bacterial penetration. The many egg membranes also help prevent the passage of bacteria. The shell membranes contain lysozyme, a substance that helps prevent bacterial infection. The egg white discourages bacterial growth because it is alkaline and binds nutrients in a form that bacteria can’t use, and the thick white discourages the movement of bacteria. As the egg ages, the white thins and the yolk membrane weakens, enabling bacteria to reach the nutrient-dense yolk, where they can grow over time if the egg is kept warm. In a clean, fresh shell egg, internal contamination rarely occurs.\nCare in the hen house helps to produce healthy eggs. Have one nest box for every four to five hens. Keep the bedding clean and deep. Collect eggs often and at least twice a day in the winter to prevent freezing. Don’t stack eggs more than five layers deep when carrying them.\nSome customers want unwashed eggs that are protected by the natural factors mentioned above. The quality of unrefrigerated eggs will decrease faster than refrigerated eggs, as the white gets thinner faster, but if refrigeration is not possible, these naturally protected eggs will keep well for many weeks or months. If you want to produce unwashed eggs, use sandpaper to remove small bits of dirt.\nIf you prefer to wash eggs, use water that is 20 degrees warmer than the egg and is at least 90 degrees F.; this will make the egg contents swell and push dirt away from the pores of the egg. If you have extremely dirty eggs, a mild detergent or sanitizer (1/2 oz. chlorine to 1 gal. of water) approved for washing eggs can be used. Never let eggs sit in water, and don’t even submerge them; just have them in a colander and slosh them in the cleaner. Otherwise, once the temperature equalizes, the egg can absorb contaminants from the water. Cool and dry eggs quickly after washing, then store them, large end up, at 45 degrees F. and at 75% relative humidity. Eggs sitting at room temperature can drop as much as one grade per day.\nIf eggs are stored properly in their own carton or other stable environment, they should hold a quality of Grade A for at least four weeks. Store eggs small end down in an egg carton to keep the air cell (the pocket of air inside the egg) stable, which should decrease breakdown of the egg white and decrease the possibility of contamination.\nYou can have your birds tested for salmonella by contacting the State Veterinarian, Don Hoenig, at Donald. [email protected] or 287-3871.\nThe Maine Department of Agriculture requires that eggs offered for retail sale be labeled with:\n(a) Name and address of the person or persons responsible for packing\n(b) Grade (Eggs for sale must meet a minimum grade of B if they are sold any place other than the farm door.)\n(d) Weight and count\n(e) Safe Handling Instruction (Keep Refrigerated at 45 degrees F. or less.)\nIf you pack in used cartons, Maine requires that you obliterate any USDA shield; obliterate grade declarations and replace with “B,” then affix your label.\nGrades are determined by candling to measure the air cell and determine the quality of the white and yoke, besides the cleanliness and shell quality. A Grade A egg is clean, unbroken, practically normal with an air cell less than 3/16 inch, has unlimited movement of the yoke within the white and is “free or bubbly,” i.e., the white is not bound to the egg shell and can look bubbly when the egg is candled. The white must be clear and reasonably firm, the yolk free from defects. The Maine Department of Agriculture recommends that folks who cannot candle their eggs should label their eggs grade B, which includes all but the worst eggs. If you can candle your eggs, explicit rules dictate what is allowed for each grade. The information is available from the USDA at www.usda.gov/, from the Maine Dept. of Agriculture at 287-3871 or by mail from me.\nWeight classes are:\nMedium – 1.7 and 21.3;\nLarge – 1.9 and 24.3;\nExtra-large – 2.2 and 27.3;\nand Jumbo – 2.5 and 30.4.\nAnother way to grade eggs according to USDA regulations is called “U.S. Nest Run % AA Quality,” which “shall consist of eggs of current production of which at least 20 percent are AA quality; and the actual percentage of AA quality eggs shall be stated in the grade name. Within the maximum of 15 percent which may be below A quality, not more than 10 percent may be B quality for shell shape, pronounced ridges or thin spots, interior quality (including meat or blood spots), or due to rusty or blackish-appearing cage marks or blood stains, not more than 5 percent may have adhering dirt or foreign material on the shell 1/2 inch or larger in diameter, not more than 6 percent may be Checks [cracks], and not more than 3 percent may be Loss [losses from checks, dirt, etc.]. Marks which are slightly gray in appearance and adhering dirt or foreign material on the shell less than 1/2 inch in diameter are not considered quality factors. The eggs shall be officially graded for all other quality factors. No case may contain less than 75 percent A quality and AA quality eggs in any combination.” The weight classes for Nest Run % AA Quality are: XL – 1.7lb./doz., 2.2 oz. each; 1 – 1.6 lbs. and 2.1 oz.; 2 – 1.5 lbs. and 2 oz.; 3 – 1.4 lbs. and1.9 oz.; 4 – 1.3 lbs. and 1.8 ounces. [From https://www.ams.usda.gov/PYEggGradingManual.pdf]\nRestricted eggs and cracked, dirty, leakers, or incubator rejects can be sold only directly to the consumers. They must be labeled as Restricted.\nFresh eggs must be fewer than 30 days old; older eggs must be labeled as “Storage Eggs.” Eggs that have been treated to inhibit natural deterioration must be labeled “Processed.” The terms “fresh eggs,” “strictly fresh eggs,” “hennery eggs,” “new-laid eggs,” “farm fresh eggs,” “selected eggs,” “quality certified eggs,” “nearby eggs,” “native eggs” or words or descriptions of similar import shall not be used on any eggs that do not meet the minimum requirements for Maine consumer Grade A.\nBlood or meat spots are found occasionally on an egg yolk and merely reflect either the genetics or age of the hen. They occur when a blood vessel ruptures on the yolk surface when it’s being formed or by a similar accident in the wall of the oviduct.\nCare of Eggs for Hatching\nDO NOT wash eggs unless necessary. Store the clean, fertile eggs in an area that is kept at 55˚ to 60˚ F. and at 70 to 75% humidity, never at temperatures above 75˚ F. or at lower than 40% humidity. Store the eggs small end down and slanted at 30 to 45 degrees, and turn them daily. Putting a 2″ x 4″ under one end of the carton or storage container and moving it to the other end daily works well.\nDo not store eggs for more than 10 to 14 days, since hatchability begins to decline significantly after 14 days. Just before setting eggs under a hen or in the incubator, let the eggs warm to room temperature (70 to 80˚ F.) and remove any cracked eggs.\nSome Natural Egg Colors\nIf you want to use some natural pigments to color eggs, at Easter, for example, you can use the following dyes on hard boiled eggs or on raw eggs that are not going to be eaten (since submerging raw eggs in dye may force pathogens into the egg). These pigments work best on white or light eggs.\nYellow: To a cup of hot water, add 1 to 1-1/2 teaspoons of turmeric and 1/2 teaspoon vinegar.\nGolden Tan: Save the skins from yellow onions. Add them to the water when you hardboil your eggs.\nBrown: To a cup of hot water, add 1 Tablespoon of instant coffee and 1/2 teaspoon vinegar.\nGreen: Soak your eggs in liquid chlorophyll (available from pet stores or drug stores).\nPretty Pastels: Rub blueberries and cranberries on the shells for soft blues and pink. Blend them for another pretty result.\nFor more information, see:\nDr. Michael Opitz’s Poultry Fact Sheet, University of Maine Cooperative Extension. [email protected]\n“Care of Hatching Eggs,” Small Flock Factsheet Number 8, Phillip J. Clauer, Poultry Extension Specialist, Animal & Poultry Sciences Department, Virginia Tech Univ., https://pubs.ext.vt.edu/2902/2902-1090/2902-1090.html\nIncredible Egg Web site, www.aeb.org/\nRosie’s Easter Basket, Rosemary (Rosie) Winters, www.night.net/easter/eggcolor.html-ssi (information on dyeing eggs; restricted website)\nAbout the author: Diane Schivera is Assistant Director of Agricultural Services for MOFGA … as well as our resident eggspert! You can contact her at 207-568-4142 or at [email protected].","We’ve all been there….not knowing exactly how old a carton of eggs in the refrigerator is or how long the farm fresh chicken eggs have been sitting on the countertop for. It’s important to know if your eggs are safe to consume. Luckily, there is a fresh egg water test that can help you to determine how old your eggs are so you can make the decision to keep or toss them.\n1. Why do Old Eggs Float in Water?\nOld eggs float because they contain a larger air pocket than a fresh egg. When a chicken lays an egg, the contents inside the egg contracts. This causes a small air cell or “air pocket” to form at the top of the fat end of the egg.\nWhy does an air pocket form inside eggs? When the contents of the egg contracts, an air pocket forms inside of eggs. This happens because the egg is being brought from a very warm temperature of 105℉ inside the hen, to a much cooler outside temperature.\nAs an egg ages, moisture is released through the pores of the egg and is replaced with more air. This is why an older egg will have a larger air pocket and float to the surface.\nGenerally, the larger the air pocket, the older the egg. Also, the larger the air pocket, the increased likelihood of the egg being contaminated with bacteria or considered “bad.”\n2. How to Test Eggs for Freshness [Fresh Egg Water Test]\nMaterials Needed for Fresh Egg Water Test\n- Clear glass\n- Lukewarm water(slightly warmer than room temperature)\n- The reason you want to use slightly warmer than room temperature water is to prevent bacteria that is on the outside of the shell from being drawn into the egg. Using cold water will cause the egg membranes to retract. Any bacteria that is on the outside of the egg will be absorbed through the egg membranes, causing the egg to become contaminated.\nStep 1: Fill a clear glass of lukewarm water.\nStep 2: Wait until water stops moving.\nStep 3: Gently place an egg into the glass of water.\nStep 4: Is it ok to eat eggs that float to the top? Should I throw away eggs that float? It is my personal opinion to discard any eggs that float to the top. I do not recommend feeding them back to your chickens either, as they can potentially have bacteria or other harmful diseases present. It isn’t worth the risk.\nStep 5: FOR QUESTIONABLE EGGS:\n- Sniff Test: if the eggs smell “off” at all, discard them.\n- Cracks and Discharge: Check for cracks or any discharge coming from the egg. If the eggs have any cracks, they are prone to bacterial growth inside. If you see cracks, discard them.\n- Crack the eggs open in a separate bowl. If the eggs look questionable or smell odd at all, discard them.\nStep 6: For all eggs, questionable or good, always thoroughly cook them. Eggs need to reach an internal temperature of 160℉ in order to kill bacteria.\nJust because an egg sinks to the bottom doesn’t necessarily mean that it is “SAFE” to eat. Always check eggs before cracking them for any discharge or foul smells.\nIt is also a good practice to crack eggs into a separate bowl, just in case you notice a smell or bacterial growth after the egg is cracked.\n|WHAT HAPPENS TO THE|\nEGG WHEN YOU PLACE\nIT INTO A GLASS OF\n|AGE OF EGG|\n|EGG SINKS TO BOTTOM|\nAND LAYS IN A\n|FRESH EGG, NOT|\n|EGG FLOATS IN|\nMIDDLE OF GLASS\nOR STANDS UPRIGHT\nON BOTTOM OF\n|AGING, BUT LIKELY|\nSTILL GOOD TO\n|EGG FLOATS TO|\n|OLD OR “BAD” EGG|\n3. Can You Get Sick from Eating Old Eggs?\nOld eggs are more likely to carry bacterial diseases that can make you sick if you eat them, especially if they are eaten raw or if they are undercooked.\nBacterial Diseases Transmitted Through Old, Undercooked or Raw Eggs\nSymptoms of Salmonella, E.Coli and Campylobacter\n- Abdominal Cramping\n4. How Long do Eggs Last in the Refrigerator?\nEggs that you buy in the refrigerated section of a grocery store have been washed and many have even been chemically sanitized prior to shipment to your local grocery store. They must be kept refrigerated at a consistent temperature of at least 45℉ and consumed within a month.\n“FACT: By law, a farmer has 30 days to get a freshly laid egg into a carton and another 30 days before it needs to be sold! That means that the egg can be as old as two months old when it hits the grocery store shelf!“9 Important Facts: How Long Are Chicken Eggs Good For?\nHow Can You Tell How Old a Grocery Store Egg Is?\nGrocery store eggs in the United States are a little more difficult to get an exact age of. The reason for this is that in the United States, farmers have up to 30 days to get eggs packaged and another 30 days to get these eggs sold. So, once you purchase eggs from your local grocery store, they can already be 2 months old!\nWhat is a Julian Date on the Egg Carton?\nEggs in the supermarket are packaged and marked with what is called a “Julian Date.” These numbers range from 1-365 and correspond to the day of the year in which they were packaged. For instance, eggs that were packaged on August 29th will have a Julian Date of 241 and eggs that were packaged on January 1st, have a Julian Date of 001.\n5. Should You Wash Farm Fresh Eggs?\nRight before a hen lays an egg, it is covered with what is called a “bloom.” This protective coating is what helps to prevent bacteria from penetrating through the pores of the egg shell. It’s ok to wash farm fresh eggs, but just know that you will be removing this protective coating and must follow a few food safety rules.\n- Only wash eggs in lukewarm water. This is to prevent any bacteria that is on the outside of the egg from penetrating inside of the egg. Washing eggs in cold water will cause the egg membranes to retract bringing any dirt or bacteria that is on the outside egg shell, inside. This increases the chances of the egg growing bacteria inside.\n- Refrigerate immediately after washing. If you choose to wash your farm fresh eggs, they must be put into the refrigerator right away and kept there until ready for use.\nDid You Know?\nDid you know that only farm fresh eggs contain a protective coating or “bloom” on the outer part of the shell? Eggs that you buy at the supermarket, in the refrigerated section, have been cleaned with a sanitizer, washing this protective bloom away.\nFor more information on egg safety, please refer to the the FDA Egg Safety Guide.\nCONCLUSION: 5 Things You Need to Know-Fresh Egg Water Test\n- Old eggs will float in water because as an egg ages, it releases moisture and this moisture is replaced with oxygen. This “air” allows it to float in the water.\n- When should you not eat an egg? If you perform a fresh egg water test and the egg floats to the top of the water, you should not eat it.\n- You can get sick from eating old eggs, especially if they are raw or undercooked. Bacterial diseases that are common are salmonella, E.coli and campylobacter.\n- Supermarket eggs should be kept in your refrigerator at at least 45℉ and used within 1 month.\n- Farm fresh eggs do not need to be washed and will last longer if they aren’t. If you choose to wash them, they must be stored in your refrigerator until ready for use (for up to 3 months)."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:353ae097-6ef3-4df9-8519-aba61d2becf2>","<urn:uuid:c4af7884-58a8-4744-9b14-7aff1e95d9f9>"],"error":null}
{"question":"What are the initial challenges faced by newcomers in boxing gyms, and how do electric vehicle adoption barriers affect utility companies?","answer":"When joining a boxing gym, newcomers face several initial challenges. The environment can be intimidating, with most gyms having a hardcore, dark, warehouse-type atmosphere where people appear mean and unfriendly. New members often receive minimal initial guidance, being expected to learn basics on their own while coaches focus on experienced fighters. Additionally, the intense training demands require good fitness levels and basic skills like hand-wrapping and jump rope proficiency. As for utilities dealing with EV adoption, they face multiple challenges including charging pricing issues that can lead to grid reliability problems and complex billing involving multiple stakeholders. There are also infrastructure limitations with limited charging networks and unpredictable charging experiences affecting customer satisfaction. Furthermore, utilities must address the challenge of specialized maintenance, as 97% of today's mechanics aren't qualified to work on electric vehicles.","context":["Will it cause you to nervous when you think about strolling into or signing up for a boxing health club or club?\nI get e-mail on a regular basis from men and women who would like to learn to box but are terrified of going for walks into a fitness center or conversing with a coach - and I get it - not just do you've to cope with the mysterious and being the new male or gal at school, but with boxing everything fear is magnified when you believe that somebody is going to need to punch you from the confront.\nMost of us aren't bred for beat.\nI need you to be comfy walking into a boxing health club and conversing with a coach because I wish to get a lot more e-mails such as this 1 from Alexandra:\n\"Thanks for every one of the appealing boxing articles you've composed over the years! I began reading through your website page just about four yrs ago and Understanding the fundamentals gave me that very small Strengthen of confidence I needed to visit a boxing health and fitness center and begin schooling. 4 many years afterwards I have had six Muay Thai fights in Canada and also the U.S. and expending per month in Thailand for teaching. I'm up for the BC ISKA Women's Welterweight title with any luck , throughout the upcoming year. Many thanks yet again for offering me that nudge I needed to get started!\"\nSo, to attempt to Raise your self confidence - I will Offer you a good idea of Anything you can hope any time you stroll into a boxing gym for The 1st time and afterwards Present you with some guidelines for rendering it an satisfying expertise instead of a traumatic one.\nThe sort of BOXING CLUB OR Health club MATTERS\nYou can find essentially a few varieties of boxing clubs.\nThe hardcore struggle club. This is the style of gym you sign up for if you'd like to learn the way to battle and compete. If getting a boxing winner is your objective then You will need a area like this. These gyms will also be essentially the most intimidating varieties of gyms to stroll into. Competition among the club users could be intense and all are vying for that coach's consideration Using the hopes of demonstrating ample possible to become the club's golden boy or girl.\nThe Health club. These kinds of golf equipment Will not breed fighters. They use boxing as a way to assist you to get in condition. The trainers/coaches are much less worried about method plus much more concerned with holding you relocating to burn calories. Hugely doubtful you'd at any time really spar with everyone in a location like this.\nThe hybrid club. This is generally the sort of club you will really be part of. Whether they would like to or not - the coach runs Conditioning classes and trains fighters. It is a subject of profits and viability. You can find considerably more people enthusiastic about getting form than you will discover in Finding out how to box and compete. Generally the fitness classes fund the fighters (journey, lodge, food, Match charges) once they should travel to get a fight.\nWalking right into a Conditioning club Using the intent of just employing boxing for getting in condition is straight forward. There's nothing to be nervous about there. They see plenty of new folks constantly and can combine you into your classes. You'll get an orientation session - top notch is often free of charge - and you'll likely come to feel welcome very speedily. If that's all you need out of boxing, then Do not give it some thought for an additional 2nd - there is nothing to worry about joining a Health and fitness sort club - aside from the outrageous service fees you'll pay...\nWalking into a club where they train fighters - either hardcore or as being a hybrid is a little bit of a special story...\nWALKING INTO THE BOXING CLUB FOR The 1st time\nYou'll probably wander in and down some ways to the basement of some constructing. If I surveyed the many gyms on the market - I bet a minimum of 50-sixty% go with the hardcore, dark, dirty, warehouse sort glance. These properties are likely The most cost effective to lease or obtain and uncovered beams ensure it is simpler to hang heavybags and that kind of point. In any case, it's actually not all golf equipment - but likelihood is you may enter this sort of ambiance.\nNobody will greet you within the doorway. You'll see a boxing ring and people will be hitting luggage, skipping, and usually searching all mean and unpleasant. At this stage, a good deal of individuals turn all-around depart - Do not. By no means intellect what is going on. Just go come across whoever would be the coach or coach that day and introduce yourself. Like Physical fitness golf equipment - your top quality will often be free of charge so you can test it out. That is important since not every club or coach is going to be an excellent fit in your case. You can find certainly some points to look for in a fantastic trainer.\nAs you locate someone ready to talk to you (and a few coaches are significantly better than Other people) they can very likely get you (or your guardian) to register and indicator a waiver releasing them of legal responsibility in the case that you choose to get harm. The mentor will usually question if you need to combat. Should you say Certainly (and you ought to if you are in a place such as this), they gives you some extra paperwork to get dwelling along with you such as a clinical launch kind that a health care provider will have to fill out and an application to affix the boxing association in regardless of what point out/province/nation you might be in. Paperwork will change by place - but you must be a part of the beginner boxing association with your locale to compete.\nUp coming, The category will get going. Ordinarily the classes will include 3 moment rounds of labor accompanied by a moment of relaxation. A typical class may possibly resemble:\nthree rounds of skipping (bounce rope)\nWrap up (put in your handwraps)\n3 rounds of shadowboxing\nGlove up (place in your bag gloves)\n6-twelve rounds of heavybag get the job done (lots of people will be pulled in to the ring to work Together with the mentor on focus on mitts or to spar)\n2-3 rounds of bodyweight exercise routines\nCooldown (which include some ab do the job)\nYou can expect to immediately Learn how men and women from the club interact - but normally:\nnobody will discuss even though Doing work. The minutes of relaxation gives you slightly time for you to socialize As you capture your breath.\nthere'll commonly become a head mentor who'll be from the ring and pull in specific people to operate sure competencies though A different mentor supervises the conditioning operate Absolutely everyone else is undertaking\ncoaches will stroll close to and proper faults or train some capabilities because they deem required\nIf you're new and know very little - you may perhaps get pulled off to your aspect for being immediately demonstrated some Principles. Over most likely, You will be predicted to flounder close to with Everybody for awhile and pick up Anything you can all by yourself. The quantity of assist you will get from Others will differ. Talk to issues but understand that people are there to educate. Some could have fights coming up and may be entirely centered on that. Some might be practical but some can even ignore you absolutely.\nIt might appear to be all unorganized and disjointed, but in case you stick to it you will start to see the way it actually will work.\n10 Guidelines To create THE Practical experience ENJOYABLE AND LESS TRAUMATIC\nIf I can offer you any guidance - Never stroll into a boxing club or gymnasium until finally that you are All set. To help you prepare, consider the following ten strategies:\nRealize that you are not intending to combat on working day one particular. It will often take a number of months and even months prior to the mentor will put you from the ring to spar or struggle. The mentor will view you produce and would not put you in that predicament right until you can actually protect you. If a mentor or trainer puts you from the ring your to start with day - you must stroll out of your club and never go back. So quit worrying that you will get defeat up on your own to start with day.\nLearn how to wrap your arms. As a coach/trainer it is completely disheartening to show new boxers how to wrap their fingers at first of every session. It is easy to discover this in your house. Buy some handwraps and learn how to put them on so you won't need to squander a person's time on the health club asking how to do here it or even worse - making them do it for you personally.\nFind out a number of the Principles at your house. Use This great site and no less than get an notion of how to face, guard, go, punch, and defend. It's not necessary to be excellent at it, but a coach or trainer can have much more time in your case when you demonstrate them you have carried out some analysis ahead of time. Note: some coaches/trainers prefer to you not know everything so they can educate you their way and not have to deal with bad habits you might have picked up. I like that men and women Use a foundation of information to fantastic tune. In any event, Mastering the fundamentals will provide you with a great deal more confidence to wander right into a health club with. Just Do not go in pretending like you realize everything Irrespective of how self-confident you happen to be. You're there to master.\nDo a thing regarding your Health and fitness level. Boxing teaching is exertions. It truly is powerful. If you're fat and lazy - you will Get the ass handed to you on your own very first day and you will produce a terrible perception on Every person there. Before going for walks into a spot in which you will prepare to struggle - stroll into a location where you will do a little something about your level of Health/well being initially (or attempt my on line Pumpt Health club Boxing Physique Transformation (CBBT) Software for guys or Girls).\nLearn to soar rope/skip. Not totally important - but in the event you've under no circumstances jumped rope prior to - you may spend what looks like an eternity whipping yourself and tripping more than the rope. Just take a while on your own to determine how you can skip - even in a basic degree so you are not a complete freak present within the fitness center.\nGet your own personal devices. You can use products that's been sweated in and perhaps washed or you can demonstrate the coaches that you are significant plenty of about Studying boxing that you've absent out and procured some equipment. All you'll need can be a skipping rope ($three), handwraps ($four-$eight), and bag gloves ($20-$50), and drinking water bottle ($one). Shorts, T-Shirt and operating footwear operate great. Put it all in the health and fitness center bag and display up seeking the aspect (pretend it till you allow it to be...). Check out the Pumpt Gymnasium for your personal boxing equipment.\nConsider a pal. It does aid when you choose some other person that's in the same boat as you're. At the very least you'll need someone to talk to in-between rounds. Try not to pair up with them though when it comes time to do partner talent training. You'll find out more from someone who knows something.\nGo with the proper Mindset. Do not walk into the club until you know you want to struggle sometime. Get by yourself mentally ready for the way hard and powerful the instruction will likely be. Should you go in thinking that you'll just try it and find out how it really works out - then There exists a excellent opportunity you won't ever return. read more The initial day in the health and fitness center isn't an excellent good experience. You can expect to sense considerably dismissed and inadequate. Thrust by way of that even though and there are actually benefits on the opposite side.\nBe consistent. If you are going to join - dedicate and be a part of. Show up regardless of the. Under no circumstances skip a category. The trainer may have zero time in your case Should you be sporadic. Boxing abilities choose time and repetition to become second character. If you aren't regular it's a confident sign to the trainer that you are not actually dedicated to getting wonderful within the Activity.\nRelieve into preventing. If you are becoming a member of a hybrid club - it is not a nasty concept to affix the fitness courses first. They are sometimes taught by exactly the same coaches who practice the fighters so you'll understand the techniques accurately, develop some rapport, and it provides you with a while to adjust to how the club performs and have your self into preventing condition. Then - when you're All set - you can simplicity in the hardcore combat training.\nIt really is ALL ABOUT Probable\nOn a last Observe - keep in mind that the coaches and trainers while in the struggle golf equipment are trying to find boxers who may have the opportunity to more info get fights.\nThe more difficult you're employed, the greater dedicated you might be, the a lot quicker you find out, and the greater heart you present - the greater time the coaches/trainers are going to have in your case.\nYou should prove oneself worthy in a very boxing club - no mentor or coach is going to waste their time with someone that would not put in 100% work at every single teaching session. For those who prove to them you're willing to do the perform and demonstrate them you might have the probable to master the talents vital to achieve success in the ring, they'll concentrate their attempts on you.\nThey're often on the lookout for the following champ - so show to them you've got what it requires.","Utilities in the age of electric vehicles\nUtilities in the age of electric vehicles\nUtilities in the age of electric vehicles\nThe impact of vehicles on the environment has driven regulatory mandates to adopt a more sustainable way of commuting. As a result, electric vehicles (EVs), and the necessary infrastructure to operate them, has changed the automobile and utility industries over the past decade.\nElectric vehicles are powered by a charged battery pack and can be separated into two categories:\n- Battery Electric Vehicles (BEVs): These EVs are purely electric with lithium ion batteries suitable for short to medium distances.\n- Plug-In Hybrid Electric Vehicles (PHEVs): Electric vehicles with an internal combustion engine (ICE) with support from a small electric motor.\nWhy Electric Vehicles?\nThe 2015 Paris Agreement has challenged countries to reduce their carbon emissions to “net zero” over the coming years. This international treaty has prompted governments around the world to phase out gas and diesel powered vehicles, shifting instead to EVs:\nSales of electric vehicles have grown steadily over the last decade. The following chart from the International Energy Agency shows China leading market share at 47%. Twenty other countries have reached a market share of above 1%: emissions. As a segment, the automobile industry can tout sustainability and the environmental benefits of emerging technologies to entice consumers to buy EVs.\nAccording to a study by IRENA (International Renewable Energy Agency) on EVs:\n- Electric passenger cars will reach 200 million by 2030\n- Electric two-wheeled and three-wheeled vehicles could outnumber four-wheeled vehicles, with as many as 900 million on roads by 2030\n- Electric buses and light-duty vehicles could surpass 10 million by 2030\nFactors Contributing to EV Adoption\n1. Consumer Interest:\nEco-friendly consumers who want to decrease their carbon footprint prefer to buy EVs. Transportation around the globe is one of the biggest contributors of carbon emissions. As a segment, the automobile industry can tout sustainability and the environmental benefits of emerging technologies to entice consumers to buy EVs. A 2019 international electric vehicle consumer survey (of 7,600 consumers in seven regions) shows consumer interest in electric vehicles is high. 50% of consumers say they’re interested in owning an EV and 28% say they’ll purchase one as their next vehicle.\nConsumer benefits to owning electric vehicles:\n- Reduced operating costs, lower charging prices and simpler maintenance\n- Quieter driving experience\n- Exemption in Clean Air Zones – areas that charge fees to vehicles that pollute the environment\n- Government subsidies that make EVs cheaper than ICE vehicles\n- Preferential parking permits in dense urban areas\nEV technology has vastly improved. Range limitations and charging times have been addressed, alleviating concerns and increasing purchase momentum. Consider these three, top selling EV models in the world in 2020:\n3. NetZero Target:\nIn support of the 2015 Paris Agreement, utility and automobile companies are working to achieve net-zero emissions. To do this, they’re offering customers low-carbon products such as renewable electricity and electric vehicles. By taking advantage of these offerings, individual consumers can reduce their carbon footprint. Businesses can reduce their overall cost of fleet ownership, and organisations can reduce fuel costs, reap tax benefits and take advantage of government incentives.\nChallenges for Utilities:\nEVs help combat climate change. However, barriers to adoption exist:\nCharging Pricing: An increase in the number of electric vehicles can lead to disorganised charging. This makes peak shaving difficult, creates incremental costs for generators, increases transmission and distribution pressures and reduces grid reliability and security. It also degrades power quality and increases the harmonics of the grid. Ultimately, an unreasonable pricing structure can lead to its failure. A dynamic pricing strategy can help utilities overcome the challenges of EVs and can reduce the burden of power on a grid.\nComplex Billing: EVs also present billing challenges for utilities:\n- Number of Stakeholders: Charging hosts, charging point operators, eMobility service providers, roaming network providers, etc. are all involved in the billing process. These stakeholders have to manage multiple plans – pre-paid, postpaid, ad hoc, group plans, etc.\n- Customer Type and Charging Location: Plans offered will vary based on customer type such as individual, fleet, business, public and private. They’ll also vary based on location, including home, office, fleet charging center, parking lot, multi-tenant unit, municipal location and more.\n- Price Per Charge: The customer can be charged based on charge point, price per kWh or by minute/ hour (flat fee). The charging session may include ancillary fees such as a connection fee or a waiting fee for staying connected after reaching a full charge.\nCharging Infrastructure: The mechanics of charging pose challenges to utility companies:\n- Network: Availability remains limited\n- Technology: Fast-charge still in its initial stage and widely unavailable in the network\n- Customer Experience: Unpredictable charging experience negatively affects customer opinion\nService and Maintenance: Electric vehicles require specialised mechanics who are still difficult to find. According to a study done by UK’s Institute of the Motor Industry (IMI), 97% of today’s mechanics aren’t qualified to work on electric vehicles. Of the 3% of mechanics who do qualify, many work directly for EV dealerships, limiting service options for general EV buyers.\nHigher Upfront Investment: Higher manufacturing costs vs. the cost to make a combustion engine vehicle make EVs more expensive to buy. This sticker shock feeds consumer doubt about the long-term economic benefits of an electric vehicle. Government subsidisations help alleviate that doubt, but total consumer buy-in will take time.\nThe Utility Opportunity\nAs more people switch to electric cars, the impact of EV charging loads on generation, transmission and distribution networks translates into more energy and more revenue opportunities for utility companies.\n- Charging Infrastructure: Utilities can play a vital role in modulating charging rates and shifting charging times to provide grid services that support supply and demand. Consider these energy giants already investing in charging infrastructure:\n- Shell recently announced the rollout of 500,000 electric charging stations over the next four years.1\n- Ecotricity a “Big Six” UK energy supplier, partners with Moto, RoadChef and Welcome Break to offer 45-minute fast-charge stations. They call the network “The Electric Highway.”2\n- In the UK, companies like Centrica are building out their EV charging capabilities by acquiring smaller independents. Centrica invested in Driivz, a software company that manages EV fleets and charging networks, to create Centrica Electric Vehicle Services (CEVS) 3\n- New EV Tariffs: Consumer tariff structures (e.g. time-of-use tariffs) reward consumers who slow-charge during off-peak hours. These tariffs, which reduce consumer bills and prevent overloads on the grid, help influence EV drivers to shift their charging behavior. By partnering with EV manufacturers, utility companies can create custom electricity tariffs that can be bundled into the purchase of an electric vehicles. Energy suppliers in the US, UK and other European countries have already begun offering EV energy tariffs.\n- Improved Customer Experience: Careful planning, phased execution and synergy with non-utility businesses can help electric utilities facilitate a smooth transition to EV adoption. With the right customer relationship management (CRM) platform in place, utilities can offer consumers “charging ecosystems” – chargers, charging plans, etc. - for their vehicle. This positive consumer experience, combined with the financial upside of aligning with non-utility companies, translates into increased revenue for the utility company.\n- Vehicle-to-Grid (V2G): While EV tariffs can prevent overloads by shifting charging behavior, they also present challenges. If too many EV drivers charge during off-peak times, it can spike load levels and lead to grid congestion. To counter this, vehicle-to-grid (V2G) enables energy to be pushed back to the power grid from the battery of an electric vehicle. This helps balance the variations in energy production and consumption. Furthermore, V2G can support the integration of renewable energy resources into the grid.\n- AI Driven EV Marketing: With electric vehicle purchases on the rise, utilities must position themselves at the forefront of energy innovation to ensure brand credibility. AI-driven marketing helps identify crucial digital touchpoints for targeted messaging.\n- Data Advantages: Utilities can use data analytics and data science tools to develop services, applications and hyper-personalised product offerings. They can also leverage the data to expand into non-core markets. This allows for:\n- Joint offerings with automotive companies\n- After sales services in conjunction with car dealerships\n- Installation of charging stations at locations where customers park electric vehicles for more than an hour\nGlobally the uptake of electric vehicles is leading to the transportation and electricity sectors becoming increasingly connected.\nEven though barriers to EV adoption exist they are phasing out due to technological advancements. Innovation is the key in identifying opportunities to minimise costs and reducing pain points.\nFor utilities the biggest challenges is to ensure grid reliability and resilience. Providing a successful infrastructure for EV adoption will require coordination among various parties - Vehicle & charging manufactures, Electricity service providers, Distribution network operators, and Regulatory authorities\nIn the long run - Utilities that invest in electric vehicle infrastructure and technology will be well-equipped to offer solutions that benefit future customers.\n2Ecotricity and Nissan install UK electric-car-charging network | Guardian sustainable business | The Guardian\nEXL Utilities Academy"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:95abe045-ad57-4988-9294-50b9bbf0088c>","<urn:uuid:dc7f0a0b-46cd-416c-b618-7a830371a8fd>"],"error":null}
{"question":"How do the fermentation temperature requirements differ between traditional sauerkraut production and Lactobacillus-based beer souring?","answer":"Sauerkraut fermentation occurs at room temperature for 1 to 6 weeks, while Lactobacillus-based beer souring requires specific higher temperature ranges. For instance, some breweries maintain temperatures between 108-112°F (42-44°C) for their Lactobacillus delbrueckii strain, while others operate at 115°F (46°C). The temperature control is much more precise in beer production compared to traditional sauerkraut fermentation, as incorrect temperatures in beer souring can result in either insufficient or excessive bacterial activity.","context":["To find out which kraut is king, we tried six nationally available supermarket sauerkrauts plain, with hot dogs, and in pierogi.\nHow We Tested\nSauerkraut isn’t for everybody. The pungent acidity of fermented cabbage can be polarizing, but fans of this zesty condiment swear by its ability to add refreshing tang to rich meats or hearty potatoes. To find out which kraut is king, we tried six nationally available supermarket sauerkrauts plain, with hot dogs, and in pierogi. Sauerkraut has a similar tanginess to pickled foods, but unlike most supermarket pickles, sauerkraut contains no vinegar. Instead, it gets its acidity from fermentation: Shredded cabbage is sprinkled with salt, packed in containers, and left to sit at room temperature for 1 to 6 weeks. During this time, natural bacteria and yeasts eat away at sugars in the cabbage, leaving behind tart lactic acid in their wake. Once manufacturers deem the sauerkraut suitably tangy, it’s packed into jars, cans, or bags along with some water to prevent browning.\nWhile it only takes three ingredients to make sauerkraut—cabbage, salt, and water—our tasters detected “off,” “chemical” flavors in three lower-ranked sauerkrauts. A peek at ingredient labels revealed that these products all added sodium benzoate and sodium bisulfate—preservatives that extend shelf life. With so few other ingredients to mask off-flavors, sauerkrauts with chemical preservatives had a prominent “fizzy,” “sulfuric,” almost “ammonia-like” quality, even when tasted atop hot dogs or in pierogi. Tasters preferred products that contained just the core three ingredients, calling them “fresher,” “brighter,” and “classic.”\nSince salt enhances flavor, it wasn’t surprising that our favorite products also contain more sodium. We liked the “punchy,” “zippy” flavor of sauerkrauts with 200 milligrams of sodium or more per 2-tablespoon serving. No kraut was too salty for tasters, who thought more salt made for kraut with a hearty, fermented flavor; those with any less just tasted like wet cabbage.\nWhat did surprise us, though, was that these sharper, brighter-tasting krauts were packaged in shelf-stable jars or cans, while lower-ranked products were packed in refrigerated plastic bags. Though we often assume that the products we buy in the refrigerated section of the supermarket are fresher than their shelf-stable counterparts, our science editor explained that in this case, they’re not. Unlike jars and cans, plastic bags let in small amounts of air over time, which degrades some of the sauerkraut’s pungent flavor. This is also why bagged products are the only ones to add preservatives: Unlike the canned and jarred krauts, their packaging alone isn’t enough to prevent the growth of microorganisms.\nIn addition to tasting fresher, canned and jarred sauerkrauts also had a softer, more tender texture. Bagged sauerkrauts were tough and crunchy, which tasters found distracting on hot dogs and in pierogi. A condiment should know its place, and we preferred softer krauts with only a hint of crunch to complement a dish. Lower-ranked products also had strands that were large and uneven, as if they had been roughly chopped with a knife, while our favorite krauts had small and uniform shreds, like they had been shredded with a grater. Big, chunky krauts slipped off hot dogs and crunched unpleasantly in pierogi; we preferred smaller shreds with good cling and subtle chew.\nOur favorite was Eden Organic Sauerkraut, a jarred kraut with punchy, tangy flavor and even, delicate shreds. A bonus: Its jar makes refrigerating leftovers easier, so we can keep this kraut on hand for heaping on hot dogs all summer long.","Soured beer can be produced in the same amount of time as non-soured styles with the help of Lactobacillus. Generally, this is done using the kettle-souring method for styles like Gose and Berliner weisse, however other methods and styles are sometimes in play too. Three pros share some sweet tips on souring with Lacto.\nFal Allen, Brewmaster at Anderson Valley Brewing Co. in Boonville, California.\nAt Anderson Valley we have about eight years of kettle souring experience. We use this method for making our Goses and, on occasion, other beers (like our Tropical Hazy Sour beer). We also do a fair amount of barrel souring beers — we have about 1,200 wood barrels in our sour beer production. This process differs greatly from the kettle souring process. It can take anywhere from nine months to four years to sour a beer this way; in contrast kettle souring can be done in less than 8 hours. The flavor that each process creates can be very different as well. We use kettle souring to create clean, sharp, bright tartness and we use our barrel souring process to create a more complex, deeper, funkier range of flavors. For kettle sours, we keep our temperature at about 108–112 °F (42–44 °C). We use a strain of Lactobacillus delbrueckii that seems to work best at that temperature, but each strain is different.\nWe have tried several sources for Lacto, but we prefer the one we get from a lab. It creates flavors we like, and it creates these flavors more consistently on a regular basis. It is also healthier than some other sources, which makes it easier to grow up to the proper pitching rate.\nPrior to pitching the Lacto we look for the same pH as we would in any of our other beers (about 5.2). We do a very large pitch of lactic acid bacteria (LAB) and expect to see the pH drop in to our desired range within 6–8 hours. We also exclude oxygen from the process as much as possible and this helps retard unwanted bacteria with no deleterious effects on the LAB. We do not add extraneous acid to our kettle souring process other than to adjust the pH of the brewing water prior to mash-in (which we do for all our beers as our water is quite high in pH).\nAfter the Lacto does its thing we prefer a wort pH of 3.35 to 3.25, but will accept wort between 3.4 and 3.2. We are looking for a clean, bright acidity and don’t want the pH to be less than 3.2 or above 3.4. We also use titratable acidity to judge acidity and its quality of impact. Future fruit additions play into our target sourness level to a lesser extent. We are trying to achieve a harmonious balance of flavors and if a fruit has a very low pH we will factor that into our kettle souring process.\nOther important factors for kettle souring is to get the wort off the grain (as you would with a “normal” beer) and into the kettle. This needs be done to avoid too much bad funkiness that you would probably get in your wort if you did not sour it fast enough. The second thing is sour your wort fast (in less than 24 hours). To achieve that you need to pitch a good amount of LAB into the kettle; slightly more than one million cells per mL per degree Plato. So about 12 million cells per mL for a 11 or 12 degree Plato wort (1.044–1.048 specific gravity). And the third thing is to exclude oxygen as much as you can. This will help keep the bad funk in check. We blanket the top of the kettle with an inert gas to help keep oxygen out of the process.\nFor much more on the subject, I wrote the book on Gose for the Brewer’s Association’s style guideline series and there is a lot of information about kettle souring in there.\nNicole Reiman (right), Head Brewer & Amanda Oberbroeckling (left) Head of the quality control lab at Odd13 Brewing in Lafayette, Colorado\nAt Odd13 we’ve been kettle souring for about five years. We employ this method any time we produce a sour with the intention of canning. The kettle souring method is perfect for our process because it provides us with a finished product that maintains the same flavor through the shelf life of the beer. Conversely, we use traditional souring methods with small experimental batches. Most of these are long-term souring processes, typically using Lactobacillus and Pediococcus and aging in barrels or foeders. We have also experimented with open fermentation in foeders.\nWe get our Lacto from Inland Island Yeast Laboratories, out of Denver, Colorado. We prefer L. delbrueckii because it gives us a quicker sour, keeping the wort at 115 °F (46 °C). In the past we have also worked with several other Lacto species at various temperatures, including L. brevis, and have found that at incorrect temperatures there is either less activity or too much activity. We chose our current temperature based on the recommendation from our supplier.\nOur process across all of our production is to acidify our wort to a pH of 5.2 using lactic acid. Then, after the souring phase, we typically target a pH around 3.5; however, the decision to stop the souring process is ultimately determined from sensory evaluation of the wort. As we expand our portfolio to include more fruited sours we do take into consideration the acidity level of the fruit that will be added to the beer, and adjust the target pH accordingly. This typically results in a higher pH wort so that fruit additions don’t turn the beer too sour.\nThe most important lesson we’ve learned is that kettle souring is its own process that requires great attention to detail, and has its own intricacies that don’t necessarily carry over from traditional brewing methods. The kettle souring process introduces the possibility of less common off flavors, such as isovaleric acid and butyric acid. We’ve learned that it’s important to make sure the process is dialed in — do your homework and come up with a plan before just jumping in. Monitor and control the process, including cleanliness, wort temperature and pH, and gas levels . . . oxygen makes Lacto angry!\nJoe Mashburn, Head Brewer at Night Shift Brewing in Everett, Massachusetts\nWe don’t kettle sour, but rather have a Lactobacillus fermentation phase, followed by a brewer’s yeast fermentation for our Weisse Series releases. We’ve done a single kettle sour and weren’t happy with it, so we moved on from that. Now, we never denature the Lacto and really like the consistency and results of this approach. We produce between 200–300 bbls (6,200–9,300 gallons/235–352 hL) of this style each month. We’ve also used Lacto for more time-intensive Lacto/Brettanomyces/brewer’s yeast fermentations, which are generally destined for oak barrels that will have adequate time for the Lacto to produce acid and the Brett to do its thing.\nFor our Weisse Series beers, we target a pH of 5.2 in the kettle, just from normal mashing/sparging procedures. We haven’t played around with acidifying prior to Lacto additions, mostly because the 5.2 gives us the results we’re looking for.\nWe use a Lacto culture from Lallemand, but we’ve also tried White Labs and Brewing Science Institute. The Lacto from Lallemand is incredibly easy to use and it comes as a dry pitch so it has a very long shelf life. For that addition we knock out at 100 ˚F (38 °C). This has been the same for the two different types of Lacto we’ve tried. When the pH reaches 3.2–3.3 we then pitch the brewer’s yeast. Our sours are heavily fruited, so that low of a pH helps the acid come through.\nWhen working with Lacto, watch your diacetyl production. We’ve had success eliminating and minimizing diacetyl by adding fruit early in fermentation (day 2). Additionally, during the Lacto fermentation, try to eliminate all oxygen. You could hook up CO2 to an oxygen stone and continue to purge during knockout. If you don’t have an oxygen stone, try not to splash during knockout."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:d28ee090-fd8f-4ae7-b3d9-d85d595c6532>","<urn:uuid:1e805fc3-8d79-4d8c-b995-262e985e0b54>"],"error":null}
{"question":"What is the main difference between structured and unstructured log formats, and why does it matter?","answer":"The main difference is that structured logs, like Heroku's key value pair format, have clearly defined fields and values that can be easily identified and analyzed by both humans and machines. In contrast, unstructured or semi-structured flat formats (like syslog, apache, IIS events) lack clear field definitions. This distinction matters because structured logs are more readable, easier to understand, and can be automatically processed by log management services. For example, with structured logs, you can easily search for specific field values and perform analytics like calculating averages over time. Traditional flat log formats make these operations more difficult since they lack defined key names for referencing values in search queries.","context":["Logs are event streams that are constantly spewed from every application, server instance, mobile and IOT device. They contain valuable information pertaining to application errors, system performance, security, feature usage and more.\nLikely, the biggest issue with getting value from log data has been its structure, or lack of it… and while today many systems can produce JSON structured log data with keys and values that can be easily identified and analyzed by both human and machine, the vast majority of log data produced is in a semi- structured flat format e.g. syslog, apache, IIS events.\n127.0.0.1 – frank [10/Oct/2000:13:55:36 -0700] “GET /apache_pb.gif HTTP/1.0” 200 2326\nFlat Apache Log Format\nHeroku Key Value Pair Structure\nThe two examples above of the flat apache log vs. a Heroku key value pair (KVP) structured log highlight the value of adding some structure to your logs. The KVP log is more readable and easier to understand. Furthermore log management services will often identify the fields in KVP structured logs automatically so that you can easily extract and work with the values. For example, in the Heroku log above I can easily search only for logs where the value of the field ‘service’ is greater than 100. I can also then easily work with the results and visualize the average ‘service’ value over time.\nExample Search Query for Heroku Log in Logentries\nResults of Query\nThis has always been harder to do because logs did not have any key names, and you cannot easily reference the values in your search query. Today, however at Logentries we have announced the ability to better define the structure of your logs through our RegEx field extraction using Named Capture Groups .\nThis capability allows you to define a field using RegEx such that you can more easily work with values in flat log events (think syslog, apache, windows event logs, mysql etc.). You can now define and work with field values in almost any log format such that you can start to perform queries and analytical functions on these logs as if they were in a structured format.\nThis can be particularly useful if you cannot change the configuration of your apache logs because they are produced in JSON or if your application produces some strange custom log format and therefore you do not have access to modify the log format.\nOur new RegEx field extraction works by allowing you to identify values in your log events then allowing you to assign a name to these values – similar to having a Key value pair in your log events, using named capture groups. By assigning a name to the identified value(s), these values can be used with advanced search functions such as GroupBy or for calculating Counts, Sums, Averages or Unique Instance Counts. They can also be used for comparisons when creating alerts or tagging events.\nUsing the RegEx field extraction is pretty straightforward and in many cases you don’t need to be a RegEx expert (we’ve provided some nice common examples to help you out). To allow you to extract values from your logs we have followed the RE2 RegEx named capture groups concept. By using the RE2 regex named capture group syntax, you can identify a value and assign it a name which can be used in aggregation functions as in the following example:\n12:12:14 new sales event – customer Tom – total sale 24.45 – item blanket\n12:12:15 new sales event – customer Tom – total sale 100.45 – item jacket\n12:12:16 new sales event – customer Tom – total sale 1000.33 – item computer\nSample Log events\n/total sale (?P<saleValue>\\d*)/)\nSample regex to find the value following ‘total sale’ and assign this value to a named variable ‘saleValue’\nOnce you have identified and named the value you can then reuse the named capture group in a comparison with a search function.\n/total sale (?P<saleValue>\\d*)/ Calculate(Average:saleValue)\nSample Query to find the Average ‘saleValue’ including regex\nExample of using RegEx Named Capture Group Field Extraction\nAdding structure to a log of any format allows us to consider logs as a universal language of communication across teams and systems. We can now take logs in any format, identify the important fields in those logs and begin to analyze those fields. This is useful for both team and inter-system communication. In particular as today’s systems move to the cloud, logs are becoming even more valuable for understanding system and application performance. Why? Well, it is difficult to instrument the cloud or cloud services and, thus, alternative approaches are required to give visibility into cloud-based components which otherwise can become black boxes from a performance or system monitoring perspective.\nWhile it can be difficult to instrument cloud-based components, in general they tend to produce log data streams or provide access to APIs that can be polled to generate data streams. These data streams can be analyzed to give visibility into your systems for a range of different users and use cases, for example:\n- development: performance testing/optimization, error tracking\n- operations: monitoring performance metrics and server resource usage, identifying threshold breaches and anomalies, tracking trends\n- product management: understanding usage metrics and trends in how features are being used (note using logs for usage tracking means no need for complex or expensive BI tools – I like to call it ‘risk free analytics’)\n- marketing: tracking ad campaigns – e.g. via pixel tracking\nSome examples of how logs can also be used as a universal language for intersystem communications:\n- For IT Dev and Ops Automation:\n- Tool integration: logs regularly act as the glue between different tools in your Ops toolkit. For example logs can be used to track errors, send a notification to a third party API (e.g. PagerDuty, Twillio, HipChat) such that it can be communicated with across your team. Similarly log events can be linked into bug tracking tools like Jira such that they provide relevant context to bugs for debugging and resolution.\n- Auto scaling: logs can contain information on server resource usage and are regularly used as a way to track trends in your server metrics and to trigger autoscaling of more servers where resource capacity is reached\n- For IOT:\n- It’s common for IOT devices to spew out streams of data in lots of different custom formats. Often a centralized controller or management portal needs to listen to this data to understand the network of devices and how they are behaving. Being able to translate any log format into meaningful metrics (e.g. using RegEx field extraction) opens up logs as an intermediate language for IOT system communication – expect logs to play a key role in IOT as it continues to grow.\n- For system integration:\n- Users of logentries regularly send events into our system, and then use our open API to extract key metrics or events that act as the input to other components in their system.\nLogs have always captured important information, but due to their unstructured nature they have always been difficult to work with. At Logentries we think of them as a ‘linga franca.’ Linga franca is a Latin term to describe a situation where a third intermediate language is used to make communication possible between persons not sharing a native language. Lingua Franca was actually a mixed language that was used throughout the eastern Mediterranean as the language of commerce and diplomacy in and around the Renaissance era (14th-17th centuries) and was composed mostly of Italian with a broad vocabulary drawn from languages like French, Greek, Spanish, Portuguese and Arabic. If you think about it, logs are very similar insofar as they are a mix of information often pertaining to system errors, user actions, security related events, performance metrics, system load and more…Now with the ability to work with any log format, log management technologies are serving as a translation service allowing for communication through this lingua franca between team members and different systems and devices. Logs are thus fast becoming the universal language of communication for today’s systems."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:acb0e819-4341-46fb-b62a-5ed4e565ed0f>"],"error":null}
{"question":"How does the separation of powers doctrine influence cabinet operations differently in the UK versus US systems?","answer":"The separation of powers affects cabinet operations differently in both systems. In the US, there is a stricter separation, with cabinet members prohibited from being legislators and only able to interact with Congress as witnesses before committees. The UK system, however, follows what Bagehot called a 'close union' or 'nearly complete fusion' of executive and legislative powers, with significant overlap between the executive and legislative branches. UK cabinet members are typically drawn from Parliament and actively participate in legislative activities, while maintaining collective responsibility for government decisions. The US cabinet members are solely part of the executive branch and are individually responsible to the president rather than collectively to the legislature.","context":["cabinet(redirected from Cabinets)\nAlso found in: Dictionary, Thesaurus, Legal, Idioms.\ncabinet,group of advisers to the head of the state who themselves are usually the heads of the administrative government departments. The nature of the cabinet differs widely in various countries. In Great Britain, where the cabinet system originated, it was at first a committee of the privy council and rose to its modern status only after the sovereignty of ParliamentParliament,\nlegislative assembly of the United Kingdom of Great Britain and Northern Ireland. Over the centuries it has become more than a legislative body; it is the sovereign power of Great Britain, whereas the monarch remains sovereign in name only.\n..... Click the link for more information. had been established by the Glorious Revolution of 1688 and the gradual emergence of party government in the 18th cent. The British cabinet is a body of ministers drawn from the party that possesses a majority in the House of Commons; it is responsible to the Commons for the conduct of the administration. The cabinet is chosen by the prime ministerprime minister\nchief member of the cabinet in a parliamentary system of government. The prime minister is head of the government, in contrast with the head of state, who may be a constitutional monarch, as in Great Britain, or an elected official, as in the\n..... Click the link for more information. , who is guided by the necessity of choosing a group that will represent the disparate elements in his party. The defeat in the Commons of an important ministerial measure or a general election adverse to the government results in the fall of the cabinet. In continental European countries, where the two-party system is not the rule, the coalition cabinet is more common. Cabinet members need not be selected from the majority party nor necessarily from the legislature, and they may speak in either house of the legislature.\nThe U.S. cabinet was not specifically established by the Constitution; it evolved through custom and is now defined by statute law. The members of the cabinet are not members of either house of Congress and are responsible, individually and not as a body, to the president, who appoints them with the approval of the Senate and may remove them at will. The cabinet member may not address Congress but may be called as a witness before congressional committees. As an advisory body, the U.S. cabinet is generally a weak institution and is often overshadowed by a strong president and his staff. The first cabinet appointments (1789) were the secretaries of State, the Treasury, and War. Since then the size and composition of the cabinet has varied considerably. Presently the 15 executive departments whose heads sit in the cabinet are the departments of StateState, United States Department of,\nexecutive department of the federal government responsible, under the President's direction, for the making and execution of American foreign policy.\n..... Click the link for more information. ; the TreasuryTreasury, United States Department of the,\nfederal executive department established in 1789. It is charged with advising the president on fiscal policy and acting as fiscal agent for the federal government.\n..... Click the link for more information. ; DefenseDefense, United States Department of,\nexecutive department of the federal government charged with coordinating and supervising all agencies and functions of the government relating directly to national security and military affairs.\n..... Click the link for more information. ; JusticeJustice, United States Department of,\nfederal executive department established in 1870 and charged with providing the means for enforcing federal laws, furnishing legal counsel in federal cases, and construing the laws under which other federal executive departments act.\n..... Click the link for more information. ; the InteriorInterior, United States Department of the,\nfederal executive department established in 1849, delegated custodian of U.S. natural resources, and whose head, the Secretary of the Interior, has cabinet rank.\n..... Click the link for more information. ; AgricultureAgriculture, United States Department of,\nfederal executive department established in 1862, whose head was made a cabinet member in 1889. The department administers federal programs related to food production and rural life.\n..... Click the link for more information. ; CommerceCommerce, United States Department of,\nfederal executive department charged with promoting U.S. economic development and technological advancement. In Feb., 1903, the Congress established a Department of Commerce and Labor empowered to investigate and report upon the operations\n..... Click the link for more information. ; LaborLabor, United States Department of,\nfederal executive department established in 1913 and charged with administering and enforcing statutes that promote the welfare of U.S. wage earners, improve their working conditions, and advance their opportunities for profitable employment.\n..... Click the link for more information. ; Health and Human ServicesHealth and Human Services, United States Department of,\nfederal executive department charged with administering government health programs. Successor to the Department of Health, Education, and Welfare, which had been created in 1953, it was redesignated in 1979 with the\n..... Click the link for more information. ; Housing and Urban DevelopmentHousing and Urban Development, United States Department of\n(HUD), established 1965 to coordinate and administer programs that provide assistance for housing and community development.\n..... Click the link for more information. ; TransportationTransportation, United States Department of,\nexecutive department of the U.S. government, established by the Department of Transportation Act of 1966. Its chief executive officer, the secretary, is a member of the president's cabinet.\n..... Click the link for more information. ; EnergyEnergy, United States Department of,\nexecutive department of the federal government responsible for coordinating national activities relating to the production, regulation, marketing, and conservation of energy.\n..... Click the link for more information. ; EducationEducation, United States Department of,\nexecutive department of the federal government responsible for advising on educational plans and policies, providing assistance for education, and carrying out educational research.\n..... Click the link for more information. ; Veterans AffairsVeterans Affairs, United States Department of,\nfederal executive department established to operate programs to benefit veterans and their families. The department was established in 1989; its predecessor was an independent agency, the Veterans Administration, which had been\n..... Click the link for more information. ; and Homeland Security.\nSee J. E. Cohen, The Politics of the U.S. Cabinet (1988).\nCabinet(religion, spiritualism, and occult)\nThe enclosed space in which a Spiritualist medium works is known as the cabinet. This can be anything from a carefully constructed wooden structure (as was used by the Davenport Brothers) to a simple curtained-off corner of a room. Most mediums favor the latter. According to mediums, the cabinet is necessary in order to condense the psychic energy needed for séance room manifestations. Hereward Carrington compared it to a battery cell that could be charged. The medium usually sits outside the cabinet, though some few do sit inside. The curtains may be dark or light in color; it seems to make no difference.\nSome mediums, such as William Stainton Moses, and Daniel Dunglas Home, never used a cabinet. Eusapia Paladino was typical of those who, although they had a cabinet, sat outside it; about twelve inches away from the material of the cabinet. Materializations—such as a hand—emerged from the cabinet behind her. Sir Arthur Conan Doyle described the medium Eva C. using a cabinet that was “a small space shut in by curtains at the back and sides and top, but open in front.”\nWhen Harry Houdini was investigating the medium Mina Crandon, he designed a special cabinet in which she could sit with only her head and hands visible. The second time this cabinet was used, Mina Crandon’s spirit guide, Walter, accused Houdini of placing incriminating evidence inside the cabinet, to be discovered after the séance. This was found to be a folding ruler. Houdini denied the charge and in turn accused Mina of planning to use the ruler to manipulate a small box. After Houdini’s death in 1926, an assistant of his confessed that he had placed the ruler there, on Houdini’s instructions.\nThe Davenport Brothers had a special cabinet made with three doors at the front and a bench inside, running the full length of the cabinet. The center door had a small diamond-shaped opening covered by a curtain, through which various phenomena could manifest. The Davenport Brothers performed at theaters and would allow audience members to examine the cabinet before the start of their performance. They would then sit astride the bench, facing one another, where they were securely tied so that they could not move. Within seconds of the doors being closed, rappings, musical sounds, and a wide variety of phenomena occurred. At the end of the show they were discovered still tightly bound.\nthe official designation for the government in several foreign countries, including Great Britain, India, Zambia, Kenya, the United States, Tanzania, and Japan. It is headed by either a prime minister (Great Britain, India, and Japan) or a head of state, such as a president (USA, Zambia, Kenya, and Tanzania). In some countries, such as Great Britain and India, the cabinet does not include every member of the government; it consists only of the prime minister and the ministers heading the most important governmental offices (for example, the ministers of defense, foreign affairs, finance, and domestic affairs).","2.1.2 Constitutional Institutions Lecture\nThe Separation of Powers\nPublic law regulates the relationship between the state and its organs, and private citizens. Public law is a shorter way of describing constitutional and administrative law. Constitutional law is the law that provides a state framework and establishes its principle institutions and the interrelationships between these institutions. Administrative law confers the legal powers and legal duties of public bodies and authorities.\nThe separation of powers serves an essential democratic function, since it enables the three main powers of the state to act as a check on the absolute exercise of power. These powers are divided between three principle branches of government. Firstly, the legislative branch has powers to create legislation and to represent the views of the people. Second, the judicial branch is the systems of courts and tribunals who have powers to interpret legislation passed by the legislature and to adjudicate on legal disputes. Thirdly, the executive branch has the responsibility of making and implementing public policy.\nIn The Spirit of Laws, Montesquieu warned against the use of power in a 'tyrannical manner' if it was not divided between the three branches of government. Much of his observations were carried out within the court of George II in England, moving in political circles and formulating much of his work based on the English government of the time.\nModern democracies tend now to exist as a partial, or 'checks and balances', conception of the separation of powers, which includes the ability of one branch to involve itself in issues that are primarily the concern of another branch.\nAlthough very few countries adhere rigidly to the separation of powers doctrine, most constitutional systems do attempt some form of demarcation between the legislature, executive and judicial organs of government to avoid abuse of power by any one of the three branches.\nSeparation of Powers and the Constitution\nThere are various different views as to whether the doctrine is part of the UK constitution. In Hinds v The Queen  AC 195, Lord Diplock stated that he was certain that\n'the basic concept of the separation of legislative, executive and judicial power...had been developed in the unwritten constitution of the United Kingdom'(at 212).\nIn The English Constitution (London, 1867) Bagehot argues that the\n'efficient secret of the English Constitution may be described by the close union, the nearly complete fusion, of the executive and legislative powers\".\nThere is a significant overlap in the work of the executive and the legislative branches, with the executive exerting a substantial influence over the work of Parliament. At the same time, there are examples where separation of powers is strictly adhered to, such as in relation to the independence of the judiciary.\nIn R v Secretary of State for the Home Department, ex p Fire Brigades Union  2 AC 513 a majority held that the Home Secretary had exceeded his powers in refusing to implement a statutory compensation scheme. The minority judgment held that since the legislation was not yet in full force, it was inappropriate for the court to intervene, making judicial intervention a breach by the judiciary of the separation of powers doctrine. The case illustrates how a different emphasis on one particular aspect of the separation of powers can lead to a different conclusion.\nThe Institutions - the Executive\nThe executive branch of the UK government is comprised of the Head of State, or monarch, the Prime Minister, the Cabinet, Secretaries of State, ministers of the Crown, departments of state, other public bodies, devolved administrative bodies, local authorities, the police and the military.\nThe Prime Minister is appointed by the Head of State; if appointed after a General Election, this takes place soon after the outcome is announced.\nFigure 1: The UK Executive\nThe powers of the executive\nPrimarily the executive has a vast array of statutory powers afforded to it by Parliament. Since Parliament is unable to legislate for every eventuality, the Inquires Act 2005 makes provision for inquiries into matters of public concern.\nThe Prime Minister's powers come from the Royal Prerogative and statute. He or she has a role to advice the monarch on:\n- the exercise of all powers of entitlement which concern the government;\n- the appointment of all members of the judiciary, heads of the security services and senior officers in the Church of England.\nThe Prime Minister also appoints senior officers in the armed forces, and recommends honours or life peerages. The Prime Minister also makes decisions regarding the Cabinet, such as determining its size, controlling its agenda and creating and disbanding Cabinet Committees.\nThe Cabinet is chosen by the Prime Minister and appointed by the monarch. It functions to consider questions which concern the collective responsibility of government and are of critical importance to the public. The Cabinet determines the contents of the Queen's speech, the legislative timetable and the broad economic policy, which establishes the basis of the Chancellor of the Exchequers budget.\nStanding and ad hoc Cabinet Committees are empowered by the Cabinet to deal with matters of current importance. Collective cabinet responsibility was endorsed in AG v Jonathan Cape  QB 752,  3 All E R 484.\nThe Civil Service is required to act in a way that is independent of any political party. The advantage of this was said to be the element of stability despite political change in Parliament, Northcote-Trevelyan, Report on the Organisation of the Permanent Civil Service (House of Commons, 1854).\nDevolution in the UK means that executive powers have been conferred upon executive organisations within Scotland, Wales and Northern Ireland.\nThe Scottish Government was established by part II Scotland Act 1998; it consists of the First Minister, the Scottish Ministers and the Scottish Law Officers. The Government of Wales Act 1998 (sections 52-55) established the Welsh Assembly. The Government of Wales Act 2006 establishes the Welsh Assembly Government, which is separate from the Welsh Assembly. The Northern Ireland Act 2000 suspended the Northern Ireland Assembly, but this was re-established by the Northern Ireland Act 2006, along with a Northern Ireland First Minster and other Ministers.\nLocal Government in England consists of areas of counties, districts, and unitary authorities created by the Local Government Act 1972, as amended in 1985 and 1992. Greater London and the Metropolitan Police District were established by the London Government Act 1963, the Local Government Act 1985, the Police Act 1996, and the Greater London Local Authority Act 1999.\nIn Wales, the Local Government (Wales) Act 1974 established twenty-two Unitary Authorities in Wales.\nScotland in made up of twenty-nine Unitary Authorities and three Island Authorities, according to the Local Government (Scotland) Act 1974.\nNorthern Irelandconsists of the parliamentary counties of Antrim, Armagh, Down, Fermanagh, Londonderry and Tyrone and the parliamentary boroughs of Belfast and Londonderry. This is provided for in section 43(2) Northern Ireland Constitution Act 1973.\nThe police forces in the UK are part of the executive. The Police Act 1996 and the Police Reform Act 2002 contain provision for the organisation of the police forces and police areas in England and Wales.\nThe Institutions - Parliament (Legislature)\nThe UK Parliament is comprised of the House of Commons (or lower house) and the House of Lords (the upper chamber). Local voters in general elections elect members of Parliament within the lower house. Finally, the monarch is formally the head of Parliament, and is required to give royal assent to legislation.\nHouse of Commons\nMember of the House of Commons are elected directly by UK citizens.\nThe House of Commons as the representative assembly has come under criticism for its ability to represent the will of the people in the UK, in that:\n- The current system of elections does not represent all parties equally within Parliament\n- The House of Lords is unelected, however, it plays an important role in the making of the countries laws;\n- There are insufficient women and ethnic minority MPs to represent the electorate.\nThere is no particular consensus on how MPs should represent their constituents.\nHouse of Lords\nThe second and upper chamber is the House of Lords, whose members are peers. The vast majority of peers are life peers who are appointed to the chamber and remain members for their lifetime. This is provided for in the Life Peerages Act 1958, which also permitted women to sit in the House of Lords. The House of Lords also retains ninety-two hereditary peers, who have inherited their title. The number of hereditary peers reduced signification due to the passage of the House of Lords Act 1999; the current hereditary peers will remain as members of the Lords for their lifetime. Twenty-six bishops and archbishops (referred to as Lords Spiritual) of the Church of England are also members of the House of Lords until they retire from the roles in the Church.\nThe democratic legitimacy of the House of Lords has been drawn into question since they are not an elected body through the system of universal suffrage and cannot be removed by the electorate, since their role in the House of Lords is through appointment or inheritance. The House of Lords is going through a long-term period of reform, and a number of proposals have been made to improve its democratic legitimacy.\nFunctions of Parliament\nThe House of Commons Select Committee on Procedure (First Report, 1987) concluded that there were four main areas of Parliamentary responsibility. These include enacting legislation, scrutinising the executive, controlling public spending and address the concerns of their constituents. Parliament's legislative role is the enactment of primary and secondary legislation, which is said to respond to social, economic and political changes in society, which require new laws to be made.\nThe House of Lords and the House of Commons perform distinct functions in relation to the creation of legislation. This is known as a bicameral system with two chambers that perform different functions. The House of Lords acts as a check on the abuse of power by the executive, by blocking legislation that the House of Commons have proposed. The House of Lords may delay legislation; however, under the Parliaments Acts of 1911 and 1949, it cannot be prevented if the House of Commons agree that it should be passed.\nThe Institutions - The Judiciary\nThe primary role of the Judiciary is to adjudicate on legal disputes that are brought before courts and tribunals in the UK. The primary sources of law in the UK are legislation or Acts of Parliament and the common law. The judges' role is in the interpretation of legislation and in the development of the common law. Judicial independence is of primary importance, it has implications for its relationship with the executive and Parliament, and provides public confidence in the judge's ability to adjudicate on disputes in an impartial manner.\nOne of the primary roles of the court systems is in holding the executive to account, by introducing accountability for the performance of public functions. This involves the checking, controlling and regulating of those functions.\nThe Senior Court Act 1981 and the Civil Procedure Rules are the most important legal instruments governing judicial review. In order to bring a claim for judicial review, claimants must illustrate at least one ground for judicial review is satisfied, or that a public authority has acted in a way that is incompatible with a human right included within the European Convention on Human Rights and Fundamental Freedoms 1950 (ECHR).\nIn Council of Civil Service Unions v Minister for the Civil Service  AC 374, three grounds for judicial review were elucidated:\n- procedural impropriety\nThe Human Rights Act\nThe Human Rights Act 1998 (HRA) gives effect to the ECHR in UK law.\n- When interpreting the Convention section 2HRA, a UK court must take into account any judgement, decision or declaration or advisory opinion of the European Court on Human Rights (ECtHR).\n- Section 3 HRA provides that courts must give effect to UK legislation in a manner that is compatible with the ECHR.\n- If not possible to interpret in accordance with section 3, section 4HRA enables the higher courts to grant a declaration of incompatibility stating that a statutory provision in inconsistent with the ECHR.\nR v A (No.2)  UKHL 25;  1 AC 45 illustrates how legislation introduced to promote complainants in rape cases from coming forward and reporting the crimes committed against them, and hence serving a public function, can still be overruled when the human rights of the accused are prioritised.\nThe European Union\nAlthough the UK's membership within the European Union is currently in question, the EU is still of considerable relevance in UK law and governance.\nThe European Union as exists today was established in 1992 during a meeting of the heads of state or government of the Member States in which the TEU was signed at Maastricht in the Netherlands. The TEU made significant changes to the provisions of the preceding EC Treaty, including strengthening the powers of the European Parliament and establishing the foundations of the economic and monetary union.\nThe European Council\nThe European Council has no legislative function, but is to 'define the general political directions and priorities of the [EU]'(Art 15(1) TEU). It is made up on heads of state or government of Member States, its President, and the President of the Commission.\nThe Council of the EU\nThe Council is the hardest of the EU institution to place within the three branches of government advocated within the separation of powers doctrine. The Council considers legislation initiated by the Commission.\nThe Commission carries out both executive and legislative functions. It is made up of a Commissioner from each of the Member States, who looks after a particular area of responsibility (e.g. trade and industry, competition).\nThe European Parliament consists of directly elected citizens of the Member States to exercise powers endowed upon it under the TEU and TFEU. In the UK, elections to the European Parliament are governed by the European Parliamentary Elections Act 2002. The Act provides for a system of proportional representation for election of MEPs. Article 14(2) of the TEU provides that the European Parliaments membership shall not exceed 750, in addition to the President of the Commission.\nThe Court of Justice of the European Union\nThe CJEU sits in Luxemburg and its membership consists of one judge per member state (Art 19(2) TEU). The rules of the court allow it to sit as the full court or in chambers of as a Grand Chamber. The primary function of the Court is to ensure that in the interpretation and application of the Treaty, the law is observed.\nCourt of Justice of the EU\nCourt of Auditors\nFigure 2: The separation of powers in the European Union\nCite This Module\nTo export a reference to this article please select a referencing style below:"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:885b5fe1-69de-4b2f-bf3a-2ab0178f1648>","<urn:uuid:aa61647a-bf32-4b30-b161-99f7f5b61ab7>"],"error":null}
{"question":"Do binary operations in monoids and thread scheduling both involve working with pairs of elements?","answer":"Yes. Monoids are defined by binary operations that work on two values of the same type, while thread scheduling operations like zip and merge (<>) also operate on pairs of threads, combining them according to specific rules.","context":["Let's imagine that a thread is just a list of values:\ntype Thread a = [a]Each a represents one atomic step in our thread.\nNow let's assume we have two such threads and we need to schedule them. The simplest way to schedule them would be to interleave them:\nzip :: Thread a -> Thread a -> Thread a zip  ys = ys zip xs  = xs zip (x:xs) (y:ys) = x:y:zip xs ysHowever, I can think of three obvious problems with this approach. First, it is not associative:\n(xs `zip` ys) `zip` zs /= xs `zip` (ys `zip` zs)Second, it assumes that all thread actions have equal priority, which probably isn't the case.\nWe can fix this by switching to cooperative threads which can either provide a value, yield \"left\" or yield \"right\":\ndata Step a = YieldL | Step a | YieldR type Thread a = [Step a]Now, we can merge threads in such a way that respects their yields:\n(<>) :: Thread a -> Thread a -> Thread a  <> ys =  (YieldL:xs) <> ys = YieldL:(xs <> ys) (Step a:xs) <> ys = Step a:(xs <> ys) (YieldR:xs) <> (YieldL:ys) = (xs <> ys) -- From this point onward, xs = YieldR:xs' xs <> (Step a:ys) = Step a:(xs <> ys) xs <> (YieldR:ys) = YieldR:(xs <> ys) xs <>  = Interestingly, this new operation is associative:\n(xs <> ys) <> zs = xs <> (ys <> zs)It also has an empty thread which acts like an identity:\nmempty = YieldR:YieldL:mempty mempty <> xs = xs xs <> mempty = xs\nWhile working on Proxys, I discovered they had certain nice mathematical properties:\nreturn <-< g = return (respond >=> f) <-< g = respond >=> (f <-< g) (lift . k >=> f) <-< g = lift . k >=> (f <-< g) (request >=> f) <-< (respond >=> g) = (f <-< g) -- For the following equations, f = request >=> f' f <-< (lift . k >=> g) = lift . k >=> (f <-< g) f <-< (request >=> g) = request >=> (f <-< g) f <-< return = returnNow, where have I seen that before? Why, these are identical the equations for the above list merge, except we need to make the following substitutions to make the analogy complete:\n(>=>) -> (++) return ->  respond -> [YieldL] request -> [YieldR] lift . k -> , [Step a], [Step a, Step a'] ... (<-<) -> (<>)Well, if those substitutions were correct, we'd expect that we could use them to derive the correct form for idT:\nmempty = YieldR:YieldL:mempty mempty = [YieldR] ++ [YieldL] ++ mempty idT = request >=> respond >=> idT... and it works!\nThis is what I mean when I say that Proxy composition is just merging lists of Kleisli arrows.\nI was a little bit skeptical at first when I had to give Proxys an extra input parameter to get them to be composable. However, the surprising connection to lists of Kleisli arrows convinced me that the Kleisli arrow is the true currency of concurrency.","Monoids by Mark Seemann\nIntroduction to monoids for object-oriented programmers.\nThis article is part of a larger series about monoids, semigroups, and related concepts. In this article, you'll learn what a monoid is, and what distinguishes it from a semigroup.\nMonoids form a subset of semigroups. The rules that govern monoids are stricter than those for semigroups, so you'd be forgiven for thinking that it would make sense to start with semigroups, and then build upon that definition to learn about monoids. From a strictly hierarchical perspective, that would make sense, but I think that monoids are more intuitive. When you see the most obvious monoid example, you'll see that they cover operations from everyday life. It's easy to think of examples of monoids, while you have to think harder to find some good semigroup examples. That's the reason I think that you should start with monoids.\nMonoid laws #\nWhat do addition (\n40 + 2) and multiplication (\n6 * 7) have in common?\n- binary operations\n- with a neutral element.\nBinary operation #\nLet's start with the most basic property. That an operation is binary means that it works on two values. Perhaps you mostly associate the word binary with binary numbers, such as 101010, but the word originates from Latin and means something like of two. Astronomers talk about binary stars, but the word is dominantly used in computing context: apart from binary numbers, you may also have heard about binary trees. When talking about binary operations, it's implied that both input values are of the same type, and that the return type is the same as the input type. In other words, a C# method like this is a proper binary operation:\npublic static Foo Op(Foo x, Foo y)\nOp is an instance method on the\nFoo class, it can also look like this:\npublic Foo Op (Foo foo)\nOn the other hand, this isn't a binary operation:\npublic static Baz Op(Foo f, Bar b)\nAlthough it takes two input arguments, they're of different types, and the return type is a third type.\nSince all involved arguments and return values are of the same type, a binary operation exhibits what Eric Evans in Domain-Driven Design calls Closure of Operations.\nIn order to form a monoid, the binary operation must be associative. This simply means that the order of evaluation doesn't matter. For example, for addition, it means that\n(2 + 3) + 4 = 2 + (3 + 4) = 2 + 3 + 4 = 9\nLikewise, for multiplication\n(2 * 3) * 4 = 2 * (3 * 4) = 2 * 3 * 4 = 24\nExpressed as the above\nOp instance method, associativity would require that\ntrue in the following code:\nvar areEqual = foo1.Op(foo2).Op(foo3) == foo1.Op(foo2.Op(foo3));\nOn the left-hand side,\nfoo1.Op(foo2) is evaluated first, and the result then evaluated with\nfoo3. On the right-hand side,\nfoo2.Op(foo3) is evaluated first, and then used as an input argument to\nfoo1.Op. Since the left-hand side and the right-hand side are compared with the\n== operator, associativity requires that\nIn C#, if you have a custom monoid like\nFoo, you'll have to override\nEquals and implement the\n== operator in order to make all of this work.\nNeutral element #\nThe third rule for monoids is that there must exist a neutral value. In the normal jargon, this is called the identity element, and this is what I'm going to be calling it from now on. I only wanted to introduce the concept using a friendlier name.\nThe identity element is a value that doesn't 'do' anything. For addition, for example, it's zero, because adding zero to a value doesn't change the value:\n0 + 42 = 42 + 0 = 42\nAs an easy exercise, see if you can figure out the identity value for multiplication.\nAs implied by the above sum, the identity element must act neutrally both when applied to the left-hand side and the right-hand side of another value. For our\nFoo objects, it could look like this:\nvar hasIdentity = Foo.Identity.Op(foo) == foo.Op(Foo.Identity) && foo.Op(Foo.Identity) == foo;\nFoo.Identity is a static read-only field of the type\nThere are plenty of examples of monoids. The most obvious examples are addition and multiplication, but there are more. Depending on your perspective, you could even say that there's more than one addition monoid, because there's one for integers, one for real numbers, and so on. The same can be said for multiplication.\nThere are also two monoids over boolean values called all and any. If you have a binary operation over boolean values called all, how do you think it works? What would be the identity value? What about any?\nI'll leave you to ponder (or look up) all and any, and instead, in the next articles, show you some slightly more interesting monoids.\n- Angular addition monoid\n- Strings, lists, and sequences as a monoid\n- Money monoid\n- Convex hull monoid\n- Tuple monoids\n- Function monoids\n- Endomorphism monoid\n- Maybe monoids\n- Monoids accumulate\n==operator. On the other hand, there's no\nTimeSpan, because what does it mean to multiply two durations? What would the dimension be? Time squared?\nA monoid (not to be confused with a monad) is a binary operation that satisfies the two monoid laws: that the operation is associative, and that an identity element exists. Addition and multiplication are prime examples, but several others exist.\n(By the way, the identity element for multiplication is one (1), the all monoid is boolean and, and the any monoid is boolean or.)\nNext: Angular addition monoid"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:2896aacc-26ea-411a-8f7a-60ad54a10f50>","<urn:uuid:7d03a359-5b99-48f4-87af-5490ca964c36>"],"error":null}
{"question":"I work in corporate strategy. Could you explain the key differences between inventory exclusions and target exclusions in science-based emissions targets, and how do they relate to Deloitte Australia's emission reduction commitments?","answer":"Inventory exclusions and target exclusions are distinct concepts in emissions reporting. Inventory exclusions allow companies to exclude up to 5% of their scope 1 and 2 emissions and up to 10% of scope 3 emissions due to data constraints. In contrast, target exclusions refer to emissions that are reported in the inventory but not covered by the science-based target boundary. Looking at Deloitte Australia's commitments, they have set comprehensive targets without notable exclusions, aiming to reduce absolute scope 1 and 2 emissions by 70% by 2030 from a 2019 base year, and scope 3 emissions from business travel by 50% per FTE in the same timeframe.","context":["Ten tips for completing the Near-Term Submission Form\n29th Jul 2022\nIf your company is committed to reducing its emissions, setting near-term science-based targets is the first step in your decarbonization journey. Defining how your company will reduce its emissions by 2030, 1.5°C-aligned near-term targets enable you to begin taking science-aligned action to slash emissions today, while paving the way for a pathway to net-zero by 2050 via the SBTi’s Net-Zero Standard.\nOnce your company has committed to the SBTi and developed a target, it must then be validated by the SBTi’s Target Validation Team (TVT) as aligned with climate science. The near-term submission form gives the TVT the information they need to do this.\nIf this form isn’t completed correctly, it can cause delays to the process - preventing your company from aligning its climate action with limiting global temperature rise to 1.5°C - which the IPCC tells us is necessary to avoiding the worst climate carnage.\nThese top tips will help you avoid the most common mistakes when completing your near-term submission form.\n1: Only give us the facts\n- Do: Provide clear, factual descriptions of business activities\n- Don’t: Give us marketing copy\nWhen it comes to providing a detailed description of business activities in section 1.2.7 of the submission form, companies must provide factual information only. This includes, but is not limited to:\nAny distinct business divisions, including percentage breakdown by revenue/business activity.\nExplanation of products sold.\nExplanation of services your company offers and procures.\nYour company’s place within the value chain of each business area, and description of operations.\nGeographical markets your company operates in.\nDon’t provide us with marketing content, such as a company overview from your website’s homepage. This won’t give us the information needed, and will delay your submission while we reach out to you for clarification.\nCaitlin explains what sort of information we need from your company.\n2: Explain your emissions\n- Do: Include details across all categories of your emissions generating activities\n- Don’t: Just provide emissions calculation numbers\nIn order to assess and approve your target, we need to understand all your company's business activities and associated emissions-generating activities. Emissions calculation numbers alone are not enough: We require companies to provide 50-100 words per emissions category (such as purchased goods and services; capital goods; and fuel and energy related activities) to explain the operations, locations, activities and emission sources. We also need adequate justification if a category is not relevant to your company.\nThis helps us ensure that all angles have been considered and your emissions have been calculated accurately. If you need to omit a category, provide a detailed justification as to why it’s not relevant so as to not slow down the validation process.\n3: Justify your greenhouse gas inventory\n- Do: Explain how data reflects your emissions\n- Don’t: Just provide the figures with no justification\nBecause it can be difficult to acquire primary scope 3 data on real activities, we allow companies to develop targets based on secondary data. However, both primary and secondary data must be presented with a detailed justification of the emission estimates, and why secondary data reflect the company’s real-world emissions.\nDon’t just include the figures: You must justify the business activities associated with each scope and category, and provide a high-level overview of the methodological calculations and any associated assumptions that were used to generate each estimate.\nThis will give our validation team the information needed to assess the target without having to contact you for further explanation.\n4: Understand the difference between inventory exclusions and target exclusions\n- Do: Account for at least 95% of scope 1 and 2 emissions and 90% of scope 3 emissions\n- Don’t: Confuse GHG inventory exclusions with exclusions from the target boundary\nIn order to allow for data constraints within the greenhouse gas (GHG) inventory, companies are allowed to exclude no more than 5% of their GHG emissions from their scope 1 and 2 submission, and no more than 10% for scope 3. This is known as an inventory exclusion, and shouldn’t be confused with target exclusions.\nTarget exclusions refer to emissions that are reported in the inventory, but are not covered by the science-based target. This is known as the target boundary.\n5: Understand the difference between omissions and emissions\n- Do: Detail any omitted greenhouse gasses\n- Don’t: Say that gasses you don’t actually emit are omitted gasses\nIn sections 2.5.1 and 2.5.2 of the submission form, you must detail gasses that have been omitted from your accounting. These are gasses that your company emits, but have not been accounted for in the submission form.\nDon’t confuse these with gasses that your company does not actually emit.\n6: Provide accurate growth projections\n- Do: Ensure growth projections are as accurate as possible\n- Don’t: Omit justification of growth projections\nGrowth projections must reflect the actual emissions that are being produced. If these are not accurate, companies may find achieving the target is easier - or more difficult - than anticipated.\nTo guard against this, justify growth projections by providing reasoning or supporting documentation, such as your company's business development strategy. All information shared is confidential.\n7: ‘Category 15: Investments’ may apply to you - even if you aren’t a financial institution\n- Do: Read the GHG Technical Guidance for Calculating Scope 3 Emissions\n- Don’t: Assume this category is irrelevant to your company\nMany companies assume that because they aren't a financial institution, this category isn’t relevant to them, but this isn't always the case.\nTo find out if this category is relevant to your company, review pages 130 - 135 of the GHG Protocol Scope 3 Technical Guidance for Calculating Scope 3 Emissions.\nAs explained in the guidance, companies that choose an operational or financial control consolidation approach to calculate their GHG inventory should account for emissions from any asset the company wholly or partially owns but does not control, in category 15. This relates to any subsidiaries, joint ventures, financing or other activity or project, that your company has a financial stake in but that does not sit within the organizational boundary.\nScope 1 and 2 emissions from these activities should be reported in scope 3 category 15 proportionate to your company’s equity share.\nThis category is especially important for companies to account for, not only so the GHG inventory is complete, robust, and accurate. but it also gives you visibility over the emissions sources your company profits from.\nWatch Phoebe explain why Category 15 may be applicable to your company.\n8: Correctly understand your scope 3 target coverage\n- Do: Fill in the percentage of the category’s emissions which are to be included in the target\n- Don’t: Label categories as ‘not applicable’ just because the value of emissions is low\nCompanies with scope 3 emissions that exceed 40% of total emissions must set scope 3 targets. Under version 5 of the SBTi’s criteria, these targets must at least be aligned with the well-below 2°C temperature pathway.\nAt least 67% of scope 3 emissions must be covered by near-term targets in total, whether that is multiple targets covering smaller portions of scope 3 emissions or one target covering various categories. For net-zero targets, at least 90% of scope 3 emissions must be covered. Because of this requirement, the SBTi always recommends maximizing target coverage. This to ensure the step between near-term and net-zero targets is as easy as possible and as well as maximizing real-world emissions reductions.\nIn table 3.1.5 of the near-term submission form, companies are requested to provide the percentage of emissions covered within each category to determine the coverage of near-term targets. For example, if a company wants the target boundary to include all category 1 emissions, then 100% must entered into the corresponding cell in the table.\nCompanies often mistakenly enter the percentage of total scope 3 emissions each category is responsible for, or the percentage of the total target’s coverage in each category. This results in confusion regarding target coverage.\nDo not provide\n✓ Percentage of emissions covered within each category\n⨯ Percentage of total scope 3 emissions each category is responsible for\nLucas outlines how to approach completing Table 3.1.5.\n9. Don’t confuse upstream and downstream transportation and distribution emissions\n- Do: Ensure you allocate upstream and downstream emissions based on who is paying for the service\n- Don’t: Incorrectly categorize your transportation and distribution emissions based on if the service is inbound or outbound\nScope 3 categories 4 and 9 relate to transportation and distribution emissions, including refrigeration, freezing and heating services for storage of items being distributed. These categories cover any transportation emissions between a company’s own facilities and the next person or business to receive the goods or services.\nThe GHG Protocol defines these categories as upstream or downstream based on who purchased these third-party services.\nUpstream means that the company setting the science-based target paid for these services.\nDownstream means the services were paid for by any other entity, such as customers or suppliers.\nEnsure you do not confuse these terms and allocate your emissions correctly.\nGuillermo breaks down the difference between upstream and downstream emissions.\n10: Assess your company’s future activities accurately\n- Do: Select a base year that is representative of future business activities and operations\n- Don’t: Under- or overestimate your base year\nAnticipating your company's future business operations is extremely important as it ensures your decarbonization approach is as ambitious as possible.\nDoing this correctly means getting three things right:\n1. An accurate representative base year inventory\nHaving a representative base year inventory is very important as this is what your company’s future emissions reductions will be based on.\nAn over-inflated base year GHG inventory can create a situation where emissions reductions can be reported as having occurred, without any actual change in real world emissions. While a base year inventory that is too low will lead to unachievable or unrealistic targets.\n2. Covid-impacts assessment\nThe Covid-19 pandemic changed the emissions profiles of many industries. While some industries are likely to bounce back to their old ways of working and thus emissions patterns, many sectors, such as the professional services sector, are adapting to a new, post-pandemic style of working.\nWhen setting a base year, consider whether the base year selected is representative of your company’s future business activities and operations. This will ensure that your targets result in ambitious decarbonization, that goes beyond what will happen thanks to evolving business practices in your sector.\n3. Forward looking ambition\nIf your company has already been taking decarbonization action before joining the SBTi, your target must lead to further action from the point of submission. That is why your target must have sufficient forward-looking ambition: To ensure it is not already achieved at the point it is being set.\nWe hope these tips help you to complete your near-term submission form successfully, and we look forward to evaluating your target.\nIf there are other SBTi tools and processes that you think would benefit from an explainer blog or video, get in touch at email@example.com.","Deloitte Australia believes climate change is one of the biggest shared challenges facing humanity. We believe in the science of climate change and the economic and commercial risks inaction poses to our society, economy, communities, and businesses.\nAs business leaders, policy influencers and individual citizens, we recognise the need for comprehensive action. Doing nothing is not an option, and it is not without cost. There will be tangible long-term benefits by acting now.\nOur commitment to change\nTaking tangible climate action is an absolute priority for us. We’re acting on this through reducing our carbon footprint, supporting our clients and using our voice.\nDeloitte’s near-term (2030) greenhouse gas (GHG) reduction goals have been validated by the Science Based Targets initiative (SBTi) as 1.5°C-aligned, science-based targets. Deloitte has also committed to set long-term emissions reduction targets using the SBTi’s Net Zero Standard.\nOur near-term goals are to:\n- Reduce absolute Scope 1 and 2 GHG emissions 70% by 2030 from a 2019 base year.\n- Reduce Scope 3 GHG emissions from business travel 50% per FTE by 2030 from a 2019 base year.\n- Engage with our major suppliers with the goal of having 67% (by emissions) set science-based targets by 2025.\n- Invest in meaningful market solutions for emissions we cannot eliminate.\nOur additional 2030 goals to reduce emissions include:\n- Sourcing 100% renewable energy for our buildings\n- Converting 100% of our fleet to hybrid and electric vehicles\nDeloitte’s near-term goals (2030) were validated in advance of the issuance of the SBTi Net-Zero Standard. Deloitte’s next step will be to set long-term emissions reduction targets following the SBTi standard to continue playing our part in achieving a net-zero world.\nAs a professional services firm, we work with our clients through the process to achieve sustainable operations and responsible climate choices.\nIn working with organisations, we take the following positions:\n- We will actively work with new and emerging low emissions intensive industries and businesses to help them establish themselves in crafting a new system of production in Australia\n- We will actively advise and work with high emissions intensive businesses to effectively manage their way through this major transition\n- We will work with regulators and governments to ensure that best practice regulation and policy is in place to support Australia’s economic growth, jobs, and as a leader in decoupling the economy from emissions\n- We will actively work with all sectors to help them understand the physical impacts of climate change and develop adaptation and response pathways, and\n- We will actively work with other businesses, communities, and governments to ensure that our economy makes a responsible and equitable transition to a new future.\nWe will participate in the discussions on government policies and actions on climate change that are in the best interests of a sustainable and prosperous future. Policies aimed at strengthening economic growth can support low-emission pathways; and actions to stimulate investment in low-emission investments can strengthen economic growth and job creation.\nAs a global firm, we will draw on our vast experience with business, communities, governments and regulators, alongside our research and analytical expertise to contribute a balanced debate on climate change."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:4cd5b53f-0dc1-418f-ab73-d8bb3be2b84c>","<urn:uuid:d63cf17d-1e7f-4566-8cc4-b19d16392cd4>"],"error":null}
{"question":"How does Atlanta's Midtown transit development affect housing density, and what broader lessons can be drawn about the relationship between transit and housing affordability in US cities?","answer":"Atlanta's Midtown transit development shows a push toward higher density near MARTA rail lines, with the area allowing construction of three to four story residential buildings and five to six story commercial buildings. The city's comprehensive plan calls for high-density commercial development throughout Midtown, with plans for high-density and very high-density residential buildings nearby. Regarding broader implications, transit-oriented developments are crucial for housing affordability as they allow for greater density, encourage public transportation, and create business opportunities along transit corridors. Additionally, living near transit saves on transportation costs, allowing that money to be used for housing. However, while transit can make neighborhoods more desirable and revitalize areas, this often leads to increased housing costs and potential displacement of existing residents. To address this, cities need supportive public policies like inclusionary zoning, value capture, and zoning for greater density to ensure private development creates more affordable housing alongside transit investment.","context":["Atlanta’s growth has, for decades now, been a quintessential example of Sunbelt sprawl. While the city has some tall buildings downtown, the metro area is more an amalgamation of smaller activity centers. When measured by population density, its urban core is less dense than even downtown Los Angeles, as Alain Bertaud’s recent book makes clear with the image below.\nSource: Alain Bertaud, Order Without Design, p. 64, December 2018\nBut pressure is building for Atlanta’s downtown to grow. Norfolk Southern recently announced a move to Midtown, bringing more than a thousand jobs to the streets beside Georgia Tech. The last few years have seen Midtown’s street parking lots give way to buildings at the maximum allowed local density, a sign that Atlanta is feeling the same pressures of gentrification that fuels angst in other big cities. Fortunately, Atlanta has planned for this. Their comprehensive plan calls for “high-density commercial” development in all of Midtown, with areas of “high density” and “very high density” residential buildings nearby.\nYet including an idea in a comprehensive plan is different from changing city zoning codes to allow for planned development. Below are a few changes Atlanta might want to consider if it wants Midtown to grow into the dense, transit-oriented neighborhood it envisions.\n1. Simplify and merge zoning districts\nA simple reading of Midtown’s zoning code reveals a pair of neighborhood-specific zones that cover most of the core of Midtown. Both are codified as “Special Public Interest”, or SPI, zones, that exist only in one neighborhood and can be changed without altering zoning in the city at large. SPI-16 regulates the areas within a few blocks of Midtown’s rail lines, while SPI-17 regulates areas along Piedmont Street further east.\nLeft: SPI-16 and SPI-17 with subareas. Right: Midtown future land use. Source: City of Atlanta\nOn the surface, this seems like a reasonable policy decision. Special zoning near transit can allow for higher population densities than less developed neighborhoods can support. Problems arise when one reads the statute and realizes that both SPI-16 and SPI-17 are split into multiple subareas—and one of SPI-16’s subareas, Subarea 2 is further divided into the “Juniper Street Transition area” (JSTA) and “non-Juniper Street Transition Area”.\nThe city’s comprehensive plan calls for all of Subarea 2, JSTA and non-JSTA alike, to become “very high-density residential”, the densest residential development typology currently planned for the Atlanta region. Similarly, SPI-16’s third subarea is only half a block wide, controlling density in an area where views are already protected by other regulations. These rules also limit density in all 3 of SPI-17’s subareas. Transition areas within subareas in neighborhood-specific zones make for complicated land use regulations that can change dramatically from block to block. In a fast-developing area, needlessly complicated rules mean that property owners struggle to understand how much their land is worth, sometimes leading them to sell for less than they would if they fully understood their property’s development potential.\n2. Allow bigger buildings around Midtown’s transit stations\nAtlanta officials have long hoped for Midtown to be a natural extension of the city’s downtown office building core. The area is one of the best served by transit in the city, with trains every five minutes on MARTA’s Red and Gold lines and all of SPI-16 and 17 within half a mile of one of the stations. Heights are somewhat limited in SPI-17 due to view protections, but SPI-16 at the core of midtown does not have height limits at all.\nRather, Atlanta limits density with a system of floor area ratio (FAR) rules that force developers to trade height for extra open space on their properties. Each point of FAR is equal to the area of the property, so a 3 FAR building could be three stories covering the full lot, or six stories covering half the lot. They can earn more allowed FAR by including amenities like ground floor retail and affordable housing, but these amenities may not be appropriate for every project. As it stands, the area allows for and regularly sees construction of three to four story residential buildings, and five to six story commercial buildings without employing any bonuses.\nAn alternative would be to increase by-right FAR while retaining the system of density bonuses should it makes sense to offer them. Raising FAR limits as high as 15, including bonuses, would add approximately 100 million buildable square feet across Midtown.\nWhat would that mean for Midtown? If the area’s 60-40 bias toward commercial development is maintained, it would add 40 to 50 million square feet of office space, 10 to 20 million square feet of retail space and 50,000 residential units at an average of 800 square feet per unit. It would add space for 2 to 3 people to work for every new residential unit created, maintaining job balance while adding enough downtown units to put Atlanta more in line with Los Angeles in Bertaud’s density diagram above. A table with alternative housing and commercial mixes for the zone may be found here.\nAt the end of the day, aligning existing zoning with future plans is a political choice for Atlanta policymakers. Simplification of the zoning map would lend certainty and clarity to property use guidelines for landowners. Adding transit-accessible jobs and housing along underused rail lines would make better use of existing infrastructure investments. It would bring more people to the urban core, supporting more retail and office jobs and growing the tax base, all by simplifying rules and extending the right to build a little higher into the air. Sounds like a good deal to me. Whether the people of Atlanta agree is for them to decide.","Last year, New York City’s Comptroller Scott Stringer released a bleak report: between 2000 and 2012, New York’s median rent skyrocketed 75 percent. Median household income, meanwhile, decreased by 5 percent. New Yorkers now are making less money but paying more to live in the city than they were a decade ago.\nThese numbers are extreme, but they highlight a dangerous trend in American cities: housing is becoming increasinglydifficult to afford. In many cases, high prices are disrupting longstanding city communities, and even forcing low-income residents out of their neighborhoods.\nThere’s no magic solution to the problem. But in addition to finding funds and space for more affordable housing, one often-overlooked strategy, many experts agree, is improving city transportation.\nHow can changing the way people get around a city make it easier for them to afford to live there? In advance of the Zócalo/Metro event “Can Transit Make Housing More Affordable?” we asked people who study, write about, and are deeply engaged in urban development: How can new transit projects make more affordable housing?\nConnect people to the cities they live and work in\nIf we’re going to get serious about fixing the housing affordability problem in high-priced markets such as Southern California, smarter land use and access to transportation are key. The 20th-century formula of finding cheap land further and further away from employment centers no longer works, as commute times—and expenses—have soared to the point where an affordable home or apartment outside the city can actually cost more in the end.\nTransit-oriented developments are key to changing all of that because they allow for greater density, encourage public transportation, and create business and economic opportunities along the transit corridors. And, of course, they connect people and jobs.\nWe’re seeing a number of examples of this throughout the Los Angeles area, particularly along some of the light-rail systems that have been put into play during the past decade. Land that doesn’t fit our traditional definition of “residential use” is being converted to dynamic, multidimensional communities within communities.\nAccessible transportation is at the core of all great cities, and the nexus between it and housing affordability has always been strong. Just as our challenges have become more complex, so have our opportunities. Promoting housing and transit not as separate entities, but as interlocked elements of our American dream, will allow us to move in a bold, new, great direction.\nMake housing more accessible\nIn many cities, transit enters a neighborhood, and housing prices rise. These rising prices are encouraging because they demonstrate that transit is providing a service that people want—a service that they’re voting for with their feet and their pocketbooks. But while price increases help property owners and schools, they typically aren’t helpful to renters and low-income residents.\nAdding bus or rail transit service to neighborhoods increases the housing supply accessible by high-quality transit. Allowing for greater density around transit stations increases housing supply, too. This link between housing and transit is made very clear by the “Location Affordability Portal” developed by the United States Department of Transportation and the Department of Housing and Urban Development. The portal’s “Cost Calculator” provides estimates of housing and transportation expenses at the neighborhood level to help consumers know what they can afford to pay.\nLiving near transit saves on transportation costs so that money can be used for housing. Location-efficient mortgages increase the borrowing limits for people who reside near transit, and can also make some housing more affordable by shifting transportation spending to housing. Transit agencies from Los Angeles to Atlanta are setting goals for housing affordability on land that they own near transit stations.\nDensity bonuses, inclusionary zoning, and housing subsidies are all options as well. While there is no single silver bullet, it is clear that transit makes housing more affordable.\nCombat longstanding inequalities\nMajor transportation and urban renewal projects have a history of displacing communities of color, leaving behind disinvested neighborhoods. Racialized housing patterns, investment practices, and public infrastructure projects have helped solidify systemic structures of household wealth and poverty for multiple generations.\nThe introduction of new transit networks in cities is a once in a lifetime opportunity to address this history of inequities and its ongoing impacts in our communities. While the increased desirability of neighborhoods with new transit is revitalizing areas that have seen little private investment for decades, this desirability is also increasing housing costs for existing residents and displacing long-established communities. Supportive public policies like inclusionary zoning, value capture, community benefits agreements, and zoning to accommodate greater density all can help ensure private development creates more affordable housing alongside the transit investment.\nThe private market alone will not produce equitable outcomes. Public investments are critical to achieving community stability during the periods of neighborhood change that often accompany new transit investments. Nonprofit organizations accountable to the community must build affordable housing that meets the needs of existing residents. Land acquisition funds, local housing gap financing, publicly owned land, and tax credits are some of the resources that can be targeted for areas anticipating new transit.\nLeveraging transit investment to achieve equitable outcomes requires making affordable housing investments ahead of market pressures, planning in partnership with the communities most impacted by neighborhood change, and organizing comprehensive community development strategies, such as stabilizing culturally distinct small business districts and strengthening nonprofit cultural organizations.\nIncrease travel options\nTwo rules of thumb in home economics class were that housing shouldn’t cost more than a quarter of income, and no one should ever go into debt for an automobile. But today, housing and transportation costs are skyrocketing. Even when a house on cheap exurban land may seem like a good deal—because the high costs of traveling from a disconnected place to work every day can completely eat up those apparent savings.\nToday, we are returning to the city, but we’ve skimped on providing enough travel options to make transportation affordable. My organization recently used our H+T Index to take a look at the amount the average-income household pays for transportation each year, and we found that many are spending more than $10,000. These costs are predominantly for owning and operating personal motor vehicles. Parking spaces for these vehicles takes up room we could otherwise use for a more compact form of community.\nThankfully, hundreds of regions have begun to adopt a definition of “affordability” that includes the costs of both housing and transportation. Several have gone even further, such as the San Francisco Bay Area, where the region’s Metropolitan Transportation Commission now has an official goal to lower the combined cost of housing and transportation for low- and moderate-income families by 10 percent.\nOther ways cities and towns are trying to build location-efficient places include improving regional transit service, reforming zoning and increasing the frequency and connectivity of existing transit, including buses, trains, and shared-use mobility like bike sharing and ride-hailing.\nTransportation options are growing in L.A. and in many other regions across the country. People are even voting for taxes to gain that choice—they’re recognizing the need for investment.\nAs cities successfully revitalize, density and activity go up, and so must the public investment in infrastructure that enables this happy outcome.\nRecognize benefits aren’t evenly distributed, and change tax policies\nIf transit is reasonably well-planned and implemented, it will make housing more accessible to socio-economic activity, including commercial business. This increases housing’s value and price, which makes it seem less affordable to residents. But because residents don’t need to own so many automobiles, they’ll have more disposable income.\nAt the societal level,, if a transit system is extensive enough to change the economic geography of an area, it can provide greater density of development, and so increase productivity and job growth. Reduced levels of pollution from automobiles would improve quality of life. Even though the apparent effect is more expensive housing, this housing is more affordable because the net benefits to the population are higher. Residents can more easily access growing job opportunities, for instance.\nStill, for people in these areas not able to take advantage of improved accessibility, the effect can be experiencing the higher costs, but not the improved benefits, which could lead to their displacement.\nAs an example, in the Boston metropolitan area, overall auto ownership costs are reduced by more than the cost of the transit system. Congestion costs and pollution levels are lower than they would otherwise be. Densities are higher in business districts, agglomeration benefits are real, and job numbers are up.\nAt the same time, net benefits are not uniformly distributed in the city. The tax system that provides the public subsidies to support transit service is primarily a statewide sales tax. If the tax system was changed to instead assess costs upon the regions with the most tangible benefits, and rely more heavily on taxes on enhanced property values, and on income and corporate taxes, equity could improve.\nFred Salvucci is senior lecturer at MIT’s department of Civil and Environmental Engineering. He served as Secretary of Transportation of the Commonwealth of Massachusetts under Governor Michael Dukakis between 1975 and 1978 and again from 1983 to 1990."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:1f4ea6c3-7e0c-4efb-9574-b3d3e022bdf1>","<urn:uuid:b9797fc6-8721-4a27-aebc-31ddacfbd6ae>"],"error":null}
{"question":"Student here - how did Tabu Ley influence African music and what's the global impact of strokes nowadays?","answer":"Tabu Ley was a prolific songwriter and leading African vocalist who transformed Soukous music by creating a fusion of Congolese folk music with various international styles. He innovated constantly, creating new rhythms like 'Soum djoum' and founding the successful backup dancer group 'Les Rocherettes.' Regarding strokes globally, they affect 15 million people annually, with 25% being fatal and over 30% causing permanent disability. Strokes are the first cause of motor disabilities in adults and the third cause of mortality. The impact is particularly severe in less-developed countries, where the risk of disability is 10 times higher due to lack of specialized care.","context":["The undisputed King of Soukous, Congolese musician Tabu Ley Rochereau, died of stroke on November 30, 2013 in Belgium at the age of 73. He was a prolific songwriter and one of Africa's leading vocalists who internationalised Soukous by creating a fusion of Congolese folk music and Cuban, Caribbean and Latin American rumba.\nReacting to the news of his death, radio producer and DJ Minna Zhou remembered how Tabu Ley experimented with diverse music styles, which includes incorporating Jimi Hendrix's guitar techniques and producing a cover of The Beatles’ “Let It Be” in Lingala, a language spoken in the Democratic Republic of the Congo:\nThroughout his 50-plus-year-long career, Tabu Ley never stopped innovating and keeping himself open to sounds from around the world. In the same 1993 interview cited above, he spoke of changing the more intellectual, refined feel of L’African Jazz to create something that could appeal more readily to the masses. In 1972 after a tour of Senegal, he came back with a new rhythm for rumba called “Soum djoum,” which some say was inspired by Soumbedioune, Dakar’s largest fish market. When Jimi Hendrix approached the man in London as a fan of Dr. Nico, they exchanged musical ideas, which led Tabu Ley to incorporate some of Hendrix’s guitar techniques into Afrisa International. He made a Lingala cover of The Beatles’ “Let It Be”. He experimented with synths as a stand-in for likembe [a thumb piano, which is also known as Mbira]. He also created a hugely successful back-up dancer group “Les Rocherettes,” which included the sensual and honey-voiced Mbilia Bel who became an integral part of the Afrisa International [Tabu Ley's band] sound.\nBelow is a YouTube video of one of his greatest hits titled “Muzina”:\nIt was only in 2008 that the King of Soukous moved to Paris where his family had immigrated years prior. He sought his family’s support and medical help for the stroke from which he would never truly recover. As if prescient, the twin capitals Kinshasa and Brazzaville held a months-long tribute to Tabu Ley just last year in 2012. The DRC’s Chancellor of National Orders honored the living legend with two gold medals — one for civic merit and the other for his deep cultural contributions to Congolese arts, sciences, and humanities. In November of 2013, he was admitted to l’Hôpital Saint-Luc in Brussels, where he spent his last days.\nKenyan blogger Ken Opalo wrote the following after hearing the news of Tabu Ley's death:\nThe Rhumba legend Tabu Ley has passed on. For Kenyans of my generation his songs are a reminder of a childhood marked by our parents’ great love of Congolese music (dominated by Tabu Ley and Franco Luambo Makiadi). Back then Kinshasa seemed like the most fun place on the planet (and probably is/was, as I have never been) and a bustling centre of cultural production. We didn’t know what the songs were about, but we knew the lyrics (or what we imagined them to be). I particularly grew to love “Muzina.”\nOn Twitter, Zichivhu pointed out that the only major Western media that covered his death was France24:\nThe only major Western news network to carry the death of #TabuLey was France24…we Africans really do need our own “AlJazeera”. *sigh*\n— Zichivhu (@Zichivhu) December 1, 2013\nActivist and founder of activist @SavetheCongo, Vava Tampa wrote:\n— Vava Tampa (@VavaTampa) December 1, 2013\nNaomi Mutua described why Tabu Ley is a legend:\n— Naomi Mutua (@AKenyanGirl) November 30, 2013\nBelow is a YouTube video of King of Congolese rumba Tabu Ley and Congolese singer M'bilia Bel, known herself as the Queen of Congolese rumba, singing “Shauri Yako”:\nĔĎ ђØŦĔҎ reported that Tabu Ley has a son who is a rapper:\n— ĔĎ ђØŦĔҎ (@EdOG_Azaza) January 15, 2012\nKenyan artist Suzanna Owiyo mourned:\nAfrica has lost a true legend in the music fraternity. #Tabuley‘s music inspired many both young & old.We will dearly miss you.May you RIP\n— Suzanna Owiyo (@SuzannaOwiyo) December 3, 2013\nfunk of 40k years noted:\n— funk of 40k years (@antwoman1) December 1, 2013","STROKE is a condition which occurs very suddenly, and causes motor deficits (limb movement), loss of sensitivity or language disorders.\nThere are two types of strokes : in most cases (85 %) it is an infarction – a blocked artery in the brain ; and the rest of the time (15 %) it is a hematoma due to rupture of a vessel in the brain. In both cases an area of the brain is deprived of irrigation and the tissue dies ( focal lesion) losing its neurological functions and leading to the symptoms observed.\nIn most of the 15 million STROKES occurring each year globally, about 25% of them are fatal and more than 30% leave severe after-effects with permanent disability, making its victims dependent, directly impacting their family and relatives.\nIn France, the number of new cases a year is currently estimated at 130 000, in other words, STROKE occurs every 4 minutes. Even if all strokes do not have the same severity, they are the 1st cause of motor disabilities acquired in adults, 2nd cause of dementia and 3rd cause of mortality. Because of a lack of specialised care in less-developed countries, the risk of disability is 10 times higher in the least-developed countries.\nICM researchers are trying to understand the brain plasticity neurological process set up at the brain level in response to stroke and work more specifically on post-stroke recovery. It is possible through Trans-Cranial Magnetic Stimulation therapeutics (Charlotte Rosso’s work in Stéphane Lehéricy and Marie Vidailhet’s team), and through patient rehabilitation with therapeutic games – serious games such as “Voracy Fish” (work of the Brain e-NOVATION LabCom, joint lab common to the ICM and the GENIOUS group). These approaches improve patients’ everyday life and ease the after-effects.\nTRANS-CRANIAL MAGNETIC STIMULATION THERAPEUTICS\nCharlotte Rosso, neurologist specialised in STROKE, working both in the Pitié-Salpêtrière hospital, in the department devoted to this pathology (Pr Yves Samson) and in Pr Marie Vidailhet and Dr. Stéphane Lehéricy’s team on movement control within the ICM, explains her research :\nAfter stroke and the onset of a focal lesion, even if the underlying nerve tissue dies, there is a chance of recovery through brain plasticity implementation. The team I am working with at the ICM is interested in this brain plasticity. Thanks to magnetic resonance neuroimaging techniques (MRI) in static (observation of lesions) or dynamic (follow up of the activation of different brain areas during a movement), we are studying in what proportion different brain plasticity processes are implemented in each patient : we may find management of the lost function by surrounding tissues, participation in movement control by secondary areas involved in programming a movement or support by contralateral areas (healthy hemisphere, non-affected by stroke) since we have 2 cerebral hemispheres. For example, when an individual suffering from stroke shakes hand (as long as he still can) an area of his brain, different from a healthy person’s one, will activate.\nWe want to help patients recovering from stroke by determining which areas of the brain could be made stronger through Trans-Cranial Magnetic Stimulation therapeutics, (TCMS), a medical technology currently used for diagnosis and tested at the ICM in terms of treatment. This is a non-invasive brain stimulation using a coil placed next to the patient’s skull, which will try to make an area more excitable so that it supports a function.\nThese new innovative technologies will be of greatest hope in the forthcoming years. We hope that treatments are adapted to each patient in his individuality and the specificity of the stroke he was victim of, by focusing on a specific area rather than another one, through TCMS.”\nPOST-STROKE PATIENTS REHABILITATION THROUGH THERAPEUTIC GAMES – “VORACY FISH”\nMarie-Laure Welter, hospital neurologist practitioner, coordinator of the Brain e-NOVATION LabCom at the ICM, responsible for the deep brain stimulation activity within the Neurology Department and co-director of the “Power/Balance/Posture/Movement/TMS and neuronavigation in man” platform at the ICM, tells us about it:\nWith a desire to set up a partnership between the ICM and the GENIOUS group, a company manufacturing video games, the Brain e-NOVATION joint lab aims at creating “serious games” – therapeutic games – aiming at re-educating and rehabilitating patients suffering from neurological or psychiatric diseases. The “Voracy Fish” therapeutic game has been created for patients suffering from stroke, to enable them to rehabilitate their upper limbs.\nThese therapeutic video games aim at being played at home or in institutional settings (with a practitioner or at hospital). The patient can play alone, with a relative, or networking with other patients. Remote practice of this game is monitored through a technology platform allowing to collect different parameters of the patient’s motor behaviour, and their analysis by therapists and so propose an adjustment of the video game according to each patient and his progression.\nThe concept of a “video game therapy” aims at both overcoming the difficulties encountered by patients in more conventional rehabilitations and resolving their possible lack of motivation facing the repetitive aspect and the difficulty of downtown access to a therapist. The benefit of this type of innovative treatment intended to be playful, is to be able to combine different components of human behaviour : motor skills with body movements, cognition with the challenges and objectives of success on different levels of the game, while combining the motivational and emotional aspect with the playfulness of the device.\nBrain e-NOVATION’s idea is to incorporate these games – which are complementary to rehabilitation with practitioners (therapists, or physical therapists) – in clinical trials to evaluate and demonstrate the effectiveness and the benefit of this type of treatment and tools, either for stroke with Voracy Fish or for other kinds of pathologies."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:c288f58f-cb5d-4d08-8fe4-7925a65b5fcf>","<urn:uuid:48c28642-4304-437d-9722-7bc7b074d34f>"],"error":null}
{"question":"What are the technical features of the Heritage Lab's immersive design, and how was this preservation project funded? 💫","answer":"The Heritage Lab's immersive design features mirrored side walls that reflect the central image, creating an expanded concert experience, along with a torus segment screen offering multiple viewing angles. The installation includes 3D sound systems with virtual reconstruction of old venues, and a specialized browsing system for accessing 44,000 songs. As for funding, the project was supported through a public-private partnership, with the Swiss federal government financing half of the 30-million-franc cost, while private partners, including the Gandur Foundation for Art, provided the remainder. The project involved collaboration between more than 60 students, 3 interns, 7 external companies, and 35 researchers across 8 labs at EPFL.","context":["Montreux Jazz Heritage Lab II\nBringing the History of Jazz back to life\nThe public will be able to delve into 50 years of archives concert of the Montreux Jazz Festival in a new Kengo Kuma’s building at EPFL. The immersive installation resulting from a research program at a crossroads between design, architecture and technology has been unveiled at the EPFL + ECAL Lab. It answers many new challenges: how to revive digitized heritage, how does this change our perception of the past, and what new cultural prospects does this open?\nThe world’s largest audiovisual archives of blues, jazz and rock live recordings are not only listed in the UNESCO Memory of the World Register, they have also now been digitized. Eight years of work under the coordination of the Metamedia Center at the EPFL, technological development and scientific research have transformed the original material into an information system. But how to revive these archives? Research conducted by the EPFL+ECAL Lab in close collaboration with ALICE ( EPFL’s Space Conception Laboratory) aims to create a unique, specific experience, rather than mimicking the past. A first test installation for a more intimate audience got a Swiss Design Award in 2013. The new experience, which will welcome the public in the Montreux Jazz Café at EPFL, includes almost all of the archives, can accommodate twenty people and will give an unprecedented sense of immersion.\nSeveral principles have guided the EPFL+ECAL Lab and ALICE in this research. First, the wish for the effort to serve the actual content and its cultural value. The original take in the archives, video and sound, is at the heart of the device – unaltered and dominant.\nThe second principle is to enhance immersion. The side walls of the space are made up of mirrors which reflect the central image. The space seems to expand and the concert grows. The immersion is strengthened by the display on the mirrors of additional information on music, iconic visuals and anecdotes revealing the festival’s history and unique identity.\nThe third principle of the device is its simple yet sophisticated geometry. The screen is a torus segment offering a variety of views to visitors from inside and outside the Building. ALICE’S screen design enhances proximity to the stage by creating a sense of depth, but without any fatigue or queasiness. The physical texture of the screen improves the perception of the old standards, gives a tangible physical existence of the screen and contributes to the overall acoustic performance.\nSound acts also as a key factor for the immersion, involving EPFL research labs and innovative companies. The installation includes 3D sounds with full virtual reconstruction of Montreux Jazz old venues.\nFinally the browsing system helps to create an overall perception of the archive, its wealth and its contents. It stands out from traditional search systems made to find specific information Over 44,000 songs are at the users’ fingertips with a design reminiscent of a music score.\nThe Montreux Jazz Heritage Lab is based on the work which started when Audemars Piguet, Montreux Sounds and the EPFL joined forces in order to digitize, restore and preserve the immensely valuable archives of the Montreux Jazz Festival. Since 2008, several development projects have been carried out at EPFL, involving more than a dozen laboratories, using this unique collection as a database for researchers.\nAfter its public opening, the Montreux Jazz Heritage Lab will continue to evolve. It will be a tool to test new research questions, provide a testing ground for design students, and also to observe user perception so as to better understand the impact of immersive devices. But the main objective will always remain to strengthen our relationship to our cultural heritage and history.\nNicolas Henchoz, Project Curator\nCédric Duchêne, Project Manager, Senior Engineer\nTommaso Colombo, Senior Designer\nKarian Foehr, UI Designer\nDelphine Ribes, Senior Computer Scientist\nGuillaume Bonnier, Senior Computer Scientist\nDavid Roulin, Developer\nSusanne Schneider, Product Designer\nPr Dieter Dietz, Architecture Curator\nRudi Nieveen, Senior Research Architect\nManon Fantini, Architect\nYannick Claessens, Assistant\nJavier Puchalt, Assistant\nAlain Dufaux, Operations and Development Manager\nIgor Ristic, IT Manager, Project Coordinator, digitization\nOlivier Bruchez, Senior Developer, database\nGregory Marti, Senior Developer, media file manager\nSarah Artacho, Documentalist, song indexing\nCaryl Jones, Technology Watcher, quality control\nJulien A. Raemy, Archivist, picture digitization & anecdote creation\nCéline Racine, Archivist, picture digitization & tagging\nDirk Schröder, Acoustic Scientist\nSönke Pelzer, Acoustic Scientist\nFabian Knauber, Acoustic Scientist","The selection of the EPFL to receive and preserve the archive was made, on the one hand, because of its ability to guarantee continuity, as universities have traditionally been among the most stable institutions, and on the other hand, because of its technological competences to assure its storage, preservation and presentation to a wider public audience.\nIt is the musical and technological restoration of this heritage which is at the origin of the creation of the « Montreux Jazz Digital Project ».\nThe first chapters of this project will serve primarily to safeguard this unique musical history, whose carrier media are subject to the destructive tests of time, with a view to guaranteeing access to it to future generations. The operation will progress from the systematic digitalisation of the 15,000 hours of audio and visual medias of different generations and end with the creation of a digital treasure which, through the richness of its content, constitutes an educational resource of the highest order. This represents by far the largest collection of concerts recorded live to be brought together in one place. The greatest names in jazz appear on them and a great number of improvised jam sessions are extremely rare, thanks to the combination of talents playing.\nEPFL and Montreux Sounds, curator of the archives have therefore joined forces to create a unique and first of a kind, high resolution digital archive of the Montreux Jazz Festivals, with EPFL as exclusive licensee for scientific research and educational use. The goal of this ambitious project foreseen for 60 months from September 2010 to December 2015, is to exploit the know-how and expertise of EPFL for creation of the most technologically advanced high resolution digital media archive and long-term preservation ever produced, and doing so to set the ground for conception of novel and advanced technologies for tomorrow's digital media, hence maintaining a key know-how in a strategically important field in science, education and economy.\nExperimental pavilion to bridge culture and science at EPFL:\nA public‐private partnership brings science and art together \"The ArtLab\"\nThe Japanese architectural firm Kengo Kuma & Associates, together with Holzer Kobler Architekturen from Zurich, won the architectural design competition launched in 2012 to develop Cosandey Square at EPFL. Their project, “The ArtLab” will unite an experimental Art & Sciences space and a demonstration pavilion under a single, long stone roof at the Montreux Jazz Lab. The Swiss federal government will finance half of the 30‐million‐franc project, with the remainder coming from private partners including the Gandur Foundation for Art.\nPress release \"ArtLab\" EPFL 2016\nAccess The Montreux Digital Project:\nand Private donators\nMontreux Jazz CLAUDE NOBS LEGACY\nMANY THANKS TO\nMR. PATRICK AEBISCHER\nMR. FRANçOIS CARRARD\nMS. Adrienne corboud-Fumagalli\nMR. ALAIN DUFAUX\nMR. Lê-Binh Hoang\nMR. MATHIEU JATON\nMR. ERIC MERK\nMR. XAVIER OBERSON\nMR. STéPHANE PERRIN\nCollaborating and working with more than 60 students, 3 interns, 7 external companies and 35 researchers across 8 labs at EPFL for 25 digitization and valorization projects.\nThe Montreux Jazz Digital Project is a unique partnership between EPFL and Montreux Sounds. A list of EPFL labs, researchers, students, staff and external partners involved in the Montreux Jazz Digital Project is provided here."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:ed850f07-a73c-4129-847d-cf9cf8532287>","<urn:uuid:141f3950-05be-47af-9b0d-d6b468ba674a>"],"error":null}
{"question":"I'm interested in studying in Iceland through Ohio State's environmental program. What topics would I study there?","answer":"In the Iceland: Environment and Natural Resources program, you would spend two weeks in June studying geology, soil, geothermic energy, agriculture, ecotourism, and Icelandic history. The program includes a pre-departure course to prepare participants and is open to students from all majors.","context":["Education abroad provides the opportunities to learn about cultures, histories, and environments different than your own. The School of Environment and Natural Resources offers experiential learning opportunities in a variety of locations around the world. Through studying abroad, you can earn academic credit through hands-on learning experiences.\nENR Education Abroad programs are high-impact learning opportunities that explore a variety of environmental and social issues. For more information about ENR education abroad contact Cheryl Walter.266\nWhere can you go?\nThere are nearly 200 education abroad programs offered through The Office of International Affairs at Ohio State. These opportunities offer the potential to meet your specific goals, such as learning about issues impacting other nations, or in some cases, fulfilling major or minor credit hours. To explore the possibilities, visit the Office of International Affairs education abroad webpage. SENR offers several opportunities to explore the natural world and the global community in which we all live while earning ENR credit. Meet with your advisor to discuss where an education abroad program can fit into your academic plan.\nSchool of Environment and Natural Resources education abroad programs:\nIceland: Environment and Natural Resources\nSpend two weeks in June studying geology, soil, geothermic energy, agriculture, ecotourism, and Icelandic history. This program is open to students from all majors. Participants enroll in a pre-departure course to prepare them for the program. For more information about Iceland: Environment and Natural Resources, read the latest Iceland student blog!\nAustralia: Human Impacts on the Natural Environment\nSpend the month of May in North Queensland, Australia, surveying environmental issues including water scarcity and quality, the impacts of rising ocean temperatures, wildlife conservation, and more. Learn about conservation and restoration efforts on the Great Barrier Reef, hike in the Wet Tropics Rainforest, learn about agriculture and mining and learn about the history of Aborigianl Australians pre and post colonization.\nNew Zealand: Sustainable Tourism & Human Impacts on the Environment\nAttention is paid to examining the natural and social history of New Zealand while traveling the south island in May. The impacts of ecotourism, land use and wildlife conservation, agriculture and Maori history pre and post colonization.\nHow do students pay for education abroad?\nThe School of Environment and Natural Resources is pleased to offer financial assistance for full-time, undergraduate SENR majors to participate in OSU sponsored, credit-bearing education abroad programs related to the environment and sustainability. This financial assistance is meant to reduce barriers to access for those who would otherwise be unable to participate in education abroad opportunities. Preference is given to students with acute financial need and limited or no international experience. Access the application HERE.\n- A variety of university-level grants are scholarships are available. All SENR students who are accepted into an ENR or FAES education abroad program are eligible for a scholarship from the College of Food. Agricultural, and Environmental Sciences.\n- Financial aid can be adjusted, as well. Budget letters for your program are available through the Office of International Affairs. Make an appointment with student financial to review your budget letter and aid package."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:ae194b5c-31f8-44b0-9330-bfb82013e2c1>"],"error":null}
{"question":"Which originated further east: saffron or Spanish olive oil?","answer":"Saffron originated further east than Spanish olive oil. According to the documents, saffron originated from Greece, while olive oil production in Spain began during the Roman colonization of the Iberian peninsula, which started in 206 BC when they invaded the region that would become Baetica.","context":["Olive Oil – that most ancient of liquors\nPic – España Es Cultura\nIt is currently thought that olive oil was produced domestically around the Mediterranean as early as 2500 BC.\nSqueezed and drawn from the green and purplish fruit that hang in pendulous bunches amidst silver-green leaves, this golden green liquor has long been used in cuisine all around the Mediterranean basin. Gnarled trees, some with trunks greater than a metre across, are still farmed today while others, younger, stand in serried ranks spread over hill and dale, clearly evincing the olive’s current commercial importance.\nBlindfolded camel olive press Sidi Kacem, Maroc\nSpanish – Baetican Olive Oil and the Amphorae\nWhile olive oil is produced by most countries bordering the Mediterranean Sea, one country stands out for the sheer volume of its oil production and widespread distribution – Spain – and it has long been so.\n“As part of the Roman struggle against Carthage, they invaded the Iberian peninsula in 206 BC. Scipio Africanus was victorious at Alcalá del Rio near present day Seville and founded the city Italica and his army crushed the resistance of the native Iberians and soon transformed Andalucia (Baetica) into one of Rome’s richest and best organised colonies. Cadiz became Roman in 200 BC. The Romans remained for 700 years.” (Ref: andalucia.com/history/romans)\nBaetica was the Roman Empire’s southernmost (and earliest) province in their eventual colonisation of the whole Iberian Peninsula. Its capital was Corduba (Cordoba), situated on the River Baetis (now the Guadalquivir). The region, with both the Guadalquivir and Guadiana Rivers flowing through it, was already agriculturally rich and the Romans took full advantage of this.\nThe Roman Empire was expanding at a rapid pace; they had a huge war machine to maintain and it was olive oil, figuratively speaking, that ‘oiled the wheels’ of their massive enterprise. It was an indispensable condiment, fuel and cooking oil. Under their reign olive production in the bountiful soils of Baetica increased extensively, providing a continuing legacy: to this day the region of Andalucia accounts for 75% of Spain’s production of olives and olive oil.\nThe amphora used for storage and transport of olive oil, wine, and the very popular fermented fish condiment, ‘garum’ to Rome’s far-flung outposts was of a distinctive style: tall, cylindrical with angular shoulders, characteristic bifid handles, a beaded rim, pointed bottom and a longish neck narrower than the body. Its design, though, was a continuum of that of the Greeks before them – the terracotta amphora having been a common household item for millennia.\nThe Romans already had pottery factories in Italy, Gaul, the Eastern Mediterranean and also southern Britain long before they started and geared-up production in Baetica, Spain. The wine or olive oil amphora was considered a disposable, single-use bulk-carrier item, perhaps because of sediment that accumulated in their bottoms. Demand for the amphora’s continued supply and production was assured.\nPic: Assorted terracotta amphorae\nAs olive farming and oil production increased to meet demand so, too, did the need for more amphorae for its transport, and from the archaeological finds it is now certain that millions were manufactured along the shores of the river Baetis alone, in areas where suitable clay was to be found. It was a perfect commercial symbiosis.\nThere is now conclusive archaeological evidence that the Romans sent regular shipments of olive oil from Baetica to distant provinces such as Volubilis (Mauritania, now Morocco), Israel, the British Isles, Alexandria, Germania and Rome via existing combinations of shipping and land routes. This evidence lies in the numerous amphora remains bearing the distinctive Baetican pottery mark or stamp.\nPic: Typical wine & oil amphora – backtobodrum.blogspot.com.au\nThese vessels with their tapered and pointed bottoms appear to us to make unlikely containers for the storage of liquids, but the Romans (and Greeks before them) found their shape highly practical. They were perfectly designed to be stacked upright, padded with straw packing and tied in place aboard their wooden-hulled sea-going craft. Those same pointed bases could be tucked down behind fore-and-aft planking in the holds of the vessel, the outer amphorae’s curves snuggling against the curve of the hull. Once ashore, the amphora’s pointed bottom could be pushed into the sand for upright storage and, without a pedestal or flat base, be easily tilted or hefted (with one hand underneath) to discharge its contents.\nLike many races before and after them, the Romans may have been ruthless colonisers, but we cannot deny their productivity.\nOur own experience with ancient methods of olive oil extraction was during November of 2001 near Sidi Kacem in Morocco (see photo at top) and the raw oil from this direct source was the richest, most aromatic and flavoursome we have ever had: a superb olive oil, quite different to commercial product but not hard to find in that wonderful country. However, it was carried away in plastic containers, unlike the days of yore when clay vessels were the norm.\nFor those who would like to know more about Spain’s olives this site provides good detail of the varieties grown there: Olive Oil From Spain","The Indian Spices Board recently organised the 13th World Spice Congress in Ahmedabad with a theme of ‘Target 2020: clean, safe and sustainable supply chain’. Spices are the main attractions of an Indian market. With a variety of climate in different regions, India produces a range of spices. Most spices are native to the sub-continent and some were imported initially. The main spice producing state is Kerala, which is also known as the ‘Spice Garden of India’.\nSpices not only enhance the taste of our food, but also are an important part of our traditional medicine or the Old Naani’s Prescriptions. When most of the world was not even discovered, Indian spices were exported and used to enhance the flavors in different kitchens and were used as medicines worldwide. Spices are now grown and used across the globe in different ways and for various purposes. Here is a list of 10 spices that are a major part of Indian cuisine.\nHing or devil’s dung is one of the major spices used in almost every Indian dish. This pungent smelling spice is extracted from the dried gum secreted from the Ferula plant’s tap root, which gives a different aroma when used to make dal or rasam. It also acts as a digestive aid and is used as a condiment in food and pickles. This spice travelled to India and other countries from Iran and now holds a pride of place in every kitchen of the sub-continent.\nBlack pepper is the King of Spices, not because it is used for seasoning but for its medicinal properties. Usually found in South India, it has been a part of Indian cuisine since 2 B.C. It has various anti-oxidant properties and is a source of many usefulvitamins and minerals like potassium, vitamin A, and vitamin C.. It also fights cancer stem cells and stimulates your skin to produce pigments.\nAjwain or Bishop’s seed is often confused with the lovage seed. Ajwain is usually consumed after roasting or frying it in ghee after which it gives a complex aroma to the food. It has medicinal properties and can be taken to cure respiratory problems. This spice is probably a native to Egypt and travelled to India from near East, but is now only cultivated in Northern India and some parts of Iran.\nFenugreek or Methi seeds are one of the major ingredients of the various sauces and spice mixtures of not only Indian but Persian and Turkish cuisines. Fenugreek leaves are used fresh but its yellow colored-cuboidal seeds that can be preserved for later use. This is one sweet smelling spice with a slight bitter taste. It helps in reduction of body fat and enhances hair growth. Fenugreek seeds can be dried and then crushed for consumption to help women during menopause.\nCloves are dry, wood textured, nose-pin shaped spice, and its name is derived from the latine word ‘Clavus.’ This spice is comes from Maluku islands of Indonesia and is often consumed after roasting or frying it in ghee. It is also a major ingredient in the widely used spice mixture called garam masala in curries and is usually take to cure toothaches. Cloves are also considered sacred in Hindu mythology and are burned in pairs with camphor during rituals.\nCilantro or coriander or Dhaniya is a native to Southern Europe, North Africa and South Western Asia. It is an essential part of Asian and Russian cuisines. All the parts of the herb are edible. Its leaves are used raw as they can lose their fresh whiff if frozen or cooked. It is also widely used to treat digestive disorders and is highly beneficial in treating nausea and dysentery.\nTurmeric is used in all kind of cuisines in India and its bitter taste gives a desired flavor to the food. Leaves of a turmeric plant are used to make different Indian sweets. It contains various types of powerful polyphenol curcumin, which can help in the treatment of all types of cancer with no major side-effects. Turmeric is usually found in India and has been a part of Siddha (Tamil) medicine for thousands of years. Because of its anti fungal and anti-oxidant properties, it helps in treatment of stomach illnesses, skin ailments, liver problems and wounds.\nSaffron is the most delicate and most expensive of all spices in the world by weight. It originated from Greece and is mainly grown in Kashmir. It is used for seasoning and flavoring purposes in most of the Indian, Persian, European, Arab and Turkish cuisines. Saffron gives a beautiful yellowish-orange color and a fresh fragrance to the food and is obtained by drying the stigma of the flower from the plant saffron-crocus.\nCardamom or elaichi is one of the oldest Indian spices and the third most expensive spice by weight. Daily consumption of some cardamom seeds after meals or with tea can keep cancer away. It is a natural food preservative and helps in the reduction of tumor by blocking the growth of extra blood vessels in the human body. It is a major source of iron and calcium and is widely used to treat glaucoma.\nIran gave birth to the most common spice found in India. Today, India is the largest producer as well as consumer of cumin or jeera. It is believed to improve saliva secretion in the mouth and is thus used as a remedy for digestive illnesses and also works as a preservative. Cumin is also a part of traditional Brazilian cuisine and can be found in some types of cheese and home-made French cookies."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:4f6d912c-2a46-4b97-b0d0-e7d7c66b0573>","<urn:uuid:60a01801-2b6b-469e-b568-cdd2d80c73d2>"],"error":null}
{"question":"How do modern trickling filters with plastic media compare to traditional activated sludge systems in terms of handling variable conditions?","answer":"Modern trickling filters with plastic media are more resilient to variable conditions compared to activated sludge systems. Trickling filters are less susceptible to changes in effluent quality, toxicity, and shock loads because they use attached growth processes, while activated sludge uses suspended growth systems. Additionally, trickling filters can better handle hydraulic variations in peak and dry weather flows since the hydraulic retention time isn't substantially affected by flow variation - water simply falls by gravity from top to bottom. In contrast, the activated sludge process is more sensitive to changes, as maintaining proper Mixed Liquor Suspended Solids (MLSS) levels is crucial - if MLSS content is too high or too low, the process can become unstable and treatment effectiveness can be compromised.","context":["Activated Sludge Process Overview: The process deals with the treatment of sewage (and industrial wastewater) and was developed around 1912-1914. Activated sludge is a biochemical process for treating sewage and industrial wastewater that uses air (or oxygen) and microorganisms to biologically oxidize organic pollutants, producing a waste sludge (or floc) containing the oxidized material. Atmospheric air or pure oxygen is bubbled through primary treated sewage (or industrial wastewater) and combined with organisms to develop a biological floc which reduces the organic content of the sewage. The combination of raw sewage and biological mass is commonly known as Mixed Liquor. In all activated sludge plants, once the sewage (or industrial wastewater) has received sufficient treatment, excess mixed liquor is discharged into settling tanks and the treated supernatent is run off to undergo further treatment before discharge. Part of the settled material, the sludge (RAS), is returned to the head of the aeration system to re-seed the new sewage entering the tank. Mixed Liquor is a mixture of raw or settled wastewater and activiated sludge within an aeration tank in the activated sludge process. Mixed Liquor Suspended Solids (MLSS) is the concentration of suspended solids in the mixed liquor, usually expressed in milligrams per litre (mg/l).\nWhy Measure MLSS\nIf MLSS content is too high the process is prone to bulking and the treatment system becomes overloaded, this can cause the dissolved oxygen content to drop with the effect that organic matters are not fully degraded and biological 'die off'. Conversely, if the MLSS content is too low the process is not working efficiently, and is likely to be wasting energy whilst not treating the effluent effectively.The typical control band is 2,000 to 4,000 mg/l.\nRAS and SAS\nA proportion of the floc is called Return Activated Sludge (R.A.S.) and is used to maintain the desied MLSS value. Measuring the solids concentration of RAS allows the return volume to be adjusted to keep the solids level in the aeration basin within the control parameters. Excess sludge which eventually accumulates beyond that returned is defined as Surplus or Waste Activated Sludge (SAS/WAS). This is removed from the treatment process to keep the ratio of biomass to food supplied (sewage or wastewater) in balance. Typical Range: 4,000 to 6,000 mg/l.\nThe sample is sent away to a remote laboratory and the results are typically received 24hours+ after the event, this makes remedial action on site during the inital visit impossible. Additionally the sample degrades in transit.\nSite Settling Jars\nThe test takes 30 minutes or more and is extremely operator dependent, this means that a site can be kept in control when the same operator is looking after the site and has time to make the measurement carefully. If the operator changes or if time is limited the validity of the settling jar test becomes very questionable.\nPortable SS Monitor\nMeasurement using a properly calibrated portable monitor is now very reliable andrepeatable, the data is also available immediately and can be used to make site adjustmens to improve the performance of the site.\nFixed installation Monitor\nWith a permantently installed monitor 24/7 trending and alarming is available. This brings in the possibility of automated control, which improves plant efficiency by providing stability and continuity to the treatment process.Continuous On-Line Monitoring reduces the need for time-consuming laboratory analysis, removes operator dependancy from the measurement.","The last twenty years have seen substantial improvements to biological trickling filters, prompted by introduction of modern structural plastic media instead of traditional stone fill.\nPlastic media has transformed the treatment capability of trickling filters, making them two to three times more effective for a given volume. Reductions of more than 95 percent are now possible in BOD and ammonia, making trickling filters a viable option in many instances.\nA key advantage of trickling filters, compared to other treatment technologies, is their very low power requirements. In fact, the * Global Water Research Coalition (2011) has identified trickling filters to have the lowest energy usage of any secondary processes in the hierarchy of wastewater treatment processes.\nThis energy advantage, combined with operational simplicity, and resilience to manage variable loadings, has proven to be effective. Many WWTP’s in Europe, USA, NZ and elsewhere select trickling filters as their process solution of choice, in some cases even where capacity is greater than 500,000 EP.\nTrickling filters operate by distributing wastewater over media (plastic or traditionally stone/rock) that is typically 2-6m deep. Bacteria and micro-organisms grow on the media and feed off the contaminants in the wastewater as it percolates through the profile, thereby providing treatment. Trickling Filters are designed to maintain aerobic conditions by maintaining “free draining” conditions within the filter, and drawing air into the system through the updraft from ventilation holes at the base of the tank. This passive aeration mechanism is the underlying reason why trickling filters are not dependent on energy intensive blowers, achieving such low energy operation.\nAlthough a range of different media can be used in industry, structured plastic media has revolutionised design and operation of trickling filters. It significantly increases the surface area for microbial biofilms per unit volume, achieves void ratios >95% (e.g. 95% air) and avoids blockages deep within the profile. These characteristics are essential to maintain efficient oxygen delivery to the microbes, and drive efficient performance.\nFilter flies, a common problem with stone media or random packed media, are not an issue with structured plastic media. This is because the open matrix structure is an unsuitable habitat, so fly lava cannot proliferate.\nAdvantages of Trickling Filters Compared to Activated Sludge\nModern trickling filter designs offer many benefits that Activated Sludge processes cannot. These include:\n- Low energy (50-70% less energy than equivalent performing Activated Sludge);\n- Less susceptible to changes in effluent quality, toxicity and shock loads: Attached growth processes (e.g. Trickling Filters) are more resilient to variable wastewater conditions than suspended growth systems (e.g. activated sludge);\n- Ability to handle hydraulically variation in peak and dry weather flows. The hydraulic retention time within the Filter is not substantially affected by flow variation as a fixed volume suspended growth tank; water “falls” by gravity from top to bottom, irrespective of the flow;\n- Simple to operate, and;\n- Low sludge production, sludge thickens and dewaters easily.\nHistory of Trickling Filters in Australia\nIn Australia, Trickling Filters have been used since at least the 1930’s, generally by the municipal waste industry. Whilst trickling filter systems were common until the 1970’s, they were mainly comprised of stone media, which presented a number of short-comings. Some of the disadvantages were poor oxygenation particularly deeper down in media bed; blockages on the surface; proliferation of filter flies; odour; and inadequate treatment performance. As WWTP’s faced increasing pressure, over the last thirty to forty years, to deliver higher performance outcomes, they opted for a range of activated sludge technologies. These superseded many old trickling filter plants when upgrades were needed.\nAlthough trickling filters have been dismissed in recent times due to their historic poor performance, development of high performance plastic media over the last fifteen to twenty years has transformed trickling filter technology. These improvements have addressed many of the short comings associated with stone media. Modern plastic media Trickling Filters are two to three times more effective than stone media systems of the past, and require far lower energy than comparable activated sludge processes.\nInternationally, developments in trickling filters have been recognised, and the technology has seen a resurgence in many parts of the world over recent decades. These advances have taken longer to adopt in Australia, but with growing pressure to reduce energy costs, interest in the benefits of modern trickling filters is growing.\nAn example of modern plastic media Trickling Filter solutions being embraced in Australia is the upgrade of Water Corporations’ 1ML/day Narrogin WWTP in Western Australia. The project entails design and construction of a plastic media “nitrification” trickling filter.\nLow Nutrient Wastewater with Trickling Filters\nBiological nutrient removal requires a process train that incorporates a combination of aerobic and low oxygen conditions. Trickling filters are an aerobic process, and are highly effective at organic removal and ammonia nitrification, but by themselves they are unable to deliver low Nitrogen or Phosphorous outcomes. However, when trickling filters are complemented by separate anoxic processes, such as anoxic bioreactors or surface flow wetlands, they are able to achieve very low nitrogen results. Water Corporations’ Narrogin WWTP upgrade is designed to achieve final TN<5.8mg/L by integrating the nitrifying trickling filter with a 2ha anoxic surface flow wtland. Nitrogen levels could be lowered further if required, by modifying the trickling filter volume and wetland area.\nThe 3ML/day South Lismore WWTP in northern NSW is an example of using an old stone media trickling filter and a surface flow wetland for successful nitrogen removal. The graph below shows 4 years of EPA monitoring data for total nitrogen at the end of the WWTP. The ninetieth percentile TN over a four year period was 8.0mg/L, half the ninety percent licence limit of 15mg/L. Using plastic media in the trickling filter and implementing better design of the wetland, such as water level control, could improve the performance still further.\nTrickling filters don’t provide significant removal or reduction of phosphorous, except for minor amounts that are absorbed into the biofilm. Phosphorous reduction can be achieved easily by integrating chemical dosing such as alum or ferric into the process train. The addition of chemical dosing doesn’t contribute significantly to overall energy consumption of the plant, so overall low energy benefits are still afforded by trickling filters.\nAlternative Solutions for Aerated Bioreactors in Activated Sludge Process Trains\nAnother application of trickling filter technology is to integrate it into mainstream activated sludge treatment trains, as a substitute for any bioreactor that requires an aerobic process. The advantage of substituting trickling filters for aerated suspended growth bioreactors is that it can significantly reduce energy consumption of a WWTP, by delivering biological outcomes without the need for energy intensive blowers.\nThis ‘hybrid’ activated sludge/trickling filter solution has been adopted at the 275,000 EP Ingolstadt WWTP in southern Germany. Four plastic media nitrification trickling filters, each 3,400m3, have been integrated into the secondary activated sludge process train, as an alternative to a second stage aerated bioreactor. The WWTP has achieved significant energy savings as a result.\nAdditional Reference Papers / Information About Trickling Filters\n- Energy-efficient Wastewater Reuse – The Renaissance of Trickling Filter Technology (2013) C.-D. Henrich*, M. Marggraff\n- Setting new low energy benchmarks for Australian Sewage Treatment with Plastic Media Trickling Filters and Constructed wetlands – a 1ML/day case study (2015) Kikkert, Moulds, Personnaz\n- Australian Meat Processor Corporation: Trickling Filter Technology for the Treating Abattoir Wastewater\n- Random packing media VS GEA structured plastic media\n- 2H Components and Solutions – Enexio, the pioneer and global provider of trickling filter technology\n*Global Water Research Coalition [GWRC] (2011) ENERGY EFFICIENCY IN THE WATER INDUSTRY: A COMPENDIUM OF BEST PRACTICES AND CASE STUDIES – A Global report (Black and Veatch report on behalf of UK water Industry Research Limited)."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:80fe9ae8-d6c1-427c-9e2e-eee35e8dd873>","<urn:uuid:8dfd002d-8608-42c1-8957-9aba4a2b1d5a>"],"error":null}
{"question":"As someone learning to teach music, I'm wondering: what's the difference between what Mike Campese and Carl Rath taught in their music careers?","answer":"Mike Campese focused on teaching guitar-related content and various musical styles, while Carl Rath had a broader teaching portfolio that included bassoon, music theory, woodwind methods, music appreciation, band, percussion, popular music courses, and student teacher supervision. He taught at multiple institutions including Lawrence University and the University of Oklahoma, where he also formed bassoon ensembles.","context":["Welcome back! In this lesson we will be focusing on picking and moveable shapes that will help to create longer lines. All of the examples are based in the diminished scale, the one that begins with a whole step and the formula is (1, 2, b3, 4, b5, #5, 6, 7). You can also look at it as, whole step, half step, whole step, half step etc and it is an 8 note scale. There is a mode of this scale that begins with a half step and the formula for that is (1, b2, b3, 3, b5, 5, 6, b7). We won't go in too much detail with the diminished scale though, since I covered this scale in previous lessons.\nMost of the examples in this lesson are built using two strings and a 6-note shape with the fingering (1, 3, 4, 1, 2, 4), which are the first six notes of the scale. Once you master these patterns, be sure to move them around the neck and apply them to any scale or key. Also, you don't have to play these patterns over diminished chords, they work over minor chords or you could use power chords as well. Be sure to alternate pick these examples.\nExample 1 is a 16th note pattern that uses the first 6 notes of the A diminished scale, (A, B, C, D, Eb, F, F#, G#) and it moves up a minor 3rd to C diminished. The scale is symmetrical, so you can move these patterns in minor 3rd intervals and the same notes will repeat. Begin playing this one slow and be sure that both hands are in sync.\nMP3 - Movable Picking Patterns - Example 1\nExample 2 is the same pattern as the previous example, but moved through the A diminished scale ascending up the neck on all 6-strings. This pattern does not move through each note of the A diminished scale, it moves up in b5 intervals with the scale, except the last pattern on the B string, which is a major 6th. Don't forget to move this pattern around all over the neck.\nMP3 - Movable Picking Patterns - Example 2\nExample 3's patterns are variations from the 6-note pattern we have been using. This is just a repeated, descending four note sequence.\nMP3 - Movable Picking Patterns - Example 3\nThis variation in Example 4 is a little different sounding, because it is built with different intervals like 2nd's, a major 3rd and a minor 6th. It can be tricky to play and it does sound cool if you move it around the neck. Be sure to apply it to other scales.\nMP3 - Movable Picking Patterns - Example 4\nOK, that is it for now! Be sure to make up your own examples, and be sure to visit www.mikecampese.com for the latest news, updates and releases.\nMike Campese is an all-around music performer, session artist and teacher competent in many musical styles, electric and acoustic. He has studied at G.I.T. (Honors Graduate), and with Paul Gilbert, Norman Brown, Stanley Jordan, Scott Henderson and Keith Wyatt.\nHis latest CD is entitled \"The Fire Within\", brand new for 2018.\nSend comments or questions to:","Instructor in Music\nCarl Rath teaches bassoon and courses in popular music, arranges for and directs the Viking Bassoon Ensemble (ViBE), and coaches woodwind chamber music ensembles. Rath returned to Lawrence following his tenure at the University of Oklahoma School of Music and 22 years as Principal Bassoon in the Oklahoma City Philharmonic Orchestra. During this time, he established an international reputation as a bassoon performer and teacher. At OU, he performed with the Oklahoma Woodwind Quintet, a very active ensemble that performed in Carnegie Recital Hall, Austria, England, and throughout the U.S. They were the first woodwind quintet to release a compact disc of Christmas Music, which included two arrangements by Rath.\nHe has presented concerts in Argentina, Austria, Canada, China, England, Hungary, Taiwan, and the U.S. Rath performed as Principal Bassoon with the Classical Music Festival (Eisenstadt, Austria) for 17 summers and was solo artist three times in several performances of concertos by Mozart and Haydn. His performances have been heard on national and international radio programs and are featured on five CDs: A Christmas Delight (Oklahoma Woodwind Quintet), Moosmann Artists Sampler Disc, Moosmann Live (live performances from the 2002 IDRS conference in Banff, Canada), Moosmann 25th Anniversary, and Landscapes: The Double Reed Music of Daniel Baldwin. He studied bassoon with Fred Schroeder, Stanley Scheller, Stephen Basson, and Wil Roberts; composition with James Ming; and Conducting with Joel Rosenberg and Vincent C. LaGuardia. In 1985, he was a Quarter-finalist in the Concert Artists Guild Competition.\nA patron member of the International Double Reed Society, he has performed at 18 annual conferences. In 2010, he was the bassoon host of the 39th annual Conference at the University of Oklahoma and in 2017 will again host the Conference, at Lawrence University.\nHe has presented masterclasses in Beijing, Buenos Aires, Shanghai, Taipei, and the U.S. In addition to bassoon-related courses, Rath has taught music theory, woodwind methods, music appreciation, band, percussion; developed new courses in popular music; and supervised student teachers. He has been a guest performer and clinician for the Bocal Majority Music Camp (Dallas), Double Reed Days in Wisconsin, Oklahoma, Texas, Ohio, and Utah., and soloed with several high school/college bands.\nIn addition to Lawrence and the University of Oklahoma, Rath has taught at the University of Denver, Northwestern State University (LA), Centenary College, Louisiana College, and Ripon College.\nRath is an advocate for bassoon ensemble performance forming the Sooner Bassooners at the University of Oklahoma and the Viking Bassoon Ensemble (ViBE) at Lawrence University to supplement his teaching. The student groups perform original music for bassoon ensemble, as well as arrangements by Rath, providing the students with experience in a varied repertoire of classical, jazz, rock, and popular music. Some of his arrangements are available through Imagine Music (NY).\nRath also arranges music for woodwind ensembles. His most recent commission was the Queen Medley Fantasy for woodwind quintet for Brightmusic Chamber Ensemble (OKC). As Artist-in-Residence with the Chinook Winds (Great Falls, MT Symphony Orchestra) in 2009, he performed with them on bassoon and arranged music by The Beatles, including a 45-minute multi-media Guide to The Beatles for Wind Quintet, Powerpoint, and Narrator, and Yellow Submarine in La Mer.\nRath is in demand as guest speaker on The Beatles and other popular music topics. He presented a 5-day course on The Beatles as part of the 2015 Bjorklunden Seminars program in Door County, Wisconsin. He is a conductor for 1964 the Tribute and was a founding member and drummer of a classic rock band, MidLife Crysis.\nContact by e-mail: email@example.com"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:30321e26-46a8-4741-b3e4-45d9176a9dab>","<urn:uuid:e2672e3b-d587-445e-a16f-a1c218903e30>"],"error":null}
{"question":"What were the total bird sightings and new species count achieved during this week-long Morocco trip in March 2017?","answer":"The trip resulted in sightings of over 170 bird species in total, with 30 of these being new species. The expedition took place between March 10th and March 20th, 2017.","context":["PART THREE – For some years now I have wanted to experience the desert birding in Morocco, and during 2017 I was fortunate enough to achieve my goal and I spent a week there, between 10th March and 20th March 2017, birding in the special desert areas. I traveled with Boletas Birdwatching Tours, operated by Josele Saiz. Our team comprised of 7 birders, most of which were also keen photographers, two leaders – Chris Townend and Danny Cazo Monesma and not forgetting our brilliant driver, Mohammed. It was a stunning trip, managing to see 30 new species and over 170 species for the week, 11 species of butterfly, 4 species of dragonfly, not to mention 3 species of frog and a single species of gecko. A massive thank you to Chris and Danny for their superb leadership skills, to the rest of the guys on the trip (Steve x 2; Pete, Rob, Chris and Karim), to Mohammed and lastly to Boletas Birdwatching Tours.\nI saw all my target birds, which included Bald Ibis, Pharoah Eagle Owl, Crowned & Spotted Sandgrouse, Brown-throated Martin, Thick-billed Lark, Moussier’s Redstart, Egyptian Nightjar, Red-rumped Wheatear, White-crowned Wheatear, Magreb Wheatear, Seebohm’s Wheatear, Scrub Warbler, African Desert Warbler, Crimson-winged Finch, Levaillant’s Woodpecker, Temminck’s Lark, Hoopoe Lark, Bar-tailed Lark, Black-crowned Tchagra, Tristram’s Warbler and Desert Sparrow. Some of which I managed decent photos, some were only record shots. Nevertheless all the birds were seen well. Some of the best views of Quail I’m ever likely to get, thanks to Danny, the “Quail King”, along with a stunning “Swift Extravaganza” and we even found a Lesser Scaup, the 7th record for Morocco and also, what was almost certainly, a Rock Martin. All in all some fabulous birding experiences.\nSummary of the trip – We commenced our birding journey in Marakesh, spending a full day in the high Atlas Mountains. Then a long drive east to Boulmane Dades, visiting the stoney desert area of Hammada and the Tagdilt Track. Another long drive further east to the Sahara Desert, staying in Merzouga for three nights and birding the vast desert area. Our return journey was via Ouarzazate, visiting the Anti-Atlas Range and the large Mansour Reservoir, where we found a Lesser Scaup. Then on to Agadir, birding the coastal river and the famous Sous Massa area and finally returning to Marakesh.\nI thought my time with Morocco’s Desert Birds was summed up perfectly in an email that Chris Townend sent to me – ” Hope you are not missing the Desert too much – The sand stays in the optics for weeks afterwards” – very true words and I’m missing it already…\nFat Sand Rat (Psammomys obesus) – Tagdilt Plains, Morocco – March 2017 – Tony Davison© – A common mammal of the Gerbil family\nAtlas Day Gecko (Quedenfeldtia trachyblepharus) – Oukaimedem, Toubkal National Park, Morocco – March 2017 – Tony Davison© – Endemic to Morocco, a member of the Lizard family\nAfrican Green Toad – (Bufo boulengeri) – Begaa Oasis, Morocco – March 2017 – Tony Davison©\nMoroccan Painted Frog – (Discoglossus scovazzi) – Oued Massa, Morocco – March 2017 – Tony Davison©\nEgyptian Nighjar – Merzouga Desert Area, Morocco – March 2017 – Tony Davison© – A return trip during the early evening gave a second chance to observe these stunning desert birds\nIberian Chiffchaff – Cafe Ibrahim Oasis, Morocco – March 2017 – Tony Davison© – We all felt this bird was an Iberian Chiffchaff – well just look at it, looks nothing like our Chiffy\nBooted Eagle – Tizi n Tichka Pass, Morocco – March 2017 – Tony Davison©\n“Atlas” Horned Lark – Oukaimedem, Morocco – March 2017 – Tony Davison©\nTrumpeter Finch – Above 2 images – Tagdilt Plains, Morocco – March 2017 – Tony Davison©\nThekla Lark – Souss Valley, Taroudant, Morocco – March 2017 – Tony Davison©\nEuropean Stonechat – Oued Massa, Morocco – March 2017 – Tony Davison©\nSouthern Grey Shrike (algeriensis) – Begaa Oasis, Morocco – March 2017 – Tony Davison©\nSeebohm’s Northern Wheatear – Oukaimedem, Morocco – March 2017 – Tony Davison© one of our target Wheatear species\nCommon Redstart – Begaa Oasis, Morocco – March 2017 – Tony Davison© – Lots of Common Redstart were migrating through Morocco\nCommon Quail – Oued Massa, Morocco – March 2017 – Tony Davison© – I had the best views of Quail I think I’m ever likely to get – This bird was simply amazing and put on a stage performance..\nWestern Olivaceous Warbler – Oued Massa, Morocco – March 2017 – Tony Davison© – Olivaceous Warbler were just beginning to arrive and we saw several in the Oued Massa.\nCommon Nightingale – Begaa Oasis, Morocco – March 2017 – Tony Davison© – several migrant Common Nightingales were seen whilst birding the Oasis areas\nEurasian Magpie (mauritanica) – Marakesh, Morocco – March 2017 – Tony Davison© – the Moroccan race which is very attractive, note the brilliant blue ear patch and tuft on the crown.\nLevaillant’s Woodpecker – Above 2 images – High Atlas, Ourika Valley, Morocco – March 2017 – Tony Davison© – Another Moroccan speciality, the top bird had a very badly deformed bill, fortunately we had another bird which was perfect."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:ad19d699-74e1-46e7-90ad-c2ff3a0318c2>"],"error":null}
{"question":"I'm doing research on emotional responses to displacement. What's interesting is how homesickness and separation anxiety symptoms are treated differently - could you compare the main treatment approaches for both conditions?","answer":"The treatment approaches for homesickness and separation anxiety differ in their focus and methods. For homesickness, the most effective approach is 'mixed and layered' coping, combining both primary goals (changing circumstances) and secondary goals (adjusting to circumstances). Specific strategies include doing fun activities to forget homesickness, positive thinking, reframing time, maintaining connections with home through letters, and talking with others for support. For separation anxiety, treatment involves a more comprehensive approach including cognitive-behavior therapy with response prevention and exposure therapy. The focus is on gradually returning to normal daily function through a coordinated effort between family, school staff, and healthcare providers. Treatment includes positive reinforcement for independent functioning, relaxation exercises, and potentially anti-anxiety medications (though these aren't FDA-approved for those under 18). Additionally, separation anxiety treatment emphasizes parental involvement and addressing any parental anxiety that might reinforce the child's fears.","context":["The examples and perspective in this article deal primarily with the United States and do not represent a worldwide view of the subject. (December 2015) (Learn how and when to remove this template message)\nHomesickness is the distress caused by being away from home. Its cognitive hallmark is preoccupying thoughts of home and attachment objects. Sufferers typically report a combination of depressive and anxious symptoms, withdrawn behavior and difficulty focusing on topics unrelated to home.\nIn its mild form, homesickness prompts the development of coping skills and motivates healthy attachment behaviors, such as renewing contact with loved ones. Indeed, nearly all people miss something about home when they are away, making homesickness a nearly universal experience. However, intense homesickness can be painful and debilitating.\nHomesickness is an ancient phenomenon, mentioned in both the Old Testament books of Exodus and Psalm 137:1 (\"By the rivers of Babylon, there we sat down, yea, we wept, when we remembered Zion\") as well as Homer's Odyssey, whose opening scene features Athena arguing with Zeus to bring Odysseus home because he is homesick (\"...longing for his wife and his homecoming...\"). The Greek physician Hippocrates (ca. 460–377 BC) believed that homesickness—also called \"heimveh\" (old German word for \"Heimweh\") or a \"nostalgic reaction\"—was caused by a surfeit of black bile in the blood. In recent history homesickness is first mentioned specifically with Swiss people being abroad in Europe (\"Heimweh\") for a longer period of time in a document dating back to 1691. A normal phenomenon amongst the many common Swiss mercenaries serving in different countries and many rulers across Europe at that time. It was not uncommon for them staying many years away from home and, if lucky enough, return home if still alive. This phenomenon at that time was first only thought to affect Swiss people until this was revised, probably caused by big migration streams across Europe suggesting the same symptoms and thus homesickness found its way into general German medical literature in the 19th century. American contemporary histories, such as Susan J. Matt's Homesickness: An American History eloquently describe experiences of homesickness in colonists, immigrants, gold miners, soldiers, explorers and others spending time away from home. First understood as a brain lesion, homesickness is now known to be a form of normative psychopathology that reflects the strength of a person's attachment to home, native culture and loved ones, as well as their ability to regulate their emotions and adjust to novelty. Cross-cultural research, with populations as diverse as refugees and boarding school students, suggests considerable agreement on the definition of homesickness. Additional historical perspectives on homesickness and place attachment can be found in books by van Tilburg & Vingerhoets, Matt, and Williams.\nDiagnosis and epidemiology\nWhereas separation anxiety disorder is characterized by \"inappropriate and excessive fear or anxiety concerning separation from those to whom the individual is attached\"  symptoms of homesickness are most prominent after a separation and include both depression and anxiety. In DSM terms, homesickness may be related to Separation Anxiety Disorder, but it is perhaps best categorized as either an Adjustment Disorder with mixed anxiety and depressed mood (309.28) or, for immigrants and foreign students as a V62.4, Acculturation Difficulty. As noted above, researchers use the following definition: \"Homesickness is the distress or impairment caused by an actual or anticipated separation from home. Its cognitive hallmark is preoccupying thoughts of home and attachment objects.\" Recent pathogenic models support the possibility that homesickness reflects both insecure attachment and a variety of emotional and cognitive vulnerabilities, such as little previous experience away from home and negative attitudes about the novel environment.\nThe prevalence of homesickness varies greatly, depending on the population studied and the way homesickness is measured. One way to conceptualize homesickness prevalence is as a function of severity. Nearly all people miss something about home when they are away, so the absolute prevalence of homesickness is close to 100%, mostly in a mild form. Roughly 20% of university students and children at summer camp rate themselves at or above the midpoint on numerical rating scales of homesickness severity. And only 5–7% of students and campers report intense homesickness associated with severe symptoms of anxiety and depression. However, in adverse or painful environments, such as the hospital or the battlefield, intense homesickness is far more prevalent. In one study, 50% of children scored themselves at or above the midpoint on a numerical homesickness intensity scale (compared to 20% of children at summer camp). Soldiers report even more intense homesickness, sometimes to the point of suicidal misery. Naturally, aversive environmental elements, such as the trauma associated with war, exacerbate homesickness and other mental health problems.\nIn sum, homesickness is a normative pathology that can take on clinical relevance in its moderate and severe forms.\nRisk and protective factors\nRisk factors (constructs which increase the likelihood or intensity of homesickness) and protective factors (constructs that decrease the likelihood or intensity of homesickness) vary by population. For example, a seafarers on board, the environmental stressors associated with a hospital, a military boot camp or a foreign country may exacerbate homesickness and complicate treatment. Generally speaking, however, risk and protective factors transcend age and environment.\nThe risk factors for homesickness fall into five categories: experience, personality, family, attitude and environment. More is known about some of these factors in adults—especially personality factors—because more homesickness research has been performed with older populations. However, a growing body of research is elucidating the etiology of homesickness in younger populations, including children at summer camp, hospitalized children and students.\n- Experience factors: Younger age; little previous experience away from home (for which age can be a proxy); little or no previous experience in the novel environment; little or no previous experience venturing out without primary caregivers.\n- Attitude factors: The belief that homesickness will be strong; negative first impressions and low expectations for the new environment; perceived absence of social support; high perceived demands (e.g., on academic, vocational or sports performance); great perceived distance from home\n- Personality factors: Insecure attachment relationship with primary caregivers; low perceived control over the timing and nature of the separation from home; anxious or depressed feelings in the months prior to the separation; low self-directedness; high harm avoidance; rigidity; a wishful-thinking coping style.\n- Family factors: decision control (e.g., caregivers forcing young children to spend time away from home against their wishes);\nFactors which mitigate the prevalence or intensity of homesickness are essentially the inverse of the risk factors cited above. Effective coping (reviewed in the following section) also diminishes the intensity of homesickness over time. Prior to a separation, however, key protective factors can be identified. Positive adjustment to separation from home is generally associated with the following factors:\n- Experience factors: Older age; substantial previous experience away from home (for which age can be a proxy); previous experience in the novel environment; previous experience venturing out without primary caregivers.\n- Attitude factors: The belief that homesickness will be mild; positive first impressions and high expectations for the new environment; perceptions of social support; low perceived demands (e.g., on academic or vocational performance); short perceived distance from home\n- Personality factors: Secure attachment relationship with primary caregivers; high perceived control over the timing and nature of the separation from home; good mental health in the months prior to the separation; high self-directedness; adventure-seeking; flexibility; an instrumental coping style.\n- Family factors: High decision control (e.g., caregivers including a young person in the decision to spend time away from home); individuals making their own choice about military service; supportive caregiving; caregivers who express confidence and optimism about the separation (e.g., \"Have a great time away. I know you'll do great.\")\n- Environmental factors: Low cultural contrast (e.g., same language, similar customs, familiar food in the new environment); physical and emotional safety; few changes to familiar daily schedule; plenty of information about the new place prior to relocation; feeling welcome and accepted in the new place.\nTheories of coping\nMany psychologists argue that research into the causes of home sickness is valuable for three reasons . First, homesickness is experienced by millions of people who spend time away from home (see McCann, 1941, for an early review) including children at boarding schools, residential summer camps and hospitals.\nSecond, severe homesickness is associated with significant distress and impairment. There is evidence that homesick persons are present with non-traumatic physical ailments significantly more than their non-homesick peers. Homesick boys and girls complain about somatic problems and exhibit more internalising and externalising behaviours problems than their non-homesick peers. First-year college students are three times more likely to drop out of school than their non-homesick peers. Other data have pointed to concentration and academic problems in homesick students. And maladjustment to separation from home has been documented in hospitalized young people and is generally associated with slower recovery. See Thurber & Walton (2012) for a review.\nThird, learning more about how people cope with homesickness is a helpful guide to designing treatment programs. By complementing existing theories of depression, anxiety and attachment, a better theoretical understanding of homesickness can shape applied interventions. Among the most relevant theories that could shape interventions are those concerned with Learned Helplessness and Control Beliefs.\nLearned helplessness predicts that persons who develop a belief that they cannot influence or adjust to their circumstance of separation from home will become depressed and make fewer attempts to change that circumstance. Control beliefs theory predicts that negative affect is most likely in persons who perceive personal incompetence in the separation environment (e.g., poor social skills at a summer camp or university) and who perceive contingency uncertainty (e.g., uncertainty about whether friendly behavior will garner friends). Although these are not the only broad etiologic theories that inform homesickness, note that both theories hinge on control, the perception of which \"reflects the fundamental human need for competence\" (Skinner, 1995, p. 8). This is particularly relevant to coping, because people's choice of how to respond to a stressor hinges partly on their perception of a stressor's controllability.\nAn equally important coping factor is social connection, which for many people is the antidote to homesickness. As the results of several studies have suggested, social connection is a powerful mediator of homesickness intensity.\nWays of coping\nThe most effective way of coping with homesickness is mixed and layered. Mixed coping is that which involves both primary goals (changing circumstances) and secondary goals (adjusting to circumstances). Layered coping is that which involves more than one method. This kind of sophisticated coping is learned through experience, such as brief periods away from home without parents. As an example of mixed and layered coping, one study revealed the following method-goal combinations to be the most frequent and effective ways for boys and girls:\n- Doing something fun (observable method) to forget about being homesick (secondary goal)\n- Thinking positively and feel grateful (unobservable method) to feel better (secondary goal)\n- Simply changing feelings and attitudes (unobservable method) to be happy (secondary goal)\n- Reframing time (unobservable method) in order to perceive the time away as shorter (secondary goal)\n- Renewing a connection with home, through letter writing (observable method) to feel closer to home (secondary goal)\n- Talking with someone (observable method) who could provide support and help them make new friends (primary goal)\nSometimes, people will engage in wishful thinking, attempt to arrange a shorter stay or (rarely) break rules or act violently in order to be sent home. These ways of coping are rarely effective and can produce unintended negative side effects.\nHomesickness is a major theme of the film Brooklyn (2015). One critic said that the protagonist's depiction of homesickness \"as a physical, implacable reality is acute, and it's backed up by what we see around her.\"\n- Kerns, Brumariu, Abraham. Kathryn A., Laura E., Michelle M.(2009/04/13). Homesickness at summer camp. Merrill-Palmer Quarterly, 54.\n- Thurber, C.A. & Walton, E.A. (2007). Preventing and treating homesickness. Pediatrics, 119, 843–858.\n- Thurber, C.A., Sigman, M.D., Weisz, J.R., & Schmidt, C.K. (1999). Homesickness in preadolescent and adolescent girls: Risk factors, behavioral correlates, and sequelae. Journal of Clinical Child Psychology, 28, 185–196.\n- Thurber, C.A. (1999). The phenomenology of homesickness in boys. Journal of Abnormal Child Psychology, 27, 125–139.\n- Fisher, S. (1989). Homesickness, Cognition, and Health. Hove, UK: Lawrence Erlbaum.\n- Thurber, C.A. & Weisz, J.R. (1997). \"You Can Try or You Can Just Give Up\": The impact of perceived control and coping style on childhood homesickness. Developmental Psychology, 33, 508–517.\n- van Tilburg, M.A.L. & Vingerhoets, A. (Eds.) (1997). Acculturation stress and homesickness. Tilburg, The Netherlands: Tilburg University Press.\n- Thurber, C.A. & Walton, E.A. (2012). Homesickness and adjustment in university students. Journal of American College Health, 60, 1–5.\n- Fisher, S. & Hood, B. (1987). The stress of the transition to university: A longitudinal study of psychological disturbance, absent-mindedness and vulnerability to homesickness. British Journal of Psychology, 78, 425–441.\n- Zwingmann, C. (1959). \"Heimveh\" or \"nostalgic reaction\": A conceptual analysis and interpretation of a medico-psychological phenomenon [dissertation]. Stanford (CA): Stanford University.\n- Schweizerisches Idiotikon Bd. XV Sp. 42 f., Artikel Heimwē\n- van Tilburg, M.A.A. & Vingerhoets, A. (Eds.). (1997). Acculturation Stress and Homesickness. Tilburg, The Netherlands. Tilburg University Press.\n- Matt, S.J. (2011). Homesickness: An American History. USA: Oxford University Press.\n- Williams, A. (Ed.). (1999). Therapeutic Landscapes: The Dynamic Between Place and Wellness. New York: University Press of America.\n- American Psychiatric Association. \"Diagnostic and Statistical Manual of Mental Disorders.\" 5th ed. Washington, DC: Author: 2013\n- Thurber, C.A. (1995). The experience and expression of homesickness in preadolescent and adolescent boys. \"Child Development, 66\", 1162–1178.\n- Thurber, C.A., Patterson, D., & Mount, K.K. (2007). Homesickness and children's adjustment to hospitalization: Toward a preliminary model. \"Children's Healthcare, 36\", 1–28.\n- Verschuur, M.J., Eurelings-Bontekoe, E.H.M., Spinhoven, P., & Duijsens, I.J. (2003). Homesickness, temperament and character. \"Journal of Personality and Individual Differences, 35\", 757–770.\n- McCann, W.H. (1941). Nostalgia: A review of the literature. \"Psychological Bulletin, 38\", 165–182.\n- Fisher, S., Elder, L., & Peacock, G. (1990). Homesickness in a school in the Australian Bush. \"Children's Environments Quarterly, 7\", 15–22.\n- Mitchell, J.V. Recreational therapy program alleviates homesickness. \"Hospital Topics, 44\", 97–98.\n- Fisher, S., Frazer, N., & Murray., K. (1986). Homesickness and health in boarding school children. \"Journal of Environmental Psychology, 6\", 35–47.\n- Burt, C. (1993). Concentration and academic ability following the transition to university: An investigation of the effects of homesickness. \"Journal of Environmental Psychology, 13\", 333–342.\n- Abramson, L.Y., Seligman, M.E.P., & Teasdale, J.D. (1978). Learned helplessness in humans: Critique and reformation. \"Journal of Abnormal Psychology, 87\", 49–74.\n- Weisz, J.R., (1990). Development of control-related beliefs, goals, and styles in childhood and adolescence: A clinical perspective. In K.W. Schaie, J. Rodin, & C. Scholler (Eds.), \"Self-directedness and efficacy: Causes and effects throughout the life course (pp. 103–145). New York: Erlbaum.\n- Hendrickson, B., Rosen, D., & Aune, R.K., (2010). An analysis of friendship networks, social connectedness, homesickness and satisfaction levels of international students. \"International Journal of Intercultural Relations, 35\", 281–295.\n- Kerns, K.A., Brumariu., L.E., & Abraham, M.M., (2008). Homesickness at summer camp: associations with the mother-child relationship, social self-concept, and peer relationships in middle childhood. \"Journal of Developmental Psychology, 54\", 473–498.\n- Thurber, C.A. & Weisz, J.R., (1997). \"You can try or you can just give up\": The impact of perceived control and coping style on childhood homesickness.\" Developmental Psychology, 33, 508–517.\n- Byrnes, Paul (13 February 2016). \"Brooklyn: An Irish twist on the agonies and ecstasy of a migrant's story\". The Sydney Morning Herald. Retrieved 20 February 2016.\n- CampSpirit.com – Ideas about homesickness prevention and treatment, especially with children, plus empirical research on homesickness phenomenology.\n- CampParents.org – The American Camp Association's main page for parents, with links to more research on homesickness and materials for homesickness prevention.\n- \"Preventing and Treating Homesickness\" – Direct link to the American Academy of Pediatrics clinical report published in the journal \"Pediatrics\"\n- \"Curing Homesickness\" – profiles Dr. Christopher Thurber and his methods for preventing and dealing with homesickness.","What is seperation anxiety?\nSeparation anxiety is a fairly common anxiety disorder that affects children and young adolescents. According to the Diagnostic and Statistical Manual of Mental Disorders, Fourth Edition (DSM-IV-TR), a child with separation anxiety experiences recurrent excessive anxiety beyond that expected for the child's developmental level. This anxiety results from separation or impending separation from the child's attachment figure (for example, primary caretaker, close family member). As defined, this condition affects children younger than 18 years of age and occurs over a period of at least four weeks.\nCharacteristic features of separation anxiety disorder include severe distress, fear, or worry leading to impairment of functioning and frequently accompanied by somatic symptoms such as headaches or stomachaches (see Prognosis).\nWhat causes seperation anxiety?\nSeparation anxiety is a developmentally normal characteristic in infants and toddlers younger than 4 years of age upon separation from their primary attachment figure. Mild distress and clinging behavior are anticipated for short periods of time when young children are separated from their primary caregivers (attachment figures) in situations such as day care or initial exposure to school. Short-term developmental fears such as fear of the dark are expected in young children and are generally not severe enough to interfere with daily functioning or result in long-term difficulty.\nResearch studies indicate that some children who are overly fearful early in life may eventually develop anxiety disorders that result in substantial impairment. Significant symptoms of anxiety may emerge when a child enters school for the first time and is expected to adjust to daily separation from a parent or caregiver. In some cases, initial separation anxiety resolves over the first few weeks of school, while less commonly, the anxiety does not resolve spontaneously and worsens over time. Children who persist with significant anxiety disorders may have difficulty adjusting to the classroom leading to compromised academic performance.\nResearchers have hypothesized that children who develop separation anxiety disorders may have altered sensitivity to endocrine influences such as maternal cortisol, and the way in which they process emotionally intense experiences of separation. It is well known that certain parts of the brain (such as the amygdala) are involved in modulating the processing of emotional experiences.\nBullying and experiences of recurrent social rejection may contribute to the development of separation anxiety in vulnerable children and adolescents.\nHow do I know if my child has separation anxiety?\nSymptoms of separation anxiety disorder include the following:\n- Subjective feeling of anxiety\n- Unrealistic worries about the safety of loved ones\n- Reluctance to fall asleep if not near the primary attachment figure\n- Excessive dismay (for example, tantrums) if separation from the primary attachment figure is imminent\n- Nightmares with separation-related themes\n- Psychosomatic symptoms such as:\nWhen to Seek Medical Care for Separation Anxiety\nSeek medical evaluation when social functioning becomes impaired, that is when a child or adolescent is refusing to go to school, is not socializing, is avoiding participation in sports or recreation, or is unwilling to be separated from the primary caregiver.\nAnxiety Disorder Pictures: Symptoms, Panic Attacks, and More with Pictures\nQuestions to Ask the Doctor about Separation Anxiety\n- Can you perform an evaluation to determine if my child is socially isolated due to anxiety or depression?\n- Can you perform or refer for a family assessment?\n- How can the child be supported in the school environment to prevent secondary school refusal?\n- What other tests should be performed to rule out other causes of anxiety symptoms?\nSeparation Anxiety Exams and Tests\nThe following structured and semistructured interview scales, administered by a medical professional, can be extremely helpful for the diagnosis and treatment of separation anxiety disorder:\n- The Anxiety Disorders Interview Schedule for Children (ADIS)\n- The Anxiety Rating Scale for Children (Revised)\n- Multidimensional Anxiety Scale for Children (MASC) - Duke University\n- Revised Children's Manifest Anxiety Scale\n- Visual Analogue Scale for Anxiety (Revised)\n- Interview Schedule for Anxiety Disorders for DSM-IV (Child Version)\n- Social Anxiety Scale for Children (Revised)\n- Diagnostic Interview for Children and Adolescents Revised (DICA-R)\n- National Institute of Mental Health Diagnostic Interview Schedule for Children (DISC)\n- Child Behavior Checklist (Achenback ASEBA)\n- The Screen for Child Anxiety Related Emotional Disorders (SCARED) - Western Psychiatric Institute and Clinic (WPIC)\n- The Separation Anxiety Test (Wash U)\nA physical exam with clinically pertinent medical testing should be performed, preferably by the primary-care physician. Tests may be performed to rule out metabolic abnormalities (for example, hyperthyroidism, hypoglycemia), cardiovascular abnormalities, or central nervous system infections because they may cause symptoms of acute anxiety that, in children, might appear to be separation anxiety.\nSeparation Anxiety Treatment\nThe child or adolescent and his or her family, school staff, and primary-care physician should work together to design a plan to accomplish a gradual return to developmentally expected function in settings such as school, sports, and social events. It is very important to acknowledge the level of distress that the child or adolescent feels.\nUtilizing positive reinforcement aids in encouraging the child's return to the feared situation and becoming comfortable with anticipated brief separations from parents and caregivers.\nCognitive-behavior therapy, including response prevention and exposure therapy has been shown to be effective, especially in helping the child or adolescent return to normal daily function.\nAntianxiety medications may be effective but are not U.S. Food and Drug Administration (FDA)-approved for people younger than 18 years of age.\nSeparation Anxiety Home Remedies\nDeveloping a routine of self-directed relaxation exercises, including breathing routines of about five to six deep and slow breaths during periods of discomfort, may be beneficial in reducing anxiety symptoms; however, avoiding continuous deep breathing leading to hyperventilation is important.\nMedical Treatment for Separation Anxiety\nMedical treatment should include treating any contributory medical causes of anxiety if present.\nOther Therapy for Separation Anxiety\nGentle exercises that encourage relaxation, such as meditation or yoga or tai chi, may be helpful in reducing anxiety symptoms. In older children and teenagers, mindful meditation can be especially helpful.\nFollow-up for Separation Anxiety\nThe child's progress in regaining normal function should be closely monitored. Factors that discourage the child from returning to health, such as family stressors, should also be explored. The therapist's approach to a child with separation anxiety should be low-key and expectations should progress at a pace that does not increase the child's anxiety.\nSeparation Anxiety Prevention\nTechniques such as modeling, role-playing, relaxation techniques, and positive reinforcement for independent functioning can be helpful in preventing young children from developing crippling symptoms associated with separation anxiety.\nfor Separation Anxiety Prognosis\nHelping children with separation anxiety to identify the circumstances that elicit their anxiety (upcoming separation events) is important. A child's ability to tolerate separations should gradually increase over time when he or she is gradually exposed to the feared events. Encouraging a child with separation anxiety disorder to feel competent and empowered, as well as to discuss feelings associated with anxiety-provoking events promotes recovery.\nChildren with separation anxiety disorder often respond negatively to perceived anxiety in their caretakers, in that parents and caregivers who also have anxiety disorders may unwittingly confirm a child's unrealistic fears that something terrible may happen if they are separated from each other. Thus, it is critical that parents and caretakers become aware of their own feelings and communicate a sense of safety and confidence about separations.\nPanic attacks are repeated attacks of fear that can last for several minutes.\nMedically reviewed by Margaret Walsh, MD; American Board of Pediatrics\n\"Anxiety disorders in children and adolescents: Epidemiology, pathogenesis, clinical manifestations, and course\""],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:978069a7-58af-4a11-a0d8-1a5ee2640311>","<urn:uuid:1aafed97-d5c1-4da9-8a54-55d2e5d02704>"],"error":null}
{"question":"Could you explain how T-cell memory regulation through selectins might influence vaccination strategies, particularly considering the challenges with immunocompromised patients and measles vaccines?","answer":"T-cell memory regulation through selectins has important implications for vaccination strategies. Research shows that selectin-binding capacity could be a new stable marker of memory T cells that have achieved effector function, which could be valuable for clinical studies. This is particularly relevant when considering vaccination strategies, especially for measles, where we face specific challenges with immunocompromised patients. People with suppressed immune systems cannot receive the live measles vaccine, making them particularly vulnerable. This situation emphasizes the importance of achieving widespread vaccination in the general population to protect these vulnerable individuals through herd immunity. Understanding selectin-regulated T-cell memory could potentially lead to new approaches in vaccine development and protection strategies.","context":["Understanding mechanisms that regulate memory in T cells is crucial for developing strategies to protect against epidemic and pandemic influenza viruses. The goal of this project is to determine the contribution of the selectin family of adhesion molecules (E, P, and L) and the selectin ligand, PSGL-1, to T cell memory Recently, we found that glycosylated, biologically active ligands for selectins are acquired by a subset of CD4 and CD8 effectors in the draining lymph nodes after influenza virus infection and represent the majority of responding T cells in the lungs including IFN-g or IL-17 producers, in vivo correlates of Th1 and Th17 cells, respectively. Moreover, we find that a consistent fraction of memory phenotype T cells express selectin-binding activity, suggesting that this is a stable heritable trait that distinguishes a subset of memory cells. In the absence of functional selectin ligands or PSGL-1, CD4 cell expansion and localization in the lungs after influenza virus infection is unaltered. However, CD4 effectors produce elevated levels of IFN-g and IL-17 suggesting a role for selectin ligands in dampening the effector response. Importantly, the development of memory CD4 cells with the capacity for secondary expansion after infection is impaired, possibly because of altered homeostatic regulation. Our data support the hypothesis that mechanisms regulated by selectins can be essential for the delivery of signals that control CD4 effector cell responses as well as the homeostatic maintenance of a subset of memory cells. We will investigate the novel function(s) of selectins in the regulation of effector and memory T cells in following specific Aims: 1) to determine if differences in selectin-binding capacity identify memory T cell subsets with distinct functional properties and homeostatic regulation;2) to investigate selectin-dependent responses of T cells and the role of selectin- binding capacity in the generation of memory cells after influenza virus infection;and 3) to identify mechanisms by which selectins regulate T cell homeostasis. We will take advantage of mice that are deficient in PSGL-1-/-, mice that lack PSGL-1 signaling, and mice that lack functional selectin ligands due to deficiency of the IV/VII fucosyl transferases. We will use IFN-g and IL-17 reporter mice, selectin ligand fusion proteins, and WT and engineered influenza viruses to enable us to assess the responses of polyclonal and TCR transgenic CD4 cells and make comparisons to CDS cells. In each of these Aims we will collaborate with Projects 1 and 2 to examine defined subsets of CD4 and CD8 cells in the influenza model. We will collaborate with project 4, which will determine the relevance of selectins in the tuberculosis model.\nThese studies together with those of projects 1, 2, and 4 will investigate means by which the immune system controls pulmonary infections and will provide new insights into the regulation of the development and homeostasis of memory T cells through mechanisms that regulate adhesion and migration that could be important for strategies to help protect the population from acute as well as chronic infections. Selectin- binding has the potential to be a new stable marker of memory T cells that have achieved effector function This would be an important breakthrough that could be extremely valuable in both clinical and basic studies.\n|Bautista, Bianca L; Devarajan, Priyadharshini; McKinstry, K Kai et al. (2016) Short-Lived Antigen Recognition but Not Viral Infection at a Defined Checkpoint Programs Effector CD4 T Cells To Become Protective Memory. J Immunol 197:3936-3949|\n|Strutt, Tara M; McKinstry, Karl Kai; Kuang, Yi et al. (2016) Direct IL-6 Signals Maximize Protective Secondary CD4 T Cell Responses against Influenza. J Immunol 197:3260-3270|\n|Tinoco, Roberto; Carrette, Florent; Barraza, Monique L et al. (2016) PSGL-1 Is an Immune Checkpoint Regulator that Promotes T Cell Exhaustion. Immunity 44:1190-203|\n|Brodeur, Tia Y; Robidoux, Tara E; Weinstein, Jason S et al. (2015) IL-21 Promotes Pulmonary Fibrosis through the Induction of Profibrotic CD8+ T Cells. J Immunol 195:5251-60|\n|Torrado, Egidio; Fountain, Jeffrey J; Liao, Mingfeng et al. (2015) Interleukin 27R regulates CD4+ T cell phenotype and impacts protective immunity during Mycobacterium tuberculosis infection. J Exp Med 212:1449-63|\n|Cooper, Andrea M (2015) Mouse model of tuberculosis. Cold Spring Harb Perspect Med 5:a018556|\n|Cruz, Andrea; Torrado, EgÃdio; Carmona, Jenny et al. (2015) BCG vaccination-induced long-lasting control of Mycobacterium tuberculosis correlates with the accumulation of a novel population of CD4âºIL-17âºTNFâºIL-2âº T cells. Vaccine 33:85-91|\n|Sell, Stewart; Guest, Ian; McKinstry, K Kai et al. (2014) Intraepithelial T-cell cytotoxicity, induced bronchus-associated lymphoid tissue, and proliferation of pneumocytes in experimental mouse models of influenza. Viral Immunol 27:484-96|\n|McKinstry, K Kai; Strutt, Tara M; Bautista, Bianca et al. (2014) Effector CD4 T-cell transition to memory requires late cognate interactions that induce autocrine IL-2. Nat Commun 5:5377|\n|Jain, Nitya; Miu, Bing; Jiang, Jian-kang et al. (2013) CD28 and ITK signals regulate autoreactive T cell trafficking. Nat Med 19:1632-7|\nShowing the most recent 10 out of 80 publications","A measles virus infection starts off as a respiratory infection. Thus, it starts off looking and feeling like a common cold. But then it takes a dangerous turn: it infects the immune system. Measles can cause long-lasting damage to the immune system. Recent studies have shown that a case of measles can increase a child’s risk of death from other infections for more than 2 years!\nMeasles is not the only viral infection that is known to produce long-term suppression of the immune system. Another example is the human immunodeficiency virus (HIV), which is the cause of acquired immunodeficiency syndrome (AIDS). However, HIV and the measles virus attack different kinds of white blood cells, which are the workhorses of the immune system.\nHIV attacks the T4 lymphocytes, which are often called T-helper cells. T-helper cells help the other cells of the immune system recognize infections and tumor cells. After an HIV-infected person’s T4 cell count drops to dangerously low levels, his or her immune system is less able to fight many infections and some cancers (such as Kaposi’s sarcoma). Thus, the weakening of the immune system gives germs and cancer cells an opportunity to survive and thrive. The resulting diseases are called opportunistic.\nPeople who are infected by HIV will remain infected for the rest of their lives. In contrast, most people who catch the measles will eliminate the measles virus from their body after only a few weeks. Yet the measles infection can cause long-lasting effects on the immune system because it wipes out the immune system’s memory. Measles virus kills the B memory cells, which are the white blood cells that are supposed to remember the germs that the body has successfully fought in the past. After the B memory cells are killed off, the immune system must relearn much of what it had already learned about dangerous germs. In the meantime, the person remains at risk for opportunistic infections.\nHIV is bad, and so is measles. Having HIV and measles at the same time is particularly bad. The death rate from measles is particularly high in people who have any other form of immune suppression. Unfortunately, people who have a suppressed immune system cannot be vaccinated against measles, because the measles vaccine is a “live” vaccine. To protect those vulnerable people, we must ensure that practically everyone else is vaccinated against measles.\nMost of the deaths due to measles are due to opportunistic infections. Thus, it is hardly surprising that the death rate from measles started to fall after the introduction of antibiotics, even though antibiotics have no effect on the measles virus itself. Yet even with the best of modern medical care, people still die of measles. Even if they survive, they may be left with permanent disabilities, such as blindness, deafness, and brain damage. In some cases, the measles virus infection may persist in the brain. This persistent infection leads to a horrible disease called subacute sclerosing panencephalitis (SSPE), which slowly destroys the brain. Thus, it leads to a slow and horrible death. There is no cure or even any effective treatment. Fortunately, SSPE can be prevented by preventing measles.\nThe vaccine against measles provides powerful, long-lasting protection. If you have received two doses of the measles vaccine, your chances of catching measles go down by about 97%. Thanks to the widespread use of the measles vaccine, measles was eliminated from the United States by the year 2000. Unfortunately, we still have occasional outbreaks of measles in the United States. Most of these cases can be traced to someone who was exposed to measles in some other country. So the best way to protect ourselves against measles is to drive the measles virus into extinction worldwide.\nUnfortunately, many parents are refusing to allow their children to be vaccinated against measles. Many of these parents have been told that it is better to allow their children to get sick, so that they develop immunity naturally. In reality, many of the vaccine-preventable diseases are dangerous because they suppress the immune system. This immune suppression is good for the germ that causes the disease, but it is bad for the person who has the disease. As a result, having a vaccine-preventable infection can increase your risk of dying of some other infection.\nMany parents are refusing vaccination because they think that the vaccines are unnecessary and unsafe. Conspiracy theorists claim that vaccines are being promoted simply to make money for the pharmaceutical companies. Yet if some sociopathic “pharma bro” really wanted to make money on vaccines, he would make sure that the vaccine-preventable diseases remain in circulation. Once a disease has been driven into extinction through vaccination, there is no longer any need to vaccinate anyone against it.\nSmallpox is extinct. Today, nobody vaccinates children against smallpox. After polio is extinct, the sales of the polio vaccine will drop to zero. Like smallpox and polio, measles is caused by a virus that can be found only in human beings. Once we have wiped measles, mumps, and rubella off the face of the earth, nobody will need the MMR vaccine. But it would be madness to stop vaccinating against those diseases before then.\nFor information about efforts to eradicate measles, visit the Measles & Rubella Initiative."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:3174022b-d7c8-4a9d-aa85-a4bda16f34ca>","<urn:uuid:44b9c60c-fc94-4bf6-90d1-e4c3595cb2e5>"],"error":null}
{"question":"How do shark attacks vary across different activities and populations, and what role do lifeguards play in beach safety?","answer":"Surfers and board sport participants account for 65% of shark attack victims, swimmers and waders 32%, and snorkelers only 3%. Men are particularly vulnerable, comprising 93% of shark attacks from 1580 to 2010. Regarding safety, beaches with lifeguards provide the best protection. Lifeguards use whistles, sirens, speaker announcements, hand signals, and verbal instructions to keep beach-goers safe. They monitor water conditions and may close beaches due to dangerous conditions like rips, shark sightings, or jellyfish presence.","context":["13 Things You Didn’t Know About Shark Attacks\nWomen are safer from sharks than men, punching a shark isn’t the best defense, and most shark attacks occur during non-summer months. Surprised? Read on for more scintillating facts about shark attacks.\nShark attacks are rare, and almost never deadly\nThe real-life likelihood that you’ll have a close encounter with a shark is about 1 in 11.5 million, according to the International Shark Attack File. In fact, you’re more likely to be injured in a boating accident or bike wreck than you are in a shark attack. More good news: death by shark hardly ever happens. In 2017, for example, there were no fatalities from shark attacks in America. These are the tips that could save your life in the event of a shark attack.\nThe safest people in the water are snorkelers\nAccording to the Florida Museum of Natural History, surfers and other people participating in board sports accounted for 65 percent of shark attack victims in 2014, followed by swimmers and waders (32 percent), and snorkelers (3 percent). These are the water safety tips lifeguards wish you knew.\nPunching a shark may not be your best defense\nPieter De Pauw/iStock\nSwinging your arm through water can be difficult, so, if you’re attacked by a shark, “grab at the eyes and gills, which are very sensitive,” Andrew P. Nosal of the Scripps Institutions of Oceanography the New York Times. Here’s what happened when this surfer punched a shark to try to save his friend.\nVery few species of sharks attack humans\nOf the nearly 500 species of shark, only about 30 have ever attacked a human, and three species—great white, tiger, and bull—are responsible for the majority of human fatalities.\nMost shark attacks are on men\nAccording to Nat Geo Wild, 93 percent of shark attacks from 1580 to 2010 were on boys or men. The explanation comes down to numbers: More men than women surf, boogie board, and SCUBA dive—all sports that come with a risk of attack.\nAttacks spike in September\nIn Florida, the U.S. state with the most shark attacks, September is the most dangerous month to be in the water, according to the International Shark Attack File. From 1926 to 2012, 103 attacks occurred in that month, compared to 61 in June, 73 in July, and 84 in August. Can’t get enough of sharks? Check out these fascinating facts about the filming of Jaws.\nJust like us, sharks eat breakfast and dinner\nSharks feed around dawn and dusk, so it’s best to stay out of the water or be especially careful then.\nSharks don’t attack on purpose\nBut they sometimes mistake humans for food in murky water. Imagine the white flashes of the underside of a person’s feet as they are kicking through the water or the sparkle of jewelry on ankles or wrists. “A shark may confuse it with its natural prey,” John Carlson, a research biologist at the Southeast Fisheries Science Center, told the New York Times. Reduce your (already slim) chances of a shark encounter by leaving your jewelry on the beach. Here are some far more dangerous (and much smaller!) creatures to watch out for this summer.\nThe world’s shark population is decreasing\nLest you think the ocean is “teeming” with sharks: “The shark population in the U.S. and around the world are at perhaps all-time lows,” George Burgess, director of the International Shark Attack File at the Florida Museum of Natural History, told NPR. “On the other hand, the human population continues to rise every year. Fundamentally, the number of shark attacks every year is driven by the number of people in the water, not the number of sharks.” Here are some more wild animal species you had no idea were endangered.\nYou can track sharks online\nScientists and conservationists tag a small population of sharks, usually with dart guns or through slightly more dangerous methods, to gather information on their migratory patterns, size, and growth. Using that data, tracking the animals online has also become somewhat of a hobby for some beachgoers, who can follow tiger sharks in and around Hawaii, and several shark species in Western Australia and in much of the northern hemisphere. One popular great white named Mary Lee has more than 120,000 followers on Twitter.\nSharks follow the (non-human) food\nScientists have reported high numbers of herring and sea turtles in the Outer Banks of North Carolina, which may have explained the unusually high number of shark attacks in that area in recent years.\nFew shark attacks happen in fresh water\nAlthough bull sharks, one of the most aggressive and attack-prone species of sharks, can survive in rivers, lakes, and even streams, in addition to the ocean, few freshwater human-shark encounters have been recorded. Next, check out these tips that can keep you and your family safe on a beach vacation.","no body of water is safe without a lifeguard\nNo Body Of Water Is Safe Without A Lifeguard\nWhen lifeguards get on patrol, the best place to swim is between the red as well as yellow flags. The flags are put at either end of the areas of the sea the lifeguards take into consideration to be secure to swim in. Swimmers need to prevent these locations unless you intend to police officer a board to the head. When at patrolled beaches, the very first point to do is take note of any signs, especially if the indications state the beach is shut.\nAlthough playing in the water is a terrific kid-friendly task, it is very important to know that swimming can be dangerous. Do not undervalue an unsafe situation in the water, such as if a person is sinking or being drawn by a present. Treat these possibly deadly situations with urgency and severity. If you are an unskilled swimmer yourself or you are with individuals who are unskilled swimmers, U.S. Coastline Guard-approved life jackets need to be put on around the water. A dog swims much like a meal to a shark as well as will certainly attract attention.\nBe positive in your safety and security as opposed to jumping in the water without recognizing just how deep it is. Surf Life Saving Australiaconsiders slits to be the primary threat on Australian beaches (yes, it’s not sharks in spite of the media hype). Many individuals have actually died or come close to fatality by panicking or attempting to swim versus the split attempting to get back to coast. Make it easier for lifeguards to maintain so many people secure by following their instructions.\nTake into consideration selecting coastlines, rivers, pool and water parks that utilize lifeguards and also have them at work. Prior to you enter the pool, lake or sea, examine the deepness of the water in the location you intend to swim in.\nThe primary step to staying safe from shark assault while swimming is to stay out of the water throughout the sharks feeding times. Many species of shark are understood to come closer to shore during sunset, dawn, and night time hours. Do not swim or surf throughout these high threat time frames. In a swimming pool, you’re always aware of what the exact deepness is, where the sides are, as well as the water in it is not moving, as well as not transforming. Find out just how to stay shark risk-free while swimming in Australia. And also, we breast the misconceptions and also type reality from fiction around the real risks. While an Australian summer season will do wonders for your tan, several tourists take too lightly the harshness of the Australian sun.\nRed, roasted Brits and also Europeans on Australian beaches are an usual view, yet this can be avoided. Constantly slip, slop, put; slip on a t shirt, slop on a waterproof, broad-spectrum sun block (at the very least 30+) and also slap on a hat. Worldwide annually, approximately 10 individuals are fatally bitten by a shark. Statistically, you are more likely to sink at a coastline than be bitten by a shark. in 2017, 116 people sank at coastlines and coastal locations in Australia. Most of Australia’s beaches have slits, effective currents that can drag a swimmer bent on sea. Splits can behave in many different means and are affected by the morphology, swell, waves as well as various other variables.\nThose are all bacteria that you do not want to show other people that are swimming in the water. It is your responsibility to see to it your youngsters are refraining from doing things they ought to not be doing but in public areas or in your own backyard pool. Swimming is one of the best exterior activities that you can do during the summertime.\nThey will certainly utilize whistles, sirens, speaker news, hand signals and also verbal instructions to keep beach-goers secure. Australia is understood for its unbelievable shoreline as well as magnificent, pristine beaches. And with 85% people living within 50km of the coast, Aussies enjoy the coastline as long as visitors. Every person will certainly be much more secure and have a a lot more fun time if they understand just how to swim. Instructing kids to swim as well as how to have secure fun in the water is just one thing every moms and dad should carry out in their life time. Bathing thoroughly with soap before swimming can help remove perspiration, body oils, cosmetics and also traces of pee and fecal matter on the body.\nMake certain that you leave the pets at home for your beach trip or at the very least maintain them out of the water. Make certain that the coastline you are going to swim at is patrolled by lifeguards.\nThis is not due to the fact that the lifeguards are on strike, it’s since the water is considered as well harmful. This can be because of rips, shark sighting, jellyfish etc . Do not disobey any kind of signage or instructions from lifeguards, they are there for your safety and security. If you remain in a public place, it is essential to swim in designated locations where lifeguards can quickly be accessed."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:1297209b-b2de-40e8-9b9f-6681f9f2348a>","<urn:uuid:91fddb2d-bb52-4fef-a129-29a7a9f1cc93>"],"error":null}
{"question":"Hey, as someone interested in mental health support options - how do live supervision techniques in counseling compare to the therapeutic approach used in group therapy sessions when it comes to real-time feedback and interaction?","answer":"Live supervision techniques in counseling and group therapy sessions utilize real-time feedback and interaction in different ways. In live supervision, the supervisor actively monitors and intervenes in a counseling session using methods like bug-in-the-ear devices, phone-ins, or computer monitors to provide immediate guidance to the supervisee counselor. This requires careful pre-session planning and can potentially affect the therapeutic relationship if not handled well. In contrast, group therapy sessions focus on peer-to-peer interaction where members provide immediate feedback to each other under a therapist's guidance. The group becomes a safe environment where participants can address difficult situations and practice new behaviors with multiple people simultaneously. While live supervision aims to develop counselor skills through direct intervention, group therapy leverages the collective wisdom and feedback of peers to help members gain insights and improve their interpersonal relationships.","context":["Individual and Group Supervision in Counseling\nIndividual supervision is one-to-one supervision with a supervisor and a supervisee. This can be completed face-to-face, by telephone, or by email, although the latter is still a relatively new area and requires additional attention in relation to relevant practical, ethical and legal issues. Group supervision can be used as a complement to, but not a substitute for, individual supervision. It provides many advantages to both the supervisee and supervisor. In this article, we describe different methods and techniques offered by individual and group supervision in counseling.\nIndividual and group supervision in counseling\nOne critical issue for the application of different techniques of supervision is that the supervisor focuses on the learning needs of their supervisee, not on client issues. Bernard and Goodyear (1998) describe in detail the different methods and techniques offered by individual supervision, below is a brief summary of each.\nSelf-Report: Like a case conference, the supervision technique of ‘self-report’ requires the supervisee to recollect and discuss therapy sessions. This is the most frequently used supervision method and allows the supervisee to reflect in detail their own experiences with their clients. However, the effectiveness of the technique is greatly affected by the insightfulness and observation skills of the supervisee.\nProcess Notes: This technique requires the supervisee, after a therapy session, to write comprehensive notes about the processes encountered. This is not a literal account of what occurred in therapy, rather an introspective description of the experience from the supervisee’s perspective. The discussion of these notes in supervision can create a productive and meaningful supervisory environment. However, like other self-report methods it is dependent on the supervisee’s ability to accurately observe internal and external occurrences.\nAudiotape: The use of an audiotape of the supervisee counseling sessions is one of the most widely used methods of supervision. Although supervisees are often hesitant to embark on what seems like a very disclosing process, with practice, it can become a valuable tool for both supervisees and supervisors. While recording counseling sessions is a useful supervision resource, it is important to also consider the impact that this can have on clients and potentially on the therapeutic relationship. Clients must be given the opportunity to refuse to participate in the recorded sessions, and it is essential that their expectation of confidentiality is assured.\nVideotape: This can be an expensive and bulky resource, but videotaping supervisee counseling sessions provides the most valuable source of information for the supervision of all the techniques discussed. The problems with this method are that the supervisee needs to be comfortable with the use of technology. Otherwise, it can cause excessive performance anxiety, and it might provide too much information causing both the supervisee and supervisor to be overwhelmed.\nBernard and Goodyear, (1998) suggest six guidelines for using video in supervision. These are:\n- Focus supervision by setting realistic goals for the videotaped therapy session.\n- Discuss the internal processes of the supervisee during the videotaped therapy session.\n- Select tape segments that focus on performance that the supervisee is able to change with corrective feedback.\n- Use supervisor comments to create a moderate discrepancy between performance and the target goal.\n- Refine goals moderately as the videotape review must be seen in the larger context of supervisee development.\n- Maintain a moderate level of challenge so that the supervisee is stimulated to grow without becoming overly threatened.\nLive Observation & Live Supervision: Live observation as its name suggests is simply when a supervisor observes through a one-way mirror, the supervisee conducting a counseling session with a client. Live supervision, however, occurs when the supervisor observes and interacts with the supervisee during the counseling session. Both live observation and live supervision provide a more complete picture of the supervisee’s skills than audio or videotape, and allow the supervisor to intervene in the case of an emergency.\nLive supervision can be conducted by using any of the following methods:\n- Bug-in-the-Ear: An ear receiver that provides brief, one-way communication from the supervisor.\n- Monitoring: The supervisor monitors the session and steps in and runs the session if necessary.\n- In Vivo: Therapy is interrupted and a supervision consultation occurs in front of the client/s, then the supervisee continues the session.\n- Walk-in: Is more of a therapy intervention where the supervisor enters the room at a pre-arranged time and talks with the supervisee and the client/s.\n- Phone-in and Consultation Breaks: The session is interrupted so the supervisee can receive input from the supervisor. This is done either by a phone call in the session or a break where the supervisee leaves the room for consultation with the supervisor.\n- Using Computer Technology: A computer monitor is placed behind the client and the supervisor would type comments for the supervisee to read during the session.\nAs live supervision requires a co-ordinated response from the supervisee and the supervisor, all the methods above require pre-session planning and post-session debriefing. It is essential that the supervisor is sensitive to the supervisee’s anxiety and vulnerability with the use of this form of supervision. Live supervision increases the practical demands of supervision in time, cost of facilities, and organizing appointment schedules.\nIf not handled effectively by the supervisor it can also decrease the supervisee’s initiative and creativity, and the therapeutic relationship could potentially be negatively affected by the intrusion of this form of supervision. However, when managed correctly live supervision provides a more profound learning experience for supervisees and a more protective environment for clients. Most supervisees require instruction in the many counseling strategies at some point in their supervision. During these instances the supervisor will most likely use the four steps of micro-training:\n- teach one skill at a time,\n- present the skill using modeling or demonstration,\n- practice the skill;\n- allow for mastery using practice and feedback.\nGroup supervision can be used as a complement to, but not a substitute for, individual supervision. It provides many advantages to both the supervisee and supervisor including:\n- Vicarious learning about a broader range of clients and situations than the counselor/ supervisee could gain in individual supervision session\n- Efficient use of time, money and expertise\n- Providing the supervisor with a more comprehensive picture of the supervisee for evaluation\n- Provision of diverse feedback for the counselor/ supervisee from their peers and from the supervisor\nTasks completed in group supervision include didactic presentations, case conferences, individual development, and group development. All of these tasks can provide valuable experiences to the supervisees while the group continues to function effectively. It is the role of the supervisor in group supervision to monitor the group processes and ensure that supervisees are challenged to stretch themselves but do not feel overwhelmed, and are supported but not patronized. Supervisors must also be aware of the five stages of group development: Forming, Storming, Norming, Performing, and Mourning.\nOne important task during the early stages of development is the establishment of the group structure. This involves making decisions about group participants (e.g. homogenous versus heterogeneous), group rules, and termination (e.g. a time-limited versus an ongoing group). The impact of all five stages needs to be addressed by the supervisor to maintain the benefits of group supervision for all supervisees.\nSource: Becoming a Supervisor CE Course","About Group Therapy\nGroup psychotherapy is a form of treatment in which a small number of people, usually between five and ten, meet together under the guidance of a professionally trained therapist to help themselves and one another. This form of therapy is widely used and has been a standard treatment option for over 50 years.\nTo a great extent, the quality of a person's life depends on the quality of their relationships. Much of our growth and development as human beings occurs in relationship with a number of people simultaneously, such as occurs in families, schools, workplaces, houses of worship, and organized activities such as parties.\nThe value of group psychotherapy lies in its ability to allow the individual group member to recreate the social aspects of his or her life in a way that is difficult to achieve in one on one therapy. Under the guidance of a trained therapist, the individual, with the help of the other group members, can gain tremendous insight into issues that might be interfering with the enjoyment of life. The group also gives the participant an ideal \"laboratory\" to develop and experiment with newer, healthier behaviors.\nIn a number of studies, group psychotherapy has been shown to be at least as effective, and sometimes even more so, than individual therapy. To give just one example, in cases of medical illness, there is substantial evidence that group psychotherapy helps people cope better with their illness, and enhances the quality of their lives.\nThe Group Psychotherapist\nGroup psychotherapists are mental health professionals trained in one of a variety of areas, including psychiatry, psychology, social work, psychiatric nursing, marriage and family therapy, pastoral counseling, creative arts therapy or substance abuse counseling. Although most group psychotherapists perform individual psychotherapy, and are skilled at it, they have particular training and experience in the running of groups. It is important to ask a potential group therapist about his or her background, as many professionals who run groups are not necessarily trained to do so. Practitioners with the letters “CGP” after their names are registered by the National Registry of Certified Group Psychotherapists, which means that they have completed a course of study and have spent a certain number of supervised hours in doing groups. There are many professionals who may lack the CGP, but who have completed group training programs, or have gotten a great deal of experience running groups in organized settings, such as outpatient clinics, schools, and hospital units, and bring these skills to bear in private practice.\nWho Can Benefit?\nLike individual therapy, group therapy can benefit most people. Among the issues typically addressed in groups are:\n- Difficulties with interpersonal relationships\n- Problems facing children and adolescents (such as impact from a divorce, peer issues, learning or behavioral problems)\n- Medical illness\n- Depression, anxiety, and other mental health issues\n- Loss (i.e., bereavement)\n- Personality disorders\n- Addictive disorders\nThe Group Therapy Session\nGroup therapy sessions generally last between 75 and 90 minutes. Although group therapists may have different styles, they all concern themselves not only with the progress of the individuals in the group, but also with the safety of the group as a whole. Depending on the particular focus of the group, members work to express their own needs, feelings, ideas and reactions as freely and honestly as possible. To a remarkable extent, the issues that arise for individuals in a therapeutic group mirror what is occurring in their lives in \"the real world\". The group becomes a place where its members can address difficult situations in a safe, caring and confidential environment. The work of giving feedback is divided between the leader and the other group members. In this way, the members become each other’s \"therapists\".\nFrequently Asked Questions\nHow is group therapy different from support groups and self-help groups?\nGenerally speaking, leaders of therapy groups strongly discourage contacts between members outside of the group. This rule helps protect the group and its participants from outside relationships, and it also enhances confidentiality. This is usually not true of self-help and support groups, where outside contact is encouraged as a means of boosting necessary social support. Therapy groups are run by clinical professionals who are specifically trained for that purpose. This is not true of many support groups, and is not at all true of self-help groups, which are usually facilitated by volunteers.\nIn summary, group therapy focuses on improving interpersonal relationships under the guidance of a trained mental health professional. Self-help and support groups have as their focus the resolution of a specific issue or situation (e.g., addiction; spousal loss).\nWhy is group therapy useful?\nStudies have shown that groups are better at solving problems than individuals. The collective wisdom of a group of people is far broader and deeper than that of any one group member. (This insight accounts for our tradition of trial by jury.) When a person receives the same piece of feedback from several peers within a group, it is usually a sign of an issue that might require some work. She can use the group to practice different and more adaptive responses, which will then improve her experience of her life outside the group. She can also respond to others within the group about their problems and difficulties, thereby learning even more about herself and how she interacts with others.\nGroups mimic social situations in a way that individual therapy does not. A person who is shy and finds it difficult to talk to people on the job or at parties, for example, will find a group tremendously helpful. He can practice new socializing behavior in a safe environment under the guidance of a clinical professional.\nWhat kind of commitment do I need to make?\nThe time commitment depends on the type of group you're considering. Short-term groups devoted to concrete issues can last anywhere from several weeks to several months. Many therapy groups are open-ended, meaning that there is no set point to termination. People leave these groups when they feel that they have derived sufficient benefit. Their involvement may span a period of years. In groups such as these, the therapist generally requires some kind of time commitment, so that the individual can give the group a fair chance to work for them.\nWhat if I am uncomfortable discussing my problems in front of others?\nIn professionally run therapy groups, the individual has already met with the therapist privately prior to starting the group. The connection developed during this meeting generally alleviates the anxiety and discomfort that can occur when entering into a group. With regular attendance and participation, most people soon begin to develop feelings of trust with their peers. Meeting on a regular basis with a gathering of people with similar issues can provide a great source of relief in that the group members feel less \"alone\" with their difficulties.\nHow do I find a group therapist?\nA professional group therapist has received specialized training in group therapy and meets rigorous standards. As was stated earlier, some group therapists have the CGP credential, which is granted by the National Registry of Certified Group Psychotherapists. Others may not have that particular credential, but they have received training and/or have extensive experience in running groups in clinical settings. The members of the Eastern Group Psychotherapy Society (EGPS) have a special interest in group therapy, and they are listed in a special database by name, specialty and location. EGPS also has a referral service that helps individuals seeking a therapy group."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:5e5388e8-6e02-4174-b8c6-2c27c280c502>","<urn:uuid:f6612d63-bc89-43cc-bd91-abe831878b4e>"],"error":null}
{"question":"What are the current scientific efforts to enhance biodiversity in ecosystem restoration projects, and what major environmental challenges are these projects facing as exemplified by coral reef degradation?","answer":"Scientists are working to bridge the 'practice science gap' between practitioners and biodiversity research to optimize restoration projects. Research shows that increasing biodiversity leads to improvements in ecosystem functions. However, challenges include larger spatial scales of restoration projects compared to scientific studies, and funding constraints for monitoring. Meanwhile, environmental challenges are severe, as demonstrated by coral reef degradation. For instance, the Great Barrier Reef has experienced unprecedented coral bleaching, with 91% showing signs of bleaching and coral cover dropping from 28% to 13% over the last 27 years. This bleaching is directly linked to global warming, and the severity of recent events means slow-growing corals won't have time to recover.","context":["As restoration projects throughout Massachusetts and the country focus on restoring natural ecosystems, researchers are looking for ways to better bridge the \"practice science gap\" between practitioners and biodiversity research in an effort optimize these types of projects. The findings were recently published in the journal Conservation Letters.\n\"Our sense was that some of the science we do wasn't being translated to restoration practice,\" said Dr. Randall Hughes of Northeastern University's Marine Science Center and lead author of the paper. \"We aren't pointing any fingers at a particular side of this gap, we are pointing out that the gap exists and it would be nice to try and close it.\"\nHughes says there are more than two decades of research that show if you increase biodiversity—the living organisms that occupy an ecosystem—important ecosystem functions begin to see positive improvements.\n\"The goal of ecosystem restoration is to improve functioning of natural systems,\" said Heather Leslie of University of Maine's Darling Marine Center and a co-author of the paper. \"We know a lot about how coastal and marine ecosystems work and by applying that knowledge to restoration in practice, we'll be in a better position to deliver on the benefits that motivate the efforts in the first place.\"\nClosing this gap is easier said than done, though. Many restoration projects happen at a larger spatial scale than scientific studies. Funding and logistical constraints may limit opportunities for involving researchers in the restoration design and monitoring, as well; often grants are available for implementing the projects, but not necessarily for monitoring. Through this research, Hughes and the team hope to build partnerships with federal and state agencies. They want to better connect practitioners, who are oftentimes thinking about logistics, funds, and practicalities, with researchers, who might have the capabilities of suggesting small, feasible modifications to possibly enhance the biodiversity and success of the project.\n\"Unless we are on a colorful coral reef, we tend to see a coastal marine habitat as a monochrome field of green, focusing on the largest, dominant species and missing the smaller, less obvious ones,\" said Dr. Susan Williams, of the Bodega Marine Laboratory at University of California, Davis. \"Even if we know the community is more diverse, we instinctively reach for an efficient restoration solution by focusing on a single species or the one that has been impacted most. Our instincts are often at odds with our growing understanding of the benefits of biodiversity.\"\nAs a second phase of this project, the team is conducting an online survey of organizations that focus on estuarine and marine habitat restoration. Their goal is to better understand practitioner beliefs about diversity and how they influence restoration practice. The results will give researchers a better understanding of the relationship between practitioners and researchers,\nCurrently, Hughes is partnering with the Massachusetts Division of Marine Fisheries on two large seagrass restoration projects. Hughes is helping design how the restoration project includes/considers biodiversity. \"We're going out to collect data to see if these diversity measures have had an impact on restoration,\" said Hughes. \"We'll be collecting data in six month intervals, and should know what the results are next year.\"\nHughes, along with Professor Jonathan Grabowski of the Marine Science Center, is collaborating with the Rhode Island Division of Environmental Management and the Nature Conservancy on oyster bed restorations in the state. \"They are allowing us to modify the restoration project to test out the ideas at a scale that we couldn't easily to do on our own. It takes these kinds of partnerships and resources coming together to do something like this in a real-life scale.\"\nHughes and the team hope publishing this paper will lead to future collaborations on restoration projects.\n\"There is reason to believe that biodiversity may be able to enhance the success of restoration, but we need more data, and the only way we'll get that data is if more partnerships are formed between biodiversity scientists and restoration practitioners. It might be a relatively simple way to enhance the success of restoration projects,\" she said.\nExplore further: For seagrass, biodiversity is both a goal and a means for restoration\nA. Randall Hughes et al, Inclusion of Biodiversity in Habitat Restoration Policy to Facilitate Ecosystem Recovery, Conservation Letters (2017). DOI: 10.1111/conl.12419","New report reveals details of the largest and most damaging coral bleaching event on record\nGlobal warming is the main cause of coral bleaching, which eventually kills reefs\nOver 90% of the Great Barrier Reef now shows evidence of bleaching\nGlobal warming has severely damaged huge sections of Australia’s Great Barrier Reef, according to a new paper published Wednesday in the journal Nature.\nThe paper’s authors warn that the resilience of the planet’s largest living structure is waning rapidly.\nData from a series of aerial and underwater surveys shows that a heatwave in summer 2016, which saw sea temperatures in Australia reach record levels, triggered the most damaging and widespread coral bleaching event on record.\nAlmost 50% of the reef is now “extremely” bleached and 91% shows at least some signs of bleaching, Sean Connolly, program leader of a government-funded coral reef center at James Cook University, Queensland and the paper’s co-author told CNN.\n“Coral cover [on the Great Barrier Reef] has halved over the last 27 years,” Connolly said.\n“[In the last three decades] coral cover went from 28% to 13%. Preliminary estimates [from last year’s disaster] are saying we’ve lost half that amount again. To have that kind of mortality on that kind of scale is unprecedented,” said Connolly.\nRising temperatures, diminished responsibility\nCoral bleaching happens when an increase in sea temperatures causes the expulsion of algae that grow inside coral, turning the reefs white and eliminating their main energy source. It’s directly linked to global warming.\nSustained bleaching will result in coral death. The bleaching during last year’s heatwave was worse than expected and the episode’s severity has raised serious concern for the future of the reef ecosystem.\nThe study pointed to the bleaching of hardy, century-old reefs as a particular red flag.\n“The severity and frequency of these [bleaching] events means slow-growing corals won’t have time to come back,” said Connolly.\n“If all the coral bleaches and dies, it’s no longer a coral reef. The coral skeletons are quickly colonized by algae which turns them dark in color,” said David Baker, assistant professor at the University of Hong Kong’s Swire Institute of Marine Sciences.\nEventually those skeletons collapse, he added, and the natural habitat for fish and other marine life is completely lost.\nThe paper’s authors also concluded, whether bleached or not, the reef had not acclimatized or adapted to high temperatures over time.\nConnolly said that, as temperatures increase, reefs would eventually die off and be replaced with more stress-tolerant species such as seaweeds.\n“We have known that things would go in this way for decades and unfortunately … our international system of government and policy has utterly failed to take relatively inexpensive action to head off what could be potentially catastrophic climate change – not just on reefs, but on other ecosystems we depend on.”\nAround 275 million people globally directly rely on reefs for livelihood and sustenance, and globally reefs form the nurseries for around a quarter of the world’s fish, according to the UN.\nThe Great Barrier Reef is worth $3.7 billion annually to the Australian economy through fishing and tourism, and provides around 70,000 jobs, Connolly said.\n“You’re looking at some potentially unfolding human tragedy over the decades if reefs cannot provide the same source of livelihood,” he added.\nLast year’s disaster was the third major mass coral bleaching of the Great Barrier Reef on record, and scientists suspect that – less than a year on – a fourth is already underway.\nThe Great Barrier Marine Park Authority is currently conducting aerial surveys of the reef and, last week, Greenpeace released photos and video footage highlighting the ongoing damage.\n“Greenpeace has just been on the Great Barrier Reef with a marine biologist to document the situation and it is heartbreaking,” said Alix Foster Vander Elst, Campaigner for Greenpeace Australia Pacific.\n“We should know in the coming days or weeks the exact impact of this year’s disaster.”"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:38584ae5-cf85-4a5f-a4a1-254a4887bb33>","<urn:uuid:6bad2bf2-4761-4db7-9df5-647bccb56223>"],"error":null}
{"question":"What are the unique architectural features of the Dadaocheng Presbyterian Church's chapel design, and what maintenance guidelines should be followed to preserve its pipe organ?","answer":"The Dadaocheng Presbyterian Church features several unique architectural elements, including a rare double-door design that segregated male and female visitors (left and right sides respectively), gothic windows, Corinthian columns, and a blend of Eastern and Western architectural styles with traditional Taiwanese patterns in exposed aggregate concrete. The chapel houses Taiwan's fourth-largest pipe organ, with 40 organ stops and 2,377 pipes. To maintain such a pipe organ properly, it requires annual tuning and maintenance by a reputable organ-builder, who should provide written reports. The church should maintain a steady temperature of 15-20 degrees Celsius and 60% humidity when possible, as excessive heat and humidity can damage the organ. Additionally, the organ must be protected during any building work or redecoration, and water damage from roof leaks must be addressed immediately by an organ-builder.","context":["The design of Dadaocheng Presbyterian Church in Taipei is a combination of the architecture styles of the late 19th and early 20th centuries. This historical landmark is, moreover, a combination of Eastern and Western cultures. The front façade of this magnificent western church building is made of exposed aggregate concrete displaying traditional Taiwanese patterns to present a beautiful blend of Eastern and Western art. As the oldest of the three remaining Presbyterian churches that were built in Taipei during the Japanese era in Taiwan, this building features a very rare design not found in most modern Taiwanese buildings. The chapel’s most peculiar aspect is its lack of a single main entrance. Based on traditional teachings of separation of the sexes, men were required to enter and exit the building through the left side entrance, while women used the right side entrance.\nDadaocheng Presbyterian Church was originally known as Dalongdong Church. It was established by Priest George Leslie Mackay (1844 – 1901) in 1875. During the Sino-French War (1884 – 1885), local citizens attacked the churches and Dalongdong Church was so badly damaged that it was reduced to rubble. It was later rebuilt on Niumoche Street (now Dihua Street) after the first governor of Taiwan, Liu Mingchuan (1836 – 1896) approved funding. The rebuilt church, named Fansi Chapel , was one of the largest churches in Taiwan at the time. In 1915, Li Chunsheng (1838-1924), the founding father of Taiwan’s tea industry, proposed donating a piece of land for the rebuilding of the church. The new building, renamed Dadaocheng Presbyterian Church, Taipei, still stands today. In 2007, a new church building was constructed behind the original; only the chapel’s left and right façades were left intact. The bricks of the front wall were removed and it was rebuilt in its original form a mere six meters forward from its previous position to serve as the entrance to the new church building. In 2002, the old chapel was designated a municipal historic site.\nThe design of Dadaocheng Presbyterian Church is mainly gothic. It is said that Li Chunsheng (the founding father of Taiwan’s tea industry) used churches built by foreign missionaries in his hometown of Xiamen City (known as Amoy at the time ) as references for the design. The front façade includes symmetrical gothic windows, short spires, and a roof gable. The two main columns are of the Corinthian order (an ornate ancient Greek architectural style), dividing the front of the church evenly into three parts to represent the Christian teaching of the holy trinity (Father, Son, and Holy Ghost) being God in three persons.\nAlthough the design of Dadaocheng Presbyterian Church pays homage to western architectural styles, the patterns formed with exposed aggregate on the roof gable are actually a mixture of western and eastern art with some traditional Taiwanese patterns incorporated. Curving tendrils flow gently along the ridgeline of the gable to the two small spires on either side, which rest upon paired Corinthian columns. Directly below the gable is an oeil-de-boeuf (French for “bull’s eye”) window with terra cotta decoration. Underneath the window is a typical gothic arch with traditional relief carvings, a design technique commonly found in the Dadaocheng district during the Taisho Period (1912 – 1926).\n3Double Door Design\nMost traditional Taiwanese architecture adopted an odd number of doors, such as single-door designs (in city walls or residences), three-door designs (in arch gateways and temples), or five-door designs (in the front halls of temples or large gateways). It was rare to see a double door. Dadaocheng Presbyterian Church, however, used two doors on each side to segregate male (left) from female (right) visitors. The unusual design was a new approach to architecture for the otherwise conservative culture of the time.\n4Restored Front Façade\nBy 2007, the front façade of the church had been damaged by significant weathering. In order to preserve the original architectural design, a space was cleared out behind the chapel to construct a new church building. The old chapel, including the two sidewalls, was removed from its foundation and shifted six meters forward. The façade was then restored according to its original blueprint using its original bricks. The new church building is designed in a U-shape to allow the old chapel to serve as the entryway to the new building. The resulting exterior is the only one of its kind in Taiwanese architectural history.\n5The Pipe Organ in the Chapel\nDadaocheng Presbyterian Church is one of the few chapels in Taiwan with a large pipe organ. Made by Swiss company Mathis in 2013, the organ at Dadaocheng Presbyterian Church includes 40 organ stops, 2,377 pipes, and a mechanical keyboard. It is currently the fourth largest pipe organ in Taiwan, providing solemn accompaniment to worshippers singing hymns.\nThe chapel is open to the public every other Saturday morning. Professional guides are available to provide tours. Visitors may also reserve a tour in advance in Chinese, English, or Japanese. Services in Taiwanese are held Sunday mornings at 9:30 a.m. Chinese (Mandarin) services are held Sunday mornings at 11:00 a.m.","Care of pipe organs\nA long tradition associates the organ with Christian worship. The pipe organ is described by its devotees as the King of Instruments and it certainly is very versatile when properly designed. The organ’s ability to lead and sustain congregational singing is its primary role. Lively singing is best encouraged by the pipe organ. For the accompaniment of a large congregation there is no substitute, and the sustained and under-girding tone of the organ’s pedal department makes it particularly suitable for bold, harmonic music such as stately hymn tunes and marches.\nDepending on its design, the organ has a wide variety of tone, from pungent reeds to mellow flutes, and a great range of volume, from pianissimo to fortissimo. So, this also makes it a most useful instrument for solo pieces and for the support of small groups of voices. For example, the imaginative use of stop changes can greatly enrich the singing of the psalms and other parts of the liturgy.\nPipe organs also play an important evangelical role in churches’ outreach to the wider community in sacred concerts and other musical and cultural programmes.\nParish churches find it increasingly difficult to persuade organists to accept appointed positions. Organists require adequate instruments for practice purposes and the church with a pipe organ that has been well maintained and cared for will find it easier to attract trained musicians than the church whose organ has been neglected or replaced with an electronic instrument. Realising this, the dioceses asked Church Music Dublin to draw up the following guidelines.\nUNITED DIOCESES OF DUBLIN AND GLENDALOUGH\nGUIDELINES FOR THE CARE AND MAINTENANCE OF PIPE ORGANS IN CHURCHES\nPrepared by Church Music Dublin and approved by the Diocesan Councils on 8th September 2019\nThe following guidelines are intended as a resource for clergy, Select Vestries, organists and other persons responsible for the care and maintenance of pipe organs in churches. These are general principles for best practice and are not definitive. Independent and impartial advice should always be sought before seeking tenders or signing contracts. In some cases, work may require the consent of the Diocesan Councils. Church Music Dublin can provide further advice.\nEvaluating an organ\nPipe organs are complex instruments, and so are expensive to build and maintain. Before deciding to invest money in an organ, it is worth evaluating an existing instrument in terms of its suitability for the musical needs of the church, and its historic and aesthetic value. Is the organ used for playing repertoire, accompanying congregational singing, accompanying a choir, or a mixture of these? Are the resources of the organ adequate for this purpose? Is the location of the organ satisfactory and does it sound well in the building? Does the organ contain historic pipework? Was the organ donated to the church for a particular purpose (e.g. given in memory of a deceased member of the congregation)? Does the organ add to the beauty of the church?\nAn organ should be tuned and maintained at least once a year. A reputable organ-builder should be contracted to visit the church at agreed intervals to carry out tuning and any necessary minor maintenance work. Cost will depend on frequency of visits, the size of the organ, and incidental work. The organ-builder should be required to supply a brief written report when submitting their invoice, and these reports should be brought to the attention of the Select Vestry. A representative of the church should speak regularly with the organ-builder regarding maintenance of the organ. A log-book should be kept at the organ console in which users of the organ can record faults (notes not working, unusual noises, etc.) so as to maximise the benefit of visits from the organ-builder. Ensure that the church is heated to normal Sunday temperature when the tuner is in, as the pitch of the organ alters with the temperature. In the case of an organ that is not used regularly or at all, an organ-builder should be asked to carry out a basic inspection at least once every two years, so as to prevent the organ falling into an unusable state. If your organ has fallen into an unusable state, seek the opinion of an experienced and reputable organ-builder. Be sceptical of any suggestion that an organ is not worth repairing. It may well be that the instrument requires only minor repairs, some electrical work, and cleaning, to restore it to a playable state. If in any doubt, seek a second opinion.\nOrgans are particularly at risk from water damage from roof leaks. If any evidence of water is found near the organ, seek advice from an organ-builder immediately. Pipe organs contain substantial quantities of wood and metal that respond to changes in temperature and humidity. Ideally, a steady temperature of 15–20 degrees Celsius and 60% humidity should be maintained. While this ideal is seldom achievable in church buildings, church officers should be reminded regularly that excessive heat and high humidity can cause parts of the organ to warp and crack. The days before Christmas and Easter, when heating may be powered on for long periods, are times when such problems may occur. Organs are frequently damaged in the course of redecoration or building work in a church. Covering an organ with blankets or plastic sheeting can prevent damage by dust or debris, which may cost thousands of euro to repair. It is essential that an experienced organ-builder is engaged to install such protection. Do not allow a building contractor under any circumstances to get into the organ, unless the organ-builder is present.\nThe pipe organ may well be the single most valuable asset in the building. Depending on its size, the instrument’s replacement value could run into hundreds of thousands. Insurance cover should take this into account.\nMajor restoration and renovation\nSignificant work on an organ may be required if it is found to be unfit for purpose, or in a state of major disrepair. In the course of normal use pipes can become dirty or damaged, and may need cleaning and repair. Outmoded technology (such as an old-fashioned pneumatics or electrics) may need to be replaced. It may be advisable in some cases to add or replace pipes or alter the pitch. In such circumstances, the first step is to appoint an experienced and reputable independent organ consultant. Such a consultant should understand the workings of the organ as well as the musical needs of the church. Next, a detailed specification for the work required should be prepared, to provide a base for evaluating quotations. Best practice is to seek quotations from at least three different organ-builders. Owing to the wide range of approaches to organ-building, you may well receive three entirely different proposals, which will need to be evaluated carefully.\nFaculties and controls\nIn most denominations there are controls on what happens to the fabric of a church. In the Church of Ireland, a faculty is required to add, replace, remove or reposition an organ, or carry out any work that alters the existing artistic character of the instruments, such as changing the keyboard action, adding or removing a rank of pipes, or changing the outward appearance. The Diocesan Registrar will be able to offer help and guidance on the faculty jurisdiction and how it relates to the role of the Representative Church Body as trustee of parish property. For more information on the RCB and alterations to fabric or furnishings see the ‘Parish Resources’ section of the Church of Ireland website. Certain dioceses will require a parish to obtain the permission of Diocesan Council prior to spending over a certain figure. It would not be difficult for works on an organ to exceed this threshold. The Diocesan Secretary can offer advice on this."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:09ac0ddf-5214-45b2-b7c2-ff3bfbe08be6>","<urn:uuid:23382ff3-7307-487e-95f7-f8a6c8569b1b>"],"error":null}
{"question":"¿Cómo afecta una barrera hematoencefálica defectuosa al cerebro envejecido y qué relación tiene esto con los tumores cerebrales? 🤔","answer":"A blood-brain barrier dysfunction affects the aging brain by allowing blood proteins like albumin to leak into the brain, causing inflammation and cognitive decline. After age 70, nearly 60% of adults have leaky blood-brain barriers. This leakage triggers inflammatory responses that damage brain cells and neural circuits. Regarding brain tumors, the blood-brain barrier (BBB) plays a crucial protective role as it normally hinders the penetration of potentially toxic compounds into the brain and cerebrospinal fluid, acting as a barrier between the vascular system and the brain tissue.","context":["Drugs that tamp down inflammation in the brain could slow or even reverse the cognitive decline that comes with age.\nIn a publication appearing today in the journal Science Translational Medicine, University of California, Berkeley, and Ben-Gurion University scientists report that senile mice given one such drug had fewer signs of brain inflammation and were better able to learn new tasks, becoming almost as adept as mice half their age.\n“We tend to think about the aged brain in the same way we think about neurodegeneration: Age involves loss of function and dead cells. But our new data tell a different story about why the aged brain is not functioning well: It is because of this “fog” of inflammatory load,” said Daniela Kaufer, a UC Berkeley professor of integrative biology and a senior author, along with Alon Friedman of Ben-Gurion University of the Negev in Israel and Dalhousie University in Canada. “But when you remove that inflammatory fog, within days the aged brain acts like a young brain. It is a really, really optimistic finding, in terms of the capacity for plasticity that exists in the brain. We can reverse brain aging.”\nThe successful treatment in mice supports a radical new view of what causes the confusion and dementia that often accompany aging. More and more research shows that, with age, the filtration system that prevents molecules or infectious organisms in the blood from leaking into the brain — the so-called blood-brain barrier — becomes leaky, letting in chemicals that cause inflammation and a cascade of cell death. After age 70, nearly 60% of adults have leaky blood- brain barriers, according to Friedman’s magnetic resonance imaging (MRI) studies.\nAn accompanying paper by the two researchers and Dan Milikovsky of Ben-Gurion University shows that the inflammatory fog induced by a leaky blood-brain barrier alters the mouse brain’s normal rhythms, causing microseizure-like events — momentary lapses in the normal rhythm within the hippocampus — that could produce some of the symptoms seen in degenerative brain diseases like Alzheimer’s disease. Electroencephalograms (EEGs) revealed similar brain wave disruption, or paroxysmal slow wave events, in humans with epilepsy and with cognitive dysfunction, including Alzheimer’s and mild cognitive impairment (MCI).\nTogether, the papers give doctors two biomarkers — leaky barriers detectable by MRI and abnormal brain rhythms detectable by EEG — that can be used to flag people with blood-brain barrier problems, as well as a potential drug to slow or reverse the consequences.\n“We now have two biomarkers that tell you exactly where the blood-brain barrier is leaking, so you can select patients for treatment and make decisions about how long you give the drug,” said Kaufer, a member of UC Berkeley’s Helen Wills Neuroscience Institute. “You can follow them, and when the blood-brain barrier is healed, you no longer need the drug.”\nScientists have long suspected that a leaky blood-brain barrier causes at least some of the tissue damage after brain injury and some of the mental decline that comes with age. But no one knew how.\nIn 2007, however, Friedman and Kaufer linked these problems to a blood protein, albumin. In 2009, they showed that when albumin leaks into the brain after trauma, it binds to the TGF-β (TGF-beta) receptor in brain cells called astrocytes. This triggers a cascade of inflammatory responses that damage other brain cells and neural circuits, leading to decreased inhibition and increased excitation of neurons and a propensity toward seizures.\nThey also showed in mice that blocking the receptor with an antihypertension drug, losartan, prevented the development of epilepsy after brain trauma. Epilepsy is a frequent consequence of concussions like those sustained by soldiers from roadside bombs.\nSubsequent studies revealed leakiness in the barrier after stroke, traumatic brain injury and football concussions, solidly linking albumin and an overexcited TGF-β receptor to the damage resulting from these traumas.\nIn their new studies, Kaufer and Friedman showed that introducing albumin into the brain can, within a week, make the brains of young mice look like those of old mice, in terms of hyperexcitability and their susceptibility to seizures. These albumin-treated mice also navigated a maze as poorly as aged mice.\n“When we infused albumin into the brains of young mice, we recapitulated aging of the brain: the gene expression, the inflammatory response, resilience to induced seizures and mortality after seizures, performance in a maze. And when we recorded their brain activity, we found these paroxysmal slow wave events,” Kaufer said. “And all were specific to the site we infused. So, doing this is sufficient to get an aged phenotype of this very young brain.”\nWhen they genetically engineered mice so that they could knock out the TGF-β receptor in astrocytes after they’d reached old age, the senile mouse brains looked young again. The mice were as resistant to induced seizures as a young mouse, and they learned a maze like a young mouse.\nSerendipitously, a Palo Alto, California, medicinal chemist, Barry Hart, offered to synthesize a small-molecule drug that blocks the TGF-β receptor in astrocytes only, and that could traverse the blood-brain barrier. When they gave the drug, called IPW, to mice in doses that lowered the receptor activity level to that found in young mice, the brains of the aged mice looked younger, too. They showed young brain-like gene expression, reduced inflammation and improved rhythms — that is, reduced paroxysmal slow wave events — as well as reduced seizure susceptibility. They also navigated a maze or learned a spatial task like a young mouse.\nIn analyzing brain tissue from humans, Kaufer found evidence of albumin in aged brains and increased neuroinflammation and TGF-β production with age. Friedman developed a special type of MRI imaging — dynamic contrast-enhanced (DCE) imaging — to detect leakage in the blood-brain barrier and found more leakage in people with greater cognitive dysfunction.\nAltogether, the evidence points to a dysfunction in the brain’s blood filtration system as one of the earliest triggers of neurological aging, Kaufer said.\nKaufer, Friedman and Hart have started a company to develop a drug to heal the blood-brain barrier for clinical treatment and hope that the drug will help reduce brain inflammation — and, thus, permanent damage — after stroke, concussion or traumatic brain injury, and eventually help older adults with dementia or Alzheimer’s disease who have demonstrated leakage of the blood-brain barrier.\n“We got to this through this back door; we started with questions about plasticity having to do with the blood-brain barrier, traumatic brain injury and how epilepsy develops,” Kaufer said. “But after we’d learned a lot about the mechanisms, we started thinking that maybe in aging it is the same story. This is new biology, a completely new angle on why neurological function deteriorates as the brain ages.”\nThis work was supported by the National Institutes of Health (R01NS066005, R56NS066005), European Union’s Seventh Framework Program, Israel Science Foundation and United States-Israel Binational Science Foundation.\n- Blood-brain barrier dysfunction in aging induces hyper-activation of TGF-β signaling and chronic yet reversible neural dysfunction (Science Translational Medicine)\n- Paroxysmal slow cortical activity in Alzheimer’s disease and epilepsy is associated with blood-brain barrier dysfunction (Science Translational Medicine)","General Information about Brain Tumors\nPrimary brain tumors are tumors that originate in the brain. Brain tumors can be benign (non-cancerous) or malignant (cancerous). Benign brain tumors can grow and compress nearby structures of the brain but rarely spread into other parts of the body. Malignant brain tumors are likely to grow quickly and spread into other parts of the central nervous system including the spinal canal. There are several types of brain tumors, which include gliomas, meningiomas, pituitary adenomas, and nerve sheath tumors. These types of cancers are not to be confused with metastatic cancer, which is cancer from another part of the body that has spread to the brain.\nFacts about Brain Tumors\n- Represent roughly 1.5% of all newly diagnosed cancers.\n- Overall cognitive ability may be affected depending on which lobe of the brain contains the cancer. For examples: Gliomas arise from the glial cells and are the most common form of brain and CNS (Central Nervous System) tumors. Gliomas make up approximately half of all brain tumors and are classified by the cell type, grade, and location of the disease. The most common types of gliomas are oligodendrogliomas, ependymomas, and astrocytomas.\n- Frontal lobe – Behavioral and cognitive decline\n- Temporal lobe – Memory or visual field defects, aphasia (inability to speak), seizures, and hemiparesis (partial paralysis).\n- Parietal lobe – Sensory seizures. Motor dysfunctions that the patient may not recognize\n- Meningiomas are the second most common of all brain tumors and account for roughly 20% of all brain tumors. Meningiomas are generally slow growing and produce very little symptoms throughout a patient’s life. Only a very small percentage of these tumors are malignant.\n- Pituitary adenomas are benign lesions that originate in the pituitary gland. These tumors make up for approximately 15% of all brain tumor patients. They can be hormone secreting or non-hormone secreting. If they grow they can compress the optic chiasm leading to visual problems.\nSigns and Symptoms of Brain Tumors\nGeneral symptoms are related to the area of the brain that is affected and can include:\n- Vomiting due to intracranial pressure\n- Papilledema (edema of the optic disk)\n- Cognitive and behavioral changes\n- 50% of patients present with headaches\n- Blood-brain barrier (BBB) – The barrier system that hinders the penetration of some substances into the brain and cerebrospinal fluid. The BBB exists between the vascular system and the brain. Its purpose is to protect the brain from potentially toxic compounds.\n- Cerebellum – Part of the brain that is responsible for the coordination of voluntary muscular movements.\n- Cerebrospinal fluid (CSF) – The fluid that flows through and protects the brain and spinal canal.\n- Cerebrum – The largest part of the brain and consists of two hemispheres (left and right). The functions of the cerebrum include interpretation of sensory impulses and voluntary muscular activities. It is the center for memory, learning, reasoning, judgment, intelligence, and emotions.\n- Debulking – A surgical procedure used to reduce tumor size, reduce tumor burden, and increase the opportunity to obtain a pathologic diagnosis.\n- Edema – Excessive accumulation of fluid in a tissue, producing swelling.\n- Frontal lobe – Front part of the cerebral hemisphere.\n- Intracranial pressure (ICP) – Increased pressure in the brain resulting in headaches, nausea, and vomiting.\nTreatment of Common Brain Tumors\nTreatment of choice for most gliomas is dependent on the location, grade of malignancy, and its histology. Treatment often includes a combined approach between surgery, radiation therapy, and sometimes chemotherapy. Surgical removal of the tumor is typically the first line of treatment with post-operative chemotherapy or radiation therapy depending on the findings from surgery.\nMeningiomas can be initially observed if their growth is very slow. However for certain tumors that are growing and near critical structures (such as cranial nerves), earlier treatment may help preserve neurologic function. Tumors requiring treatment are typically treated with surgical removal and/or radiation therapy.\nThese tumors are mostly treated with medication but can also be surgically removed. Radiation therapy also can be used to treat these tumors. It is important that patients with these tumors are evaluated by an endocrinologist to correct any hormone abnormalities.\nMetastatic brain cancers are tumors that have spread from another organ system in the body. These patients are considered Stage 4. These tumors are more common than primary brain tumors. Metastatic brain cancer most commonly originates from lung, breast, and melanoma. A majority of these patients present with multiple lesions throughout the brain and can be treated with surgery or radiation therapy.\nRole of Radiation Therapy in Managing CNS and Brain Tumors\nRadiation therapy can be used to help manage both primary brain tumors and secondary brain tumors. Post-operative radiation can be used on tumors that require additional treatment for residual disease. Radiation therapy is commonly used to treat brain tumors in difficult surgical locations or for patients who are medically unfit to undergo surgery.\nMetastatic brain tumors often present with multiple small lesions throughout the brain and are often too complex to be removed with surgery. For this reason, radiation to the whole brain is often performed to treat the multiple lesions throughout the cranium.\nFrequently Asked Questions\nQ: What are the side effects of radiation to the brain?\nA: Patients can experience some hair loss which may be permanent. They can also have headaches and fatigue. Your physician may start you on a steroid medication to decrease the swelling in the brain during radiation. Long term, patients may experience mild to moderate temporary memory problems depending on what part of the brain receives radiation. Patients also occasionally experience transient taste changes. If you have seizures you may need to take anti-seizure medication.\nQ: How do we know the tumor is being properly radiated?\nA: We are able to use MRI images and fuse them with our planning CT images. This forms a map where we can outline exactly where the disease in the brain is located, allowing us to target the tumor precisely. We can also use this map to make sure critical structures in the brain do not receive too much radiation.\nQ: What diet should I be on during radiation treatments?\nA: There are usually no diet restrictions with radiation to the brain."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:4661d3a9-b3e1-4fd8-b078-3d8108065655>","<urn:uuid:65c6114d-dbfe-4242-8d44-f1700e0f07a1>"],"error":null}
{"question":"Hey there! I'm researching medieval manuscripts. What were the different types of manuscript editions used historically, and what was unique about the Harley 7368 manuscript's editing process?","answer":"There were four main types of manuscript editions: facsimile (photographic reproduction with commentary), diplomatic (transcription of a single manuscript), eclectic (composite text from multiple manuscripts), and critical (establishing a 'best text' through variant comparison). As for the Harley 7368 manuscript, it underwent a complex editing process involving multiple hands and revisions. The original text was written around 1591-3 by Anthony Munday and Henry Chettle, then heavily revised by a team including Thomas Heywood, Thomas Dekker, and William Shakespeare. The manuscript contains six different hands (labeled S, A, B, C, D, and E), with Hand C attempting to provide corrections throughout to enhance coherence. Despite scholars describing it as 'chaotic' and 'incoherent,' it was finally printed in 1844 by the Shakespeare Society.","context":["Manuscript Harley 7368\nClick thumbnails to the different hands in high resolution\nNow MS. Harley 7368 in the collection of the British Library, the manuscript's provenance can be traced back to 1728, when it belonged to a London book collector named John Murray. He donated it to the collection of Edward Harley, 3rd Earl of Oxford and Earl Mortimer, who bequeathed it to the British Museum with the rest of his manuscript collection in 1753. Some time between 1728 and 1753 the play was bound with another manuscript, The Humorous Lovers.\nNow in poor condition, the original manuscript probably consisted of 16 leaves—31 handwritten pages of a working draft of the play (foul papers), with the last page blank. Two or three of the original leaves have been torn out, and seven leaves and two smaller pieces of paper have been inserted.\nAside from folios 1 and 2, the wrapper of the manuscript proper, the revised extant manuscript comprises the following:\n1) Folios 3–5, Hand S: the first three scenes of the play, through page 5a; censored by Edmund Tylney, the Master of the Revels, but otherwise intact. On page 5b, all text after the first 16 lines is marked for deletion. At least one, and probably two, of the leaves immediately following (the original leaves 6 and 7) are missing.\n2) Folio 6, Addition I, Hand A: a single leaf, written on only one side. The addition is misplaced, and belongs later in the play, with page 19a.\n3) Folios 7–9, Addition II: three leaves replacing the excised material on 5b and the original 6 and probable 7. Each of the three leaves is in a different hand.\n- Folio 7a, Addition IIa, Hand B: a scene to replace a short deleted scene on 5b.\n- Folio 7b, Addition IIb, Hand C: another complete scene, with stage directions leading to its successor.\n- Folios 8–9, Addition IIc, Hand D: a three-page scene (page 9b being blank), with about a dozen corrections in Hand C.\n4) Folios 10–11, Hand S: back to the original manuscript, though with some insertions on pages 10a and 11a in Hand B.\n5) Folio 11c, Addition III, Hand C: the first of the two insertions on smaller pieces of paper, formerly pasted over the bottom of page 11b, and consisting of a single 21-line soliloquy meant to begin the next scene.\n6) Folios 12–13, Addition IV, Hands C and E: four pages to replace excised or cancelled material, written mainly in Hand C but with input from Hand E on page 13b.\n7) Folio 14a Hand S: the original again, and the whole page cancelled for deletion. Addition IV, directly previous, replaces this material.8) Folio 14c, Addition V, Hand C: the second of the insertions on smaller sheets of paper, formerly pasted over the bottom of page 14a.\n9) Folios 14b and 15, Hand S: the original again.\n10) Folio 16, Addition VI, Hand B: the last of the six Additions.\n11) Folios 17-22a, Hand S: the conclusion of the play in the original version. On page 19a a long passage is cut, and this is the place where the mislocated Addition I, folio 6, actually belongs.\nHand C attempted to provide corrections to the whole, enhancing its coherence; yet some stage directions and speech prefixes are missing, and the stage directions that exist are sometimes incorrect. (In Additions III and IV, More speaks his soliloquy before he enters.)\nScholars, critics, and editors have described the text as \"chaotic\" and \"reduced to incoherence\", but in 1987 Scott McMillin maintained that the play could be acted as is; and at least one production of the play has ensued, by the Royal Shakespeare Company in 2005.\nThe manuscript was first printed and published in 1844, two and a half centuries after it was written, by the Shakespeare Society, edited by Alexander Dyce; and again in 1911 by the Malone Society, edited by W. W. Greg.\nPart of the need for revisions of the play was clearly due to purely practical concerns of stagecraft, apart from the demands of political censorship. Much of the point of the revision was to streamline the play, to make it more actable; though even the revised version would have needed a minimum cast of 18—13 adults and five boys. Two of the Additions, III and VI, occur at the beginning and end of the middle third respectively, giving more time for costume changes. Addition III provides a soliloquy by More and a 45-line dialogue between two actors; Addition VI provides a similar breathing-space for the actors to get ready for the play's final phase.\nAllowing for a range of uncertainties, it is most likely true that the original text of Sir Thomas More was written ca. 1591-3, with a special focus on 1592-3 when the subject of hostility against \"aliens\" was topical in London. Edmund Tylney censored the play when it was submitted to him for approval at that time, for this topicality as well as for more general considerations of controlling political expression on the stage. The effort at revision is difficult to date; many scholars have favoured ca. 1596, though a date as late as ca. 1604 is also possible.\nThe manuscript is a complicated text containing many layers of collaborative writing, revision, and censorship. Scholars of the play think that it was originally written by playwrights Anthony Munday and Henry Chettle and some years later heavily revised by another team of playwrights, including Thomas Heywood, Thomas Dekker, and William Shakespeare.\nThe most common identifications for the six hands:\n- HAND S – Anthony Munday, the original manuscript;\n- HAND A – Henry Chettle;\n- HAND B – Thomas Heywood;\n- HAND C – A professional scribe who copied out a large section of the play;\n- HAND D – William Shakespeare;\n- HAND E – Thomas Dekker.\nMunday, Chettle, Dekker, and Heywood wrote for the Admiral's Men during the years before and after 1600, which may strengthen the idea of a connection between the play and that company. Shakespeare, in this context, seems the odd man out. In his study of the play, Scott McMillin entertains the possibility that Shakespeare's contribution might have been part of the original text from the early 1590s, when Shakespeare may have written for the Lord Strange's Men.","Medieval and Early Modern\nV.iii. Textual Bibliography: Kinds of Edition\nYou are here: > Main Page > Course Notes > Textual Bibliography: Kinds of Edition\nWe can define four main types of edition:\nBesides the actual edited text, every type of edition should have all or most of the following types of commentary:\n- Facsimile edition: reproduction (now usually photographic) with commentary.\n- Diplomatic edition: transcription of a single MS (no attempt to establish \"best\" readings), indicating as far as possible the \"state\" of the text in this manuscript. Masai in 1950 established a now commonly used system of conventional symbols for diplomatic transcription, distinguishing three levels: the original reading, revisions made by correctors (before the MS left the scriptorium), and later alterations. Original readings are typed out as the main text, using italics for the expansion of recognized abbreviations (for ambiguous marks, or when there is no obvious expansion, the mark itself should be reproduced as accurately as possible, with notes of explanation). Corrector's revisions are distinguished with square brackets for deletions, various combinations of oblique lines for additions, and a combination of deletion and addition symbols for replacements. Later alterations are enclosed in angle brackets.\n- Eclectic edition: a composite text, produced by an editor by taking a line from this MS and another line from that, without the use of a single \"copy\" text.\n- Critical edition: an attempt to establish a \"best text\" (closest to the author's \"ur-text\") through comparison of various versions (study of \"variants\"); the editor chooses a \"copy text\" (usually that of the most authoritative manuscript) and \"corrects\" it using the variants from other manuscripts. On the principles of critical editions, see Bidez and Drachmann (1932); Dondaine (1960) (who also gives a system of Latin abbreviations for use in textual apparatus). Also see the various works of Jerome McGann, who challenges many of the assumptions of the traditional critical edition.\nVarious systems have been developed for indicating \"special\" aspects of the text; the following suggestions are to show what sorts of things an editor might need to highlight in the edited text. The main consideration, however, is that the editor needs some system or other, and that the principles of that system be fully explained in the Introduction to the edition.\n- Introduction: the Introduction will usually include a codicological description of the manuscript and/or earlier printed versions used in constructing the text. Any matters which are relevant to the understanding or interpretation of the work as a whole should be discussed in the Introduction. And the Introduction should include an account of the editorial principles used to create the text.\n- Textual (or \"critical\") apparatus (apparatus criticus): a complete record of substantive variant readings found in different versions of the text; wherever the editor has been forced to make choices or to supply emendations, the range of available choices should be presented to the users of the edition so that they can determine whether those choices were correct or reasonable.\n- Commentary: sometimes this will be no more than an apparatus fontium (a list of the sources used by the author of the original, such as identifying the chapter and verse of quotations from the Bible), but usually the Commentary will be more extensive than this, including explication of difficult passages or discussion of points to be considered when attempting to interpret particular passages (as opposed to points to be considered for the interpretation of the whole work, which should be included in the Introduction, not in the Commentary), the discussion of any cruces in the text remaining after the editing has been completed, translations of passages in the text which are not in the main language of the text (Latin quotations in an English text, for instance, should be translated in the notes), identifying parallels of phrasing in other texts (including the identification of allusions).\n- Glossary: any text not in the language of the intended reader (a Latin text for an English audience, or an Old English text for a Modern English audience) should be equipped with a glossary, at least of the \"difficult\" words; as computers make the production and printing of texts and glossaries cheaper, it is now not uncommon to provide complete \"glossarial concordances\" with a text (indicating every word in the text, with definitions, and a list of all locations).\n- simple insertions (by the hand of the main scribe or of another scribe) might be surrounded by single quotation marks (inverted commas): this is a scribal insertion.\n- words marked for deletion by the scribe could be placed within square brackets: [this is a scribal deletion].\n- insertions and emendations by the editor might be surrounded by angle brackets: <text inserted by the editor>.\n- where there is missing or damaged text, the lacuna can be indicated with a string of asterisks; if the passage is short, it can be useful to use as many asterisks as one estimates there are letters missing.\n- where there appears to be no missing or damaged text, and yet the sense of the passage suggests that something is missing, the conjectural lacuna can be indicated by placing the row of asterisks to indicate the lacuna between the angle brackets used to mark editorial intervention: <* * *>.\n- a \"locus desperandus,\" a corrupt passage which defeats the editor's attempts at conjectural emendation, could be marked with a obelus before and after the passage: gobble gobble gobble, cluck cluck cluck: this is an incomprehensible passage with which the editor did not know how to deal.\nForward to next page: Examples of over emendation on\n[ Course Notes: Introduction ] |\n[ I. Towards a definition of \"manuscript studies\" ] |\n[ I.ii. The four branches of bibliographical study ] |\n[ I.iii. Topics in the social history of texts ] |\nI.iii.a The \"Rescue\" of Medieval Manuscripts from Grocers and Fishmongers |\n[ II. Diplomatics ] |\n[ III. Codicology ] |\n[ III.ii. Decoration and Illumination ] |\n[ IV. Paleography ] |\n[ IV.ii. Historical Notes ] |\n[ IV.iii. Writing Implements ] |\n[ IV.iv. Letter Formation ] |\n[ IV.v. Special Characters in English Manuscripts ] |\n[ IV.vi. Scribal Abbreviations ] |\n[ IV.vii. Punctuation ] |\n[ IV.viii. Paleographical sample: William Herebert, OFM (early fourteenth-century England) ] |\n[ Herebert sample, with transcription ] |\n[ Herebert sample: enlargement of full page reproduced at high resolution ] |\n[ V. Textual analysis (James E. Thorpe) ] |\n[ V.ii. Scribal error ] |\n[ V.iii. Kinds of edition ] |\n[ V.iv. Examples of over emendation on insufficient grounds ] |\n[ VI. Linguistic competence (an example): An Outline History of the English Language ] |\n[ VII. Libraries and archives: ] |\n[ VII.ii. British Library Manuscript Collections ] |\n[ VII.iii. Bodleian Library Manuscript Collections ]\n© 1998, 2015 Stephen R. Reimer\nEnglish; University of Alberta; Edmonton, Canada\nAll rights reserved.\nCreated: 2 Dec. 1998; Last revised: 30 May 2015"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:1c5b47b6-c51e-467b-882e-3db97e15cd0b>","<urn:uuid:215d5db7-610b-4afc-a268-cbcced0a94e5>"],"error":null}
{"question":"How do the manufacturing processes compare between applying anti-reflective coatings to eyeglasses and controlling light scattering in graphene?","answer":"The processes are quite different. Anti-reflective coating application is a highly technical vacuum deposition process involving multiple cleaning steps, followed by precisely layering metallic oxides onto lenses using electron beams in a vacuum chamber, resulting in extremely thin layers about 0.2 to 0.3 microns thick. In contrast, controlling light scattering in graphene involves manipulating its electronic structure through electrostatic doping - applying voltage through an ion gel to shift the Fermi energy level, which controls which quantum pathways are available for light scattering.","context":["Scientists at the U.S. Department of Energy's Lawrence Berkeley National Laboratory (Berkeley Lab) and the University of California at Berkeley have learned to control the quantum pathways determining how light scatters in graphene. Controlled scattering provides a new tool for the study of this unique material – graphene is a single sheet of carbon just one atom thick – and may point to practical applications for controlling light and electronic states in graphene nanodevices.\nThe research team, led by Feng Wang of Berkeley Lab's Materials Sciences Division, made the first direct observation, in graphene, of so-called quantum interference in Raman scattering. Raman scattering is a form of \"inelastic\" light scattering. Unlike elastic scattering, in which the scattered light has the same color (the same energy) as the incident light, inelastically scattered light either loses energy or gains it.\nRaman scattering occurs in graphene and other crystals when an incoming photon, a particle of light, excites an electron, which in turn generates a phonon together with a lower-energy photon. Phonons are vibrations of the crystal lattice, which are also treated as particles by quantum mechanics.\nQuantum particles are as much waves as particles, so they can interfere with one another and even with themselves. The researchers showed that light emission can be controlled by controlling these interference pathways. They present their results in a forthcoming issue of the journal Nature, now available in Advance Online Publication.\nManipulating quantum interference, in life and in the lab\n\"A familiar example of quantum interference in everyday life is antireflective coating on eyeglasses,\" says Wang, who is also an assistant professor of physics at UC Berkeley. \"A photon can follow two pathways, scattering from the coating or from the glass. Because of its quantum nature it actually follows both, and the coating is designed so that the two pathways interfere with each other and cancel light that would otherwise cause reflection.\"\nWang adds, \"The hallmark of quantum mechanics is that if different paths are nondistinguishable, they must always interfere with each other. We can manipulate the interference among the quantum pathways that are responsible for Raman scattering in graphene because of graphene's peculiar electronic structure.\"\nIn Raman scattering, the quantum pathways are electronic excitations, which are optically stimulated by the incoming photons. These excitations can only happen when the initial electronic state is filled (by a charged particle such as an electron), and the final electronic state is empty.\nQuantum mechanics describes electrons filling a material's available electronic states much as water fills the space in a glass: the \"water surface\" is called the Fermi level. All the electronic states below it are filled and all the states above it are empty. The filled states can be reduced by \"doping\" the material in order to shift the Fermi energy lower. As the Fermi energy is lowered, the electronic states just above it are removed, and the excitation pathways originating from these states are also removed.\n\"We were able to control the excitation pathways in graphene by electrostatically doping it – applying voltage to drive down the Fermi energy and eliminate selected states,\" Wang says. \"An amazing thing about graphene is that its Fermi energy can be shifted by orders of magnitude larger than conventional materials. This is ultimately due to graphene's two-dimensionality and its unusual electronic bands.\"\nThe Fermi energy of undoped graphene is located at a single point, where its electronically filled bands, graphically represented as an upward-pointing cone, meet its electronically empty bands, represented as a downward-pointing cone. To move the Fermi energy appreciably requires a strong electric field.\nTeam member Rachel Segalman, an associate professor of chemical engineering at UC Berkeley and a faculty scientist in Berkeley Lab's Materials Sciences Division, provided the ion gel that was key to the experimental device. An ion gel confines a strongly conducting liquid in a polymer matrix. The gel was laid over a flake of graphene, grown on copper and transferred onto an insulating substrate. The charge in the graphene was adjusted by the gate voltage on the ion gel.\n\"So by cranking up the voltage we lowered the graphene's Fermi energy, sequentially getting rid of the higher energy electrons,\" says Wang. Eliminating electrons, from the highest energies on down, effectively eliminated the pathways that, when impinged upon by incoming photons, could absorb them and then emit Raman-scattered photons.\nWhat comes of interference, constructive and destructive\n\"People have always known that quantum interference is important in Raman scattering, but it's been hard to see,\" says Wang. \"Here it's really easy to see the contribution of each state.\"\nRemoving quantum pathways one by one alters the ways they can interfere. The changes are visible in the Raman-scattering intensity emitted by the experimental device when it was illuminated by a beam of near-infrared laser light. Although the glow from scattering is much fainter than the near-infrared excitation, changes in its brightness can be measured precisely.\n\"In classical physics, you'd expect to see the scattered light get dimmer as you remove excitation pathways,\" says Wang, but the results of the experimenter came as a surprise to everyone. \"Instead the signal got stronger!\"\nThe scattered light grew brighter as the excitation pathways were reduced – what Wang calls \"a canonical signature of destructive quantum interference.\"\nWhy \"destructively?\" Because phonons and scattered photons can be excited by many different, nondistinguishable pathways that interfere with one another, blocking one path can either decrease or increase the light from scattering, depending on whether that pathway was interfering constructively or destructively with the others. In graphene, the lower and higher-energy pathways interfered destructively. Removing one of them thus increased the brightness of the emission.\n\"What we've demonstrated is the quantum-interference nature of Raman scattering,\" Wang says. \"It was always there, but it was so hard to see that it was often overlooked.\"\nIn a second observation, the researchers found yet another unexpected example of inelastic light scattering. This one, \"hot electron luminescence,\" didn't result from blocked quantum pathways, however.\nWhen a strong voltage is applied and the graphene's Fermi energy is lowered, higher-energy electron states are emptied from the filled band. Electrons that are highly excited by incoming photons, enough to jump to the unfilled band, thus find additional chances to fall back to the now-vacant states in what was the filled band. But these \"hot\" electrons can only fall back if they emit a photon of the right frequency. The hot electron luminescence observed by the researchers has an integrated intensity a hundred times stronger than the Raman scattering.\nThe road taken\nThe poet Robert Frost wrote of coming upon two roads that diverged in a wood, and was sorry he could not travel both. Not only can quantum processes take both roads at once, they can interfere with themselves in doing so.\nThe research team, working at UC Berkeley and at Berkeley Lab's Advanced Light Source, has shown that inelastic light scattering can be controlled by controlling interference between the intermediate states between photon absorption and emission. Manipulating that interference has enabled new kinds of quantum control of chemical reactions, as well as of \"spintronic\" states, in which not charge but the quantum spins of electrons are affected. Strongly enhanced Raman scattering can be a boon to nanoscale materials research. Hot luminescence is potentially attractive for optoelectronics and biological research, in which near-infrared tags – even weak ones – could be very useful.\n\"Likewise the phenomenon of hot electron luminescence, because it immediately follows excitation by a probe laser, could become a valuable research tool,\" says Wang, \"particularly for studying ultrafast electron dynamics, one of the chief unusual characteristics of graphene.\"","Anti-reflective coating (also called AR coating or anti-glare coating) improves both your vision through your lenses and the appearance of your eyeglasses.\nBoth benefits are due to AR coating's ability to eliminate reflections of light from the front and back surface of eyeglass lenses.\nAR coating is especially beneficial when used on high-index lenses, which reflect more light than regular plastic lenses. Generally, the higher the index of refraction of the lens material, the more light that will be reflected from the surface of the lenses.\nFor example, regular plastic lenses reflect roughly 8 percent of light hitting the lenses, so only 92 percent of available light enters the eye for vision. High index plastic lenses can reflect up to 50 percent more light than regular plastic lenses (approximately 12 percent of available light), so even less light is available to the eye for vision. This can be particularly troublesome in low-light conditions, such as when driving at night.\nToday's modern anti-reflective coatings can virtually eliminate the reflection of light from eyeglass lenses, allowing 99.5 percent of available light to pass through the lenses and enter the eye for good vision.\nAnti-reflective coating reduces the glare that you see, as well as the glare that others can see on your lenses.\nBy eliminating reflections, AR coating also makes your eyeglass lenses look nearly invisible so people can see your eyes and facial expressions more clearly. Anti-reflective glasses also are more attractive, so you can look your best in all lighting conditions.\nThe visual benefits of lenses with anti-reflective coating include sharper vision with less glare when driving at night and greater comfort during prolonged computer use (compared with wearing eyeglass lenses without AR coating).\nAnti-reflective coating also is a good idea for sunglasses, because it eliminates glare from sunlight reflecting into your eyes from the back surface of tinted lenses when the sun is behind you. (Generally, AR coating is applied only to the back surface of sunglass lenses because there are no cosmetic or visual benefits to eliminating reflections from the front surface of dark-tinted lenses.)\n- Questions about dry eye? Click to ask our dry eye expert right now\n- Afraid of Lasik? This new interactive quiz separates fact from fiction\n- The LASIK experience: learn what happens before, during and after laser eye surgery surgery\nMost premium anti-reflective coatings include a \"hydrophobic\" surface layer that prevents water spots from forming and makes the lenses easier to clean. Some AR coatings also include an \"oleophobic\" surface layer that repels skin oils and makes it easier to remove smudges from the lenses.\nSome eyeglass lenses have factory-applied AR coating on both lens surfaces. Other lenses, particularly progressive lenses and other multifocal lenses (i.e., bifocals and trifocals), have the coating applied after the lenses have been customized to your eyeglass prescription by an optical lab.\nHow Anti-Reflective Coating Is Applied\nApplying anti-reflective coating to eyeglass lenses is a highly technical process involving vacuum deposition technology.\nThe first step in the AR coating process is to meticulously clean the lenses and inspect them for visible and microscopic surface defects. Even a tiny smudge, piece of lint or hairline scratch on a lens during the coating process can cause a defective AR coating.\nTypically, a production line includes multiple washing and rinsing baths, including ultrasonic cleaning to remove any traces of surface contaminants. This is followed by air drying and heating of the lenses in special ovens to further remove unwanted moisture and gases from the lens surface.\nThe lenses are then loaded into special metal racks with spring-loaded openings so the lenses are held securely but with virtually all lens surfaces exposed for the coating application. The racks are then loaded into the coating chamber. The door of the chamber is sealed, and the air is pumped out of the chamber to create a vacuum.\nWhile the lens racks are rotating in the coating chamber, a power source within the machine focuses a beam of electrons onto a small crucible that contains a series of metal oxides in separate compartments.\nModern vacuum coating machine for applying AR coating to eyeglass lenses. (Image: SatisLoh)\nWhen bombarded by the beam of this electron \"gun\" in succession, the metal oxides are transformed into vapors that fill the coating chamber and adhere to the lenses in a specific order to form a precise multilayer AR coating.\nEach AR coating manufacturer has its own proprietary formula, but generally all anti-reflective coatings consist of multiple microscopic layers of metallic oxides of alternating high and low index of refraction.\nDepending on the AR coating formula, most lenses with anti-reflective coating have a very faint residual color, usually green or blue, that is characteristic of that particular brand of coating.\nAnti-reflective coatings are incredibly thin. The entire multilayer AR coating stack generally is only about 0.2 to 0.3 microns thick, or about 0.02 percent (two one-hundredths of 1 percent) of the thickness of a standard eyeglass lens.\nCaring for Glasses With Anti-Reflective Lenses\nWhen cleaning AR-coated lenses, use only products that your optician recommends. Lens cleaners with harsh chemicals may damage the anti-reflective coating.\nAlso, don't attempt to clean AR-coated lenses without wetting them first. Using a dry cloth on a dry lens can cause lens scratches. And because anti-reflective coating eliminates light reflections that can mask lens surface defects, fine scratches often are more visible on AR-coated lenses than on uncoated lenses.\nAbout the Author: Gary Heiting, OD, is senior editor of AllAboutVision.com. Dr. Heiting has more than 25 years of experience as an eye care provider, health educator and consultant to the eyewear industry. His special interests include contact lenses, nutrition and preventive vision care. Connect with Dr. Heiting via Google+.\n[Page updated May 2014]\nFor more Eyeglass Frames and Lenses articles, please visit this section's home page or use the search box below."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:24be5049-2260-44d7-8b27-a78caedef166>","<urn:uuid:68d80260-ee03-4cd0-b980-42936c7b0ea4>"],"error":null}
{"question":"Has anyone here tried ART vs CPT for PTSD treatment? Which one focuses more on changing memories? 😊","answer":"ART and CPT work differently in treating PTSD. ART focuses specifically on changing how traumatic memories are stored and remembered in the brain, allowing patients to 'replace' distressing images with positive ones so the original distressing images can no longer be accessed. In contrast, CPT focuses on modifying beliefs about self, others, and the world that changed after trauma, particularly addressing 'stuck points' related to power, control, esteem, safety, trust, and intimacy. CPT works by developing more balanced beliefs rather than directly altering memories.","context":["A new therapeutic approach uses traditional psychotherapies and training to relieve combat-related symptoms of post-traumatic stress disorder (PTSD) among veterans and active U.S. service members.\nThe technique is called Accelerated Resolution Therapy, or ART, and is a combination of evidence-based psychotherapies and use of eye movements.\nInvestigators have found the intervention is shorter and more likely to be completed than conventional therapies.\nThe findings appear online in Military Medicine, the international journal of AMSUS (The Society of Federal Health Professionals).\nPTSD is a prevalent, disabling disorder that can emerge following a life-threatening event or traumatic experience. Those experiences create chronic symptoms such as flashbacks, nightmares, sleep disturbances, mood swings, and loss of interest in life.\nAccording to PTSD Foundation of America, one in three soldiers returning from combat suffers PTSD symptoms, although less than 40 percent seek help. The organization also reports that at least five active duty military members attempt suicide every day.\nKevin Kip, Ph.D., F.A.H.A., professor and executive director at the University of South Florida College of Nursing, led the team of scientists and clinicians who conducted the first randomized controlled trial of ART in a military population.\nThe trial enrolled 57 service members and veterans, primarily from the Tampa Bay area.\n“Based on this trial and an earlier study completed at the USF College of Nursing, we believe that accelerated resolution therapy may provide the quickest way to effectively and safely treat post-traumatic stress disorder,” Kip said.\n“Our goal is to obtain enough evidence and interest to warrant classifying ART as a potential first-line treatment for PTSD among both civilian and military personnel.”\nThe patient first visualizes in his or her mind a prior traumatic experience which typically elicits uncomfortable physiological sensations like tightness of the chest, increased heart rate and sweating.\nThen, through talk therapy and a series of rapid left-to-right eye movements in which the patient follows the clinician’s hand back and forth, the sensations are minimized.\nIn the second phase, and with similar clinician input, the patient “replaces” the distressing images they have seen with positive ones in a way that the original distressing images can no longer be accessed.\nART is delivered in two to five one-hour sessions, requires no homework, and no written or verbal recall of the traumatic experience.\n“Through this therapy, we’re able to quiet down and separate physiological symptoms that come with re-envisioning a traumatic experience,” Kip said.\n“We can also alter or replace the traumatic images and add positive material to them. We are changing how images are remembered in the brain.”\nIt worked well for Brian Anderson, a former Green Beret, 10-year Army veteran and director of the Pasco County Veteran Services and Stand Down program.\nHe had tried an endorsed first-line PTSD treatment known as prolonged exposure therapy, which was very lengthy and worked for a while, but then symptoms like hypervigilance returned.\n“ART changed my life,” Anderson said.\n“This brief therapy took the bad memories that constantly resurfaced and put them in the proper order or long-term storage; it was almost like I was thinking about a time in history.\n“As a veteran, I would much rather go through a therapy that works, in only a few sessions, than sit through intensive and grueling sessions that last as long as 16 weeks.”\nIn the new study, researchers compared ART to a non-therapeutic PTSD treatment called attention control (AC) regimen.\nClinicians treated half of the 57 study participants (29) with ART, and the other half (28) received AC, which consisted of either physical fitness assessment and planning or career assessment and planning.\nAfter initial treatment, both groups received a three-month follow-up assessment.\n“Before and after these interventions, we compared the response, analyzing reductions in PTSD symptoms, depression and anxiety, and the results were very impressive,” Kip said.\n“In an average of less than four ART sessions, participants had very substantially reduced symptoms of PTSD, while those who received AC did not.”\nAfter the AC regimen, all veterans had the opportunity to receive ART, and in the full study, 94 percent completed treatment. Favorable results persisted at three months.\n“Accelerated resolution therapy is giving hope to many veterans who felt like they had no hope,” said Lt. Col. (Ret.) Lawrence A. Braue, Ed.D., director of the USF Office of Veterans Services.\n“I look forward to the day when this treatment is widely available across the country.”\nSource: University of South Florida","This is Part 2 of a 3-part series on posttraumatic stress disorder (PTSD) and eating disorders by Dr. Mary Hill. To access the first post describing the co-occurrence of eating disorders and PTSD click here.\nEvidence-based trauma therapies reduce symptoms of posttraumatic stress disorder (PTSD) and common co-occurring problems like depression, and improve functioning and well-being.1 Prolonged exposure (PE), cognitive processing therapy (CPT), and trauma-focused cognitive behavioral therapy (CF-CBT) are well-established evidence-based treatments for individuals with PTSD.2,3,4,5 Descriptions of each treatment and how they work are presented below.\nPE has the strongest recommendation as a treatment for individuals with PTSD in clinical practice guidelines.2,3,4,5 It addresses problematic avoidance that develops as a result of the trauma. People with PTSD often try to avoid things that remind them of the trauma because encountering people, places, objects, and memories that remind them of the trauma is highly distressing. Avoidance reduces distress in the moment, but ultimately makes PTSD worse. Over time, people avoid more and more trauma reminders, even those that most people would consider safe. Not only does this avoidance keep PTSD symptoms going, it negatively impacts individuals’ ability to engage in meaningful activities and live the kind of lives they want.\nPE works by helping individuals limit problematic avoidance through gradual, systematic exposure to feared but safe stimuli (e.g., places, situations, memories). Essentially, PE helps individuals face their fears safely. PE involves two types of exposure: imaginal exposure and in vivo exposure. During imaginal exposure, individuals retell the trauma memory. The major goal of imaginal exposure is to help individuals emotionally process the trauma memory in order to reduce PTSD symptoms. By repeatedly telling the trauma narrative, individuals better organize and process the memory and their cognitive and emotional reactions to it.\nDuring in vivo exposure, individuals approach objectively safe trauma-related situations (e.g., going to crowded places) that they have avoided because of trauma-related distress. Through direct experience during exposure, individuals learn that the trauma memory, reminders, and physiological responses are not dangerous, and the distress experienced when encountering them is temporary. In addition, new information learned through direct experience that is incompatible with trauma-related beliefs (e.g., “people can’t be trusted,” “I can’t handle being out by myself”) promotes improved quality of life as individuals reengage in meaningful activities previously avoided because of trauma-related distress.6\nCPT is another evidence-based treatment that focuses on one’s beliefs about self, others, and the world that changed as a result of the trauma and how these beliefs affect emotions and behaviors. Specifically, unhelpful beliefs related to power and control, esteem, safety, trust, and intimacy are addressed. It is thought that these beliefs that developed after the trauma make PTSD worse.\nThe primary focus of CPT is to modify dysfunctional cognitions that impair functioning, known as “stuck points.” For example, the “just world belief” states that, “good things happen to good people, and bad things happen to bad people.” If that is believed to be true, it can be hard for trauma survivors to make sense of why something bad happened to them and may impact their ability to engage in their lives as they did before the trauma. CPT challenges stuck points by teaching individuals how to assess whether facts support their stuck points. If not, they can work with their therapist to create a new perspective. CPT is believed to work by developing more balanced and helpful beliefs which decrease difficult emotions and other PTSD symptoms.7\nFinally, TF-CBT is an evidence-based treatment for children with PTSD or traumatic grief and their parents. Treatment includes components of PE and CPT. TF-CBT is comprised of psychoeducation about trauma and PTSD, teaching relaxation skills and other coping skills, in vivo exposure to reminders of the trauma, creation of a trauma narrative (which is similar to imaginal exposure), processing trauma-related thoughts and emotions, and developing safety skills.8\nDespite research support for these treatments, many trauma survivors and therapists express concern that trauma-focused therapies will make people with PTSD feel worse.9 However, the literature shows that most who participate in evidence-based PTSD treatment improve and do not experience worsening of PTSD symptoms or depression.10,11 These treatments are safe and effective, although it is important to find a therapist who is trained in the treatment modality, and it can be beneficial to ensure that individuals have good coping skills prior to beginning treatment as addressing trauma in treatment can be emotionally intensive. Although there are currently no established guidelines for when to address trauma in treatment for individuals with eating disorders or which treatment may be most beneficial, evidence-based PTSD treatments can be used in combination with eating disorders treatments. It is important for future research to assess the best way to integrate treatment for both PTSD and eating disorders.\n- van Minnen, A., Zoellner, L. A., Harned, M. S., & Mills, K. (2015). Changes in comorbid conditions after prolonged exposure for PTSD: A literature review. Current Psychiatry Report, 17, 1-16, doi: 10.1007/s11920-015-0549-1\n- Bisson, J. & Andrew, M. (2007). Psychological treatment of post-traumatic stress disorder (PTSD). Cochrane Database of Systematic Reviews, 3, 1-122. doi: 10.1002/14651858.CD003388.pub3\n- Institute of Medicine (2008). Treatment of posttraumatic stress disorder: An assessment of the evidence. Washington, D.C. The National Academic Press.\n- Cusack, K., Jonas, D. E., Forneris, C. A., Wines, C., Sonis, J., Cook Middleton, J., …Gaynes, B. N. (2016). Psychological treatments for adult with posttraumatic stress disorder: A systematic review and meta-analysis. Clinical Psychology Review, 43, 128-141. doi: https://doi.org/10.1016/j.cpr.2015.10.003\n- Difede, J., Olden, M. & Cukor, J. (2014). Evidence-based treatment of post-traumatic stress disorder. Annual Review of Medicine, 65, 319-332. doi: 10.1146/annurev-med-051812-145438\n- Foa, E. B., Hembree, E. A., & Rothbaum, B. O. (2007). Prolonged exposure therapy for PTSD: Emotional processing of traumatic experiences. New York, NY: Oxford University Press.\n- Resick, P. A., Monson, C. M., & Chard, K. M. (2014). Cognitive processing therapy: Veteran/military version: Therapist’s manual. Washington, DC: Department of Veterans Affairs.\n- Cohen, J. A., Mannarino, A. P., & Deblinger, E. (2006). Treating trauma and traumatic grief in children and adolescents. New York, NY: Guilford Press.\n- Ruzek, J. I., Eftekhari, A., Rosen, C. S., Crowley, J. J., Kuhn, E., Foa, E. B., Hembree, E. A., and Karlin, B. E. (2014). Factors related to clinician attitudes toward prolonged exposure therapy for PTSD. Journal of Traumatic Stress, 27, 423-429. doi: 10.1002/jts.21945\n- Jayawickreme, N. J., Cahill, S. P., Riggs, D. S., Rauch, S. A. M., Resick, P. A., Rothbaum, B. O., and Foa, E. B. (2014). Primum non nocere (first do no harm): Symptom worsening and improvement in female assault victims after prolonged exposure for PTSD. Depression and Anxiety, 31, 412-419. doi: 10.1002/da.22225\n- Foa, E. B., Zoellner, L. A., Feeny, N. C., Hembree, E. A., & Alvarez-Conrad, J. (2002). Does imaginal exposure exacerbate PTSD symptoms? Journal of Consulting and Clinical Psychology, 70, 1022-1028. http://dx.doi.org/10.1037/0022-006X.70.4.1022"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:4d752eb0-160e-41e8-8f79-ff97da2b1689>","<urn:uuid:5fad2a10-a33d-4b16-ba4f-975d7b54b260>"],"error":null}
{"question":"Hi! Do slot machines and other gambling games have specific built-in features to keep players engaged, and how do these affect different player motivations?","answer":"Yes, slot machines incorporate specific engagement features like the near-miss function, which affects players' brain activity and heart rate, though its direct influence on gambling behavior isn't fully proven. These machines also include bonus games and themed content based on popular media, movies, or TV shows to prevent boredom. Players' motivations vary significantly - some gamble purely for entertainment and excitement, others for socializing, and some to escape negative feelings. However, these motivations aren't static; they often change over time, particularly as people progress from social to regular gambling, where the focus typically shifts toward winning money and chasing losses.","context":["How Do Slot Machines Work?\nBonus games on slot machines are usually random. They involve choosing from a video display of multiple treasure chests or boxes. In such games, you don’t have to use any skills to win. Slot machine designers are also experimenting with video game elements. Some of them have features of classic games like Space Invaders.\nVideo slot machines have a video image rather than actual rotating reels\nVideo slot machines are similar to traditional slot machines but use a video image on the screen instead of actual spinning reels. The video image is created by an electronic circuit that changes the symbols on the screen depending on a predetermined outcome or sequence of events. Instead of rotating reels, video slots use a computer processor to create a video image, allowing players to see what they could win in advance without having to spin the reels.\nWhile this technology makes video slots more attractive, there are a few drawbacks. First of all, the visuals on a video slot machine may be difficult to interpret. Since a video image is digital, you may not be able to see the symbols on the reels very clearly. Also, it may be difficult to see if your winnings are obscured by a video.\nThey use a random number generator to determine the results of each spin\nTo ensure the randomness of results, slots use a random number generator (RNG). A RNG is a computer algorithm that generates a series of random numbers based on a mathematical formula. As such, the results of each spin are independent of previous spins and can therefore never be influenced by previous decisions. After you press “Spin,” a virtual reel starts spinning. During this spin, the RNG generates a random sequence of symbols, which is displayed to the player.\nRandom number generators are computer programs written by human programmers. They work like real random numbers, but with no order, pattern, or sequence. They can be programmed to generate random numbers based on a number of inputs, including machine date and time, and other data.\nThey have a higher RTP than mechanical slots\nThe UK Gambling Commission requires gaming machines to display the RTP. This figure is generally available in the paytable or help menu of a slot machine. The paytable also contains information about the rules of the game, the symbols, and statistics. A slot with a high RTP has higher winning potential than one with a lower RTP.\nOne game with a high RTP is Push Gaming’s Dinopolis slot. It’s a game that draws inspiration from a popular 90s cartoon series. Players aim to hit coins to earn instant prize wins or trigger free spins. The free spins can also contain sticky wilds and multipliers, and they can lead to a 50,000x payout.\nThey have a near-miss feature\nNear-miss features are built into slot games to increase player engagement. It’s a psychological phenomenon that can be combined with a player’s ability to stop the reels. Manufacturers use near-miss elements to keep players interested in the game, which is entirely legal. However, the underlying principle behind near-miss isn’t very clear.\nNear-miss events have been shown to influence brain activity and heart rate. However, there is little evidence that near-miss events increase gambling. There are other factors that influence people’s decisions to play. But scientists hope to learn more about this phenomenon in future research.\nThey have a theme\nSlots have a theme, and this theme often affects the symbols and bonus features of the game. This helps prevent boredom and makes playing more fun. The most popular themes include nature, sports, holidays, and popular films. Choosing a theme is an excellent way to avoid monotony and find the perfect slot game for you.\nA theme can also be found in video slots. Many video slots feature characters or motifs from popular media such as movies, TV shows, and cult classics. Other themes are more unique, such as those of crypto currencies. Cryptopunks, for instance, might be inspired by a cryptocurrency, and there are even slots devoted to crypto currencies. Other themes may include an ancient god of wealth or stunning visuals.","Back to the ‘why’ fronts: A brief look at gambling motivation\nPosted by drmarkgriffiths\nIn the three decades that I have been studying gambling, the question that I am most asked is ‘Why do people gamble?’ and variations on it, such as ‘Why do people gamble when most people consistently lose?’ All surveys of gambling have shown that there are a broad range motivational factors that are central to gambling, and that attitudes towards gambling are positively related to availability and cultural acceptability. However, this perspective fails to take into account many key findings and observations in gambling research. Surveys have also shown that not everyone gambles and some people gamble more than others (e.g., professional gamblers, problem gamblers). Research has consistently shown that people often gamble for reasons other than broad social and economic reasons. These other motivations may vary according to personal characteristics of the gambler and the type of gambling activity. Additionally, broad social and economic theories fail to explain why certain gambling activities are more popular or ‘addictive’ than others.\nVariations in gambling preferences are thought to result from both differences in accessibility and motivation. Older people tend to choose activities that minimise the need for complex decision-making or concentration (e.g., bingo, slot machines), whereas gender differences have been attributed to a number of factors, including variations in sex-role socialisation, cultural differences and theories of motivation. Stereotypically, women tend to prefer chance-based games and men tend to prefer skill-based games. Even some games that are predominantly chance-based, men attempt to impose some level of skill. For instance, poker – which people regard as skill-based – has a massive amount of chance involved. Similarly, men often, in their own minds, change playing a slot machine from a chance-based event into a more skill-based activity via cognitive processes such as the illusion of control. The other factor to consider is that (in general) women don’t like it when other people see them losing. On a slot machine, no-one sees the player is losing so it’s very often a very guilt-free, private experience. Men, on the other hand, even when they lose big, there’s a machismo attached to it that says: “Yes, I’ve lost £500 but I can afford it.”\nVariations in motivation are also frequently observed among people who participate in the same gambling activity. For example, slot machine players may gamble to win money, for enjoyment and excitement, to socialise and to escape negative feelings. Some people gamble for one reason only, whereas others gamble for a variety of reasons. A further complexity is that people’s motivations for gambling have a strong temporal dimension; that is, they do not remain stable over time. As people progress from social to regular and finally to excessive gambling, there are often significant changes in their reasons for gambling. Whereas a person might have initially gambled to obtain enjoyment, excitement and socialisation, the progression to problem gambling is almost always accompanied by an increased preoccupation with winning money and chasing losses.\nGambling is clearly a multifaceted rather than unitary phenomenon. Consequently, many factors may come into play in various ways and at different levels of analysis (e.g., biological, social, or psychological). Theories may be complementary rather than mutually exclusive, which suggests that limitations of individual theories might be overcome through the combination of ideas from different perspectives. This has often been discussed before in terms of recommendations for an ‘eclectic’ approach to gambling or a distinction between proximal and distal influences upon gambling. However, for the most part, such discussions have been descriptive rather than analytical, and so far, few attempts have been made to explain why an adherence to singular perspectives is untenable.\nGambling is one of those activities where people effectively can get something for nothing, which is why some people will take risks. The attraction of a lotter for example is that, for a very small stake, the individual can have a life-changing experience (and things are further complicated by the fact that most lottery players don’t see the activity as gambling). People who enjoy playing roulette or betting on a football match enjoy the betting or gaming experience itself. In short, each gambling activity has its own unique psychology (although there are undoubted overlaps).\nMost economists claim that gamblers are primarily driven by the profit motive. However, the psychological evidence is overwhelming that other desires affect gambling actions. Put simply, for most gamblers, our actions contradict the desire to maximize profits. Whilst I am no Freudian, there appear to be a whole range of unconscious factors at play in gambling. For instance, if players make a successful bluff during a card game, it’s human nature to want to let people to know how smart they are. The golden rule in poker is never to give anything away but the human psyche works in such a way that we usually want to show off once in a while. Our psychological make-up also means that we let pride get in the way of minimizing losses. There are always games that should have been avoided but players end up staying in them long after they knew it was a mistake. None of us like to lose to who we think are weaker players, or admit that the game was too hard. How many times does a player continue playing because they want to try and get the better of a great player or show off because there is someone they are trying to impress? Although it’s a cliché, pride before a fall is commonplace. These short-term psychological satisfactions will almost always have a negative impact on long-term profits.\nBecause there are many non-financial types of rewards from many different sources while gambling, some people view losses as the price of entry. To these players (and I include myself as one of them), winning may be a bonus. However, most of us don’t like losing – and we especially don’t like persistent losing, regardless of whether there are other types of reinforcement. In the cold light of day, we are all rational human beings. In the height of action, rationality often goes out the window. I’ve done it myself at the roulette table and standing in front of a slot machine. While gambling I have felt omnipotent. It is only after I walk away penniless that the non-financial rewards are short-term and not worth it.\nUnderstanding our own psychological motives is clearly important while gambling. Most players know the strategies they should be adopting but fail to apply them in real gambling situations. Players do not lack the information. It is far more profitable to learn why we don’t apply the lessons we have already learned, then ensure that we apply them. Until we understand and control our own motives — including the unconscious ones — we cannot possibly play to our best ability.\nDr Mark Griffiths, Professor of Gambling Studies, International Gaming Research Unit, Nottingham Trent University, Nottingham, UK\nCalado, F., Alexandre, J. & Griffiths, M.D. (2014). Mom, Dad it’s only a game! Perceived gambling and gaming behaviors among adolescents and young adults: An exploratory study. International Journal of Mental Health and Addiction, in press.\nGriffiths, M.D. (1990). The dangers of social psychology research. BPS Social Psychology Newsletter, 23, 20-23.\nGriffiths, M.D. (1999). The psychology of the near miss (revisited). British Journal of Psychology, 90, 441-445.\nGriffiths, M.D. (2006). An overview of pathological gambling. In T. Plante (Ed.), Mental Disorders of the New Millennium. Vol. I: Behavioral Issues. pp. 73-98. New York: Greenwood.\nGriffiths, M.D. (2007). Gambling psychology: Motivation, emotion and control, Casino and Gaming International, (3)4 (November), 71-76.\nGriffiths, M.D. & Wood, R.T.A. (2001). The psychology of lottery gambling. International Gambling Studies, 1, 27-44.\nMcCormack. A. & Griffiths, M.D. (2012). What differentiates professional poker players from recreational poker players? A qualitative interview study. International Journal of Mental Health and Addiction, 10, 243-257.\nParke, A. & Griffiths, M.D. (2011). Poker gambling virtual communities: The use of Computer-Mediated Communication to develop cognitive poker gambling skills. International Journal of Cyber Behavior, Psychology and Learning, 1(2), 31-44.\nParke, A. & Griffiths, M.D. (2012). Beyond illusion of control: An interpretative phenomenological analysis of gambling in the context of information technology. Addiction Research and Theory, 20, 250-260.\nAbout drmarkgriffithsProfessor MARK GRIFFITHS, BSc, PhD, CPsychol, PGDipHE, FBPsS, FRSA, AcSS. Dr. Mark Griffiths is a Chartered Psychologist and Professor of Behavioural Addiction at the Nottingham Trent University, and Director of the International Gaming Research Unit. He is internationally known for his work into gambling and gaming addictions and has won many awards including the American 1994 John Rosecrance Research Prize for “outstanding scholarly contributions to the field of gambling research”, the 1998 European CELEJ Prize for best paper on gambling, the 2003 Canadian International Excellence Award for “outstanding contributions to the prevention of problem gambling and the practice of responsible gambling” and a North American 2006 Lifetime Achievement Award For Contributions To The Field Of Youth Gambling “in recognition of his dedication, leadership, and pioneering contributions to the field of youth gambling”. His most recent award is the 2013 Lifetime Research Award from the US National Council on Problem Gambling. He has published over 600 research papers, four books, over 130 book chapters, and over 1000 other articles. He has served on numerous national and international committees (e.g. BPS Council, BPS Social Psychology Section, Society for the Study of Gambling, Gamblers Anonymous General Services Board, National Council on Gambling etc.) and is a former National Chair of Gamcare. He also does a lot of freelance journalism and has appeared on over 2000 radio and television programmes since 1988. In 2004 he was awarded the Joseph Lister Prize for Social Sciences by the British Association for the Advancement of Science for being one of the UK’s “outstanding scientific communicators”. His awards also include the 2006 Excellence in the Teaching of Psychology Award by the British Psychological Society and the British Psychological Society Fellowship Award for “exceptional contributions to psychology”.\nPosted on December 11, 2014, in Addiction, Compulsion, Cyberpsychology, Gambling, Gambling addiction, Gender differences, Internet gambling, Online gambling, Problem gamblng, Psychology, Technology and tagged Biopsychosocial influences, Gambling, Gambling decision-making, Gambling machismo, Gambling motivation, Gambling stereotypes, Illusion of control, Lottery psychology, Motivation psychology, Poker gambling, Problem gamblers, Professional gamblers, Sports betting. Bookmark the permalink. Leave a comment."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:51a6d85a-88ba-4c44-a621-f18885dcb422>","<urn:uuid:9b4ac671-4b26-4240-aa78-a1b803929efa>"],"error":null}
{"question":"How to prioritize safety action items using risk scoring?","answer":"To prioritize safety action items using risk scoring, multiply the risk score (consequence times likelihood, scoring between 1-36) by a chemical multiplier based on toxicity and flammability. For example, ethylene glycol with a risk score of 12 and multiplier of 2 gets a final score of 24, while epichlorohydrin with the same risk score but a multiplier of 4 gets a higher priority. This two-part scoring system helps bring clarity to decisions about priority recommendations, especially when dealing with different types of chemical incidents.","context":["By Gregory Hale\nProcess plants must remain safe, but budgets are tight and getting tighter, so that means safety professionals have to learn to more with less people and money.\nThat is where three safety professionals come in and suggested ideas during their presentations at the 14th Global Congress on Process Safety at the 2018 AIChE Spring Meeting, Orlando, FL, to lower costs on various projects they worked on over the years.\nIn one case, inspecting pressure vessels can be expensive and dangerous, but Russ Davis, national AIMS MI COE manager at Mistras Group said there are instances where non-intrusive inspections (NII) in lieu of intrusive inspections could benefit a company.\nNormally pressure vessels are inspected at one half of the remaining life based on corrosion rate or every 10 years. Intrusive inspection is very dangerous and expensive,” Davis said. “External inspections can eliminate the need for confined space inspection.”\nIt also eliminates the need for an empty and clean process, the need to degas, internal surface preparation and the requirement for personnel to enter the vessel.\nFor an external inspection, Davis said, there are very rigid requirements to assess the vessel which could ensure a safer operation.\nDisadvantages to an external inspection include:\n• Can’t inspect internal parts\n• No visual records of internals\n• May not detect small surface indicators\n• External does not inspect 100 percent of vessel, but internal does not either\nIntegrity review, Davis said, is essential to gather and evaluate background data and documentation on equipment.\nThe following are part of the decision process to see if the user is eligible for NII:\n• Should the vessel be considered for NII\n• Confidence to predict damage of vessel; do you have data to predict damage\n• Previous inspection effectiveness\n• Security and rate of degradation\n“The inspection plan looks at what needs to be done and where it needs to be done,” he said. “Also, you have to understand damage mechanisms. Once a plan has been created, it is then executed and once that is done there is an inspection analysis. We then can assess the outcome and address it.”\nSo, for project where a pressure vessel inspection is needed, there are options.\n“NII in lieu of internal is an option over the traditional method,” Davis said. “There are significant benefits and it is cost effective and inherently safer for personnel.”\nAlong the lines of working on projects, Steven Maher principal engineer with RMP Corp. talked about optimizing a remote HazOp/LOPA.\n“A quality process hazard analysis is fundamental,” Maher said. “You can’t have safety without knowing the hazard. PHA has been a fundamental element of safety for quite a while and it is constantly evolving. The team is expected to do more and there are more demands for some busy people.”\nThat is why he talked about the possibility of teleconferencing with large groups to iron out issues.\n“There has been an evolution on HazOp/LOPA over the years, but the core applications have not changed much, but how we apply them has,” he said.\nThere are tools out there that can help, he said, but with some of the “flashy” technologies out there, they also present issues if you don’t know what you need.\nWhile having everyone in one location is ideal, video conferencing tools can help in a global engagement.\nThere have been changes in capital projects including financial pressures to accelerate project schedules, the use of package vendors, understanding that time is money and making mistakes is not an option.\nThat also falls in line with geographic issues, the number of stakeholders changes the way we do projects and assembling large groups in one location is very costly.\nTeleconferencing technology has evolved to where it is more cost effective to bring people together from remote locations. The catch is, though, planning becomes even more important.\nThe following are some tips, Maher suggested to prepare for a remote meeting:\n• Adequate computers/displays\n• IT support\n• Verify room is available\n• Make sure you have bandwidth\n• Predefine and communicate causes\n• Predefine and communicate questions\n• Extra planning and preparation is required\n• It can accelerate the progress of capital projects\n• Aid in project control\n• Enhance teamwork\n• Result in tangible savings\n• Technology advances will continue to make collaboration easier\n“Process safety professionals have been able to embrace and adapt new ways of working together. Don’t let the flashy technologies blind you to the importance of HazOp/LOPA.”\nSafety Severity Levels\nFinding a new way to understand the severity of safety issues was something Humbert “Joe” Howard, global manager of Process Safety at SACHEM Inc. had to create.\n“We needed to standardize our procedures and processes, Howard said during his presentation. “As our teams started working on process safety, they were generating action items and the system was starting to get stressed out. There were more action items than money to take of them.”\nThat is when senior management decided the company needed help to alleviate the stressed-out system.\n“We needed to prioritize action items to get relief every month,” Howard said.\nThe company wanted to:\n• Use the existing company global risk matrix\n• Integrate an action management system\n• Spend as little money as possible\nAt first the action items assigned only four levels: Low, medium, high, very high. There was no separation of action items with each level. That process worked with two plants, but Howard said they added new plants and there needed to be more context on the action items.\nThat is when they created risk scoring. The risk score equaled consequence times likelihood with scores between 1 and 36. While at first they thought that was the answer, but the issue was everything scored somewhere in the middle. There was not enough differentiation for incidents.\nThat is when they got an idea.\n“We had to consider the chemical involved. If a plant had eight spills, it was marked as a spill, but what kind of spill was it? We had to consider the flammability and toxicity.”\nAs a result, they didn’t really reinvent the wheel, so they didn’t change the existing risk score, but “we added a multiplier on top of that to give a more informed action item score.”\nAn example he gave was ethylene glycol would have a risk score of 12, but with a multiplier of 2 based on toxicity and flammability the final score came in at 24. With epichlorohydrin, it received the same risk score of 12, but got a multiplier of 4 based on its toxicity and flammability which meant it was a larger safety issue and should be a higher priority.\n“Using a two-part scoring system can help bring clarity to tough decisions a company must make about recommending a priority.”"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:d13c34d3-6af3-4d58-9a7f-bff234cc68e7>"],"error":null}