{"question":"What has happened to the number of hedge funds operating in Eastern Europe since the start of 2022?","answer":"Since the outbreak of war in Ukraine, the number of hedge funds tracked by BarclayHedge in the Eastern European region has dramatically decreased, falling from 43 at the start of the year to just 15 funds.","context":["Hedge funds investing in Eastern Europe face worst results in eight years By Reuters\nEconomy 4 minutes ago (Sep 15, 2022 15:56)\n© Reuters. FILE PHOTO: A skyline of skyscrapers is reflected in the Vistula river in the evening in Warsaw, Poland August 22, 2022. REUTERS/Kacper Pempel\nBy Nell Mackenzie\n(Reuters) – Hedge funds trading Eastern European stocks and bonds are seeing their worst performance in eight years, weakened by the surge of global inflation, the strength of the U.S. dollar and the war in Ukraine, the BarclayHedge Eastern European index shows.\nThe index, which tracks the performance of hedge funds trading stocks and bonds in the region, has dropped by 22.65% from the start of 2022 to the end of August, the index compiled by the data provider BarclayHedge shows.\nThis puts it on track for its worst performance since 2014.\nAnother index by the same data provider, which follows fund managers trading only stocks in Eastern Europe, is down even further, by almost 32% over the same time period.\nAn MSCI EM Eastern Europe ex-Russia index that trades in euros is down just over 30% year-to-date, underperforming wider emerging market equities as well as global stocks benchmarks. The MSCI International EM Price Index is down 22% and the MSCI All Country World Price Index is down 20%.\nThe dollar‘s surge to 20-year highs in the face of soaring inflation and aggressive rate hikes from the Federal Reserve have caused pain across the world. It draws funds back to U.S. assets and pushes up the cost of imports as local currencies weaken against the dollar.\n“There’s a difficult combination of factors occurring in that part of the world right now,” said Ben Crawford, vice president of research at BarclayHedge. “The smallest threat that the war might cross into the other Baltic states makes investors nervous to take on exposure to these markets.”\nSince the outbreak of war in Ukraine, the number of funds BarclayHedge tracks in the region has fallen to just 15 from 43 since the start of the year, the data provider said.\nOne portfolio manager at a fund with over $100 billion under management said the stock prices of companies in Eastern Europe stood no chance against the rise in the dollar.\nStock prices tumbled across Europe on Wednesday after higher-than-expected U.S. inflation this week foreshadowed another significant rate hike by the Federal Reserve.\nHedge funds investing in Eastern Europe face worst results in eight years\nWASHINGTON (Reuters) – Downside risks continue to dominate the global economic outlook and some countries are expected to slip into recession in 2023, but it is too early to say…\nWASHINGTON (Reuters) – The International Monetary Fund could provide about $1.4 billion in emergency aid to Ukraine almost immediately if its executive board approves a new “food…\n(Reuters) – Global growth is heading for an “increasingly synchronous downturn”, economists at Barclays (LON:BARC) said on Thursday, citing a deepening energy crisis in Europe,…\n© 2007-2022 Fusion Media Limited. All Rights Reserved.\nRisk Disclosure: Trading in financial instruments and/or cryptocurrencies involves high risks including the risk of losing some, or all, of your investment amount, and may not be suitable for all investors. Prices of cryptocurrencies are extremely volatile and may be affected by external factors such as financial, regulatory or political events. Trading on margin increases the financial risks.Before deciding to trade in financial instrument or cryptocurrencies you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.Fusion Media would like to remind you that the data contained in this website is not necessarily real-time nor accurate. The data and prices on the website are not necessarily provided by any market or exchange, but may be provided by market makers, and so prices may not be accurate and may differ from the actual price at any given market, meaning prices are indicative and not appropriate for trading purposes. Fusion Media and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information contained within this website.It is prohibited to use, store, reproduce, display, modify, transmit or distribute the data contained in this website without the explicit prior written permission of Fusion Media and/or the data provider. All intellectual property rights are reserved by the providers and/or the exchange providing the data contained in this website.Fusion Media may be compensated by the advertisers that appear on the website, based on your interaction with the advertisements or advertisers."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:64b4b15a-66ab-42a1-a932-bc5de821d74d>"],"error":null}
{"question":"I work in manufacturing and need to know: which material has higher temperature resistance - polyurethane or RTV silicone adhesives?","answer":"RTV silicone adhesives have higher temperature resistance compared to polyurethane. Silicones can withstand temperatures from -45°C to over +180°C, with specialized types remaining elastic even at 250°C and tolerating even higher temperature spikes. In contrast, polyurethane materials can only withstand temperatures between -80°F up to 300°F (approximately 149°C).","context":["Single part RTV (RTV-1) silicones are one-step, ready-to-use adhesives and sealants. They crosslink automatically when exposed to air humidity at room temperature. Cost-effectiveness and sustainability are key considerations when it comes to bonding and sealing. Bonding with silicone adhesive sealants has decisive advantages over traditional mechanical joining technologies in terms of handling, functionality, durability and cost efficiency. These silicone rubbers are either room-temperature-vulcanizing (RTV) or one-part heat-curing systems. Both systems are exceptional for their processing properties.\nAnother important criterion for selecting the best product is the flow property – we offer you RTV-1 silicones with a consistency ranging from free-flowing to non-sag pastes.\nWACKER silicone adhesive sealants can be applied easily and economically either manually or with automated dispensing equipment. Compared to mechanical joining methods, adhesive sealants significantly reduce not only the quantity of parts (e.g. screws, rivets, etc.) but also the number of process steps. Hence, silicone adhesive sealants help to reduce process cycle time.\nRTV-1 silicones find many applications in form-in-place (FIP) gaskets and cure-in-place (CIP) gaskets.\nFeatures & Benefits\n- Bonding efficiency: An adhesive sealant acts as a bonding agent and sealant at the same time. The need for additional mechanical safeguarding measures often becomes obsolete.\n- High joint reliability: Thanks to the good electrical insulating properties of silicones, different metals can be bonded without the risk of galvanic corrosion.\n- Joint stress relaxation: Thanks to their low Young’s modulus, silicone adhesive sealants effectively compensate thermomechanical loads resulting from substrates with a different coefficient of thermal expansion.\n- Versatile applicability: Silicone adhesive sealants have a high ability to bond dissimilar materials, usually without the need for primers.\n- Temperature resistance: Permanently elastic properties from -45°C to over approx +180°C; Specialised types remain elastic even at 250°C and briefly tolerate even higher temperature spikes\n- Chemical resistance: Permanent resistance to aqueous solutions, dilute acids and bases as well as solvents\n- Resistance to radiation: Can be exposed to electromagnetic radiation emitted by sources from microwaves to UV even at higher doses\n- Vibration and mechanical strength: Processing tolerances for joint parts are effectively compensated and vibrations are effectively dampened thanks to its high elasticity\n- Minimal moisture absorption: The hydrophobic, water-repellent surface of silicones offers excellent protection against moisture\n|Product||Colour||Cure Mechanism||Rheology||Cure Time||Applications|\n|Elastosil N9111||Black||Alkoxy||Non slump paste thixotropic||Skin 25-30 mins||Neutral cure non-corrosive adhesive sealant with excellent primerless adhesion; applications in electronics/automotive/appliances|\n|Elastosil N9111||White||Alkoxy||Non slump paste||Skin 25-30 mins||Neutral cure non-corrosive adhesive sealant with excellent primerless adhesion; applications in electronics/automotive/appliances|\n|Elastosil N2010||Colourless / Translucent||Alkoxy||Flowable||Skin 20 mins||General-purpose potting and coating grade for technical applications; self-levelling|\n|Elastosil N2034||Black||Alkoxy||Flowable||Skin 20 mins||General purpose adhesive sealant; suitable for FIP gaskets; UL94 V-0; neutral cure|\n|Elastosil N2189||Black||Alkoxy||Non slump||Skin 15 mins||General purpose adhesive sealant; suitable for FIP gaskets; UL94 V-0; neutral cure; oil and coolant resistant; hard|\n|Elastisil N2199||Transparent||Alkoxy||Non slump paste||Skin 15 mins||Excellent adhesion to plastics and metals; high elasticity makes it suitable for joining materials with different coefficients of thermal expansion; meets the physical requirements of MIL-A-46146, Group I, Type I|\n|Elastosil E4||Transparent||Acetoxy||Non slump||Skin 15 mins||General-purpose adhesive and sealant with low compression set|\n|Elastosil E10||Red||Acetoxy||Very low viscosity||Skin 10-15 mins||Excellent heat stability and good mechanical properties; sealing tubular heaters|\n|Elastosil E43||Transparent||Acetoxy||Self levelling||Skin 15 mins||General-purpose adhesive and sealant; excellent primerless adhesion to many substrates|\n|Elastosil E43 N||Transparent||Acetoxy||Self levelling||Skin 5-10 mins||Food compliant; excellent primerless adhesion to many substrates|\n|Elastosil E47||Transparent||Acetoxy||Non slump||Skin 5-15 mins||General-purpose adhesive and sealant; very good mechanical properties|\n|Elastosil E50 N||Translucent||Acetoxy||Flowable||Skin 8-20 mins||Food compliant; excellent primerless adhesion to many substrates; Meets MIL-A-46106|\n|Semicosil 989/1K||Black||Thermal||Non slump thixotropic||6h at 100°C;\n10 min at 150°C\n|General purpose adhesive for electronics; FIP and CIP gasket applications; primerless adhesion to many substrates; cold storage|\n|Product||UL94 V-0||Tensile Strength||Elongation %||Temperature Range||Hardness|\n|Elastosil N9111||Yes||2.2 N/mm2||500||-50 to 200°C||Shore A 30|\n|Elastosil N9111||Yes||2.2 N/mm2||500||-50 to 200°C||Shore A 30|\n|Elastosil N2010||1.0 N/mm2||200||-50 to 180°C||Shore A 25|\n|Elastosil N2034||Yes||2 N/mm2||200||-50 to 180°C||Shore A 35|\n|Elastosil N2189||Yes||2.3 N/mm2||250||up to 180°C||Shore A 45|\n|Elastosil N2199||2.5 N/mm2||350||-50 to 150°C||Shore A 30|\n|Elastosil E4||2.0 N/mm2||750||up to 180°C||Shore A 15|\n|Elastosil E10||6.2 N/mm2||600||Shore A 25|\n|Elastosil E43||4.5 N/mm2||500||-50 to 180°C||Shore A 30|\n|Elastosil E43 N||6.2 N/mm2||600||Shore A 30|\n|Elastosil E47||4.5 N/mm2||450||Shore A 35|\n|Elastosil E50 N||1.5 N/mm2||150||up to 180°C||Shore A 35|\n|Semicosil 989/1K||5 N/mm2||200||-50 to 180°C||Shore A 55|\nWe supply the equipment necessary to dispense silicones, including manual silicone dispensing guns and complete automated silicone dispensing systems. Get in touch with our team to discuss the best options for your production environment.\nSee how one of our customers improved their manufacturing process and quality in this silicone dispensing Case Study:\n|Automated dispensing helps security manufacturer increase throughput and quality\nGJD Manufacturing switched to an automated method of dispensing silicone for sealing a plastic lens to aluminium housing. By doing this, they improved the throughput and quality of their white-light and infrared LED illuminators for the security industry.\n- Last updated: October 2019\n- Version: 2.0\nSemicosil® and Elastosil® are registered trademarks of Wacker Chemie AG. Statements, technical information and recommendations contained herein are based on tests we believe to be reliable but they are not to be construed in any manner as warrantees expressed or implied. The user shall determine the suitability of the product for his intended use and the user assumes all risk and liability whatsoever in connection therewith.","Polyurethane vs Silicone\nSilicone and polyurethane are common types of materials used to produce many products and components. While both materials may be used to create similar objects, the physical properties and environmental conditions in an application will ultimately dictate the appropriate material for your product design. In this post, we will uncover the differences between silicone and polyurethane to streamline your material decisions.\nWhat is Silicone?\nSilicone, also known as polysiloxane, is a rubbery elastomeric material made of carbon, hydrogen, oxygen, and silicon. Like polyurethane, most silicone is a thermosetting material that can essentially take on any shape or form, depending on the viscosity and manufacturing process. When designing with silicone, there are typically three types of materials available, such as Liquid Silicone Rubber (LSR), High Consistency Rubber (HCR), or Room Temperature Vulcanizing (RTV). Each material option features a different set of physical properties and molding techniques to accommodate various design needs. Specific chemical additives can be incorporated in silicone during its raw, liquid state to achieve a range of properties, including tear strength, temperature, electrically conductive, and flame resistance. Silicone is available in hardness levels between 10 to 90 Shore A.\nWhat is Polyurethane?\nPolyurethane is formed through the chemical reaction between a polyol and diisocyanate. Unlike silicone, polyurethane can be soft and flexible as a cushion to something as hard and rigid as metal. Thermoset polyurethanes, in particular, can be chemically engineered into a solid or foam and portray a wide range of physical properties and surface finishes through either a cast molding or Reaction Injection Molding (RIM) process. Cast molding with thermoset polyurethane can offer a significant amount of customization to meet specific design and performance requirements, while RIM combines the superior properties of thermoset polyurethanes with the adaptability of injection molding techniques. Because of this, there is almost an endless range of material options and design flexibility to meet exact requirements. Polyurethane is available in three hardness scales, including Shore A, D, and 00. For more information about hardness and how its measured, click here.\nDifferences Between Silicone & Polyurethane\nDespite making similar products, silicone and polyurethanes differ significantly. As an example, the table below breaks down these variations to help discern between these two sought-after materials:\n|Commonly injection, cast, or compression molded||Commonly cast or Reaction Injection Molded (RIM)|\n|Foam is often considered a specialty material, due to high costs & processing difficulties||Can be engineered into many types of solid and foam materials|\n|Hardness levels typically range in Shore A scale||Hardness levels can range between Shore A, D, 00 scales|\n|Able to withstand temperatures between -65°F up to 500°F||Able to withstand temperatures between -80°F up to 300°F|\n|Exhibits high resistance to extreme temperatures, but often displays low tensile strength, abrasion resistance, & wear and tear properties||Exhibits high abrasion resistance, tensile strength, & extended wear and tear properties. Physical properties can be customized to meet specific performance requirements|\n|Material costs are significantly higher, especially for foam||Offers a more economical setup for small & large runs|\nWhich Material Should You Choose?\nSilicone and polyurethane can fit into a wide range of products and components, depending on your application and performance requirements. However, polyurethanes can produce stronger, more robust products with an almost endless range of physical properties and small to large, complex geometries. For this reason, this adaptable material is often considered for applications, such as military & defense, medical devices, and paper & media handling to name a few. Silicone, on the other hand, is typically best for products that must withstand high resistance to extreme temperatures. For instance, silicone can often be found in consumer and medical products, such as baby goods, baking or cooking supplies, and tubing or hoses, depending on the type of silicone. When evaluating silicone vs polyurethane, it is important to consider the key physical properties required for improved performance.\nIf you are seeking material assistance for your product design idea, complete our design tool, here, or download our Durethane datasheet below to explore the superior properties available."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:71b4f071-e256-4ed9-b143-483e4b64c7e7>","<urn:uuid:118202f4-befd-473b-9a24-09b1754b9096>"],"error":null}
{"question":"Hey! I've been diagnosed with atypical hyperplasia in my breast tissue and I'm worried! What types are there and what can I do about my risk?","answer":"There are two main types of atypical hyperplasia: atypical ductal hyperplasia (ADH) and atypical lobular hyperplasia (ALH). Both types have similar potential to develop into breast cancer, with research showing a 2:1 ratio of cancer developing in the same breast versus the opposite breast. If you're diagnosed with atypical hyperplasia, you should speak with your healthcare provider who can refer you to a genetic counselor. They can assess your risk based on medical and family history and determine if genetic testing is needed. For high-risk individuals, preventative options include risk-reduced surgery (preventative mastectomy), chemoprevention (using drugs to reduce risk), and enhanced screening programs. It's important to note that being high risk doesn't guarantee developing breast cancer, but understanding your risk allows you to take appropriate preventative measures.","context":["Definition: HIGH RISK\nWe know that being a woman and aging are risk factors in developing breast cancer. However, there are certain factors that can increase a person’s risk of developing the disease – more so than just the average woman.\nAccording to the Canadian Breast Cancer Foundation, if a person has one (or a combination) of these 4 characteristics they are considered “high risk:”\n- Is a confirmed carrier (has been genetically tested) of BRCA1 or BRCA2 gene mutations\n- Is a first degree relative (parent, sibling, or child) of a confirmed BRCA1 or BRCA2 carrier\n- Has a family history of breast cancer (usually multiple family members)\n- Has a personal history of high levels of radiation exposure to the chest (ie/ radiation therapy for Hodgkin’s lymphoma)\nWhat’s the deal with BRCA1 and BRCA2?\nEveryone has these genes. In fact, they are actually designed to protect us from developing breast and ovarian cancers. However, when there is a mutation in the gene, DNA repair doesn’t happen as it should – leading to the overproduction of cells (or cancer). This kind of mutation can be inherited from maternal and paternal sides of the family.\nClick HERE for more information.\n2You aren’t doomed\nWomen with BRCA1 or BRCA2 gene mutations have a 40-85% chance of developing breast cancer in their lifetime. However, only 5-10% of breast cancer cases are the result of hereditary/genetic factors. What does this mean? It means that being high risk does not give you a 100% guarantee of developing breast cancer. Rather, the term “high risk” is a classification that medical professionals (and the women and men in question) can use to increase their understanding of the situation and to take preventative measures, if necessary.\nIf you are high risk or you know someone who is, don’t freak out. This knowledge takes you one step closer to being in charge of the decisions surrounding your breast health. Find out about the preventative measures that high risk individuals can take below!\n3What can you do?\nSpeak to your health care provider\nIf you are unsure about your breast cancer risk or think you might be high risk, the first thing you can do is speak to your health care provider. From there, you can be referred to a genetic counsellor.\nGenetic counsellors help you understand what your risk of breast cancer is. With the counsellor’s help, you will be assessed depending on your medical and familial history. From there, it can be decided if you are eligibe for genetic testing.\nGenetic testing occurs as a blood or saliva test to determine if you have any genetic mutations that could predispose you to breast cancer (like BRCA1 or BRCA2).\nPreventative treatment options for high risk women\n- Risk-reduced surgery (AKA preventative mastectomy): the removal of one or both healthy breasts\n- Chemoprevention: the use of drugs to reduce risk in healthy individuals\nUltimately, every choices is yours to make. While, the preventative treatments mentioned above are the most impactful in reducing breast cancer risk, they aren’t for everyone. Other basic steps you can take to try to reduce your risk every day are:\n4Screening is your friend\nAccording to Cancer Care Ontario, women who are high risk only make up 1% of the general population. However, high risk women tend to develop more aggressive breast cancer and at earlier ages. As such, breast screening for these individuals is very important.\nIt is important that you check what the screening guidelines are in your province/state. However, if you are a high risk woman living in Ontario, you may be eligible for the Ontario Breast Screening Program (OBSP), which uses a combination of MM/MRI screening for high risk women ages 30 to 69 in hopes to “improve their quality of care, ensuring that they receive the benefits of screening and promote the early detection of breast cancer.”\nThe National Comprehensive Cancer Network (NCCN) has created a series of screening recommendations depending on the type of risk factor(s) you possess. See the full chart here and speak to your health care provider about the screening options available to you.\n5You are your best advocate\nAs a high risk young women, you are you best advocate. It’s unfortunate, but don’t be surprised if your concern gets shrugged off with the all too familiar response: “You’re too young to get breast cancer.” If you think you might be high risk, advocate for yourself. Ensure your health care provider speaks to you seriously about your risk and get the referral you need. Again, no one is guaranteed to get breast cancer. But, you have the right to be informed about your breast health so you can make the decisions that feel right for you.","A breast biopsy is a common procedure often performed after a mammogram reveals evidence of abnormal hyperplasia (increased cell production). Now a new study finds two types of breast tissue abnormalities have the same potential to progress to breast cancer, which is contrary to the existing understanding. The scientists responsible for this investigation suggest the care and management of patients with breast tissue abnormalities might be improved based on the results of their study. \"We work in the area of atypical hyperplasia because it is the most important pre malignant lesion in the breast,\" Dr. Lynn C. Hartmann, professor of oncology at the Mayo Clinic, told Medical Daily in an email. \"And we are interested in bringing forward optimal means of screening and reducing risk in women who have atypia.\" Hartmann is co-author of the new study published in Cancer Prevention Research.\nA mammogram, which is an x-ray picture of the breast, is commonly used to screen for breast cancer in women over the age of 40 because they can detect tumors as well as abnormal cell growth that cannot be felt during self-examination. One breast tissue abnormality frequently spotted during a mammogram is atypical ductal hyperplasia (ADH), which is generally considered to be a direct precursor to a low-grade invasive ductal cancer. Atypical lobular hyperplasia (ALH) is another frequent discovery, but ALH is generally thought to be only a risk indicator and not a sign of impending breast cancer.\nAlthough both these types of atypical cell growth are not fully understood, the current recommendations followed by many doctors include surgically removing any ADH lesions found in the breast, while allowing most ALH lesions to remain. The current study, then, is all about testing these guidelines: Are they accurate? Having previously investigated atypical hyperplasia in 331 women diagnosed at the Mayo Clinic from 1967 to 1991, Hartmann and a team of scientists decided to extend the follow-up period through 2001 and in this way come to better understand both ductal and lobular atypical hyperplasia. The current study, then, tracks 698 women for an average of 12.5 years after their mammograms detected atypical cell growth.\nADH versus ALH\nAmong the 698 women in the Mayo Benign Breast Disease Cohort who had atypical cell growth, the research team identified 330 women with ADH, 327 with ALH, and 32 with both. Of these women, 143 of them eventually developed breast cancer during the extended follow-up period of the study. The first result of the study was unsurprising: The ratio of breast cancer in the same breast in which the unusual cell growth was detected versus in the opposite breast was the same, 2:1, for both ADH and ALH.\nUnexpectedly, though, the researchers found a similar number of women with either ADH or ALH had developed breast cancer in the same breast within five years of diagnosis; contrary to the current understanding, then, ALH may be a precursor in addition to being a risk indicator for cancer. Similar to ADH, the study data showed, ALH predominantly resulted in ductal cancer of the breast and both ADH and ALH resulted in invasive ductal cancers, of which 69 percent were intermediate or high grade cancers. \"We showed that even though the two types of atypia look different histologically, they behave quite similarly in terms of what happens to patients,” said Hartmann, who also told Medical Daily she chose to work in breast cancer because it is \"a major health problem in women.\"\nEven more, this final result directly conflicts with previous expert opinions that suggest women with atypia develop \"better risk\" or low-grade cancers with a good prognosis. In fact, the pattern of cancers found in these patients did not differ from those seen in the general population. \"If a woman has a breast biopsy and if it shows atypia, it might be wise for her to be seen at a breast center for recommendations about surveillance and preventive therapy options,\" Hartmann stated. \"We hope these data will further help clinicians make informed decisions for breast atypia management strategies.\" Going forward, Hartmann and her team will continue to advance their research in the area of breast tissue abnormalities. \"We are pursuing a number of molecular studies in atypia samples from women who progressed to breast cancer, vs those who did not, to answer these biological questions,\" she told Medical Daily.\nSource: Hartmann LC, Radisky DC, Frost MH, et al. Understanding the Premalignant Potential of Atypical Hyperplasia through Its Natural History: A Longitudinal Cohort Study. Cancer Prevention Research. 2014."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:78f514e6-c4b9-4bf5-9bce-1aab56c20bf1>","<urn:uuid:b987c083-0427-44ae-8c28-389791edf4cf>"],"error":null}
{"question":"Hi! I'm interested in understanding health crises - could you compare how scientific expertise helped handle the Ebola outbreak versus how allergic reactions are managed in terms of their life-threatening potential?","answer":"Both Ebola and severe allergic reactions (anaphylaxis) can be life-threatening, but they're managed differently based on scientific expertise. During the 2014 Ebola outbreak, countries with well-trained researchers and connections to global experts were able to quickly contain cases that crossed their borders, while nations in West Africa with fewer resources struggled. In contrast, allergic reactions, while usually not fatal, require immediate medical attention when they progress to anaphylaxis, which is a severe, life-threatening reaction. The key difference is that countries with scientific expertise can prevent Ebola's spread through containment, while allergic reactions require individual medical management regardless of a country's scientific capacity.","context":["Grateful for progress toward a disease-free world\nNovember / December 2017 | Volume 16, Issue 6\nOpinion by Fogarty Director Dr Roger I Glass\nTerrifying news accounts of recent deaths from Ebola, flesh-eating bacteria, HIV/AIDS, Zika and even the plague can give the misleading impression we are at greater risk than ever. But we are fortunate to live in a time when - thanks to scientific advances that have produced lifesaving vaccines and treatments - we can actually begin to imagine a disease-free world.\nAs we gather with our families to give thanks this season, it's appropriate to acknowledge the commitment of scientists around the globe who work tirelessly, often under difficult and dangerous circumstances, to solve the world's most pressing health problems. As we have all been reminded, diseases know no borders so it's important that we share our expertise and data, and form strong research collaborations - especially in locations with the fewest resources. After all, we are all only as strong as our weakest link.\nAt Fogarty, we support research and training programs to develop the next generation of global health leaders and increase scientific capacity in low- and middle-income countries (LMICs). We believe this work is critical to improving health around the world, in addition to bringing great dividends to Americans.\nPhoto by David Snyder for Fogarty/NIH\nFogarty acknowledges the commitment of scientists around\nthe globe who work tirelessly to solve the world's most\npressing health problems.\nFogarty trainees in many cases provide the bedrock that makes NIH research possible in low-resource settings. When HIV/AIDS emerged as a global crisis in the 1980s, Fogarty began programs to build scientific capacity in the LMICs where the suffering was greatest. Since then, research advances have informed care and treatment so that a diagnosis of HIV/AIDS has been transformed from a death sentence to a manageable chronic illness. Fogarty trainees played a significant role in research discoveries including development of rapid diagnostics for detecting and monitoring HIV infections, new drugs for treatment and new strategies for prevention, such as avoiding mother-to-child transmission, voluntary medical male circumcision and treatment as prevention.\nFrom a security standpoint, nations with scientific expertise are better prepared to contain infectious disease outbreaks when they occur. As we saw with Ebola in 2014, the countries that had well-trained researchers who were networked with global experts were able to swiftly manage the Ebola cases that crossed their borders, unlike some nations in West Africa, which had few technical or human resources to deploy. That's why Fogarty has launched a program that is specifically directed at building partnerships and supporting training for scientists in Guinea, Liberia and Sierra Leone.\nTraining foreign researchers helps U.S. scientists take advantage of unique opportunities for discovery. When an unusual number of babies were born with microcephaly in rural Brazil, scientists trained by Fogarty to investigate Chagas disease redirected their research to examine the Zika virus, which was suspected of causing the spate of birth defects. Ongoing studies show adults can also be affected and that the virus can remain in the central nervous system for longer than originally expected.\nWe may learn the key to preventing the ravages of Alzheimer's disease - which is expected to strike one in three Americans and cost $1 trillion annually by 2050 - by studying an extended family with hereditary, early-onset Alzheimer's in rural Colombia. Fogarty has provided critical scientific training so that local researchers can perform brain scans, genetic analysis and other sophisticated approaches. That has already enabled a clinical trial of a U.S. manufactured drug that might help stop Alzheimer's at its earliest stage.\nAs we take stock during Fogarty's 50th year of existence, we measure much of our success in the people whose training we have supported. As they have advanced in their careers, they have in turn mentored the next generation, multiplying the value of our investment and increasing its impact. By partnering with researchers around the globe, we can hasten progress. Together, we can someday achieve a world without disease.\nA version of this article, Imagine a disease-free world, was originally published as part of Research!America's Public Health Thank You Day campaign.\nTo view Adobe PDF files,\ndownload current, free accessible plug-ins from Adobe's website.","An allergy is a reaction of your immune system to something that does not bother most other people. People who have allergies often are sensitive to more than one thing. Substances that often cause reactions include pollen, dust mites, mold spores, pet dander, food, insect stings, medicines.\nHow do you get allergies? Scientists think both genes and the environment have something to do with it. Normally, your immune system fights germs. It is your body's defense system. In most allergic reactions, however, it is responding to a false alarm.\nAllergies can cause a runny nose, sneezing, itching, rashes, swelling or asthma. Symptoms vary. Although allergies can make you feel bad, they usually won't kill you. However, a severe reaction called anaphylaxis is life-threatening.\nNote: This topic was prepared to help consumers find reliable health resources on the web. This site is not responsible for the information on other sites. The information here — and on all websites — is not intended to be a substitute for care given to you by a health professional.\n- Asthma and Allergy Foundation of America\n- Includes fact sheets that you can print out on various topics related to allergies, asthma and immunology.\n- American College of Allergy, Asthma and Immunology\n- Check out this site for information on various allergies, interactive quizzes and finding an allergist.\nAllergies and Children\n- Children and Allergies\n- This link from the American College of Allergy, Asthma and Immunology website covers common symptoms, allergies at school, food allergies and more.\n- Asthma and Allergies in Children\n- This link takes you to the American Academy of Pediatrics website where you can search for information on common allergy triggers and ways to reduce them.\n- Information About Food Allergies\n- This link on the U.S. Food and Drug Administration website offers the latest news on food allergies from the FDA.\n- About Food Allergies\n- Food Allergy Research and Education (FARE) is a group that promotes awareness of food allergies and anaphylaxis. This website has answers to many common questions.\n- Allergies and Food Sensitivities\n- This link from the Food and Nutrition Information Center offers articles, cookbooks and resources for both adults and children.\n- Allergy Information, National Jewish Health\n- Information about common allergies is available from a major medical center in Denver.\n- Mayo Clinic Allergy Center\n- This website offers a wealth of information, from basics about allergies to treatment options and living with allergies.\n- National Institute of Allergy and Infectious Diseases\n- This website offers a broad range of information on food allergies. NIAID is one of the National Institutes of Health.\n- Asthma, HealthInfoSource.com\n- This health topic on HealthInfoSource.com offers a collection of links to more information about asthma.\n- What's Today's Pollen Count?\n- Visit this site and enter a ZIP code for a report on the pollen index in Fort Collins or other locations in the United States.\n- Poudre River Public Library District\n- Search the library collection for books about allergies, or use the library's health, sciences and technology databases.\n- Best Health Sites\n- This collection of web links, organized by site type, will help you find the health information you're looking for."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:59b0f79a-3d64-444d-ad22-090a76f93fb1>","<urn:uuid:5deb03ce-f99f-496a-8a84-5f8dc8ad9a47>"],"error":null}
{"question":"I'm researching industrial inspection methods. How do metallographic examination and ultrasonic testing differ in their ability to detect internal material defects?","answer":"Metallographic examination and ultrasonic testing (UT) approach internal defect detection differently. Metallographic examination is a process that involves preparing and examining samples under a microscope to analyze the internal structure of metallic materials, allowing researchers to identify defects, study grain size, and determine phase composition. In contrast, ultrasonic testing uses sound waves to provide a view into a component's interior without sample preparation. UT involves moving a probe over the surface of a component and tracking ultrasonic wave reflections on a screen. UT is particularly effective for detecting both flat and voluminous imperfections and can be superior to other methods for surface imperfections. While both methods can detect internal defects, UT has the advantage of being non-destructive and can be performed on intact components, while metallographic examination provides more detailed microstructural information.","context":["Unveiling the Secrets of Materials: The Multiple Uses of Metallographic ExaminationD\nIn the realm of material science and engineering, understanding the microstructure of metals is crucial for ensuring product quality, enhancing performance, and solving failure-related issues. One of the most powerful techniques employed to analyze the internal structure of metallic materials is metallographic examination. This non-destructive process involves preparing, examining, and analyzing samples under a microscope. Through metallographic examination, researchers, engineers, and scientists gain valuable insights into a material's composition, defects, and properties. This article explores the various uses of metallographic examination in different industries and applications.\n- Material Characterization:\nMetallographic examination plays a fundamental role in characterizing the properties and structure of metallic materials. By analyzing the microstructure, scientists can determine grain size, phase composition, and distribution. This data is crucial for understanding the mechanical and thermal behavior of metals, leading to the selection of appropriate materials for specific applications.\n- Quality Control:\nIn industries where the performance and reliability of products are paramount, metallographic examination is an indispensable quality control tool. By inspecting samples for defects, cracks, inclusions, or other irregularities, manufacturers can identify and rectify potential issues before the products reach the market. This process ensures that materials meet required standards and specifications, reducing the risk of failures and recalls.\n- Failure Analysis:\nWhen a material or component fails unexpectedly, metallographic examination is often the first step in root cause analysis. By examining the fracture surface and surrounding microstructure, engineers can determine the cause of failure, such as fatigue, corrosion, or improper processing. Understanding failure mechanisms helps in designing more robust materials and preventing future failures.\n- Process Optimization:\nMetallographic examination aids in optimizing manufacturing processes. By studying the microstructural changes resulting from different processing techniques, engineers can fine-tune manufacturing parameters to achieve desired material properties. This is particularly crucial in industries like aerospace and automotive, where even small improvements can have a significant impact on performance and efficiency.\n- Weld Assessment:\nIn welding processes, metallographic examination helps assess the quality of welds. By analyzing the weld interface and heat-affected zone, engineers can identify potential defects like porosity, inclusions, or cracks. This information ensures that welded joints meet the required standards and are suitable for critical applications.\n- Phase Transformation Studies:\nCertain metals and alloys undergo phase transformations during processing or operation. Metallographic examination enables researchers to study these phase changes, which have a profound impact on material properties. Understanding these transformations helps in designing materials with specific characteristics, such as shape memory alloys or superalloys.\n- Research and Development:\nMetallography serves as a powerful tool in materials research and development. Scientists can examine the effect of different alloying elements, heat treatments, and processing techniques on a material's microstructure and properties. This knowledge contributes to the discovery of novel materials with enhanced properties for advanced applications.\nMetallographic examination is a versatile technique that finds application in various fields, from quality control and failure analysis to research and development. By providing valuable insights into the microstructure of metallic materials, this technique helps engineers and scientists make informed decisions, leading to improved product performance and reliability. As technology advances, metallography continues to evolve, offering new possibilities and contributing to the advancement of materials science and engineering.","Non-destructive testing (NDT) is an examination of components or workpieces for their quality and structure that does not damage or impair them. It is regulated in the international standard DIN EN ISO 9712 and is used in various industrial sectors such as plant engineering, mechanical engineering, steel, power plant or vehicle construction.\nNDT is subject to a strict certification process to prevent personal injury and damage to property. In this context, one also talks about finding and evaluating so-called discontinuities or imperfections, since the actual assessment of whether a defect is present is subject to the testing regulations.\nWhat types of non-destructive testing exist?\nThe 5 most important types of NDT are the following, they differ in the tools used and the evaluation e.g. imaging techniques.\n- VT – Visual Testing\n- MT – Magnetic Particle Testing\n- PT – Penetrant Testing\n- UT – Ultrasonic Testing\n- RT/DR – Radiographic Testing and Digital Radioscopy\nOther types are for example eddy current testing (ET), leak testing (LT), acoustic emission testing (AT) or thermographic testing (TT).\nVT - Visual Testing\nVisual Testing (VT) is an optical method to check objects for discrepancies. You can check with the naked eye as well as with tools like magnifying glasses or mirrors.\nMany imperfections, such as external cracks, can already be found with visual testing, which makes this type of inspection a simple but powerful procedure. It can be used to check some imperfections of welds, fractured surfaces, corrosion phenomena or grinding.\nMT - Magnetic Particle Testing\nMagnetic particle testing (MT) is a method for testing magnetizable materials with a minimum of time. Magnetic particles are applied to the object to be tested with a liquid or powder. Inconsistencies are then revealed by a change in the magnetic field, which causes the particles to be aligned differently from the ‘good’ part of the object.\nIn this way cracks or inclusions of non-magnetic materials can be quickly detected. Especially remarkable is the detection of small cracks with a width of 0.001 mm and a depth of 0.01 mm. For comparison: a human hair has a thickness of 0.04 mm or more.\nPT - Penetrant Testing\nPenetrant testing (PT) is a flexible procedure that uses the capillary forces of cracks or pores. For this purpose, color or fluorescent penetrant (contraster) is applied to a cleaned component, e.g. with a spray can, followed by a ‘developer’. The penetrant then ‘creeps’ into the smallest cracks and reveals the imperfections. Important for the handling of the substances are environmental aspects, storage, disposal and correct transport. For dye penetrant testing, the colors red and white (contraster-developer) are usually used. Care should be taken with rough or brittle surfaces, as this can lead to so-called false readings, or with the color intensity, as these do not necessarily indicate the depth of a crack.\nUT - Ultrasonic Testing\nUltrasonic testing (UT) allows a view into the inside of a component. To do this, a probe is moved over the surface of a component and the ultrasonic waves emitted by it or their reflections are tracked on a screen. A phased-array imaging test can also be performed, which allows easier interpretation. Both flat and voluminous imperfections can be inspected. In the case of surface imperfections, it is often superior to radiographic testing (RT). It is used, for example, for wall thickness measurement with vertical probes and for simple geometries with angle probes.\nRT/DR - Radiographic Testing and Digital Radiography\nRadiographic testing (RT) refers to an imaging test method that allows a view into the inside of a component. Depending on the component and size, an X-ray tube or radioactive material is used to irradiate a film. One advantage of this method compared to ultrasonic testing is that the type of imperfections, e.g. whether pore or slag, can be determined more easily. Since the handling of the preparations is subject to special safety regulations, the recording is often carried out by service providers. An evaluation of the imperfections can then be carried out separately. Digital Radiography (DR) using X-ray image intensifiers or radioscopy systems is becoming increasingly popular because images can be stored and evaluated digitally.\nWhich products/sectors are tested?\nThe most frequently tested components and products are:\n- Castings – Pc\n- Forgings – Pf\n- Welded products – Pw\n- Pipes and piping – Pt\n- Rolled products – Pwp\nA test can be carried out both during production and in the factory. Depending on the regulations and safety requirements for a component. The products and sectors are regulated in DIN EN ISO 9712 and also include some industrial sectors:\n- Production – In\n- Service inspection in production and maintenance – Is\n- Railway maintenance – Ir\n- Aerospace – Ia\nand Thermographic Techniques:\n- Active Thermography – TA\n- Passive thermography – TP\n- Active and passive thermography – TAP\nWho may perform non-destructive testing?\nStandard-compliant testing requires a certified inspector who, depending on experience and training, has achieved one of the following three levels in the respective test type (VT, MT, PT, UT, RT).\n- Level 1: May perform test procedures and record the test results\n- Level 2: May additionally evaluate test results according to standards and regulations\n- Level 3: May additionally select test procedures, prepare procedure descriptions and is responsible for test facility\nThe test personnel must have good near vision and color vision. There are also rules of professional ethics which are intended to prevent personal injury and damage to property.\nVarious certification bodies such as TÜV NORD or the independent personnel certification body (DPZ) of the American Society for Nondestructive Testing (ASNT) or German Society for Non-Destructive Testing (DGZfP) issue certificates after a successful examination of the candidate. They themselves require confirmation from the German Accreditation Body (DAkkS) in order to be allowed to certify personnel in accordance with DIN EN ISO/IEC 17024:2012. The international standard DIN EN ISO 9712 requires that certificates must be renewed or recertified every 5 years.\nHow to reach a higher level?\nWhat should you know about welds?\nHow can evaluation be performed digitally?\nDigital radioscopy (DR) and working with imaging plates is becoming increasingly popular, but other imaging techniques such as Phased Array (UT) also offer image material that can be digitally evaluated. To save time and nerves during examination and evaluation, the right tool should be used. Often an interpretation of anomalies is also not clear, so one asks a colleague for advice. The sentin EXPLORER facilitates the evaluation by automatically analyzing and marking of imperfections."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:5a8c76f1-2624-44cd-81c0-8709eca4da44>","<urn:uuid:fdbb9905-374f-4627-a46c-15557a0e223f>"],"error":null}
{"question":"What recommendations exist for managing cognitive performance at suboptimal times, whether you're a morning person doing evening work or a night shift worker trying to stay alert?","answer":"For cognitive performance management during suboptimal times, different strategies are recommended based on the situation. For typical day workers, research suggests strategically planning tasks - saving creative or 'diffuse thinking' work for non-peak hours (evening for morning people, morning for night owls) since being less focused can actually enhance innovative problem-solving. For night shift workers, several specific practices are recommended to maintain alertness and manage sleep: establishing consistent bedtime routines, reducing caffeine intake at least 4 hours before sleep, wearing sunglasses on the way home to reduce light exposure, and creating a sleep-conducive environment that's dark, cool, and quiet. Additionally, night shift workers should go straight to bed after work and may need medical interventions like melatonin, wakefulness medications, or prescription sleep aids if behavioral techniques aren't sufficient.","context":["If you’re a morning person, who jumps out of bed ready to take on the day but feels sluggish by the time afternoon or evening hits, you might think you should do your most creative work at the beginning of the day, when you’re fresh. Likewise, if you’re a night owl, and feel barely awake until mid-afternoon, it’s logical that you’d save your most creative work until late at night.\nBut a new research study by Mareike Wieth of Albion College and Rose Sacks of Michigan State University finds otherwise (hat tip to the folks over at PsyBlog). The researchers asked 428 students to tackle six problem-solving tasks at different times of day. Those who identified themselves as morning persons actually did better on “insight”-based problem solving—tasks that required original thinking—in the evening. Night owls’ performance was the opposite, with more of their “aha!” moments coming earlier in the day.\nWieth and Sacks hypothesized this would happen, because a key aspect of solving “insight” problems is being able to overcome an impasse in your head. To come up with an original idea or novel solution, in other words, we must be able to approach it from a different perspective. During our “non-optimal” times of day, we’re more influenced by distracting information, and are less blinded by an initial solution that, when we’re more clear-headed, might seem obvious but turns out to be wrong.\nIn other words, when our brains are “on,” “we’re really good at screening out what we think is irrelevant, and we really get focused on one thing,” says Wieth. “That’s great if you’re doing a task where you have to concentrate, but for creativity that’s probably not the best thing. We get stuck on one way and don’t think of other ways to resolve it.”\nThat’s not to say that some problems aren’t better solved at our best times of day. Much research, the authors note, has shown that we’re better at concentrating and solving unfamiliar tasks when we’re most “on.” And while Wieth and Sacks do raise the point that their participants were mostly night owls, their results are still worth considering when it comes to productivity and time management. Countless time-management gurus counsel people to tackle their most pressing deadlines first thing in the morning, before they’re interrupted by meetings and phone calls. But if you’re a morning person and your most important job of the day is to come up with a new marketing slogan or dream up a completely new solution to a problem that everyone in your office has already tried to solve, it might actually be better saved until later in the day.\nIn other words, the best way to manage your time isn’t so much by making yourself do the most pressing thing first, but by figuring out what kind of task it is and then picking the best time to do it. “Is it diffuse thinking or constrained thinking?” Wieth says, as a good rule of thumb. If it’s the former, do it when you’re not as fresh, and if it’s the latter, pick the time when you’re really on.\nMore from On Leadership:\nLike On Leadership? Follow us on Facebook and Twitter:","How You Can Sleep Better If You Work the Night Shift\nIf you work a non-traditional shift like the night shift or rotating shifts, you may be missing out on more than daylight and watching your kids’ soccer games. You could be missing out on sleep and better health. Advertising Policy Cleveland Clinic is a non-profit academic medical center. Advertising on our site helps support our … Read More\nIf you work a non-traditional shift like the night shift or rotating shifts, you may be missing out on more than daylight and watching your kids’ soccer games. You could be missing out on sleep and better health.\n“Working non-traditional shifts interferes with the body’s circadian rhythms,” says sleep expert Tina Waters, MD. “Most of us are awake during the day because our body’s internal clock is keeping us awake. So no matter how tired you are after working all night, your awakening signals will conflict with your desire to sleep.”\nFortunately, there are some lifestyle changes that can help. But first, let’s look at the problems this disorder can cause.\nWhy shift work sleep disorder can be hazardous to your health\nStudies have shown that lack of sleep can lead to other health issues. Some people develop gastrointestinal distress or metabolic disorders, such as diabetes. Others may develop heart disease.\n“There was also a large study done on nurses who worked the night shift in which they were found to have a higher prevalence of infertility and even cancer,” Dr. Waters says.\nFrom a non-health perspective, working alternate shifts can make it difficult to lead a balanced life. “If you’re a spouse or a parent, there are things going on during the time you need to be sleeping,” Dr. Waters says.\nIf you’re having trouble sleeping and you think this disorder could be the culprit, expect your doctor to first run some tests to rule out other underlying sleep disorders, such as sleep apnea or narcolepsy.\n“It’s also a good idea to keep a sleep diary of which shifts you worked and what hours you slept,” says Dr. Waters. A sleep diary can help your doctor identify the problem and monitor its progression over time.\nWhat you can do to get a good ‘night’s’ sleep\nPractice good sleep hygiene. If you’re diagnosed with shift work sleep disorder, one of the most important things you can do to make sure you are getting enough sleep is to practice ‘good sleep hygiene.’ which includes:\nEstablishing a regular bedtime routine and sticking to it\nMaking your environment conducive to sleep (e.g., keeping your bedroom dark, cool and quiet)\nGo straight to bed after work. Dr. Waters also recommends going home and sleeping as soon as your shift is over. “One of the triggers that keeps people awake is light, so it helps to decrease your light exposure at least 30 minutes before trying to sleep,” she says. “One way you can do that is to wear sunglasses on your way home, even on a cloudy day.”\nCut back on caffeine. Another thing you can do to help you get a better ‘night’s’ sleep is to reduce your caffeine intake. “If you’re drinking caffeine to stay awake, try not to drink any within four hours of the end of your shift to give your body time to metabolize it,” Dr. Waters says.\nSet boundaries. It’s also a good idea to let people know what hours you’re working and when you will be sleeping, so they know when to leave you alone.\nGet help from your doctor if you need it. If behavioral techniques aren’t helping you sleep, your doctor may prescribe melatonin to induce sleep, medications to promote wakefulness, or prescription sleep aids."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:1796bd23-2b80-46ad-84cd-070cefbbde66>","<urn:uuid:fff09103-9383-47b0-990b-9472a8be1e5f>"],"error":null}
{"question":"What are the key differences between wildlife viewing opportunities in Svalbard, Norway and the cultural heritage sites in Mavrovo National Park?","answer":"In Svalbard, Norway, wildlife viewing focuses primarily on Arctic species with a guaranteed chance to see polar bears (with a population of 3000), along with arctic foxes, seals, and walruses. In contrast, Mavrovo National Park's attractions are centered on cultural heritage, featuring archaeological locations from the late classical to medieval periods, sacral monuments including both Christian and Islamic buildings, and traditional architecture in rural settlements. While Svalbard emphasizes natural wildlife encounters, Mavrovo's significance lies in its cultural artifacts, traditional crafts, and architectural achievements that reflect the region's complex cultural identity.","context":["General Information on Cultural Heritage\nThe significant number of locations, registered on the territory of Mavrovo National Park contributes to the continuous development of an organized way of living. The chronological limits of recorded archaeological locations encompass a period from late classical period until the late medieval period. However, the biggest concentration of archaeological locations belongs to the medieval period and offers valuable data on the quality of life of the medieval population on this territory.\nThe importance of the archaeological artifacts and the more representative field findings impose the need of creating permanent forms and types of their presentation for the purpose of cultural affirmation of the region. Archaeological heritage, as a basic component of the cultural identity of the region, should be treated as one of the most important segments in planning of future project activities.\nThe cultural heritage of Mavrovo National Park, which is represented by sacral monuments, reflects the most important dimensions of the local population’s creative contribution in shaping the cultural identity of the area, rich in representative objects and marked with high achievements and realizations of art. The parallel existence of the Christian and Islamic sacral buildings, which suitably contribute to the architectural and artistic traditions cherished throughout the centuries, witnesses about the creative cohabitation of different cultures, united in their creative existence today. Marked with the skill of the craftsmen – builders, and enriched with the magnificent vividness of the decorative components, they are real representatives of specific dimensions and features of the complex cultural identity of the region.\nIn the line of the oldest sacral objects is the most representative monument of the architectural and artistic heritage of the region, the monastery complex Saint Jovan Bigorski (St. John the Forerunner Bigorski Monastery). Inheriting the religious values of the old location of worship from the 11th century, and built on the foundations of older, medieval buildings, the monastery, which was restored starting from the end of the 18th and in the first decades of the 19th century, represents a compact architectural unity which is a real example of this area’s cultural identity with its building and art qualities.\nAlso, the church dedicated to the Saint Apostles Peter and Paul in the village of Tresonche deserves a special place, and represents a location of exceptional importance for realizing the traditional values of the regional cultural environment. The basilica with three-nave disposition (mid-19th century), with an additionally built open porch, is extraordinarily related to the morphology of the ground, creating exciting and impressive unity with the picturesque area.\nNonexistence of appropriate marking of sacral objects, which would point the way to their location, is one of the reasons for making it difficult to find them and arrive at particular locations.\nCompared to the relatively large concentration of Christian sacral objects, the cultural heritage related to the Islamic monuments shows drastically more reduced range. Unfortunately, in the archive documentation of the Republic Institute for Protection of Monuments of Culture, there is only scarce information about them, which, together with the lack of appropriate research treatment and nonexistence of relevant expert literature, disables their evaluation in the context of general contribution to the Islamic heritage for the region’s cultural image.\nProfane Objects and Traditional Architecture\nThe profane objects include part of the region’s cultural heritage which is significant in its size and important in its meaning. They reflect the specific forms of living from the past and also reflect the complex picture of various factors that have influenced the manner of creating the architectural look of the urban and the rural areas of this territory. The richness of the preserved fund and the specific forms of profane buildings and objects of traditional architecture contribute to the characteristic presentation of the building traditions, cherished during the 19th century.\nThe structure of the rural settlements which are on the territory of Mavrovo National Park shows various characteristics, originating from the field configuration, the climate features of the region, and the manner or organization of life. In addition, the region mainly has compact and semi-compact rural settlements, while the villages of dispersed type can be rarely seen. The fact that majority of the villages represent mountain settlements, points out the appropriate way of their organization as rural units, with architectural profile defined by the elements of chronological development of construction buildings, whose lower limit can be placed in the first half of the 19th century. Not neglecting the conclusion that the architectural look of the villages in the region has gone through particular changes, still, a certain number of settlements has preserved its original structure, which reflects the functional and esthetic value of the local building specifics. It mostly refers to the villages in the area of Dolna Reka and in the region of Mala Reka, whose architectural features are achievements of the craftsmen from the local builders’ guilds. Located in the picturesque area with dynamic natural qualities, these rural settlements represent exceptional examples of the traditional masonry, characterized with the values of the local cultural matrix.\nIn this context, we could mention the village of Bitushe, located in the area of Dolna Reka; the village of Rosoki in Mala Reka; the neighboring village of Selce; the village of Tresonche in Mala Reka that offers a slightly different image of the organization of housing units and possesses different and unique urban setting compared to the villages of this region as a mountain settlement of dispersed type; the village of Galichnik which, with its rural structure, represents organic unity of several ensembles – separate neighborhoods, connected in a unique architectural unity with the remarkably fitted architectural look of the old houses, related to the dramatic landscape environment. Among the rural settlements, characterized with an extraordinary vividness of the architectural look, we could mention the villages of Lazaropole, Gari and Janche, perfectly fitting into the authentic mountain landscape.\nTraditional Crafts and Skills\nThe development of crafts, the quality of the craftsmen’s production and the features of the traditional manufacturing are significant part of the cultural existence of Mavrovo National Park, which reflects the local population’s specific way of living and contributes to the maintenance and cherishing the genuine elements of the ethno-cultural stratigraphy of the area. Appearance of certain crafts and development of skills was related to the specific organization of life in different settlements, and has taken place in close correlation with the local characteristics of the region, resulting in extensive picture of craftsmen activities and rich production of traditional forms of local manufacturing. Change in lifestyle conditions, modern life dynamics and introduction of new production means and technologies that simplify and accelerate the process of making, have made a contribution for the large part of registered crafts to be altered, some of which even to disappear completely, and others have been integrated in the manufacturing and industrial production.\nIt can be concluded that it is a fact that majority of traditional crafts have completely disappeared, and have given their place to the modern industrial production.\nCertain continuation can be observed only in the development of particular crafts techniques (cooperage, carpentry, goldsmith or silversmith craft), whose production shows quite a reduced scope and limited product sales.\nRegarding the traditional skills, which used to be cherished as specific forms of traditional production, today we can register: weaving, embroidery, carpet making, and woodcarving, which, although “modernized” in terms of the modern materials and raw materials used, have retained the traditional characteristics of making. In that context, the first one that should be mentioned is the making of traditional folk costumes, which show exceptional vividness of the decorative elements and colorful variety.\nIt can be concluded that the rich fund of authentically preserved folk costume, as well as the representative scope of its continuous production, are a solid base for planning more organized ways for its presentation in form of ethnographic collections of special character, which would popularize this, in many of its characteristics, most representative traditional skill in the municipality.\nThe possibility of using this skill in the production of souvenirs with the traditional features of the folk costume could be utilized for different kinds of activities in the context of affirmation and popularization of the ethnological heritage, within the organized tourist offer.\nWeaving of various types of fabrics, especially wool processing in the traditional way from the past, also represents one of the registered skills, which are still being maintained in the modern rural conditions of the settlements in the region, although in a very reduced scope. The existence of traditional looms, registered in some of the villages of Reka region, still enables production of woolen handiwork of considerable quality, representing constituent part of the interior home decoration.\nAdequately planned activities for designing, production and distribution of these products would enable their suitable sale on the wider market and would provide affirmation to part of the traditional production in this region. From the aspect of the possibility for using the traditional skills in the planned activities for development of cultural heritage tourism, the woolen handiworks could become an integral part of the interior design of the accommodation facilities, reflecting the appropriate relationship with the traditional values of the characteristic local environment.\nLocal Customs and Folk Tradition\nOne of the components for shaping the general cultural image of the region is the existence, maintenance and treatment of the living heritage, which contains the various segments of the local myths, spoken traditions, ancient legends, rituals, seasonal rites and customs related to wedding and funeral ceremonies and religious holidays. Condensing in itself the extract of the folk beliefs throughout the centuries, these elements reflect the specific “myth” of the local population, embedded in the sociological concept of modern living. Cherishing the living heritage, which commemorates the ancient forms of folk traditions through the contemporary practice of worship, represents one of the important features of the cultural identity of this region, reflecting the various dimensions of its ethno-cultural stratigraphy.\nIn the existing literature, both expert and popular one, there is a rich fund of information on the folk tradition of the region whose richness and variety have been subject to admiration of travel writers and chroniclers, and have become part of the research of many historians and ethnologists. Originating from the religious music heritage, which in certain areas (Mijak region) it has ancient chronology and reaches the medieval period, the folk existence of this region has developed in several types of traditional singing, whose sounds have been kept as a music tone of the contemporary folk events. Exceptionally inspirational shepherd, wedding, and migrant workers’ songs, love lyric poetry and rite melodies, as well as the instrumental matrix for folk dances, represent valuable relic from the remote past time of folk tradition. However, as a result of the disappearance of the folk groups and fading away of traditional folk events, the characteristic music heritage of the region lives through a more compact form of performance during the period of seasonal rites and days of religious holidays.\nThe event that could best define the genuine forms of traditional customs in the region, and the devoted care for their continuous maintenance, is the magnificent ritual of the Galichnik Wedding Festival (Galichka svadba), which every year, on the religious holiday St. Peter, takes place as a ceremony of national character.\nRevitalization of the events from the old customs and their wider affirmation, as well as reanimation of the rich folk tradition, in the context of more organized forms of presentation, would contribute to permanent preservation of the traditional qualities of the ethnological treasury in particular kinds of cultural presentation in public.","For those who love nature and dream of watching mammals or birds in their natural habitat, it’s better to go to one of the many national parks for impressions, the benefit is huge. Just keep in mind that wildlife is unpredictable, and animals try to avoid contact with people, so in most reserves, it is almost impossible to meet an animal larger and more interesting than a squirrel.\nTo help you avoid disappointment at the failed meeting, we have compiled a list of places where you can certainly see the most interesting representatives of the fauna – from a tiny lemur the size of a finger to a giant blue whale.\n1. Kalimantan, Indonesia\nOrangutans, monkeys, deer, clouded leopard, 230 different bird species, crocodiles and many reptiles inhabit the Indonesian part of the island in the Tanjung Puting National Park. In the northern part of the park in Camp Face, a scientific base for the study and protection of orangutans, in conditions as close as possible to the natural, there are several dozen individuals of these animals. The animals move freely around the base, and almost the entire population can be immediately seen during the daily feeding.\n2. Masai Mara, Kenya\nOne of the most spectacular sights on the planet – the great migration of animals can be seen in the Masai Mara National Park in Kenya. From August to October, thousands of herds of zebras, antelopes, and gazelles in search of green pastures across the ford of the dangerous Mara River.\n3. Bwindi Forest, Uganda\nBwindi Forest is a unique eco-system that is home to many birds, reptiles, insects and mammals. The main inhabitants of this jungle are mountain gorillas, the closest relatives of a person. Look at the gorillas from a short distance (up to five meters) is possible only during the tracking tour. To participate in the tour, it is desirable to have at least the average physical form; walking over rough terrain will have a lot.\n4. Azores, Portugal\nIn the coastal waters of the Azores, there are more than 20 different species of cetaceans. If dolphins and bottlenose dolphins live here permanently, then most of the whales swim to the Azores during migration. In the spring and at the end of winter off the coast you can see a blue whale, and in the summer you will almost certainly meet a seyval whale. Most of the offices that organize whale tours are located on the islands of Pico, Faial, and Terceira.\n5. Galapagos Islands, Ecuador\nGalapagos is primarily unique in that the majority of animals living here are endemics, i.e. they are not found anywhere else in the world. It was the diverse and unique fauna of these islands that inspired Charles Darwin to write his famous work, The Origin of Species. Amazing sea iguanas, fur seals, blue-footed boobies, Galapagos penguins, and, of course, a giant ivory turtle – a long-lived champion among mammals (the average life expectancy is 150 years).\n6. Svalbard, Norway\nSvalbard (in Norwegian Svalbard) is an archipelago located in the Arctic Ocean and the northernmost part of Europe. Despite the distance from civilization and harsh conditions, tourism is very well developed here. The capital of the archipelago, the city of Longyearbyen – the main starting point for expeditions to the North Pole and less extreme tours along the coast or deep into the archipelago. Most of Svalbard is a huge nature reserve, where you can meet arctic foxes, seals, walruses and, of course, polar bears. To date, the size of the population of bears on Svalbard is about 3000, i.e. there are literally more of them than people, so meeting at least one of them is almost guaranteed.\n7. Everglades, USA\nThe Everglades Nature Reserve is located in the marshland less than 100 kilometers from the bustling Miami. Most of the park is an “absolutely wilderness zone”, i.e. there are no buildings and there is no economic activity. The reserve is equipped with convenient walking routes that allow you to observe a variety of birds and small mammals. Rivers, marshes and channels of the Everglades, which are literally teeming with crocodiles and alligators, conduct special excursions on the airboat (boat with a propeller).\n8. Isla Mujeres, Mexico\nOne of the best places for swimming with whale sharks is water near the island of Isla Mujeres in Mexico. The whale shark is the largest fish in the world, reaching 20 meters in length. They eat plankton and are absolutely safe for humans, so you can get close to them and even touch them. The migration routes of the whale shark pass along the shores of Mexico from May to September.\nOn this African island, there are about a hundred of various species of lemurs — animals that are not found anywhere else in the world, from a 30-gram dwarf lemur to a 10-kilogram ring-tailed lemur. Keep in mind that some species of these cute animals can only be observed during the night tour (they sleep during the day). In addition to lemurs in Madagascar, you can see Madagascar chameleons, several species of turtles and lizards, and a few island predators, foss and wyvern.\n10. Yellowstone, USA\nYellowstone is the largest national park in America and one of the largest in the world. The fauna of the Yellowstone Park is represented by predators (including large ones), diverse artiodactyls, rodents, birds and reptiles. And if it is absolutely impossible to see rare animals like wolves, lynxes or cougars near tourist paths, then a meeting with a herd of wild buffalo is almost guaranteed even during a short excursion. Also recently, coyotes have been increasingly seen here, sometimes even near tourist areas."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:c541c5ef-4d5c-4e94-8e4c-41196ab2e9dd>","<urn:uuid:5c0882c7-fa18-4851-98a1-894074f543a5>"],"error":null}
{"question":"What is the relationship between critical reading and prison narratives, and how do they both address the concept of questioning authority?","answer":"Critical reading involves questioning what an author presents rather than accepting it at face value, similar to how prison narratives often explore challenging authority structures. In Shawshank, Andy Dufresne questions and ultimately undermines the corrupt prison system, particularly Warden Norton's money laundering scheme, by gathering evidence and planning his escape. This parallels the critical reading process, which requires asking questions while reading, evaluating evidence and methodology, and considering alternative possibilities. Both processes emphasize the importance of not accepting presented information or authority without examination and validation.","context":["Written and Directed By: Frank Darabont Run Time:\nEdit Inbanker Andy Dufresne Tim Robbins is convicted of murdering his wife and her lover at his house, and sentenced to two consecutive life sentences at Shawshank State Penitentiary.\nAndy quickly befriends contraband smuggler Ellis \"Red\" Redding Morgan Freemanan inmate serving a life sentence. Red procures a rock hammer for Andy, allowing him to create small stone chess pieces. Red later gets him a large poster of Rita Hayworth, followed in later years by images of Marilyn Monroe and Raquel Welch.\nAndy works in the prison laundry, but is regularly assaulted by the \"bull queer\" gang \"the Sisters\" and their leader, Bogs Mark Rolston.\nInAndy overhears the brutal chief guard Byron Hadley Clancy Brown complaining about taxes on a forthcoming inheritance and informs him about a financial loophole.\nAfter another vicious assault by the Sisters nearly kills Andy, Hadley severely beats Bogs resulting in Bogs being sent to another prison.\nAndy is not attacked again. Warden Samuel Norton Bob Gunton meets with Andy and reassigns him to the prison library to assist elderly inmate Brooks Hatlen James Whitmorea pretext for Andy to manage financial duties for the prison. His advice and expertise are soon sought by other guards at Shawshank and from nearby prisons.\nAndy begins writing weekly letters to the state government for funds to improve the decrepit library. InBrooks is freed on parole, but unable to adjust to the outside world after 50 years in prison, he hangs himself.\nAndy receives a library donation that includes a recording of The Marriage of Figaro.\nHe plays an excerpt over the public address system, resulting in his receiving solitary confinement. After his release, Andy explains that he holds onto hope as something that the prison cannot take from him, but Red dismisses the idea.\nInNorton begins exploiting prison labor for public works, profiting by undercutting skilled labor costs and receiving kickbacks. He has Andy launder the money using the alias \"Randall Stephens\".\nInTommy Williams Gil Bellows is incarcerated for burglary. Inafter hearing the details of Andy's case, Tommy reveals that an inmate at another prison claimed responsibility for an identical murder, suggesting Andy's innocence. Andy approaches Norton with this information, but the warden refuses to listen.\nNorton places Andy in solitary confinement and has Hadley murder Tommy, under the guise of an escape attempt. Andy refuses to continue with the scam, but Norton threatens to destroy the library and take away his protection and preferential treatment. After Andy is released from solitary confinement, he tells Red of his dream of living in Zihuatanejo, a Mexican Pacific coastal town.\nWhile Red shrugs it off as being unrealistic, Andy instructs him, should he ever be freed, to visit a specific hayfield near Buxton to retrieve a package.\nThe next day at roll call, upon finding Andy's cell empty, an irate Norton throws one of Andy's rocks at the poster of Raquel Welch hanging on the wall. The rock tears through the poster, revealing a tunnel that Andy had dug with his rock hammer over the previous two decades.\nThe previous night, Andy escaped through the tunnel and the prison's sewage pipe with Norton's ledger, containing details of the money laundering.The Shawshank Redemption () - Frank Darabont. See more What others are saying \"The shawshank redemption hope essays In the film \"The Shawshank Redemption\" the prevalent theme seemed to be the effect of hope in bleak circumstances.\nThe Shawshank Redemption Watch Trailer After the murder of his wife, hotshot banker Andrew Dufresne is sent to Shawshank Prison, where the usual unpleasantness occurs. Frank Darabont's film \"The Shawshank Redemption\" () is a deep meaningful representation of friendship within a prison.\nIt shows us how hope can be encountered in a dark and deceitful place, how both literal and figurative walls trap Andy. To the end, Darabont uses symbolism in his description of setting, in his use of camera angles and lighting. Film title: The Shawshank Redemption Keywords: Hope, despair, freedom, imprisonment, salvation Tagline(s): Fear can hold you prisoner.\nHope can set you free. Director: Frank Darabont Screenplay: Frank Darabont, based on 'Rita Hayworth and Shawshank Redemption', a short story by Stephen King. 'Shawshank' Secrets Revealed: Frank Darabont, Tim Robbins and Morgan Freeman Reveal All at 20th Anniversary Screening.\nAnd Frank Darabont, an unknown director of television movies and a writer of horror sequels, was making his feature film debut with a prison movie based on an obscure novella by Stephen King, the literary horror master who wasn’t.\nAs a director, he is known for his film adaptations of Stephen King novellas and novels such as The Shawshank Redemption, The Green Mile, and The Mist. Frank Darabont Darabont at .","Critical analysis involves the ability to evaluate an author’s work, whether it is an article, a book, a movie,or some other product. Ultimately, the purpose of critical analysis is to engage with a text instead of simply reading it over and accepting everything it says without questioning. This will facilitate a better understanding of the material, as well as lead to more interesting and meaningful observations about the topic.\nA critique is the written analysis of the subject. Critical analysis skills are needed to write an effective critique, but it is also necessary to be able to communicate the analysis to a reader in a clear, effective way.\nCritical reading is the ability to read a text without automatically accepting everything it says. In other words, it means questioning what an author has to say about a topic. In order to read critically, it is essential to ask questions while reading, not only afterwards.\nWhile reading a text, consider the following points:\nIdentify the author’s thesis (central argument of the text).\nEvaluate how the author has attempted to prove his or her thesis (has he or she used facts,\nstatistics, anecdotes, theoretical research, etc.?). Is this support adequate to prove the thesis?\nIdentify why the study is important or interesting. What new insights or applications does it add to the field of research?\nConsider the theoretical framework that the paper is built on. What are the theoretical implications of this paper in regards to the field of study? Do the author’s findings support thetheoretical conclusions that the author makes? Are there differences between the way that the author uses the theory and the way in which other researchers interpret it?\nObserve whether or not the author has provided alternative possibilities, theories, or evidence. If so, has he or she explained why they are less useful or applicable than the one presented? Has the author justified his or her choice of theory or methodology?\nDecide whether or not you agree with the author’s argument or findings. Based on yourknowledge of the subject and theory, do you agree with the author’s conclusions?\nCheck to see whether or not the author has made any generalizations, assumptions, or illogical connections between ideas. If so, what are they?\nCritical analysis is not simply paraphrasing or summarizing what an author has stated. This process requires the careful consideration of the information presented in the work and an evaluation of what it means, how it is presented, how it relates to other ideas, and possibly what implications it might have for other perspectives or other pieces of writing.\nIt is important to note that critical analysis is not the same thing as criticism. Criticism often means to find fault with something, even if it is not merited. However, as mentioned earlier, critical analysis means tolook at a text through a critical lens: examining the assumptions and implications of the author’s argumentor study.\nThus, it simply means thinking about whether or not the text is useful; whether or not its arguments are valid; and whether or not there are problems with the theory, methodology, or assumptions used by the author.\nWriting the Critique\nOnce the evaluations from the critical reading process are complete, you must consider the structure of the actual critique. The critique should almost always have the following elements:\nIntroduction with Summary\nA critical analysis should not simply summarize the work, but a brief summary is usually necessary to ensure the reader of the critique is generally familiar with the source material. Depending on the length of the summary, it could be included as part of the introduction or as a separate paragraph after the introduction. This is not the place to give a detailed outline of the arguments an author makes; covering the broad ideas is sufficient.\nThis thesis statement is the thesis of the critique, not the thesis of the work under investigation. This is the place to outline the final evaluation of the work as useful or not, well-argued or not, etc. As with all academic writing, this thesis statement should be well supported by evidence from a thorough analysis.\nAnalysis of the Theoretical Framework\nWhen analyzing the author’s use of theory, refer back to the questions asked during the critical reading process. This section may address whether the author adequately considered competing theories and interpretations, or whether he or she justified the reliance on a particular theory. Any differences between the use of a particular theory by this author and others could also be discussed here. Finally, evaluate whether the theories used were actually supported by the evidence the author put forth.\nAnalysis of the Methodology\nDepending on the field of study, the methodology section could address several elements. If the work relies on argument and interpretation, this section may be used to address whether the author was able to successfully argue his or her position, including the kinds of evidence and arguments used. If the work relies on empirical research, this section could address the literal methodology the author used to gather data, including experiment setup and any sources for errors the author may not have accounted for.\nAs with any academic essay, your conclusion should include a brief summary of your thesis and main points, as well as a statement that broadens the argument into a larger context. For a shorter critique, the conclusion does not need to be more than a couple of sentences; however, it is still needed to finish off the critique in a unified manner, as well as review the main points for the reader."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:aab4447a-71c2-4c4e-805d-e11227483cb9>","<urn:uuid:c9fc39bc-2435-4d47-97e3-b8feded4f197>"],"error":null}
{"question":"How does image localization accuracy compare between individual photos and group photos, and what legal considerations exist for photographing people in public?","answer":"For image localization, group photo localization achieves better accuracy than single image localization by leveraging adjacency information between photos taken within 300 meters of each other. This is demonstrated through testing on 521 GPS-tagged images. Regarding photographing people in public, there is no personal right to one's image or right of privacy, so taking pictures of people in public places is generally allowed. However, commercial use requires a model release form, and there are restrictions around photographing private acts or children - taking 'indecent' photographs of children under 16 without legitimate reason is a criminal offense that can result in fines or imprisonment.","context":["“Where Am I?!”\nAccurate Image Localization Based on Google Maps Street View\n1. Amir Roshan Zamir, Mubarak Shah, “Accurate Image Localization Based on Google Maps Street View”,\nNote: This version contains minor typographical corrections over the version published in the ECCV10 proceedings.\n2. Gonzalo Vaca, Amir Roshan Zamir, Mubarak Shah, “City Scale Geo-spatial Trajectory Estimation of a Moving Camera”,\n25th IEEE International Conference on Computer Vision and Pattern Recognition (CVPR), 2012\nCODE: Please email us your name and affiliation in order to obtain the code.\nIn this project a new system for image localization and location recognition in terms of Longitude () and Latitude () with an accuracy which is comparable to hand held GPS-devices is proposed. Our geolocation system is based on Google Maps Street view.\n· Google Maps Street View Reference Dataset\nThe reference dataset if based on Google Maps Street View. There are ~100k images in the dataset collected from Pittsburgh, PA and Orlando, FL. ~50k of the reference images are Collected automatically from Street View website and the rest of them are provided by Google.\nReference Image Place marks in Green and Query Images in Red\nNote: the dataset set provided by Google and the automatically captured images are overlapping in location and captured at different times.\nThere are 4 side view and 5 top views per place mark. The following figure shows the images of 3 sample place marks in Pittsburgh, PA.\nSample Reference Image and Their Location on the Map\nIn order to preprocess the reference dataset, the SIFT descriptors for SIFT interest points are computed and saved in a K-means tree using FLANN along with their GPS Tag.\n· Single Image Localization\nThe following block diagram shows each step of geolocating a query image. The input to the system is an image and the output is the found GPS location in terms of Longitude () and Latitude ().\nFirst Row: Single Image Localization Block Diagram, Second Row: The result of each step for a sample query.\nGeospatial Pruning and Smoothing steps are explained in more details in the following sections.\no 3.1 Geospatial Pruning\nGeospatial Pruning is an essential step in the proposed geolocation system. Geospatial Pruning is helpful when reference images have overlap in scene (i.e. one object is in the view of several reference images) and when there are repeated structures such as man-made structures in urban areas (e.g. the windows of a skyscraper are almost identical). Regarding the following figures, using Lowe’s pruning method most of the detected interest points and their descriptors will be removed in the pruning step resulting in a sparse vote distribution which is not appropriate for a reliable geolocation. On the other hand, using the proposed geospatial pruning method which incorporates the GPS location of each reference descriptor, the incorrectly matched descriptors are removed while the repeated structures of urban area and overlap in reference images do not affect the pruned results adversely.\nGeospatial Pruning: Two sample correctly-matched descriptors\nGeospatial Pruning Equation\nRegarding the above figures which show two sample correctly-matched descriptors, using the Lowe’s pruning method the two interest points will be removed from voting (descriptor ratio will be between 1st NN and 2nd NN) while the proposed method will retain them (descriptor ratio will be between 1st NN and 4th NN).\no 3.2 Smoothing\nSince Street View place marks are about 12 meters away from each other one object in a query image might be in the view of several reference images. This results in several short close peaks instead of one tall peak for the correct location in the vote function. Also, there might be some solitary peaks in the vote function which are due to incorrectly-matched descriptors. In order to amplify several close peaks and attenuate solitary peaks, the vote function is smoothed by Gaussian using the following figure.\nSmoothing By Gaussian\no 3.3 Confidence of Localization (CoL)\nA parameter called Confidence of Localization (CoL) which represents the reliability of localizing a query image is proposed in this project. The vote distribution after Gaussian smoothing can be normalized and treated as a Probability Distribution Function with the random variables of Longitude () and Latitude (). The proposed parameter is based on the Kurtosis (normalized forth central moment) of the vote distribution. This is due to the facts that a more peaked vote distribution function is corresponding to a more reliable localization task and the Kurtosis is a measure of how peaked a PDF is. The following figure shows how CoL changes with respect to vote distribution.\nConfidence of Localization (CoL)\nCoL value is not limited since there is no upper limited to the Kurtosis of a PDF, so CoL makes more sense when used on a comparative basis. For instance in order to find the correct city for a query image among two different cities, the query image can be geolocated within each one and the city with the higher associated CoL value should be selected as the correct one.\n· Image Group Localization\nWe propose a method for geolocating a group of query images instead of geolocating them individually. The proposed method leverages the adjacency information of query images in geolocating them. The assumption of the proposed method is that the query images are taken within a distance from each other (e.g. 300 meters). The following figure shows different steps of the proposed method for a group of 3 query images. First, each query image is geolocated individually. Later the other query images are geolocated within the neighborhood of the found location. The correct neighborhood and associated locations for each query image is neighborhood with the highest CoLgroup value.\nImage Group Localization\nWe test the proposed method on a test set of 521 GPS-Tagged user-uploaded images downloaded from Flickr, Panoramio, Picasa, etc. Since the GPS-tags of user-uploaded image are usually very noisy and inaccurate, we have manually double checked and adjusted the GPS location of the test set images.\nThe following figures show the results of geolocating the test set images using the proposed methods. The vertical axis shows the percentage of the test set images geolocated within the distance threshold (horizontal axis) of the ground truth.\nSingle Image Localization Results Image Group Localization Results\nIn order to examine the performance of the proposed Confidence of Localization parameter, the CoL values of geolocating the test set of single image localization are grouped into 8 bins based on their CoL value. The following figure shows the mean error (vertical axis) of each bin versus the mean CoL value of the bin (horizontal axis). As can be observed in the figure, higher CoL values are corresponding to lower error meaning the localization is more reliable.\nConfidence of Localization vs. Geolocation Error (m)\n(Since theoretically the value of the Kurtosis is not limited, we normalized the CoL values and showed them ranging from 0 to 1 on the horizontal axis of the plot.)\nThe following figures are more localization examples of the test set image using the proposed methods. Each example shows one query image, the retrieved image, their GPS locations and the error in meters along with the vote distribution for each step of localization.\nPlease feel free to contact us with your questions, suggestions and comments.","Cameras are everywhere nowadays. They range from the tiny lens in your smartphone to convenient point-and-shoots right up to huge digital SLRs with interchangeable lenses and flashes. Anyone can do photography these days, but while aspiring photographers learn about ISO, the rule of thirds, f-stops and so on, awareness of the legal issues around the taking of photographs is less common. In this article, Arts Law looks at some of the key issues around popular photography subjects in public spaces.\nBuildings & architecture\nUnder sections 66 and 68 of the Copyright Act it is not an infringement of copyright to photograph a building, or to publish that photograph. There are, however, issues of access and restrictions on activity surrounding some building and architectural sites.\nPublic spaces, particularly ones that attract a lot of people, are controlled by a local council or a government authority which can impose restrictions on people and activities that take place in that space. For example, the New South Wales Sydney Harbour Foreshore Authority which manages Darling Harbour, Circular Quay, the Rocks and Luna Park prohibits commercial photography in these areas without permission, and any person who causes an annoyance or inconvenience in these areas – say a photographer stubbornly blocking a walkway with his tripod awaiting that perfect shot – can be removed by a ranger or police. Sydney Olympic Park takes this further in that anyone causing an annoyance or inconvenience by taking photographs can have their camera confiscated by an authorised person if the photographer doesn't comply with directions to stop.\nGovernment property such as power stations, railway yards, and military stations are restricted areas, and trespassing into these places may lead to arrest and prosecution. With military stations and areas declared 'prohibited' for purposes of Commonwealth defence, photography is actually illegal, and the mere possession of a camera while in such an area can result in its confiscation and destruction along with any pictures and equipment. In serious cases, you yourself may face fines or even imprisonment.\nPrivate property requires permission from the land owner prior to access, otherwise you may be liable for trespass. The land owner will have a right to impose restrictions on activities, for example only allowing certain areas or objects to be photographed. This is done by many museums and galleries which restrict photography of artworks as a condition of entry.\nParks, pools, reserves & beaches\nParks, pools, beaches, nature reserves, etc. are not works for the purposes of the Copyright Act and as such there is no need to seek copyright permissions to photograph them. They are, however, managed or controlled by either a local council or government authority which as described above can make rules regulating photographic activities.\nLocal councils: These have responsibility for local parks, pools, and most beaches. In the wake of public concern over photography of unsuspecting swimmers in bathing suits, many local councils such as Waverley which manages Bondi Beach have imposed restrictions on photography at beaches and/or public pools. These restrictions have in some cases been extended to other sites such as streets and cemeteries. Most of these restrictions would seem to apply to commercial photography however photography of any sort may be prohibited in specific spaces such as pool changing rooms. If you are going to take photographs in a public space controlled by a local council – pool, beach, cemetery, etc. – you should check with the managing council as to whether any restrictions apply and if so, what.\nGovernment authorities: These have responsibility for national parks and wildlife reserves. It is necessary to identify whether the government authority is a State one or a Federal one. For example, the Federal Government has control over Commonwealth Marine Parks and Reserves, Kakadu National Park, Australian National Botanic Gardens, and restricts the taking and commercial use of photographs in these areas without a permit. State and Territory governments will also control various parks in their jurisdiction such as regional parks, historic sites, and state conservation areas. If you are planning a trip to these types of sites for photography you should make inquiries as to which specific body manages it in order to identify the laws and regulations that may affect you.\nPublic art & street art\nMurals and sculptures enhance a public space and are attractive photography subjects, however because they are artworks they are likely to be protected by copyright. This means a photographer will need to seek permission to reproduce the work in a photograph unless an exception applies. Whether or not there is an exception will depend on the type of art work being photographed.\nSculptures: Under section 65 of the Copyright Act, it is not an infringement of copyright to photograph or publish a photograph of a sculpture if the sculpture is permanently situated in a public place or in premises open to the public. This would include sculptures in a park or city street, but also sculptures such as headstones and statues in a publicly accessible cemetery.\nMurals and graffiti: Although murals and graffiti are generally situated in a public place, because they are two-dimensional artworks the section 65 exemption does not apply. As such, if you substantially reproduce a mural or graffiti work in a photograph you may be infringing the copyright in that mural or graffiti work. Substantial reproduction is not a question of how much has been reproduced like 10% of 70%, but rather a question of quality (i.e. what has been reproduced). This means a photograph looking down a street that happens to have a mural wall running down one side adding perspective is less likely to infringe copyright than a photograph that focuses on a key part of the mural making it the main subject of the photograph, even though the first photograph shows more of the mural.\nLogos and trade marks\nThe way advertising and marketing work nowadays, it is almost impossible to take pictures in an urban area without catching some company's logo or trade mark. A trade mark, especially a registered one, gives a trade mark owner exclusive rights to use the trade mark and authorise its use on particular goods and services. However, a trade mark is only considered infringed if it is used as a trade mark by another person without authorisation. That means while it's okay to take a picture of yourself standing in front of the gigantic Coca-Cola sign in Kings Cross and share it on Facebook, using that picture in association your own line of drinks will not be.\nFinally, people. The first thing to know about people photography is that there is no personal or publicity right in one's personal image, so there's no need to 'clear' anything before taking pictures of someone's face. Current privacy laws are concerned more with the collection and storage of personal information meaning there is no right of privacy, and neither is there (at least thus far) a tort of invasion of privacy. As such, snapping a picture of someone in the street in an urban scene or because you like their fashion sense is generally allowed.\nThings get a little more complicated when you photograph people for a commercial purpose, such as a poster where someone's face is used to sell or advertise a product or service. In this case the subject of the photograph will need to have signed a model release form in order for their picture to be taken. If a photograph of a person is used commercially without that person's permission, you could potentially be liable for misrepresentation, the tort of passing off, or defamation.\nBe aware also that there sensitivities around the photography of people in certain circumstances, and also children. Snapping pictures of people in a private act where they would reasonably expect to be afforded privacy without their permission such as in the bath, on the toilet, or engaged in sexual activities, is a punishable offence under New South Wales law. With children, charges can be laid in many states such for taking “indecent” photographs of a child under the age of 16 without a legitimate reason, even the child was in a public place. These are criminal offences and can result in a fine or imprisonment.\nAs far as photography in public goes, there is no need to seek permission to take a picture whether the camera is aimed at a building or a person. There may, however, be issues of access to the space, and, where people are concerned, how the photograph is going to be used. And of course, there is one important thing to always remember as a photographer, namely that any photograph you take is protected by copyright owned by you.\nJo Teng is a solicitor at Arts Law who enjoys taking photographs in her spare time."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:eed90da9-c0ee-44fa-98ce-c5347780a354>","<urn:uuid:b5a0b8db-c32c-4153-b378-2ed12e12c0eb>"],"error":null}
{"question":"How do the timing patterns differ between salsa 'on 2' and traditional waltz dancing?","answer":"Salsa 'on 2' and waltz have different timing structures. Salsa 'on 2' is played in 4/4 time with 8 beats across two measures, where dancers step on beats 1,2,3,5,6,7 (no steps on 4 and 8) and break movement on beats 2 and 6. In contrast, waltz is danced in 3/4 time rhythm, making it distinct from other four-beat rhythms. The waltz uses box steps and turning patterns that rotate both clockwise and counterclockwise in a smooth, fluid motion around the floor.","context":["Definition Of Dancing Salsa on “2”\n“Breaking On 2” – The New York club style salsa\n“Breaking on 2” is taught to be step on 1,2,3,5,6,7 and it is sometimes referred or called “Eddie Torres Style”. While a few other dancers may step differently, while still calling it “dancing on 2”, the definition used here follows what is taught exclusively by the majority of the New York City area independent salsa dance studios and instructors. This way of dancing salsa is often referred to as “New York’, “club”, “street”, “Latino” or “Eddie Torres” style. This method is different from ” ballroom”, ” international” and Cuban son montuno styles, and also different than some of what is taught at other New York area studios such as those who teach to step on 2, 3, 4, 6, 7, 8, and those which break on 1, 3 or 4, and those who do not dance in a line or “slot”.\nSalsa Music – Salsa music is played in 4/4 time, and has 4 beats to the measure or bar, and we dance within 2 measures, so we count 8 beats; and loosely say that we “dance to an 8 beat measure or bar”, although technically it is two 4 beat measures. Many dances, not just salsa, are done within 2 measures, and therefore some people use the terms “musician’s measure” and “dancer’s measure”. The “musician’s measure” has 4 beats, while the “dancer’s measure” has 8 beats and consists of 2 “musician’s measures”.\nThe ON 2 Basic Step – The basic step, the man’s left foot goes back and the woman’s right foot goes forward on the 1st beat of this so-called 8 beat measure or bar. We step with our feet on the 1st, 2nd, 3rd, and 5th, 6th, and 7th beats of the measure. We do not step on the 4th and 8th beats. We actually “break” our movement, in other words we change body direction, on the 2nd and 6th beats of the measure. We call it “breaking on 2”, or “dancing on 2”, or “bailando en dos”. This is mambo, danced forward and back, in a line or slot, not side to side or in a circle or square.\nThe basic step is as follows:\n1st beat of the measure – The man steps back with his left foot. The woman steps forward with her right foot.\n2nd beat of the measure – The man steps farther back with his right foot = “breaks back on 2” and changes direction, starting to lean forward with his body . The woman steps farther forward with her left foot = “breaking back on 2” and changes direction, starting to lean back with her body .\n3rd beat of the measure – The man steps in place with his left foot, while his body is moving forward. The woman steps in place with her right foot, while her body is moving backward.\n4th beat of the measure – No steps.\n5th beat of the measure – The man steps forward with his right foot, in front of his left foot. The woman steps backward with her left foot, behind her right foot.\n6th beat of the measure – The man steps farther forward with his left foot = “breaks forward on 6”, and changes direction, starting to lean backward with his body . The woman steps farther back with her right foot = “breaks back on 6”, and changes direction, starting to lean forward “.\n7th beat of the measure – The man steps in place with his right foot, while his body is moving backward. The woman steps in place with her left foot, while her body is moving forward.\n8th beat of the measure – No steps.\nTechnically, as you learn proper timing, it is proper to start the dance in the following way: You walk onto the dance floor with your partner, set up the standard partner position frame, and then begin on the 6th beat of the measure, with the man stepping forward with his left foot and the woman stepping back with her right. On the 7th beat, the couple changes direction, with the man rocking back onto his right foot and the woman rocking forward onto her left foot. They then go right into the basic step pattern which is maintained through the rest of the song: the man’s left foot goes back and the woman’s right foot goes forward on the 1st beat of the measure, and the pattern continues as described above in detail. Although this is technically the proper way to start, most New York dancers simply begin on the 1st beat of the measure as described above, sometimes not even setting up the partner position first.\nsalsanewyork.com Salsa Magazine.","Wedding dance styles for the bride and groom’s first dance, father-daughter dance, mother son wedding dance and dancing at the reception include waltz, foxtrot and slow dancing but in recent years many more dance styles have become popular. Some couples choose a romantic, slow song, others opt for a spirited, energetic song or a mash up (mix) starting slow and romantic then breaking into a fast dance or freestyle.\nWe chose the best wedding first dance routines from the web with dance styles including traditional music like waltz, slow dance or foxtrot to the swing, Lindy hop or jitterbug, as well as, Latin selections like rumba, mambo, salsa and some mash up routines.\nWatch/listen to Best 25 First Dance Wedding Songs\n(Photo Art of Emotion’s “Best Dance Ever” 2013, see below)\nThe Different Types of Wedding Dance Styles\nWaltz Wedding Dance Style (classic, fast)\n(Recommended Waltz Dance Music Picks)\nThe Waltz dance is one of the most popular wedding dance styles. The waltz is a great choice for a wedding first dance. It is a 3/4 time rhythm, which differentiates it from other four beat rhythms. This dance is a smooth, fluid dance that normally moves around the floor in a counter clockwise direction. There is an additional rhythm called the Hesitation that is used in combination with three count or six count patterns in the waltz. There are a variety of waltz dance variations including: American Waltz, International, Country Western, Cajun, French and Viennese waltz and there are classic versions and contemporary versions of waltz.\nWaltz Wedding Dance Styles (Contemporary, fast)\nA Thousand Years by Christina Perri (Fast Waltz)\nThe waltz is composed of box steps and turning patterns that rotate both clockwise and counterclockwise. The waltz started in the mid-nineteenth century and was considered scandalous because of the facing embrace, in its day. The first waltzes were danced to Strauss music, which were fast, referred to as Viennese waltz (tempo) today. This is an enduring favorite among the different wedding dance styles for couples first dance. Read more about the different types of waltz styles here!\nSlow Wedding Dance Styles\nThinking Outloud by Ed Sheeran (a slow dance)\nSlow Dance (or Nightclub Two Step)\nThe slow dance (or nighclub two step) is a more recent popular wedding dance style of music and dancing. It is also a very popular dance genres for wedding first dance since they are slow and romantic. There is music which does not fit into any of the ballroom slow dances: waltz, foxtrot and rumba. These songs are slower than the tempos for the ballroom dance genres. Choosing one of these types of songs means dancing either a traditional slow dance, which includes side steps and pivots or one might choose a Nightclub Two Step depending on the music.\nNightclub Two Step was developed by a Buddy Schwimmer, a dance studio owner, dancer, promoter that was part of the Golden State Teachers Association in Southern California. The nightclub two step has evolved over the years and can be done starting with a rock step on counts 1&, followed by a side step on count 2 or some start with the side step on count one. A slow dance or nightclub two step is a great choice for a sensual, slow wedding first dance.\nFoxtrot Wedding Dance Styles\nLove by Michael Buble\nThe Foxtrot dance is a smooth, progressive dance that moves around the dance floor to a 4-beat rhythm with a combination of 6 or 8 beat patterns. It is an elegant wedding dance style that is perfect for a larger dance floor and a smooth medium tempo music especially big band style music or some of the contemporary artists like Michael Buble.\nThe foxtrot dance developed in the early part of the 20th century from other dance genres and popularized by Vernon and Irene Castle. The foxtrot has continued in its popularity among both social ballroom dancers and dancesport enthusiasts.\nSwing Wedding Dance Styles (Jitterbug, Lindy Hop)\nSing Sing Sing by Louis Prima (Swing dancing)\nSwing dance is a term used to refer to a group of dances that includes the jitterbug, jive, boogie woogie, shag, Lindy hop, Balboa, West and East Coast swing. This is a fantastic choice for a wedding first dance if you are looking for an energetic wedding dance style for your wedding!\nSwing Wedding Dance Styles (Shag)\nStagger Lee by Lloyd Price (Swing dance)\nSwing dancing is all American as the swing originated in the United States, in Harlem at the Savoy Ballroom in the 1920’s following the Charleston and in conjunction with the Balboa and other swing forms like the origin swing dance, the Lindy Hop. The swing is a great and more energetic than the previous wedding dance styles.\nJitterbug Wedding Dance Styles\nSing Sing Sing by Benny Goodman (Jitterbug)\nSwing Wedding Dance style (Mix)\nSwing music “Fly Me To the Moon” by London Swingfonia\nRumba Wedding Dance Style\nSway by Michael Buble\nThe rumba dance (also Rhumba) is danced to Latin music that has is fluid and varies but averages about 140 beats per minute. It is rhythmic, sensual and romantic so it is a great choice for a wedding first dance. Also, the American style box rumba is slower and easier than other forms of Latin dance like mambo, salsa and cha cha. The rumba is easy to learn as it is composed of a box step and a variety of break steps (rock steps).\nThe history of the rumba dance is elusive since it derives from a group of other dances that originated in different countries. The term “Rumba” (also Rhumba) is used to refer to a group of rhythmic dances of Spanish and African roots that originated in Cuba. The American ballroom rumba developed from some of these early Cuban “son” dances in the early 20th century. The word used to mean “party” but later in the 1920’s and 1930’s came to refer to a dance genre. The early ballroom rumba was done to faster music, e.g. Peanut Vendor but later the International style Latin dancers danced to slower “bolero” son music. The rumba is a romantic dance style danced to slower music with a Latin flair.\nMambo Wedding Dance style\nMambo (or Salsa)\nThe mambo dance is a fast, energetic Latin style dance. Wedding couples choose this dance often because of the movie, Dirty Dancing, and the mambo that Patrick Swayze danced with Jennifer Grey in the movie to the song, “I’ve Had the Time of My Life,” by Bill Medley & Jennifer Warnes. The mambo dance uses a faster tempo Latin music and is more staccato than the salsa. It is a more complex dance than the rumba and requires more time to become an accomplished mambo dancer.\nThe mambo dance originated in the 1940’s and was popular in Cuba, Mexico City and New York but eventually spread across the globe and was popular for several decades until it evolved into the salsa in the mid-1970’s. It is still danced today especially in American rhythm competitions. The Latin dances have become more popular in recent years among the various wedding dance styles!\nThe salsa dance is a rhythmic Latin dance that has continued in popularity since the 1970’s. Choosing a salsa song to dance as a wedding first dance is an exciting option. This dance is sensual, fast paced and rhythmic. It requires more time to learn than a rumba or basic swing dance.\nThe salsa dance originated in New York with influence from Cuba and Puerto Rico. It is derived from cha cha and mambo. There are unique styles of salsa in different regions of the world including: Cuban, Miami, Colombian, Los Angeles and New York.\nWatch and read more about the salsa dance here.\nMashup Wedding Dance styles\nLove Never Fails by Brandon Heath (Slow, Freestyle, Swing)\nWedding Mixed Songs Mashup Style\nUnchained Melody by Air Supply\nWedding Dance Mash Up Style\nThe mash up wedding dance has become popular in the last few years with brides and grooms. A mash up is a choreographed routine to more than one song. I could be two, three or more different types of music. For instance, a mash up might include a slow romantic song like a waltz, then an energetic swing dance followed by a classic Michael Jackson. Moreover, a mash up is a great way to include several of your favorite wedding dance songs. Lastly, a mash up keeps everyone’s attention during the wedding first dance.\nWedding Dance Music\n- Check out DanceTime’s Recommended Wedding Songs\n- Watch Listen to Popular Wedding Reception Music\n- Watch/Listen to Top 25 First Dance Wedding Songs\n- Watch/Listen to Best 25 Father Daughter Dance Songs\n- Watch / Listen to Mother Son Wedding Dance Songs\nMore Wedding First Dance Information:\n- Watch/Read Complete Guide to Wedding Dance Lessons\n- Watch some Wedding Dance Fails (humor)\n- Read more about the Wedding Dance\n- Additional Wedding Dance FAQ’s"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:1cc99d0b-8393-4f48-9990-ef02a6d30a65>","<urn:uuid:49c195cd-95f7-4776-99c7-c4d6df9ca1d8>"],"error":null}
{"question":"How do the initial performances of the Book of Deuteronomy's laws compare with the premiere performances of Tchaikovsky's Serenade in terms of their public presentation and audience?","answer":"The Book of Deuteronomy was first delivered by Moses as public discourses to the Israelites in the plains of Moab, with the laws being commanded to be publicly read every seventh year. In comparison, Tchaikovsky's Serenade had its first performance as a private concert at the Moscow Conservatory on November 21/December 3, 1880, performed by professors and students as a surprise for Tchaikovsky. Its first public performance occurred later in Saint Petersburg on October 18/30, 1881, at the third symphony concert of the Russian Musical Society, conducted by Eduard Nápravník.","context":["Commentary on the Bible, by Adam Clarke, , at sacred-texts.com\nPreface to the Book of Deuteronomy\nWe have borrowed the name of this book, as in former cases, from the Vulgate Latin, Deuteronomium, as the Vulgate has done from the Greek version of the Septuagint, Δευτερονομιον, which is a compound term literally signifying the second law, because it seems to contain a repetition of the preceding laws, from which circumstance it has been termed by the rabbins משנה mishneh, the iteration or doubling.\nIt appears that both these names are borrowed from Deu 17:18, where the king is commanded to write him a copy of this law; the original is משנה התורה mishneh hattorah, a repetition or doubling of the law, which the Septuagint have translated το δευτερονομιον, this second law, which we, properly enough, translate a copy of the law: but in Hebrew, like the preceding books, it takes its name from its commencement, אלה הדברים Elleh Haddebarim, these are the words; and in the best rabbinical Bibles its running title is ספר דברים Sepher Debarim, the book of debarim, or the book of the words. Our Saxon ancestors termed it the after law.\nThe Book of Deuteronomy contains an account of what passed in the wilderness from the first day of the eleventh month of the fortieth year after the departure of the Israelites from Egypt to the seventh day of the twelfth month of the same; making in the whole a history of the transactions of exactly five weeks, the months of the Jews being lunar. The history is continued about seven days after the death of Moses; for he began to deliver his first discourse to the people in the plains of Moab the first day of the eleventh month of the fortieth year, Deu 1:3, and died on the first day of the twelfth month of the same year, aged 120 years.\nAs the Israelites were now about to enter into the promised land, and many of them had not witnessed the different transactions in the wilderness, the former generations having been all destroyed except Joshua and Caleb; to impress their hearts with a deep sense of their obligation to God, and to prepare them for the inheritance which God had prepared for them. Moses here repeats the principal occurrences of the forty years, now almost elapsed; shows them the absolute necessity of fearing, loving, and obeying God; repeats the ten commandments, and particularly explains each, and the ordinances belonging to them, adding others which he had not delivered before; confirms the whole law in a most solemn manner, with exceeding great and precious promises to them that keep it, and a denunciation of the most awful judgments against those who should break it; renews the covenant between God and the people; prophesies of things which should come to pass in the latter days; blesses each of the tribes, prophetically, with the choicest spiritual and temporal blessings; and then, having viewed the whole extent of the land, from the top of Mount Nebo or Pisgah, he yielded up the ghost, and was privately buried by God, leaving Joshua the son of Nun for his successor.\nThe Book of Deuteronomy and the Epistle to the Hebrews contain the best comment on the nature, design, and use of the law; the former may be considered as an evangelical commentary on the four preceding books, in which the spiritual reference and signification of the different parts of the law are given, and given in such a manner as none could give who had not a clear discovery of the glory which was to be revealed. It may be safely asserted that very few parts of the Old Testament Scriptures can be read with greater profit by the genuine Christian than the Book of Deuteronomy.\nThe contents of the different chapters may be thus briefly summed up: -\nOn the first day of the eleventh month of the fortieth year, after the departure from Egypt, the Israelites being then on the east side of Jordan, in the land of the Moabites, Moses gives them a brief recapitulation of what took place in the wilderness, from their leaving Mount Horeb till they came to Kadesh; Deuteronomy 1.\nTheir travels from Kadesh till they come to the country of the Amorites, with the defeat of Sihon their king; Deuteronomy 2. The war with Og, king of Bashan, with the dividing his land and that of Sihon among the tribes of Reuben and Gad, and the half tribe of Manasseh; Deuteronomy 3.\nMoses exhorts them to observe the Divine precepts; threatens those who should violate them; and appoints Bezer, Ramoth, and Golan, to be the cities of refuge on the east side of Jordan; Deuteronomy 4.\nRepeats the decalogue, and tells the people what effect the publication of it had on their fathers, when God spoke to them from the mount; Deuteronomy 5.\nExhorts them to love God with all their heart, and promises them an abundance of good things; Deuteronomy 6.\nRepeats the command to exterminate the Canaanites, and all vestiges of their idolatry; Deuteronomy 7.\nRecites the many interpositions of God's kindness which they had received during their forty years' travel in the wilderness, and strongly exhorts them to remember those mercies, and not to forfeit a continuance of his favors by ingratitude and disobedience; Deuteronomy 8.\nShows them that they were to pass Jordan in a short time, and that God was about to bring them in, not on account of their goodness, but of his mercy; Deuteronomy 9.\nGives an account of the second tables of the law, which he made at the command of God; mentions their journey from Beeroth to Jotbath, the choosing of the Levites, and the necessity of having the heart circumcised; Deuteronomy 10.\nContinues an account of God's mighty acts in their behalf, and shows the blessings which should come on them who kept his law, and the curse on those who were disobedient. The blessings to be pronounced on Mount Gerizim, and the curses on Mount Ebal; Deuteronomy 11.\nCommands them to destroy all monuments of idolatry in the land, to offer the different offerings and sacrifices, and to avoid eating of blood; Deuteronomy 12.\nOrdinances against false prophets, idolatrous cities, etc.; Deuteronomy 13.\nForbids their cutting themselves at funerals, recapitulates the law concerning clean and unclean animals, and exhorts them to remember the Levites; Deuteronomy 14.\nEvery seventh year shall be a year of release for the poor of usury; first-born, etc.; Deuteronomy 15.\nConcerning the annual feasts, passover, pentecost, and tabernacles; the establishment of judges and officers; no groves to be planted near the altar of God; Deuteronomy 16.\nIdolaters are to be put to death; difficult cases in equity to be referred to the superior judges; of a king and his duties; Deuteronomy 17.\nAll divination is prohibited. The grand promise of an Extraordinary Prophet. How false prophets are to be distinguished; Deuteronomy 18.\nThe laws relative to the cities of refuge, and how the intentional murderer is to be treated; Deuteronomy 19.\nLaws relative to the carrying on of war; who should be sent back from the army, how they are to treat the Canaanites, and how they are to commence sieges, Deuteronomy 20.\nHow to make expiation for an uncertain murder; marriages with captives; rights of the first-born, etc.; Deuteronomy 21.\nThings lost or strayed are to be restored to their right owners; men and women must not interchange apparel; improper mixtures to be avoided; of the tokens of virginity; adulterers and adulteresses to be put to death; Deuteronomy 22.\nEunuchs, bastards, Moabites, and Ammonites, are not to be permitted to enter into the congregation of the Lord. Harlots not to be tolerated; Deuteronomy 23.\nLaws relative to divorce; privileges of the newly-married man: concerning pledges, wages, gleanings, etc.; Deuteronomy 24.\nMore than forty stripes shall not be given. If a man die childless, his brother shall take his wife. Of weights, measures, etc.; Deuteronomy 25. Different ceremonies to be used in offering the first-fruits; tithes. Of full self-consecration to God; Deuteronomy 26.\nThe words of the law to be written on stones, and to be set up on Mount Ebal. The tribes which stand on Mount Gerizim to bless the obedient, and those which should stand on Mount Ebal to curse the disobedient. Who they are that are to be cursed; Deuteronomy 27.\nThe blessings of those who are faithful; curses against the disobedient; Deuteronomy 28.\nA recital of the covenant of God, made not only with them, but for their posterity; Deuteronomy 29.\nPromises of pardon to the penitent; good and evil, life and death, are set before them; Deuteronomy 30.\nMoses, being now 120 years old, delivers a copy of the law which he had written into the hands of the priests, to be laid up in the ark, and to be publicly read every seventh year; a charge is given to Joshua; Deuteronomy 31.\nThe prophetical and historical song of Moses: he is commanded to go up to Mount Nebo that he may see the promised land; Deuteronomy 32.\nThe prophetical blessing of the twelve tribes. The indescribable happiness of Israel; Deuteronomy 33.\nMoses views the promised land from the top of Mount Nebo, dies, and is privately buried by the Lord. The Israelites mourn for him thirty days.\nJoshua takes command of the people. The character of Moses; Deu 34:1-12.\nAt the close of this book I have added a number of useful Tables, such as no edition of the Bible ever could boast, viz.:\nTable I. A perpetual table, showing through the course of 13 lunar cycles (which embrace every possible variation) the day of the week with which the Jewish year begins, and on which the passover is held; as also the lengths of the months Marchesvan and Cisleu.\nTable II. Containing the whole variations in the reading of the Pareshioth or sections of the law for every year of the Jewish cycle of 247 years.\nTable III. To find, with the help of Table IV., the day of the week upon which any Jewish new moon or festival happens.\nTable IV. To determine upon what day of the week any Jewish month commences for any given year; as also the day of the week upon which the Jews celebrate their principal fasts and festivals.\nTable V. Containing the order of reading the Pareshioth and Haphtaroth for 90 Jewish years, i. e., from A. M. 5572 to A. M. 5661, both inclusive, connected with the corresponding dates in the Christian Era, according to the Gregorian or new style.\nTable VI. Containing the year of the Jewish lunar cycle, the golden number, the first day of the Jewish pass over, Easter Sunday, and the commencement of each Jewish year according to the Gregorian Calendar, a. d. 1812 to a. d. 1900, both inclusive. All concluded with an explanation of the preceding tables. To them succeeds A Chronology of the Pentateuch, with the Book of Joshua; or a Systematic Arrangement of Events from the creation of Adam, A. M. 1, to the birth of Peleg, A. M. 1757, and thence to the death of Joshua, A. M. 2561. This chronology includes two tables, viz.: Table I. The birth and death of all the patriarchs, from Adam, A. M. 1, to Rhea, son of Peleg, A. M. 1787. Table II. A chronology of ancient kingdoms synchronized with the sacred history, from A. M. 1757, B. C. 2247, to A. M. 2561, B. C. 1443. The whole so calculated as to prevent the necessity of having recourse to systems of chronology for historic facts in anywise connected with those mentioned in the Sacred Writings.\nThe great utility of these tables will, I think, be at once evident to every Biblical critic, chronologist, and antiquary; and for the immense labor employed in their construction the editor, no doubt, will have their hearty thanks.","Serenade for String Orchestra\nThe Serenade is scored for violins I, violins II, violas, cellos, and double basses. In the score Tchaikovsky noted: \"The larger number of players in the string orchestra, the more this shall be in accordance with the author's wishes\".\nMovements and Duration\nThere are four movements:\n- I. Pezzo in forma di sonatina. Andante non troppo—Allegro moderato (C major, 295 bars)\n- Ii. Valse. Moderato. Tempo di Valse (G major, 223 bars)\n- Iii. Elegia. Larghetto elegiaco (D major, 162 bars)\n- Iv. Finale (Tema russo). Andante—Allegro con spirito (C major, 406 bars).\nA complete performance of the Serenade lasts approximately 30 minutes.\n\"No sooner had I begun to spend a number of days relaxing, than I began to feel somewhat restless and rather unwell... Today I could not bear it, and endure it no longer, and I busied myself a little with designs for a future symphony—perhaps? I immediately began to feel cheerful, well and relaxed ... This effect proved not to diminish itself with time, and I satisfied my intrinsic need to work—especially composition. Now here I am already with designs for a symphony or string quartet; I do not yet know which\", Tchaikovsky told Nadezhda von Meck on 9/21 September 1880 . He also wrote to Anatoly Tchaikovsky on 21 September/3 October 1880 that he had: \"started to write something\" . By 25 September/7 October three movements of the new work were ready .\nIn a letter to Nadezhda von Meck of 25 September/7 October, Tchaikovsky described his new work as a suite for string orchestra. On 6/18 October in a letter to Anatoly Tchaikovsky he reported: \"I've done quite a lot recently. I've already written the overture for the exhibition , and also written and should finish off a Serenade for string instruments\" . \"I am now gradually orchestrating it\", we read in a letter to Nadezhda von Meck of 8/20–10/22 October 1880, and later: \"The Serenade... I composed from an innate impulse; that is something which arises from having freedom to think, and is not devoid of true worth\" .\nBy 14/26 October the Serenade was ready, and Tchaikovsky set to work on its arrangement for piano duet , which according to the date on the manuscript was completed on 23 October/4 November 1880. Despatching the score and piano duet arrangement to Pyotr Jurgenson to be published, Tchaikovsky wrote: \"I happened to write a Serenade for string orchestra in four movements, and am sending it to you the day after tomorrow in the form of a full score and four-hand arrangement ... I love this Serenade terribly, and fervently hope that it might soon see the light of day\" .\nAs noted above, Tchaikovsky's arrangement of the Serenade for piano duet (4 hands) was made between 14/26 October and 23 October/4 November 1880.\nThe Serenade was performed for the first time on 21 November/3 December 1880 at a private concert in the Moscow Conservatory by a force of professors and students, as a surprise for Tchaikovsky, who was visiting after long absence from the Conservatory .\nOn 17/29 June 1881, Tchaikovsky wrote to Eduard Nápravník, asking if the Serenade might be included in one of the future concerts . In his reply of 27 June/9 July that year, Nápravník agreed to perform the Serenade in one of the forthcoming concerts .\nThe first public performance of the Serenade for String Orchestra took place in Saint Petersburg on 18/30 October 1881, at the third symphony concert of the Russian Musical Society, conducted by Eduard Nápravník. In Moscow it was performed for the first time on 16/28 January 1882 at the seventh concert of the Russian Musical Society, conducted by Max Erdmannsdörfer.\nOther notable early performances include:\n- Tiflis, 2nd Russian Musical Society symphony concert, 27 March/8 April 1884, conducted by Mikhail Ippolitov-Ivanov\n- New York, Academy of Music, Symphony Society concert, 12/24 January 1885, conducted by Leopold Damrosch\n- Saint Petersburg, Philharmonic Society concert, 5/17 March 1887, conducted by Tchaikovsky (2nd and 3rd movements only)\n- Hamburg, 6th Philharmonic Society concert, 8/20 January 1888, conducted by Tchaikovsky\n- Prague, National Theatre, 9/21 February 1888, conducted by Tchaikovsky\n- Paris, Colonne Orchestra concert, 16/28 February 1888, conducted by Tchaikovsky (2nd and 3rd movements only)\n- Paris, 16th Châtelet concert, 21 February/4 March 1888, conducted by Tchaikovsky\n- Paris, 17th Châtelet concert, 28 February/11 March 1888, conducted by Tchaikovsky (2nd and 3rd movements only)\n- London, Saint James's Hall, 2nd Philharmonic Society concert, 10/22 March 1888, conducted by Tchaikovsky\n- Berlin, Philharmonic Society concert, 14/26 February 1889, conducted by Tchaikovsky\n- Geneva, New Theatre, 25 February/9 March 1889, conducted by Tchaikovsky\n- Kiev, 1st Russian Musical Society symphony concert, 21 October/2 November 1889, conducted by Aleksandr Vinogradsky\n- Tiflis, special Russian Musical Society symphony concert, 20 October/1 November 1890, conducted by Tchaikovsky\n- Baltimore, Lyceum Theatre, 3/15 May 1891, conducted by Tchaikovsky\n- Warsaw, 2/14 January 1892, conducted by Tchaikovsky (2nd and 3rd movements only)\n- Brussels, 2/14 January 1893, conducted by Tchaikovsky (2nd and 3rd movements only)\n- Odessa, Slavonic Society free concert, 22 January/3 February 1893, conducted by Tchaikovsky (2nd movement only)\n- Kharkov, 2nd Russian Musical Society symphony concert, 14/26 November 1893, conducted by Ilya Slatin (2nd movement only)\nSergey Taneyev assisted Tchaikovsky in correcting the score for publication . In January 1881 the full score and parts of the Serenade were printed and issued by Pyotr Jurgenson, and the following April the composer's arrangement for piano duet was published.\nThe full score of the Serenade was published in volume 20 of Tchaikovsky's Complete Collected Works (1946), edited by Ivan Shishov, and Tchaikovsky's arrangement for piano duet in volume 50Б (1965), edited by Irina Iordan.\nTchaikovsky's manuscript score and arrangement for piano duet are preserved in the Glinka National Museum Consortium of Musical Culture in Moscow (ф. 88, Nos. 82 and 83).\nIn the Serenade's finale, the opening Andante section includes the folksong 'On the Green Meadow' (А как по лугу), and the main theme of the ensuing Allegro is the folksong 'Under the Green Apple Tree' (Под яблонью зеленою). These tunes had previously been arranged by Tchaikovsky as Nos. 28 and 42 respectively of Fifty Russian Folksongs (1868-69).\nNotes and References\n- Letter 1585 to Nadezhda von Meck, 9/21–12/24 September 1880 [back]\n- Letter 1599 to Anatoly Tchaikovsky, 21 September/3 October 1880 [back]\n- See Letter 1601 to Nadezhda von Meck, 21 September/3 October–25 September/7 October 1880 [back]\n- i.e. The Year 1812 [back]\n- Letter 1608 to Anatoly Tchaikovsky, 6/18 October 1880 [back]\n- Letter 1609 to Nadezhda von Meck, 8/20–10/22 October 1880 [back]\n- See Letter 1613 to Nadezhda von Meck, 14/26–16/28 October 1880 [back]\n- Letter 1619 to Pyotr Jurgenson, 27 October/8 November 1880 [back]\n- See Letter 1632 to Nadezhda von Meck, 27 November/9 December 1880 [back]\n- See letter from Sergey Taneyev to Tchaikovsky, 1/13 March 1881 — Klin House-Museum Archive [back]\n- Letter 1786 to Eduard Nápravník, 17/29 June 1881 [back]\n- Letter from Eduard Nápravník to Tchaikovsky, 27 June/9 July 1881 — Klin House-Museum Archive [back]"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:e4843c11-190f-4dab-9bdb-d6acbb605587>","<urn:uuid:de321f57-7dd5-4171-8d0f-ccfbb1170f93>"],"error":null}
{"question":"How did ePharmacy growth rates compare across regions in 2022?","answer":"Australia with New Zealand showed the highest growth at +29.9%, followed by Southern Asia at +25.7% and Sub-Saharan Africa at +17.1%. In contrast, Northern America experienced a 20.7% decline, with major retailers like Rite Aid (-51.2%), Walgreens (-29.3%), and CVS Health (-21.2%) showing significant drops in online visits.","context":["Prescription medications (Rx) are now sold online in 53 of the 94 countries that have ePharmacies.\nSweden remains the top market in ePharmacy penetration in the population with 9.4 online visits per resident in the first semester of 2022.\nApollo Pharmacy in India ranks as the ePharmacy with the biggest traffic growth of 374% at 7.9M av. monthly online visits in the first semester of 2022.\nLast-mile delivery and ePrescription adoption in the consumer healthcare eCommerce industry may create an accelerated growth as consumers and patients vouch for convenience and quicker means to obtain their required medication.\nEven after the pandemic had subsided, the global population continues to visit online pharmacies with an astonishing 5.8 billion online visits being recorded in the first 6 months of 2022 across 94 countries. The data is based on Convert Group‘s latest S1 2022 report on online pharmacy trends. The findings of this global study are available online at epharmacydata.com.\nThis report indicates a significant opportunity for Consumer Healthcare Retailers and Manufacturers to leverage eCommerce for addressing the needs of new online shopper. In 53 countries out of the 94 included in this report, patients can acquire prescription medications online.\nMore online Pharmacies’ highlights of the first semester of 2022 across the world, include:\n- As Amazon Pharmacy gains pace in the industry and the last-mile delivery becomes more essential than ever, the US-based NowRx has partnered with the Korean Hyundai Motor Group to outpace Amazon by providing an out-of-the-box last-mile delivery service to its customers. Brazilian-based RaiaDrogasil is also partnering with Uber to strengthen its delivery services across Brazil. Additionally, UK-based Pharmacy2U also partnered with Royal Mail to distribute NHS prescriptions to patients in the UK.\n- A pivotal move towards online marketplaces becomes evident, with European Shop Apotheke launching its second marketplace, as the eRetailer recognises the potential of the marketplace model in the ePharmacy ecosystem. Additionally, Walmart-backed Indian eCommerce giant Flipkart infused nearly $700M into its marketplace and healthcare unit. Additionally, British Superdrug is also preparing to launch a new marketplace, with premium and start-up brands in September.\n- A global ePharmacy Summit took place this May bringing some of the brightest minds of the industry in Greece.\nRetailers from all over the world are seizing opportunities to enter the ePharmacy industry in the post-pandemic era in an effort to meet patients’ rising needs, distinguish themselves from rivals, and gain extra market share points. Additionally, pharmacists increasingly trial new omnichannel strategies to maintain their place in today’s highly competitive industry.\nKey findings of the research include:\n- 53 out of the 94 countries permit the online ordering of prescription medicine (Rx)\n- 87 out of the 94 countries permit the online ordering of non-prescription medicine (OTC). The only countries prohibiting it are Algeria, Cyprus, Greece, Morocco, Iran, UAE and Turkey.\n- Australia with New Zealand was the region with the highest growth, as online visits grew by +29.9%, followed by Southern Asia with a +25.7% increase and Sub-Saharan Africa with a +17.1% increase. On the contrary, Northern America, which up until this point had been the region leading the pack, recorded a 20.7% drop in growth. This decrease was driven by a massive drop in online visits in leading American retailers like Rite Aid (-51.2%), Walgreens (-29.3%) and CVS Health (-21.2%) in the first semester of 2022, according to Similar Web. The same applies to other regions like Northern Africa, with Chefaa (-44.4%) and Vezeeta (-13.9%), Northern Europe, with Superdrug (-22%) and Boots (-8.7%), and Western Europe, with Medpex (-13.6%) and DocMorris (-11.6%).\n- Sweden was the leading country with 9,416 visits to online pharmacies per 1,000 residents, followed by 6,702 visits per 1,000 residents in Bulgaria, 6,297 visits per 1,000 residents in Norway, and 5,021 visits per 1,000 residents in Australia, leaving the US in the 6th place with 4,656 visits per 1,000 residents and the UK in the 8th place with 4,272 visits per 1,000 residents.\n- Brazil had the most Tier 1 online pharmacies (pharmacies with more than 5M average visits per month in S1 2022) with 6 total for the whole year, followed by Russia, India and USA with 5 each, and the UK and Mexico with 3 each.\n- Apollo Pharmacy, based in India, is the world’s fastest growing ePharmacy, with a +374% Y-o-Y visit growth rate in S1 2022 compared to the same period last year, followed by Russian-based ePharmacy Wer with +112% Y-o-Y visits growth rate and Hong Kong-based Mannings with +78% Y-o-Y visits growth rate. The remaining top 10 fastest growing ePharmacies in ascending order are: Planeta Zdorovo with +76% growth (Russia), Dr. Max with +67% growth (Romania), Apteka April with +58% growth (Russia), Sber Apteka with +55% growth (Russia), Drogaraia with +51% growth (Brazil), Watsons with +50% growth (Philippines) and Shop Farmacia with +46% growth (Italy).\nThe research was carried out by Convert Group, the leading global ePharmacy Data company that Consumer Healthcare & FMCG Manufacturers such as Bayer, Haleon, J&J, L’Oréal, Nestlé, P&G, Perrigo, Pierre Fabre, Reckitt Benckiser, Roche, Unilever, and others trust for their data-driven strategy and sell-out insights on the eCommerce channel. Traffic data for 3.478 Online Pharmacies in 94 countries across all continents was used with permission from Similarweb, the world’s top source of digital market intelligence.\nepharmacydata.com offers the global Consumer Healthcare community insights and data on one of the fastest rising sectors of global eCommerce."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:66ab5f97-2fd7-4199-b08c-e77a1faad81a>"],"error":null}
{"question":"Can both hieroglyphs and African beads be used as communication symbols representing wealth and status?","answer":"Yes, both hieroglyphs and African beads serve as communication symbols for status. In African tribes, beaded jewelry indicates wealth, marital status, and achievements - for instance, women wear beads to show wealth and number of children, while Maasai warriors wear specific arm bands to mark their achievements. Similarly, hieroglyphs were used on important monuments and were understood only by high-status groups in society including officials, doctors, and priests, serving as a mark of elevated social position.","context":["If you have visited Africa and left without seeing or buying any magnificent African beaded jewellery, let me fill you in on what you missed out on… and what you can look forward to next time.\nAfrican beaded jewellery is not just a piece of adornment. It’s so much more than that.\nBeads are integral to the traditions of many tribes across the continent, and taking the time to learn a bit about them can deliver a real insight into these cultures and add more depth and richness to your experience of Africa.\nIf you live here, then you probably see African beaded jewellery and beadwork in many different forms when you visit a local market or while encountering different tribes. But have you ever wondered what these beads symbolise? Here are some interesting facts to pique your interest the next time you encounter beaded jewellery.\nBeads vary in material (bone, glass, horn, seeds, shells, stones and fossilised materials), their significance, colour, size, and their placement on the body or clothing. All these denote and evoke different meanings in different tribes. In most African tribes, beads embody beauty, tradition or culture, strength, marital status, age, power and warrior-hood.\nThey have also been used as a form of currency. Trade beads can be dated as far as the 15th century, when European trading ships would travel to West Africa to draw on resources such as gold, ivory, palm oil and slaves. At the time, glass bead making technologies were more sophisticated in Europe, which made these colourful beads very attractive and highly valued to the African elite who were willing to accept the beads as a form of exchange.\nThe Maasai, Samburu, Turkana and Rendille tribes are highly associated with beadwork in Kenya. They can be found in Kenya’s northern Great Rift Valley. Some of their notable characteristics are the elaborate African beaded jewellery encircling their necks, red-painted chins with ochre, beaded headdresses, stacked beaded bracelets jangling on their wrists, and to the married ones, heavy brass earrings.\nThe women in these tribes wear these beaded pieces as a sign of wealth, marital status, health and to denote the number of children they have. For instance, if a woman’s first child is a boy, she wears many earrings. The same applies for women with several male children. Similarly, traditional wedding collars have several beaded strands hanging off them. This represents the amount of dowry paid for that bride, which in most cases takes the form of cattle.\nWomen wear these pieces as a sign of beauty and wealth while men wear beaded pieces and different symbols on different parts of their bodies to mark their achievements. For instance, young Maasai warriors wear an arm band, known as the “errap”, made of leather and metal wire coils, which shows that he has fought and killed another man.\nTo girls, a crimson collar of beads is given to her by her father which indicates that a husband has already been chosen for her, but she is not yet engaged. Once engaged, the crimson collar will come off and is traded for brass earrings, which signifies marriage.\nEach colour bead represents a specific and significant aspect of their culture, however these may vary from tribe to tribe.\nIn general, blue beads symbolise the colour of the sky which provides water for the people and cattle, hence sustenance and energy.\nGreen represents the land and pastures that produces food, which gives nourishment to the people and animals.\nRed mirrors the colour of blood, symbolising danger, bravery, strength, challenges and unity.\nBlack reflects the colour of the people which symbolises their daily hardships and represents harmony and solidarity.\nWhite portrays the colour of milk from cows which provides nourishment. It symbolises purity and good health.\nOrange represents the colour of the gourds that store milk which is shared with guests, as well as animal skins which are laid out as beds. It therefore signifies warmth, friendship, generosity and hospitality.\nYellow is the colour of the sun which nurtures the growth of people, animals and grass, hence symbolising fertility and growth.\nNext time you buy African inspired jewellery you’ll be well equipped to share the meaning behind the colours and impress your friends when you wear these beautiful works of art that are skilfully fashioned by these nomadic tribes.\nHow’s that for a fascinating conversation starter?!","Characters used for writing in ancient Egypt, and generally connected to writing on monuments.\nThe word \"hieroglyph\" was not used by the Egyptians themselves, but is a Greek term introduced in the 1st century BCE. \"Hieroglyph\" means \"sacred carving,\" and is a term correctly designating its use on religious monuments (see Ancient Egyptian religion).\nThe Egyptians themselves traced the origin of hieroglyphs back to the god Thoth. At first the Egyptians called the writing system \"pictures;\" later it was elevated to mean, \"writing of God's words.\"\nHieroglyphs are a mixture of picture symbols (ideograms) as well as phonetic characters (phonograms), and were used in a way different from alphabetic writing. The hieroglyphic system is best described as \"rebus\" writing, in which words could be made up of one single hieroglyph or a combination of several hieroglyphs.\nHieroglyphs were pictures, though some pictures are hard to understand. They were written according to the following principles:\n1. A hieroglyph as a picture, f.x. in which a picture represents a \"sun\".\n2. A hieroglyph could also represent or imply a word with a meaning close to the direct translation. The same sign for sun would be read as \"day\" or the sun god, Re.\n3. The consonants of the direct translation of hieroglyphs as symbols could be used for another word with similar consonants. The hieroglyph for \"wood\" had the consonants h and t. Therefore, this hieroglyph could be used for the word hti, meaning \"retreat\" or \"carve.\"\n4. Hieroglyphs could be used to represent single consonants or combinations of consonants in a specific order, regardless of the original meaning.\n5. In cases where there was room for misunderstandings, extra symbols were used to clarify.\n6. Vowels were not written.\n7. Royal names were enclosed in a ring, called a cartouche.\nHieroglypics could be written could be both vertically and horizontally, and in most cases from right to left. It was easy to see what direction had been used for writing, since the symbols turned in the same direction as the writing.\nThe system of hieroglyphic writing used about 700 signs, but after 500 BCE this number multiplied beacuse of the inventiveness by scholars of that period who needed to make their writing easier to read and understand.\nUse and Application\nHieroglyphs were normally written on monuments, like temples and tombs. But there are examples of hieroglyphs used on gravestones, statues, coffins, vessels and implements.\nHieroglyphs could be carved in stone (either as high or bas-reliefs) or applied with paint; cast or incised in metal; or carved in or painted upon wood.\nThere was always a close connection between hieroglyphic writing and fine art. Hieroglyphic writing was more elaborate and required more labour than hieratic script which was used for writing on paper, and it served its purpose best when used as part of the decoration on important monuments. Hieroglyphic writing was only understood by a small group in the society: officials, doctors and priests together with the craftsmen doing the inscriptions.\nA type of hieroglyphs was developed for the Anatolian languages, Hittite, Luwian and Urartian language. Its structure and appearance is quite different from Egyptian, and there is nothing that suggest that Anatolian hieroglyphs depended on Egyptian hieroglyphs.\n30th century BCE: The hieroglyphic system is developed.\n500 BCE: A slow revolution of hieroglyphic writing begins, as new signs are introduced. The number of available signs in the system grows over the centuries from around 700 to several thousand.\n394 CE: The date of the last case of hieroglyphic writing.\nMiddle of 17th century: First attempt to decipher the hieroglyphic system by Athanasius Kircher.\n1799: The Rosetta Stone (see illustration) is discovered, and this became crucial to understanding the system, since it contained the same text in two languages (Egyptian and Greek), and in three writing systems (hieroglyphic, demotic and Greek).\n1822: The French scientist Jean-Francoise Champollion completes the decipherment of the phonetic values of the hieroglyphs. His work rested partly on earlier work performed by Swedish, Johan David Åkerblad, and British, Thomas Young, both of whom manged to decipher some of the hieroglyphs.\nConfused? Try to find a good place to start learning about Ancient Egypt in\nWhere to begin?"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"search_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:e66a30de-86da-42f6-9c77-56ce7600d303>","<urn:uuid:aa78c67a-ed40-4821-9ebf-171941872a61>"],"error":null}
{"question":"What conditions do immunologists and rheumatologists treat, and how prevalent are autoimmune diseases in the population?","answer":"Immunologists treat conditions affecting the immune system, including allergies, immunodeficiency disorders, and autoimmune conditions. Rheumatologists focus on musculoskeletal system conditions and autoimmune diseases like rheumatoid arthritis, Sjögren's syndrome, psoriatic arthritis, and ankylosing spondylitis. Regarding prevalence, autoimmune diseases affect approximately 5% of people and are considered one of the most significant health issues in Australia and New Zealand. Common autoimmune diseases like thyroiditis, rheumatoid arthritis, and diabetes affect more than 1% of people, while conditions like SLE (lupus) affect less than 0.1% of the population.","context":["Published Jun 08, 2022 in healthline.com\nAuthor by Michael O’Regan\nImmunologists and rheumatologists are both internal medicine doctors. While immunologists treat conditions that affect your immune system, rheumatologists specialize in the musculoskeletal system.\nThese two specialties sound pretty different, and you may be wondering why you may have to see both a rheumatologist and an immunologist.\nRead on as we answer other questions you may have about immunologists and rheumatologists.\nDifference between immunology and rheumatology\nImmunologists are also sometimes called clinical immunologists or allergists. They work with all conditions caused by problems with your immune system:\n- different types of allergies like hay fever, food allergies, and eczema\n- immunodeficiency disorders\n- conditions related to allergies, asthma, and immunodeficiency disorders\nRheumatologists are also involved in the diagnosis and treatment of autoimmune conditions. But they’re also involved in conditions that affect the joints, like gout, in addition to your musculoskeletal system:\nConditions treated by rheumatologists include:\n- rheumatoid arthritis\n- Sjögren’s syndrome\n- psoriatic arthritis\n- ankylosing spondylitis\n- inflammatory bowel disease\nWhere does the work of immunologists and rheumatologists overlap?\nEven though there are plenty of differences in what parts of your body immunologists and rheumatologists are concerned with, there are similarities as well. The best example of this overlap is autoimmune diseases.\nAutoimmune diseases often attack your musculoskeletal system, but it’s your immune system that’s responsible for these symptoms.\nAlthough autoimmune diseases can attack any organ in your body, some of the most common autoimmune conditions affect your bones, muscles, and joints. These include:\n- rheumatoid arthritis\n- systemic lupus erythematosus (SLE), or simply lupus\n- psoriatic arthritis\n- Sjögren’s syndrome\n- systemic sclerosis, or scleroderma\nRheumatologists and immunologists often team up to help resolve certain specific symptoms triggered by an autoimmune condition. Additionally, autoimmune conditions often set offTrusted Source allergies, asthma, or eczema. An immunologist can help you manage those.\nWhat are the roles of immunologists and rheumatologists?\nAlthough well-trained immunologists can recognize the symptoms of autoimmune diseases, rheumatologists are usually the go-to doctors when you need an accurate diagnosis. This is because the diagnosis of musculoskeletal autoimmune diseases is quite difficult and requires specialized training.\nOnce diagnosed, your rheumatologist will usually be the one to continue treating your condition. They may refer you to an immunologist if you develop an allergy or another symptom that needs to be checked out.\nIf you’re not sure which doctor you need to see first, you can always start with your primary care physician. These doctors are also trained to recognize the signs of autoimmune diseases and will refer you to the right specialist.\nHow much education and training do immunologists and rheumatologists get?\nRheumatologists and immunologists usually receive similar education, but there are some key distinctions.\nBoth professions complete a 4-year undergraduate degree, attend a 4-year medical school, and finish a 3-year residency in internal disease or pediatrics, depending on whether they want to treat children or adults. This is where similarities end.\nAfter their residency, future rheumatologists must dedicate 2 to 3 years doing a rheumatology fellowship, followed by a certification test confirming their knowledge and skills in rheumatology.\nImmunologists, on the other hand, complete a 2- to 3-year immunology fellowship, which ends with a certification test in immunology.\nBoth immunologists and rheumatologists are required to take continuing medical education courses in their fields of medicine. This is to ensure that doctors stay up to date on the latest medical research and information.\nShould you see an immunologist or a rheumatologist?\nIt can sometimes be hard to figure out which specialist to see when you’re dealing with sudden health issues. Let’s discuss the key symptoms you should look out for when choosing the right doctor.\nWho should see an immunologist\nYou should see an immunologist if:\n- you have persistent allergies lasting several months out of the year\n- your allergies cause other symptoms, like chronic sinus infections or difficulty breathing\n- you have warning signs of asthma like frequent wheezing and coughing (especially after exercise), occasional shortness of breath, or tightness in the chest\n- you’ve been previously diagnosed with asthma, and you have frequent asthma attacks despite taking asthma medications\nKeep in mind that this isn’t a complete list, and your primary care doctor may recommend seeing an immunologist in other cases.\nWho should see a rheumatologist\nYou should see a rheumatologist if:\n- you experience pain in multiple joints, bones, or muscles\n- you have new joint, bone, or muscle pain unrelated to any known injury\n- you have joint, bone, or muscle pain accompanied by fever, fatigue, rashes, morning stiffness, or chest pain\n- you have a chronic illness that other doctors have been unable to diagnose\nMake sure to let your doctor know if you have relatives with an autoimmune or musculoskeletal disease or if your symptoms significantly worsen over a short period.\nOther doctors who specialize in immune system problems\nBecause autoimmune diseases can affect any organ or tissue in your body, there are other doctors you may need to see if you deal with immune system issues. These include:\n- endocrinologists, who diagnose and treat conditions related to your hormones\n- gastroenterologists, or GI doctors, who specialize in gastrointestinal (GI) and liver diseases\n- dermatologists, who are trained to recognize and treat diseases that affect your skin, hair, or nails\n- neurologists, who diagnose and treat nerve problems\n- hematologists, who specialize in diseases that affect your blood\nHow are autoimmune conditions diagnosed?\nThere’s no single test that can diagnose an autoimmune disease, and diagnosis can be a long and stressful journey. Your doctors will use a combination of lab tests, review your and your family’s medical history, and perform a thorough physical exam.\nA lab test called antinuclear antibody test (ANA) is often one of the first tests a doctor might use if they suspect an autoimmune disease. But there are other tests doctors can use to confirm or rule out certain autoimmune conditions.\nHow are autoimmune conditions treated?\nThere’s no cure for autoimmune diseases, but some drugs can control your immune system and bring down pain and inflammation. These include:\n- nonsteroidal anti-inflammatory drugs (NSAIDs) like ibuprofen (Motrin, Advil, Midol) and naproxen (Aleve, Naprosyn)\n- corticosteroids, like prednisone (Deltasone, Prednicot)\n- immunosuppressant drugs\nAfter the acute (initial) illness becomes managed, long-term immune modulation is not always needed. Lifestyle management, like eating a balanced diet and getting regular exercise, may also help you feel better.\nWhile rheumatologists treat diseases of your musculoskeletal system, immunologists focus on your immune system. Both rheumatologists and immunologists can help if you’re dealing with an autoimmune disease that affects your muscles, bones, or joints.\nAlthough there’s no cure for autoimmune diseases, doctors can prescribe drugs to bring down your pain and inflammation.","Autoimmune diseases are a broad range of related diseases in which a person’s immune system produces an inappropriate response against its own cells, tissues and/or organs. This results in inflammation and damage. There are over 80 different autoimmune diseases, ranging from common to very rare. These diseases can be localised to a single organ or tissue, or generalised (systemic), affecting many body organs and tissues.\nAutoimmune diseases include common and rare diseases\nAutoimmune diseases affect around 5% of people and are one of the most important health issues in Australia and New Zealand. Common autoimmune diseases such as thyroiditis, rheumatoid arthritis and diabetes affect more than 1% of people. SLE (lupus) affects less than 0.1% of people and is more common and severe in Indigenous Australians, Polynesians and those with descendants from South East Asia.\nWhat causes autoimmune diseases?\nThe causes of autoimmune diseases are unknown. In many cases it appears that there is some inherited tendency. However other factors such as infections and some drugs may play a role in triggering autoimmune diseases.\nHow are autoimmune diseases diagnosed?\nAutoimmune diseases are usually diagnosed using a combination of clinical history, blood tests (autoantibodies, inflammation, organ function) and other investigations such as x-rays. Sometimes a biopsy of affected tissues may be required for diagnosis.\nLocalised (organ specific) autoimmune diseases\nWhilst localised (organ specific) autoimmune diseases mainly affect a single organ or tissue, the effects frequently extend to other body systems and organs. These diseases are often managed by organ-specific medical specialists, such as endocrinologists, gastroenterologists, neurologists or rheumatologists.\nSystemic autoimmune diseases\nSystemic autoimmune diseases can affect many body organs and tissues at the same time. They can be broadly classified into rheumatological disease and vasculitis disorders (inflammation of blood vessels). These diseases are often managed by clinical immunology/allergy specialists and/or rheumatologists. Vasculitis disorders are relatively rare and result from inflammation of blood vessels. Information on vasculitis is available on the ASCIA website www.allergy.org.au/patients/autoimmunity\nExamples of localised (organ specific) autoimmune diseases\nAddison’s disease (adrenal)\nAutoimmune hepatitis (liver)\nCoeliac disease (gastrointestinal tract)\nCrohn’s disease (gastrointestinal tract)\nDiabetes Mellitis Type 1a (pancreas)\nGrave’s disease (thyroid)\nGuillain-Barre syndrome (nervous system)\nHashimoto’s thyroiditis (thyroid)\nMultiple sclerosis (nervous system)\nMyasthenia gravis (nerves, muscles)\nPernicious anaemia (stomach)\nPrimary biliary cirrhosis (liver)\nSclerosing cholangitis (liver)\nUlcerative colitis (gastrointestinal tract)\nExamples of rheumatological systemic autoimmune diseases\nAntiphospholipid antibody syndromes (blood cells)\nDermatomyositis (skin, muscles)\nMixed connective tissue disease\nPolymyalgia rheumatica (large muscle groups)\nPolymyositis (skin, muscles)\nRheumatoid arthritis (joints, less commonly lungs, skin, eyes)\nScleroderma (skin, intestine, less commonly lungs, kidneys)\nSjögren’s syndrome (salivary glands, tear glands, joints)\nSystemic Lupus Erythematosus (skin, joints, kidneys, heart, brain, red blood cells, other)\nTreatment options for autoimmune diseases\nCurrently there are no cures for autoimmune diseases, although there is a wide range of treatment options, which depend on the stage and type of autoimmune disease. The main aims of treatments for autoimmune diseases are to relieve symptoms, minimise organ and tissue damage and preserve organ function.\nTreatment options include:\n- Replacement of end organ functions (such as insulin in diabetes and thyroxine in autoimmune thyroid disease)\n- Non-steroidal anti-inflammatory medications (NSAIDS)\n- Corticosteroid anti-inflammatory medications (such as Prednisolone)\n- Immunosuppressive medications\n- Therapeutic monoclonals (such as TNF inhibitors)\n- Immunoglobulin replacement therapy.\nWhat happens if I have an autoimmune disease?\nThere are many different autoimmune diseases with different treatments and consequences for people with these diseases. It is important to find out as much as possible about your autoimmune disease by asking questions of your treating doctor.\nThere are also many patient support organisations and foundations that offer information and support.\nSome of these are listed on the ASCIA website www.allergy.org.au/patients/patient-support-organisations\nYou can learn about autoimmune disease from books and the internet, however you need to be aware that what is actually written may not apply to you, and you should always check the information with your doctor.\n© ASCIA 2017\nASCIA is the peak professional body of clinical immunology/allergy specialists in Australia and New Zealand\nPostal address: PO Box 450 Balgowlah NSW 2093 Australia\nThis document has been developed and peer reviewed by ASCIA members and is based on expert opinion and the available published literature at the time of review. Information contained in this document is not intended to replace medical advice and any questions regarding a medical diagnosis or treatment should be directed to a medical practitioner. Development of this document is not funded by any commercial sources and is not influenced by commercial organisations.\nContent updated 2017"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"search_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:2a049e3e-2582-4dc0-8ea1-2d4760bdcb02>","<urn:uuid:0958a839-9160-4cc7-8633-198854819f9e>"],"error":null}
{"question":"How many items did Judith Merril initially donate to create the Merril Collection?","answer":"Judith Merril donated 5,000 items in 1970 to start the Merril Collection of Science Fiction, Speculation and Fantasy at Toronto Public Library.","context":["Science fiction. It’s a genre that is loved by many, but largely misunderstood. The question “Can you recommend a good science fiction book?” has struck fear into the heart of many a librarian. This year at the Readers’ Advisory Committee’s annual RA in a Day conference, we decided to tackle this tough genre once and for all.\nRA in a Day is an annual one-day conference that brings some of the best readers’ advisory advocates together to share their knowledge and expertise on meeting the needs of adult readers.\nLorna Toolis, head of the Merril Collection of Science Fiction, Speculation and Fantasy at Toronto Public Library, was our first speaker of the day. Lorna spoke about the history of the Merril Collection. This collection began in 1970 with a donation of 5,000 items from science fiction author Judith Merril and has grown to include over 72,000 items. Lorna gave a great overview of the various subgenres that fall under the science fiction umbrella, including space opera, steampunk and space westerns, just to name a few!\nA panel discussion followed about the past, present and future of the science fiction genre. Chris Szego, manager of Bakka-Phoenix Books (a well-known science fiction speciality bookstore in Toronto) and Julie Czerneda, a science fiction author with fourteen novels in print, were our panelists. Chris and Julie shared great insights about current trends in sci-fi, how to market the genre, and how science fiction has evolved over the years (hint: Harry Potter changed everything!) They also shared some great reading suggestions for a variety of audiences.\nMadeline Ashby was our lunchtime speaker. Madeline is an accomplished writer, having written numerous short stories, essays, and books. Her 2016 book Company Town, a futuristic murder-mystery thriller, was shortlisted for Canada Reads 2017 and was championed by Measha Brueggergosman. By day, Madeline has the coolest-sounding job ever: she is a futurist, working with companies and businesses to plan for future potential scenarios. Madeline spoke to the group about her own experiences as a science fiction writer, how her interest in forecasting helps her imagine dystopic, futuristic worlds, and how the science fiction community has supported and inspired her. Madeline also shared her experience as a participant in Canada Reads, and how it feels to be an American living in Canada.\nSam Maggs was the keynote speaker at the end of our sci-fi day. Sam is a self-described “geek girl,” assistant writer of video games at Bioware, and author of two books, The Fangirl’s Guide to the Galaxy and Wonder Women: 25 Innovators, Inventors and Trailblazers Who Changed History. Sam read two excerpts from Wonder Women, inspirational stories about little known women who did great things. She shone the spotlight on:\n- Anandibai Joshi, one of the first Indian female physicians\n- Sarah Emma Edmonds, a Canadian female spy for the Union army.\nTo find out more, read Sam’s book. Sam also shared her experiences being a woman in the world of video games, and gave a swath of great recommendations for everything from books to video games.\nLast but certainly not least, we put together our Best Bets in science fiction and speculative fiction and shared them with the group–check it out.\nPhoto credit: Jennifer Green\nKristen Caschera is the Information Services Librarian at London Public Library. She sits on the OPLA Readers’ Advisory Committee and is a member of the LoanStars steering committee. She can be reached at kristen.caschera @lpl.ca."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:67079ee5-b81d-4880-9b2f-45d4de081a1d>"],"error":null}
{"question":"For my research paper: What are the similarities between the factors driving extreme climate events identified in climate science studies and the variables considered in modern climate prediction models?","answer":"Both climate science studies and modern prediction models recognize three key convergent factors: 1) The fundamental role of greenhouse gas impacts through radiative transfer physics, 2) The disruption of Earth's climate system affecting water, food, and resources, and 3) The close agreement between model predictions and observed changes. The prediction models specifically account for natural variability and human influences by incorporating observations of current climate states, including sea surface temperatures, subsurface ocean conditions, and atmospheric parameters. Both approaches also emphasize the interaction between weather shocks, exposure, and vulnerability in driving extreme events like heat waves, droughts, and floods.","context":["Drought, flood, fire — these are the extreme weather events we fear, as our human capacity to fight them is so limited. In the last 5 years alone, extreme heat waves, floods, droughts, and wildfires have cost significant financial and personal harm as the population and economies expand and the planet rapidly warms.\nBut early warning systems can anticipate these disasters. If constituents like cleantech entrepreneurs and others have a data-driven climate change toolkit that demonstrates the influence of climate change on real-world weather and climate extremes, we can learn a lot about our planet — and possibly save it. We can cut away inefficiency, develop new green technologies, and build a more sustainable future .\nThe need for this effort is profound, as the author of a new book argues.\nTold in first person narrator, Drought, Flood, Fire: How Climate Change Contributes to Catastrophes, by Chris Funk, is a readable climate science data collection. At the US Agency for International Development’s Famine Early Warning Systems Network (FEWS NET), Funk works every day on predicting and monitoring climate hazards. Funk diagnoses the factors driving extreme events in order to improve the capacity to monitor and predict them, pointing out that the impacts of climate change are arising through the “potentially explosive interaction” of weather shocks, exposure, and vulnerability.\nRight now we appear to be headed for a 3 degree C. of warming or more, Funk points out, and this level “would almost certainly have catastrophic and potentially irreversible impacts on our planet’s life support system.”\nThe Data Behind Climate Change & Catastrophe\nOutside our windows sunlight streams down; climate scientists study where that energy goes, what it does, and how it moves through the Earth system. The sun supplies a constant source of high-quality energy, and this energy supports and maintains gradients of many kinds:\n- temperature and pressure gradients that drive our atmospheric winds and ocean currents\n- chemical gradients that help support the evolving complexity of life\nWhile the perils of natural disasters are not new to humankind, it’s important to remember that life on Earth has only been possible due to a series of delicate balances that arise at all scales of the universe. Funk describes how the Earth occupies a “fortuitous middle ground in the atmospheric arena,” with just the right kind of atmosphere to protect us from the worst impacts of high-energy radiation and enough of a greenhouse gas effect to bring us up to a comfortable average temperature.\nAdmitting that “I’m fantastically and fatalistically addicted to data,” Funk uses this fascination to demonstrate that warming won’t just manifest as a smooth, low-frequency increase in ocean and atmospheric temperatures. Instead, the author outlines how we’ll see the results of more intense weather and climate extremes — stronger heat waves, droughts, and floods, as well as more intense climate anomalies like El Niños and La Niñas. In fact, the relative contributions to annual emissions have changed dramatically. Between 2000 and 2019, global carbon emissions increased by 50%. Funk says “we are literally stepped on the gas pedal (or coal pedal, actually).”\nUnderstanding how humans can so radically alter the atmosphere so quickly begins with understanding that the atmosphere is extremely thin, says Funk, as well as to differentiate between the atmosphere’s volume and its mass. When we recognize the Earth’s delicate balance, we can see why dumping 37 gigatons of carbon dioxide into our atmosphere is, according to Funk, “like 5 people chain-smoking in a small car with the windows rolled up. This is not going to end well, and it is not going well now.” These extremes feed conflict and substantially reduce worker productivity.\nThe Intergovernmental Panel on Climate Change (IPCC) Fifth Assessment Report examines the factors contributing to the rapid acceleration of emissions over the last decade, citing 3 primary lines of evidence.\n- Greenhouse gas impacts originate from the basic physics of radiative transfer.\n- We are experiencing a huge disruption in our climate, and this disruption will manifest itself in the 21st century just as population growth and increasing demands for water, food, and resources place unprecedented strains on our Earth’s ecosystems.\n- Agreement between climate model predictions and observed changes is very close, so, if we continue to emit greenhouse gases at an accelerating rate, then 21st century global warming will be “dramatic, dangerous, and disruptive.”\nFunk calls upon 3 separate but convergent sources of observational evidence: terrestrial air temperature records, observations of sea surface temperatures, and observations of global sea levels. There is solid observational and model-based evidence supporting the link between a warming atmosphere and more extreme precipitation extremes — such as strong and very rainy hurricanes and cyclones — and clear evidence that these extremes are having deadly and costly impacts today.\nFunk says that modest and aggressive reductions in emissions will limit increases in these human catastrophes and attendant human suffering. Including many personal stories about drought, flood, and fire that demonstrate the impact of climate change on humans, sidebars that examine topics in specific detail, images of extreme weather impacts, and graphics that capture evidence-based conclusions, the book offers much evidence that our increased wealth, combined with our increased population, has led to massive increases in greenhouse gas emissions.\nYet Funk concludes the book by arguing that, just as humanity has tackled famine and infant mortality, “so, too, fighting climate change is very much in reach. We can be both wealthy and wise,” the author offers, by investing in highly efficient, high-tech, highly renewable energy. Associated investments in education, infrastructure, and worker education create a sustainable, lucrative, and equitable economy in which many people have good paying jobs.\nFunk points to some of the suggestions contained within the IPCC Impacts of Global warming of +1.5C report as mechanisms to “seriously tackle climate change.”\n- Reducing carbon and methane emissions by 45% by 2030, reaching zero emissions by 2050\n- Switching very rapidly to renewable energy sources\n- Rapidly improving the efficiency with which we use energy\n- Stopping the burning of coal\n- Switching to biofuels\n- Planting billions of trees to absorb more CO2\n- Increasing investments in low-carbon energy sources and increased energy efficiency\n- Taking an “all of the above” approach — simultaneously pursuing reductions in emissions, increases in efficiencies, and increases in terrestrial carbon uptake\nThe last paragraph of the book contains a reminder that the stories about drought, flood, and fire we tell each other matter and can coalesce into positive change.\n“We need to act coherently and quickly to avoid rapid warming. We need to see and understand climate change as something that is hurting people and our planet now. We have been blessed with a miraculous planet, and the opportunity to live through an exciting and momentous time, filled with increasing prosperity and innovation. We can wear the White Hat. Compassion and logic demand that we do so. The great spiritual leaders taught us that ‘peace is a verb,’ telling us stories that eventually led to unprecedented peace and prosperity. We need to make peace with our planet. Climate change is hurting people and our planet; we need to act to prevent that, and we can afford to do so.”\nDon't want to miss a cleantech story? Sign up for daily news updates from CleanTechnica on email. Or follow us on Google News!\nHave a tip for CleanTechnica, want to advertise, or want to suggest a guest for our CleanTech Talk podcast? Contact us here.","Outlook for global climate in the coming years\nForecast issued January 2021. The forecast will next be updated in 2022 and will be issued via the WMO Lead Centre for Annual and Decadal Prediction. Further discussion and background information can be found in this research news article.\nDecadal forecasts, also called ‘near-term’ climate predictions, range up to a decade ahead. Predictions account for natural variability and climate change as these are expected to be of similar size in many parts of the world over this forecast period. Forecasts are experimental, so at this early stage of development expert advice is needed to assess the skill and reliability of regional predictions\n- Long-range forecasts are unlike weather forecasts for the next few days\n- Forecasts are for a range of possible conditions over a wide region and time period\n- Averaged over the five-year period 2021-2025, forecast patterns suggest enhanced warming over land, and at high northern latitudes. There is some indication of continued cool conditions in the Southern Ocean. Current relatively cool conditions in the north Atlantic sub-polar gyre are predicted to warm, with potentially important climate impacts over Europe, America and Africa.\n- During the five-year period 2021-2025, annual global average temperature is expected to remain high and is very likely to be between 0.91°C and 1.61°C above the pre-industrial period from 1850–1900.This compares with an anomaly of +1.16±0.1°C observed in 2016, currently the warmest year on record. In the absence of a major volcanic eruption a new record is likely in the coming 5 years. There is a small but increasing (~25%) chance of one year temporarily exceeding 1.5°C, and this will be updated in April using multi-model forecasts and revised observations. These high global temperatures are consistent with continued high levels of greenhouse gases.\nDecadal forecasts are designed to predict fluctuations in the climate system over the next few years. They take into account natural variability as well as human influences. This is achieved by initialising climate models with observations of the current climate state, in addition to specifying changes in radiative forcing due to greenhouse gases, aerosols (both volcanic and anthropogenic), and solar variability. Further details can be found in a Met Office article about the basis of decadal forecasting.\nThe latest Met Office decadal forecast presented here was started from the observed sea surface temperature pattern shown in Figure 1, along with similar observations of temperature and salinity below the ocean surface, atmospheric winds, temperatures and surface pressure. The temperatures in Figure 1 show warm conditions in many regions, especially at high northern latitudes, relatively cool conditions in parts of the Southern Ocean, and a La Niña with cool conditions in the eastern Pacific.\nObserved sea surface temperature\nFigure 1: Observed sea surface temperature differences (°C) relative to 1981-2010 for October 2020. These, together with similar observations below the ocean surface, have been used as starting conditions for the decadal forecast.\nThe maps below (Figure 2) show predicted temperatures over the period November 2020–October 2025 relative to 1981-2010 averages. Diagram A shows the most likely forecast outcome. Diagrams B and C indicate the range of forecast temperatures, such that we expect only a 10% chance of temperatures at particular locations being less than those in B, and only a 10% chance of temperatures higher than in C. Note that these ranges are for each individual location. The chances of these limits being met everywhere are very small, so the complete patterns shown in diagrams B and C are very unlikely to be realised.\nFive-year mean forecast: mean, lower and upper estimates\nFigure 2: Forecast (A) of surface temperature differences (°C) relative to 1981-2010 for the 5-year period November 2020 to October 2025. Forecasts consist of 10 ensemble members starting from November 2020. The probable range is diagnosed from the ensemble spread, and shown as the lower (B) and upper (C) limits for each 5° grid box, such that there is a 10% chance of the observations being cooler than (B), and a 10% chance of the observations being warmer than (C). Note that the actual anomaly patterns in (B) and (C) are unlikely to occur since extreme fluctuations would not be expected at all locations simultaneously.\nSpatial patterns suggest enhanced warming is likely over much of the globe, especially over land and at high northern latitudes. Uncertainties in the forecast are considerable: for the period 2021-2025 most regions are expected to be warmer than the average of 1981 to 2010, but regional cooling is possible – especially over parts of the Southern Ocean. Further forecasts from other international modelling centres are available from the WMO Lead Centre for Annual to Decadal Prediction.\nDuring the five-year period 2021-2025, annual global average temperature (see blue shading in Figure 3 below) is expected to remain between 0.91°C and 1.61°C (90% confidence range) relative to pre-industrial conditions represented by the period 1850 to 1900 (0.30°C to 1.00°C above the 1981-2010 mean). There is a small but increasing (~25%) chance of one year temporarily exceeding 1.5°C, and this will be updated in April using multi-model forecasts and revised observations. The warmest individual year in more than 160 years of Met Office Hadley Centre (HadCRUT4), National Oceanic and Atmospheric Administration (NOAA) and National Aeronautics and Space Administration (NASA) global temperature data is 2016 with a temperature of 1.16 ± 0.1 °C relative to pre-industrial conditions. In the absence of a major volcanic eruption a new record is likely in the coming five years. Averaged over the whole five-year period 2021-2025, global average temperature is expected to be between 1.20°C and 1.46°C above pre-industrial conditions (0.59°C to 0.85°C above the 1981-2010 mean).\nGlobal annual temperature\nFigure 3: Observed (black, from Met Office Hadley Centre, GISS and NCDC) and predicted (blue) global average annual surface temperature difference relative to pre-industrial conditions represented by the period 1850-1900. Previous predictions at 5-year intervals starting from November 1960 and through to 2010 are shown in red. 22 model simulations, from the Coupled Model Intercomparison Project phase 5 (CMIP5), that have not been initialised with observations are shown in green. In all cases, the shading represents the probable range, such that the observations are expected to lie within the shading 90% of the time. The most recent forecast (blue) starts from November 2020. All data are rolling 12-month mean values. The gap between the black curves and blue shading arises because the last observed value represents the period November 2019 to October 2020 whereas the first forecast period is November 2020 to October 2021. An observed offset based on the average of HadCRUT4, NOAA and NASA data is used to relate the forecasts to the period 1850-1900.\nThe forecast is for continued global warming largely driven by continued high levels of greenhouse gases. However, other changes in the climate system, including longer term shifts in both the Pacific Decadal Oscillation (PDO) and Atlantic Multidecadal Oscillation (AMO), are also contributing. Near record temperatures are predicted during the coming five years, although La Niña is likely to depress temperatures slightly in 2021, consistent with the Met Office annual global temperature forecast. After the first year the forecast remains towards the mid to upper end of the range simulated by CMIP5 models that have not been initialised with observations (green shading in Figure 3). Barring a large volcanic eruption or a very sudden return to negative PDO or AMO conditions (which could temporarily cool climate), ten year global average warming rates are very likely to be similar to late 20th century levels over the next few years.\nVerification of previous forecast\nThe following maps (Figure 4) compare observed (A) and forecast (B, issued in January 2016) surface temperatures (°C) for November 2015 to October 2020 relative to the 1981-2010 long-term average. Forecasts were made starting from November 2015 using the version of our forecast system at the time. Stippling shows regions where the observed temperatures lie outside the 5-95% range of the forecast.\nObservations and five-year mean forecast from November 2015\nFigure 4: Observed (A) and issued forecast (B) of surface temperature differences (°C) relative to 1981-2010 for the 5-year period November 2015 to October 2020. Forecasts consist of 10 ensemble members starting from November 2015. The stippling shows where the observations lie outside of the 5-95% confidence interval of the forecast ensemble.\nThe forecast issued five years ago predicted enhanced warming over high northern latitudes, and cooling in parts of the Southern Ocean. Although there are some differences in the precise magnitude and location of anomalies, the observations generally lie within the forecast uncertainty range. However, the forecast was generally warmer than observed in parts of the Southern Ocean, the North Atlantic sub-polar gyre, the Arctic and the east Pacific, and cooler than observed over parts of the Arctic. The 5-year average global temperature for the period 2016-2020 was forecast to be between 1.02°C to 1.27°C relative to pre-industrial conditions and compares well to the observed value of 1.11°C."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:f55b898d-2fc4-4c24-835e-dfb9a841f912>","<urn:uuid:aa77101b-18f4-4ca5-992b-40939ab2a81b>"],"error":null}
{"question":"What is Lewis Hamilton's best qualifying position at the Mexican Grand Prix?","answer":"Lewis Hamilton has taken pole position in 2016 and has never failed to qualify in the top three in Mexico City.","context":["Four drivers have scored on every appearance at the Mexican Grand Prix, seven drivers have a 100% Q3 appearance rate and Max Verstappen is the only driver to have taken consecutive wins at the track in its World Championship history. Here’s everything you need to know about each driver’s history at the Mexican Grand Prix!\n🇬🇧 Lewis Hamilton\nDespite clinching his last two World Championships at the Mexican Grand Prix, Lewis Hamilton hasn’t finished on the podium at the event since he won in 2016. He also finished on the podium in 2015, with second place. Hamilton has a 100% points scoring record at the track, with a worst finish of ninth in 2017. Hamilton has never failed to qualify in the top three in Mexico City, having taken pole position in 2016 and having started from the front row in 2015. 2015 is the only season where Hamilton has been out-qualified by a team-mate here. Hamilton is yet to finish the Mexican Grand Prix in a better position than where he started from.\n🇫🇮 Valtteri Bottas\nValtteri Bottas has finished on the podium twice at the Mexican Grand Prix, with a best finish of second place in 2017. The Finn has a 100% points-scoring finish rate at the track, and is yet to finish outside the top eight. Bottas also holds a 100% Q3 appearance rate here, but is yet to qualify within the top three. He qualified a best of fourth in 2017. He has never finished in a lower position than where he started, gaining a best of three positions in 2015. Bottas is yet to lead a lap at the circuit and is yet to out-qualify Lewis Hamilton here.\n🇩🇪 Sebastian Vettel\nIt’s fair to say that the Autodromo Hermanos Rodriguez has been a bit of a bogey track for Sebastian Vettel. In 2015, a puncture on the first lap following contact with Daniel Ricciardo left him way down the field, he then spun later in the race at Turn 7 before crashing out at the same turn some laps later. 2016 is memorable for his expletive-laden radio rant after Max Verstappen overtook him off circuit. He stood on the podium, but was later demoted to fourth due to moving under braking when defending from Ricciardo. In 2017, after qualifying on pole, Vettel made contact with Lewis Hamilton on the first lap and had to pit. He fought back to fourth to record his best finish so far in Mexico, then bettered that result last year with a second place finish. 2016 is the only season where Vettel has been out-qualified by a team-mate at the circuit. He has led sixteen laps in total here – twelve in 2016 and four in 2018.\n🇲🇨 Charles Leclerc\nOn his first appearance at the Mexican Grand Prix last year, Charles Leclerc finished seventh. He out-qualified his team-mate and reached Q3, qualifying in ninth place. He made up two places during the race to bring home six points for the Sauber team.\n🇳🇱 Max Verstappen\nMax Verstappen has won both of the last two Mexican Grands Prix. He has a 100% finish record at the circuit, with a worst finish of ninth in 2015. He very nearly took pole last season, but was beaten by team-mate Daniel Ricciardo by just 0.026 seconds. It was the first time he has been out-qualified by a team-mate at the circuit. Verstappen has lined up on the front row of the grid at the event in the last two seasons, while 2015 is the only time he hasn’t started within the top three. He has a 100% Q3 appearance rate at the track. Verstappen lost one position in each of his first two races at the track, and has gained a position from where he started in each of the last two seasons. Verstappen has led over double the number of laps of any other current driver in Mexico.\n🇹🇭 Alexander Albon\nAlexander Albon has no past racing experience in Mexico.\n🇦🇺 Daniel Ricciardo\nDaniel Ricciardo secured his third and most recent Formula 1 pole position at last year’s Mexican Grand Prix. He was unable to win though, and retired with hydraulic issues. It was his second consecutive retirement at the track, having also been out after five laps in 2017 with turbo issues. His best finish here is third, which he inherited as a result of penalties for other drivers. While Ricciardo has never failed to reach Q3 at the circuit, last year marked the first time he has qualified in the top three at the circuit. Last season was also the first time he has out-qualified a team-mate in Mexico City.\n🇩🇪 Nico Hulkenberg\nNico Hulkenberg recorded his best Mexican Grand Prix result so far last season with sixth place. Prior to that, he had two seventh place finishes plus a DNF in the 2017 race. Hulkenberg has a 100% Q3 appearance rate at the track, qualifying a best of fifth in 2016. He has started from seventh on the grid in each of the last two years and has out-qualified his team-mate at the track in all of the last three seasons.\n🇫🇷 Romain Grosjean\nRomain Grosjean has scored just one point at the Mexican Grand Prix, with a tenth place finish in 2015. He has a 100% finish rate at the circuit, but is yet to score here with Haas. The Frenchman has never reached Q3 at the track and has been eliminated in Q1 in all of the last three years. Grosjean is yet to finish the Mexican Grand Prix in a lower position than where he started from, gaining a best of two places in both the 2015 and 2018 events.\n🇩🇰 Kevin Magnussen\nFrom his three previous appearances at the Mexican Grand Prix, Kevin Magnussen has scored only once. That was with an eighth place finish in 2017. Like his team-mate, he has a 100% finishing record at the track. He too has never reached Q3 here, and has been eliminated in Q1 in both of the last two seasons. Last year marked the first time Magnussen has been out-qualified by a team-mate in Mexico City. His best qualifying position here is fourteenth in 2016, though he also lined up fourteenth on the grid in the following season. The most positions Magnussen has gained in a race at the track is six, which happened on his only points-scoring appearance in 2017.\n🇪🇸 Carlos Sainz\nCarlos Sainz is yet to score a point at the Mexican Grand Prix and has retired in both of the last two seasons. His best finish here came in 2015 with Toro Rosso, when he finished thirteenth. Despite never scoring, Sainz has qualified in the top ten in all of the last three years, qualifying a best of eighth in 2018. 2016 is the only season where he’s out-qualified a team-mate at the track.\n🇬🇧 Lando Norris\nLando Norris made his first outing at the Autodromo Hermanos Rodriguez last season, when he took part in Free Practice 1 with McLaren.\n🇲🇽 Sergio Perez\nSergio Perez recorded his first home retirement at last year’s Mexican Grand Prix. He had scored points on every appearance before that, with a best finishing position here so far of seventh, scored in 2017. Perez has reached Q3 twice and has been eliminated in Q2 twice. His best qualifying position here is ninth in 2015, though he also started from ninth in 2017. 2015 is the only time that Perez has out-qualified a team-mate at the track. Before his retirement last year, the Mexican had gained at least one position from where he started in all of his home races.\n🇨🇦 Lance Stroll\nLance Stroll finished sixth on his first appearance at the Mexican Grand Prix, but was unable to finish in the top ten last year, coming home twelfth for Williams. He’s yet to reach Q3 at the track, with a best qualifying position of twelfth in 2017. He out-qualified his team-mate here for the first time last year. The Canadian has gained five positions from where he started in both of his Mexican Grand Prix appearances so far.\n🇫🇮 Kimi Raikkonen\nKimi Raikkonen’s coming together with fellow Finn Valtteri Bottas in 2015 marks his only DNF so far at the Mexican Grand Prix. Raikkonen has finished on the podium in Mexico in each of the last two seasons. 2015 is the only year where Raikkonen has failed to reach Q3 at the track, while 2016 is the only time that he has out-qualified his team-mate. His best qualifying position here is fifth in 2017. Raikkonen is yet to finish in a position worse than where he started in the three races which he’s completed at the track.\n🇮🇹 Antonio Giovinazzi\nAntonio Giovinazzi has made two F1 appearances in Mexico. He competed in Free Practice 1 here with Haas in 2017, and with Sauber in 2018.\n🇷🇺 Daniil Kvyat\nDaniil Kvyat has appeared at the Mexican Grand Prix twice previously. He has a best finishing position of twelfth at the circuit in 2015, and finished a lowly eighteenth in the following year. Kvyat has qualified in the same position as where he finished in both of his appearances so far. He out-qualified his team-mate in 2015, but was out-qualified in 2016.\n🇫🇷 Pierre Gasly\nPierre Gasly has appeared twice at the Mexican Grand Prix, and scored his first point at the track last year. He’s yet to appear in Q3 here, having qualified last in 2017 and fifteenth in 2018. Gasly has been out-qualified by his team-mate in both of his appearances at the Mexican Grand Prix. As a result of his low starting positions, the Frenchman has been able to gain places in both of his races at the track. He made up seven places in 2017 and ten places in 2018.\n🇵🇱 Robert Kubica\nThis weekend will be Robert Kubica’s first appearance at the Mexican Grand Prix.\n🇬🇧 George Russell\nGeorge Russell is yet to race in Mexico City.\nEnhance your viewing experience of the 2019 Mexico Grand Prix and track your favourite drivers with F1 TV.\nAfter graduating in 2015 with a First Class honours degree in English Language and Literature, Nicky Haldenby, a lifelong fan of Formula 1, founded the Lights Out F1 Blog in 2016. Now in its sixth season, the blog has become a firm fan-favourite, delving deep into the sport’s history books and lifting the cover on unusual F1 statistics. Nicky also writes at F1Destinations and GPDestinations. In 2017 and 2018, he wrote for Badger GP. Nicky is also the host of the F1 Rewind Podcast and can be heard as the resident stats man on the 2 Soft Compounds Podcast."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:301f544d-b05f-4534-8c97-bbb5a814395d>"],"error":null}
{"question":"Does marketing and B2C marketing differ in their primary goal regarding customer relationships?","answer":"No, both marketing and B2C marketing share a fundamental focus on customer relationships. Marketing is described as consumer-oriented, revolving around fulfilling the needs, wants, and demands of customers while making profits. Similarly, B2C marketing works on understanding customers' buying habits and solving their precise problems, with both approaches ultimately aiming to develop and maintain strong customer relationships through value delivery and satisfaction.","context":["Contrary to what most people think, marketing isn’t just about communicating and informing about the brand and its offering, but everything that’s involved in developing the offering, promoting it, selling it, and making the customer buy it (and rebuy it).\nIt doesn’t revolve around the product. Marketing revolves around the customers. This process focuses on exploring, creating, and developing an offering that fulfils the needs, wants, and demands of the customers while helping the business make sustain and gain.\nBut what exactly is marketing, and why is it important?\nLet’s find out.\n- 1 Marketing Definition\n- 2 What Is The Purpose Of Marketing?\n- 3 What Is The Importance Of Marketing?\n- 4 What Are The Objectives Of Marketing?\n- 5 The Four Principles Of Marketing\n- 6 Nature Of Marketing\n- 7 Types Of MarketingScope Based On Entities Marketed\n- 8 Scope Of Marketing\n- 9 Marketing Vs Sales\n- 10 Marketing Vs Advertising\nMarketing is a process or a set of processes used to understand the target audience better, develop a valuable offering, communicate and deliver value to satisfy the needs, wants, and desires of the target audience at a profit.\nIn simple terms, marketing is an umbrella that includes –\n- Identifying the unfulfilled needs, wants, and desires of the target market,\n- Developing a valuable offering that satisfies the unmet needs,\n- Communicating the value to the target audience,\n- Delivering value to meet the needs, wants, and desires of the customers, and\n- Earning a profit.\nA simple definition of marketing would be, as Kotler puts it, “meeting the needs of your customer at a profit.” Thus, marketing involves everything that a business requires to meet the needs of its customers, and that too, at a profit.\nBesides this, other institutes and renowned personalities define marketing as –\nThe activity, set of institutions, and processes for creating, communicating, delivering, and exchanging offerings that have value for customers, clients, partners, and society at large.American Marketing Association (AMA)\nThe science and art of exploring, creating, and delivering value to satisfy the needs of a target market at a profit.Dr Philip Kotler\nThe management process responsible for identifying, anticipating and satisfying customer requirements profitably.Chartered Institute of Marketing (CIM)\nWhat Is The Purpose Of Marketing?\nContrary to what most people believe, the purpose of marketing isn’t limited to selling the offering. Considering there are seven functions of marketing ranging from product development to pricing to selling, marketing pertains to all aspects of the business and works on fulfilling the three core purposes of the business –\n- Identification of the goals and needs of the customers,\n- Development of offerings that provide value to the customers, and\n- Communication and sale of the product to earn profit.\nWhat Is The Importance Of Marketing?\nMarketing is essential because it helps the business consider the customer as its focal point and develop a sustainable business that provides value to society.\nIt is the heart of the business which collects information from the outside, filter it, and convert it into specialized strategies which help the business fulfil the customer requirements while making profits.\nMarketing is important because it flows among all the departments of the business including product development, distribution methods, sales, and advertising, and makes the business follow a holistic approach –\n- It enquires: It is through market research that business understands the actual needs, wants, and desires of the customers.\n- It builds: Marketing helps the business produce what is actually needed in the market.\n- It informs and engages: Communicating about the brand and the offering is a huge role that marketing plays.\n- It sells: Marketing is important because it helps the company to sell its offerings. It helps the company to make money by attracting customers, making them buy the offering, and reaching the set end goals.\n- It sustains: Marketing makes sure the company and its offering sustain for the long run by adapting to the changes in the business environment.\n- It builds identity: Marketing builds identity.\n- It grows: Marketing is an essential function to ensure the smooth growth of the business. It helps the business expand its customer base, increase sales, and build a brand.\nWhat Are The Objectives Of Marketing?\nThe main objective of marketing is to fulfil customers’ demands while making profits. Besides this, the other five objectives of marketing are –\n- Customer Satisfaction: Satisfying the needs, wants, and demands of the customers.\n- Profitability: Earning profit for the business to support sustainable growth.\n- Demand Creation: Develop demand for the offerings by communicating about it to the target audience.\n- Brand Development: Building a brand out of the company and/or the offering and differentiating it from other players in the market.\n- Create Goodwill And Public Image: Building up a public image of the brand and increasing its equity by providing offerings with a consistent brand promise.\nThe Four Principles Of Marketing\nSince marketing is the sum total of all the activities involved in the transfer of the goods from the seller to the buyer, it relies on four basic principles. These principles, also called the 4 Ps or the marketing mix, are –\n- Product: It is the offering that the company sells or intends to sell.\n- Price: It is how much the company charges from the customer for the offering.\n- Place: It refers to the point of sale – the place where the offering is offered for sale.\n- Promotion: It encompasses all the marketing communication strategies to communicate and persuade the customer to buy the offering.\nThese four principles form the pillars marketing stands on. These principles give way to the core functions of the marketing too –\n- Developing an offering that the market needs\n- Pricing the offering by predicting the perfect balance of product value and the customer’s paying capacity, to maximise profits.\n- Using the right distribution channels to distribute the offering\n- Communicate about the brand, brand message, offering, and offering’s USP to increase sales.\nNature Of Marketing\n- Managerial Function: Marketing is a process that requires officials to manage product, place, price, and promotion of the business in a holistic manner.\n- Economic Function: Earning profit and developing a sustainable business is a crucial objective of marketing.\n- Social Process: Marketing is a social process that results in the parties obtaining what they need through the creation and exchange of offerings and values.\n- Consumer-Oriented: Marketing revolves around fulfilling the needs, wants, and demands of the customers and earning profits in the process of doing so.\n- Both Art and Science: It is science as it requires the marketer to understand customer behaviour and art as it involves using this knowledge along with skills to create the demand for the offering.\n- Goal-Oriented: Marketing revolves fulfilling the goals of the business by aligning it with the customers’ goals.\n- Interactive Activity: Marketing involves the marketer to actively interact with the audience at all stages of the business.\n- Dynamic Process: It makes sure that the business keeps at pace with the changing business environment, trends, and demands of the customers.\n- Creates Utility: Marketing aims at providing utility to the customer through four different means – offering (kind of product or service), time (whenever needed), place (distribution availability), and possession (ownership).\nTypes Of MarketingScope Based On Entities Marketed\nMost people mistake types of marketing strategies to be types of marketing.\nThey both differ.\nTypes of marketing strategies refer to the ‘how’ of marketing – how an offering is marketed. Types of marketing, however, focuses on the ‘what’ of marketing – what is marketed.\nMarketing isn’t limited to just physical goods. Today, even human, places, and experiences are marketed.\n- Product Marketing: Tangible offerings manufactured in bulk and requiring proper marketing to make it available to the right customer at the right time. Example – mobile phones, televisions, etc..\n- Service Marketing: Intangible activities that can’t be separated by the provider. Example – hotels, airlines, barbers, etc.\n- Event Marketing: Time based events like trade shows, artistic performances, etc.\n- Experience Marketing: An orchestrated mix of services and goods which leads to an experience. Example – amusement park experience, foreign trip experience, etc.\n- Person Marketing: A person known for his skills, profession, art, experience, etc. Example – Ronaldo, Michael Jackson, etc.\n- Place Marketing: Places, cities, states, and countries with an aim to attract potential investors and/or tourists. Example – Hawaii.\n- Property Marketing: Intangible rights of ownership of the real estate, stocks, securities, debentures, etc.\n- Organisation Marketing: Corporations and not for profit organisations like schools, colleges, universities, NGOs, etc.\n- Information Marketing: Information related to healthcare, technology, science, media, law, tax, market, finance, accounting, etc. offered by books, schools, universities, websites, media houses, etc.\n- Idea Marketing: The basic ideas that result in the entity, offering, etc.\nScope Of Marketing\nWhen compared to other functions of the business, marketing’s scope seems to be a bit more vast. It flows within almost all of the business activities and present at all stages of the customer buying cycle.\nEven a separate type of marketing, known as digital marketing, has evolved to expand the scope of marketing over the internet.\n- Market Research: Researching consumer demands and consumer behaviour.\n- Product Planning and Development: Planning and developing the offering according to what’s needed in the market.\n- Product Pricing: Pricing the offering according to the product value and the buyer’s paying capacity to maximise profits.\n- Distribution: Distributing the offering, so it is available wherever and whenever the customer demands it.\n- Promotion: Communicating the right message that results in demand creation.\n- Sales: Offering incentives that increase sales.\n- After-Sales: Providing after-sales support to the customer to maintain a good brand image in the market.\nMarketing Vs Sales\nWhile sales and marketing have the same goal – generate revenue and increase the profits of the company, there’s a big difference between them.\nMarketing is an umbrella that includes all the activities that result in meeting the needs, wants, or demands of the customers at a profit.\nSales, on the other hand, is a process that results in a transaction between two or more parties in which the buyer(s) receive the offering and seller(s) get something of value in return which is usually money.\nIn simple terms, sales is a subset of marketing.\n|Definition||Systematic planning, implementation, and control of business activities to fulfil the needs of the customer at a profit.||A transaction between two or more parties where the buyer receives the offering and the seller gets something of value in return.|\n|Approach||Broader approach that involves identifying, anticipating, and satisfying customers’ requirements with the purpose to make profits.||Narrow approach to make the customer’s demand match what the company offers.|\n|Focus||On fulfilling the customers’ need and making profit out of it.||Fulfil sales volume goals.|\n|Horizon||Long Term||Short Term|\nMarketing Vs Advertising\nAdvertising is the subset of marketing which focuses only on the promotion aspect of the business. It is the action of calling public attention to an idea, good, or service through paid announcements by an identified sponsor.\nMoreover, marketing’s promotion aspect includes activities like public relations and sales promotion, that are not limited to advertising.\n|Definition||Systematic planning, implementation, and control of business activities to fulfil the needs of the customer at a profit.||A paid communication message intended to inform people about something or to influence them to buy or try something.|\n|Approach||Broader approach using more than just promotion.||Offering oriented promotion backed by a goal to increase awareness or increase sales, etc.|\n|Focus||On developing a customer relationship.||On fulfilling offering related goals.|\n|Strategy||Holistic strategy||Promotion strategy|\nGo On, Tell Us What You Think!\nDid we miss something? Come on! Tell us what you think about our article on marketing definition in the comments section.\nA startup consultant, dreamer, traveller, and philomath. Aashish has worked with over a 50 startups and successfully helped them ideate, raise money, and succeed. When not working, he can be found hiking, camping, and stargazing.","Business to customer marketing, commonly known as B2C marketing, is a set of strategies, practices, and tactics that a company uses to push its products or services to customers. B2C campaigns don’t just focus on the benefit or value that a product offers, but also on invoking an emotional response from the customer.\nB2C marketing works on the basis that customers look for goods or services to meet an immediate need. Therefore, they tend to purchase without doing much research on the product or service. With B2C purchases, users typically complete their purchase within the first hours or days of becoming aware of a product or service. For a successful B2C campaign, a business owner should understand their customers’ buying habits, trends in the market, and what strategies the competitors use.\nB2C promotions should be bright, easy for consumers to understand, and focused on solving the precise problem faced by their customers. With this information and the right tools, it is easy to create a campaign that triggers the right reactions from customers and as a result, drives sales.\nWhy is B2C marketing important?\n- Boosts website visits\n- Helps brands grow their subscriber list\n- Offers more refined interactions with customers\n- Gives businesses better rankings on search engines\n- Increases conversion and brand awareness\nB2C marketing is vital for all businesses that sell consumer-based products or services. These include restaurants, drug stores, car companies, fashion businesses, software companies, grocery stores, and so forth. Today, however, the internet has become the most preferred channel for B2C brands to promote their goods or services and for conducting market research. Almost every B2C company wants to get a share of the $2.3 trillion e-commerce industry and shift its marketing outreach online.\nB2C e-commerce sales stood at $1.5 billion in 2013, with forecasts showing steady growth to 2.35 billion in 2018. These figures show that B2C marketing is worth the investment for higher ROI and business growth. B2C marketing is beneficial in the following ways, it:\n- Boosts website visits: B2C campaigns are created to woo prospective customers into visiting your brand’s website to earn more about your brand.\n- Helps brands grow their subscriber list: when the number of leads that visit a business’s website increases, the number of new subscribers also goes up.\n- Offers more refined interactions with customers: with knowledge about your target audience, B2C companies can send more specific messages at strategic times. Here segmentation proves to be useful.\n- Gives businesses better rankings on search engines: by using targeted keywords, a website can increase its position in search results. As a result, there are more chances for users to find YOUR company.\n- Increases conversion and brand awareness: B2C marketing strategies enable businesses to reach and connect with large audiences through bulk emailing, social media outreach, and other channels. As a result, a brand becomes popular, and conversion rates increase.\nFeatures of B2C Marketing\nB2C marketing can be characterized by a list of features that makes it stand out. Look below.\n- A short sales cycle. Unlike B2B marketing, in which the sales cycle is much longer, B2C clients don’t spend hours on research, hesitating, and comparing every single feature. B2C customers usually buy products that were advised by their friends so the entire process is less intimidating for clients and sellers.\n- Domination of an emotional element over the rational one. B2C customers look for instant solutions to their problems based on their desires. They rarely think strategically over the purchase. They are just looking for a fast solution that will satisfy their needs here and now. So if a brand manages to provide them with this solution, they will definitely return to for the same emotional experience.\n- Working with the end-user. B2C companies usually deal directly with the consumers of their products. This makes it easier to convince a person, find the right words, and use special techniques. While in B2B, a salesperson needs to negotiate with multiple influencers who make decisions on behalf of the entire company.\n- The high importance of social media. Working with the end consumers is impossible today without investing in social media marketing. While choosing a product, people desperately look for customer feedback. They investigate each channel they know to make the right decision. They not only look for reviews but prefer Facebook and Instagram to talk to the brand via chatbots. You will hardly find a person who will give a call or visit the company’s office. So, brands create chatbots to provide clients with 24/7 support, collect reviews, share updates, and run retargeting campaigns to bring in new customers and maintain relationships with them.\nB2C Marketing vs. B2B Marketing\nB2C and B2B marketing differ significantly; therefore, understanding these differences can make a brand’s marketing campaigns more relevant and successful. The following is a comprehensive comparison of the two:\n|B2C Marketing||B2B Marketing|\n|Sells to the final customer directly.||Targets a company or business.|\n|Customers are impulsive and want to see all the information about the product at once. They will rarely do more research to understand the product.||Customers are likely to do more research before purchasing and compare the product with competing options.|\n|Targets the emotional drive associated with purchasing a product.||Focuses on the features and value of a product.|\n|Works around benefits and desires.||Is more about the characteristics and logic.|\n|The goal of customers is a personal improvement.||The aim of target customers is to power their business.|\n|Makes small-scale sales for personal use. These are low-volume sales spread across many consumers.||Sales are large-scale. The customers are limited, but the purchasing volume is large.|\n|Consumers make purchases instantly after seeing the product ad or within a very short time. They look for immediate results.||Customers typically go through a much longer buying process. They want to fulfill long-term goals.|\nB2C Marketing Channels\n- Email marketing\n- Mobile marketing\n- Web push marketing\n- Social media marketing\n- Paid Search Advertising\nB2C marketing has been in existence for a long time and relies on various communication channels to reach the final customer. Just like other types of marketing, growth in technology has also increased the number of marketing channels in B2C.\nThe most important channels for B2C marketers include the following:\nEmail marketing is a popular and effective way for consumer brands looking to increase their sales to reach the target audience. It primarily involves sending out email blasts or personalized promotional emails to new leads or loyal customers. Email marketing, however, is only useful if it is relevant to the recipients.\nIt is estimated that over half of all internet shoppers buy things from their mobile devices. Therefore, successful B2C companies should work on reaching mobile users through interactive and mobile-optimized promotions. Mobile marketing aims to reach mobile users through websites, apps, SMS, MMS, and social media.\nWeb push marketing\nPush notifications are a way to deliver messages about sales, discounts, or offers to customers in real-time when they visit a website. Push notifications usually pop up on users’ computers or mobile screens and help elicit an immediate response from the viewer.\nSocial media marketing (SMM)\nSMM is the use of social media networks like Facebook, Instagram, and Twitter to promote goods or services directly to customers. It entails creating and sharing marketing content on social media platforms. Usually, B2C businesses use social media as a channel to market their brands' potential target customers, loyal clients, and the general public.\nSearch Engine Optimization is a natural or organic marketing process for increasing the visibility of a site or webpage on a search engine’s non-paid results. Good SEO practices and tools help businesses drive more traffic to their websites and consequently increase sales.\nPaid Search Advertising\nThis form of marketing is a type of pay-per-click advertising where brands pay for their digital advertisements to appear on the results page of a search engine like Google or Yahoo. The placement and frequency of these ads depend on one’s quality score and bid.\nB2C Marketing Tools\n- Email marketing\n- SMS marketing\n- Web push marketing\n- Messenger marketing\nB2C marketers, sales executives, and business owners can benefit from marketing tools offered by services such as SendPulse. Here are the most prominent services:\nEmail marketing tools with SendPulse can be used to build and segment mailing lists, create and send personalized email campaigns, automate email sending, analyze subscriber activity, and monitor results. This channel assists marketers with user onboarding and moves users down the sales funnel.\nLet's increase your income!\nSend segmented email campaigns to convert leads to clients. We offer a free plan, ready-made templates, marketing automation, and even more.\nSMS marketing tools enable brands to reach prospects and loyal customers on their mobile devices. With SendPulse, brands can send bulk promotional or non-commercial SMS messages to 800 mobile networks in more than 190 countries worldwide. You can schedule SMS sending to a specific date and time or choose gradual sending at defined times. You can perform B2C marketing with SendPulse at speeds of up to 500 SMS messages per second.\nWeb push marketing\nSendPulse helps brands send browser push notifications about sales, exciting updates, new content, and products that get the attention of visitors and drive traffic back to websites. They are easy to set up and work on most browsers, including Chrome, Opera, and Firefox.\nYou can promote your products via messengers as well as answer users' frequently asked questions, help them order, and register for events using a chatbot. With SendPulse you can create a chatbot for Facebook Messenger and Telegram and send up to 10,000 messages every month at no cost.\nB2C Marketing Strategies\n- Content marketing. You've definitely heard the quote published on Microsoft's site \"Content is King.\" Every famous brand invests in content marketing. This strategy helps businesses generate leads, increase their target audience, boost engagement, nurture leads, build brand awareness, blow up sales, and raise customer loyalty. Different content formats help effectively reach these goals. You can start a blog both to drive traffic to your site and educate your audience about your products.\n- Search Engine Optimization. Now, that you're in content marketing, it's high time you take SEO seriously. This strategy means optimizing your site pages to rank high in the search engine results page. In short, this is a set of techniques that enables the search engine robots to make your content visible and help people find it. This is a long-term strategy that implies working with users' search queries, the load speed of your pages, and building links to your website.\n- Paid advertising. This strategy is similar to SEO, the only difference is that you have to pay for it. It includes PPC, ads on Facebook, and Instagram, retargeting campaigns. All these ads help drive users who are already interested in your product to your site. Depending on the ad format, you can either pay for views or for clicks.\n- Email marketing. With a well-thought email marketing strategy, you can increase your outreach, build long-lasting relationships with your audience, increase brand recognition, and boost sales. Combine promotional emails with transactional campaigns to perform better. With SendPulse's Automation 360, you can send emails triggered by users' actions automatically.\n- Social media. People spend hours per day on social media channels and they DO use them to buy products online. They look for reviews and customer feedback on Facebook and seek more behind-the-scenes information about brands on Instagram. Besides, they tend to share content they liked with their friends, so you can both increase sales and user engagement. In addition, you can use Facebook and Instagram to talk to your audience, find out which improvements will make you brand the best choice.\n- Influencer marketing. Find the most popular bloggers in your niche. They will help you promote your brand to their vast audience in favorable terms. If they enjoy using your product, you’ll get the benefits of long-term cooperation and increase sales significantly. You only need to carry out research to find the right influencers.\n- Membership and rewarding programs. Your loyal clients let your brand prosper. They not only increase your ROI but bring in new clients, spread a good word about your brand, and can help you improve. Create programs to reward their loyalty. Offer them to collect points that they can change for a product or a discount.\nHow to Start B2C Marketing with SendPulse\n- Register in SendPulse\n- Choose the optimal channel or mix them\n- Upload a mailing list or grow your current list\n- Send your marketing campaign\n- Monitor results and improve strategy\nConsumer-based companies can achieve B2C marketing success with SendPulse for free. Follow these steps to create and send B2C campaigns.\n- Register in SendPulse. Sign up on the website and start using marketing tools to reach and connect with prospects for free.\n- Choose the optimal channel or mix them. Choose a suitable channel for your new campaign. You can choose email, SMS, web push, Facebook Messenger, and Telegram app. SendPulse also lets you combine multiple channels in one campaign for better outreach.\n- Upload a mailing list or grow your current list. You can add a mailing list if you have one already or create a new list of contacts. With the help of a subscription form or a script for push notifications — which you can make and segment with SendPulse — brands can grow their mailing list without much effort. Besides, you can create multichannel forms to communicate with your audience via messengers. If you upload your existing mailing list, we recommend your verify the addresses with our free tool. This check will help you stay out of the spam folder and keep your sender reputation high.\n- Send your marketing campaign. Create the content for your campaign, add the list of recipients, and send it. Alternatively, schedule a date and specific time for automatic sending.\n- Monitor results and improve strategy. With SendPulse reports, track how the campaign performs. Analyze delivered emails, opens, clicks, delivery errors, unsubscribes, spam complaints, and improve your marketing strategy.\nB2C Marketing Automation\nMarketing Automation is essential, especially for B2C companies, as it simplifies and optimizes most marketing tasks. With SendPulse Automation 360, you can automate marketing campaigns across multiple channels. This automation tool lets you send triggered messages after customers perform actions such as making a purchase, registering on the website, abandoning products in their carts, or any other event you specify.\nTo get started with Automation 360:\n- Sign up. Add an event to be tracked, such as a «Add subscriber,» when a visitor joins your mailing list.\n- Create an email, SMS, or web push message to send when the event is triggered.\n- Start the automation flow.\n- Track conversions.\nB2C Marketing Examples\nSee how Habitat tempts its customers to buy the products at reduced prices.\nCheck out another example of the B2C tactic to increase sales. Skiphop offers a free shipping day for all the orders.\nLook how True Citrus takes advantage of Valentine’s Day. They offer generous, time-limited sales to push clients to make a purchase.\nB2C Marketing Tips and Best Practices\n- Ethically collect recipient addresses to avoid being blacklisted. A permission-based marketing approach is the choice of a good marketer.\n- Categorize your leads and keep detailed buyer profiles.\n- Create catchy headlines on landing pages to pull in the potential buyer.\n- Create personalized, interactive, and engaging content to attract and enhance the customer experience with the help of segmentation.\n- Optimize marketing messages and web pages for mobile.\nStart B2C marketing, grow brand awareness, and increase sales with the help of SendPulse today.\n- The article \"BUSINESS-TO-CONSUMER (B2C) MARKETING\" on Brafton explains the difference between B2C and B2B marketing approaches.\n- The article \"What Is B2C Marketing?\" on Emarsys defines B2C marketing, explains its importance, considers top priorities for B2C content creators, sheds light on its biggest challenges, and offers essential B2C tips.\n- The article \"5 Examples of B2C Marketing Strategies with Big Results\" on Emarsys provides proven B2C strategies to implement.\n- The article \"Understanding the Differences Between B2B and B2C Marketing\" on The Balance Small Business explains the critical differences between these two marketing approaches.\n- The article \"We Break Down B2B vs. B2C Marketing\" on HubSpot blog defines B2B and B2C marketing and compares the approaches.\nLast Updated: 19.03.2021"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:96f691e5-a10e-4fc4-a8cd-e2ba2d6fe52e>","<urn:uuid:909275d6-9891-4fa6-bb5e-44e110416f08>"],"error":null}
{"question":"Could you explain how airplane bathrooms are monitored for safety and how lithium-ion batteries are tracked through their lifecycle?","answer":"Airplane bathrooms are monitored through several non-invasive methods including locked door indicators, smoke detectors, and regular checks by flight attendants. Visual surveillance equipment is never installed inside the lavatories, but flight crews maintain oversight for passenger safety. For lithium-ion batteries, tracking through their lifecycle involves multiple stakeholders including manufacturers, dealer networks, recycling programs, and various recyclers. The batteries are classified as dangerous goods and require specialized handling systems. Their lifecycle monitoring is complicated by the diverse range of sources, from small portable devices to large format applications, and requires careful management of collection and recycling processes to ensure safety and proper disposal.","context":["Airplane bathrooms have always been a source of curiosity for many travelers. The small, cramped space leaves little room for privacy. This leads to the common question – are there cameras in airplane bathrooms? Read on as we uncover the truth about cameras in those tiny airplane lavatories.\nIf you’re short on time, here’s a quick answer to your question: No, there are no cameras in commercial or private airplane bathrooms. While airplane bathrooms are monitored by flight attendants for safety, visual surveillance equipment is never installed inside the lavatory.\nWhy People Wonder if There Are Cameras\nHave you ever wondered if there are cameras in airplane bathrooms? It’s a question that has crossed the minds of many travelers. Let’s explore the reasons why people have this curiosity and concern.\nCuriosity About the Enclosed Space\nAirplane bathrooms are small, enclosed spaces that can feel quite private. This sense of privacy can make people wonder if there are hidden cameras monitoring their every move. The idea of being watched in such an intimate setting can be unsettling for some.\nWhile it may seem like an invasion of privacy, it’s important to note that the vast majority of airlines prioritize passenger safety and comfort. They adhere to strict regulations and policies that prohibit the installation of cameras in airplane bathrooms.\nConcerns Over Safety and Security\nAnother reason why people wonder about cameras in airplane bathrooms is the concern over safety and security. Air travel is heavily regulated and monitored to ensure the safety of passengers. However, there have been instances of misconduct by individuals, which has fueled these concerns.\nIt’s important to remember that airlines have robust security measures in place to prevent any unauthorized access to passenger areas, including bathrooms. These measures include regular inspections, surveillance cameras in public areas, and strict access control protocols.\nSuspicion of Being Watched\nIn today’s digital age, where privacy breaches are a growing concern, it’s not surprising that some individuals are suspicious of being watched everywhere, including airplane bathrooms. With the prevalence of smartphones and other recording devices, the fear of being secretly recorded has become more prominent.\nHowever, it is crucial to differentiate between legitimate concerns and unfounded paranoia. Airlines are committed to maintaining the privacy and security of their passengers, and the installation of cameras in airplane bathrooms would be a violation of these principles.\nRegulations Prohibiting Bathroom Cameras\nThe Federal Aviation Administration (FAA) has strict regulations in place to ensure the safety and privacy of passengers on board aircraft. One of these regulations explicitly prohibits the use of cameras in airplane bathrooms.\nThis rule is in place to protect the privacy of passengers and to prevent any potential misuse of recorded material.\nThe FAA regulations also extend to electronic devices that have the capability to record. This means that even if a camera is not specifically installed in the bathroom, passengers are still not allowed to use their personal devices to record in these private areas.\nIt is important to note that violating FAA regulations can result in serious consequences for both passengers and airlines. Any individual found to be using a camera in an airplane bathroom may face legal action and potential bans from flying.\nIn addition to the FAA regulations, airlines themselves also have policies in place to prevent the use of cameras in airplane bathrooms. These policies are in line with the industry standards and are aimed at ensuring the comfort and safety of passengers.\nAirlines typically include clear language in their terms and conditions, stating that the use of cameras in bathrooms is strictly prohibited. This information is often communicated to passengers through safety briefings and announcements made by the flight crew.\nPassengers are encouraged to report any suspicious behavior or potential violations of this policy to the flight crew or airline staff. This allows the airline to take appropriate action and maintain the integrity of their policies.\nMonitoring and Safety Features\nWhen it comes to air travel, safety is of utmost importance. Airlines have implemented various monitoring and safety features to ensure the well-being of their passengers. One common concern among travelers is whether there are cameras in airplane bathrooms.\nLet’s take a closer look at the monitoring and safety features in place.\nLocked Door Indicators\nPrivacy is a top priority in airplane bathrooms. To address concerns about cameras, airlines have installed locked door indicators. These indicators provide a clear visual signal to flight attendants when the bathroom is occupied.\nThis allows them to ensure the privacy of passengers while maintaining the overall safety of the aircraft. So rest assured, you can use the bathroom without worrying about being monitored.\nAirplane bathrooms are equipped with smoke detectors, just like other areas of the aircraft. These detectors are essential for ensuring the safety of passengers in case of a fire or smoke-related incident. They are designed to detect any signs of smoke or fire and alert the flight crew immediately.\nThis allows for prompt action to be taken, ensuring the safety of everyone on board.\nFlight Attendant Monitoring\nFlight attendants play a crucial role in maintaining the safety and security of the aircraft. They are responsible for monitoring various aspects, including the bathrooms. While there are no cameras in airplane bathrooms, flight attendants regularly check on them to ensure cleanliness, restock supplies, and address any maintenance issues.\nTheir presence and vigilance contribute to a safe and comfortable flying experience for passengers.\nCase Studies and Examples\nRecent Incidents Involving Bathrooms\nWhile there have been occasional reports of hidden cameras in public restrooms, including airplane bathrooms, it is important to note that such incidents are extremely rare. Airlines prioritize passenger safety and privacy, and any violation of this trust is taken very seriously.\nHowever, there have been a few isolated incidents that have raised concerns among passengers.\nOne example of a recent incident involving airplane bathrooms occurred in 2017 on a United Airlines flight. A passenger discovered a hidden camera in the first-class bathroom and reported it to the flight attendants.\nThe airline immediately launched an investigation and found that the camera was placed there by a maintenance worker for personal use. The employee was promptly terminated, and United Airlines issued a public apology to the affected passenger.\nAnother incident took place in 2019 on a British Airways flight. A passenger noticed a small camera lens hidden behind an air vent in the bathroom and reported it to the cabin crew. The airline investigated the matter and found that the camera was not functional and had been left there accidentally during routine maintenance.\nNevertheless, British Airways took the incident seriously and implemented additional security measures to prevent similar occurrences in the future.\nPassenger Concerns and Complaints\nDespite the rarity of incidents involving hidden cameras in airplane bathrooms, passenger concerns and complaints about privacy remain. The enclosed nature of airplane bathrooms can make some travelers feel vulnerable, especially when they are aware of the possibility of hidden cameras.\nIt is important for airlines to address these concerns and reassure passengers of their commitment to ensuring privacy and safety.\nMany airlines have taken proactive measures to alleviate passenger concerns. For instance, some airlines have installed tamper-proof seals on bathroom doors to provide visual reassurance that the space has not been tampered with.\nAdditionally, flight attendants receive training on how to identify and respond to any suspicious activity in the cabin, including potential privacy violations.\nPassengers are also encouraged to report any concerns they may have regarding privacy to the flight crew. Airlines take these reports seriously and conduct thorough investigations to ensure the safety and well-being of their passengers.\nIt is worth noting that the Federal Aviation Administration (FAA) and other aviation regulatory bodies have strict regulations in place to protect passenger privacy. These regulations include regular aircraft inspections and maintenance checks to detect and prevent any unauthorized recording devices from being installed in airplane bathrooms.\nExpert Opinions on Bathroom Privacy\nPilot and Flight Attendant Views\nWhen it comes to bathroom privacy on airplanes, pilots and flight attendants have differing opinions. Some pilots argue that installing cameras in airplane bathrooms could enhance security measures and help prevent potential threats.\nThey believe that having constant surveillance in these confined spaces would act as a deterrent for illegal activities. However, flight attendants emphasize the importance of passenger privacy and argue that cameras in bathrooms would be a violation of personal space.\nThey argue that passengers should be able to use the restroom without feeling like they are being watched.\nAccording to a survey conducted by the Flight Attendants Association, 80% of flight attendants believe that cameras in airplane bathrooms would be an invasion of privacy. They argue that passengers have the right to use the restroom without feeling monitored, and that the presence of cameras could lead to increased anxiety and discomfort among passengers.\nIt is important to note that, as of now, there are no regulations or requirements for cameras in airplane bathrooms. The decision ultimately rests with the airlines themselves, who must consider the opinions of both pilots and flight attendants, as well as the concerns of passengers.\nTravel Advocate Perspectives\nTravel advocates, who work to protect the rights and interests of passengers, also have strong opinions on the issue of bathroom privacy on airplanes. They argue that installing cameras in airplane bathrooms would be a violation of personal privacy and could potentially lead to abuse or misuse of the footage.\nThese advocates believe that passengers should have a reasonable expectation of privacy when using the restroom on an airplane. They argue that this expectation is rooted in the basic principles of human dignity and respect.\nFurthermore, they argue that the installation of cameras could create a chilling effect, deterring passengers from using the bathroom when necessary due to fear of being watched.\nAccording to a statement from the Air Travelers Association, “Passengers deserve the right to use the restroom in peace and privacy. Installing cameras in airplane bathrooms would be a clear violation of this right and would undermine the trust between airlines and their customers.”\nWhile there are varying opinions on the matter, it is evident that bathroom privacy on airplanes is a topic of concern for both aviation professionals and passengers. Ultimately, the decision regarding the installation of cameras in airplane bathrooms should take into account the opinions and rights of all stakeholders involved.\nWhile airplanes have many safety and security measures, cameras in lavatories would be a major breach of privacy. Strict aviation regulations prohibit their installation and use. Flight crew are responsible for monitoring the facilities during flights.\nUltimately, evidence and expert opinions show there are no cameras watching passengers in airplane bathrooms.","In 30 years since commercialisation, lithium-ion (li-ion) batteries have been used in an increasingly diverse range of products, starting from early generation handheld electronics to powering cars and buses. Additionally, these batteries are increasingly sought after for utilisation in energy storage applications, often paired with renewable energy generation. The continued decline in battery prices combined with the global trend toward energy grids being powered by renewable energy sources is predicted to increase the world’s cumulative energy storage capacity to 2,857GWh by 2040 , a substantial increase from the current capacity of ~545MWh , according to recent estimates by Bloomberg New Energy Finance.\nThese staggering projections paint an encouraging picture for how prominent li-ion-driven energy storage applications will become in the future as the world increases usage of renewable, clean energy sources to power energy grids worldwide. Driven increasingly by electro-mobility as well as grid-scale energy storage applications, the volume of li-ion battery cells being sold is set to surge. The graph in Figure 2 contextualises the relative volume (in tonnes) of new li-ion battery cells forecasted to be sold through to 2025. The growing quantities of li-ion batteries being placed on the markets accelerates the urgency with which the world must find an economically viable, commercial-scale recycling solution for end-of-lifecycle li-ion batteries to be recycled at a ‘mega’ scale. This article will take a closer look at some of the challenges that exist today within the li-ion recycling sector and where opportunities exist to overcome the current roadblocks.\nLi-ion recycling industry challenges\nSecondary resource recovery (i.e. recycling) has a set of unique operational challenges that need to be addressed concurrent to the development of an economic, advanced technology. For the purpose of recycling, feed materials are typically inherently distributed, making it difficult to collect a high volume of feed for a processing plant. Although the collection supply chains for some analogous industries such as lead-acid battery recycling are well-established and mature by comparison, the li-ion battery recycling supply chain continues to be fluid. Spent li-ion battery sources can be broadly segmented into portable/’small format’ and ‘large format’ sources, which corresponds to the relative voltage of li-ion batteries (i.e. low voltage and intermediate to high voltage, respectively). Each of these types of batteries has a diverse group of stakeholders – from manufacturers, to the dealer network, recycling programmes, electronics and vehicle recyclers. In the context of the energy storage sector, its own diverse group of stakeholders exists – battery technology provider, energy storage integrator, project developer and asset owner. Managing the inherently heterogenous nature of li-ion batteries from a wide range of stakeholders remains a central challenge for companies in the li-ion resource recovery industry.\nLogistics and regulations\nLi-ion batteries are currently classified as Class 9 Dangerous Goods due their dual chemical and electrical hazard. Li-ion batteries can possibly undergo thermal runaway, typically resulting from internal shorting, leading to fire or explosion. There are numerous factors that can cause thermal runaway, including but not limited to overcharging, environmental conditions (e.g. extreme external temperatures) and manufacturing defects. At the onset of thermal runaway, the battery heats in seconds from room temperature to above 700°C. As part of this complex set of chemical reactions, the electrolyte solvent in lithium-ion batteries – typically alkyl carbonate-based – acts as a ‘fuel’ source for combustion.\nAdded care must also be taken when handling critical or damaged/defective batteries as there is an increased risk of thermal runaway. Specialised systems (e.g. Genius Technology’s LionGuard container for intermediate to high voltage lithium-ion batteries ) are typically used in tandem with non-flammable packing material to safely transport these batteries. As the overall volume of li-ion batteries increases, the quantity of critical or damaged/defective batteries is expected to increase across a broad swath of applications. As the li-ion battery resource recovery industry is still maturing, regulations vary significantly around the world. These regulations can also change significantly from year to year, as new industry and research reports are released. As a result, it is important to keep close track of regulatory (including logistics) considerations concurrent to process development.\nSafety and storage\nThe challenges of logistics and changing regulations typically revolve around one key factor – safety. Safety is paramount for those who handle, transport, store and process li-ion batteries, as there is a risk of thermal runaway. This raises another unique challenge for processors and consolidators, relative to the primary production of commodities and specialties. Specifically, the safest approach is to have the lowest amount of spent li-ion batteries on site as possible, in order to mitigate the risk of a thermal runaway event occurring. However, this is contradictory to the requirement to secure significant amounts of feed for processing purposes. The development of safe storage is further complicated by the currently prominent format factor of spent li-ion batteries, i.e. portable/small format batteries (e.g. from mobile phones, laptops and other consumer products). Portable li-ion batteries are typically consolidated in drums and could be mixed with other battery types. Upon an initial inspection, the state of all collected batteries within a single drum is not always clear (i.e. whether undamaged or damaged) and often only becomes apparent when the drums are tipped for sorting or processing. As a result, strict protocols must be implemented regarding the pallet/container spacing, total storage density and application of appropriate fire suppression systems within any li-ion battery storage space in order to mitigate the risk associated with thermal runaway and fire.\nSecondary resource processing challenge\nFrom a process development standpoint, the recovery of constituents from li-ion batteries presents a unique challenge compared to traditional primary metal resources due to the highly heterogeneous nature of the feed material. Currently, there are at least 14 different types of li-ion battery cathode chemistries currently existing in the market , each of which has even further permutations when considering specific constituents. With traditional metal resources the primary concentrate stream might have 1-4 elements to be recovered (e.g. copper, gold, silver and platinum). Li-ion batteries may however contain over 20 elements that demand consideration for recycling as illustrated by the example composition in Figure 3 . In addition, the metal values are typically contaminated with inorganic materials, organic materials and plastics, further complicating the recycling process. To be able to separate out the valuable constituents typically requires complex process flowsheets with many individual unit operations. Under this scenario, it is critical that the physical test-work required to develop the process flowsheet is well focused and driven by techno-economic analysis.\nLi-Cycle is one company with a strong focus on technology for resource recovery of end-of-lifecycle li-ion batteries. Since incorporation in 2016, Li-Cycle has developed and validated a unique process to recover 80-100% of all li-ion battery constituent materials using a two-step mechanical and hydrometallurgical system. This advanced resource recovery process, alongside concentrated efforts focused on battery sourcing from various supply chain players and a continuous prioritisation of safety, are fundamental elements supporting Li-Cycle’s goal of global commercialisation of Li-Cycle Technology.\nOpportunities and future outlook\nIt is evident that the global volume of li-ion batteries deployed in energy storage and other applications is set to increase steadily over the next two decades, underscoring the necessity for a sustainable end-of-life pathway for these batteries both now and into the future. Li-Cycle is on a mission to leverage its innovative solution to address an emerging and urgent global challenge. Li-ion batteries are increasingly powering our world and there is a need for improved technology and supply chain innovations to better recycle these batteries, and to meet the rapidly growing demand for critical and scarce battery-grade materials. Scalability, low-cost, safety and environmental sustainability are core tenets of commercialising Li-Cycle Technology. In turn, Li-Cycle seeks to enable the global transition to electro-mobility and reduce greenhouse gas emissions worldwide. Lithium-ion batteries will continue to electrify our world, now and into the foreseeable future. As a key driver of the transition away from a carbon-based economy, li-ion batteries are integral to the opportunity to drastically reduce greenhouse gas emissions worldwide. However, to ensure a truly positive impact over their lifecycle, we must ensure a closed-loop system is in place to safely handle and recycle spent li-ion batteries at scale. This will enable the reintegration of critical battery materials into the li-ion battery supply chain and the broader economy, while preventing negative environmental and safety impacts.\nThis article first appeared in PV Tech Power, Vol20, which is available now to download for free, here.\n- Munuera, Luis (2019) Energy Storage – Tracking Clean Energy Progress https://www.iea.org/tcep/energyintegration/ energystorage/\n- Bloomberg New Energy Finance (2018) Energy Storage is a $620 Billion Investment Opportunity to 2040 https://about.bnef.com/ blog/energy-storage-620-billion-investment-opportunity-2040/\n- Nitta N, Wu F, Lee JT, Yushin G (2015) Li-ion battery materials: present and future https://www.sciencedirect.com/science/article/pii/ S1369702114004118. Accessed 10 September 2018 • Lithium Collect (2018) https://ecobatgroup.com/occ-liion/en/ ss.php. Accessed 10 September 2018.\n- Diekmann J, Hanisch C, Frobose L, Schalicke G, Loellhoeffel T, Folster AS, Kwade A (2017) Ecological recycling of lithium-ion batteries from electric vehicles with focus on mechanical processes Journal of The Electrochemical Society 168 (1): A6184-A6191\nStay up to date with the latest news, analysis and opinions. Sign up here to the Energy-Storage.news Newsletter."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:b876b57f-924a-47d9-b25b-cffd8bd73ba3>","<urn:uuid:9c9e2902-e591-4e64-b4f3-05dfa51a0e53>"],"error":null}
{"question":"Hey! I heard Charles wants to change the monarchy structure - what's his plan about?","answer":"King Charles III plans to slim down the monarchy by recalibrating what it means to be a working member of the monarchy. This plan involves potentially relieving some existing posts and members of the monarchy from their duties. The goal is to establish a more autonomous monarchial system without distributing power to too many people who could affect the system's credibility, although this change could impact the fluency of operations and the monarchy's functionality.","context":["Table of Contents\nThe death of Queen Elizabeth means that Prince Charles III will be taking over as head of the Monarch. Contrary to the other members of the Monarch, Charles III has been vocal about his political views. Gerring et al. (2020) highlighted that the Monarchial system had exempted its members from participating in the country’s political affairs. Generally, the members of the royal family are expected to be neutral. This expectation implies that they are not allowed to vote or make any political stand concerning any matter. However, Charles III has shown a different side of the Monarch. Low (2022) reports that the Prince has often been known to be fairly liberal. This fact generally means that he is an individual who is not afraid to speak his mind. Although there has been some scrutiny relating to his general conduct, the Prince has remained steadfast in his beliefs and principles, speaking out on matters he feels are of public interest. In this regard, the Queen’s death raises controversial discussion on the extent of the authority of King Charles III. There are growing uncertainties about what to expect from him especially given the difference in character he brings to the table. The current assessment is therefore directed towards uncovering what should be expected in the reign of King Charles III as the head of the Monarch and the Leader of the United Kingdom. Charles expected to respect the monarchial neutrality, but he will not desist from voicing his political concerns.\nwith any paper\nThe Reign of Liberal Power\nThe most crucial factor to expect in the reign of King Charles III is that there will be significant changes to the structure of the Monarch. With the assessment of Suliman (2022), the first shift would be the extension of the liberal government to promote equality beyond the confines of the monarchial system. Charles III has already expressed his stand on politics. Generally, this implies a likelihood of increased engagement of the King and the members of the Monarch in the country’s political affairs. For instance, Charles has been at the forefront of the discussion of environmental factors and their influence on the climate. According to the discussions by Suliman (2022), there have been growing concerns from the house of representative over the influence that the Prince had on the public regarding the observed climatic change and the role that the public, as well as the government, has played in it. The Prince, however, never shied away from such debates despite the constitutional expectation of neutrality of the Monarch. His comments on the housing problem and the country’s architectural work also sparked tension in the country over the accuracy of his assessment. In this regard, it is safe to say that the King may introduce a more inclusive monarchial system that also weighs in on matters of the state. The general belief of the Prince has often been that there should be equal distribution of authority, which points to the extension of the liberal government.\nThe Slimming Down of the Monarchy\nThe plans to slim down the Monarch have been in the King’s mind for several years. With his entry into power, it is becoming eminent that this plan could be implemented. According to Krasteva (2022), the intention to slim down the Monarch basically involves the recalibration of what it takes to be a working member of the Monarch. There are general expectations that some of the existing posts and other members of the Monarch could be relieved from their duties. Initially, the intentions of the Prince were met with a lot of scrutiny from different stakeholders. There were concerns about the risks associated with taking such actions. Generally, this is accurate especially given the interconnection between the existing power hierarchy. As reported by Krasteva (2022), the functionality of the Monarch has been based on the ability of every system member to fulfill their duties. A change in the system could affect the fluency of operations, the Monarch’s functionality, and the King’s reign.\nyour paper for you\nNonetheless, it is worth upholding the risk that the King is willing to take to manage the authority and functionality of the Monarch. The King intended to establish an autonomous Monarchial system without necessarily distributing power to many people who could alter the system’s credibility. The underlying factor is that there should be a general expectation of changes to the Monarchy’s structure under King Charles III’s reign.\nAlthough the death of Queen Elizabeth leaves the entire world in a period of moaning, the excitement that comes with the expectation of the reign of King Charles III is rather satisfactory. For one, the King has been by the Queen’s side for a more significant part of her reign as the head of the Monarch. It means that he has the knowledge and experience to maintain and build upon the achievements that the Queen had brought to the country. However, his connection to the country and the public gives him added insight into what he should do to promote sustainable living. It is evident that the King is willing to speak on behalf of the people and is not afraid to express his political stance regarding matters affecting the people. There is, therefore, that security and the hope of a different Monarchial rain that is more inclusive of the people.\n- Gerring, J., Wig, T., Veenendaal, W., Weitzel, D., Teorell, J., & Kikuta, K. (2020). Why Monarchy? The rise and demise of a regime type. Comparative Political Studies, 54(3-4), 585-622. https://doi.org/10.1177/0010414020938090\n- Krasteva, G. (2022, September 9). King’s ‘slimmed down’ Monarchy could see key relatives cut from the firm. Metro. https://metro.co.uk/2022/09/09/king-charles-monarchy-could-see-key-relatives-cut-from-the-firm-17333619/\n- Low, V. (2022, September 9). Slimmed-down Monarchy is fit for the 21st century. The Times & The Sunday Times. https://www.thetimes.co.uk/article/slimmed-down-monarchy-is-fit-for-21st-century-c0p789nk6\n- Suliman, A. (2022, September 9). Britain has a new monarch: What to know about King Charles III. The Washington Post. https://www.washingtonpost.com/world/2022/09/09/uk-king-charles-iii-what-to-know/"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:391bd749-e366-433a-af23-39e626d0a970>"],"error":null}
{"question":"What are the main differences between open spine surgery and minimally invasive spine surgery?","answer":"Open surgery requires a long incision to access the spine, while minimally invasive spine surgery (MISS) uses smaller incisions and avoids open manipulation of muscles and tissue around the spine. MISS leads to shorter operative time, less postoperative pain, and faster recovery. However, not all patients are candidates for MISS - there needs to be certainty that MISS can achieve same or better results than open surgery.","context":["If you’ve struggled with back pain for any length of time, you may be wondering if spine surgery is your only treatment option. Sometimes, surgery is the only treatment. However, there’s good news. The vast majority of back problems can be remedied with non-surgical treatments—often referred to as non-surgical or conservative therapies.\nAging, improper body mechanics, trauma and structural abnormalities can injure your spine, leading to back pain and other symptoms such as leg pain and/or numbness or even leg weakness. Chronic back pain is a condition that generally requires a team of health professionals to diagnose and treat. Before resigning yourself to surgery, consider getting opinions from several spine specialists. This investment of time and information-gathering will help you make an informed treatment decision that will best support your lifestyle and desired level of physical activity.\nWhat about conservative non-surigcal treatment?\nAs with all non-emergency spinal surgeries, a trial of non-operative treatment, such as physical therapy, pain medication—preferably an anti-inflammatory, or bracing should be observed before surgery is considered. The trial period of conservative treatment varies, but six weeks to six months is the general timeframe.\nSpine surgery may be recommended if non-surgical treatment such as medications and physical therapy fails to relieve symptoms. Surgery is only considered in cases where the exact source of pain can be determined—such as a herniated disc, scoliosis, or spinal stenosis.\nOpen surgery vs. minimally invasive spinal surgery\nTraditionally, spine surgery is usually performed as open surgery. This entails opening the operative site with a long incision so the surgeon can view and access the spinal anatomy. However, technology has advanced to the point where more spine conditions can be treated with minimally invasive techniques.\nBecause minimally invasive spine surgery (MISS), does not involve long incisions, open manipulation of the muscles and tissue surrounding the spine is avoided, therefore, leading to shorter operative time. In general, reducing intraoperative (during surgery) manipulation of soft tissues results in less postoperative pain and a faster recovery.\nImaging during spine surgery\nComputer-assisted image guidance allows surgeons to view the operative site in far finer clarity than traditional visualization techniques. In addition, implants such as rods or screws can be inserted and positioned with a greater degree of accuracy than is generally achieved with conventional techniques.\nIn computer-assisted image guidance, images taken preoperatively (before surgery) are merged with images obtained while the patient is in surgery, yielding real-time views of the anatomical position and orientation of the operative site while the patient is undergoing surgery. Preoperative computed tomography (CT) and intraoperative fluoroscopy (real-time x-ray) are generally used, as these enable surgeons to operate with a high level of precision and safety.\nNot all patients are appropriate candidates for MISS procedures. There needs to be relative certainty that the same or better results can be achieved through MISS techniques as with an open procedure.\nWhether open surgery or MISS, the spine can be accessed from different directions. These are referred to as surgical approaches and are explained below:\n- Anterior approach: As the name implies, the surgeon accesses the spine from the front of your body, through the abdomen.\n- Posterior approach: An incision is made in your back.\n- Lateral approach: The pathway to your spine is made through your side.\nCommon spine surgical procedures\nThere are a number of conditions that may lead to spine surgery. Common procedures include:\n- Discectomy or Microdiscectomy: Removal of a herniated intervertebral disc. Therefore, removing pressure from the compressed nerve. Microdiscectomy is a MISS procedure.\n- Laminectomy: Removal of the thin bony plate on the back of the vertebra called the laminae to increase space within the spinal canal and relieve pressure.\n- Laminotomy: Removal of a portion of the vertebral arch (lamina) that covers the spinal cord. A laminotomy removes less bone than a laminectomy.\nBoth laminectomy and laminotomy are decompression procedures. “Decompression” usually means tissue compressing a spinal nerve is removed.\n- Foraminotomy: Removal of bone or tissue at/in the passageway (called the neuroforamen) where nerve roots branch off the spinal cord and exit the spinal column.\n- Disc replacement: As an alternative to fusion, the injured disc is replaced with an artificial one.\n- Spinal fusion: A surgical technique used to join two vertebrae. Spinal fusion may include the use of bone graft with or without instrumentation (eg, rods, screws). There are different types of bone graft, such as your own bone (autograft) and donor bone (allograft). A fusion can be accomplished by different approaches:\nALIF, PLIF, TLIF, LIF: All pertain to lumbar interbody fusion used to stabilize the spinal vertebrae and eliminate movement between the bones.\n- Anterior Lumbar Interbody Fusion\n- Posterior Lumbar Interbody Fusion\n- Transforaminal Lumbar Interbody Fusion indicates a surgical approach through the foramen.\n- Lateral Interbody Fusion in which the minimally invasive approach is from the side of the body.\nExamples of spinal instrumentation include plates, bone screws, rods, and interbody devices; although, there are other types of devices your surgeon may recommend in treatment of your spinal disorder. The purpose of instrumentation is to stabilize or fix the spine in position until the fusion solidifies.\n- An interbody cage is a permanent prosthesis left in place to maintain the foraminal height (eg, space between two vertebral bodies) and decompression following surgery.\n- Interspinous process devices (ISP) reduce the load on the facet joints, restore foraminal height, and provide stability in order to improve the clinical outcome of surgery. An advantage of an ISP is that it requires less exposure to place within the spine and therefore is a MISS procedure.\n- Pedicle screws help to hold the vertebral body in place until the fusion is complete.\nSome patients are at-risk for their fusion not to heal properly or completely. Your surgeon may refer to this as a non-fusion, pseudarthrosis or a failed fusion. To help avoid fusion problems, your surgeon may recommend a bone growth stimulation. There are different types of stimulators; those implanted internally and others that are worn about the body area, such as the neck or low back.\nShould surgical treatment be your only recourse, it may help to understand that minimally invasive spine surgery offers many benefits. Patients who want to return to work and active play, as well as the elderly or those with major spinal problems, often achieve a higher level of function once symptoms are alleviated."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:cfc7e8a4-90d2-4423-8535-1f3dd1b1acc4>"],"error":null}
{"question":"How do down insulation and polyurethane foam compare in terms of their long-term durability?","answer":"Down insulation typically lasts about 3 times longer than synthetic alternatives, though its longevity depends heavily on usage conditions, care, and storage. Polyurethane foams, particularly in radome applications, are engineered for dimensional stability and maintain their properties over time, especially the LAST-A-FOAM FR-3700 series which is specifically designed to be tougher and more durable for rugged environments.","context":["Caring for Down\nThere are other general topics which need to be covered to give a more complete picture about down.\nThe one major criticism of down is its poor performance when wet and there's no denying that it can lose up to 90% of its insulation value when soaked through. The responses to this vulnerable point are; don't get it wet, use a proofed outer material, waterproof the down itself.\n'Don't get it wet'\nFor many people this works fine. Cold conditions present less problems and care can avoid most other potential soakings - but not all. An overflowing stream, a poor tent, even a long stay in very humid conditions with heavy condensation, and you may have a wet bag. In those circumstances a synthetic bag would be performing better, but so might the right down bag.\nPHD's Drishell outer fabric is waterproof, highly breathable and very light. We think this is the best way at present to tackle the problem. However proofed outers are not perfect. Bags made with Drishell and similar fabrics do carry a small weight penalty (Drishell is the lightest we know of this type), and they do let water in at the stitch line (e.g. if you are sleeping in a puddle). Bags can also be made with complete taped outer shells (we offer this option), which will be proof against nearly all situations, but the weight penalty of an extra skin is considerable.\nThe only remaining alternative is to waterproof the down itself. Methods for doing this have been around for years, all making substantial claims about improved performance in wet conditions. We test this kind of material ourselves at regular intervals for 3 simple criteria:\n- Does the down wet out more slowly?\n- Does it absorb less water when fully wet (weight gain)?\n- Does it dry more quickly (left to dry without applied heat, as in a true 'field' situation)?\nRight up to the present we have found no measurable difference between treated and ordinary untreated down.\nThe fillpower test gives a measure of the loft of the down tested at that moment, nearly always new down. It gives no indication of how long any particular down will hold that performance or of how quickly it will deteriorate. The only method of assessing long-term performance lies in the experience and skill of both supplier and manufacturer. As before processing can affect the future life of the down as much as the raw material itself and experienced eyes know what to look for in a new down.\nThe criteria which ensure longevity differ a little from those which produce good results in the first fillpower test. For example cluster size: I have seen downs composed of small clusters, which only afforded average - good results when new, still giving undiminished performance after more than twenty years of regular use, several washes and continual stuff-sac storage - while other downs with larger clusters have deteriorated much more quickly. However these are not scientific tests - no two bags get identical usage over a period of years and deliberately storing bags under compression bears no resemblance to the hard treatment of real use.\nOverall this may appear a discouraging point: you can buy a bag with good down in it, but with no guarantee of how long it will last. That is true enough, but the factor most likely to degrade your down bag is your usage of it - how often, how dirty and wet the conditions, how you care for it, store it, etc. Read about cleaning and washing down. Console yourself with the thought that even downs with a comparatively 'short' life are likely to last 3 times as long as a synthetic equivalent, and a down with long life . . . well, you may give up the sport first!\nBag design and construction\nThe whole point of high quality down is to provide warmth for the least weight (otherwise you might as well use feathers - much cheaper and just as warm if you put enough in). To maximise the effectiveness of the finest fill requires good design. Down with the highest fillpower in the world will not provide the best weight/warmth package if the shell uses inferior materials or poor construction. And such is the price of the best downs that they are an expensive folly unless matched by design and craftsmanship of an equally high order.\nPHD's bag design is covered in this article, but it is worth remembering that high fillpower figures by themselves are only the start of a superior bag.","Protecting Signal Strength – General Plastics’ Foam for Radomes\nFrom defense and solar system research to boats and aircraft, radome structures perform the function of protecting radar equipment. These weatherproof shells transparent to radio frequency systems, notably radar, microwave, and other antennae, are used for signal transmission and capture that do not affect the signal passing through them. Although “radome” is a blend of “radar” and “dome,” these protective structures are not always dome-shaped but come in many different types, which include flat panels covering sensitive components of antennas on large dishes and small radar systems used in naval applications.\nGeneral Plastics’ polyurethane foams are commonly used as composite materials and offer dielectric properties for constructing radomes and related housings. They provide an optimal, insulating barrier between sensitive electronics used in communication, telemetry and radar systems and environmental threats posed by rain, wind, hail, snow, sand, insects, bird strikes, UV damage and rapid fluctuations in temperature.\nWide-ranging radome applications\n- Security/Military/defense – Radomes protect and conceal electronic surveillance equipment, such as that used to intercept satellite communications and other radar air defense applications. They support military aircraft platforms for reconnaissance, electronic warfare, defense and preemptive strikes, data links and electronic countermeasures.\n- Stationary antennae – Radomes prevent debris, ice and freezing rain from accumulating directly onto the metal surface.\n- Commercial aircraft – Needed for navigation or communications, commercial flights rely on signals. Radomes used in protective structures on the noses of aircraft ensure optimal antenna functionality for weather detection.\n- Maritime satellite communications – Ships employ radomes to protect dish antennae used to continually track fixed satellite and for navigation.\n- Broadband communications – On oil tankers and large cruise ships, radomes extending more than three meters in diameter may cover antennae connecting them to voice, data television and Internet transmissions.\n- Private yachts – Small private yachts may use radomes as small as 26 cm in diameter for voice and low-speed data.\n- Solar system research – NASA uses large radar dishes in far-flung, uninhabited areas that offer minimal pollution of signal.\nWhy polyurethane foams are optimal for constructing effective barriers\nRadomes built using suitable materials and configured properly for the application and radio frequency range are essentially invisible electronically, preventing negative impact on the performance of the signals produced or captured. Versatile, robust and cost-effective, our polyurethane foams offer high performance and low dielectric interference, with superb dimensional stability. Two reasons they don’t change over time is that these foam materials are closed-cell and hydrophobic: They do not absorb water. Water is highly polar and can cause them to lose their properties or change over time.\nWhat’s more, in extremely cold and windy environments, foam structures surrounding radar dishes prevent snow and wind from moving them around. And, as a natural insulator, our foam material prevents cold and heat from transferring, slowing down potentially undesirable changes in temperature. For example, in the transition from night to day, an unprotected antenna in direct sunlight can heat up quickly, jeopardizing performance and longevity.\nGenerally, radomes are fabricated using layup or prepreg methods in which resin-reinforced laminate materials are readily bonded to low- or medium-density rigid polyurethane foams. Our polyurethane foams are already renowned for supporting composite structures, which capitalize on their high strength-to-weight ratio.\nAll of General Plastics’ foam material holds distinct characteristics and advantages that help determine their applications. Specific General Plastics foam feature low dielectric constant and low loss tangent, making it ideal for radome applications. Material selection may also depend on the shape or contours of the sensitive electronics being covered and how imperative it is to protect them. The polyurethane foams best suited for these applications are our LAST-A-FOAM® FR-3700 Performance Core series and FR-7100 Multi-Use Core series.\nLAST-A-FOAM® FR-3700 has specifically engineered properties that make it tougher and more durable than the FR-7100. The FR-3700 is able to handle rugged environments for a given density, such as those needed for military and defense applications that dictate the highest levels of protection. This performance core series is flame-retardant, is an excellent alternative to wood, resistant to most chemicals and solvents, and has a high-strength to weight ratio.\nAlthough not as tough as the FR-3700, our LAST-A-FOAM® FR-7100 is sufficient and more affordable for applications involving less risk. Other benefits of this multi-use core series include its fine cell structure that supports smooth finishes, dimensional stability, and its closed-cell characteristic that does not absorb water or moisture. We recommend using FR-7100 for applications that allow for more variation or have less performance requirements.\nLarger radomes typically have simpler exposure requirements. For example, a very large radome in Alaska only has to handle some wind and potentially hail, whereas a naval ship or a weaponized system will call for a tougher, more significant composite to protect that radar system from loss. This is also a function of foam formulation and density driving material properties.\nTesting conducted on General Plastics’ signature LAST-A-FOAM® materials (see our dielectric materials white paper for dielectric constant and loss tangent data), demonstrates how the foams performed well under a range of applied microwave frequencies without significant heat loss. Our products are proven impervious to moisture and virtually transparent to radio signals, they are the leading choice for protecting aerospace, marine and land-based microwave antennae.\nOur polyurethane foams can be provided in three ways: 1) as sheet stock, which can be further modified to meet customer needs, 2) machined to shape based on a supplied drawing with dimensions noted and 3) as a molded part. In addition, for some applications, we can provide material cast to a specified shape.\nRegardless of whether you are selecting foam material in boards or blocks, or you rely on General Plastics for machining or finished product, we advise contacting our Customer Solutions team early in the design process. Each query may be very specific, so tap our expertise to identify in advance the design’s impact on cost. Our technical data sheets for each product also provide valuable guidance.\nComposite Core: Factors to Consider When Choosing Core Material for Your ApplicationRead More\nGeneral Plastics’ Aerospace-Grade Core Materials and Built-to-Print Polyurethane Parts For the Business Aviation IndustryRead More\nGeneral Plastics to Feature High Temp, Low CTE Tooling Board, Dielectric Foam and Other High Performance Polyurethane Foam at CAMX 2019.Read More\nGeneral Plastics to Spotlight Lightweight Composite Core and Dielectric Materials at SAMPE, May 22-23Read More"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:f671db4d-ad62-4a20-a11d-1a7712979731>","<urn:uuid:76f67e3e-32fc-4375-80cb-bba94bd34a49>"],"error":null}
{"question":"¿Qué diferencias existen entre los riesgos financieros de iniciar un negocio independiente versus una franquicia de restaurante?","answer":"The key differences in financial risks are that independent businesses require building everything from scratch while franchises provide pre-existing plans and support. Independent startups need comprehensive financial modeling to project revenues, costs and cash flows, requiring significant time spent on creating models and templates. In contrast, franchises come with established business models and easier access to financing since banks and investors are more familiar with franchise operations. However, franchises have high upfront costs including renovation, equipment, permits, and ongoing franchise fees paid to the franchisor.","context":["Starting a new business is an exciting yet challenging endeavor. With new ventures come financial risks and uncertainties that need to be carefully managed for success. This is where financial modeling comes into play. Developing comprehensive financial models with the help of templates can provide immense value in planning and risk mitigation for startups.\nThe Imperative of Financial Modeling in Startup Risk Management\nFinancial modeling is an indispensable tool for startups to identify growth opportunities and chart a path to profitability and long-term success. By creating detailed projections of revenues, costs, cash flows, and other key financial metrics, startups can get valuable insights into the financial viability of their business models.\nFinancial modeling serves as an essential risk management tool by revealing potential cash flow issues, working capital requirements, profitability timelines, and funding needs in advance. This allows startups to plan accordingly and ensure sufficient capitalization in order to survive the crucial early stages. Robust financial planning is essential for startups to successfully pitch to investors as well.\nIn summary, financial modeling provides clarity, direction, and focus for startups by enabling informed decision-making under uncertainty. The exercise of building models forces startups to thoroughly evaluate their assumptions and scenarios.\nThe Power of Templates in Financial Modeling\nBuilding an accurate financial model from scratch is complex and time-consuming. This is where using templates can make the process significantly easier for startups.\nProfit and loss Google Sheets template offers pre-formatted spreadsheets that include commonly used financial statements, formulas, and modeling layouts. This saves startups countless hours and reduces the chance of errors. Templates are flexible and allow for customization based on the startup’s unique projections and assumptions.\nWith the formulas already built in, startups can focus their time on the quality of inputs and analysis rather than structuring the model. Pre-made templates ensure all essential financial statements are included and appropriately integrated. Overall, templates enable startups to create comprehensive, investor-ready models efficiently.\nThe Anatomy of a Financial Model\nA financial model is made up of three key components – the income statement, balance sheet, and cash flow statement. Together, they provide a comprehensive view of the company’s expected financial performance.\nAccording to a 2022 PwC study, 87% of investors say a financial model is essential for them to properly evaluate a startup’s potential.\nThe income statement projects revenues, expenses, and profits over a period of time. It offers visibility into the company’s profitability. The balance sheet is a snapshot of assets, liabilities, and equity at a given point. It provides insights into the company’s financial strength. The cash flow statement projects cash inflows and outflows. It shows the company’s liquidity position and need for external financing.\nIn addition to these core statements, financial models include other vital elements like key performance metrics, drivers and assumptions, scenario analysis, and sensitivity analysis.\nPreparing for Financial Modeling: Data and Assumptions\nThe quality of a financial model depends on how accurate the inputs and assumptions are. For startups, it’s important to do the necessary work of researching industry data, looking at how things have gone in the past, figuring out what will drive growth, and making educated guesses.\nCreating assumptions for best, worst, and likely scenarios is really important. This gives you a realistic range of predictions to figure out if your idea makes sense and what risks are involved. It’s also important to write down these assumptions clearly so that everyone can understand why you’re making them.\nWhen you have good data and assumptions, you can trust that your models will help you make important decisions for your business. Going through the financial planning process also helps startups see where they might be missing information or where their guesses need to be improved.\nSelecting the Right Financial Modeling Software\nStartups have a bunch of financial modeling tools to pick from, so it’s crucial to choose one that suits their needs and how much they know about this stuff. Excel is everywhere and easy to use for simple modeling. But if you’re dealing with more complicated stuff, you might want to check out fancier options, which give you more control and flexibility.\nLook for tools that let you work together on the model and can show different scenarios. It’s also important that the software has enough pre-built formulas and can connect with other programs. Being able to easily update the model as your business changes is a big deal too. The tools you go for can make a difference in how efficient you are, how accurate your numbers are, and how much you can actually learn from them.\nSpreadsheet Mastery: Building the Financial Model\nSpreadsheet skills are vital for constructing financial models. Startups should structure the model logically with separate tabs or files for each statement, properly formatted columns and rows, and consistent formulas.\nBest practices include color coding, notes explaining assumptions, separating inputs from calculations, hyperlinking sheets, protecting cells, and keeping previous versions for comparison. Macros can automate repetitive steps.\nError-checking formulas like variance analysis should be used. Startups should also avoid using hard-coded values and circular references. Mastering spreadsheets takes practice but is well worth the effort for error-free models.\nTesting and Validation: Ensuring Model Integrity\nCompleting the initial model is just the first step. Startups must thoroughly test the model to identify weaknesses or errors. Validation techniques like sensitivity analysis, scenario modeling, and stress testing evaluate assumptions and simulate alternative conditions.\nTesting reveals which drivers most influence the outputs and how vulnerable the projections are to change. This allows for strengthening the model by adjusting unrealistic assumptions. Ongoing testing and refinement are key to keeping the model relevant as the business evolves.\nInterpreting Outputs and Key Metrics\nThe true worth of financial modeling comes from looking at the results and using them to make smart choices. Startups need to pay attention to important numbers like how much their revenue is growing, how much money they’re making after taking out costs when they’ll start making a profit, how much cash they have, what their short-term money needs are, and how well they’re using their resources.\nThese numbers give a clear idea of how well the business is doing and where there might be problems. This helps startups come up with plans, set goals, and decide where to spend their money. It also helps them figure out if they’re missing any money and what they should change about their plans.\nBest Practices in Financial Modeling\nCreating robust startup financial models requires following certain best practices:\n- Make conservative assumptions to allow for unforeseen events\n- Build scenarios to stress test the business concept\n- Clearly document assumptions for transparency\n- Structure model logically with consistent formulas\n- Validate with sensitivity analysis and external opinions\n- Update periodically as business plans progress\nAdhering to these practices results in high-quality models that can be reliably used for planning and decision-making.\nFrequently Asked Questions\n- How often should a startup update its financial model?\nStartups should aim to update their financial models at least quarterly. More frequent monthly updates are recommended in the early stages as the business is rapidly evolving. Events like fundraising, new product launch, expansion plans, or change in assumptions also warrant immediate model updates.\n- What are the common pitfalls in financial modeling for startups?\nCommon mistakes like overlooking costs, underestimating timescales, including sunk costs, using hockey-stick projections, and not testing assumptions can reduce the reliability of startup models. Insufficient documentation, messy spreadsheets, and lack of version control are other pitfalls.\n- How do investors evaluate the financial models of startups?\nInvestors scrutinize the assumptions, growth metrics, profitability timeline, and viability of the business model. They assess the thoroughness of scenario planning and risk analysis. The clarity and integrity of the model itself are also important investment criteria.\nFinancial planning is a core discipline that differentiates successful startups. Developing detailed models leveraging templates accelerates the process and provides the visibility required to make smart financial decisions. Robust financial modeling and forecasting enable startups to successfully manage risks and capitalize on growth opportunities. With a reliable financial roadmap powered by comprehensive models, startups can embark on their entrepreneurial journeys with confidence.","Franchise investments don’t come without a steep cost. Most restaurant ventures require a considerable amount of capital and industry savvy to even get off the ground, but franchises can be a suitable option for those looking to invest in the restaurant sector without starting from scratch (plus, the success rates are much higher). If you’re thinking about taking the leap into a food-related franchise, make sure you’re well-versed on the responsibilities and costs that come along with this endeavor.\nWhile opening a restaurant franchise might seem like a walk in the park compared to other independent restaurant ventures, that’s not to say it’s without its drawbacks. Finding the right franchise to invest in from a site like Franchising.com is just the tip of the iceberg.\nThe Personal Sacrifices\nThe restaurant industry is no walk in the park. The hours are long, the labor can be physically intensive, and the stress level is high. You’ll often get there before anyone else, leave long after everyone has left, and you’ll be responsible for any legal issues that may arise. If you don’t have a cache of time to commit, this endeavor might not be suited for you.\nThe Initial Investment\nYou’ll need quite a bit of capital to ensure your plans for a food franchise come to fruition. From venue renovations to rent, food preparation equipment to furniture, plumbing and utilities, and more, you’ll need to come up with a hefty sum before making headway in your venture. You’ll also need to pay your employees, access the right insurance, and consider the rising costs of vendor supplies. Remember that when profits do start rolling in, you’ll be handing over a significant chunk of what you make to the franchisor.\nThe Permits and Regulations\nThere’s no end to the permits you’ll need to secure and regulations you’ll be required to abide by. Food businesses are governed strictly, and must keep up with legislation and various codes to ensure product safety for customers. This can be an expensive venture, and securing the permits initially (and renewing them) can take quite a bit of time and capital. For starters, you’ll need to secure your venue, then apply for zoning permits, and make sure all of your equipment is up to standard. On top of all this, if your restaurant franchise is known for serving alcohol, you may find it hard to secure the proper liquor licenses. Say you’re in a highly saturated area, like California. Your chances of securing a liquor license can be slim to none, depending on your budget and the current economics of your specific area. More often than not, franchisees will need to secure these licenses through brokerage services like License Locators, Inc, and heavy competition might mean soaring prices.\nThese are just a smidge of the stressful aspects of the business. You’ll have to have a comprehensive handle on the tax implications of your new franchise venture, deal with unsavory guests, and pay fees to the franchisor in addition to the abovementioned issues. However, with all of these risks addressed, it’s important to take a look at the major benefits inherent to a franchise investment.\nA Pre-Existing Plan\nA lot of the work is done for you when it comes to franchise ventures, as the business has shown itself to be previously successful and forged out a specific concept. From customer service to the foods served, operation facets to atmosphere, you’ll have a roadmap of sorts to get your business off the ground.\nAs a franchisee, you’ll be given a variety of materials and assets that independent restaurant owners don’t get. From advertising and marketing help, to customer support, to training seminars, you’ll have a variety of resources to draw from, there for you from the get-go.\nLuckily, financing for franchise ventures are relatively easy to come by. Private lenders and banks alike are often approached by those looking to succeed with restaurant franchises. As they’ll likely have a good handle on the real estate, equipment, and day to day operations that come along with such a proposal, convincing private investors of your potential is a much easier task. Similarly, franchise investments tend to have a fairly high return rates, which can be extremely attractive to investors who have run this particular gamut before.\nBuying a restaurant franchise might be the perfect business endeavor for you, but it’s essential to have the proper education and knowledge about the industry before diving in head first. While franchise ventures are generally considered to be a safer bet than starting a business from scratch, it’s definitely riddled with its own risks so do your homework on the franchise sector."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"content_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:0938d464-7b41-4a39-9dc6-304dbd651a37>","<urn:uuid:4a8fde1d-915b-447b-a674-2d478645dc78>"],"error":null}
{"question":"What's the shelf life of prepared salads with meat or fish, and what symptoms indicate they've made you sick?","answer":"Ready-to-eat salads containing meat or fish last 3-5 days in the fridge when properly stored. If contaminated, they can cause foodborne illness with symptoms including diarrhea, vomiting, abdominal pain, fever, and headache. More serious cases may present with vomiting blood, double vision, and bloody stools. The onset of symptoms can occur anywhere from 30 minutes to three weeks after consuming contaminated food.","context":["How long does salad last in the fridge? That will depend on what it’s made of! From dressings to toppings, what makes up a salad dictates how long you can expect your salad to stay fresh. Want to know more? If so, read on!\nHow Long Does Prepared Salad Last in Fridge?\nSo, how long does prepared salad last in the fridge?\nPrepared salad lasts about 1-5 days in the fridge, depending on the freshness of the ingredients beforehand. It also depends on what the salad is made up of.\nFor this segment, we will assume that your salad is traditional and is made up of lettuce and vegetable produce. A salad of this sort will last a few days before it loses its crisp freshness, but again, it also depends on how fresh your lettuce and other salad components were, to begin with.\nHow Do You Keep Salad Fresh in the Fridge?\nKeeping a traditional leafy green salad fresh in the fridge is relatively easy.\nSimply place your undressed salad in an airtight container or store it in a ziplock bag large enough to contain all of your lettuce and toppings.\nYou may also consider placing paper towels in your storage bowl or ziplock bag before placing your salad in the refrigerator to keep your salad leaves nice and crisp.\nHow Can You Tell If Salad is Bad?\nA “bad” salad will likely be brown and mushy. The leaves will no longer have their familiar crunch, and your toppings, such as your tomatoes, may have turned to mush as well.\nBear in mind that most salad leaves have little to no smell, so if you smell something funny when taking a whiff of your salad, be sure to throw it out.\nIs It Safe to Eat Leftover Salad?\nAssuming that all of the ingredients that compose your salad are still good, your salad should still be safe to eat.\nParameters that would make your salad unsafe to eat would be a salad that is left out at room temperature that contains dairy products, such as cheese or yogurt, meat products, such as bacon or ham, or egg.\nMoreover, any dressed salads would likely not be safe for consumption if the salad was left at room temperature for many hours, especially if those salad dressings, such as ranch, contain dairy.\nCan You Eat Leftover Salad the Next Day?\nYes, but with caveats.\nAgain, provided that you have refrigerated your leftover salad within two hours of making it, your salad should be perfectly safe to eat the next day.\nJust be sure to note any brown spots, odd smells, or sliminess before chowing down.\nHow Do You Make a Salad Last Longer?\nA salad lasts the longest if you use fresh ingredients, to begin with. It’ll also last longer if you refrigerate your salad within two hours of making it and use paper towels when storing it.\nAlso, consider purchasing a salad spinner as this will rid your leaves of excess water which can make your salad soggy and mushy after a few days.\nCan You Get Sick From Old Salad?\nEating anything “old” can technically make you sick, however, it will depend on what your salad is composed of to determine how high the risks of foodborne illness are.\nIf your salad contains meat, dairy, or egg products, the risk of foodborne illness may be higher than if your salad was composed of veggies only.\nHowever, if the products used in your salad were in any way contaminated before consumption, then, of course, your risk of illness will increase.\nExpired dressings may also make you sick, especially if those dressings contain dairy.\nHow Long Certain Types of Salad Last in the Fridge\nHow Long Does Tuna Salad Last in the Fridge?\nTuna salad can last in the fridge for 3-5 days.\nHow Long Does Green Salad Last in the Fridge?\nGreen salad typically lasts anywhere from 1-5 days in the fridge.\nHow Long is Caesar Salad Good in the Fridge?\nCaesar salad can last about 1-5 days in the fridge.\nHow Long Does Spring Mix Last in the Fridge?\nSpring mixes tend to last in the fridge for 1-5 days, or until the expiration date marked on the package.\nHow Long Does Pasta Salad Last in the Fridge?\nPasta salad can last in the fridge for 4-5 days.\nHow Long Does Chicken Salad Last in the Fridge?\nChicken salad tends to last in the fridge for about 3-5 days, similar to tuna salad.\nHow Long Does Potato Salad Last in the Fridge?\nPotato salad can last in the fridge for up to 5 days.\nHow Long Does Egg Salad Last in the Fridge?\nEgg salad lasts in the refrigerator for up to 5 days.\nHow Long Does Macaroni Salad Last in the Fridge?\nMacaroni salad lasts in the fridge for 3-5 days.\nHow Long Does Quinoa Salad Last in the Fridge?\nQuinoa salad lasts in the fridge for 3-5 days.\nHow Long Does Fruit Salad Last in the Fridge?\nFruit salad can last in the refrigerator for up to 5 days.\nA dressed leafy green salad will technically still keep for 1-5 days, but be aware that the dressing on the salad can cause the leaves to become wilted after a few days. Thus, you shouldn’t expect your salad to have the same crispy crunch it had when the salad was fresh.\nHow Long Does Salad Last in the Fridge? That Depends on the Salad!\nSalad lasts in the refrigerator for up to 5 days in most cases, but ingredients do matter. Whether your salad is a snappy leafy greens salad or potato salad, just be sure to keep an eye out for signs of spoilage as the days go by. Enjoy!","Seniors and Foodborne Illness\nFoodborne illness is a serious problem in the U.S. A staggering 76 million people get sick each year from eating contaminated food, and 5,000 die. And seniors are especially vulnerable, according to NIH SeniorHealth, a division of the National Institutes of Health that focuses on older people. The reasons: less stomach acid, which makes it harder to get rid of harmful bacteria like E.coli and salmonella; slowed-down digestion, allowing the bacteria to stay longer in the system; and a weaker sense of taste and smell, which might otherwise warn us away from doubtful food. (In addition to bacteria, parasites and viruses may also cause illness.)\nOverall, the number of cases is increasing because we tend to eat out more often and have no control over how our food is prepared; our food is also transported to us over longer distances and more resistant bacteria may contaminate it. Additionally, according to the U.S. Department of Agriculture, summer brings great risks because of the often dicey circumstances of outdoor food preparation and storage.\nClick through to learn more:\nTap this link to comment.\nSymptoms and Overview Symptoms of food poisoning include diarrhea, vomiting, and abdominal pain. Other symptoms may be fever and headache. Signs of an even more serious case of foodborne illness include vomiting blood, double vision and bloody stools.\nAlthough many people tend to think that they’re being affected by their most recent meal, SeniorHealth says that the gap between eating the bad food and the onset of illness is anywhere from 30 minutes to three weeks.But although the thought of foodborne illness can be scary, there are steps you can take to protect yourself. At home, make sure to wash prep surfaces and food thoroughly. Cook food all the way through, and don’t wait to store leftovers. If you’re eating out, the restaurant should be clean in everything from tables to rest rooms, and if you ordered a hot meal it should be hot and not lukewarm.\nWhether you’re eating at home or away, though, there are some foods you need to be skeptical about, and maybe skip altogether. Here they are:\nRaw or undercooked poultry, meat or seafood...\nRaw milk, milk products and juices...\nPartially cooked or raw eggs as well as foods made with them, including cookie dough, cake batter and Caesar salad dressing. Eggnog’s also on the list...\nRaw sprouts - bean, alfalfa, corn...\nReady-to-eat salads, whether with meat or fish\nClick through to find the best ways to handle foodborne illness if you think you have it:\nContact your doctor or health care provider immediately; go to a hospital emergency room if you need to. The federal Centers for Disease Control and Prevention (CDC) has a 24/7hotline: 1-800-232-4636.\nPreserve the food in question. Wrap it securely, label it \"Danger\", and freeze it. The food may be used to diagnose your illness and prevent others from getting sick. Save all packaging materials, such as cans or cartons. Write down the food, the date and time consumed, and save any identical unopened products.\nReport the contaminated food to the USDA Meat and Poultry Hotline at 1-888-674-6854. You can also call the FDA Consumer Complaint Coordinator in your state A complete list can be found at: www.fda.gov/safety/reportaproblem/.\nCall your local county or city health department if you think you became ill from food you ate at a local restaurant or other eating establishment so they can investigate.\nTap this link to comment."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:0655c1f1-76aa-4eed-8951-9fd8e8ce469c>","<urn:uuid:e1e0a05e-2b61-4c7b-ad60-ae516b701bc7>"],"error":null}
{"question":"I'm researching the early history of Taoism. When and where was Lao-Tse, the founder of Taoism, believed to have lived according to traditional accounts?","answer":"According to traditional accounts from the Chinese historian Sima Quian, Lao-Tse was born in 571 BC in Kuxien in the state of Chu (located in today's Henan Province). He served as an archivist at the court during the Zhou dynasty in the 6th century BC. However, some religious scholars dispute this timeline and believe Lao-Tse actually lived in the 3rd century BC, as they consider such an early development of the Taoteking improbable in intellectual history.","context":["(Published in Grail World 14/1999)\nAmong the three great Asian founders of religion - Buddha, Confucius, Lao-Tse - one has received special attention in the West: Lao-Tse (Lao-zi, Lao Tan). The Taoteking (Dao-de-jing) attributed to him has been translated several times into European languages. No less a person than Martin Heidegger (1889- 1976) worked out a translation together with a Chinese, and Carl Gustav Jung (1875- 1961) wrote commentaries on Taoist writings. GralsWelt editor Siegfried HAGL summarizes what is known about the \"enigmatic sage\".\nWho Was Lao Tzu?\nLittle is known historically of the great Chinese sage; However, there are many legends surrounding the life of the Lao-Tse, similar to the reports about Buddha, some of which contradict each other. The only official account of the life of Lao-Tse does not appear until centuries after his work in the Chinese historian Sima Quian (Ssu ‑ ma Ch'ien, approx. 145-90 BC). Accordingly, Lao-Tse (= the \"old master\") had the name Li ‑ Erl, the age name Eo ‑ Yang and the taboo name Dan. Under the rule of the Zhou dynasty, he held the office of archivist at the court in the 6th century BC. According to these reports, Lao-Tze was founded in 571 BC. Born in Kuxien in the state of Chu (today's Henan Province), he was about 20 years older than Confucius.\nSome religious scholars consider this information to be incorrect and assume that Lao-Tse did not live until the 3rd century BC, as such an early development of \"Taoteking\" is improbable in intellectual history.\nIn Sima Quian's “historical records” (Shih ‑ chi) one of the most cited statements about the life of Lao-Tse appears, which also inspired Bert Brecht to write his ballad:\n“Lao-Tzu spent most of his life in Chou. Foreseeing the city's decline, he left it and came to the border. The border guard Yin-Hi said to him: The Lord wants to withdraw, may I ask the Lord to write me a book? ' Then Lao-Tse wrote a book in two parts, containing more than 5,000 words, in which he dealt with the terms \"the way\" (Tao) and \"the power\" (Te). Then he left. Nobody knows where he died. \" (5, p. 358)\n\"But let's not only praise the wise\nWhose name is emblazoned on the book!\nBecause one must first wrest his wisdom from the wise man,\nThat's why the customs officer should also be thanked:\nHe demanded it from him. \"\nFrom the \"Legend of the origin of the book Taoteking on the path of Lao-Tse into emigration\" by Bertold Brecht (1898-1956).\nMany scholars have questioned these few historical dates, and there remains room for conjecture and legend. The existence of the above-mentioned book is indubitable, regardless of when and by whom it was written. As Taoteking (Dao ‑ de ‑ jing) it is one of the most translated books in Chinese literature, of which German translations are also available in every major library.\nTo us Westerners, Taoteking is usually only accessible in translations, which are all the more difficult as the original is ancient Chinese texts, the exact meaning of which is not always clear even for Chinese scholars, and the interpretations of the ancient traditions are correspondingly contradictory. A central term for Lao-Tse is the Tao (Dao), and at the beginning of Taoteking there is a famous play on words, which in its contradiction leads to the Asian method of conveying truths:\n\"A writable Tao would not be the eternal Tao,\nA name that can be named would not be the eternal name. \" (4, p. 103).\nThe first verse of the text already says that what is to be conveyed cannot be described. The author deliberately expresses himself unclear, even makes contradicting statements in order not to give the thinking too many fixed points that could be used to suppress feelings that are better suited to absorbing spiritual knowledge. The millennia-old tradition of the West in philosophical and theological speculations has a hard time with the open and therefore ambiguous, sometimes illogical statements that are used in Asia when dealing with higher insights.\nTao literally means \"way\". It is often interpreted as the original principle, elemental force, from which all being and all things emerge:\n“There is a being, completely perfected, even before heaven and earth existed. It stands alone, quiet and empty, and does not change. It turns in circles and never gets tired. It can be seen as the mother of the world. I don't know his name, so I call it (hence simply) Tao. \" (2, p. 53).\nRegarding the origin of the Tao, Lao-Tse says that he does not know who it came from. However, it appears more originally than the gods, has already existed before heaven and earth and is to be regarded as the mother of the world. So would the Tao in Lao-Tse be the effect of the living laws of creation, the working of God's will? In the words of the Lao-Tse, which are not easy to understand, the occidental seeker of God will even sense a recognition of the only God through whom all created things came into being.\nIn the West it is generally assumed that the knowledge of the only God is due to Moses and the people of Israel. However, regardless of this, there are also echoes of this knowledge of God in other peoples - from the ancient Egyptians to Indian myths - so that one can also trust ancient China and its sage Lao-Tse with corresponding insights.\nA second important term in Taoteking is the Te (De):\n“Tao creates things, Te maintains them.\nThe world of things forms it, power completes it.\nSo there is none among the ten thousand beings who do not respect Tao and value Te.\nRespect Tao and value Te - nobody gave the order, and it will forever happen by itself. \" (4, p. 106).\nThis text is usually interpreted in such a way that Te is understood to mean the work of the Tao in the world. Tao and Te - creating and sustaining power - therefore work together. But unfortunately not always as it would be natural and right: Conceived by the Tao, the young, tender life is still completely subject to the effectiveness of the Tao. As you grow up, however, an increasing proportion of life of your own takes effect, which more and more suppresses the influence of the Tao:\n“When people begin to live they are tender and weak, when they die they are tough and strong. When the ten thousand beings, plants and trees begin to live, they are tender and soft; when they die, they are withered and rigid. Therefore that which is hard and strong is a companion of death and that which is soft is a companion of life. \" (2, p. 54).\nSo the Tao works in every person. According to Taoist doctrine, with increasing age, people develop ever greater activity, which removes them more and more from their true roots. Above all, it is selfish drives that cut people off from the Tao. In Taoism, the way back to the sources of its existence is liberation from all desires. Uninterrupted activity leads to ruin, so the motto is: Don't act! This inaction by the Taoist means switching off human activity, reflecting on inner values so that the Tao can develop in people.\nConsequently, Lao-Tse thinks little of comprehensible knowledge and the imparting of earthly knowledge; he advocates an unpretentious life. His ideal for earthly life are small states that work together modestly and peacefully, without rivalries or even wars and without personal ambition. Man should also not intervene in the ways of nature.\nYou have to see this ideal of peaceful life against the background of the epoch: Lao-Tse lived at the time of the \"Warring States\" (481-221 BC), while China was a chaos of rival and fighting small states brought a chain of suffering and hardship upon their citizens. As a counter-reaction, there was almost inevitably a lesson that renounced not only the war, but also envy, ambition and all the other vices that repeatedly gave rise to self-destructive arguments. Last but not least, parallels to Buddhism can be found: Buddha's “eight-part path” also wants to lead to liberation from desires, to the dissolution of earthly ties.\nLao-Tse and Confucius\nAccording to tradition, the \"old masters\" and Confucius, who was two decades younger than him, met in person, and Zhuangzi reports in the 4th century BC about a presumably fictitious dialogue between the two opponents.\n- LAOTSE strives for internalization, turns away from the world and its gears and preaches looking upwards.\n- CONFUCIUS builds on intelligible thinking and above all gives his students earthly rules of conduct without dealing with the transcendent, the hereafter, the divine, which he himself says he cannot grasp with his own means.\nAccording to tradition, Lao-Tze draws Confucius' attention to the futility of his path; Knowing full well that humanity cannot be morally uplifted through understanding efforts and doctrines directed towards earthly well-being, and predicts its failure. But neither Confucius nor the royal court in which the meeting is said to have taken place allow themselves to be dissuaded from their earthly goals by the words of the “old master”.\nIt was and is no different in China than anywhere else in the world: The path of internalization, of spiritual striving, is known, but it is left to individuals, medieval mystics or so-called \"saints\". Thinking towards the outside, looking for solutions to daily problems without finding their true causes, is closer to most people who strive for material success and do not strive for spiritual and spiritual development, whose value, especially for life on earth, is not is recognized.\nLao-Tze said: “When the highest human species hears the Tao (truth), they strive to live according to it. When the mediocre hear the Tao, they seem to notice and yet not notice. When the lower class of people hears of the Tao, they burst into laughter. Because if the Tao weren't laughed at, it wouldn't be the Tao. \" (3, p. 14).\nThe volume “Lao-Tse - Life and Work of the Trailblazer in China”, published by the Grail Message Foundation, is particularly suited to illuminating the spiritual contrasts between the teachings of Lao-Tse and Confucius.\nTaoism has undergone many changes since Lao-Tse. From a more philosophically oriented religious doctrine it became a strongly esoteric movement that even wanted to overcome the phenomena of physical decay such as old age, illness and death through alchemy and meditation in the Middle Ages.\nEnd-time expectations of a “New Kingdom of the Chosen” emerged, just as many manifestations of other religions were practiced in Taoism (monasticism, celibacy of the priests, hermitism, etc.). Confrontations with Buddhism, to which Taoism is close in some respects, did not fail to materialize in the 13th century, for example.\nTaoism has always been a typical Chinese religion, which, in addition to the motherland, is found primarily in Chinese settlement areas (e.g. Taiwan, Hong Kong, Southeast Asia) but also in Korea. There Taoism could outlast the Cultural Revolution, which made practically all religious practice in Red China impossible. Today there are Taoists and renovated Taoist temples again in the People's Republic of China, and the old traditions are being maintained. Due to their long history and extensive literary tradition, the Taoists refrain from being referred to as \"shamans\" who deal primarily with esotericism, but rather see Taoism as a high religion.\nBuddhism, Taoism and Confucianism get on well in Asia today; In the understanding of many Chinese, they even merge and complement each other, so that religiously oriented Chinese often feel that they belong to all three systems at the same time. One speaks of the \"three ways that have one goal\" or says that the three religious directions are like \"three legs of a tripod vessel\".\nThe classics of Taoism\nIt is the classical work ascribed to the Lao-Tse. Today it is of the opinion that the scriptures undoubtedly come from the \"period of the warring states\" (Zhan ‑ guo ‑ period, 421-221 BC), and probably not only has one author. The basic work may come from Lao-Tse, supplemented and expanded by text passages added later. Its content is difficult to translate into other languages, and individual translations differ accordingly.\nThe book Zhuangzi (Tschuang-Tse):\nThe second most important representative of the Taoist school is Zhuangzi (Master Zhuang), who lived in the 4th century BC, about 100 years later as Lao-Tse. The thoughts of the Zhuangzi are based on the teachings of the Lao-Tse, but bring differentiation and expansion. For Zhuangzi, too, the Tao is the focus as the all-encompassing primal force, the all-inclusive principle through which the universe came into being.\nAsians are less inclined to religious fanaticism or even to religious wars, which does not have to mean that they take their religious teachings less seriously than other peoples.\nBut today people meditate on the essence of the Tao as they did two and a half millennia ago:\n\"The Tao is a hollow vessel,\nAnd its use is inexhaustible!\nLike the fountainhead of all things\nIts edges rounded,\nHis snares loosened\nHis light dimmed\nHis vertebra submerged,\nIt still seems to remain dark like deep water.\nI don't know whose son it is\nA picture of what existed before as God. \" (3, p. 56).\n(1) Glasenapp, Prof. Dr. Helmuth v .: \"The non-Christian religions\", Fischer, Frankfurt aM, 1957.\n(2) Ladstätter / Linhart: \"China and Japan\", Carl Ueberreuter, Vienna, 1983.\n(3) Lin Yutang: “The wisdom of Lao-Tse”, Fischer, Frankfurt aM, 1955.\n(4) Moritz, Ralf: \"The Philosophy in Old China\", German Science Publishing House, Berlin, 1990.\n(5) Tworuschka, Monika and Udo: “Religions of the World”, Orbis Verlag, Munich, 1996."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:812ece2f-bf00-4579-b5d3-15d06492dada>"],"error":null}
{"question":"As a behavioral economics student, I want to understand how Mauboussin's and Thaler's views on rationality differ. Can you compare their perspectives on human decision-making?","answer":"Mauboussin and Thaler present complementary views on human rationality and decision-making. Mauboussin focuses on how people tend to adopt an 'inside view' that leads to overconfidence, underestimating risks while overestimating benefits, without considering distributional information from previous similar situations. Meanwhile, Thaler introduces the concept of 'limited rationality,' demonstrated through the 'endowment effect' where people irrationally value items more when they own them. He also identifies 'social preferences' showing people don't act purely out of self-interest, and 'limited control' arising from conflict between the short-term focused 'doing-self' and long-term oriented 'planning-self'. Both scholars ultimately challenge traditional economic assumptions about rational decision-making, with Mauboussin emphasizing overconfidence biases and Thaler focusing on systematic deviations from pure economic rationality.","context":["Samuel Goldwyn recast Thomas Jefferson’s earlier observation: “I am a great believer in luck, and I find the harder I work, the more I have of it.”\nMichael Mauboussin, of Columbia University, and previously Chief Investment Strategist at Legg Mason Capital Management Inc. investigated this relationship between effort and luck in his book, The Success Equation.\nMauboussin, an innovator in behavioral finance, adopted Harvard biologist Stephen Jay Gould’s “paradox of skill” to analyze the interaction of effort, skills, and luck, and best strategies to optimize outcomes in investing, sports, and career performance.\nHe posits that as skill improves in activities where outcomes are affected by skill and luck, the standard deviation of skills narrows.\nIn this case, luck becomes more important in determining outcomes:\n“Whenever you see an outlier in sports, it is always a combination of really good skill and really good luck… (Often) they are about one and a half or two standard deviations away from the average…not all skilled players have (winning) streaks, but all (winning) streaks are held by skillful players.”\nFor example, as investors become more sophisticated and have access to advanced computational tools, as athletes benefit from targeted training and development regimens, and as students are groomed for admission to top universities, differences among these skilled performers decreases.\nChance influences can determine outcomes.\nMauboussin says that luck has several elements:\n- Affects an individual or organization,\n- May be evaluated as “good” or “bad”\n- Another outcome could have occurred\n- The outcome is uncontrollable, but is comprised of several elements\nTo increase luck, he advises assessing each contender’s strength in the situation and finding “…something completely different to get you on the right side of the tail of the skill distribution,” such as employing an unusual or unexpected tactic.\nThe stronger player has positive asymmetric resources, so the effective strategy is to simplify the game.\nIn contrast the underdog should seek to complicate the game, such as through disruptive innovation, a flank strategy or a guerilla tactic.\nBecause most people have a bias toward optimism and overestimate personal capabilities, it may be difficult to assess oneself as an “underdog” in a performance situation.\nNobel Prize winner Daniel Kahneman and Amos Tversky explained that individuals who adopt an inside view gather substantial information, combine it with their own inputs, then project into the future without considering “distributional information” about a wide variety of previous instances.\nThis approach risks developing an idiosyncratic, overconfident perspective by underestimating costs, completion times, and risks of planned actions, while overestimating benefits.\nIn contrast, people who adopt the outside view consider the problem as an instance of a larger reference class and consider the entire distribution of outcomes when this type of situation occurred previously.\nThis approach can reduce overconfidence.\nHowever, this approach could discourage entrepreneurs, who will realize that a small percentage actually succeeds.\nIn addition, besides the bias toward overconfidence, people tend to “under-sample” instances of failure when a previously successful approach is applied in a new situation and doesn’t succeed.\nSabermetricians like Nate Silver, posit that worthwhile statistics provide:\n- Persistence or correlation from one period to the next, a strong indicator of high skill\n- Predictive value or high correlation with the target objective\nThe Oakland As baseball team uncovered these principles in determining that a superior measure of athletic performance in this sport is on-base percentage rather than the traditional measure, batting average.\nIn this case, on-base percentage has a higher correlation from one season to the next and a higher correlation with run production than batting average, fulfilling both criteria.\nDaniel Kahneman also suggested that skill, expertise, and intuition render more uniform results in a predictable environment.\nCollective judgments through “the wisdom of crowds” may mitigate the challenges of unstable contexts because they provide more data points.\nMauboussin advocated considering the continuum of stability vs instability in which the issue is situated to determine strategy and to beware of applying simple heuristics that are vulnerable to bias, and social or situational influences.\nHe suggested the guideline “think twice” to prepare, detect and correct for common mental traps, including:\n- The Inside-only View\n- Tunnel Vision\n- Situational Power\n- Overvaluing Expert Knowledge\n-*How do you optimize your performance when chance elements can affect your outcomes?\n- It’s Mostly Random, So Just Do Something\n- Biases in Unconscious Automatic Mental Processing, and “Work-Arounds”\n- Reduce Evaluator Bias: Showcase Best Features in Any Offer\n- Useful Fiction: Optimism Bias of Positive Illusions\n- Consider All Your Options at Once, Be Happier with Choices: Minimize “Quest for the Best” Bias\n- Hypothetical Questions May Lead to Bias\n- Detect and Mitigate Decision Biases\n- Human Decision Biases Modeled with Automatons\n- Overcoming Decision Bias: Allure of “Availability Heuristic”, “Primacy Effect”\n- Creating Productive Thought Patterns through “Thought Self-Leadership”","Richard H Thaler—the Charles R Walgreen distinguished service professor of behavioral science and economics at the University of Chicago Booth School of Business—who is engaged in researching behavioral economics and finance and the psychology of decision making has been awarded the 2017 Nobel Prize in Economics “for his contributions to behavioral economics” that built a “bridge between the economic and psychological analyses of individual decision-making”, paving the way for “the new and rapidly expanding field of behavioral economics.”\nReacting to the award of Nobel Prize, Thaler said that his major contribution to economics is “the recognition that economic agents are human, and economic models have to incorporate that [factor]”. And perhaps, as an acknowledgement of his argument about the sometimes-unreasonable behavior of humans, he jocularly said, “I intend to spend the prize money ‘as irrationally as possible’”.\nJokes apart, what Thaler meant when he said “economic agents are human” is: traditionally, economists assuming that each person makes totally rational choice in pursuit of their own self-interest, built elaborate theoretical and mathematical models to explain how markets work to efficiently allocate capital and set prices. But Thaler along with Daniel Kahneman and Amos Tversky challenging this underlying premise of the models, demonstrated how often individuals make illogical choices that sabotage their economic interests, that too, believing that they are totally rational. Citing Brexit as a classic example of behavioral economics in action, Thaler observed that British voters chose an economically irrational route while considering the options offered to them by the elites.\nStudying the underlying reasons for people to behave irrationally, he came up with three propositions: one, ‘limited rationality’; two, ‘social preferences’; and three, ‘limited control’. The concept of limited rationality is explained through ‘endowment effect’ where individuals value an item more when they own it rather than when they do not. To test this hypothesis, he gave coffee mugs at random to half of a group of test subjects asking them to sell them, if they wish, to the other mug-less half of the group. Rationality demands that people from both the groups must, on average, value them the same, and accordingly, half of the mugs should change the hands. Contrary to this expectation, the have-nots valued the mug less while the haves have valued it high and as a result few mugs have changed hands.\nMoving to the role of ‘social preferences’ in economic decisions, Thaler says that individuals do not necessarily make choices driven solely by selfish interests. For instance, in an experiment conducted by him, he asked a randomly selected student to divide a $20 bill between himself and another subject. Rarely had he noticed any student retaining the whole amount with himself, as pure rationality would suggest. Similarly, his studies revealed that people find practices like overcharging for a good under duress as unfair.\nAlong with Hersh Shefrin, Thaler developed the third idea, namely, ‘limited control’ that emanates from the conflict between two competing cognitive forces of an individual: ‘doing-self’ which is more concerned with short-term happiness and ‘planning-self’ that values long-term goals more. To resolve this dichotomy, he says that the planning-self perhaps offers fewer choices to the doing-self that lie in the immediately upcoming future. And this phenomenon runs contrary to the economic theory of rationality, for more the choices, the better would be the decision. It otherwise means, presenting people with a “choice architecture” which favors the planning-self than the doing-self can impact people’s behavior in a big way.\nIt is perhaps taking a cue from this phenomenon that Thaler came up with his now famous “nudging” theory. He co-wrote the global best-selling book, ‘Nudge: Improving Decisions about Health, Wealth and Happiness’ in 2008 with Cass Sunstein that nudged governments to explore his ‘nudging’ theory to achieve better outcomes in the financial behavior of people—of the society at large. For instance, we are all aware that we need to save more for our retired life. But under most of the hitherto operating schemes one has to voluntarily choose: you need to first decide to save, then decide how much to put aside, in which scheme and for how long? It is too much for most of the people and thus many in the US were found under-saving.\nThen came Thaler with a paper, “Save More Tomorrow: Using Behavioral Economics to Increase Employee Saving” jointly with Shlomo Benartzi of UCLA that revolutionized designing pension schemes. Under this new design, employees of the company are automatically enrolled in the plan, that they will contribute an initial percentage of their salary, that this contribution will increase each year by a certain percentage of their salary increase, and if the employees make no further choices, they will be assigned to a target date fund that is designed to automatically control asset allocation along the way towards assumed date of retirement of the respective employee. There is, of course, a provision for the employees to always opt out of any of these provisions. Intriguingly, thus default-enrolment proved to nudge employees to save for their retired life more effectively, for seldom anyone opted out. With the result, people in the automatic plans found saving more than those outside of them. And an obvious improvement is: the quality of life for future retirees.\nHe thus came up with the concept of improving “choice architecture”—an architecture that does a favor to their planning-self over their doing-self, so that it can result in better financial behavior. For instance, suppose a prospective client of credit card is provided with all the charges and fees to be paid under its usage right at the time of his choosing the card, would it not enable him to make a better choice rather than to struggle with loads of fine print later and crib at the decision already taken?\nWorking for over three decades in association with a group of behavioral economists around psychology of decision making, economics and sociology, Thaler has simply nudged even the hardnosed rationalists to look differently at how people think when it comes to money and the decision making thereof and importantly nudged rationalists to appreciate that there exists deviations in human behavior, for human agents act fallibly. And all this happily nudged him to pocket his much deserving Nobel Prize too."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:20737c08-4a1c-4a2d-bad0-5f7404fe4ccd>","<urn:uuid:c29ddd2e-9609-4a06-934c-0f839795a9f2>"],"error":null}
{"question":"What are the key principles of fine bubble aeration systems in wastewater treatment, and what factors affect their oxygen transfer efficiency?","answer":"Fine bubble aeration systems transfer oxygen by creating small bubbles through diffusers located near the tank bottom. The diffusers break up air from a low pressure, high volume compressor to disperse bubbles throughout the aeration tank. The bubbles transfer oxygen across their surface into the water as they travel upward. For good performance, the oxygen supply rate should match the consumption rate. Several factors affect oxygen transfer efficiency: depth (approximately 1.6% efficiency per foot of depth), basin geometry (full floor coverage provides better efficiency than partial coverage which can create spiral flows), and installation configuration (diffusers may be floor-mounted or side-mounted to produce specific flow patterns). The air flow rates typically need to be 0.33-0.67 L/m3 to ensure adequate mixing.","context":["ADVANTAGES OF DIFFUSED AIR SYSTEMS\nThe equipment used to deliver oxygen to an aeration system is typically provided by surface\nmechanical type aerators or diffused aeration systems. Common types of mechanical\nsurface aeration equipment include low speed mechanical aerators, direct drive surface aerators\nand brush type surface aerators.\nDiffused aeration systems include a low pressure, high volume air compressor (blower), air piping system and diffusers that break up the air by the dispersement of bubbles throughout the aeration tank.\nThe diffusion of air can be accomplished with several types of diffusers.\nDiffusers are normally located near the tank bottom. Optionally, they may also be placed along one tank side to produce a spiral or cross-roll pattern or may be installed as a floor-mounted grid system. The installation must support air flow rates of 0.33 to 0.67 L/m3 x (20-40 cfm/1000 cu ft), which are usually required to ensure adequate mixing. The air flow rates that are necessary to meet oxygen transfer requirements could also depend on digester loading.\nBoth fine bubble and coarse bubble diffusers have been used in aerobic digesters. Plugging of diffusers is a potential problem in aerobic digesters, especially in digesters whose operation includes periodic settling and supernatant removal. When air is turned off, slude and sediments can enter the air piping and adhere to the inner walls of piping or diffusers. Nonclog and porous media fype devices are more resistant than the large bubble orifice type diffusers to this type of plugging. However, surface fouling of porous diffusers may occur.\nOXYGEN TRANSFER VIA AERATION\nOxygen transfer, which is a vital part of numerous wastewater treatment processes, is the process by which oxygen is transferred from the gaseous to the liquid phase. The functioning of the aerobic process (such as activated sludge) depends on the availability of sufficient oxygen. Because of oxygen’s low solubility and its consequential low rate of oxygen transfer, the amount of oxygen required to sufficiently meet the needs of aerobic waste treatments is not introduced through normal surface air-water interfaces, but through additional interfaces.\nOxygen can be supplied by means of air or pure oxygen bubbles introduced to the water, which create gas-water interfaces. In wastewater treatment facilities, submerged bubble aeration is most frequently accomplished by dispersing air bubbles into the liquid through diffusion aerators, or “bubble diffusers”\nThe diffuser or bubble aeration process consists of contacting gas bubbles with water for the purpose of transferring gas into the water. The most commonly used diffuser system consists of a matrix of perforated tubes (or membranes) or porous plates arranged near the bottom of the tank to provide maximum gas to water contact.\nFor GOOD PERFORMANCE, the rate of supply of dissolved oxygen should be equal to the rate of oxygen consumption exerted by the mixed liquor under any given set of circumstances.\nWhile a number of equipment and operational parameters interact to influence the efficiency and rate of transfer of oxygen for a given volume of water being aerated, aeration devices are evaluated on the basis of the “quantity of oxygen tansferred per unit of air introduced to the water for equivalent conditions”.\nAERATION TO MAINTAIN AN AEROBIC CONDITION\nThe function of aeration in wastewater treatment is to maintain an aerobic condition. Its basic purpose is to improve water quality for subsequent reuse.\nAeration for wastewater or water treatment (or oxygen transfer) is well-studied. Methods developed to estimate the oxygen demand are biochemical oxygen demand (BOD), chemical oxygen demand (COD), total oxygen demand (TOD), total organic carbon (TOC), and theoretical oxygen demand (ThOD).\nAeration can bring about the physical removal of taste- and odor-producing substances, such as hydrogen sulfide (H2S) and other volatiles and the chemical removal of metals (iron, manganese), gases (hydrogen sulfide), and other compounds (organics and inorganics) through oxidation and settling. Aeration is also used extensively for the biological oxidation of both domestic and industrial organic wastes.\nThe Flexcap™ Diffuser can replace any existing diaphram aeration diffuser currently being used. This diffuser meets all aeration requirements required in commercial, municipal, recreational and residential property package wastewater treatment systems.\nAERATOR DIFFUSION FEATURES\n16 Air Holes on underside of diffuser, along with its self-wiping action, keep diffuser from plugging\nPockets reinforce locking lips to prevent blow-off\n|C.||Pockets actually agitate back and forth during aeration; the agitation wipes away debris and prevents plugging.|\nCap placement on the base allows movement – yet cannot be forced off, even under extreme contraction (including bursts up to 80 psi)\n|E.||Uniform thread design provides ease of replacement in existing or new water treatment installations.|\n|F.||Diffuser cap material is formulated to retain flexibility and resist brittleness|\n|G.||Multiple fingers are extra long and uniform to accept direct stress, which hold the cap on longer – even under extreme pressure, shifting or vibration|\n|H.||Smooth top keeps debris from clinging and settling on the base and provides a clean, even seating surface even when the air is shut off|\nRFQ Inquiry Form","For years, wastewater lagoon systems have provided secondary treatment performance to many small to medium sized communities. The attributes of these processes have been attractive as cost effective options for the treatment of municipal wastewater. The aeration segment in these systems is the most critical component and is the core of their biological treatment process. A lagoon systems ability to aerate the incoming sewage has a direct impact on the level of wastewater treatment it achieves. This page will focus on the heart and soul of these systems - aeration.\nAn ample oxygen supply in a wastewater pond system is the key to rapid and effective wastewater treatment. Oxygen is needed by the bacteria to allow their respiration reactions to proceed rapidly. The oxygen is combined by the bacteria with carbon to form carbon dioxide. Without sufficient oxygen being present, bacteria are not able to quickly biodegrade the incoming organic matter. In the absence of dissolved oxygen, degradation must occur under septic conditions which are slow, odorous and yield incomplete conversions of pollutants. Under septic conditions, some of the carbon will react with hydrogen and sulfur to form sulfuric acid and methane. Other carbon will be converted to organic acids that create low pH conditions in the ponds and make the water more difficult to treat. For example, treated ponds designed to biodegrade wastewater pollutants without oxygen often must hold the incoming sewage for six months or longer to achieve acceptable levels of pollution removal. This is because the biodegradation of organic matter in the absence of oxygen is a very slow kinetic process.\nThe designers of wastewater lagoon systems must take into account the fate of the biological cells, called sludges, that would eventually settle to the pond’s bottom. One advantage to using an aeration system to treat wastewater is the lack of sludge volumes that require treatment. Unlike conventional wastewater treatment plants that must remove excess sludges daily, a pond type system can go from ten to twenty years without ever needing cleaning. This is because, in the presence of sufficient oxygen, bacterial cells that settle to the ponds bottom are eventually biodegraded into carbon dioxide and inert materials. Since a large portion of municipal wastewater consists of biodegradable organic carbon matter, much of the settled sludge in the lagoon can be quickly decomposed by the remaining active bacteria. If sufficient oxygen is not present in the ponds, the sludge layer will accumulate faster than it can be biodegraded. When this occurs, the sludges may build up to a point that it must be removed at a faster rate than would be expected for a pond. This effectively eliminates the main advantage of a lagoon system which is supposed to be an infrequent sludge removal need.\nAdequate aeration is also an important element in keeping the lagoons content mixed and in suspension. Even in a partially-mixed hydraulic regime, mixing is very important to the overall treatment process. With adequate mixing, incoming pollutants and wastewater are better distributed throughout the entire lagoon volume. This results in more uniform and efficient treatment. In addition, solids that settle can be resuspended by the aerator’s mixing action and brought back into contact with the microbial population floating throughout the pond. Poor mixing has the effect of creating thick solids deposits that fall to the lagoon floor before proper treatment has occurred. This causes improperly treated solids to fall away from the active, overhead treatment process. It also creates septic conditions on the lagoon bottom which, in themselves, pull available oxygen out of the upper layers of the pond and reduce the effectiveness of treatment in the upper zone.\nClearly the proper aeration and mixing of a lagoon is critical if the system is to properly treat the influent wastewater pollutants. A plant that has never had proper aeration and mixing will often result in a lot of money spent on electrical power for aeration purposes with little lagoon oxygen to show for this expenditure as well as deep accumulations of partially treated sludge on the lagoons floors which requires frequent removal.\nThe proper oxygenation of a treatment system also has important implications for an emerging wastewater treatment plant toxicity issue. Raw sewage contains large amounts of ammonia (N H3). The typical ammonia concentration of raw sewage is 30 ppm. This ammonia is present as a natural consequence of the degradation of protein-based compounds in wastewater. Nitrogen is a major building block of protein which is present in wastewater due to the discharge of protein based wastewater materials. As the organic compounds that contain protein are degraded, ammonia is released into the raw sewage stream. This is problematic because ammonia has been found to be toxic to aquatic organisms in the water body. In the presence of adequate oxygen, the nitrogen in ammonia can combine with the oxygen to form non-toxic nitrate compounds (NO3-). In order for this reaction to occur, the plant must have sufficient dissolved oxygen available.\nBoth coarse and fine bubble diffused aeration systems transfer oxygen into the water by creating small bubbles. As the bubbles travel through the water, oxygen is transferred across the bubble’s surface and into the water. Mechanical aerators work in the opposite way by creating small droplets of water using a mixer. These droplets are propelled through the atmosphere above the ponds surface. Oxygen in the air is transferred into the small water droplets which then fall back into the water.\nThere are many factors that will act to hinder the transfer of the oxygen load in a wastewater lagoon system. All of these factors must be considered to ensure that sufficient air is added to allow the necessary pounds of oxygen per day to be transferred. Some of these factors include:\nAll of the above factors must be considered collectively to properly size aeration equipment for any treatment system. These factors can be mathematically related to match the actual oxygen requirement (AOR) needed to meet field conditions, with the standard oxygen requirements (SOR), at which aeration equipment is rated in the laboratory. The relationship between AOR and SOR is very important in properly designing a pond’s aeration system. AOR represents the actual amount of oxygen that needs to be added to the ponds under full design loading, full ammonia conversion, and worst case temperature conditions. SOR represents the excess oxygen that must be added in order to make sure that the AOR will be met. Blowers and diffusers are sized on the basis of SOR which represents clean water conditions at 20 degrees Celsius and sea level air pressures. They are purchased on the basis of SOR after first relating the required AOR conditions to SOR conditions.\nHaving determined the standard oxygen requirement of a pond system, it is next important to consider how much air volume in SCFM (standard cubic feet per minute) will be needed to deliver that mass of oxygen. Each cubic foot of air added to the lagoon will contain about 0.0173 pounds of oxygen. The oxygen transfer efficiency (OTE) of a diffuser system is a function of its depth in the ponds. Typically, an OTE of about 1.6% per foot of depth is found for fine bubble diffusers in a pond setting. For a lagoon with ten feet of depth, a transfer efficiency of about 16% could be expected. This means that 16% of the air added at a depth of ten feet will actively be transferred into the water while eighty-four percent will be excess and will bubble to the surface. This seems like an excessive air loss rate, but it is the best now available with current technology.\nWould your wastewater treatment plant benefit by replacing an older aeration system such as coarse bubble diffusion with fine bubble technology? It’s well worth investigating. It is important to understand some critical terms, such as oxygen transfer efficiency and alpha, before beginning your evaluation. The oxygen transfer efficiency of an aeration system is the ratio of the amount of oxygen that actually dissolves into the water to the total amount of oxygen pumped into the water. Only the dissolved oxygen is available for treatment, and any portion of oxygen that does not dissolve is a waste of energy and, therefore, money.\nFinally, aeration basin and aerator layout geometry can dramatically alter oxygen transfer efficiency. Standard clean water transfer efficiency tests are usually based on full floor aerator coverage. This creates a nearly ideal situation for oxygen transfer. A turbulent counter-current flow regime is established with a volume of water being dragged upward with the rising bubbles, being opposed by an equal flow of water traveling downward. In large basins, such as lagoons, full floor coverage is not normally needed to meet the biological aeration demands. As a result of incomplete coverage, large scale currents can form a spiral roll in the basins. The air bubbles flow with the water, which significantly reduces the transfer efficiency. Compared with the full floor configuration, many more air bubbles short-circuit their way to the top of the aeration basin.\nAlthough it may be true that fine bubble systems can provide an appreciable savings in many situations, those who purchase and operate these systems without verification do so at the peril of their own bottom line cost. How can you avoid this pitfall? First, test the system proposed with your wastewater. Do not trust a vendor who does not recommend oxygen transfer testing. Second, make sure that oxygen transfer testing mimics the actual conditions, including the configuration of your basin. The cost of aeration system testing can be high and may not be affordable for many plants. Before testing, the potential cost savings of switching to fine bubble aeration should be evaluated. Literature, vendor, and EPA values for oxygen transfer efficiently and alpha can be used. Find plants with similar wastewater to refine from their experiences the values and contact plants to learn from their experience. If the investment in fine bubble diffusion appears favorable, consider testing before replacing the system.\nWhether it be a plant upgrade or a new facility, a lagoon system will not work well without proper aeration. As sludge disposal regulations become stricter and disposal sites become scarce, proper aeration will reduce the amount of solids that may have to be removed from the lagoons since more of the incoming pollutants will be oxidized."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:305d1741-5231-4cb3-884b-2444e84e3081>","<urn:uuid:41dd101a-b183-4d8a-8759-e3cb319dd78c>"],"error":null}
{"question":"What are the similarities and differences in feeding behaviors between velvet ants and honey bees, and how do these impact their effectiveness as pollinators?","answer":"Velvet ants and honey bees exhibit distinct feeding behaviors that affect their pollination effectiveness. Velvet ants have been observed drinking nectar from flowers and coming in contact with anthers during feeding, potentially facilitating pollination. However, their pollination services may be limited due to their primary role as predatoids of other Hymenoptera and infrequent flower visits. In contrast, honey bees focus primarily on nectar collection rather than pollen and are less effective pollinators compared to native species. Additionally, honey bees cannot perform buzz pollination, which is required for 15,000-20,000 plant species. While honey bees may contribute to pollination, they can also compete with native pollinators for resources and potentially spread parasites and diseases to native species.","context":["Nectaring by nocturnal velvet ants (Hymenoptera: Mutillidae).\nVelvet ants (Hymenoptera: Mutillidae) are a conspicuous component\nof the fauna of Nearctic deserts, but little is known about their\nnatural history. We observed an aggregation of female velvet ants on the\ndune-restricted plant Croton californicus var. mohavensis\n(Euphorbiaceae). We collected 44 female velvet ants on or directly\nbeneath a group of male and female plants during 2 nights. Some\nindividuals were on flowers drinking nectar. The discovery of nocturnal\nvelvet ants on C. californicus marks the first record of nectaring in\nnocturnal female velvet ants.\nLas hormigas aterciopeladas (Hymenoptera: Mutilidae) son un componente conspicuo de la fauna de los desiertos Nearticos, pero su historia natural es poco conocida. Observamos una agregacion de hembras de hormigas aterciopeladas en Croton californicus var. mohavensis (Euphorbiaceae), una planta de solo dunas de arena. Colectamos 44 hembras de hormigas aterciopeladas sobreo directamente debajo de un grupo de plantas machos y hembras durante 2 noches. Algunos individuos estuvieron en las flores consumiendo nectar. El descubrimiento de avispas aterciopeladas en C.\ncalifornicus en la noche constituye el primer registro de hembras nocturnas de hormigas aterciopeladas consumiendo nectar.\nInsect-plant relationships (Research)\nAnts (Environmental aspects)\nWilson, Joseph S.\nWilliams, Kevin A.\nTanner, David A.\nPitts, James P.\n|Publication:||Name: Southwestern Naturalist Publisher: Southwestern Association of Naturalists Audience: Academic Format: Magazine/Journal Subject: Biological sciences Copyright: COPYRIGHT 2010 Southwestern Association of Naturalists ISSN: 0038-4909|\n|Issue:||Date: Sept, 2010 Source Volume: 55 Source Issue: 3|\n|Topic:||Event Code: 310 Science & research|\n|Geographic:||Geographic Scope: United States Geographic Code: 1USA United States|\nVelvet ants (Hymenoptera: Mutillidae) are major components of the\nNearctic fauna. Despite their abundance, however, little is known of\ntheir natural history. While diurnal velvet ants have conspicuous\naposematic color patterns, such as those in the genus Dasymutilla,\nnocturnal species are small and inconspicuous. Male nocturnal velvet\nants are winged, and commonly are collected passively in light traps.\nFemales, which lack wings and are much less vagile, are collected most\ncommonly by visually searching potential habitat with a flashlight or by\nusing pitfall traps. It is common to collect >500 individual males in\na single night at one light, although <10 females may be found by\nsearching. While these methods are sufficient means of collecting velvet\nants, they do not facilitate observations of their behaviors. Passive\nmethods of collection, such as light and pitfall traps, preclude\nbehavioral observations, and the light from a flashlight often disrupts\nforaging by females.\nField observations of velvet ants are rare, especially for nocturnal forms. Previous observations on the biology of nocturnal velvet ants are limited to three Nearctic species, Sphaeropthalma unicolor, S. orestes,and S. blakeii (Mickel, 1938; Ferguson, 1962), and one African species, Pseudophotopsis continua (Mellor, 1927). None of these observations record any interactions of plants and velvet ants. Observations of feeding behavior in Nearctic forms include drinking of liquid sugars provided by researchers in a laboratory setting, and drinking from wounds in larvae of hosts caused during parasitism (Ferguson, 1962). Observers of the African species of Pseudophotopsis noted that female velvet ants wound adults of their host, a species of Bembix (Hymenoptera: Crabronidae), and drink liquid from the wounds (Mellor, 1927). Nearctic velvet ants may feed similarly on resting adults of their hosts, but no observation has been made (Ferguson, 1962). Here we present the first observations in the field of feeding behaviors by adult, nocturnal velvet ants.\nOn 4-5 September 2008, while collecting on a small sand dune 15 km ESE Saint George, Washington County, Utah, we observed an aggregation of nocturnal female velvet ants on Croton californicus var. mohavensis (Euphorbiaceae). Croton californicus var. mohavensis is a dioecious perennial shrub that grows exclusively in loose sandy soils of the Mojave Desert (Baldwin et al., 2002). This plant blooms late summer-autumn, but no detailed information is available concerning its requirement for pollinators. We collected 44 female velvet ants on or directly beneath a group of male and female plants during 2 nights. When lights were shone on shrubs in an attempt to observe behaviors of female wasps, most wasps dropped from branches to the ground and either ran away, or remained cryptically immobile in the sand.\nAfter initial observations, we returned to the shrubs to observe wasps using lights with red filters. Velvet ants did not seem to be affected by our presence or that of the light. We observed many individual wasps running up and down stems and leaves of male and female plants. Some individuals were on flowers drinking nectar. Additionally, we noted that while velvet ants were extricating nectar from a flower, they came in contact with the anthers. Because of the large number of individuals on an individual plant ( > 15), and proximity of male and female plants ( <0.5 m), velvet ants moving from one flower to another in search of nectar may transfer pollen from male to female plants. Pollination services offered by nocturnal velvet ants to C. californicus may be mitigated, however, by their poor dispersal ability, and the supposed infrequency with which they visit flowers. Velvet ants primarily are predatoids of other Hymenoptera and, consequently, spend the majority of their time searching for suitable hosts. Additionally, C. californicus may be serviced by other pollinators, as its flowers also are open during the day.\nFollowing their collection, female velvet ants were sorted to genus and morphospecies at Utah State University. Four morphospecies were in the genus Odontophotopsis and one morphospecies was in the Sphaeropthalma hyalina species-group. Hosts for these species are unknown, but each species had a well-defined pygidial plate. This trait is characteristic of velvet ants that parasitize ground-nesting bees and wasps. Twig-nest parasitoids often have a smooth, undefined pygidium (Pitts and Manley, 2004; Pitts et al., 2004). This supports our assertion that velvet ants on C. californicus were nectaring, rather than searching for hosts. This is the first behavioral observations for the genus, whose females were onlyrecently discovered (Pitts and Parker, 2003; Pitts et al., 2007). Aside from nesting aggregations of hosts (Ferguson, 1962), this is the largest concentration of nocturnal female velvet ants to be recorded.\nWe acknowledge the following people who helped collect specimens: C. Montierro-Waichert, J. Rodriguez, R. Barbosa, A. Ermer, and S. Clark. We also thank S. Topham ( JBR Environmental Consulting) for identification of plants and J. Rodriguez for helping to translate the abstract. This research was supported by the Utah Agricultural Experiment Station, Utah State University, Logan ( journal paper 8057).\nSubmitted 30 January 2009. Accepted 5 December 2009.\nAssociate Editor was Jerry L. Cook.\nBALDWIN, B. G., S. BOYD, B.J. ERTTER, R.W. PATTERSON, T. S. Rosatti, and D. H. Wilken. 2002. The Jepson desert manual: vascular plants of southeastern California. University of California Press, Berkeley.\nFERGUSON, W. E. 1962. Biological characteristics of the mutillid subgenus Photopsis Blake and their systematic values (Hymenoptera). University of California Publications in Entomology 27:1-92.\nMELLOR, J. E. M. 1927. A note on the mutillid Ephutomma continua Fabr. and of Bembex mediterranea Hdl. in Egypt with a summary of the distribution and of some previously recorded habits of the Mutillidae. Bulletin de la Societe Royale Entomologique d'Egypte 20:69-79.\nMICKEL, C. E. 1938. Photopsoid mutillids collected by Dr. K.A. Salman at Eagle Lake, California (Hymenoptera). Pan-Pacific Entomologist 14:178-185.\nPITTS, J. P., and D. G. MANLEY. 2004. Review of Lomachaeta Mickel (Hymenoptera: Mutillidae) of North and Central America. Zootaxa 474:1-27.\nPITTS, J. P., and F. D. PARKER. 2003. Description of the female and larval stage of Odontophotopsis succinea Viereck (Hymenoptera: Mutillidae), with a new synonymyand notes on the species. Zootaxa 137:1-10.\nPITTS, J. P., T. J. BOUD, and E. M. PILGRIM. 2007. Molecular sex association of three species of nocturnal velvet ant (Hymenoptera: Mutillidae). Journal of the Kansas Entomological Society 80: 136-145.\nPITTS, J. P., F. D. PARKER, and T. L. PITTS-SINGER. 2004. A review of the Sphaeropthalma uro species-group (Hymenoptera: Mutillidae), with taxonomic changes. Journal of the Kansas Entomological Society 77: 223-234.\nJOSEPH S. WILSON, * KEVIN A. WILLIAMS, DAVID A. TANNER, AND JAMES P. PITTS\nDepartment of Biology, Utah State University, 5305 Old Main Hill, Logan, UT 84322\n* Correspondent: email@example.com\n|Gale Copyright:||Copyright 2010 Gale, Cengage Learning. All rights reserved.|","This is the extended version of our article \"Do you care about Bees or other Pollinators, Please read this...\" This version, written by Andrew Goebel of Indigenous Landscapes, has more detailed insight into to the current state of native bees and honey bees with research sited in the end of the article.\nThe problem with pollinators\nMuch attention has been given to the decline of honey bee (Apis mellifera) populations and the potential consequences of their demise. Recent years have seen a rise in awareness of the importance of pollinators in general with much money and effort going towards creating “pollinator gardens” and “habitats” in cities, along highways, and our backyards. The majority of this attention has been on populations of honey bees and Monarch butterflies. When thinking of a pollinator, these are likely the two examples people have in mind. Although well intended, this narrow focus limits consideration of the bigger picture and the potential negative impacts of honey bees themselves.\nMissing from popular discussion is the less well known fact that native bee species have been declining in recent decades. Since most of the 4000 species of native bees lead a solitary existence (they are not social and don’t live in hives) they are difficult to study. Therefore the majority of native bee research has examined bumble bees (Bombus spp.) since they live in small colonies. The findings highlight the need to implement conservation measures sooner rather than later. One quarter of our bumble bee species have experienced significant declines, including some of the most common species (1).\nWhy do we need native bees?\nNot only can native bees pollinate the majority of world crops they are essential components of native ecosystems. Honey bees do not have the ability to “buzz pollinate” which is a requirement for 15,000-20,000 species of flowering plants (1). Decreased numbers of native bees contributes to decreased seed set from plants that they pollinate. In fact, pollination limitation is one of the most commonly found causes of reduced reproduction in wild plants (2). This results in decreased future forage opportunities, which further pressures native bees (1).\nWhat is driving the decline in native bees?\nIt is widely assumed that habitat loss and fragmentation are some of the leading causes of native bee decline. While urbanization certainly contributes to these conditions, it is agriculture that accounts for the majority of land use. In the United States over 60% of the land has been converted to different forms of agriculture representing an enormous loss of habitat and degradation of forage for numerous organisms including native bees. Some mid western states have undergone dramatic conversions. Illinois, for example, has lost its most of its prairies, wetlands, and forests to agriculture amounting to 95% of the land area in the northern two thirds of the state. Half of the bumble bee species found historically in Illinois have been either locally extirpated or showed declines in distribution (3).\nMost species of bumble bees are ground nesting. They build their homes in abandoned rodent burrows or other cavities within the soil. Prairie habitats that include sufficient areas of clumping grasses provide the necessary conditions for rodents to dig burrows. When farms in Illinois switched from having permanent and temporary pastures with wildflowers and multiple crops to primarily corn and soybean, the steepest declines in bumble bees occurred (3).\nFragmentation can be understood as a problem of ecosystem simplification. Despite mounds of research many ecosystem dynamics are still poorly understood. One theme that has emerged is that more complex environments support more species and are more resilient to change. The current agricultural system in the US is based on only a few crops which are often planted in large monocultures. These may be interspersed with patches of semi natural areas creating islands of habitat within a sea of agriculture. Areas that were once covered in any number of our thousands of native plants have become solid stands of only a few non native crops. This simplification of the environment has consequences.\nBumble bees require a variety of plants that flower at different times to provide food throughout the season. They are further specialized in their own emergence times and by length of their tongues which impacts what flowers they will visit. Agricultural conversion to only a few species of plants reduces the foraging window for all pollinators.\nIssues with honey bees and domestication of other bees\nIntroduced from Europe, honey bees did not co-evolve with native bees or the ecosystems in which they have been placed. Like many other introduced organisms, their presence can have unintended and negative impacts on native flora and fauna. In fact there is ample evidence that honey bees can contribute to the decline of native bees and flora.\nHoney bees compete for forage with native bees. Bumble bees have been shown to have reduced amounts of foraging in proximity to honey bee colonies - sometimes avoiding entire areas. The closer the nest sites the less that native bees were able to compete (4). Further, since honey bees focus on nectar collection instead of pollen they are less effective than native bees and other non bees (flies, beetles, etc) at pollinating and may be linked to the spread of invasive plants as well (1).\nWhen honey bees encounter native bees on the same flower there is potential to spread parasites and disease. This is also true of domesticated native bumble bees. The system of apiculture and native bee domestication creates populations that can harbor much higher pathogen loads than wild or native bees, increasing their chances of exposure. It may be possible for honey bees to spread deformed wing virus to bumble bees which has been implicated in the colony collapse disorder phenomenon (1). Honey bees are shipped around the country to match various bloom times, mingling sick and healthy colonies.\nFurthermore, pesticides that have been deemed “bee friendly” are only legally required to be tested on honey bees not native ones (4). Bumble bees are often active during pesticide application in the morning or evening that is timed to avoid mid day honey bee foraging (4).\nWhat can be done?\nChanging current agricultural practices is a clear way to mitigate the decline of native pollinators. Farmland designed to include sufficient habitat could support native bumble bees which have been to shown to effectively pollinate most crops without human intervention. A shift away from intense use of non native honey bees and other domesticated bees would lower competition with native pollinators and reduce the potential of debilitating pathogen outbreaks.\nTransitioning to a food system based on native food plants could address multiple problems at once. In such a setup, crop land itself could actually act as habitat and begin to reconnect our fragmented landscape.\n(1) Xerces Society for Invertebrate Conservation. (2016). An overview of the potential impacts of honey bees to native bees, plant communities, and ecosystems in wild landscapes: Recommendations for land managers.\n(2) Potts, S. G., et al. (2010). Global pollinator declines: trends, impacts and drivers. Trends in Ecology and Evolution, 25(6), 345-348.\n(3) Grixtia, J. C., Wonga, L. T. (2009). Decline of bumble bees (Bombus) in the North American Midwest. Biological Conservation, 142(1), 75-84\n(4) Goulson, D., Lye, G.C. (2008). The decline and conservation of bumblebees. Annual Review of Entomology, 53, 191-208"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:6633c401-94fb-4bc7-8952-6774777b3f26>","<urn:uuid:4a39da67-6257-4ebc-95bc-06131b56b69d>"],"error":null}
{"question":"¿Cuál es la diferencia principal entre el análisis de perturbaciones en teoría AdS/CFT y el análisis de fuerzas en rotación de cuerpos rígidos?","answer":"The main difference lies in their analytical approaches. In AdS/CFT theory, the analysis focuses on scalar exchange graphs in the crossed channel, examining non-analytic terms in hypergeometric functions to verify the existence of operator product expansion. In contrast, the analysis of rigid body rotation uses a more direct mechanical approach, examining tangential and normal components of forces and accelerations, with specific equations like Fn = mrGw^2, Ft = mrGα, and MO = IOα to describe the motion and forces acting on the rotating body.","context":["In the Black-Scholes type financial market, the risky asset S 1 ( ) is supposed to satisfy dS 1 ( t ) = S 1 ( t )( b ( t ) dt + Sigma ( t ) dW ( t ) where W ( ) is a Brownian motion. The processes b ( ), Sigma ( ) are progressively measurable with respect to the filtration generated by W ( ). They are known as the mean rate of return and the volatility respectively. A portfolio is described by a progressively measurable processes Pi1 ( ), where Pi1 ( t ) gives the amount invested in the risky asset at the time t. Typically, the optimal portfolio Pi1 ( ) (that, which maximizes the expected utility), depends at the time t, among other quantities, on b ( t ) meaning that the mean rate of return shall be known in order to follow the optimal trading strategy. However, in a real-world market, no direct observation of this quantity is possible since the available information comes from the behavior of the stock prices which gives a noisy observation of b ( ). In the present work, we consider the optimal portfolio selection which uses only the observation of stock prices.\nWe discuss the analytic properties of AdS scalar exchange graphs in the crossed channel. We show that the possible non-analytic terms drop out by virtue of non-trivial properties of generalized hypergeometric functions. The absence of non-analytic terms is a necessary condition for the existence of an operator product expansion for CFT amplitudes obtained from AdS/CFT correspondence.\nThe paper studies the dynamics of transitions between the levels of a Wannier-Stark ladder induced by a resonant periodic driving. The analysis of the problem is done in terms of resonance quasienergy states, which take into account the metastable character of the Wannier-Stark states. It is shown that the periodic driving creates from a localized Wannier-Stark state an extended Bloch-like state with a spatial length varying in time as ~ t^1/2. Such a state can find applications in the field of atomic optics because it generates a coherent pulsed atomic beam.\nWithin this paper we review image distortion measures. A distortion measure is a criterion that assigns a \"quality number\" to an image. We distinguish between mathematical distortion measures and those distortion measures in-cooperating a priori knowledge about the imaging devices ( e.g. satellite images), image processing algorithms or the human physiology. We will consider representative examples of different kinds of distortion measures and are going to discuss them.\nLinearized flows past slender bodies can be asymptotically described by a linear Fredholm integral equation. A collocation method to solve this equation is presented. In cases where the spectral representation of the integral operator is explicitly known, the collocation method recovers the spectrum of the continuous operator. The approximation error is estimated for two discretizations of the integral operator and the convergence is proved. The collocation scheme is validated in several test cases and extended to situations where the spectrum is not explicit.\nWe consider investment problems where an investor can invest in a savings account, stocks and bonds and tries to maximize her utility from terminal wealth. In contrast to the classical Merton problem we assume a stochastic interest rate. To solve the corresponding control problems it is necessary to prove averi cation theorem without the usual Lipschitz assumptions.\nThe statistics of the resonance widths and the behavior of the survival probability is studied in a particular model of quantum chaotic scattering (a particle in a periodic potential subject to static and time-periodic forces) introduced earlier in Ref. [5,6]. The coarse-grained distribution of the resonance widths is shown to be in good agreement with the prediction of Random Matrix Theory (RMT). The behavior of the survival probability shows, however, some deviation from RMT.\nAbstract: It has recently been shown that the equation of motion of a massless scalar field in the background of some specific p branes can be reduced to a modified Mathieu equation. In the following the absorption rate of the scalar by a D3 brane in ten dimensions is calculated in terms of modified Mathieu functions of the first kind, using standard Mathieu coefficients. The relation of the latter to Dougall coefficients (used by others) is investigated. The S-matrix obtained in terms of modified Mathieu functions of the first kind is easily evaluated if known rapidly convergent low energy expansions of these in terms of products of Bessel functions are used. Leading order terms, including the interesting logarithmic contributions, can be obtained analytically.\nAt present the standardization of third generation (3G) mobile radio systems is the subject of worldwide research activities. These systems will cope with the market demand for high data rate services and the system requirement for exibility concerning the offered services and the transmission qualities. However, there will be de ciencies with respect to high capacity, if 3G mobile radio systems exclusively use single antennas. Very promising technique developed for increasing the capacity of 3G mobile radio systems the application is adaptive antennas. In this thesis, the benefits of using adaptive antennas are investigated for 3G mobile radio systems based on Time Division CDMA (TD-CDMA), which forms part of the European 3G mobile radio air interface standard adopted by the ETSI, and is intensively studied within the standardization activities towards a worldwide 3G air interface standard directed by the 3GPP (3rd Generation Partnership Project). One of the most important issues related to adaptive antennas is the analysis of the benefits of using adaptive antennas compared to single antennas. In this thesis, these bene ts are explained theoretically and illustrated by computer simulation results for both data detection, which is performed according to the joint detection principle, and channel estimation, which is applied according to the Steiner estimator, in the TD-CDMA uplink. The theoretical explanations are based on well-known solved mathematical problems. The simulation results illustrating the benefits of adaptive antennas are produced by employing a novel simulation concept, which offers a considerable reduction of the simulation time and complexity, as well as increased exibility concerning the use of different system parameters, compared to the existing simulation concepts for TD-CDMA. Furthermore, three novel techniques are presented which can be used in systems with adaptive antennas for additionally improving the system performance compared to single antennas. These techniques concern the problems of code-channel mismatch, of user separation in the spatial domain, and of intercell interference, which, as it is shown in the thesis, play a critical role on the performance of TD-CDMA with adaptive antennas. Finally, a novel approach for illustrating the performance differences between the uplink and downlink of TD-CDMA based mobile radio systems in a straightforward manner is presented. Since a cellular mobile radio system with adaptive antennas is considered, the ultimate goal is the investigation of the overall system efficiency rather than the efficiency of a single link. In this thesis, the efficiency of TD-CDMA is evaluated through its spectrum efficiency and capacity, which are two closely related performance measures for cellular mobile radio systems. Compared to the use of single antennas, the use of adaptive antennas allows impressive improvements of both spectrum efficiency and capacity. Depending on the mobile radio channel model and the user velocity, improvement factors range from six to 10.7 for the spectrum efficiency, and from 6.7 to 12.6 for the spectrum capacity of TD-CDMA. Thus, adaptive antennas constitute a promising technique for capacity increase of future mobile communications systems.\nAbstract: We develop a method of singularity analysis for conformal graphs which, in particular, is applicable to the holographic image of AdS supergravity theory. It can be used to determine the critical exponents for any such graph in a given channel. These exponents determine the towers of conformal blocks that are exchanged in this channel. We analyze the scalar AdS box graph and show that it has the same critical exponents as the corresponding CFT box graph. Thus pairs of external fields couple to the same exchanged conformal blocks in both theories. This is looked upon as a general structural argument supporting the Maldacena hypothesis.","EQUATIONS OF MOTION: ROTATION ABOUT A FIXED AXIS Today’s Objectives: Students will be able to: Analyze the planar kinetics of a rigid body undergoing rotational motion. In-Class Activities: • Rotation About an Axis • Equations of Motion\nPin at the center of rotation. APPLICATIONS The crank on the oil-pump rig undergoes rotation about a fixed axis, caused by the driving torque M from a motor. As the crank turns, a dynamic reaction is produced at the pin. This reaction is a function of angular velocity, angular acceleration, and the orientation of the crank. If the motor exerts a constant torque M on the crank, does the crank turn at a constant angular velocity? Is this desirable for such a machine?\nAPPLICATIONS (continued) The “Catherine wheel” is a fireworks display consisting of a coiled tube of powder pinned at its center. As the powder burns, the mass of powder decreases as the exhaust gases produce a force directed tangent to the wheel. This force tends to rotate the wheel. If the powder burns at a constant rate, the exhaust gases produce a constant thrust. Does this mean the angular acceleration is also constant? Why or why not? What is the resulting effect on the fireworks’ display?\nEQUATIONS OF MOTION FOR PURE ROTATION(Section 17.4) When a rigid body rotates about a fixed axis perpendicular to the plane of the body at point O, the body’s center of gravity G moves in a circular path of radius rG. Thus, the acceleration of point G can be represented by a tangential component (aG)t = rG a and a normal component (aG)n = rG w2. Since the body experiences an angular acceleration, its inertia creates a moment of magnitude IGa equal to the moment of the external forces about point G. Thus, the scalar equations of motion can be stated as: Fn = m (aG)n = m rG w2 Ft = m (aG)t = m rG a MG = IG a\nEQUATIONS OF MOTION (continued) Note that the MGmoment equation may be replaced by a moment summation about any arbitrary point. Summing the moment about the center of rotation O yields MO = IGa + rG m (aG) t = (IG + m (rG)2 ) a From the parallel axis theorem, IO = IG + m(rG)2, therefore the term in parentheses represents IO. Consequently, we can write the three equations of motion for the body as: Fn = m (aG) n = m rG w2 Ft = m (aG) t = m rG a MO = IO a\nPROCEDURE FOR ANALYSIS Problems involving the kinetics of a rigid body rotating about a fixed axis can be solved using the following process. 1. Establish an inertial coordinate system and specify the sign and direction of (aG)n and (aG)t. 2. Draw a free body diagram accounting for all external forces and couples. Show the resulting inertia forces and couple (typicallyon a separate kinetic diagram). 3. Compute the mass moment of inertia IG or IO. 4. Write the three equations of motion and identify the unknowns. Solve for the unknowns. 5. Use kinematics if there are more than three unknowns (since the equations of motion allow for only three unknowns).\nREADING QUIZ 1. In rotational motion, the normal component of acceleration at the body’s center of gravity (G) is always A) zero. B) tangent to the path of motion of G. C) directed from G toward the center of rotation. D) directed from the center of rotation toward G. 2. If a rigid body rotates about point O, the sum of the moments of the external forces acting on the body about point O equals A) IGa B) IOa C) m aG D) m aO\nEXAMPLE 17.10 Given: A rod with mass of 20 kg is rotating at 5 rad/s at the instant shown. A moment of 60 N·m is applied to the rod. Find: The angular acceleration a and the reaction at pin O when the rod is in the horizontal position. Plan: Since the mass center, G, moves in a circle of radius 1.5 m, it’s acceleration has a normal component toward O and a tangential component acting downward and perpendicular to rG. Apply the problem solving procedure.\nEquations of motion: + Fn = man = mrGw2 On = 20(1.5)(5)2 = 750 N + Ft = mat = mrGa -Ot + 20(9.81) = 20(1.5)a + MO = IG a + m rG a (rG) EXAMPLE (continued) Solution: FBD & Kinetic Diagram Using IG = (ml2)/12 and rG = (0.5)(l), we can write: MO = a[(ml2/12) + (ml2/4)] = (ml2/3)a where (ml2/3) = IO. After substituting: 60 + 20(9.81)(1.5) = 20(32/3)a Solving: a = 5.9 rad/s2 Ot = 19 N\nGROUP PROBLEM SOLVING Given: Wdisk = 15 lb, Wrod = 10 lb, w = 8 rad/s at this instant. Find: The horizontal and vertical components of the reaction at pin O when the rod is horizontal. Plan: Draw the free body diagram and kinetic diagram of the rod and disk as one unit. Then apply the equations of motion.\nmd(3.75)(8)2 15 lb 10 lb (IG)ra (IG)da mr(1.5)(8)2 Ox = Oy mr(1.5a) md(3.75a) Equations of motion: Fx = m(aG)x: Ox = (15/32.2)(3.75)(8)2 + (10/32.2)(1.5)(8)2 Ox = 142 lb Therefore, a = 9.36 rad/s2, Oy = 4.29 lb GROUP PROBLEM SOLVING (continued) Solution: Fy = m(aG)y: Oy –15 – 10 = -(15/32.2)(3.75a) – (10/32.2)(1.5a) MO = Ioa: 15(3.75) + 10(1.5) = [0.5(15/32.2)(0.75)2 + (15/32.2)(3.75)2 ]diska + [(1/12)(10/32.2)(3)2 + (10/32.2)(1.5)2]roda"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:8771f3cd-7a70-4d0c-a563-b9afa27f1bad>","<urn:uuid:8772d8df-a8cb-4e46-87f9-fcf6fae43572>"],"error":null}
{"question":"¿Cuáles son las técnicas esenciales para comprimir instrumentos en una mezcla musical, y cómo afecta la compresión a la profundidad espacial del sonido? 🎸🎼","answer":"Compression serves multiple purposes in mixing. For individual instruments, it helps stabilize their level in the stereo field, keeping them at a consistent distance from the listener. The compression ratio and threshold settings are crucial - while lead vocals typically shouldn't exceed 6 dB of gain reduction, background elements can be compressed more heavily at 10 dB or beyond to push them further back in the mix. The compression mode also matters - Peak mode produces a more squeezed, soft sound good for pulsing effects, while RMS mode better preserves natural dynamics and helps push sounds to the front of the mix. For drums specifically, compressors with longer attack times (>30ms) can make attacks sound harder and help maintain sustain, especially for toms. Guitar amplifiers typically need minimal compression since they're already compressed through overdrive, while vocals can benefit from heavier compression depending on how natural or aggressive you want them to sound.","context":["Producing studio recordings sound fascinating and effective is a genuine ability. The loudness of your guitar amplifiers and the electrical power of your drummer are not enough to make the recordings of your songs categorical the true loudness and electricity of the actual functionality.\nDoing work with Logic Studio, I have found out a variety of techniques (that are partly impressed by the tips used in skilled mixes I identified amazing) to make recordings audio far more effective.\nThe journey begins when you get ready your recordings. There are many common factors that can make a lot of variation in the stop consequence. For instance I extremely advocate you to warm up your voice before starting vocal recordings. This sounds trivial, but it is the crucial to a potent and uninhibited vocal overall performance. The following level I individually pay out shut consideration to is the situation of microphones. You ought to place microphones near sufficient to the sound resource you want to document in get to stay away from important qualifications noise or sound reflected by the walls of the area. But I highly suggest you to place microphones (if possible) at a length of at the very least thirty centimeters (one particular foot) to the instrument you are recording. I know this is fairly the reverse of what is generally accomplished in studios (particularly with drums), but I have good reason to make this recommendation. The difficulty with possessing microphones to near to the resource of sound is a very unauthentic sound on the recording. Think about it — the bass drum does not sound the exact same if you lean your head against it. In my view it is terribly difficult to restore the first seem (as you experience it from a usual distance) afterwards — particularly without having any reference.\nAfter you have completed your recordings, there are various possibilities you ought to consider for the enhancing. One of the standard (yet most strong) resources included in pretty much every audio enhancing software is the equalizer — if you are employing Logic, I recommend to continue to be with the simple to use, but thorough “Channel EQ” plug-in. To make your mix appear very clear to your listeners, a single essential approach is to assign a ‘role’ to each and every instrument (or seem) in your arrangement. Make a decision for every element no matter whether it ought to stand out, or enjoy a supportive role. Appropriately, you might raise or reduce the ranges of specified frequencies, which is when the true sound design and style commences. The single components must not seem full separately, but all of them with each other need to. To make all factors clearly audible, it does not aid to include treble frequencies to all of them, nor to raise them all to the exact same volume level. It is crucial to leave ‘gaps’ in the mix (largely by avoiding the substantial use of certain frequencies ‘needed’ for other instruments) to embed additional aspects — there must be no competitiveness between the devices in your mix. Rather, they need to appear to comprehensive each and every other. But you need to try not to disfigure the typical seem of the devices — it normally takes some encounter to actually get employed to that balancing act, but right after some time you will very easily find out what frequencies are standard of an instrument, and which can be neglected with one particular certain instrument, so they are ‘available’ for other devices that ‘need’ them to sustain their standard seem.\nGetting defined these basics, I would like to target on including the powerful nuance to the audio of your recordings. The drums enjoy a comparatively essential position in rock music normally. Making them sound strong is critical to get the appropriate seem. Generally, drums profit from treble and bass frequencies, and usually must not contain too significantly of mid-assortment frequencies if they are supposed to seem potent. The only exception are toms — they can seem a lot more mighty with some effectively-picked mid-assortment frequencies. This applies specially to floor toms — to make them seem more entire, adding minimal mid-selection or bass frequencies can have a remarkably positive result.\nThe snare drum can also have extra mid-selection frequencies, but usually tends to audio fairly peculiar if way too much of these are added. Relying on the raw materials, I personally insert three dB all around four hundred Hz to deliver out the attribute sound of the snare drum, I also tend to minimize or even lower all bass and low mid-assortment frequencies (up to two hundred Hz) of snare drums to make them seem a lot more tight.\nA related basic setting can also be employed for the hello-hat — with the tiny variation that usually no mid-selection frequencies need to be included. In most circumstances, it even helps make perception to reduce mid-range frequencies of the hello-hat drastically. All other cymbals (in my view) could contain a some much more mid-range frequencies, but they will not have to. This depends on your private desire — uncover out what seems far better in the blend for every tune independently — nicely, it might appear to hardly make any distinction. Typically talking, I would recommend to decrease frequencies instead than cut them. Specifically bass frequencies are contained normally in virtually every single signal.\nFor the bass drum, there is one particular quite certain point to spend attention to: the bass frequencies. There need to be a significant quantity of bass frequencies included to provide that “delicious” impulse that can instead be felt in the tummy than actually listened to. Because of to the individuality of the original materials, I are not able to give you a universal guideline below. Usually, I add about twelve dB of bass frequencies all around 60 Hz, and about six to seven dB of treble frequencies (down to ten,000 Hz). Optionally, I occasionally also include about the same amount at 2150 Hz — again: the result depends on the frequency equilibrium of your raw material.\nNormally I add some treble frequencies to all elements of the drum package independently (cymbals must be the primary producers of treble frequencies) to create a refined brilliance and make single strokes of a roll relatively audible in the combine (with out possessing to put the drums too much in the foreground) — this can be your acoustic reference when choosing how considerably treble you want to incorporate. Treble frequencies should never be too penetrant, but well balanced. Many playback products insert much more bass and treble frequencies — consequently I advise you to insert just slightly far more than sufficient treble. Depending on the roles of the other devices in the blend, you may well decide about the ‘shape’ of your drums much more independently. This is just a type of template I individually use for my personal recordings. Usually, I usually advocate to try out boosting and reducing diverse frequencies (bass, lower mid-assortment, mid-assortment, large mid-variety, and treble) if you are not however content material with the sound of a single certain instrument — also, this aids you to get a sensation for what impact the various frequencies have on your devices.\nThe use of compressors is generally the primary contributor to the influence of loudness — it imitates the response of the human ear to loud songs. That is why compressors are specially valuable for rock songs. Apart from that, compressors make it simpler to harmony the tracks, due to the fact they maintain the amount of the signal in a specific variety. Also, compressors help your song to ‘rock’, simply because they can make the assaults audio difficult if you set a instead long (far more than thirty milliseconds) assault time for the compressor to commence compressing the sign. Again, this is particularly valuable for drums — specifically for snare drums and toms. The tendency with toms is that their sustain gets lost in the combine. To keep away from this, I advise the use of a great compressor that has a fairly reduced threshold and substantial ratio.\nThe increased the ratio, and the decrease the threshold, the much more excessive the compression will be, and the much less organic your sign will sound — it is your choice. Generally I compress drums reasonably challenging to give them back their ‘loud’ audio, but use compression for other instruments largely to maintain the amount of the signal continual. Amplified guitars normally currently have a really constant level (due to the compressing effect of the overdrive offered by the amp), and consequently don’t need a good deal of compression — in truth it can cause unpleasant artifacts if the distortion of the amplifier is blended with too hard compression later on. In contrast, vocals can profit from reasonably challenging compression, but this clearly relies upon on how a lot you want to compromise the organic dynamics, and how ‘hard’ you want the vocals to seem.\nAstonishingly, an additional aspect that can add the result of energy to your tunes is reverb. If you are utilizing various reverbs for different instruments in the very same music, you have to be careful — it may possibly audio as if the devices will not belong with each other if their reverb traits or stages are also distinct. Nevertheless I do suggest to select reverbs independently for some devices — to make bass drums audio much more strong, I typically use the “one.5s Perc Space” from the Place Designer plug-in (in the “Rooms” listing of “Medium Areas”) at a amount of about -13 dB. The trick with this specific reverb is the level of bass frequencies it contains — these bass frequencies include maintain to the bass impulse of the bass drum. This does not only make the bass drum appear far more mighty, it also helps to make that impulse more existing — this can be really helpful thanks to the simple fact that specially bass frequencies have a tendency to get dropped in a full mix, particularly when each component of the combine is made up of a substantial sum of them. That is the reason why you should select diverse frequency focuses for different components, or groups of factors — like melody instruments, harmonic supporters (‘carpets’), and rhythm devices. If you insert seemingly ‘delicious’ bass frequencies to all components, you destroy the display for people that truly are worthy of to contribute bass frequencies — like the bass guitar and bass drum(s).\nAlso snare drums revenue quite considerably from great reverbs becoming applied to them. What sets the snare drum apart from the bulk of other factors in a blend is the reality that relatively prolonged reverbs can be employed with it (without having producing a relatively unnatural audio). Yet, for paris music use the same percussion area from the Place Designer as for the bass drum. This reverb truly operates as portion of the audio of the snare drum, extending its sustain drastically. Again, the best configurations depend on your uncooked materials.\nIn most circumstances, reverb ought to not stand out obviously to the listener, apart from of system if it is utilised to produce some sort of special result. Usually, reverb is used subtly to create that effect of smoothness, room, and at times maintain, but it must in no way make your mix audio blurred and unintelligible. One particular trick to set components aside from each and every other is to vary the level of reverb – for instance you may want to insert much more reverb to history vocals to make them audio far more distant than the guide vocals that appear to appear from proper in front of the listener.\nDoubling tracks (particularly electric guitars and backing vocals) and picking various pan settings for them (like +35 and -35) is another quite successful way to incorporate an influence of energy and room to your combine. Doubling can also be interesting to make lead vocals sound bolder, but in this circumstance I individually would not decide on severe pan options.","So, how to start?\nWith a plan. First off, I imagine in my head or on a sheet of paper the placing of individual instruments/musicians on the virtual stage and then think how to “re-create” this space in my mix. Typically I’d have three areas: foreground, mid-ground and background. Of course, this is not a rule. If we make a raw rock mix with a sparse arrangement and in-ya-face feel we don’t need much of a space, on the other hand, in a dense, multi-layered electronica the depth is crucial.\nSo, I have divided all my instruments into, say, 3 spatial groups. Then, in my DAW, I set the same colour for every instrument belonging to the certain group, what is wonderfully handy – I immediately see everything at a glance.\nThe tracks that I usually want to have close are drums, bass, vocals. A bit deeper and further I’d have guitars, piano, strings. And then, in the distant background I’d have synth textures or perhaps some special vocal effects. If there are string or brass sections in our song, then we need to learn about placing the orchestra instruments first in order to reproduce it. Surely this is the case only if we are aiming for realism.\nBut sometimes we don’t necessarily need the realism, especially in electronic music. Here almost anything goes!\nGoing back to our plan…\nNo matter whether we struggle for realism or not I suggest to start planning from pinning down which element will be the furthest – you need to identify the “back wall” of the mix. Let’s assume that in our case it is a synth pad. From this point, any decision about placing instruments closer or farther away has to be based on our back wall.\nAt this point we have to decide what reverb will we use. There are basically two ways of thinking. Traditionalists claim that we should use only one reverb in the mix, not to give misleading information to the brain. In this case we have the same reverb on each bus (in terms of the algorithm), changing only the settings – especially pre-delay, dry/wet ratio and EQ. Those of a more pragmatic nature believe that it’s not always the realism that matters, especially in electronic music and only the end result counts. Who are right? Well, they both are.\nI’d usually use two, maybe three different reverb algorithms . First would be a short room type of reverb, the second, longer, would be Plate, and the third and farthest would be Hall or Church. Thanks to using the sends from individual tracks I can easy decide how far or close the instrument will sit on our virtual stage.\nDo not add a reverb to each track, the contrast will allow you to enhance dimension and imaging even more. If you leave some tracks dry, the wet ones will stand out.\nFiltering out the highs from our returns not only sinks things back in the stereo field, but also helps to reduce the sibilants – reverb tends to sort of spread them out in the space, what is very irritating. An alternative method of getting rid of sibilances from reverb is to use de-Esser on the sends.\nCompression and its role in creating a depth\nCan you use compression to help creating the depth? Not only you can, but you must!\nAs we all know, the basic use of the compressor is to “stabilize” the instrument in stereo field. It means that compressor helps to keep the instrument the same distance away from the listener thorough the whole track. To put it another words – its relative volume is stable. But of course we don’t always need it to be. This is particularly important for instruments placed back on a sound stage, because otherwise these will not sound clear. Now, how the compression can help us here? As we all know, the unwritten rule says that the gain reduction should not exceed 6 dB. This rule works for instance for solo vocals. The bigger reduction can indeed “flatten” the sound. Yet this is not necessarily the case when it comes to backing vocals or, generally, instruments playing in the background. Sometimes these are getting reduced by 10 dB or even more. In a word – everything what is further away from the listener should be compressed heavier. The results may surprise you!\nThere is one more thing I advise to pay attention to – two basic work modes: RMS and Peak. PEAK mode is “looking” at peaks and reduces the signal according to it. What sound does it give? In general – more squeezed, soft, sometimes even pumping. It’s useful when we want the instrument to pulse softly rather instead of dazzling the listener with its vivid dynamics. The RMS mode causes the compressor to act like the human ear and not focusing on signal peaks that often have little to do with the perceived loudness. This gives a more vibrant, dynamic and more natural sound. It works best if our aim is to preserve the natural character of the source (and that’s often the case for example with the vocals). RMS mode gives a lively, more open sound, good for pushing things to the front on our sound stage.\nThe interesting fact is that built-in channel compressors in SSL consoles are instantly switchable between Peak and RMS modes. You can find something similar in the free TDR Feedback Compressor from Tokyo Dawn Records.\nAnother very popular effect is delay. It is, one might say, a very primitive form of reverb (as reverb is nothing more than series of the very quick reflections).\nAs you may remember from the earlier part of this article, I mentioned the pre-delay parameter in reverb. You can use it in pretty much the same way in delay plugin to create the sense of depth in the mix. Shorter pre-delay times will make instruments sound further away from the listener, longer times will do the opposite. But you can of course use the delay in many different ways. For instance – very short reflection times with no feedback can also thicken and fatten the sound nicely. Try it!\nThe thing I like the most in delay is that it gives the mix a certain context of space. The music played in an anechoic chamber would sound really odd to us, as we hear all sounds in a context already from birth (the situation is of course no different with the music). No matter if you listen to a garage band, a concert at the stadium or in the club – context of the place is essential to an appreciation of space in which the music is playing.\nNow, how to use all this knowledge in practice\nAnd now I will show you how I use all of this information in practice, step-by-step.\n1. The choice of reverbs.\nAs I said before, the first we have to consider if we aim for realism or not.\nI always struggle when it comes to reverb. Like, what the best sound settings for what instrument/sample. Should I use a Hall or a Plate? Should I use an aux or use it as an insert. Should I EQ after or before the reverb etc. I don’t know why, but reverb seems to be the hardest thing for me to understand and I wish it was not.\nAnd then comes another big question. How much reverb should be applied to certain tracks? All decisions made during the mixing process are based on what makes me feel good. One good advice is to try monitoring your mix in mono while setting reverb levels. Usually, if I can hear a touch of it in mono it will be about right in stereo. If I get it too light in stereo, the mix will sound too dry in mono. Also – concentrate on how close or distant the reverbated track sounds in the context of the mix, not on how soft or loud the reverb is (a different perspective).\n2. Creating the aux tracks including different reverb types.\n3. Organizing the tracks into different coloured groups.\nAt the top of the session I have a grey coloured group – these are the instruments that I want to have really close and more or less dry: kick, bass, hihats, snare, various percussion loops. I have Room reverb going on here, but it is to be felt, not heard.\nThen I have the blue group. These are the “second front” instruments with Hall or Plate type reverb on them.\nAnd then I have the background instruments, the back wall of my mix. Everything that is here is meant to be very distant: synth texture, vocal samples and occasional piano notes.\n4. Pre-delays, rolling off the top, the bottom, 300Hz and 4500 Hz.\nMy example configuration would look like this:\n- Room: 1/64 note or 1/128 note pre-delay, HPF rolling off from 200 Hz, LPF from 9 kHz\n- Plate: 1/32 note or 1/64 note pre-delay, HPF rolling off from 300 Hz, LPF from 7 kHz,\n- Hall: no pre-delay, HPF rolling off from 350 Hz, lowpassing is usually quite low, in the 4k – 5k zone (remember the air absorbs high frequencies much more than it absorbs lower ones).\nto soften the attack a little.[Example.mp3]\n- Foreground: drums, percussion, bass and saxophone.\n- Mid-ground: piano, acoustic guitar.\n- Background: synth pad, female voice.\nSome people also get nice results by playing around with Early Reflections parameter in reverb. The closer a sound source is to boundaries or large reflective objects within an acoustic, the stronger the early reflections become.\nContrast and moderation – I want you to leave with these two words and wish you all a successful experimenting!\nAbout the author: Piotr “JazzCat” Pacyna\nis a Poland based producer, who specializes in video game sound effects\nand music. He has scored a number of Java games for mobile phones and, most\nrecently, iPhone/iPad platforms. You can license some of his tracks here."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:fc1a33b4-a2d2-4b18-89d4-a010b23b8df8>","<urn:uuid:fe1f52a8-61d8-453c-81f0-56f43655718a>"],"error":null}
{"question":"Can you tell please: What actions has U.S. government taken to address Japanese internment injustice both in past and present time?","answer":"In 1988, the U.S. government formally apologized and provided $20,000 to each Japanese American internee through the Civil Liberties Act signed by President Reagan. Currently, there are ongoing efforts for redress for 2,200 Latin Americans of Japanese descent who were forcibly deported to U.S. concentration camps. Additionally, the government continues to address this historical injustice through the Japanese American Confinement Sites grant program, established by Congress in 2006, which has awarded over $22 million to preserve these sites and educate future generations about this period in history.","context":["|Hiroshi Shimizu and Sadako Kashiwagi shared their stories of internment.|\nTHE CURRENT POLITICAL CLIMATE casting a suspicious eye on Muslims and refugees is all too familiar to Sadako Kashiwagi.\nAt just 10 years old, she was rounded up and imprisoned along with more than 18,000 Japanese Americans in Tule Lake in California, one of ten concentration camps set up by the federal government.\nWhen asked if history was repeating itself, Sadako’s eyes began to well up. She cupped her hand and raised it to cover her mouth. Nodding affirmatively, she simply said “I can’t speak.”\nSadako was one of a nine people who spoke at a news conference at the Japanese American National Historical Society in San Francisco. As the country celebrates President’s Day this weekend with sales and a three day weekend, many are also pausing to remember Sunday’s 75th anniversary of Executive Order 9066. The order by President Franklin D Roosevelt set the stage for the incarceration of more than 110,000 Japanese Americans during World War II.\n- California county apologizes for Executive Order 9066\n- 'Images of Internment' photo exhibit at FDR Library\nHer husband Hiroshi Kashiwagi was also imprisoned at Tule Lake, although the two didn’t meet until after they were released. His memory of his experience is still vivid.\n“The fence, and the guard tower,” Hiroshi responded when asked about his strongest images from Tule Lake. “The fact that we were penned in, that we couldn’t go near the fence. And we would be warned to not go too close. If you continued to go on your way, they might shoot you. There were cases like that where person got maybe unknowingly close to the fence and he was shot.”\nThe news conference Friday took place just a few hours after the Associated Press reported on a draft memo which called for 100,000 National Guard troops to augment border security.\nThe White House quickly said the memo was never seriously considered and never made it up the chain of command.\n“How much of this is about direct impact and targeting and how much is about creating a culture of fear,” asked Zahra Billoo, executive director of the Council of American Islamic Relations, Bay Area. “Even if 10 percent of that rumor with the Associated Press is true, that’s still a frightening idea that we maxed out on custom and border protection agents and ICE agents, so now we’re going to bring up the National Guard.”\nHiroshi Shimizu was just 5 when he also was at Tule Lake. The AP report reminded him of 1943, when authorities at Tule Lake declared martial law out of fear of rioting. He remembers 2,000 soldiers at Tule Lake, many with tanks and jeeps mounted with machine guns. He says Tule Lake was under martial law for five months.\n“That is very similar of a military action that happened then and could happen today,” he said about reports of the National Guard. “That’s what we need to keep guard about.”\nIn 1988, President Ronald Reagan signed the Civil Liberties Act which approved a formal apology and $20,000 to each Japanese American incarcerated in the incarceration camps. The movement continues to win redress for 2,200 Latin Americans of Japanese descent who were forcibly deported to concentration camps in the United States.\n“What we’re seeing too is more normalization of trying to identify an enemy and vilify an enemy and right now it looks like anybody can be the enemy,” said Grace Shimizu; Campaign for Justice: Redress Now.\nThe news conference was part of a series of events taking place in cities across the U.S. that has commonly become known as a Day of Remembrance.\n“I see the Day of Remembrance as a way of bringing light to what people are capable of doing to each other and from that become a little aware of how as human beings we can become example of Hitler or a Mother Teresa,” said the Rev. Ron Kobata of the San Francisco Buddhist Church.\n“Know your history, be strong, and don’t be ashamed,” concluded Sadako.","WASHINGTON – The National Park Service on June 8 announced $1.6 million in grants to fund preservation, restoration and education projects at several Japanese American confinement sites.\nThe 14 grantees in four states and the District of Columbia will tell the story of the more than 120,000 Japanese Americans, two-thirds of whom were U.S. citizens, who were imprisoned by the U.S. government following the Dec. 7, 1941 attack on Pearl Harbor by Japan.\n“The incarceration of Japanese Americans during World War II is a painful episode in U.S. history, but one that future generations must remember and learn from,” National Park Service Acting Director Michael T. Reynolds said. “The National Park Service has an important role in telling this story through our stewardship of sites like Honouliuli, Manzanar, Minidoka, and Tule Lake and the support we provide communities and partner organizations through the Japanese American Confinement Sites Grant Program.”\nCongress established the Japanese American Confinement Sites grant program in 2006, authorizing a total of $38 million in funding for the life of the program. The latest announcement brings the current award total to more than $22 million.\nThe grants will fund a diverse array of projects that will tell this important story in a variety of ways.\nUsing grant funds, the National Japanese American Memorial Foundation will enlist the help of high school students to develop video apps that will provide visitors to the Japanese American Memorial to Patriotism in WWII with a deeper understanding of the incarceration sites commemorated by the memorial.\nThe Japanese American National Museum will use grant money to conserve more than 100 artifacts from the collection of Allen Hendershott Eaton, a folk art expert who acquired artwork created by incarcerees, which the museum will share as part of a traveling exhibition.\nJapanese American Confinement Sites grants may be awarded to projects associated with the 10 War Relocation Authority centers established in 1942 and more than 40 additional confinement sites. The program’s mission is to teach future generations about the injustice of the World War II confinement of Japanese Americans and to inspire commitment to equal justice under the law. Successful proposals are chosen through a competitive process that requires applicants to match the grant award with $1 in non-federal funds or “in-kind” contributions for every $2 they receive in federal money.\nA list of the winning projects is below. For more details about these projects, visit www.nps.gov/JACS. For more information on the incarceration of Japanese Americans during World War II, visit www.nps.gov/subjects/worldwarii/internment.htm.\nGrantees are listed with project title, project site and grant award amount.\n• Bainbridge Island Japanese American Exclusion Memorial Association, Bainbridge Island, Wash. “Exclusion Departure Deck, Bainbridge Island Japanese American Exclusion Memorial.” Eagledale Ferry Dock, Bainbridge Island, Kitsap County, Wash. $187,668\n• Densho, Seattle. “Making Connections with the Japanese American Incarceration II: The Online Teacher Course.” Multiple sites. $208,031\n• Go For Broke National Education Center, Los Angeles. “The Go For Broke Experience: Monument, Exhibition and Oral History.” Multiple sites. $60,843\n• Japanese American National Museum, Los Angeles. “Contested Histories: Art and Artifacts from the Allen Hendershott Eaton Collection.” Multiple sites. $250,958\n• Japanese American National Museum, Los Angeles. “Digitization and Accessibility of JANM’s Moving Image Collection.” Heart Mountain Relocation Center, Park County, Wyo.; Rohwer Relocation Center, Desha County, Ark.; Jerome Relocation Center, Chicot and Drew counties, Ark.; Granada Relocation Center (Amache), Prowers County, Colo. $176,844\n• Japanese Cultural Center of Hawaii, Honolulu. “Directory of Japanese American Internees of Hawaii.” Honouliuli Internment Camp, Honolulu County, Hawaii and other internment sites in Hawaii. $45,900\n• Japanese Cultural Center of Hawaii, Honolulu. “Hawaii’s Japanese American Wartime Evacuees.” Honouliuli Internment Camp, Honolulu County, Hawaii; Sand Island Detention Camp, Honolulu County, Hawaii. $109,912\n• National Japanese American Memorial Foundation, Washington, D.C. “National Japanese American Memorial Foundation Digital Storytelling Project.” Multiple sites. $27,066\n• New Mexico Chapter of the Japanese American Citizens League, Albuquerque, N.M. “Confinement in the Land of Enchantment Traveling Exhibit and Community Presentations.” Santa Fe Internment Camp (INS), Santa Fe County, N.M.; Fort Stanton Internment Camp (INS), Lincoln County, N.M.; Camp Lordsburg (U.S. Army), Hidalgo County, N.M.; Old Raton Ranch (INS), Santa Fe County, N.M. $85,926\n• Poston Community Alliance, Lafayette, Calif. “Restoration of the Poston Elementary School Site I Library.” Colorado River (Poston) Relocation Center, La Paz County, Ariz. $77,701\n• San Diego Chapter of the Japanese American Citizens League, San Diego. “Never Forget — Our Lost Years.” Colorado River (Poston) Relocation Center, La Paz County, Ariz. $114,200\n• Tuna Canyon Detention Station Coalition, Pacoima. “Tuna Canyon Detention Station Legacy Project.” Tuna Canyon Detention Station, Los Angeles County. $54,000\n• Visual Communications, Los Angeles. “Manzanar, Diverted.” Manzanar Relocation Center, Inyo County. $83,765\n• Wing Luke Memorial Foundation dba Wing Luke Museum of the Asian Pacific American Experience, Seattle. “Inspiring Future Generations: Friends and Supporters Who Helped Those Incarcerated.” Multiple sites. $148,764"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:198a2bc7-74c6-4c2c-87c0-c17c3595cc16>","<urn:uuid:d0e4aec9-bbf8-46f9-8dd5-8f20f0d2b7fe>"],"error":null}
{"question":"How do the educational approaches for teaching about sharks differ between the interactive Predator Protector game and Oceanopolis' shark exhibits - what are their main goals and methods?","answer":"The educational approaches differ in several key aspects. The Predator Protector game takes an immersive, role-playing approach where students actively protect three shark species (swell sharks, gray reef sharks, and great white sharks) while learning about their habitats, food webs, and threats through hands-on gameplay. Its main goals are to have students describe shark habitats, identify threats, and understand how sharks maintain ecosystem balance. Meanwhile, Oceanopolis' shark education focuses on dispelling misconceptions through direct interaction with scientific mediators in their 'Do you really know sharks?' quiz sessions, where visitors learn surprising facts about shark capabilities (like detecting blood drops in large volumes of water) and characteristics (like having multiple eyelids). Both approaches aim to improve understanding of sharks' ecological importance, but use different methods - active simulation versus guided discovery with experts.","context":["A scientific mediator will help you discover different areas usually innacessible to the public.\nOUR SUMMER ANIMATIONS\nFrom July 9 to August 28, discover all of our animations and activities for a summer under the sign of the sea.\nDiscover our summer animations in this video !\nThis summer, come and meet the extinct marine animals of the Cambrian period. It was a time when dry land was akin to a mineral desert while the ocean teemed with life! Thanks to this new immersive, family-oriented animation from the Xperiensea series, you can discover on the big screen and in 3D puzzling marine species with strange and whimsical shapes such as Anomalocaris sp. (literally the ‘strange prawn’) and Hallucigenia sp.. Accompanied by an Océanopolis scientific mediator, experience a unique encounter and let yourself be moved by the richness and vulnerability of marine biodiversity.\nDIVE INTO THE DEEP OCEAN\nIn August, discover an exceptional experience, diving down into the deep ocean. Meet the scientists from the second edition of Ifremer’s ChEReef (Characterisation and Ecology of cold-water coral Reefs) scientific campaign and follow, exclusively, new dives into the heart of the canyons in the Bay of Biscay and the search for cold water corals.\nThis activity is included in the price of your admission ticket to Océanopolis.\nFEEDING TIMES WITH COMMENTARY\n- Sea otter mealtimes\nMeet up with our keepers and watch our sea otters eating and going through their veterinary exercises.\n- Seal mealtimes in the Brittany pavilion\nMeet up with our keepers and watch our Brittany pavilion seals eating and going through their veterinary exercises.\nThose activities are included in the price of your admission ticket to Océanopolis.\nDiscover our entertainment capsules and explore exciting themes alongside an Océanopolis scientific mediator:\n- Seaweed, an essential source\nBrittany’s waters are among the richest and most diversified in the world, with more than 700 species of algae recorded! These marine plants often intrigue swimmers in the summer. Beyond their essential ecological role, marine macroalgae have many interesting properties for food and industry.\n- Sharks, moving beyond misconceptions\nThese fascinating fish are struggling to get rid of the bad reputation that sticks to them. And yet they are gifted animals in many ways, sometimes revered and even imitated by humans.\n- Objective zero plastic\nAn ocean of plastic, the 7th continent, the plasticene epoch etc. There are many expressions describing the intrusion of plastic into the marine environment. From large detritus through to nanoplastics, this man-made material is now found everywhere in the ocean, from the beaches to the deepest ocean trenches. It is ingested by organisms, but also a carrier of species. Visitors will discover the effects of plastic on marine fauna, the evolution of this material in our oceans and future solutions for plastic-free oceans.\n- Coral polyps, essential animals\nCorals form some of the most important and complex ecosystems on the planet, serving as habitats, breeding grounds and growing areas. A veritable oasis of life in the middle of the ocean, coral reefs are a reservoir of biodiversity, home to more than a quarter of the planet’s marine diversity.\nThis activities are included in the price of your admission ticket to Océanopolis.\nEVENTS IN THE BRITTANY PAVILION MINILAB\nDiscover 4 playful and interactive animations about Brittany’s marine biodiversity alongside an Océanopolis scientific mediator:\n- In a drop of seawater\nIncredible life in a single drop of seawater! Using a microscope, binocular magnifying glasses and 3D-printed models, the scientific mediator provides a live discovery of the extraordinary forms of plankton, its role and its importance in marine ecosystems.\n- Treasures of the foreshore\nAt high tide, the sea deposits a strand of seaweed mixed with unusual objects on the beaches: this is the foreshore. Cuttlefish bones, the remains of shells, the hard shells of sea urchins but also pieces of plastic. Where does this debris come from? What is the role of the foreshore? Discover with the scientific mediator many testimonials about biological activities and the significant exposure to pollution in this little-known yet essential area.\n- Quiz: ‘Do you really know sharks?’\nDid you know that some species have up to three eyelids? That a white shark can detect a drop of blood in the volume of water found in an Olympic swimming pool? Or that the Greenland shark could live up to 400 years? Visitors can test their knowledge and discover some unusual information on rays and sharks at the Minilab with an Océanopolis scientific mediator.\n- Cousins by the sea\nObserve crabs, shrimps, sea urchins and whelks and try to find the relationships between these different species. Faced with extraordinary marine biodiversity, a scientific mediator will help visitors to better understand how we manage to classify living beings.\nThese events last an average of 20 minutes and are included in the price of your admission ticket to Océanopolis.\nEXHIBITION: OBJECTIVE PLANKTON\nThis exhibition, the first produced by the Objective Plankton participatory science programme, will present the people who work on the project, the actions conducted as part of the programme and the great diversity of plankton species. It will also provide the possibility of meeting with the general public.\nHEALER FOR A DAY\nLive an unforgettable moment discovering the animal trainer profession. A fun filled morning with guaranteed emotions","Predator Protector Game Lesson\nIn the Web-based game Predator Protector, students take on the role of an Ocean Adventures expedition volunteer member. In this role, students are charged with protecting three species of sharks from danger in order to defend the balance of nature in the ecosystem that these top predators help to maintain. Use the tips and handouts below to turn the Predator Protector game into a structured learning activity for your students.\nGrades 6 through 10\nOne to two class periods\nStudents will be able to:\n- describe the habitat, food web and ecosystem of three different shark species.\n- identify threats to sharks.\n- explain how top predators, such as sharks, help to maintain the balance of nature within ecosystems.\nNational Science Education Standards Grades 5-8 (at www.nap.edu)\nScience As Inquiry - Content Standard A:\nAbilities necessary to do scientific inquiry\nLife Science - Content Standard C:\nReproduction and heredity\nRegulation and behavior\nPopulations and ecosystems\nDiversity and adaptations of organisms\nScience in Personal and Social Perspectives - Content Standard F:\nPopulations, resources and environments\nOcean Literacy: Essential Principles and Fundamental Concepts (at coexploration.org)\nEssential Principle #1: Earth has one big ocean with many features.\na. The ocean is the dominant physical feature on our planet Earth, covering approximately 70 percent of the planet's surface. There is one ocean with many ocean basins, such as the North Pacific, South Pacific, North Atlantic, South Atlantic, Indian and Arctic.\nh. Although the ocean is large, it is finite and its resources are limited.\nEssential Principle #5: The ocean supports a great diversity of life and ecosystems.\nd. Ocean biology provides many unique examples of life cycles, adaptations and important relationships among organisms (symbiosis, predator-prey dynamics and energy transfer) that do not occur on land.\ne. The ocean is three-dimensional, offering vast living space and diverse habitats from the surface through the water column to the seafloor. Most of the living space on Earth is in the ocean.\nEssential Principle #6: The ocean and humans are inextricably interconnected.\ne. Humans affect the ocean in a variety of ways. Laws, regulations and resource management affect what is taken out and put into the ocean. Human development and activity leads to pollution (point source, nonpoint source and noise pollution) and physical modifications (changes to beaches, shores and rivers). In addition, humans have removed most of the large vertebrates from the ocean.\nf. Everyone is responsible for caring for the ocean. The ocean sustains life on Earth, and humans must live in ways that sustain the ocean. Individual and collective actions are needed to effectively manage ocean resources for all.\nEssential Principle #7: The ocean is largely unexplored.\nc. Over the last 40 years, use of ocean resources has increased significantly; therefore the future sustainability of ocean resources depends on our understanding of those resources and their potential and limitations.\nIn the second episode of Jean-Michel Cousteau: Ocean Adventures, Sharks at Risk, Jean-Michel Cousteau and his dive team travel to French Polynesia and South Africa to swim with sharks and to dispel the myth that sharks are senseless killers. Their expedition uncovers the threats sharks face from their human predators and explores the vital role these top predators play in supporting the intricate balance that makes up the ocean ecosystem.\nBased on the experiences of the Ocean Adventures team, Predator Protector is a fast-paced interactive game in which students are the environmental heroes, protecting sharks from the numerous dangers that plague them in the ocean and thus helping to preserve the delicate balance of the ecosystem. Playing the part of an Ocean Adventures volunteer team member, students visit three separate locations to protect different species of sharks -- the shallow waters of California to swim with swell sharks, the mid-depth reef waters of French Polynesia to trail gray reef sharks and the cold, deep waters of Australia to protect the great white shark. Swimming behind one of the sharks, students are armed with repellent to deter the shark from life-threatening pressures. They accumulate points by keeping their shark alive long enough to find food and by ensuring their shark lives long enough to reproduce and keep the population stable. Students will need to monitor the level of shark health and time left on their mission. Upon completion of the game, students will analyze their data and compile a report describing what they have learned, then submit their report to the Volunteer Supervisor (the teacher).\n- Using blank student handouts, play Predator Protector yourself, paying particular attention to where you think your students will need extra guidance.\n- Review the Game Background and the Answer Key.\n- Based on the availability of computers, decide the best way for students to play the game -- individually, in pairs or in groups.\n- Illuminate students with background information about sharks and spark their curiosity by using the Shark Encounter activity to introduce study of sharks.\n1. Review Background Information: It will be helpful if your students have a general understanding of ecological relationships before beginning the interactive -- review terms such as \"predator,\" \"prey,\" \"producer,\" \"consumer\" and \"decomposer.\" Also introduce students to the game's three shark species (swell shark, gray reef shark, great white shark) and the location of and facts about their habitats and ecosystems. Use the Vanishing Sharks interactive and essays located on the Sharks at Risk Web site for assistance.\n2. Introducing top predators: Use ideas from the Sharks at Risk Viewing Guide to set the scene. Pay particular attention to the Segment Suggestions for the ecosystem balance/food web and longline fishing/other human factors themes. If you do not have access to the Sharks at Risk episode, use the Ocean Adventures Web site to find pictures of the sharks to show to students, then lead a class discussion about the dangers facing shark populations and the importance of sharks to ecosystem stability.\n3. Game Setup: Pass out the Volunteers Wanted! student sheet, a fictional posting for a volunteer position introducing volunteers (the students) to their shark protection mission. Explain to students that as part of the Ocean Adventures team, they are a part of this volunteer mission. Give students an overview of how to play Predator Protector, hand out the Location Data Sheet, the Shark Species Data Sheet and the Shark Threat Data Sheet and explain that they will be collecting information on these organizers for later use. Have students record their hypotheses on their Location Data Sheet before game play begins.\n4. Game Play: Allow students sufficient time to play the game and collect data.\n5. Data Sharing: Set aside time for students to gather in small groups to review data after game play has ended to ensure all students have understood the game.\n6. Reporting Information: Pass out the Reporting Data handout and explain the directions. Students will submit this \"report\" to you, their Volunteer Supervisor.\n- Depending on the number of computers available, you might want to make adjustments, such as having students play the game on alternate days.\nJessica Neely is the KQED Education Network Project Supervisor for Science Initiatives. Prior to this she was a secondary Life and Environmental Science Teacher. KQED Education Network uses the power of KQED Public Broadcasting to inspire learning by providing projects for youth and curriculum materials and professional development for teachers, child care providers and families.\nPDF FILE FORMAT\nThese Ocean Adventures lessons and other materials are available as printer-friendly PDFs (Portable Document Format). To download and view the lesson plans as a PDF, you may first have to get Adobe Acrobat Reader, available for free on Adobe's Web site. The Reader is available for most computer platforms, and once downloaded the lessons may be viewed on-screen as well as printed out. Get Acrobat Reader software (at adobe.com)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:5d63146c-1b97-4cfb-8fd5-345eba80de21>","<urn:uuid:aa95c10d-c1d9-43c7-bdc7-df9ec67172ee>"],"error":null}
{"question":"How does the Western Development Commission support job creation in Western Ireland?","answer":"The Western Development Commission (WDC) supports job creation in Western Ireland through multiple channels. It has invested €46.6 million through the Western Investment Fund (WIF) to support 131 enterprises, including 72 SMEs, 16 micro-enterprises, and 43 community enterprises, directly supporting 2,500 jobs. Since 2010, the WDC has sourced and directed over €13M towards regional enterprise and employment development. In recent years, approximately 2,700 direct jobs and 5,000 total jobs (including indirect) have been significantly supported by the WDC in the region.","context":["Western Development Commission\nThe Western Development Commission\nThe WDC is a statutory body formed in 1998, promoting economic and social development in the Western Region of Ireland (counties Donegal, Sligo, Leitrim, Roscommon, Mayo, Galway and Clare) (www.wdc.ie).The WDC operates under the aegis of DAHRRGA and its remit is to promote, foster and encourage economic and social development in the Western Region. The WDC has the following strategic goals:\nTo encourage the development of the regions rural economy based on the sustainable development of the Western Region’s strengths and resources.\n- To provide risk capital to SMEs and social enterprises in their start-up and expansion phases through the WDC Investment Fund.\n- To inform policy-making on economic and social development in the Western Region through high quality analysis.\n- To promote the benefits of living, working and doing business in the Western Region.\nA Regional Development capacity for the West of Ireland\nThe WDC has developed a way of working that delivers a unique and effective response to the development challenges of a predominantly rural region. The WDC is a lean and efficient agency that delivers a critical capacity to the Western Region to identify, design and implement economic development and growth. Furthermore it adds value and regional ‘sensitivity’ to the work of national and international bodies and actively engages with regional interests through a combination of:\n- Implementation - Initiation of regional programmes with partners that deliver real value ‘on the ground’ in a largely rural region;\n- Insight - development of a robust information base on regional issues which provides an acknowledged valuable input to national policy-making in areas such as energy infrastructure and broadband;\n- Identity - Enabling and promotion of a globally recognised, regional identity – through the www.LookWest.ie platform the Western Region has a decade of investment that allows it to connect with tens of thousands of individuals and businesses (currently it accesses ~17, 000 social media colleagues). This provides an international ability to engage individuals and to attract talent and enterprise to our communities.\n- Investment -operating the Western Investment Fund (WIF) as a unique source of risk capital for entrepreneurs in the Western Region.\nWDC Impact to date\n- Investment in regional jobs - Since 2010 the WDC has sourced and directed over €13M in total funding towards regional enterprise and employment development\n- Regional Policy and analysis capability – This regional capacity has led to advances in critical areas such as broadband roll out , proliferation of the gas network to towns in the region, showcasing novel growth sectors such as the creative economy and ensuring the region is at the forefront of growing these areas. Ensured region involved in national initiatives such as CEDRA etc.\n- Realisation of regional jobs – In recent years approx. 2700 direct jobs and 5000 total (indirect and direct), have been significantly supported by the WDC in the region (Many through the WIF facility).\n- Regional capability to access EU programming funds – From a standing start in 2009 the WDC now has a regional capacity to develop and deliver significant funding across a range of key growth sectors. In 2016 the WDC are engaged in EU projects with a total value of €6M and have arranged for local authorities technical assistance funding to access over €5M in low interest loan funding for Renewable energy DH schemes. The WDC has sourced finance and implemented practical enterprise support initiatives in critical regional growth sectors such as renewable Bioenergy, the creative economy, cultural tourism and the general micro and SME sector.\n- Regional “access to finance” capability- The WIF established by the Irish Government to be a unique source of risk funding to projects, businesses and communities in the region, has increased the regional access to venture capital (VC) funding.\nCumulative gains to date:\n- €46.6 million invested\n- 131 enterprises supported: 72 SMEs, 16 micro, 43 community enterprises\n- 2,500 jobs directly supported by the WIF alone\n- Regional identity – The www.Lookwest.ie platform has both given the region a brand with real reach (over 1M visits since launch, almost 20,000 social media “friends”), but has also allowed local authorities, organisations, individuals, and business engage with one another in all things of the West."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:4badfbb7-3899-4336-a106-5b1f363b4c23>"],"error":null}
{"question":"Hey there! I'm a new mom and I'm wondering - what's the difference between how breastfeeding affects weight loss vs. how it impacts fertility return?","answer":"Breastfeeding affects both weight loss and fertility through energy balance, but in different ways. For weight loss, breastfeeding requires about 500 extra calories per day for milk production, and mothers can safely lose weight through diet and exercise without affecting milk supply. For fertility, the return of menstruation/ovulation depends on the balance between total energy intake and output - when a mother's energy output (through breastfeeding and activity) exceeds her energy intake, ovulation typically remains suppressed. However, if she becomes less active, reduces nursing, or increases calorie intake above her needs, her body may interpret this as having sufficient resources to support another pregnancy, leading to the return of fertility.","context":["For many breastfeeding moms, lactational amenorrhea is a pretty darn nice perk. With my firstborn, I was one of the lucky ones—I went an entire year after my baby was born without getting a period thanks to breastfeeding. It would be an understatement to say I was delighted the entire time. In fact, I seriously considered adding in some extra pumping after year 1 just to keep that lovely little side effect.\nSecond baby, I was excitedly anticipating another 2 years period free—yippee!!! So imagine my surprise when at 7 and a half months postpartum, my period returned. I was supposed to get a full year—just like last time!\nNow, as I understood lactational amenorrhea theory at the time, the loss of fertility during lactation was due to the frequency of suckling or nursing intensity. According to this theory, the more often you feed the baby, the less likely you are to ovulate.1-2 While this makes sense in many cases, in my own experience it didn’t add up. As I was often home with him, I nursed my second baby much more often than I nursed my first (I was working full time and pumping), but my periods returned more than 5 months sooner.\nWhile researching lactational amenorrhea for a review article with colleagues, I came across a study with an alternate theory called the metabolic load hypothesis. Valeggia and Ellison found that in a group of Toba women in Argentina who had high nursing intensity and high nutritional status they could predict the return of menses by looking at a mother’s energy balance rather than just nursing intensity.3 They were looking at this equation:\nTotal energy taken in (eating) – Total energy used up (breastfeeding, exercise)\nWhen this equation came out to a positive number (more energy in than energy out), the authors could actually detect a rise in C peptide levels (a marker for insulin) in a women’s urine, and soon after, that woman “got her period back.”\nWhen I think about my situation using this theory, it makes a little more sense. With my first, although I went back to work full time at 3 months, my job as a graduate student in a cell biology lab was pretty physically active. Despite sitting down a bit here and there, I was frequently standing up, lifting, walking across the lab to get something and moving my body to conduct my experiments. In addition, I was pumping every 3 hours or so while I was away from my baby. My energy output was more than my energy input up until the time friends convinced me to stop pumping at work a little after my son was a year old. Within a month my period had returned.\nWith my second baby, I worked part time and had a more flexible schedule, allowing me to work at home often and be close by to nurse my son on demand much of the time rather than deal with pumping. While this situation provided for greater nursing intensity, my energy expenditure was much lower than it had been as a graduate student. In contrast to the constant movement I experienced working in the lab, as a professor I spent much of my work time sitting and writing on the computer, and sometimes snacking while I was doing that. Not a good recipe for expending energy!\nGiven the differences in my activity level while nursing my 2 children, the very different timing I experienced in return of menses starts to make sense.\nAlthough most of us (myself included) generally think about this in terms of the physical signals of menses–getting our periods back— what’s really happening is ovulation. You may have heard that high performance athletes often stop menstruating when they’re training really intensely? Scientists believe that intense energy expenditure or lack of food act as a signal to the body that it’s not a good time to reproduce, causing the body to shut down ovulation. Making and raising babies takes a tremendous amount of resources—not something mom has if she’s starving or expending huge amounts of energy, such as in training for the Olympics.\nAccording to the metabolic load hypothesis, lactational amenorrhea may work much the same way. Milk making in humans requires an average of 500 extra calories a day, even more than pregnancy. If mom is exclusively breastfeeding and active, her energy output through activity and lactation is likely to be greater than or equal to her energy input. If baby starts nursing less, mom becomes less active, or starts consuming more calories than she needs, her body gets the signal that there are ample resources to have more babies, and mom starts ovulating (and menstruating) again.\nThe average duration of lactational amenorrhea in exclusively breastfeeding (no formula, foods, or anything else) mothers in the US is about 6 months.4 This coincides fairly well with the start of the introduction of solid foods, which may begin to reduce nursing intensity. Before then, the lactational amenorrhea method can even be used as a form of birth control, believed to be about 98% effective provided you follow these rules:5-6\nLactational Amenorrhea Method\n- Baby must be less than 6 months old.\n- Mom must not have had a return of menses (defined as 2 contiguous days of bleeding, 2 contiguous days of spotting and 1 day of bleeding, or 3 contiguous days of spotting)\n- Mom is exclusively breastfeeding her baby with no more than 4 hours between daytime feeds and no more than 6 hours between night time feeds and no more than 10% of calories coming from supplementation with infant formula or complementary food5-6\nAs for me, I’m glad there’s data to explain my experience!\nWhen did you get your period back while breastfeeding? Did it differ between children?\n1. C.C.K Tay AG, A. McNeilly. Twenty-four hour patterns of prolactin secretion during lactation and the relationship to suckling and the resumption of fertility in breast-feeding women. Human Reproduction 1996;11(5):950-955.\n2. McNeilly AS, Tay CCK, Glasier A. Physiological Mechanisms Underlying Lactational Amenorrhea. Annals of the New York Academy of Sciences 1994;709(1):145-155.\n3. Valeggia C, Ellison PT. Interactions between metabolic and reproductive functions in the resumption of postpartum fecundity. Am J Hum Biol 2009;21(4):559-66.\n4. Heinig MJ N-RL, Peerson JM, Dewey KG. Factors related to duration of postpartum amenorrhoea among USA women with prolonged lactation. J Biosoc Sci. 1994;26(4):517-27.\n5. Hight-Laukaran V, Labbok MH, Peterson AE, Fletcher V, von Hertzen H, Van Look PFA. Multicenter study of the Lactational Amenorrhea Method (LAM): II. Acceptability, utility, and policy implications. Contraception 1997;55(6):337-346.\n6. Peterson AE, Peŕez-Escamilla R, Labboka MH, Hight V, von Hertzen H, Van Look P. Multicenter study of the lactational amenorrhea method (LAM) III: effectiveness, duration, and satisfaction with reduced client–provider contact. Contraception 2000;62(5):221-230.","Patient information: Maternal health and nutrition during breastfeeding (Beyond the Basics)\n- Nancy F Butte, PhD\nNancy F Butte, PhD\n- Professor of Pediatric Nutrition\n- Baylor College of Medicine\n- Alison Stuebe, MD, MSc\nAlison Stuebe, MD, MSc\n- Associate Professor of Obstetrics and Gynecology\n- Division of Maternal-Fetal Medicine\n- University of North Carolina School of Medicine\n- Section Editors\n- Steven A Abrams, MD\nSteven A Abrams, MD\n- Section Editor — Neonatology\n- Professor of Pediatrics\n- Baylor College of Medicine\n- Kathleen J Motil, MD, PhD\nKathleen J Motil, MD, PhD\n- Section Editor — Pediatric Nutrition\n- Professor of Pediatric Nutrition\n- Baylor College of Medicine\nBREASTFEEDING AND HEALTH OVERVIEW\nWomen have an amazing ability to produce a sufficient quantity and quality of breast milk to support an infant, even if the woman is undernourished. However, breastfeeding women do need an increased number of calories and nutrients to maintain their milk supply.\nIn most cases, the best way to get an adequate number of calories and nutrients is to eat a healthy, well-balanced diet that includes fruits, vegetables, protein, grains, and a limited amount of fat, sometimes with a multivitamin supplement. The components of a healthy diet are discussed in depth in a separate topic review. (See \"Patient information: Diet and health (Beyond the Basics)\".)\nThis topic review discusses the nutritional needs of women who are breastfeeding, including recommendations for calorie intake, vitamin and mineral supplements, fluid recommendations, and guidelines for weight loss while breastfeeding. Foods, drinks, and medications that should be limited or avoided are also discussed.\nTopic reviews about the basics of breastfeeding and common breastfeeding problems are also available. This topic discusses how to prepare to breastfeed, including the benefits of breastfeeding. Additional breastfeeding topics are available separately. (See \"Patient information: Common breastfeeding problems (Beyond the Basics)\" and \"Patient information: Breastfeeding guide (Beyond the Basics)\" and \"Patient information: Deciding to breastfeed (Beyond the Basics)\" and \"Patient information: Breast pumps (Beyond the Basics)\".)\nNUTRITION AND BREASTFEEDING\nCalorie recommendations — The total number of calories a woman needs depends upon the following factors:\nFor example, a 25-year-old woman who is not breastfeeding and is 5 feet, 5 inches tall and 140 pounds and is not active needs approximately 2190 calories per day. A woman who is older, shorter, who weighs less or who is less active would need fewer calories per day while a woman who is taller, younger, weighs more, or is more active would need more calories per day.\nThe energy and nutritional requirements of women who breastfeed are greater than those of women who are not breastfeeding. The energy cost of exclusive breastfeeding from birth through six months postpartum is 500 kcal/day. Because weight loss will subsidize this cost (approximately 170 kcal per day), the recommended dietary allowance (RDA) for energy is set at 330 kcal per day.\nUsing the woman in the above example, the recommended total calorie intake would be approximately 2520 calories per day.\nFluid intake — The average woman who breastfeeds exclusively produces 750 to 800 mL (approximately 25 ounces) of breast milk per day. Many women wonder how much extra fluid they should drink given this relatively large loss of fluid. It is generally sufficient for a woman to drink when she is thirsty and to watch for early signs that she is not getting enough fluids (eg, dark-colored urine, infrequent urination, dry mouth). To encourage an adequate fluid intake, some clinicians recommend keeping a bottle of water or another non-caffeinated beverage nearby while nursing or working.\nWEIGHT LOSS AND BREASTFEEDING\nFollowing pregnancy, most women lose weight gained during pregnancy gradually. Losing a moderate amount of weight by eating less and/or exercising does not usually affect a woman's ability to produce an adequate amount of breast milk.\nVITAMIN AND MINERAL REQUIREMENTS WHILE BREASTFEEDING\nWomen who are healthy and eat a well-balanced diet that includes meat and fish do not usually need to take a vitamin supplement while breastfeeding. However, all women, including those who breastfeed, should ensure that they consume an adequate amount of calcium and vitamin D. (See 'Calcium' below.)\nVegans — Women who are healthy but who do NOT eat meat, chicken, fish, or dairy products need to take a vitamin supplement that contains vitamin B12. Most commercially available multivitamins contain an adequate dose of B12.\nCalcium — Pregnancy and breastfeeding cause a temporary decrease in bone mass. However, lost bone is usually regained after a woman stops breastfeeding. This loss cannot be prevented by consuming additional calcium during pregnancy or while breastfeeding. All adult women should consume a daily minimum of 1000 mg of calcium; adolescents should consume 1300 mg of calcium per day.\nThe primary sources of calcium in the diet are milk and other dairy products, such as hard cheese, cottage cheese, or yogurt, as well as green vegetables, such as spinach (table 1). If it is not possible to consume enough milk or other foods that contain calcium, it is reasonable to take a calcium supplement (table 2). (See \"Patient information: Calcium and vitamin D for bone health (Beyond the Basics)\".)\nVitamin D — Absorption of calcium depends upon having an adequate level of vitamin D. Both breastfeeding and nonbreastfeeding women require an estimated 600 int. units per day of vitamin D. Vitamin D fortified milk is a good source of dietary vitamin D, with approximately 100 int. units per cup. A vitamin D or calcium plus vitamin D supplement is also a good source of vitamin D. (See \"Patient information: Calcium and vitamin D for bone health (Beyond the Basics)\".)\nIron — Women who are not anemic after delivery and who breastfeed exclusively do not usually have a menstrual period for the first four to six months. Thus, there is little iron lost in menstrual blood. An iron supplement is not usually needed during this time.\nWomen who are anemic after delivery usually require an iron supplement; this may include an over-the-counter or prescription iron supplement. The recommended type and dose of iron should be discussed with a healthcare provider. (See \"Patient information: Anemia caused by low iron (Beyond the Basics)\".)\nFish — The American Academy of Pediatrics recommends that nursing mothers take in 200 to 300 mg of omega-3 fatty acids per day . Women can meet this need with one to two servings of fish per week, such as herring, canned light tuna, or salmon. To reduce exposure to mercury, mothers should avoid predatory fish such as shark, swordfish, king mackerel, or tilefish, which have high levels of mercury.\nCheck local advisories about the safety of fish caught by family and friends in local lakes, rivers, and coastal areas (www.epa.gov/waterscience/fish/). If no advice is available, breastfeeding mothers may eat up to 6 ounces (one average meal) per week of fish caught from local waters, but should not consume any other fish during that week.\nMEDICATION SAFETY WITH BREASTFEEDING\nMost medications taken by mothers during breastfeeding are safe for their infants. However, there are exceptions. For this reason, it is best to consult with a healthcare provider, lactation consultant, or pharmacist if there is any question of a medication's safety while breastfeeding . It is important to be aware that the quality of information regarding medication safety in breastfeeding varies . A reliable source of up-to-date information is LactMed, which is available from the National Library of Medicine (http://toxnet.nlm.nih.gov/cgi-bin/sis/htmlgen?LACT).\nSome medications are safe but can potentially affect the amount of breast milk produced. For example, combined estrogen/progesterone birth control pills may decrease the amount of milk a woman produces. For this reason, women who are breastfeeding are discouraged from using combination birth control pills. Progesterone-only birth control pills, intrauterine devices (IUDs), and injections are less likely to affect milk supply, although early placement of progesterone-containing IUDs has been reported to decrease breastfeeding duration . As a result, nonhormonal birth control methods are preferred as the first line of contraceptive therapy for breastfeeding mothers. (See \"Patient information: Hormonal methods of birth control (Beyond the Basics)\".)\nOver-the-counter decongestants that contain pseudoephedrine (Sudafed) can also decrease milk supply .\nMedications to avoid while breastfeeding — Some medications are known to be harmful to infants and should be avoided by women who breastfeed if possible. Illegal drugs such as amphetamines, cocaine, phencyclidine (PCP), and heroin are not safe for a woman or her baby; women who use these drugs are advised to not breastfeed. There are limited data on the effects of marijuana in infants; we advise women who breastfeed to avoid use of marijuana.\nAlcohol — When a breastfeeding woman consumes alcohol, a small percentage of alcohol is transferred into her breast milk. The amount of alcohol considered to be \"safe\" while breastfeeding is controversial. A number of factors affect how much alcohol is transferred to breast milk and how much an infant absorbs.\nFor an average-weight woman, it takes about two hours for a single serving of alcohol to clear completely from her body. One serving of alcohol is 12 ounces of beer, five ounces of wine, or 1.5 ounces of 80-proof liquor. To completely avoid any alcohol being transferred to the infant, experts recommend that a woman wait two hours after consuming a single serving of alcohol. If a woman drinks more than this amount, she should refrain from breastfeeding for an additional two hours for each serving of alcohol .\nCaffeine — Most breastfeeding women can drink a moderate amount caffeine without it affecting their infants. The American Academy of Pediatrics defines a moderate intake of caffeine as two to three cups of a caffeinated beverage per day . However, some young infants are sensitive to caffeine and become irritable or have difficulty sleeping, even with small amounts of caffeine. An infant's sensitivity to caffeine usually lessens over time because caffeine clearance is initially slow in newborns, but rises to adult clearance levels by three to five months.\nTobacco — Infants of parents who smoke have an increased risk of a number of conditions, including asthma, pneumonia, ear infections, bronchitis, and sudden infant death syndrome (SIDS), among others. These risks still exist for infants who are breastfed and live with smokers. Cutting down or stopping smoking can decrease these risks. However, for women who are unable to stop smoking, the benefits of breastfeeding are thought to outweigh the risks of formula feeding. Smoking can reduce a mother's milk supply. (See \"Patient information: Quitting smoking (Beyond the Basics)\".)\nWHERE TO GET MORE INFORMATION\nYour healthcare provider is the best source of information for questions and concerns related to your medical problem.\nThis article will be updated as needed on our web site (www.uptodate.com/patients). Related topics for patients, as well as selected articles written for healthcare professionals, are also available. Some of the most relevant are listed below.\nPatient level information — UpToDate offers two types of patient education materials.\nThe Basics — The Basics patient education pieces answer the four or five key questions a patient might have about a given condition. These articles are best for patients who want a general overview and who prefer short, easy-to-read materials.\nPatient information: Health and nutrition for women who breastfeed (The Basics)\nPatient information: Nutrition before and during pregnancy (The Basics)\nPatient information: Breastfeeding (The Basics)\nPatient information: Common breastfeeding problems (The Basics)\nPatient information: Vitamin B12 deficiency and folate (folic acid) deficiency (The Basics)\nPatient information: Vitamin supplements (The Basics)\nBeyond the Basics — Beyond the Basics patient education pieces are longer, more sophisticated, and more detailed. These articles are best for patients who want in-depth information and are comfortable with some medical jargon.\nPatient information: Diet and health (Beyond the Basics)\nPatient information: Common breastfeeding problems (Beyond the Basics)\nPatient information: Breastfeeding guide (Beyond the Basics)\nPatient information: Deciding to breastfeed (Beyond the Basics)\nPatient information: Breast pumps (Beyond the Basics)\nPatient information: Calcium and vitamin D for bone health (Beyond the Basics)\nPatient information: Anemia caused by low iron (Beyond the Basics)\nPatient information: Hormonal methods of birth control (Beyond the Basics)\nPatient information: Quitting smoking (Beyond the Basics)\nProfessional level information — Professional level articles are designed to keep doctors and other health professionals up-to-date on the latest medical findings. These articles are thorough, long, and complex, and they contain multiple references to the research on which they are based. Professional level articles are best for people who are comfortable with a lot of medical terminology and who want to read the same materials their doctors are reading.\nBreastfeeding: Parental education and support\nCommon problems of breastfeeding and weaning\nMaternal nutrition during lactation\nNutrition in pregnancy\nNutritional composition of human milk for full-term infants\nThe impact of breastfeeding on the development of allergic disease\nSafety of infant exposure to antidepressants and benzodiazepines through breastfeeding\nTreatment, prognosis, and prevention of Listeria monocytogenes infection\nPrevention of HIV transmission during breastfeeding in resource-limited settings\nThe following organizations also provide reliable health information.\n●National Library of Medicine\n●The Academy of Breastfeeding Medicine\n●La Leche League\n●The Center for Disease Control and Prevention\n●American Academy of Pediatrics\n●International Board of Lactation Consultant Examiners\n●International Lactation Consultant Association\n- Section on Breastfeeding. Breastfeeding and the use of human milk. Pediatrics 2012; 129:e827.\n- American Academy of Pediatrics Committee on Drugs. Transfer of drugs and other chemicals into human milk. Pediatrics 2001; 108:776.\n- Akus M, Bartick M. Lactation safety recommendations and reliability compared in 10 medication resources. Ann Pharmacother 2007; 41:1352.\n- Chen BA, Reeves MF, Creinin MD, Schwarz EB. Postplacental or delayed levonorgestrel intrauterine device insertion and breast-feeding duration. Contraception 2011; 84:499.\n- Aljazaf K, Hale TW, Ilett KF, et al. Pseudoephedrine: effects on milk production in women and estimation of infant exposure via breastmilk. Br J Clin Pharmacol 2003; 56:18.\n- Ho E, Collantes A, Kapur BM, et al. Alcohol and breast feeding: calculation of time to zero level in milk. Biol Neonate 2001; 80:219.\n- Standing Committee on the Scientific Evaluation of Dietary Reference Intakes IoM. Dietary Reference Intakes for Thiamin, Riboflavin, Niacin, Vitamin B6, Folate, Vitamin B12, Pantothenic Acid, Biotin, and Choline, National Academy Press, Washington, DC 2000.\n- What about drinking alcohol and breastfeeding? La Leche League. Available at: www.lalecheleague.org/FAQ/alcohol.html (Accessed on June 01, 2007).\n- Anderson PO. Alcohol and breastfeeding. J Hum Lact 1995; 11:321.\n- Food and Nutrition Board and Institute of Medicine. Dietary Reference Intakes: The Essential Guide to Nutrient Requirements, Otten J, Hellwig JP, Meyers LD (Eds), National Academies Press, Washington, DC 2006.\n- Lovelady CA, Stephenson KG, Kuppler KM, Williams JP. The effects of dieting on food and nutrient intake of lactating women. J Am Diet Assoc 2006; 106:908.\nAll topics are updated as new information becomes available. Our peer review process typically takes one to six weeks depending on the issue."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:b9612f63-9eb7-4b3c-b550-bdb3d3dc57f1>","<urn:uuid:ed7c7f7f-deb5-4aba-a38c-a01bd1df0dac>"],"error":null}
{"question":"I'm reading about Islam's global reach. Could you explain how Islam is practiced differently in Arab versus non-Arab countries, and what role does the concept of Jihad play in these different contexts?","answer":"Islam manifests differently between Arab and non-Arab countries in several key ways. Non-Arab Muslim countries are heavily influenced by their indigenous cultures and customs, leading to varied religious practices. For example, ceremonies like Milad Mahfil are common in non-Arab countries but don't exist in Arab nations. Non-Arab Muslims tend to be more flexible in their approach, often participating in other faiths' festivals and being more willing to elect women leaders. Regarding Jihad, Islamic scholars emphasize that it has been misinterpreted by militants. The true meaning of Jihad encompasses both outward and inward struggles, with the inward spiritual struggle (jihad al-nafs) being considered more fundamental. This involves conquering the forces of evil within oneself and society, rather than merely engaging in armed combat. Notably, the word Jihad in the Quran is not used to denote armed combat, for which other specific Arabic terms exist.","context":["Bottom line |\nThe relevance of understanding Islam\nHarun ur Rashid\nIslam is a revealed religion like Judaism and Christianity. All these great revealed religions trace their common root to Ibrahim (Abraham) Khalil Ullah (Friend of Allah) who lived around 1900-2200 BC. According to Holy Qu'ran, Ibrahim had two sons, Ismail and Ishaque (Isaac). Prophet Mohammad (SM) belonged to the family of Ismail while Moses and Jesus to that of Ishaque.\nIslam is not a new religion, but reiterates the Divine Message proclaimed by numerous prophets in different places and at different times. It is a universal religion and its adherents currently numbering more than one billion have spread over all the continents. Islam has stimulated thought and action of Islamic and non-Islamic scholars since it was first preached during the 7th century in Arabia.\nIslam and Arabs\nPeople of Arabia were steeped in ignorance and Prophet Mohammad (SM) was sent to guide them in their language. About Arab people Surah Tauba, Verse 97 of the Holy Qu'ran states as follows:\nThe Arabs of the desert\nAre the worst in un-belief\nAnd hypocrisy and most of\nThem fitted to be in ignorance. (Translation by Abdullah Yusuf Ali)\nRift in Muslim community\nAlthough Islam is strictly monotheistic, the monolithic structure of the Muslim community did not survive three decades after the death of Prophet Mohammad (SM). The first rift in the early Muslim community was rather political in character and arose over succession to the Prophet. A section of the Muslim community supported the case of the Prophet's son-in-law and cousin, Hazrat Ali. Another group endorsed Hazrat Abu Bakr, an elderly close companion and father-in-law of the Prophet. Eventually Hazrat Abu Bakr succeeded the Prophet with the support of the elders.\nThe group supporting Ali constituted themselves into Shiah-i-Ali (Party of Ali), a term which came to be known simply as Shi'iah. The rise of Shi'iasm bifurcated the Muslim community. The bulk of Shi'ia currently live in Iraq and Iran, while the other group of Muslims who are known as Sunnis constitutes majority in other Muslim countries. As the term connotes, they take their name on the basis of their strict adherence to Sunnah or traditions of the Prophet.\nRegrettably the militant Islamists have hijacked the essence of Islam. The militants hardly follow the Qu'ranic injunctions. For example, in Surah Nisa, Verse 152, of the Holy Qu'ran , the description of a \"Believer\" is as follows:\nTo those who believe\nIn God and His Apostles,\nAnd Make no distinction\nBetween any of the Apostles\nWe shall soon give\nTheir due rewards.\nIn the verse the word \"Apostles\" (plural) is employed and it means that any person who believes in God and his/her apostle, is a \"Believer.\" It implies that not only Muslims, but also Jews and Christians are \"Believers.\" Another verse in the same Surah Nisa (Verse 93) proclaims:\nIf a man kills a Believer\nIntentionally, his recompense\nIs Hell, to abide therein\nThis verse makes it clear that if a Muslim kills a Jew or a Christian or any person who believes in God, his only place is in Hell.\nMeaning of Jihad\nAnother fact that merits attention is the true meaning of Jihad (struggle). Jihad does not mean war involving killing people. Many Islamic scholars of repute hold the view that Jihad signifies a physical, moral, spiritual ,and intellectual effort to conquer the forces of evil in oneself and in one's society. They argue that there are plenty of Arabic words denoting armed combat, such as harb (war), sira'a (combat), ma'araka (battle) or qital (killing) employed in the Holy Qu'ran. The word Jihad has not been used to denote an armed combat or killing.\nJihad means struggle within oneself to get rid of vices. It is an on-going inner struggle within oneself to remain away from sins and to move towards approved way of life in this world. Islamic scholar Abdullah Yusuf Ali (1872-1953) in his commentary number 1270 of Surah Tauba of the Holy Qu'ran stated that \"mere brutal fighting is opposed to the whole spirit of Jihad while the sincere scholar's pen or preacher's voice or wealthy man's contribution may be the most valuable forms of jihad.\"\nIt is acknowledged by many Islamic scholars that although Islam was primarily preached for Arabs, it quickly spread among non-Arab people who spoke different languages other than Arabic because the simplicity of Islamic teachings together with the concept of equality of human beings was attractive to people in different lands.\nMany Islamic scholars believe that the principle of Ijtihad, the use of reason to apply Qu'ranic injunctions to contemporary values is almost absent in most Islamic countries. Muslim people live within a given social, economic and administrative structure of a particular time and place. Accordingly, many Islamic scholars hold the view that Islamic precepts and practices are to be adapted to meet the needs of the day.\nI would argue that non-Arab Muslims in general have a different approach in understanding Islam. Many factors have a role but a few in particular deserve mention.\nFirst, Islam in non-Arab countries is influenced by indigenous culture and customs of the people. Furthermore Persian and Turkish influence is visible in Pakistan, India and Bangladesh because at one stage they ruled the undivided India prior to the British rule. Accordingly, in non-Arab Muslim countries, Islamic day-to-day practices often vary from those of Arab Muslim countries. Let me cite an example, the religious ceremony of Milad Mahfil or Milad Sharif is found common in non-Arab countries, while such ceremony does not exist in Arab Muslim countries. In fact Arab Muslims get surprised when they find out that many non-Arab Muslims perform such religious ceremony\nSecond, Arab culture is predominantly tribal and is rooted in desert environment. Many Arab Muslims consider Arab culture as Islamic culture. This has created confusion among non-Arab Muslims. Many of them argue that Arab culture is rooted in the land of Arabia and does not reflect Islamic culture. Islamic culture is wider than that of Arab culture. For example, food habits are different in every country and all Islamic countries do not follow what Arab Muslims eat. The mode of Arab dress applicable to a desert environment cannot be followed in a humid and rain-drenched country, even though they are Muslims by faith\nThird, Arab nationalism is based on Arab race and non-Arabs are not included. The Arab League consists of Arab nation-states. During the Iran-Iraq war in the 80s, most Arab nations supported Arab-Iraq against non-Arab Iran, while most non-Arab states remained neutral.\nFourth, except within the framework of the UN, Arab Muslim states have little opportunity to interact closely with non-Muslim states in view of the fact that most Arab countries have hardly any non-Muslim states as neighbours. On the other hand, non-Arab Muslim states have non-Muslim neighbours. For example Bangladesh's neighbours and near neighbours are all non-Muslims states. Furthermore, non-Arab Muslim states belong to regional inter-governmental organizations, such as, ASEAN or SAARC. They interact with non-Muslim states within the regional organisation to address regional issues where religion does not play a part.\nFifth, understanding of Islam is different among non-Arabs and this is manifested in the fact that people of non-Arab Muslim countries are willing to elect women as their heads of state/government, but the idea of women running a country seems to be an unacceptable idea in Arab Muslim countries. Conservative Muslims maintain that women have no role in politics, let alone running a country.\nSixth, most Arab Muslim states have small minority communities of other faiths. Whereas many of the non-Arab Muslim states have sizeable religious minority communities. This being the case, often many non-Arab Muslims do not hesitate to participate in festivals of other faiths as social and cultural traditions, just as many Muslims participate in Christmas festivities without being Christians. The interaction of non-Arab Muslims with people of other faiths has given an opportunity to respect other religious faiths. The result is that non-Arab Muslims tend to be less dogmatic or rigid in their views of non-Islamic faith.\nFinally, all Arab Muslim states (22 in number) are being ruled by political institutions, such as monarchs, Emirates, Sultans, and Presidents. The Presidents in some Arab countries are elected thorough a process that can hardly be called fully free and democratic. While in most non-Arab Muslim states, people elect their governments through fair and free elections (monitored by foreign observers) once every four or five years.\nIt is reported that 80 percent of the Muslim population live in non-Arab Muslim countries, and the overwhelming majority of them have tolerant views of Islam. It is noted that extremists in Islam are much fewer in number than the moderates, but their voice has not kept pace with that of extremists. It is a challenge to be taken up by moderate Muslims. It is heartening to note that Bangladesh has joined as one of the moderate Muslim states invited by Singapore Prime Minister to provide moderate and tolerant views of Islam across the world.\nBarrister Harun ur Rashid is a former Bangladesh Ambassador to the UN, Geneva.","The Greater Jihad: Is it Just a Myth?\nMuslim scholars have long identified two types of jihad (lit. “striving” in God’s cause): an outer form of jihad and an inner one. The outward jihad refers to state-sanctioned military force (i.e. armed combat), which is waged defensively to protect both religion and realm; or offensively to combat tyranny, or protect the innocent and defenceless against unjustified aggression. As for the inner jihad (jihad al-nafs), it is the struggle to oppose the ego (nafs) and its impulses, until it is in submission to God. That this inner jihad is known as the “greater” jihad, as per mainstream Sunni scholarship, has raised some objections in our time. What follows is an explanation of why there needn’t be a concern about such a designation, and why objections to it are simply misplaced. The following nine points, I hope, get to the crux of the matter:\n1. In regards to the overall schema of jihad, al-Raghib al-Asbahani, a notable scholar of the fifth Islamic century, wrote: ‘Jihad is of three types: striving against the apparent enemy; against the devil; and against the ego (nafs). All three types are included in the words of God, exalted is He: And strive hard in God’s path with all the striving that is due to Him. [22:78]’1 A few centuries on, and a similar abstract is offered by Ibn al-Qayyim: ‘Jihad is of four types: jihad against the ego, against the devil, against the disbelievers, and against the hypocrites.’2\n2. Jihad against the apparent enemy; which is to say, jihad against hostile, belligerent disbelievers, finds its equivalence in another Qur’anic term: qital (“fighting”, “armed combat”). It is in this sense that the Qur’an charges: Fight for the sake of God those who fight against you, but do not transgress. God does not love the aggressors. [2:190] The rules of jihad as military warfare are stipulated in the manuals of Islamic law (fiqh) as well as the fatwas of recognised and qualified bodies of contemporary jurists.\n3. Many verses in the Qur’an extol the virtues of seeking to purify the soul. One group of verses states: By the soul and Him that formed it, then inspired it with its depravity and piety. He is indeed successful who purifies it, and he is indeed ruined who corrupts it. [91:7-10] Another offers these tidings: But those who feared the standing before their Lord and curbed their soul’s passions, the Garden is their abode. [79:40-41] Also in this context are these words of the Prophet, peace be upon him: ‘The fighter in God’s path is one who strives against his lower soul/ego in obedience to God (al-mujahid man jahada nafsahu fi ta‘ati’lLah).’3 Thus this inward jihad refers to the personal struggle against one’s ego so as to overcome temptations, false desires and spiritual vices, as well as internalise acts of worship like prayer, fasting, pilgrimage, dhikr and almsgiving. This inner jihad, or spiritual striving, is referred to as mujahadah.\n4. Now for the tricky part. One lionised hadith states that the Prophet, peace be upon him, having returned from a military campaign with his companions, said: ‘You have returned from the lesser jihad to the greater jihad.’ When asked what the greater jihad was, he replied: ‘A person’s jihad against his desires.’4 However, according to classical hadith masters and specialists, this hadith is weak (da‘if). Which is to say, such words cannot authentically or reliably be ascribed to the Prophet, peace be upon him. Or to put it another way, the likelihood of the Prophet not having said these words is far far greater than the likelihood of him having uttered them.\nAl-Bayhaqi says after citing it: ‘This is a chain containing weakness.’5 Al-‘Iraqi relays the same ruling in his hadith verification of the Ihya.6 While Ibn Hajr al-‘Asqalani states: ‘It is related via ‘Isa b. Ibrahim; from Yahya b. Ya‘la; from Layth b. Abi Sulaym: all three are weak. Al-Nasa’i recorded it in al-Kuna as the statement of Ibrahim b. Abi ‘Abla, a famous successor (tabi‘i) of Syria.’7 Ibn Rajab al-Hanbali declares the hadith to be weak, but relates it as the saying of the above Ibrahim b. Abi ‘Abla.8 In more recent times, al-Albani made a thorough analysis of the hadith’s various chains, declaring the hadith to be unreliable (munkar).9 As for ‘Ali al-Qari and al-Suyuti, they both recorded the hadith in their respective dictionaries of weak and fabricated hadiths.10\n5. The above analysis concerns the chain (isnad) of the hadith. As for its meaning, then many scholars point out how the meaning is sound in terms of the inner jihad, jihad al-nafs, having primacy over the outer jihad. The hadith may also be read in a way that gives it a completely false meaning, which is the one I’ll tackle first. Thus, if one takes the hadith to mean that the outer “lesser” jihad is inconsequential or of little worth; or that the inner “greater” jihad replaces it or is an alternative to it, this is utterly false and at odds with the very Qur’an itself. From such a perspective, Ibn Taymiyyah said about the hadith: ‘It has no basis, and none of those who are an authority (ahl al-ma‘rifah) in the words and deeds of the Prophet, peace be upon him, have reported it. Jihad against the disbelievers is one of the greatest of deeds; in fact, it is the best of the optional deeds a person could perform. God, exalted is He, says: Not equal are those of the believers who sit [at home], other than those who have a disabling hurt, with those who strive in the cause of God with their wealth and their lives. God has conferred on those who strive with their wealth and their lives a rank above the ones who sit [at home]. To both has God promised goodness, but God has preferred those who strive over those who do not with an immense reward. [4:95]’11 There is also the hadith: A man asked: O Messenger of God, guide me to a deed equivalent to jihad. He replied: ‘You do not have the ability.’ He went on to say: ‘Do you have the ability, from the time the person leaves for jihad [until he returns], to go into the mosque and pray without stopping and fast without a break?’ The man said: Who has the ability to do this?12\n6. The hadith undoubtedly has a sound meaning, in that the inner and outer jihad are both great and of tremendous merit, but the inner jihad has primacy over the outer; and so is “greater”. A number of scholarly statements testify to this fact, including Ibn al-Qayyim who, avoiding the terms “lesser” and “greater”, noted about the verse: As for those who strive in Us, We will guide them to our paths. [29:69]: ‘The most obligatory jihad (afrad al-jihad) is jihad against one’s ego (nafs), desires (hawa), the devil (shaytan), and worldliness (dunya). One who wages jihad against these four in obedience to God, will be guided by God to the paths of His good pleasure which, [in turn], shall lead to His Paradise. One who neglects jihad shall be veiled from guidance to the degree he forsakes it.’13\n7. Explaining why jihad al-nafs has such a rank and distinction, Imam Ibn Taymiyyah stated: ‘Jihad against the ego and desires is the basis for jihad against the disbelievers and hypocrites. Indeed, one cannot do jihad against them unless he first wages jihad against his ego and desires; then he goes out and fights them.’14 Tragically, this simple truism seems to have been lost on many of those who have spent the best past of their years waging war against the preeminence of jihad al-nafs!\n8. Al-Munawi adds another dimension as to why the inward jihad is greater, or more obligatory, than the outward one. He says: ‘It is the greatest form of jihad; for fighting the disbelievers is a collective duty (fard kifayah), while jihad against one’s own ego is a personal obligation (fard ‘ayn), at all times, on all who are legally responsible: Truly the devil is an enemy to you, therefore treat him as an enemy. [35:6] So fight in the path of God. You are not responsible except for your own soul. [4:84]15\n9. Those who’ve dealt with the issue of the greater and lesser jihad have usually been of two camps. There are those who have sought to sweep the tradition and prophetic history of military jihad under the carpet, in favour of a purely spiritualised reading of “striving” in God’s cause. Such apologetics are usually proffered by those who feel the need to gratify modernist (or now liberal) notions of religion and non-violence; those, both Muslim and non-Muslim, with either colonised minds, staggering ignorance, or lacking all academic honesty and integrity. In contrast, there are those, again Muslim and non-Muslim, who insist upon surface readings of the Quranic verses relating to jihad, devoid of the juristic nuances found in fiqh manuals and contemporary Muslim juristic thought. Unlike the watered-down readings of the first group, this one seeks to make Islam synonymous with violence, war and terror, and perpetuate animosity between peoples so as to serve their political agendas. Both these misreadings, liberal and extremist, must be categorically rejected and repudiated.\nConclusion: The above verses, hadiths and scholarly quotes should have helped lay to rest the anathema some seem to have about the primacy of jihad al-nafs. Yet this need not be the case. For although the commonly cited hadith about it isn’t authentic, other evidences testify to its centrality in a believer’s overall worship of God. Thus the affair is as Ibn al-Jawzi decisively proclaimed: ‘I reflected over jihad against the ego (jihad al-nafs) and realised it to be the greater jihad.’16\n1. Mufradat Alfaz al-Qur’an (Beirut & Damascus: Dar al-Qalam, 2002), 208; under the entry, j-h-d.\n2. Zad al-Ma‘ad (Berut: Mu’assasah al-Risalah, 1998), 3:9.\n3. Al-Tirmidhi, no.1671, where he graded the hadith hasan sahih. However, he narrates it without the final phrase, ‘in obedience to God.’ This additional phrase is found in Ibn Hibban, no.4707, and is sahih. Cf. al-Albani, Silsilat al-Ahadith al-Sahihah (Beirut: al-Maktab al-Islami, 1985), 2:81; no.549.\n4. Al-Bayhaqi, Kitab al-Zuhd al-Kabir (Beirut: Dar al-Janan and Mu’assasah al-Kutub al-Thaqafiyyah, 1987), no.373; al-Khatib al-Baghdadi, Tarikh Baghdad (Egypt: Matba‘ah al-Sa‘adah, 1929), 13:494, with the wording: ‘Jihad of the heart.’\n5. Kitab al-Zuhd al-Kabir, p.165; no.373.\n6. Al-Mughni ‘an Haml al-Asfar (Riyadh: Maktabah al-Tabariyyah, 1995), 2:709; no.2584.\n7. Al-‘Asqalani, Takhrij al-Kashshaf (Beirut: Dar al-Turath al-‘Arabi, 1997), 4:114; no.33.\n8. Jami‘ al-‘Ulum wa’l-Hikam (Beirut: Mu’assasah al-Risalah, 1998), 1:489.\n9. Al-Albani, Silsilat al-Ahadith al-Da‘ifah wa’l-Mawdu‘ah (Riyadh: Maktabah al-Ma‘arif, 1996), 5:478-81, no.2460.\n10. Al-Qari, al-Asrar al-Marfu‘ah (Beirut: al-Maktab al-Islami, 1986), no.211; al-Suyuti, al-Durar al-Muntathirah (Riyadh: University of Riyadh, 1983), no.245.\n11. Majmu‘ Fatawa (Riyadh: Dar ‘Alam al-Kutub, 1991), 11:197-8. Stating that the hadith ‘has no basis (la asl lahu)’ conventionally means the hadith is chainless which, in this case, is incorrect. For the hadith does indeed have a chain, albeit flawed. Declaring that no hadith authorities have recorded it is another erroneous claim. For al-Bayhaqi and al-Khatib both relate it in their respective works.\n12. Al-Bukhari, no.2785. Something similar is related by Muslim, no.1876.\n13. Al-Fawa’id (Riyadh: Maktabah al-Rushd, 2001), 177.\n14. Cited by Ibn al-Qayyim, Rawdat al-Muhibbin (Beirut: Dar al-Kitab al-‘Arabi, 1996), 475-6, where he begins by insisting: ‘Even if jihad against one’s desires was not greater than jihad against the disbelievers, it is certainly not lesser than it. A man once asked al-Hasan al-Basri, may God have mercy on him: O Abu Sa‘id! What is the best jihad? He said: “Your jihad against your desires.” I once heard our Shaykh remark …’ He then goes on to cite the words of Ibn Taymiyyah above.\n15. Fayd al-Qadir (Beirut: Dar al-Ma‘rifah, n.d.), 4:511.\n16. Sayd al-Khatir (Egypt: Dar al-Yaqin, 1998), 122."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:e12fb07c-53cc-4969-9e22-89767cbfbc8e>","<urn:uuid:5d71e017-8a4b-4604-801f-fbd98567de4f>"],"error":null}
{"question":"I have both kidney disease and high blood pressure - which symptoms overlap between these conditions?","answer":"The overlapping symptoms between kidney disease and high blood pressure include dizziness and shortness of breath. In kidney failure, shortness of breath can occur due to fluid buildup in the lungs or anemia, while in high blood pressure, patients may experience dizzy spells.","context":["Nephrology is a branch of internal medicine and pediatrics dealing with the study of the function and diseases of the kidney.\nNephrology concerns the diagnosis and treatment of kidney diseases, including electrolyte disturbances and hypertension, and the care of those requiring renal replacement therapy, including dialysis and renal transplant patients.\nMany diseases affecting the kidney are systemic disorders not limited to the organ itself, and may require special treatment.\nExamples include acquired conditions such as systemic vasculitides (eg. ANCA vasculitis) and autoimmune diseases (e.g., lupus), as well as congenital or genetic conditions such as polycystic kidney disease.\nIn the USA, the National Kidney Foundation is a national organization representing patients and professionals who treat kidney diseases. Founded in 1966, the American Society of Nephrology (ASN) is the world’s largest professional society devoted to the study of kidney disease.\nIn the United Kingdom, the National Kidney Federation represents patients, and the Renal Association represents renal physicians and works closely with the National Service Framework for kidney disease.\nThe Renal Support Network (RSN) is a nonprofit, patient-focused, patient-run organization that provides non-medical services to those affected by chronic kidney disease (CKD).\nThe American Association of Kidney Patients (AAKP) is a non-profit, patient-centric group focused on improving the health and well-being of CKD and dialysis patients.\nPatients are referred to nephrology specialists for various reasons, such as:\n- Acute renal failure, a sudden loss of renal function\n- Chronic kidney disease, declining renal function, usually with an inexorable rise in creatinine.\n- Hematuria, blood in the urine\n- Proteinuria, the loss of protein especially albumin in the urine\n- Kidney stones, usually only recurrent stone formers.\n- Chronic or recurrent urinary tract infections\n- Hypertension that has failed to respond to multiple forms of anti-hypertensive medication or could have a secondary cause\n- Electrolyte disorders or acid/base imbalance\nUrologists are surgical specialists of the urinary tract (see urology). They are involved in renal diseases that might be amenable to surgery:\n- Diseases of the Bladder and prostate such as malignancy, stones, or obstruction of the urinary tract.\nAs with the rest of medicine, important clues as to the cause of any symptom are gained in the history and physical examination.\nLaboratory tests are almost always aimed at: urea, creatinine, electrolytes, and urinalysis, which is frequently the key test in suggesting a diagnosis.\nMore specialized tests can be ordered to discover or link certain systemic diseases to kidney failure such as hepatitis b or hepatitis c, lupus serologies, paraproteinemias such as amyloidosis or multiple myeloma or various other systemic diseases that lead to kidney failure. Collection of a 24-hour sample of urine can give valuable information on the filtering capacity of the kidney and the amount of protein loss in some forms of kidney disease. However, 24-hour urine samples have recently, in the setting of chronic renal disease, been replaced by spot urine ratio of protein and creatinine.\nOther tests often performed by nephrologists are:\n- Renal biopsy, to obtain a ”tissue diagnosis” of a disorder when the exact nature or stage remains uncertain.;\n- Ultrasound scanning of the urinary tract and occasionally examining the renal blood vessels;\n- CT scanning when mass lesions are suspected or to help diagnosis nephrolithiasis;\n- Scintigraphy (nuclear medicine) for accurate measurement of renal function (rarely done), and MAG3 scans for diagnosis of renal artery disease or ‘split function’ of each kidney;\n- Angiography or Magnetic resonance imaging angiography when the blood vessels might be affected\nMany people may be in the early stages of kidney disease and not have any indication something is wrong with their kidneys. There are certain symptoms, however, that could be a sign you have kidney failure . When kidney failure is detected in the early stages, there are steps you can take to help slow the progression of kidney disease and improve your quality of life.\nBelow are lists of kidney failure symptoms that are grouped in categories based on a typical cause. If you have any of these symptoms, you should make an appointment with your doctor as soon as possible and ask that your kidneys be checked.\nKidney failure symptoms from buildup of wastes in the body\n- A metallic taste in the mouth or ammonia breath\n- Protein aversion (no longer wanting to eat meat)\n- Nausea and vomiting\n- Difficulty concentrating\n- Loss of appetite\n- Itchiness (pruritis)\nKidney failure symptoms from buildup of fluid in the body\n- Swelling in the face, feet or hands\n- Shortness of breath (from fluid in the lungs)\nKidney failure symptoms from damage to the kidneys\n- Making more or less urine than usual\n- Blood in the urine (typically only seen through a microscope)\n- Urine that is foamy or bubbly (may be seen when protein is in the urine)\nKidney failure symptoms from anemia\n- Shortness of breath\n- Mental confusion\n- Feeling cold all the time\n- Desire to chew ice, clay or laundry starch (called pica)\nTo determine if the symptoms you have are because of kidney failure, your doctor will perform specific tests:\n- Urinalysis – An examination of a sample of your urine to check for protein, blood and white blood cells in the urine\n- Blood tests – Particularly a test for creatinine and BUN, waste products that healthy kidneys remove from the bloodstream.\nRenal failure or kidney failure (formerly called renal insufficiency or chronic renal insufficiency) is a situation in which the kidneys fail to function adequately.\nThere are two forms: acute (acute kidney injury) and chronic (chronic kidney disease); either form may be due to a large number of other medical problems.\nBiochemically, it is typically detected by an elevated serum creatinine. In the science of physiology, renal failure is described as a decrease in the glomerular filtration rate.\nWhen the kidneys malfunction, problems frequently encountered are abnormal fluid levels in the body, deranged acid levels, abnormal levels of potassium, calcium, phosphate, hematuria (blood in the urine) and (in the longer term) anemia.\nLong-term kidney problems have significant repercussions on other diseases, such as cardiovascular disease.\nCall & schedule an appointment\nWe’re dedicated to improving the quality of life for our patients with renal disease.Contact Us","High Blood Pressure\nCall for appointment:410-328-7260 410-328-7260\nHigh blood pressure, or hypertension, is a common condition in which the pressure of your blood flow against the artery walls becomes too high. The high pressure can eventually cause heart disease.\nPulmonary hypertension is a specific type of high blood pressure, where there is increased pressure in the pulmonary arteries. Learn more about pulmonary hypertension.\nThe heart specialists at the University of Maryland Heart and Vascular Center provide the full spectrum of care for patients with high blood pressure.\nYou can receive all the care you need at our center, from screenings to diagnostic exams to treatment and follow up.\nWe monitor you closely to determine if your treatment is working well or if we need to adjust. Our team offers all types of treatment, from medication therapies to surgery.\nHigh Blood Pressure Symptoms\nMany times, you may not experience any symptoms of high blood pressure. You should have regular blood pressure screenings starting at age 18, so physicians can detect any problems in their early stages. The earlier we diagnose a problem, the more successful treatments can be. When high blood pressure reaches an advanced stage, you may experience:\n- Dizzy spells\n- More nosebleeds than normal\nThere are many risk factors for high blood pressure. Some you cannot change, such as family history or age. However, some risk factors are within your control, such as diet and exercise. Talk to your doctor about taking steps to reduce your risk factors.\nRisk factors include:\n- Age -the risk increases as you age\n- Race - high blood pressure is more common among African-Americans\n- Family history of high blood pressure\n- Being overweight\n- Lack of exercise\n- Using tobacco\n- Too much salt and too little potassium and vitamin D in your diet\n- Drinking too much alcohol\n- High stress levels\n- Chronic conditions, such as kidney disease and sleep apnea\nLearn more about heart disease prevention.\nHigh Blood Pressure Diagnosis\nDiagnosing high pressure requires a simple, painless procedure using an arm cuff. The cuff measures the pressure in your arteries when your heart beats and the pressure between beats. If your blood pressure is high, we will review your medical history and conduct a physical examination. We may also recommend additional tests including:\n- Blood tests, including a cholesterol test\nLearn more about cardiac diagnosis.\nHigh Blood Pressure Treatment\nOften, lifestyle changes can dramatically improve your blood pressure. These include:\n- Eating a healthy diet with less salt\n- Exercising regularly\n- Maintaining a healthy weight\n- Quitting smoking\nWe may also recommend:\n- Medication to lower your blood pressure\n- Pulmonary thromboendarterectomy (PTE), a specialized procedure to treat pulmonary hypertension, a specific type of high blood pressure. Learn more about pulmonary thromboendarterectomy.\n- Aortic disease treatment: High blood pressure can lead to aortic complications, such as aortic aneurysm or aortic dissection. We have one of the top teams in the region with the experience and capability to treat aortic problems and hypertension together. Learn more about aortic disease, which is treated at our Center for Aortic Disease."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:7fd94002-61eb-4250-ac73-31b1b70aa3fe>","<urn:uuid:ba48b483-131b-4814-8f40-afca4686d174>"],"error":null}
{"question":"What are the key differences in habitat preferences and depth ranges between flasher wrasses and stoplight parrotfish in reef environments?","answer":"Both species inhabit reef environments but with distinct preferences. Flasher wrasses, particularly species like the filamented flasher wrasse, primarily inhabit rubble zones in passages and outer reef slopes, forming large shoals most commonly at depths of 70 feet, though smaller groups may be found as shallow as 30 feet. The Carpenter's flasher wrasse specifically prefers the base of steep outer reef slopes above rubble zones or coral in waters 70 feet or deeper. In comparison, stoplight parrotfish are found in more varied reef environments, living at depths of 9.8-164 ft, with adults preferring reef bases or slopes in shallow waters. They are particularly dependent on specific coral types like staghorn coral, boulder star coral, and elkhorn coral for both shelter and food. Additionally, while adult stoplight parrotfish prefer offshore coral reefs due to reduced fishing pressure, their juveniles can also be found in seagrass beds.","context":["Genus Paracheilinus - Flasher Wrasses\nFlashy Fish for Your Reef Tank\n|The Bell’s Flasher Wrasse (P. bellae) is a deep water fish from the Marshall Islands and Palau, which is not frequently seen in the hobby. Illustration by Karen Talbot\nThere are 14 described species of wrasses in the genus Paracheilinus, more commonly known as the “flasher wrasses.” Indeed, these are flashy fishes, and they also make great reef aquarium fishes.\nWhile flashing may have dubious (if not outright disturbing connotations for humans), flashing is a natural and quite desirable behavior demonstrated by some marine fishes. Fishes are said to be flashing when they dive toward an object or into the substrate and then quickly flash back. They may do this for two main reasons. First, they may be attempting to dislodge a parasite attached to their flesh by rubbing against live rock, an aquarium decoration or the substrate itself. Second, and as is the case with flasher wrasses, they may be attempting to impress females by quickly emerging from the reefscape, displaying their flashy coloration and showy finnage and then diving back into the live rock or coral. When a male flasher wrasse is kept with two or more female wrasses of the same species, the aquarist is in for quite a show.\nBefore discussing species specifics, it’s worth taking a look at wrasses as a group. All wrasses are from the Family Labridae (from the Greek “labrum” or “lip”). This is one of the larger families of reef fishes, and, as such, there are many variations in behavior, diet, husbandry, and aquarium suitability. Most wrasses are small (as small as two inches), but a few grow to more than six feet in length. They all have protractile mouths, cycloid scales and a lateral line that may either be continuous or interrupted. All are marine fishes, but there are both tropical and temperate species. Despite this variety, it is not infrequent to see wrasses offered by retailers of marine livestock broken down into two somewhat arbitrary categories—reef compatible and not reef compatible. The flasher wrasses are all considered reef compatible fishes.\nReef Compatible Flasher Wrasses\n|The McCosker’s falsher wrasse (P. mccoskeri) replaces the Carpenter’s flasher wrasse in the Indian Ocean. Illustration by Karen Talbot\nFlasher wrasses are zooplankton feeders (like the fairy wrasses of the genus Cirrhilabrus), and they are amongst the best wrasses for a reef aquarium. They generally stay small, are quite hardy and have generally peaceful dispositions. The males are known for their bright colors, gorgeous finnage and flashing behavior. A single male should be kept with two or more females to form a harem.\nDespite their flashy appearance, these are generally peaceful fishes that need to be housed with peaceful tankmates. Two of the most popular flasher wrasses are the filamented flasher wrasse (P. filamentosus) and the Carpenter’s flasher wrasse (P. carpenter). Other popular, although not as commonly seen, species include the McCoskeri flasher wrasse (P. mccoskeri) and (P. octotaenia).\nFilamented Flasher Wrasse (P. filamentosus)\nThis flasher wrasse (to just shy of six inches), sometimes called the filamentous wrasse, the filament-fin wrasse, or the filamentous wrasse, is indigenous to the Indo-Pacific, where it primarily inhabits rubble zones in passages and outer reef slopes. The filamented flasher wrasse forms large shoals most commonly at depths of 70 feet, although small shoals may also be observed at depths of thirty feet or less. There is some geographical variation in the male’s colors based on the presence of similar species in the same general vicinity. Regardless, the male is a very attractive fish with a crescent-shaped (lunate) caudal fin and greatly prolonged dorsal rays. Both males and females possess four or five narrow red to blue stripes, which alternate in length. Some females (depending on geographical location) also have elongate dorsal rays, although they are much shorter than the male’s in all cases. Expect male filamented flasher wrasses to display their colors and finnage to other males and available females.\nCarpenter’s Flasher Wrasse (P. carpenter)\n|The Carpenter’s Flasher Wrasse (P. carpenter) is one of the smaller flasher wrasses, growing to about three inches. Illustration by Karen Talbot\nThe Carpenter’s flasher wrasse, sometimes called the pink flasher or the redfin flasher, is one of the smaller flasher wrasses seen in the hobby (rarely exceeds three inches). It is indigenous to the Western Pacific from the Philippines north to Taiwan and Iriomotejima and south to northern Bali and Flores. This species is most commonly found near the base of steep outer reef slopes above rubble zones or coral in water 70 feet or deeper. In the Indian Ocean, the Carpenter’s flasher wrasse is replaced by the McCosker’s flasher wrasse (P. mccoskeri). Male carpenter’s flasher wrasses are usually redish orange to yellow with a yellow to white underside. The dorsal rays are prolonged, and the fish’s color deepens during courtship. Males are slightly larger than females, which are generally paler in color and almost entirely white ventrally.\nIn terms of husbandry, the filamented flasher wrasse and the carpenter’s flasher wrasse (and McCoskeri flasher wrasse, for that matter) are very similar. They should be placed in an aquarium of at least 30 gallons (larger if you intend to keep a group) that has plenty of live rock. If you are going to keep a small group (which is recommended), add the females first; otherwise add them all at the same time. Most wrasses appreciate a sandy substrate.\nAlthough shy at first, both species should readily accept a captive diet of varied foods including meaty bits of marine flesh such as raw table shrimp, squid, clam, and mussel. Supplement this with some type of herbivorous food such as a flake food formulated for herbivores or seaweed strips like Sea Veggies or nori. Nearly all will readily take commercially prepared pellet food and frozen food. Having a refugium be part of the filtration on a flasher wrasse tank is an excellent idea, as their metabolism is quite high, and a mature refugium will provide a constant food supply. Otherwise, plan to feed your flasher wrasses a little bit, often.\nHusbandry: Reproduction & Flashing\n“One of the biggest questions we get about flasher wrasses is will my male flasher wrasse flash?” says Mark Martin, director of marine ornamental research at Blue Zoo Aquatics. “Flasher wrasse males will flash—or become what some call ‘supermales’—in the presence of females OR other males of similar species. Keeping males of similar species together, such as a male Carpenter’s and a male McCoskeri, is actually a trick that we recommend for both flasher and fairy wrasses.”\nMartin’s advice is particularly useful for species where it is difficult to acquire females. “Often time the females are not collected,” says Martin. “If you have one male in a tank by itself, it will eventually lose its color. So, we will recommend people buy another male so that they keep each other brightly colored.” Do be aware that these fishes do change sex (from female to male) based on social hierarchy. In a group of females, the dominant individual will most likely become a male.\nFlasher wrasses from the genus Paracheilinus generally-speaking make excellent tropical marine aquarium fishes. They are almost as alluring as anthias but don’t have the same dietary needs; they are as pretty as parrotfishes but remain aquarium-sized; and they are as dynamic as shoaling damsels but without the aggression. Given the proper habitat and care, it’s hard to ask for more in a relatively hardy reef fish.\nPublished 17 June 2008. © Blue Zoo Aquatics","Stoplight parrotfish (scientific name, Sparisoma viride) is a fish found in the western Atlantic ocean's tropical clear waters. It ranges from Bermuda to Brazil, including Florida, the Caribbean Sea, and the Gulf of Mexico. The favored habitat of the stoplight parrotfish is the coral reef. It relies on the corals like the staghorn coral, boulder star coral, and elkhorn coral for shelter and food. It is often seen grazing among the algal coral reef. The most novel feature of the stoplight parrotfish is its sexual dichromatism. The female fish can change their sex into males to aid low population densities. The males who stay males are called primary males and the female fish who change into males are known as secondary males. Primary males and females remain a reddish-brown color whereas the secondary males turn into a beautiful emerald green color. The stoplight parrotfish has predators like jacks, snappers, and moray eels. It is also a fairly popular eating fish. As per its IUCN status, the stoplight parrotfish is a species of Least Concern.\nDead and live coral, detritus, branched corals, elkhorn corals, boulder star corals, finger corals\nWhat do they eat?\nAverage litter size?\nHow much do they weigh?\nUp to 3.5 lb (1.6 kg)\nHow long are they?\n10-23.6 in (25.4-60 cm)\nHow tall are they?\nWhat do they look like?\nReddish-brown, pale red, black, white, gray, green, orange, yellow\nWhat are their main threats?\nHumans, jacks, snappers, moray eels, bar jacks, northern red snappers, dog snappers\nWhat is their conservation status?\nWhere you'll find them\nCoral reefs, seagrass beds, clear waters\nTropical western Atlantic Ocean, Brazil to Bermuda, Florida, Caribbean Sea, Gulf of Mexico\nStoplight Parrotfish Interesting Facts\nWhat type of animal is a stoplight parrotfish?\nThe stoplight parrotfish (Sparisoma viride) is a fish.\nWhat class of animal does a stoplight parrotfish belong to?\nThe stoplight parrotfish (Sparisoma viride) belongs to the Actinopterygii (ray-finned fish) class of animals.\nHow many stoplight parrotfish are there in the world?\nIt is unclear how many stoplight parrotfishes are there in the world since these reef fish are very abundant within their habitat range.\nWhere does a stoplight parrotfish live?\nThe stoplight parrotfish (Sparisoma viride) calls the tropical waters of the western Atlantic ocean their home. These reef fish range from coastal habitats in Brazil to Bermuda and this includes places like Florida, the Caribbean Sea, and the Gulf of Mexico.\nWhat is a stoplight parrotfish's habitat?\nStoplight parrotfish chiefly inhabit packed coral reefs for the protection, shelter, and nutrition they provide. Branched finger corals that are 0.4-0.8 in (1-2 cm) wide are particularly ideal for them. Juveniles of the stoplight parrotfish are also seen in seagrass beds. Adults are more likely to be seen over reefs bases or slopes in shallow waters. Clear waters are preferred by stoplight parrotfish and they live at depths of 9.8-164 ft (3-50 m). The density of the population seen in offshore coral reefs is greater than that in the inshore reefs, mainly because of increased fishing activities near the shore. The various types of corals found in a stoplight parrotfish habitat are staghorn corals, boulder star corals, and elkhorn corals.\nWho do stoplight parrotfish live with?\nStoplight parrotfish mostly live alone but may also be seen in small groups. They are observed getting aggressive with others of their own species.\nHow long does a stoplight parrotfish live?\nThe average lifespan of stoplight parrotfish is seven to nine years. Although, many individuals have been found to live for 15-20 years with the maximum known age of a fish being 30 years. The conservative average of seven to nine years is due to reef degradation and commercial fishing.\nHow do they reproduce?\nStoplight parrotfish reproduce by spawning and laying eggs. They can spawn all throughout the year in reefs in deep waters. There are primary and secondary males. Primary males form a group to mate with a single female whereas secondary males mate with individuals female fish. Secondary males are also known to keep and defend harems of three to seven female fish and they mate with them every day. Sexual maturity is attained by stoplight parrotfish when they are four years old.\nAn astounding feature about stoplight parrotfish is that they exhibit sexual dichromatism. This means that the female fish can change sex and become secondary males. Before undergoing a sex change, the fish reproduce as females. Breeding is most common in the summer months. Eggs are released in deep areas where they are not disturbed by the water current so much. After juveniles hatch, they return to shallow areas of the reef. After the eggs are deposited, not much parental care is displayed by the stoplight parrotfish.\nWhat is their conservation status?\nThe conservation status of the stoplight parrotfish species according to the International Union for Conservation of Nature is Least Concern.\nStoplight Parrotfish Fun Facts\nWhat do stoplight parrotfish look like?\nStoplight parrotfish are known to have beaklike and strong jaws. The fused teeth form these jaws wherein the top teeth encompass the bottom teeth. Stoplight parrotfish also have pharyngeal, plate-like teeth. They have nine soft anal rays, three anal spines, ten soft dorsal rays, and nine dorsal spines.\nThe colors of the stoplight parrotfish vary with sex and age. The young fish have black scales and overall reddish-brown bodies. They also have white spots on their sides in the form of three rows. The caudal fin also has a vertical white bar. Juveniles have a pale red belly. Primary males and adult females keep this reddish-brown color. They are mottled white but do not possess distinct three rows of white spots or the white bar. Also, their scales have gray outlines with the red belly still present.\nSecondary males (ones that were born as female fish but change to males) change colors and become green and have orange bands on their heads. Behind and above the gill openings and at the caudal fin base are yellow spots. At the end of the red-brown caudal fin, there is an orange-yellow spot in the shape of a sickle.\nHow cute are they?\nStoplight parrotfish are very beautiful fish. They have gorgeous red and emerald green colors with large scales. Also, they have whimsical, funny expressions because of their fused teeth.\nHow do they communicate?\nLike most other species of fish, stoplight parrotfish have a lateral line that can detect water vibrations. They also have an inner ear that is well developed and their two nares in the head have olfactory receptors for smell detection.\nHow big is a stoplight parrotfish?\nStoplight parrotfish are 10-23.6 in (25.4-60 cm) long which makes them four to eight times smaller than nurse sharks. The stoplight parrotfish size is also 6-16 times bigger than neon tetras.\nHow fast can a stoplight parrotfish swim?\nBeing parrotfish, the stoplight parrotfish species can probably swim at speeds of 1.6-2.1 mph (2.6-3.4 kph). They can also go into speedy, quick bursts using their caudal fins, and they use the pectoral fins to move in a vertical direction.\nHow much does a stoplight parrotfish weigh?\nA stoplight parrotfish can weigh up to 3.5 lb (1.6 kg).\nWhat are the male and female names of the species?\nMales and females of the stoplight parrotfish species do not have specific names. It is important to make the distinction between primary and secondary males in this species.\nWhat would you call a baby stoplight parrotfish?\nA baby stoplight parrotfish would be called a fry or a juvenile.\nWhat do they eat?\nStoplight parrotfish eat dead and live corals, detritus, branched coral, elkhorn coral, boulder star coral, and finger coral. They are more likely to feed on dead corals than live ones.\nThey themselves are known to fall prey to humans, jacks, snappers, moray eels, bar jacks, northern red snappers, and dog snappers which is the major danger they face.\nAre they aggressive?\nStoplight parrotfish are only aggressive with others of their own species. They are not a danger to humans in the winter since they feed on corals mostly.\nSpotlight parrotfish may be inadvertently dangerous to humans since it is a common eating fish. They may eat algae that contain toxins. When these contaminated fish are eaten by humans, they may get ciguatera poisoning. Exposure to this is not very fatal, but diarrhea, nausea, and vomiting are involved. There may also be some cardiovascular problems like bradycardia and hypotension as well as neurological issues like muscle and joint pain, fatigue, and tingling and numbness in the extremities.\nWould they make a good pet?\nStoplight parrotfish are not extremely popular as pets because of the specific care they need. Since they are so vibrantly colored, they are put on display by some public aquariums and some personal ones as well. The stoplight parrotfish care has to be on an expert level. They are peaceful and mild-mannered but are not reef safe and need plenty of roaming space in a tank size of at least 1,000 gal (4,546 L). They can be given a herbivorous diet but they are very active feeders. The tank should also have live rocks for shelter and grazing. They also accept invertebrates and smaller fish as food.\nAlso, since they require more space and are naturally wild and free-roaming, they do not do as well in captivity.\nDid you know...\nStoplight parrotfish are huge contributors to the coral reef community as they feed on corals and regulate them. This is important for the human consumption of other reef fish and organisms.\nThe family Scaridae consists of about 90 parrotfish species, mostly found in the Indo-Pacific.\nIt is possible that yellowtail snappers eat stoplight parrotfish since they both share the geographic range and snappers are known predators of stoplight parrotfish.\nNaming the stoplight parrotfish\nThe 'stoplight' in the name comes from the red and green coloring of the fish, as in the color of the lights in a traffic signal. The terminal phase or secondary males also have a yellow spot near one of their pectoral fins. The 'parrotfish' comes from their fused teeth which resemble the beak of a parrot.\nAre stoplight parrotfish grazers?\nYes, stoplight parrotfish are grazers, habitually feeding on algae and dead corals. They have a high grazing rate.\nAt Kidadl we pride ourselves on offering families original ideas to make the most of time spent together at home or out and about, wherever you are in the world. We strive to recommend the very best things that are suggested by our community and are things we would do ourselves - our aim is to be the trusted friend to parents.\nWe try our very best, but cannot guarantee perfection. We will always aim to give you accurate information at the date of publication - however, information does change, so it’s important you do your own research, double-check and make the decision that is right for your family.\nKidadl provides inspiration to entertain and educate your children. We recognise that not all activities and ideas are appropriate and suitable for all children and families or in all circumstances. Our recommended activities are based on age but these are a guide. We recommend that these ideas are used as inspiration, that ideas are undertaken with appropriate adult supervision, and that each adult uses their own discretion and knowledge of their children to consider the safety and suitability.\nKidadl cannot accept liability for the execution of these ideas, and parental supervision is advised at all times, as safety is paramount. Anyone using the information provided by Kidadl does so at their own risk and we can not accept liability if things go wrong.\nSponsorship & Advertising Policy\nKidadl is independent and to make our service free to you the reader we are supported by advertising.\nWe hope you love our recommendations for products and services! What we suggest is selected independently by the Kidadl team. If you purchase using the buy now button we may earn a small commission. This does not influence our choices. Please note: prices are correct and items are available at the time the article was published.\nKidadl has a number of affiliate partners that we work with including Amazon. Please note that Kidadl is a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for sites to earn advertising fees by advertising and linking to amazon.\nWe also link to other websites, but are not responsible for their content."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:07f303f2-c94e-4e43-b418-11f9bdb7f32f>","<urn:uuid:f91d04af-52bd-4997-9e93-243dfa681430>"],"error":null}
{"question":"What determines the feasibility of Arctic shipping routes, and what safety concerns exist?","answer":"The feasibility of Arctic shipping routes is determined by multiple factors, including economic conditions and environmental hazards. Economic factors include bunker fuel prices, commodity values, and transportation costs, with low fuel prices currently making Arctic shortcuts less attractive. The availability of ice-breaker escorts and vessel size restrictions also impact feasibility. Regarding safety concerns, the presence of toxic substances in the troposphere, including ozone and mercury depletion events caused by bromine explosions, poses risks. These chemical processes are affected by changing sea ice conditions and can impact both people and wildlife in the Arctic region. The interaction between surface conditions and atmospheric chemistry creates additional challenges for safe navigation and environmental protection.","context":["Implications of Arctic Sea Ice Reduction on Tropospheric Chemistry\nThe objective of this interdisciplinary research, anchored by the BRomine, Ozone, and Mercury EXperiment (BROMEX) field study (Figure 1), is to investigate impacts of Arctic sea ice reduction on bromine, ozone, and mercury chemical processes, transport, and distribution, from sea ice surfaces and near leads on the Arctic Ocean, and atmospheric transport of these chemicals to high mountains on land.\nKey science questions still remain to be answered in order to understand the impact of the recent drastic reduction of Arctic sea ice, which profoundly changes the Arctic environment, on the physical and chemical processes involved in bromine explosions leading to depletion of tropospheric ozone (O3) and gaseous elementary mercury (GEM), specifically:\n- Will the Arctic sea ice reduction, which has shifted the state of the Arctic sea ice cover to the dominant domain of seasonal ice, continue the declining trend?\n- How is the chemical process for bromine explosion initiated from the surface with different sea ice classes (seasonal and perennial ice), frost flowers, snow cover, and open ocean that are affected by the Arctic sea ice change?\n- How is bromine recycled and distributed in the tropospheric vertical column and how are bromine explosion events propagated and terminated? What are the relative roles of vertical mixing/dilution versus depositional loss of bromine products to a relatively non-saline surface?\n- How are bromine and thus O3, GEM, and reactive gaseous mercury (RGM) distributed in time (seasonal, interannual, and decadal) and in space (on ice/ocean, near shore, inland, and around mountain complex) and what is their relationship to oceanic and atmospheric forcing in the changing Arctic environment?\n- If the Arctic sea ice reduction trend continues, how would the physical and chemical conditions above the surface change, and would the frequency and severity of bromine explosions and O3/GEM depletions increase or decrease?\nAnswers to the above key questions provide fundamental physical insights into the halogen chemical processes, which govern bromine, ozone, and mercury in the Arctic environment that is impacted by a changing Arctic sea ice surface and related changes in climate. Such understanding is critical to correctly identify the cause and consequence in Arctic O3/GEM depletion in response to Arctic change, and enables a physical-based assessment of the Arctic environmental vulnerability to geochemical change. Scientifically, a fundamental understanding is essential to enable the research community to develop reliable Earth System and Arctic System Models that connect the physical changes at the surface to the chemical compositional changes in the atmosphere, with attendant feedbacks, so that we can address questions about the future state of the Arctic system. In a practical view, tropospheric (the air the we breath) ozone and mercury are toxic to people and wildlife. Understanding the chemical sources processes, and transport will enable a better quantification of the impacts.\nOur approach will use data from multiple satellites including MODIS (NASA), AMSR-E (NASA), QuikSCAT (NASA), Envisat ASAR (ESA), GOME-2 (ESA), SCIAMACHY (ESA), RADARSAT SAR (CSA), and TerraSAR-X and TanDEM-X (Germany) together with past and present measurements from multiple field campaigns such as the IPY OASIS, INCATPA, CFL, SALT, and other present and future field experiments, to investigate how changing sea ice conditions can change the rates and nature of chemical processes involving these species. The approach will include a new unique field experiment to identify the role of different sea ice surface types in the photochemical processes, together with airborne measurements across various Arctic land-seascapes. We plan to conduct measurements from both sides of the Barrow lead in the spring of 2012, from the surface (using autonomous platforms) and from aircraft, making use of trajectory analysis and satellite data, along with the chemical information, to study the relationship between surface types and the overlying atmospheric composition and chemistry. We will use the Drift-age Model to characterize sea ice dynamics and distribution. Furthermore, atmospheric dynamics will be included in this research using model analyses such as the National Centers for Environment Prediction and National Center for Atmospheric Research reanalysis and Rising Air Parcel (RAP) trajectories.\nBased on new findings, we assess the capability for chemical weather forecasting in the Arctic, specifically aimed at short-term prediction of bromine explosions and O3/GEM depletion. Thus, this research builds on and expands NASA multi-satellite capabilities leading to the first assessment and potential development of new predictive modeling for chemical weather forecast. Thus, it lends support to Decadal-Survey satellite missions related to ozone and ice (e.g., CLARREO, GPSRO, ASCENDS, GACM, GEO-SCAPE, ACE, XOVWM, DESDynI, ICESAT-II, etc.).\n- Son V. Nghiem, NASA/JPL, Principal Investigator\n- Matthew Sturm, Cold Regions Research and Engineering Laboratory\n- Thomas Douglas, Cold Regions Research and Engineering Laboratory\n- Don Perovich, Cold Regions Research and Engineering Laboratory\n- Paul Shepson, Purdue University\n- William Simpson, University of Alaska\n- Ignatius Rigor, University of Washington\n- David G. Barber, University of Manitoba, Canada\n- Jan Bottenheim, Environment Canada\n- John P. Burrows, Oxfordshire, United Kingdom; and University of Bremen, Germany\n- Pablo Clemente-Colón, National Ice Center, U.S.\n- Hajo Eicken, University of Alaska\n- CDR Carl Hager, CDR Joe Smith, LCDR John Woods, U.S. Naval Academy\n- Dorothy K. Hall, NASA Goddard Space Flight Center, U.S.\n- Lars Kaleschke, University of Hamburg, Germany\n- Jeremy Krieger, University of Alaska, Fairbanks\n- Thorsten Markus, NASA Goddard Space Flight Center, U.S.\n- Andreas Richter, University of Bremen, Germany\n- Ralf Staebler, Environment Canada\n- Alexandra Steffen, Environment Canada\nFor more information, contact Son V. Nghiem, Jet Propulsion Laboratory","BODO, Norway – Economic factors, such as reduced bunker fuel prices and slowing demand for commodities, are the primary reasons for reduced shipping traffic along Russia’s Northern Sea Route, according to research presented by Arctic shipping experts at Bodo’s High North Dialogue conference. Higher amounts of summer sea ice during 2014 and 2015, on the other hand, play only a minor role. What does this mean for the future prospects of Arctic shipping?\nInterest in the commercial use of Arctic shipping routes first emerged following the rapid decline in summer sea ice in 2007. If the Arctic Ocean were to become ice-free during the summer months in the near future, the thinking went, it could serve as a shortcut for vessels travelling between Europe and Asia. The Northern Sea Route (NSR), as well as its less popular Canadian cousin the Northwest Passage (NWP), can cut the distance on popular routes, such as Rotterdam (the Netherlands) to Shanghai (China), by up to 35 percent potentially offering significant time and fuel cost savings.\nShipping traffic on the NSR steadily increased since the first non-Russian-flagged voyages in 2009 and reached 71 transits carrying 1.35 million tons of cargo in 2013. However, since then shipping volumes on the route have declined sharply, falling to a low of just 18 transits and 40,000 tons in 2015. Have the prospects of Arctic shipping been oversold? And what explains the lack of interest in utilizing the NSR since 2013?\nArctic Shipping Sensitive to Global Economy\nFelix Tschudi, chairman and owner of the Tschudi Group, a shipping and investment company based in Oslo, identifies the fallen bunker fuel prices as a key reason for the decline in Arctic shipping. As fuel expenditures have decreased sharply, the cost of transportation has become less significant for shipping operators and with that shortcuts have become less economically attractive.\n“The economic calculations have changed since 2013 and the benefits of the NSR as a shortcut have largely been lost,” said Tschudi. “The value of the time saved is much less compared to 2013.”\nIn addition, commodity prices of raw materials have fallen sharply, in part due to declining demand, especially in Asia. As a result the value-to-weight ratio of transported goods has decreased, placing larger emphasis on economies of scale. Simply put, when prices are low it becomes more important to ship commodities on larger vessels because it reduces the relative cost of transportation. Ice-hardened vessels capable of operating on the NSR are much smaller and regular vessels requiring icebreaker escorts have to abide by size and draft restrictions.\n“At the current price levels, commodities are no longer able to carry the transportation costs on the NSR,” Tschudi said.\nReduced Availability of Icebreakers\nAn additional factor, according to Tschudi, is the reduced availability of icebreaker escorts from Rosatomflot, the world’s only company maintaining a fleet of nuclear-powered icebreakers. While Atomflot was keen to provide icebreaker escort services in previous years, the ongoing and growing construction of the Yamal LNG gas project and the Port of Sabetta have tied up capacity, reducing the company’s ability to escort and assist commercial shipping operations.\nIce Extent Variability Minor Factor\nContrary to popular belief, the extent of summer sea ice in the Arctic Ocean only plays a minor role in determining the popularity of the region’s shipping routes. Laurence Smith, professor and chair of the geography department at the University of California Los Angeles, emphasized that ice-extent variations over the past few years, together with projected variability in the future, make up one of many factors. “Ice-extent variability under different climate forcings factors little into the overall economic equation of Arctic shipping,” Smith said, during a talk at the university in which he presented research on the impact of climate model variability on future Arctic shipping.\nSmith and his coauthor Scott Stephenson, professor at the University of Connecticut, used data from dozens of existing climate models and “translated” it with the use of a geographic information system (GIS) to devise an Arctic Transportation Accessibility Model (ATAM).\nTheir model shows a simulated future of sea-ice extent based on climate models and then calculates the fastest routes through the Arctic Ocean. Based on this research, the NSR is highly likely to remain the preferred Arctic shipping route, with only some outlier models predicting the NWP as a significant transport route.\nIn the second part of the 21st century, a more direct transpolar sea route outside the Russian Exclusive Economic Zone closer to the North Pole may also become feasible.\nArctic Shipping Remains a Complex Equation\nThe economic complexities described by Tschudi and Smith surrounding the viability of Arctic shipping were also the subject of research published by the Copenhagen Business School earlier this year. The study identified more than a dozen variables, ranging from ship hull design and fuel prices to cargo types and routes served, as key determinants of cost on the NSR. It concluded that summer ice extent and length of navigability on the NSR are just one of many variables.\n“The fall in oil prices has lowered the incentive of using the Arctic routes despite the reduced sailing distances. Low oil prices diminish the large distance benefits on the Northern Sea Route as fuel costs decline throughout the shipping industry,” said Peter Gronsedt, lead author of the study and researcher at CBS.\nWhile forecasts of a rapid increase of traffic on the NSR may have proven overly optimistic, the current slump is merely temporary, said Tschudi. Transit traffic may be down but a lot of internal and destination traffic is still going on, delivering infrastructure supplies into the Arctic and carrying hydrocarbon resources out of it. Thus, Tschudi said: “Arctic shipping is not dead, but it’s been put on ice temporarily.”\nThe views expressed in this article belong to the author and do not necessarily reflect the editorial policy of Arctic Deeply."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:4e273eb3-6583-4bb0-9d53-71a63f40ae99>","<urn:uuid:862e60cc-295d-432e-ac17-efdf00bf00ae>"],"error":null}
{"question":"What are the benefits of compliance with data protection standards, and what are the consequences of non-compliance?","answer":"Benefits of compliance include enhanced data security measures to reduce breaches and fraud, improved operational efficiency through optimized security practices, and increased customer trust. PCI DSS compliance specifically enables swift payment processing with major card networks and provides a competitive advantage. On the consequences side, non-compliance can result in severe penalties from both frameworks. Under GDPR, organizations face fines up to 20 million Euros or 4% of annual global turnover, while PCI DSS violations can lead to higher transaction costs, merchant account closure, and increased scrutiny from payment processors. Additionally, both standards' violations can result in reputational damage, legal actions from affected consumers, and mandatory security remediation procedures.","context":["The General Data Protection Regulation (GDPR)\nis a major overhaul of the EU data protection law. It upgrades the previous data protection directive of 1995 and is more suited to present day digital challenges, aiming to bring a uniformity to data\nprotection. The GDPR will have a big impact on the way you collect, store, process, and manage personal data of EU citizens, whether they are your clients, partners or employees.\nSince May 25th 2018, any organisation which processes personal data on EU citizens is required to have adequate measures in place and conform to a number of regulations or face risking hefty penalties.\nCreated to strengthen and unify data protection for individuals across the world, the GDPR aims to return control to EU citizens over their personal data and ease the flow of PII (personally identifiable information) globally.\nTable of contents for this article:\nIf you buy a third-party product or service from this website, HotelMinder may earn a commission. Our editorial team is not influenced by our affiliate partnerships.\nDoes it apply to my hotel business located outside the EU?\nGDPR applies to data collected and stored on EU citizens, wherever they are in the world. It will have an impact on the entire, global hospitality sector.\nThe big impact on the hospitality industry\nThe hotel industry is particularly vulnerable to data threats, due to the multiple points of payment, email and online booking systems and documents containing card data.\nA very high volume of payment card transactions occur daily and guest information can often be stored long term.\nTypically, a hotel database will hold guest names, addresses, date of birth, credit card details, passport details, and so on.\nThis is a lot of sensitive data that could be used fraudulently. Couple this with information which is received from multiple sources, such as point of sale systems, third-party bookings, emails, own website enquiries and walk ins, hoteliers are an easy target for cyber criminals.\nGDPR is a game changer, because the hotel industry now needs to identity where data is kept and ensure that it is protected.\nWhat if I am not compliant?\nIf an EU citizen files a complaint, the hotel may face hefty fines.\nThe maximum fine is set to 20 million Euros, or 4% of the annual global turnover (whichever is the greater).\nIn the event of a breach, the European Regulator must be notified within 72 hours where this is likely to result in a risk to the rights and freedoms of EU data subjects.\nHow does it apply to your hotel marketing strategy\nBefore May 25th, 2018, the rules on collecting potential guest data were pretty flexible.\nHoteliers could market to potential customers through ‘opt-ins’ and target the user with multiple newsletters and email marketing campaigns.\nA general consent request can result in the user being signed up to multiple subscriber lists.\nFast forward now to GDPR’s ‘explicit consent’ rule, where hotels must explain to the potential customer what data they are capturing (the nature of the data),\nexplain to the customer why they are capturing that data (the purpose of the data) and explain to the customer who is requesting that data and who else will have access to this data.\nThe idea is that the person you’re seeking to collect data from, understands with clarity what data you want and what you’re going to do with it.\nIt’s only then that they can make the decision to consent.\nNow here’s the tricky part; under GDPR this consent only applies to the specific purpose which you have declared.\nGone are the days when you could take that personal data and use it to market across multiple campaigns.\nYou are now required to ask for consent for each individual marketing campaign or newsletter.\nIt’s going to require some work.\nA good starting point might be with your own\nIdentify where on the site you request information; it may be a newsletter opt-in or an enquiry form.\nConsider the best possible online, user experience alongside being able to clearly outline your data use policy.\nIt’s not all bad.\nIf you can clearly show that you respect an individual’s personal data, it shows that you care.\nIn the future your marketing campaigns will be dedicated to those who are invested in your brand.\nAn Individual’s Rights and Hotel Response\nIt’s a hotelier’s responsibility to recognise that data belongs to the guest and define a core data protection policy with that in mind.\nHere are some individual rights under the GDPR and what action you can take to ensure compliance:\n- The right to be informed – clearly outline what data you are collecting, why and for how long.\n- The right to access/modify data – give access to personal data immediately, in a readable format, and edit on request.\n- The right to give/withdraw consent – this refers to explicit consent (explained earlier). Offer an option to withdraw consent easily and track how and when you collected the data and consent.\n- The right for data erasure – consider the individual’s rights against public interest when receiving a deletion request and delete where appropriate.\n- The right to transfer data – give the user access to their personal data to transfer on request.\nPCI Compliance and GDPR\nIf you’re already PCI compliant, then this accreditation lays the foundation for GDPR compliance.\nTo be PCI DSS compliant, a hotel must have taken appropriate steps when\n- Ensuring your IT systems are adequate.\n- Encrypting card holder and other sensitive data.\n- Secure systems to prevent data breaches (firewall, anti-virus software, access controls).\n- Security technology investment.\n- Security policy in place and accountability to protect data.\nOften, improved security solutions can result in significant operational efficiencies.\nAnd let’s face it, nobody wants the bad publicity and financial repercussions of a data breach post GDPR.\nFor more practical steps about implementing the right protocols at your hotel, you can read our\nGDPR guide for your Hotel in 10 practical steps.\nAnd if you’d like to get expert help and advice then please\nget in touch\nwith us, or\nsubscribe to our newsletter - we promise not the raid your inbox!","IDC Names Securiti a Worldwide Leader in Data PrivacyView\nPayment Card Industry Data Security Standard Compliance, better known as PCI DSS Compliance, a term which at first glance may seem daunting, is a critical framework that ensures the security of sensitive financial data. In a landscape rife with cyber threats and data breaches, understanding PCI DSS Compliance is paramount for organizations that handle credit card transactions.\nPayment Card Industry Data Security Standard, commonly known as PCI DSS, is a set of security standards and guidelines designed to ensure the secure processing, storage, and transfer of payment card data, including debit and credit card data. The two key objectives of PCI DSS compliance are protecting sensitive cardholder data and minimizing the likelihood of financial fraud and data breaches.\nInstead of being a one-size-fits-all strategy, PCI DSS Compliance is a flexible framework that organizations can customize to meet their unique requirements. PCI DSS is developed and upheld by the Payment Card Industry Security Standards Council (PCI SSC) and applies to all entities that handle credit card data, ranging from small online retailers to multinational organizations.\nPCI DSS certification refers to complying with several specific requirements and standards designed to ensure the secure handling of payment card data. The current version of the PCI DSS is PCI DSS v4.0.\nCybercriminals actively target digital transactions containing credit card data, and PCI DSS attempts to reduce such evolving security risks. These threats include:\nThreat: Unauthorized access to cardholder data while it's being processed, stored, or transferred.\nPCI DSS Requirement: When transmitting cardholder data over open, public networks, ensure data is encrypted.\nThreat: Malicious software with the ability to steal cardholder data and jeopardize system security.\nPCI DSS Requirement: Utilize antivirus software and update it regularly.\nThreat: Attempts made fraudulently to assume the identity of reliable organizations to obtain sensitive data.\nPCI DSS Requirement: Establish policies in place to protect against phishing attempts, such as training and awareness campaigns for employees.\nThreat: Inadequate authentication methods that may lead to unauthorized access.\nPCI DSS Requirement: Use strong authentication methods, such as multi-factor authentication, to protect system access.\nThreat: Weaknesses in network security that can be exploited to gain unauthorized access.\nPCI DSS Requirement: Regularly monitor and test networks and implement security measures like firewalls to protect cardholder data.\nThreat: Inability to promptly detect and respond to security incidents.\nPCI DSS Requirement: Implement robust logging and monitoring systems to track and alert security events.\nTokenization can be used to reduce the risk involved with maintaining actual card data by substituting non-sensitive tokens for sensitive cardholder data.\nFrom the point of interaction, such as a card swipe, until it reaches the payment processor, use P2PE to encrypt card data.\nConduct security audits and risk assessments to identify vulnerabilities and ensure PCI DSS compliance.\nThe PCI DSS security standards are implemented by an alliance of major credit card organizations, including Visa, Mastercard, American Express, JCB, and Discover, to ensure that every organization that accepts credit cards does so in a secure environment. Your organization may be classified into one of four PCI categories based on the annual volume of card transactions you process:\nPCI Level 1: Businesses processing over 6 million transactions per year\nPCI Level 2: Businesses processing 1 million to 6 million transactions per year\nPCI Level 3: Businesses processing 20,000 to 1 million transactions per year\nPCI Level 4: Businesses processing less than 20,000 transactions per year\nOrganizations must go through several phases and activities in the PCI DSS assessment process to ensure PCI DSS compliance. The following essential components are usually included in the process:\nEach system and procedure that handles, transmits, stores, or processes sensitive authentication data (SAD) and cardholder data (CHD) must be identified and recorded. Additionally, the cardholder data environment (CDE) must be determined to accurately assess the scope of PCI DSS compliance.\nGet familiar with the PCI DSS standard's 12 core requirements and accompanying sub-requirements, and recognize the specific security controls and practices that are essential to meet each requirement.\nSAQ types differ according to the processing, storing, and sending of cardholder data methods. Identify the relevant Self-Assessment Questionnaire (SAQ) or, in the case of Level 1 merchants, submit a Report on Compliance (ROC) evaluation.\nExamine your organization’s security controls with PCI DSS requirements to identify any vulnerabilities in the current security framework.\nTo comply with PCI DSS requirements, patch identified gaps by implementing security controls and measures. Develop and implement a remediation strategy to resolve vulnerabilities and enhance security.\nCreate security policies and procedures that align with PCI DSS requirements, document them, and ensure employees receive adequate training.\nEstablish a system for routine security testing and vulnerability assessments, as well as methods for continuous monitoring to identify and resolve security events swiftly.\nConduct the SAQ or ROC assessment in compliance with the specified parameters and relevant laws.\nProvide the acquiring bank and card brands with the completed SAQ or ROC and any necessary supporting documentation. Assure prompt submission and adherence to reporting requirements.\nEstablish and execute plans to identify and resolve any non-compliance concerns and collaborate with the QSA or Internal Security Assessor (ISA) to validate remediation efforts.\nMaintain accurate records of all security assessments, processes, policies, and remediation activities. These records would also come in handy for audit purposes and demonstrating ongoing compliance.\nEstablish procedures for continuous security control testing, monitoring, and evaluation. Additionally, to handle new threats and landscape changes, evaluate and update security measures on a regular basis.\nKeep track of compliance status by communicating with acquiring banks and payment card companies and respond to the credit card companies' requirements for more details or actions.\nReevaluate and validate compliance with PCI DSS requirements to renew the compliance status.\nInstall and maintain network security controls by employing strong firewalls, intrusion detection systems, and encryption methods to prevent data breaches and cyberattacks.\nApply secure configurations to all system components by changing default passwords, eliminating unnecessary software, functionalities, and accounts, and deactivating or uninstalling unnecessary services to reduce the possibility of compromising the system.\nProtect stored account data using encryption, truncation, masking, and hashing. Employ risk-reduction strategies such as avoiding holding account information unless absolutely essential, truncating cardholder data when the entire PAN is not required, and refraining from providing unprotected PANs via end-user messaging platforms like email and instant messaging.\nProtect cardholder data using strong cryptography keys during transmission over open and public networks. This increases the likelihood of data secrecy, integrity, and non-repudiation. Any transmissions of cardholder data through a network that stores, processes, or transmits cardholder data are immediately subject to PCI DSS. Such networks must be evaluated and assessed to comply with the applicable PCI DSS regulations.\nTo protect all systems and networks from malicious software, malicious software or firmware must be identified and eliminated. Examples of malicious software include viruses, worms, Trojans, spyware, ransomware, keyloggers, rootkits, malicious code, scripts, and links.\nDevelop and maintain secure systems and software to prevent security vulnerabilities that can be exploited to gain privileged access to systems. Organizations must routinely update their software components via the necessary software patches to ensure no software intrusion.\nRestrict access to system components and cardholder data by business need-to-know to ensure that only authorized individuals gain access to data. These requirements apply to user accounts and access for employees, contractors, consultants, internal and external vendors, and other third parties.\nTwo fundamental principles of identifying and authenticating users are to establish the identity of an individual or process on a computer system and prove or verify the user associated with the identity is who the user claims to be.\nThe element used to prove or verify the identity is known as the authentication factor. Authentication factors include something you know, such as a password or passphrase; something you have, such as a token device or smart card; or something you are, such as a biometric element.\nRestrict physical access to systems that store, process, or transmit cardholder data since it enables individuals to access and/or remove systems or hardcopies containing cardholder data.\nLog and monitor all access to system components and cardholder data to prevent, identify, or mitigate the effects of a data compromise. Logs are present on every system component and in the Cardholder Data Environment (CDE), enabling full monitoring, notification, and analysis if something goes wrong. Without system activity logs, it is difficult, if not impossible, to identify the cause of a compromise.\nTo ensure that security policies continue to take into account the ever-evolving environment, system components, processes, and customized and custom software should all undergo regular testing.\nThe overall information security policy of the organization establishes the tone for the entire organization and specifies what is expected of the employees. Every employee should understand the sensitivity of cardholder data and the need for protection.\nOrganizations face several obstacles in their quest for PCI DSS compliance, including:\nTo overcome these challenges, organizations must actively engage in strategic planning, demonstrate PCI DSS compliance commitment by implementing required security measures, and utilize PCI DSS compliance to negotiate the complex landscape of credit card security regulations.\nOrganizations that violate PCI DSS requirements may face dire repercussions, including:\nThere could be serious penalties from card companies and regulatory agencies. The fine amount depends on how serious the infraction was and how many cardholder data records were stolen.\nOrganizations that do not comply may be subject to higher transaction costs and extra scrutiny by payment processors and acquiring banks. This could result in processing payments with higher operational costs.\nA non-compliance-related data breach may damage customer trust. Consumers may become less confident in the organization’s ability to protect their personal data, which could harm its reputation and result in lost revenue.\nNon-compliance may initiate legal action, such as a lawsuit from impacted consumers, regulatory authorities, and payment card brands. Settling such lawsuits can drain an organization’s financial resources and dent its reputation.\nThe merchant accounts of organizations that do not comply may be closed by acquiring banks and payment processors. Revenue streams may be impacted if this interferes with the company's capacity to accept credit card payments.\nRegulatory agencies or payment card brands may require certain security remediation procedures. Organizations that don't comply may have to spend additional financial resources on security enhancements.\nIf there is a data breach, the organization can be held liable for the expenses associated with investigating and remediating the incident. This entails conducting legal investigations, informing those impacted, and implementing remedial action plans.\nRegulatory agencies and credit card companies may beef up their monitoring and auditing of non-compliant organizations. This might strain internal resources and interfere with regular corporate operations.\nOrganizations that do not comply with PCI DSS compliance risk missing out on opportunities to work with other organizations that prioritize security since compliance is frequently a requirement for collaboration.\nOrganizations may find it difficult to obtain cybersecurity insurance or may see higher premiums as a result of greater perceived risk if they do not comply with PCI DSS.\nFor non-compliant organizations, regulatory agencies and payment card companies may mandate more frequent and stringent compliance assessments, imposing a continuous cost on the firm.\nThe costs and efficiency of an organization can be negatively impacted by remediation activities and the repercussions from non-compliance, which include legal complexities and customer resentment towards the organization.\nPCI DSS compliance significantly benefits organizations that process credit card transactions. These include:\nOrganizations can implement strong security measures designed to reduce vulnerabilities to safeguard sensitive payment card data, reducing data breaches, fraud, and other security risks.\nIn the event of a data breach, non-compliance with PCI DSS may result in fines and penalties. Businesses can prevent these financial implications by achieving compliance.\nPCI DSS compliance may be required by law in certain regions. Being PCI DSS compliant ensures that the company is in good legal standing, preventing unforeseen legal complexities.\nOptimizing data security practices is frequently necessary to ensure PCI DSS compliance, ultimately resulting in more cost-effective and effective operations.\nMajor card networks like Visa and MasterCard require PCI DSS compliance to process payments, enabling companies to process payments swiftly without interruptions.\nPCI DSS compliance demonstrates a commitment to security, which protects and enhances an organization’s reputation and improves customer trust.\nCompliance with PCI DSS gives your company a competitive edge over competitors who might not be compliant.\nIndustry leaders embrace and mandate merchant compliance as failure to comply with the PCI DSS can lead to security lapses and the loss of sensitive credit card data, which can result in severe penalties and other legal consequences.\nIt is imperative for organizations to determine what type and level of encryption exists in their systems today. With a lack of visibility, it is essential for organizations to embrace automation and gain a holistic view of their data.\nSecuriti Data Command Center can scan, classify and keep encryption types in a data graph that is continuously updated and auditable. That visibility generates a prioritized work list for risk inventories and remediation plans.\nRequest a demo now to learn how Securiti can help improve compliance with PCI DSS v4.0."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:d67c6da4-c3f6-47e7-8264-6d569e8ee0a4>","<urn:uuid:a9acb6e1-37c4-4bad-b932-4578a90edb0e>"],"error":null}
{"question":"How does the process of applying embossing powder differ between resist stamping and traditional rubber stamp embossing, and what are their respective heating techniques?","answer":"In resist stamping, you stamp using Perfect Medium ink around the edge of the card layer, add heat embossing powder over the stamped image, tap off excess powder, and heat emboss to create a glossy finish before applying colored ink around it. In traditional rubber stamp embossing, you first saturate the rubber stamp with embossing ink, stamp onto card stock, quickly shake embossing powder onto the wet ink, pour off excess powder, and then heat it. The heating technique for both involves holding a heat source just above the embossing powder without touching the cardstock, moving it around to melt all sections. The powder typically melts between 200 and 300 degrees Fahrenheit, and you can create different effects by varying how close you hold the heat source.","context":["Stamping Techniques: What Is Resist Stamping?\nLooking for an eye-catching way to breathe life into your stamping projects this year? Resist stamping might be the perfect technique for you! It’s an easy technique to master, and will make you look at your stamp stash in a completely different way. Essentially, the concept behind resist stamping is that the design on your stamp is left blank, whilst the background and all the white spaces between the stamp lines are brought to life with coloured ink! It’s not how stamps are traditionally used, but it’s a great way to add real vibrancy and colour to your stamped cards. We asked Ann-Marie Vaux to create an eye-catching project to perfectly demonstrate how awesome resist stamping can look – and you can read her step-by-step instructions below!\nResist stamping is a really neat technique and looks great, especially when you use a really vibrant coloured ink against the resist!\nYou Will Need:\n- Ranger Ink Set\n- Embossing ink\n- White or clear heat embossing powder\n- Heat Gun\n- Floral stamps\n- Sentiment stamp\n- Clear or white embossing powder\n- 6x6inch blank white card base\n- General Create & Craft gold cardstock\n- Extra white cardstock\n- Die set for the sentiment\n- Embellishment satin bow die\n- Tape Runner or Adhesive tape\n- 3D foam\nResist Stamping Valentine’s Card: Step-by-Step Instruction\nCut a layer for the base card in the gold cardstock; the layer needs to be approximately half an inch smaller than the card. Cut a layer of the white cardstock as well.\nDie-cut 2 pieces of cardstock in white for the sentiment, and a layer for the sentiment.\nChoose your stamps and use the Perfect Medium as your ink.\nStamp using the floralstamp and the Perfect Medium around the edge of the card layer, stamping the sentiment as well. The Perfect Medium will stay tacky for a while, giving you time to heat emboss both items.\nOver a piece of scrap A4 paper, add the heat embossing powder over the stamped image and on the sentiment stamp; the images will only retain the amount of powder that they need on the wet ink. Next, tap the card and collect the excess powder on the sheet of paper underneath – then tip the excess powder back into the pot, ready for use another day!\nUsing the heat gun, heat emboss the card and the sentiment. The powder will heat up, and transform to produce a gorgeous glossy finish.\nNow you can pick the ink colour you want to use, and start inking the embossed card! Blend the ink around the card, until it is all covered, and then ink the sentiment as well.\nNext, take a darker ink, and blend this just in the centre of the floral stamp, as shown in the photo.\nNow take a dry cloth and polish over the card to remove any excess ink, and make your heat embossing shine!\nAttach the original gold layer, and then the stamped image layer, to the front of the card.\nUsing 3D foam pads, attach the 2 layers of the sentiment to the front of the card.\nFor a pretty finishing touch, add a bow just above the sentiment.\nYour card is now ready for you to write your personal message inside, and send to that special someone! If you loved this project and would like to read more of our papercraft tutorials and articles, you can find them all on the blog right here!","Create unique looks with raised surfaces on cards, tags, scrapbook layouts, and more by embossing with rubber stamps. Embossing allows you to add color and texture to your stamped images, draw focus to part of your design, and make the project look irresistibly touchable with just a few simple steps.\nLearn to Emboss with Rubber Stamps\nIf you can stamp, you can emboss. Embossing with rubber stamps is simple and requires just a few additional tools and steps.\n- Card stock\n- Embossing ink or pigment\n- Embossing powder\n- Heat source, usually an embossing gun\n- Rubber stamp\n- Apply the rubber stamp to the embossing ink pad to saturate the stamp.\n- Stamp directly onto the card stock, applying medium pressure to transfer the ink to the card stock. Lift the stamp away and set it aside.\n- Carefully shake some embossing powder onto the ink. Do this quickly before the ink has time to begin to dry.\n- Lift up the page to pour the excess powder off of the image and back into its container. Tap the paper a few times to get any loose grains of powder off of the stamp.\n- Turn on the heat source and hold it just above the embossing powder without touching the cardstock. As the powder begins to melt, move the heat source around carefully to melt all sections.\n- Repeat with as many stamps as you like.\nEmbossing Tips and Tricks\nIt's possible to get several different looks from your embossing powder and stamps by slightly varying your technique. Try any of these tips and tricks to get the most out of your stamping.\nVary Your Colors\nEmbossing and pigment inks come in a wide range of colors, as do embossing powders. While it is possible to use the same color ink and powder, or to use clear ink with any colored powder, you can get some extra dimension out of your stamps by using different colored inks and powders. Look for coordinating colors, such as silver and icy blue. If you blow away some of the embossing powder from the sections of the stamp before you emboss, you'll bring some of the original color through in places, adding both texture and dimension at once.\nMelt Varying Amounts\nEmbossing powders begin to melt between 200 and 300 degrees Fahrenheit. By moving your heat source closer to and further from the powder, you can melt it to varying degrees. This can create different looks within one stamp.\nVary Your Powder\nEmbossing powders come in several different types and finishes, including:\n- Basic solid colors\n- Antique, crackled finishes\nIf you are stamping a large area, consider using powders that have the same color, but different finishes. For example, a metallic or pearl powder in the center of a stamp and a solid color around the edges can really make your image pop.\nSpecial detail embossing powders will help raise specific sections of your stamps more completely than other sections. This adds subtle dimension and extra texture to the finished results.\nUse Fabric Softener\nHandling your cardstock will cause oils from your skin to transfer to the surface where excess powder may stick. If this happens, you can brush away the powder with a soft brush. To prevent it from occurring, rub a fabric softener sheet over the areas you aren't stamping to keep the powder from sticking.\nDon't Cut Embossed Lines\nIf you're planning on cutting out your embossed stamp to use in a scrapbook or other media, make sure you cut around your image without cutting any embossed areas. Cutting too close will cause the embossed sections to flake off.\nIf your stamp did not transfer enough ink to the card stock, use an embossing ink marker to fill in the missing areas. If your powder did not melt evenly, just reheat it. This will remelt the powder and allow you to get a more even finish.\nWhere to Buy Embossing and Rubber Stamping Supplies\nMost local craft stores will have a large selection of embossing and rubber stamping tools and supplies. If you can't locate a craft store near you, then the Internet is a great source of these supplies:\n- Scrapbooking Warehouse carries a variety of embossing and stamping supplies from powders to texture plates.\n- Herrschnerr's has been around a long time, supplying crafters with all kinds of materials. They carry a large selection of supplies for embossing and rubber stamping.\n- Paperwishes stocks glitter embossing powder as well as hundreds of other items that you will need to create your rubber stamped or embossed project.\n- The Stampin' Place carries embossing and stamping supplies and accessories such as heat guns, specialty embossing powders and a multitude of stamps.\nEmbossing allows you to create beautiful cards, gift tags, scrapbook pages and many other crafts without much effort or expense. Get started with some rubber stamping and embossing and see where the process takes you."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:e3259c75-d386-4eaa-bc43-30a38e609281>","<urn:uuid:e534ef30-38c6-49a3-bd31-0b2581b78f07>"],"error":null}
{"question":"What is Metachromatic Leukodystrophy (MLD) and what are the common side effects reported in patients taking sulfa-based treatments for this condition?","answer":"Metachromatic Leukodystrophy (MLD) is an inherited disorder characterized by the accumulation of fats called sulfatides in cells, particularly affecting the nervous system cells that produce myelin, which insulates and protects nerves. For sulfa-based treatments, commonly reported side effects include nausea, dizziness, diarrhea, malaise, vomiting, headache, dermatitis, and dry mouth. More severe reactions can include renal failure, hyperkalaemia, and in rare cases, Stevens-Johnson Syndrome.","context":["According to National Institute of Health (NIH), Metachromatic Leukodystrophy (MLD) is an inherited disorder characterized by the accumulation of fats called sulfatides in cells. This accumulation especially affects cells in the nervous system that produce myelin, the substance that insulates and protects nerves. Nerve cells covered by myelin make up a tissue called white matter.\n\"Metachromatic Leukodystrophy (MLD) - Competitive Landscape, Market and Pipeline Analysis, 2020\" report provides comprehensive insights on the therapeutic development for this mechanism of action. The objective of the report is to establish an understanding of the therapeutic competitive landscape for Metachromatic Leukodystrophy (MLD), including the pipeline products in this space. It further offers comparative pipeline analysis with their drug profiles at various stages of development covering Phase III, Phase II, Phase I, Preclinical and Discovery. Information on company collaborations, agreements, acquisitions, licensing, deals, and other development activities is also involved in this report Therapeutics assessment of active pipeline drugs by stage, therapy type, route of administration, and molecule type is also covered in this report. It features the inactive pipeline products and highlights currently undergoing institutional research in this area. The report provides the understanding of the unmet needs, market drivers and barriers of the Metachromatic Leukodystrophy market.\nFuture competitive landscape of Metachromatic Leukodystrophy (MLD) is estimated to be very strong. Key emerging drugs including Takeda's TAK-611 and others are going to be Blockbuster in the upcoming years.\nDelveinsight report on Metachromatic Leukodystrophy (MLD) help companies in understanding market dynamics based on this mechanism of action and therefore giving opportunities for a strategic alliance that will result in market penetration and enhancement of portfolios with optimal investment and maximal return. In addition, reports will assuage companies to detect conditions, determine genetic predisposition and biological response to Metachromatic Leukodystrophy (MLD).\nMetachromatic Leukodystrophy (MLD) Report Key Features\nThe report provides insights into:\n- A number of companies developing therapies of Metachromatic Leukodystrophy (MLD) with aggregate therapies developed by each company for the same.\n- Detailed profiles of therapeutic candidates in nonclinical stage, early-stage, mid-stage and late-stage of development for Metachromatic Leukodystrophy (MLD).\n- Analyses key players involved in Metachromatic Leukodystrophy (MLD) targeted therapeutics development with respective active and inactive (dormant or discontinued) projects.\n- Active pipeline therapies assessment under development based on the stage of development, route of administration, target receptor, monotherapy or combination therapy, a different mechanism of action, and molecular type.\n- Detail analysis of collaboration (company-company collaborations and company-academia collaborations), licensing agreement and financing details for future developments of Metachromatic Leukodystrophy (MLD).\nThe report is built using data and information traced from the researcher's proprietary databases, company/university websites, clinical trial registries, conferences, SEC filings, investor presentations, and featured press releases from company/university web sites and industry-specific third party sources, etc.\nMetachromatic Leukodystrophy (MLD) Analytical Perspective by DelveInsight\n- In-depth Metachromatic Leukodystrophy (MLD) Analysis: Assessment of Products\nThis report provides an in-depth commercial assessment of therapeutic drugs that have been included, which comprises of collaborations, agreements, licensing, and acquisition - deal value trends. The sub-segmentation is described in the report which provides company-company collaborations (licensing/partnering), company-academia collaborations, and acquisition analysis in both graphical and tabulated form.\n- Metachromatic Leukodystrophy (MLD) Clinical Assessment of Products\nThe report comprises of comparative clinical assessment of products by development stage, product type, and route of administration, molecule type, and MOA type across this mechanism of action.\nScope of the Report\n- The Metachromatic Leukodystrophy report provides an overview of this mechanism of action, role, significance, pathway, types, and clinical application of IDH inhibitors.\n- Therapeutic Assessment: Therapeutic pipeline activity and assessment of the products by development stage, product type, route of administration, molecule type, and MOA the complete product development cycle, including all clinical and nonclinical stages.\n- It comprises of detailed profiles of therapeutic products for Metachromatic Leukodystrophy (MLD) with key coverage of developmental activities, including collaborations, agreements, licensing, mergers and acquisition, funding, designations, technology and other product-related details.\n- In-depth Metachromatic Leukodystrophy research and development progress and trial details results wherever available, are also included in the pipeline study.\n- Coverage of dormant and discontinued pipeline projects along with the reasons if available across Metachromatic Leukodystrophy (MLD).\n- Key topics covered include strategic competitor assessment, market characterization, opportunities, unmet needs, market growth factors, barriers and challenges along with SWOT analysis of the Metachromatic Leukodystrophy market.\n- Analysis of the current and future market competition in the global Metachromatic Leukodystrophy market. Current scenario of the market with upcoming blockbuster molecules and their impact on the overall market.\n- In the coming years, the Metachromatic Leukodystrophy market is set to change due to the extensive research in this filed, and incremental healthcare spending across the world; which would expand the size of the market to enable the drug manufacturers to penetrate more into the market.\n- The companies and academics are working to assess challenges and seek opportunities that could influence Metachromatic Leukodystrophy R&D. The Metachromatic Leukodystrophy therapies under development are focused on novel approaches to treat/improve the disease condition.\n- There are many companies involved in developing therapies for Metachromatic Leukodystrophy (MLD). Launch of emerging therapies of Metachromatic Leukodystrophy (MLD) will significantly impact the market.\n- A better understanding of the target mechanism will also contribute to the development of novel therapeutics for Metachromatic Leukodystrophy (MLD).\n- Our in-depth analysis of the pipeline assets (in early-stage, mid-stage and late-stage of development for the treatment of Metachromatic Leukodystrophy (MLD) includes therapeutic assessment and comparative analysis. This will support the clients in the decision-making process regarding their therapeutic portfolio by identifying the overall scenario of the research and development activities.\n- The report provides the detailed analysis of 8+ products along with 7+ companies involved.\n- Orchard Therapeutics\n- Magenta Therapeutics\nAnd many more …\n- What are Metachromatic Leukodystrophy (MLD), their role and significance in the treatment of disease conditions?\n- What are the current treatment options based on the Metachromatic Leukodystrophy (MLD) available in the market?\n- How many therapies are developed by each company for Metachromatic Leukodystrophy (MLD) to treat disease conditions?\n- What are the key collaborations (Industry-Industry, Industry-Academia), mergers and acquisitions, licensing activities related to the Metachromatic Leukodystrophy therapies?\n- Which are the dormant and discontinued products and the reasons for dormancy and discontinuation?\n- What is the unmet need for current therapies developed on the basis of this mechanism of action?\n- What are the recent novel therapies, targets, mechanisms of action and technologies developed to overcome the limitation of existing therapies?\n- What are the clinical studies going on for Metachromatic Leukodystrophy (MLD) and their status?","Sulfa Side Effects\nHow can Sulfa Side Effects affect You? | PatientsVille.com\nView and Submit Sulfa Side Effects\nYour Sulfa Side Effect submission can play a very important role. Reporting your experience could help identify an unknown risk and inform other patients and health care professionals.\nRecord and Track Your Side Effects\nIt is very important to keep track of all side effects and discuss them with your doctor. If you think you may have a medical emergency, call your doctor or 911 immediately.\nMost drugs have a large list of nonsevere or mild adverse effects which do not rule out continued usage. These effects depend on individual sensitivity, and can include nausea, dizziness, diarrhea, malaise, vomiting, headache, dermatitis, dry mouth, etc. Check commonly reported side effects . These can be considered a form of pseudo-allergic reaction, as not all users experience these effects; many users experience none at all.\nYou are encouraged to report negative side effects of prescription drugs to the FDA. Visit the FDA MedWatch website or call 1-800-FDA-1088.\nABACAVIR ALBUTEROL AMIKACIN ATROPINE CAPREOMYC CLOPIDOGR CODEINE S CUPRIC SU EPHEDRINE FERRIC SU FERROUS S GENTAMICI HYOSCYAMI MAFENIDE MAGNESIUM MANGANESE MORPHINE NEOMYCIN NEOMYCIN, PAROMOMYC PHENELZIN POLYMYXIN PROTAMINE QUINIDINE QUININE S SILVER SU SODIUM SU SODIUM TH TERBUTALI TOBRAMYCI TRIMETHOP VINBLASTI VINCRISTI ZINC SULF\nActive Ingredient: ABACAVIR ALBUTEROL AMIKACIN ATROPINE BACITRACI BUSULFAN CAPREOMYC CLOPIDOGR CODEINE S CUPRIC SU DEXAMETHA EPHEDRINE FERRIC SU FERROUS S GALSULFAS GENTAMICI HYOSCYAMI IDURSULFA ISOSULFAN MAFENIDE MAGNESIUM MANGANESE MORPHINE NEOMYCIN PAROMOMYC PHENELZIN POLYMYXIN PREDNISOL PROTAMINE QUINIDINE QUININE S SILVER SU SODIUM TH SULFACETA SULFADIAZ SULFAMETH SULFANILA SULFASALA TERBUTALI TOBRAMYCI VINBLASTI VINCRISTI ZINC SULF\nSide Effects reported to FDA: 2149. View Sulfa Adverse Reports\nReported deaths: 58\nReported hospitalizations: 506\nFerrous Sulfate Tablets, 325 mg Labeled as Rugby Natural Iron Supplement: Recall - Bottle May Contain Meclizine HCl 25 mg Tablets\nAUDIENCE: Pharmacy, Consumer\nISSUE: Advance Pharmaceutical Inc. notified the public of a recall of one lot of Ferrous Sulfate Tablets 325 mg, after notification by a pharmacist that a bottle of Ferrous Sulfate Tablets, 325 mg contained Meclizine HCl 25 mg tablets. The lot of the Rugby Ferrous Sulfate is 12G468. Expiration date for the lot is 07/14. The lot was manufactured and packaged in 100 count bottles by Advance Pharmaceutical Inc. under the label of Rugby NATURAL IRON SUPPLEMENT Ferrous Sulfate -- see Product Photo page. Meclizine toxicity may lead to dose-related serious adverse events, including impaired alertness, drowsiness, confusion, low blood pressure, coma, and respiratory depression. Without supportive treatment meclizine toxicity has the potential to be life-threatening.\nBACKGROUND: Taking Meclizine HCl 25 mg as Ferrous Sulfate 325 mg may cause serious side effects to those who consume alcohol or other sedatives, those with a pre-existing CNS disorder, those with kidney or liver dysfunction, the elderly, nursing infants of lactating mothers who received the drug and newborns of mothers who received the drug immediately before childbirth.\nConsumers who take three tablets daily of the defective product for treatment of iron deficiency would be inadvertently ingesting 75 mg of meclizine HCl daily, which is close to the maximum daily adult dose in prescription meclizine drug products of 100 mg. Consumption of meclizine three times a day instead of once daily as monograph recommended is likely to lead to significant drug accumulation because it is a long-acting drug with effects that may persist up to 24 hours after a single dose.\nRECOMMENDATION: Consumers who have the affected lot should not take the product. They may contact Advance Pharmaceutical with questions at 631-981-4600, Ext.300, Monday through Friday between 8:30 am and 4:30 pm ET.\nSulfa Adverse Reactions\nPyrexia ( 183 Reports)|Rash ( 165 Reports)|Nausea ( 133 Reports)|Renal Failure Acute ( 132 Reports)|Headache ( 111 Reports)|Hyperkalaemia ( 83 Reports)|Pruritus ( 82 Reports)|Asthenia ( 79 Reports)|Vomiting ( 78 Reports)|Stevens-johnson Syndrome ( 76 Reports)|Dyspnoea ( 75 Reports)|Diarrhoea ( 73 Reports)|Fatigue ( 69 Reports)|Pain ( 69 Reports)|Urticaria ( 62 Reports)|Chills ( 61 Reports)|Arthralgia ( 59 Reports)|Malaise ( 56 Reports)|Neutropenia ( 55 Reports)|Hypersensitivity ( 49 Reports)|Anaemia ( 47 Reports)|Erythema ( 46 Reports)|Abdominal Pain ( 45 Reports)|Dizziness ( 45 Reports)|Lymphadenopathy ( 45 Reports)|Hypotension ( 43 Reports)|Toxic Epidermal Necrolysis ( 43 Reports)|Cough ( 40 Reports)|Blood Creatinine Increased ( 39 Reports)|Decreased Appetite ( 37 Reports)|"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:c2d952a5-e359-4969-aa2a-27dc941d05c2>","<urn:uuid:9162f280-bf95-4b66-8f2c-6474fba347df>"],"error":null}
{"question":"What were the military innovations of medieval fortifications, and how did the evolving role of archers influence architectural developments in religious buildings?","answer":"Medieval fortifications saw significant military innovations, particularly in religious buildings. Fortified churches featured specialized defensive elements including thick walls, battlements, embrasures, curtain walls, and wall towers. For example, in Székelyderzs, the church's defense system included a crucial tower and 5-meter high walls forming a square with bastions at oblique angles jutting out from all four corners. The rise of the English longbowman during the Hundred Years War influenced architectural developments, as these archers, who became increasingly wealthy and socially prominent through their military success, contributed to church renovations. Their ability to fire up to ten arrows per minute accurately at 200 yards made them crucial military assets, and their accumulated wealth from battle and increased pay led to them investing in religious buildings through donations, resulting in extensions and renovations to churches during this period.","context":["In 1337, the Hundred Years War began. A conflict that would plunge England and France into a war that would last for over a hundred years and radically change the nature of these two Medieval societies. In the beginning, this rivalry of these two monarchies culminated in the Battle of Crecy in 1346 – a battle in which it saw victory pass to the English. France, the great military power of Medieval Europe, was beaten and humbled by a much smaller English Army – an army with a less prestigious military history and yet, on the battlefield in Picardy this smaller and technically weaker force beat the flower of the French Army and raised the military prowess of England significantly. The secret to the English success was the English longbowman: an English Archer armed with a six foot long bow stave, with a draw weight within the region of 100 to 170lbs that could fire up to ten arrows in a minute, accurately, up to 200 yards. Though documentary figures vary, conservative estimates suggest that the English utilised 7000 longbowmen at Crecy which was enough to defeat a French army at least twice as large as the English force. With further victories at Neville’s Cross in 1347 against the Scots and Poitier in 1356 against the French again, the longbowmen dominated the battlefield and brought the English archer to a mythical status.\nYet despite the longbowman’s importance to the English Army, information regarding who these archers were, where they came from and the lives they had before, during and after war is remarkably vague. This is not to say that it is impossible and non-existent. Research by Matthew Strickland, Robert Hardy and Richard Wadge has managed to paint a picture of the type of person an English archer was and the sort of society they lived in. There is also the question of the ‘professional soldier’: research conducted by Andrew Ayton and others indicate that during the Hundred Years War, there was a Medieval Military Revolution in which the Medieval English Army transitioned from a conscripted Commission of Arrays force into a ‘professional’ army whereby the men who fought in it were serving and fighting as a professional occupation. This is exemplified by the rise and prominence of the Mounted Archer and his incorporation into the English Army at this time. This rise in ‘professionalism’ also coincides with the changing social status and reputation of the Medieval Archer as his military importance in English Armies became more apparent – this indicates that not only was the English Archer important to military affairs but that the increase in reputation indicates an increase in wealth as English nobles and commanders were willing to pay for the very best. This is supported by the taxation records. However, there are gaps in this research. Information regarding English archers are primarily drawn from the documentary record in the form of legal proceedings, decrees, rolls, tax records and chronicle and literary record. This is all highly useful but also limited. During the Hundred Years War, the tax records – the main source for accessing wealth during the Medieval period and the main indicator utilised by military historians for accessing the rise of the professional soldier – are scant and in poor condition. For the latter part of the period, the records are more complete and it is from this that historians, like Gary Baker, have been able to assess the increased wealth and social status of the English Archer as well as identifying individual archers. It is, then, argued that an assessment of the rise of the professional soldier for the earlier period is too difficult a subject to hypothesise. However, this may not be the case. It is possible that the archaeological record can reveal what the taxation records do not.\nStrictly speaking, an increase in personal wealth – from an increase in pay to serve as a soldier as well as accumulated wealth on campaign from chevauchees, looting and pillaging from battlefields – would have an impact on life back home in England. After a campaign season was over and after garrisons were placed to defend new acquisitions, the army would be discharged and return to the communities they came from. Though there is documentary evidence to suggest that not every retinue and soldier did this when a campaign was over, there still would have been a proportion of archers and men-at-arm that would return home to continue the lives they had before. The question is: what would an archer do with his money? From studying the social backgrounds and military behaviour of archers and soldiers from across history, the conclusion can be drawn that no matter the time period, soldiers act and respond the same way regardless. An example would be a comparison of the Siege of Caen in 1346 and the Siege of Badajoz in 1812 – first-hand accounts for both sieges show the soldiers in both sieges performing the same way: in a wild manner, looting, raping and causing chaos. The same can be said for their recruitment into the army and how they perform during battle. It could be concluded that soldiers would have spent money in the same way ergo, money would have been spent on food and drink but money could have potentially been spent on their homesteads. From this, is it possible to show an increase in wealth and social status in the archaeology of medieval peasantry homes and can they be directly linked to longbowmen who served in the English Army during the Hundred Years War? Essentially, can archers be identified based on what physically remains? In correlation with this, an examination of the archaeology of churches may prove useful. During the medieval period, it was common practice to donate to the church in order to save your soul in the afterlife. To which end, extensions and renovations were usually paid for by those who could afford it. From this, is there any evidence of churches undergoing renovations in the fourteenth century and can they be linked to a wealthy archer endorser?\nA main feature of this research will be investigating medieval villages and communities and using them as an archaeological case study to find any evidence of medieval archers. A prime case study will be Wharram Percy: a thoroughly excavated medieval site that shows evidence of social and economic change during the fourteenth century, but also has evidence for archery in the form of arrowheads. By investigating this site and its potential connection with archers, it is hoped that these methods can be transferred to the researching of other medieval sites in order to find more evidence that will enable more conclusive answers to these questions.","A fortified church is a church that is built to play a defensive role in times of war, built by the Saxons and Szeklers of Transylvania. Such churches were specially designed to incorporate military features, such as thick walls, battlements and embrasures. Churches with additional external defences such as curtain walls and wall towers are often referred to more specifically as fortress churches or Kirchenburgen (literally \"church castles\").\nThe most spectacular and well preserved monument is in Chair of Udverhely in Székelyderzs. The construction history, architectural styles, decorations and artifacts can be well observed on/in the church – this is why this edifice is frequently mentioned in art and architecture history books. Its stunning architecture, its splendid frescoes and the gastro-cultural offer of the community makes this place one of the most attractive tourist destinations in the region.\nIn 1334 the village’s priest, Tamás, has already been paying the tithes papal income tax, whereas the beginning of the church construction can pe dated to the 13th-14th century. First built in Romanesque style, the church was transformed into a Gothic one in the latter part of the 15th century with the support of the Petky family. In the same period, in 1419, the frescoes are painted on the walls of the already enlarged and renovated church. The fortifications’ oldest and most visible element, the tower, crucial part of the defense system, is to the south of the church. Before 1605 the church was attacked and destroyed by foreigners more than once. In the following decades the church was reconstructed in its present form: the 5 m high walls form a square; their bastions (4) are at an oblique angle and jut out from the walls at all four corners. A similar bastion is found in the middle of the western wall. The semi-cylindrical rib-vaulted arches, which reach into the nave and the choir, date to the first half of the 16th century. An extra floor was added (above the ship and the shrine), in order to have enough space for the men (weapons and ammunition) defending the church. Over the 18th century the church gradually lost its role as a fortress and shelter: the towers got covered with tile, the protective revetments were demolished and got replaced with storage rooms. They stored here the most valuable things of the church and community, such as textiles, grains or wine. The measuring bushels are preserved in a quite good condition and can be seen in their original places. The bacon, ham, sausage are still stored (like in the old days) in the roof of the tower.\nIn 1887 József Huszka discovered the frescoes on the church walls, which in recent years have been carefully restored. The most detailed mural is a Conversion of Paul the Apostle that includes the painter’s portrait. On the southern wall three saint bishops are painted. One of them, Saint Michael is represented as an armored soldier. The biblical tale of Saul’s (Apostle Paul) conversion is also visible here. On the northern wall of the ship the mural depicts Saint Ladislaus resting in the arms of a maiden and other painted scenes from the legends of Saint Ladislaus. The background is also a detailed work of art: on the dark main background star-like petals are drawn with much attention. On the built up window of the church a brick with szekler runes was discovered, dating from 1419.\nSince 2006 the building complex is part of the UNESCO World Heritage Site.\nThe whole building complex is a wonder. First of all, because the tourist cannot just simply “trip” on it, secondly, because one must see and taste those famous sausages (it is advisable to announce the visit at the parish)."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:9dd554bb-6f16-4cf2-94d7-cfcb72241565>","<urn:uuid:44f083aa-fcf5-411d-8834-28c0c326767a>"],"error":null}
{"question":"How does the artistic technique of layering differ between drawing a blue gem and a marble?","answer":"In drawing a blue gem, layering is relatively simple, involving a basic outline with light and dark color variations, plus a light outline supplemented by a darker part at the top. In contrast, marble drawing requires much more complex layering, involving multiple colored pencil layers built up gradually with different pressures, including layers of colors like Denim Blue, Cloud Blue, and White that must be carefully blended to create depth, translucency, and realistic light effects.","context":["Inkscape tutorials | How to draw gems\nThis time we are going to look at the process of creation cartoon gems. We’ll be using basic shapes and then modify them for our needs.\nNote: Though I’ll be using Inkscape to show the process, the principles given below can be more or less applicable to drawing process in any other vector editor.\nThe surface of our gems is highly reflective and we need to show it through sparkles. Almost every sparkle or shine can be represented by white lines or a star-based shape. So let’s create one shape, that we will use later.\n1. Grab a Star Tool from the Tool Box. Set its ‘Corners’ setting to 4, and ‘Spoke ratio’ to something about 0.131 (The last setting may vary, as I adjusted it using a handle on the shape itself). Draw a star shape.\n2. Duplicate (Ctrl+D) the result, rotate and scale it uniformly (holding down the Ctrl key).\nPurple gem has an easy distinguishable diamond shape.\n1-2. Create a square (F4), rotate and scale it down a little, just to make it look like a diamond shape. Make sure to convert object to path (Shift+Ctrl+C)\n3. Duplicate the result (Ctrl+D). Take a Node Tool (F2) and remove the lower node.\nNote: after deleting the lower node, the path between two remaining middle nodes will become curved. To make it straight, select these both nodes and click “Make selected nodes corner” at the Options Bar.\nThen select two middle nodes and insert a new node between them by clicking on the appropriate button at the Options Bar. After that, remove the left node.\n4-5. Duplicate the resulting shape four times to fill the entire diamond-like shape. The ’Align and Distribute’ dialogue (Shift+Ctrl+A) will help you in this.\nI've prepared a color palette for the purple gem in advance. But you can use any colors that you like.\nNote: you can download SVG-file with color palette for creating your own gems here.\n6. Fill the lower planes with darker color, and the upper ones - with lighter.\n7. In order to add a volume to our gem, we need to highlight the edges (as they are the closest gem's part to the viewer). Grab the Bezier Tool (Shift+F6) and draw a star-like shape over the edges using ‘from node to node’ method\n8. Also, with Bezier Tool create light and reflected light. Draw couple of circles with Ellipse Tool (F5) for the light as well.\n9. To make our shape more readable, scale up the original diamond shape, place it at the bottom (End) and fill it with the darkest color from the palette.\n10. The final touch is to add a shine to our gem. Grab our preset sparkle, fill it with white color and place it where you think the light hits. And that’s all!\nGreen gem is a little bit more complex than the purple one because of a large number of corners.\nNote: the number of corners may be different, as the original shape itself. I encourage you to experiment with forms and colors. Using the same principles of adding color and volume, you can create various versions of gems.\n1. Grab a Star Tool and change it’s mode to Regular Polygon at the Options Tool, then set its corners setting to 8. Draw a polygon.\n2. Duplicate (Ctrl+D) the polygon and scale it down uniformly and around rotation center (holding down the Ctrl + Shift keys). Make sure to convert both object to path (Shift+Ctrl+C)\n3. Duplicate (Ctrl+D) the larger polygon and make of it a triangle by deleting unnecessary nodes. Adjust the peak node, so that the edges of triangle matched the corners of the smaller polygon.\n4-5. Duplicate the triangle as many times as needed and align them as shown in the picture above.\nActually, the coloring is almost the same as for the other gems (see purple gem coloring). There is a picture above to guide you through this process.\nBlue gem is even more complex, as its form is volumetric by itself (the viewer can see the upper plane of the gem).\n1-2. For the basic shape we need a Polygon Tool with 5 corners set. Flip the result vertically (V) and convert object to path.\n3. Add more nodes to the top path...\nNote: In our example, it’s better to add nodes via ‘Insert new nodes to a selected segments’ button at the Tool Options Bar (after selecting Nodes Tool). Nodes will be added right in the middle of each segment. In our case, push this button twice after selecting top path nodes.\n... and place them slightly above.\n4-5. Duplicate this shape three times and adjust nodes as shown in the picture.\nThe coloring is almost the same as for the other gems except for one step:\n9. Earlier we used a dark color for the outline. This time we will use light outline and supplement it by a darker part at the top.\nHere is the video process of creating the crown. Take a look, if you got stuck on something.\nThat’s all for now! Please, post your results in the comments. And if you like the tutorial, please, share it :)\nBuy Gems Pack inspired by this tutorial | Download this tutorial in PDF","How to Draw a Marble\nLearn how to draw a marble in this free drawing lesson!\nIn this drawing art lesson, I'll walk you through step-by-step instructions on how to create a realistic drawing of a marble in colored pencils, just like this one:\nMarbles are fun subjects to paint and draw. (If you look on my photorealism art page, you'll see that I love to draw and paint marbles!) The translucency and luminescence of these tiny, shiny objects are alluring as the light shines through them and creates interesting reflections. Plus, when drawing marbles you get to work with a lovely balance of sharp details along with relatively wider areas of color.\nSince marbles are quite small, they work well for an introductory Photorealism Drawing Lesson that will help you prepare to draw larger, more detailed things. In this free art lesson, you'll learn how to:\n- Make your own transfer paper\n- Transfer an image to create a photorealistic colored pencil drawing\n- Build and blend layers of colored pencils to create a sense of depth and realism\n- Achieve a sense of luminosity and translucency with colored pencils\nHere is an animation that shows all the steps involved in creating this realistic drawing of a marble:\nHere are the drawing supplies you will need for this free realistic drawing art lesson:\n- Paper – I used Strathmore ArtAgain drawing paper - my all-time favorite drawing paper when working in colored pencils. The texture and weight of this paper are perfect for drawing with colored pencils – and it is acid-free.\n- Drawing Board – I use a Hardboard Panel as a drawing board, because they are perfectly smooth, sturdy, and very cheap.\n- Tape – You'll need tape to adhere the drawing paper to the drawing board, and also to stick the print-out to the board for the first few drawing steps. As you can see from the photos, I used regular old Scotch tape. Now, this will be a case of \"Do as I say and not as I do\", because using regular Scotch tape is a big no-no if conservation and longevity are important to you. You really should use painter's tape to adhere your drawings to your drawing board, because regular Scotch tape is full of acids that will turn your drawing yellow over time. Masking tape will have the same effect, so stay away from masking tape also. An archival artist tape, on the other hand, will not cause yellowing – plus it's usually easy to remove and leaves behind no residue. But, since the tape will only be touching the drawing for a few hours in this case, and since I don't have any artist tape on hand, I'll let it slide… but only this time!\n- 2B pencil – I used a sharp 2B pencil to trace the drawing. You can also use a mechanical pencil for this, which is actually preferable because it retains a sharp point.\n- 6B or 8B pencil – To make your own transfer paper, you'll need a soft 6B or 8B pencil.\n- Print-out of marble photo – Download the photo below and print it out on regular printer paper. Make sure to use regular printer paper and not something heavy like card stock.\n- Scissors – You'll need scissors to cut both the photo and the drawing paper to size.\n- Ruler – You'll use a ruler to measure out the size of the drawing on your drawing paper.\n- Pencil Sharpener – Keep a pencil sharpener on hand. When working in photorealism on such a small scale, you'll need to keep your pencils nice and sharp.\n- Kneaded Rubber – A kneaded rubber is a moldable eraser that is handy for erasing mistakes of all sizes.\nAnd of course…\nCOLORED PENCILS!! – I prefer Prismacolor Colored Pencils over every other brand, because they are highly-pigmented, lightfast, and professional quality. Basically, if you want to draw photorealistically in colored pencils, then the quality of the colored pencils matter a great deal. Lesser-quality colored pencils will yield less-great results, even if your drawing skills are superb. So I wholeheartedly recommend Prismacolors for anyone who is serious about their drawings.132 Prismacolor Colored Pencils – and that means a lot of colors to choose from! For this drawing lesson, I picked through my set to find the relevant colors and narrowed them down to these:\nDon't worry, you won't need to buy all them though! I just find that before starting a drawing, it helps to separate the colors you might possibly need from the ones you definitely won't need, to reduce both the visual and physical clutter of your workspace.\nThese are the colors I actually ended up using:\n- Scarlet Lake\n- Blue Slate\n- Tuscan Red\n- Mediterranean Blue\n- Cool Grey 10%\n- Poppy Red\n- Cloud Blue\n- Cool Grey 90%\n- Light Green\n- Non-Photo Blue\n- Warm Grey 30%\n- Jade Green\n- Denim Blue\n- French Grey 50%\n- Celadon Green\n- Violet Blue\n- French Grey 70%\n- Light Aqua\nIf you don't have all of them, you can buy Prismacolor colored pencils individually from Blick, or you can get creative and mix the colors you do have to create an approximate match.\nHere is the photo we'll be working from (above). Click the image above and it will open in a new tab or window. You can then right-click and save it onto your computer, and then print it out. It should print out at 2 inches by 3 inches. Cut the image to size, so that the piece of paper is 2\" x 3\".\nFlip the paper over. Using your 6B or 8B pencil, scribble all over the back of the paper. Make sure the entire back of the paper is covered with pencil, like so:\nNow, measure out a 2\" x 3\" rectangle on your drawing paper. Allow a half-inch to 1-inch margin on all four sides, creating a border around the rectangle, and cut the paper to size, like you see below.\nPlace the print-out of the marble photo inside the 2\" x 3\" rectangle. Use archival artist tape to tape the print-out securely onto the paper and also to tape the drawing paper securely onto the drawing board.\nUsing a sharp 2B pencil or mechanical pencil, trace the outline of the marble. You need to trace the outline, and all of the details such as different colors, highlights and shadows. Look at my tracing below to see how much detail I traced:\nBe extra careful with tracing the marble, because the marble needs to be perfectly round to create a believable photorealistic drawing.\nWhen you are done tracing the image, carefully lift up the print-out to see how the outline looks. Leave at least one edge still taped down, so that you can replace the print-out exactly where it was if you discover that you missed a spot.\nIf it all looks good, remove the print-out.\nHere's what your drawing space should look like now:\n(It's a good idea to tape down your paper so that it doesn't accidentally move and cause mistakes.)\nWhen you work on your photorealistic colored pencil drawing, keep the digital image of the marble on your computer screen so that you can look at it as you draw. Also keep the print-out handy so you can reference it as well.\nAbove you can see what my work space looked like as I created this photorealistic colored pencil drawing.\nIt's important to keep your kneaded rubber on hand because sometimes you will need to lightly erase the graphite below drawing with your colored pencils. If you draw over the graphite with your colored pencils, you may inadvertently \"set\" the graphite into the paper, making it impossible to erase.\nWhen working on a colored pencil drawing, I generally always start with the lights or the darks. In this drawing, I chose to start with the lights.\nIdentify the light and white spots in the photo and use a gentle, light pressure to draw in the areas of lightness. It doesn’t matter if the area isn't \"pure\" white – look for areas that are \"generally light\" and gently color them in with White. Working with colored pencils is a layering process, so you will draw other colors over the \"generally light\" areas later.\nUse Denim Blue to lightly color in the diagonal blue strip in the marble. Remember to use a gentle touch!\nI tape a small piece of scrap paper to my drawing board so that I can test out colors. Many Prismacolor colors look alike, so sometimes you'll need to test them to see the subtle differences and decide which one to use.\nUse Scarlet Lake for the diagonal red strip that runs parallel to the blue strip.\nLayer Tuscan Red over the upper edge of the Scarlet Lake to make that part of the red strip darker.\nAdd Blue Slate on either side of marble as shown, and also a little bit in the marble's shadow.\nRemember: if the exact color you need is not available or doesn't jump out at you, you'll need to draw several layers to create the color you need.\nIdentify the darkest areas and draw them in with Cool Grey 90%. Be careful when you apply dark colors, because they are hard to erase. Add them lightly.\nAdd more to the marble's shadow with Warm Grey 30%.\nJade Green is an important color for creating the sense of translucency in the marble. Add a touch of Jade Green to the top, right bottom and left bottom of the marble, as shown.\nAdd more Denim Blue to the diagonal stripe in the middle of the marble.\nLayer Non-Photo Blue over parts of the Denim Blue in the marble's diagonal stripe.\nAdd a touch of Mediterranean Blue to the diagonal stripe, to create more of a transition from lights to darks.\nCloud Blue adds luminosity to the marble. You might need to start pressing a bit harder at this stage, since by now you have worked up several layers of colored pencil.\nAdd Cloud Blue to the skinny diagonal highlight that is inside the marble's diagonal blue stripe. For now, we can consider that diagonal blue area done.\nAlso add Cloud Blue to the marble's other light areas.\nDeepen the color of the red diagonal stripe by adding Tuscan Red.\nMake the red diagonal stripe more vibrant by layering it with Scarlet Lake.\nAdd white to the lightest areas of the red stripe to create highlights.\nUse Poppy Red for the final touch-ups in the diagonal red stripe. The diagonal red stripe is now done!\nAdd Light Green to the left and right sides of the marble to create a sense of translucency.\nUse French Grey 70% to bring out the darker areas in the marble, as well as in the shadow. Don't worry if it seems too dark in some places – we'll lighten it up and smooth it out in the next step.\nApply Celadon Green over the French Grey 30% that you applied in the previous step in both the marble and the marble's shadow.\nApply White over the Celadon Green. The Celadon Green created more depth, so adding the White will bring back more of the translucency. Be sure to add White on the bottom left part of the marble.\nBy now, the surface of the paper feels slicker. All these layers of colored pencil have made the paper have less \"tooth\". You'll need to press harder, but be careful not to press too hard.\nAdd a hint of Light Aqua on the top and right of the marble. See how it's making the marble look even more round and solid?\nApply Cool Grey 90% to the shadow and the marble's darker spots. After that, go over the same areas where you applied the Cool Grey 90% with another light coat of Celadon Green, which will blend the Cool Grey 90% more smoothly with the rest of the marble.\nCongratulations: Now the marble is done! Time to finish the shadow:\nAdd Warm Grey 30% to the marble's shadow.\nUse Cool Grey 10% to temporarily lighten the shadow. Adding Cool Grey 10% will essentially bring out some subtle highlights in the shadow.\nNow go over the shadow with another layer of Warm Grey 30%, but leave some of the lighter areas in the shadow still showing.\nAlso, use Blue Slate to add a touch of the marble's color to the marble.\nUse French Grey 50% to add more of a warm darkness to the shadow.\nUse Warm Grey 30% to gently lighten the areas in the shadow that were too dark, and to darken the areas that are too light. In other words, you'll use Warm Grey 30% to make the shadow appear more balanced, while still retaining some variance with lights and darks within the shadow itself.\nCongratulations!! You've just drawn a photorealistic marble in colored pencil!\nHere's the finished drawing:\nI used French Grey 50% to sign the drawing. To keep the signature legible, I re-sharpened the colored pencil after every few letters.\nI hope this realistic drawing art lesson was helpful to you. Let it serve as a guide that helps you along as you explore what you can do with colored pencils.\nAs you get more comfortable drawing with colored pencils, you'll surely come up with your own way of tackling drawings, from deciding where to start first to which colors to layer and when. There's no set formula for success when it comes to drawing photorealistically with colored pencils.\nThe more you work with colored pencils, the more you'll learn to do what feels right for each drawing."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:13d4bd95-daa2-4f36-bff3-5331586e1ecc>","<urn:uuid:bf08cf5f-78af-46c8-a602-4aa09be127f1>"],"error":null}
{"question":"How do high-pressure volcanic eruptions compare between terrestrial and submarine environments?","answer":"In terrestrial environments, high-pressure eruptions occur when rapid decompression of magma causes dissolved gases to expand violently, creating eruption columns that can rise up to 45 kilometers in height and potentially collapse into deadly pyroclastic flows. In submarine environments, as seen with underwater volcanoes which make up 80% of all volcanic eruptions, the high pressure of the ocean environment affects how the eruption manifests. The evidence of these submarine eruptions often only becomes apparent when products like pumice rafts reach the surface, as demonstrated by the 1924 Iriomote-Jima eruption which produced massive amounts of floating pumice that traveled over 2700 km along the Japanese coast.","context":["Global Volcanism Program | Educational Resources | Types and Processes Gallery - Magma meets Water\nFire bubbles! That's what happens when burning hot liquid magma hits water. National Geographic writes that, “Scientists are trying to. Scientists are trying to determine the potential dangerous effects of introducing water into a pressurized pocket of magma underground. When the lava meets the sea, it cools quickly while boiling the ocean spot is out in an ocean it melts the oceanic crust into silica-poor magma.\nPhreatic or phreatomagmatic explosions are common at submarine volcanoes, crater lakes, and other places where hot magma or associated gases encounters surface water or groundwater. Kelut Kelut volcano has been notorious for the repeated ejection of crater-lake water during eruptions, producing devastating lahars. A series of tunnels and shafts were constructed in the 's to lower the lake level and reduce the hazards of eruptions. The initial tunnels lowered the lake level 50 m, but the eruption deepened the crater by 70 m, leaving 50 million cu m of water.\nFollowing another devastating eruption inlower outlet tunnels were constructed, and prior to the eruption the lake contained only 1 million cu m of water. Photo by John Dvorak, U.\nKusatsu-Shiranesan The turquoise waters of Yu-gama, one of three craters at the summit of Japan's Kusatsu-Shirane volcano, are a popular tourist destination. Yellow rafts of sulfur float on the surface of the acidic lake, which prior to an eruption inwas clear, with forested walls. Frequent phreatic explosions have occurred from Yu-gama and the two other summit craters during historical time.\nThis photo was taken from the south crater rim. Copyrighted photo by Dick Stoiber, Dartmouth College. Tokachidake A phreatomagmatic explosion on December 25,from Japan's Tokachi volcano ejects incandescent blocks and a dark ash cloud. The base of the ash column is the leading edge of a small pyroclastic surge that eventually traveled down the north flank to 1 km from the vent. The eruption began with a phreatic explosion on December Intermittent explosive eruptions with small pyroclastic flows and surges began on December 19 and continued until March 5.\nPhoto courtesy of Japan Meteorological Agency, The white ring at the base of the eruption column is a steam cloud that is traveling laterally away from the vent along the surface of the crater lake.\nWhen the water vapor bubbles try to rise they are impeded by the linkage of silica chains in the magma and can rise only slowly. The rapid change in confining pressure as the magma body rises to the surface causes the dissolved water vapor bubbles to expand and escape explosively.\nWhen Magma Meets Water\nBubbles that form quickly in a large mass of viscous rhyolitic magma can shatter into a froth of tiny glass-walled bubbles, producing a rock called pumice. A rock with larger bubbles is called scoria.\nIn magmas with a high dissolved gas content, the rapid decompression associated with a quickly rising magma body can cause the gases to expand in a violent upthrust of a dense mixture of hot gas, lava, and rocks.\nThe mixture of gas and rocks rises quickly in the cool air, forming an eruption column that can rise up to 45 kilometers 28 miles in height. Sometimes, eruption columns can collapse, producing a pyroclastic flow. Pyroclastic flows have proven to be one of the deadliest features of highly explosive eruptions due to the high speed at which they travel, riding on a cushion of air trapped below the collapsing column.\nThey can engulf surrounding villages in hot, poisonous gases, rock, and ash.\nWhen Magma Meets Water | Geology Page\nWater Circulation in Inactive Volcanoes. When a volcano's eruption ceases, the magma within the underground chamber will remain hot for hundreds or thousands of years. Circulating groundwater that comes into contact with the cooling magma is heated and rises to the surface along rock fractures to form either a thermal spring, fumarole, or geyser. Heated water from some thermal springs—for example, in Iceland, Italy, and New Zealand—are used to heat homes and businesses.\nSometimes deeply circulating hot groundwater dissolves minerals from the cooling magma. The dissolved minerals are then precipitated from the hydrothermal solution and deposited in the openings of the surrounding rock, usually filling cracks and sometimes replacing the rock itself.\nThese deposits tend not to have great vertical extent but are exceedingly mineralrich. Many famous silver and gold deposits of the western United States, such as Comstock, Nevada and Cripple Creek, Colorado are examples of hydrothermal ore deposits. Principles of Igneous and Metamorphic Petrology. Upper Saddle River, NJ: An Introduction to Physical Geology, 4th ed.\nTheir sizes range from 0. Inclusions may be observed within a given sample by cutting the mineral into very thin slices 30 to 35 microns [about 0. Fluid inclusions carry information about the history of the surrounding rock material from which they formed. They are considered to be direct samples of the volatile phases that circulated through the lithosphere the Earth's crust and uppermost mantle during the course of Earth's history.\nWhen Magma Meets Water\nVolcanoes under ice caps may exhibit an even more spectacular behavior. Basalt lava is capable of melting about ten times its own volume of ice. So when ice-covered volcanoes erupt, huge volumes of meltwater can accumulate until the glacier bursts. These destructive torrents can achieve discharges comparable to that of the Amazon River. Jeferson Jun 11, 4: As published and mostly accepted when magma gets to within kms from the surface as a boiling mass of gases and liquid rock it starts to release that vertically.\nGases break the rock, the magma exploits them and because of the lowering of the pressure it starts expanding into higher volume and really starts the process going. Higher pressure from rock, ice, ocean or a combination of all of them would serve to keep that gas from expanding.\nBut also as widely accepted is the km magma buoyancy equilibrium.\n- Types and Processes Gallery - Magma meets Water\n- Water Introduction via Plate Tectonics\n- Characteristics of Magma\nRemove the ice, or the ocean or even allow a vent tube to come up meters and it can tip the scales. There is so little that is known about the earth and its processes that we likely will never get a handle on it with only the general stuff being accepted.\nWe have seen groups like the IPCC use information, without verification and accept it because it came from some previously held in high regard scholars. Now branded charlatans we are rethinking things. Its the open mind that accepts theories and then works to disprove them. By elimination they came up with the magma equilibrium theory and it may or may not be right.\nVolcanoes and Water\nIt would be acceptable to assume just one thing about Katla. The general idea and that is when the pressures below exceed those above it will erupt. I think we can all agree on that. Everything else is conjecture and I can laugh about it and say What do they do if the ice turns to water and runs off and there is no eruption?\nOr if it does?","- Volcano List\n- Learn More\n- All About Volcanoes\n- Kids Only!\n- Adventures and Fun\n- Sitemap (Under Construction)\nUnderwater volcanoes! The sound of it piques our interests; it sounds exotic and rare. However, the occurrence of underwater volcanoes is actually more common than you might think. There are several active volcanoes constantly erupting on Earth's surface but we aren't aware of them because these eruptions occur underwater. These underwater volcanoes are not only special because of the interaction of lava and water, but also because they provide extreme environments for certain species of life to grow and flourish; these bacteria and living creatures are sometimes ONLY found in these hot, wet, and sulphuric conditions!\nAround 80% of volcanic eruptions on Earth occur underwater! Unless there are earthquakes related to the eruptions, they usually erupt unmonitored and are only spotted after they've initially erupted. Sometimes we don't even know they are there until the volcano emerges as an island! Another way of spotting an underwater volcano is from the products produced from this eruption. One of the most common products of an underwater eruption are pumice rafts. Pumice, which is a highly vesicular volcanic rock, traps air in its vesicles, making it more bouyant than water, allowing it to float. During an eruption, large amounts of pumice can be created, which float up to form pumice rafts.\nFigure above: Example of a pumice raft from the Krakatau Caldera eruption in Indonesia. (Photo credit to swisseduc.ch)\nOne really cool underwater volcanic eruption that was identified in this manner is the eruption of Iriomote-Jima, a submarine volcano off the southwest of mainland Japan. It formed on the 31st of October, in 1924, when it erupted underwater, producing 1 cubic km of rhyolitic pumice. At this point in time, it was the largest recorded historical eruption by volume in Japan. The resulting pumice raft ended up floating along the coast of Japan, being found as far as Hokkaido, over 2700 km away from the volcano!\nFigure above: Location of Iriomate-Jima volcano marked by red X. Iriomate-Jima volcano is located off the coast of Iriomate-Jima island (same name), which is one of the southernmost islands of Ryuku islands, around 950 km SSW of Honshu, Japan, and 200 km east of Taiwan. (Photo credit to NASA and Global Volcanism Program)\nSome of the pumice blocks found were recorded as being almost 2 m in diameter! Since the eruption, there have only been swarms of earthquakes recorded in the area, the most recent being in 1992. There has not been any activity recorded at Iriomote-Jima volcano since then, but that does not make this submarine volcano any less interesting. In fact, this only raises more questions related to submarine eruptions. Why do they occur where they do? In the case of Iriomote-Jima volcano, why has there been no recent volcanic activity? Was this a one time event? Unfortunately for us, this 1924 eruption was one of the few poorly recorded eruptions in volcano history, compounded by the fact that the volcano is almost 200 m below sea level.\nWith advancements in technology, however, we have been able to monitor other submarine volcanoes and their underwater action. We have even managed to record some eruptions live. With the ongoing research, we are getting closer and closer to finding answers about our underwater 'friends'.\nVideo above: Example of an underwater volcanic eruption as shown on the Discovery Channel.\nFor more information on Iriomote-Jima volcano, click here.\nFor cool and interesting information on submarine volcanoes in general, click here."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:7584c53d-5318-47ec-852e-8175cc6d6f73>","<urn:uuid:d1963194-77cc-4806-8196-a4018035ba8e>"],"error":null}
{"question":"¡Hola! Soy un amante de la naturaleza y me gustaría saber, ¿qué porcentaje de la isla de Mljet está cubierta por bosques? 🌳","answer":"Over 84% of the island of 98.01 square kilometres is covered by forest.","context":["|This article needs additional citations for verification. (June 2012)|\nSunset over the Mljet lakes\n|Area||98.01 km2 (37.84 sq mi)|\n|Length||37 km (23 mi)|\n|Width||3.2 km (1.99 mi)|\n|Coastline||135.185 km (84.0001 mi)|\n|Highest elevation||514 m (1,686 ft)|\n|Highest point||Veliki grad|\n|Largest settlement||Babino Polje (pop. 270)|\n|Population||1,088 (as of 2011)|\n|Density||11.34 /km2 (29.37 /sq mi)|\n|Ethnic groups||97.93% Croats|\nMljet (pronounced [mʎɛ̂t]; Latin: Melita, Italian: Meleda) is the most southerly and easterly of the larger Adriatic islands of the Dalmatia region of Croatia. The National Park includes the western part of the island, Veliko jezero, Malo jezero, Soline Bay and a sea belt 500 m wide from the most prominent cape of Mljet covering an area of 54 km2. The central parts of the park are Veliko jezero with the Isle of St. Mary, Malo jezero and the villages of Goveđari, Polače and Pomena.\nMljet was discovered by ancient Greco-Roman geographers, who wrote the first records and descriptions. The island was first described by Scylax of Caryanda in the 6th century BC; others prefer the text, Periplus of Pseudo-Scylax. In both texts, it is named Melite and supported by Apollonius of Rhodes.  Agathemerus and Pliny the Elder call the island Melita. Agesilaus of Anaxarba in Cilicia, the father of Oppian, was banished to Mljet by the Roman Emperor Septimius Severus (AD 145–211) (or to Malta by Lucius Verus: see Oppian).\nMljet is mentioned around 950 by the Byzantine Emperor Constantine VII Porphyrogenitos in his Of Ruling an Empire as one of the islands held by the Narentines. The island was often a controversy of ownership between them and Zachlumia until the stronger unifications of the Serbian realm in the 12th century.\nMljet has been regarded as the \"Melita\" on which Saint Paul was shipwrecked (Acts of the Apostles 27:39–28:11), this view being first expounded in the 10th century, by Eastern Roman Emperor Constantine Porphyrogenitus. Saint Paul's shipwreck is generally placed on the Mediterranean island of Malta. Mljet and Malta had the same name in the Greek and Roman sources; the mention of a viper in Acts 28:3–5 was thought to be in favour of Mljet (but there are snakes on both Mljet and Malta). A harbour named after the Saint exists on both islands.\nThe Benedictines from Pulsano in Apulia became the feudal lords of the island in 1151, having come from Monte Gargano in Italy. They came ashore in the Sutmiholjska cove and in 1187–1198 the Serbian Prince Desa of the House of Vojislavljević built and donated to them the Church and Monastery of Saint Mary on the islet in the Big Lake (Veliko Jezero) towards the north-west end of the island. Pope Innocent III issued a document consecrating the church in 1198.\nThe Benedictines renounced their rule over Mljet in 1345, keeping only a third of the land. The island got a statute and a municipality in Babino Polje. It was formally annexed by the Republic of Ragusa in 1410. According to the Contract with the Benedictines, the municipality had to pay 300 perpers each year.\nIn the 16th century, the monastery was the center of the Mljet Congregation (Congregatio Melitensis or Melitana), gathering all the monasteries of Benedictine monks in the area of the Republic of Ragusa. The first president of the Congregation was Mavro Vetranović, the abbot of the Mljet monastery and the famous poet. Another great poet was abbot there—Ignjat Đurđević in the 18th century. As time went by, the Benedictine monastery on Mljet lost its importance, while the seat of the Mljet Congregation moved to Sveti Jakov near Ragusa.\nIn 1809, during the rule of Napoleon, the Mljet monastery was disbanded. When Austria took over the island, it placed the forestry office in the building. Between the world wars, the building was owned by the Ragusa (Dubrovnik) Bishopric. In 1960 it became a hotel, and in 1998 it was returned to the bishopric.\nThe island has a long history of eco-damage. In order to ease their transport problems, the monks dug a channel to the south coast, from the lake Veliko Jezero, thus turning both fresh-water lakes into seawater-based ones.\nThe second incident involves mongooses. Small Asian mongooses were introduced onto the island in the early 20th century in order to reduce the venomous snake population (the island was apparently completely overrun). Whilst the mongooses completed this task, they also disposed of pretty much all the birdlife of the island. To this day, the island is notably short of hedgerow birds such as sparrows. Mongooses are a hazard for domestic poultry, and are also known to cause damage in vineyards and orchards.\nMljet lies south of the Pelješac peninsula, from which it is divided by the Mljet Channel. Its length is 37 kilometres (23 mi); its average breadth 3.2 kilometres (2.0 mi). It is of volcanic origin, with numerous chasms and gorges, of which the longest, the Babino Polje, connects the north and south of the island. Port Polače, the principal harbour in the north, is a port of call for tourist ferries. Mljet contains one hotel—The Odisej (from the Greek Odysseus) in the north-west corner of the island.\nThe northwestern part of the island includes an inland sea as well as a small island within it. It has been a national park since November 12, 1960.\nOver 84% of the island of 98.01 square kilometres (37.84 sq mi) is forest. The island's geological structure consists of limestone and dolomite forming ridges, crests and slopes. A few depressions on the island of Mljet are below sea level and are known as blatine (\"mud-lakes\") or slatine (\"salt-lakes\"). During the rain seasons all blatine are filled with water and turn to brackish during dry seasons.\nThe climate is Mediterranean; an average air temperature in January is 9 °C (48 °F) and in July about 24 °C (75 °F). Precipitation (mostly falling between October and April) averages between 35 and 45 inches annually, with the hills receiving the highest amounts.\nAccording to the 2011 census, the settlements of Mljet have the following population:\n- Babino Polje (270): largest settlement, police station, school\n- Goveđari (151)\n- Babine Kuće\n- Pomena (52)\n- Polače (113): ferry port, Roman ruins\n- Blato (39)\n- Ropa (37): auto camp\n- Kozarica (28)\n- Sobra (131): ferry port\n- Prožura (40)\n- Prožurska Luka (40)\n- Maranovići (43)\n- Okuklje (31)\n- Korita (46)\n- Saplunara (67): beach\nEconomy and tourism\n|This section is empty. You can help by adding to it. (June 2012)|\nThe island of Mljet has no airport. Dubrovnik Airport on the mainland provides the main international connection for the island. Mljet has ferry lines with Pelješac peninsula and Dubrovnik. Transportation to the island is provided by Jadrolinija ferry service. Sobra, the main port on the island, is connected to Dubrovnik-Gruž and Ston via a car ferry. There are two type of ferries available: a car ferry and a faster catamaran ferry (2.5 hours and 90 minutes to Dubrovnik, respectively).\nThe two-lane paved road runs throughout the island. Scheduled buses on Mljet travel just once or twice a day.\n- Duplančić Leder, Tea; Ujević, Tin; Čala, Mendi (June 2004). \"Coastline lengths and areas of islands in the Croatian part of the Adriatic Sea determined from the topographic maps at the scale of 1 : 25 000\" (PDF). Geoadria (Zadar) 9 (1): 5–32. Retrieved 2011-01-21.\n- Naklad Naprijet, The Croatian Adriatic Tourist Guide, pg. 338, Zagreb (1999), ISBN 953-178-097-8\n- \"Population by Age and Sex, by Settlements, 2011 Census: Mljet\". Census of Population, Households and Dwellings 2011. Zagreb: Croatian Bureau of Statistics. December 2012.\n- Sanader, Mirjana (2007). Kroatien in der Antike (in German). Von Zabern. p. 58. ISBN 3-8053-3740-X.\nIn der Antike hieß sie Melite (Pseudo-Skylax 23), obwohl sie bei Apollonios Rhodios (4, 5629) auch als Meleda erwähnt wird.\n- Bryant, Jacob. (1715–1804) A New System, Or, An Analysis of Antient Mythology: Wherein an Attempt is Made to Divest Tradition of Fable and to Reduce the Truth to Its Original Purity, The Third Edition in Six Volumes, printed for J. Walker; W. J. and J. Richardson; by R. Faulder Press, 1807., Vol. V., pp 357-358. (English)\n- Text from ancientlibrary.com\n- \"Mungos - ljuti neprijatelj prirode\". Zadarski list (in Croatian). Retrieved 8 June 2012.\n- \"Priručnik o kartama staništa Dalmacije\" (PDF) (in Croatian and English). June 2009. p. 97. Retrieved 14 February 2011.\n- This article incorporates text from a publication now in the public domain: Chisholm, Hugh, ed. (1911). Encyclopædia Britannica (11th ed.). Cambridge University Press.\n|Wikivoyage has a travel guide for Mljet.|\n|Wikimedia Commons has media related to Mljet.|\n- Island of Mljet\n- Mljet National Park Guide\n- Mljet Tourist Information (Croatian)\n- Mljet presented by Dubrovnik Guide\n- Is Island of Mljet Homer's Ogygia?\n- Small Travel Guide to Mljet\n- More information about Mljet\n- More information about Mljet National Park\n- Sobra & Pomena"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:cd0a9af4-3a7d-477f-b0ed-6289f1e3c449>"],"error":null}
{"question":"Which food contains more Vitamin K per serving: ground raw chicken or whole-grain cornmeal?","answer":"Ground raw chicken contains 0.225 mcg of Vitamin K per 1 oz serving, while whole-grain cornmeal contains 0.3 mcg of Vitamin K per 100 grams. Converting to the same unit of measurement, ground raw chicken has less Vitamin K than whole-grain cornmeal.","context":["Vitamin K in Chicken, Ground, Raw\nThe recommended USDA amount of Vitamin K for adults 19 and older is 90 mcg/day.\nBased on the Vitamin K content, how much can I safely consume in one day?\nWhat does this chart mean?\nWhile on Warfarin, you should consume the same amount of Vitamin K daily. The USDA recommends that adults get 90 mcg of vitamin k daily.\nIf the only thing you ate today were Chicken, ground, raw. You would have to eat 400.0 oz crumbleds in order to get your 100% recommended daily value of 90mcg of Vitamin K.\nSimilarly, in order to get 50% (45mcg) of your daily recommended value of Vitamin K. You would have to eat 200.0 oz crumbleds of Chicken, ground, raw.\nAdditionally, you would have to eat 100.0 oz crumbleds of Chicken, ground, raw to get 25% (22.5mcg) of your recommended daily Vitamin K.\nHow does the Vitamin K content in Chicken, ground, raw compare with other foods?\nHere are some examples of foods that compare with Chicken, ground, raw.\nTo view more foods in other food categories, visit the Vitamin K Food Database.\nOther Poultry Products vs. Chicken, ground, raw\nLegumes and Legume Products vs. Chicken, ground, raw\n|Food Name||Measure||Vitamin K (mcg)|\n|Chicken, Ground, Raw||1 oz crumbled||0.225|\n|Beans, liquid from stewed kidney beans||1 cup||0.0|\n|Soy protein concentrate, produced by alcohol extraction||1 oz||0.0|\n|Peanut spread, reduced sugar||1 tbsp||0.1|\n|Peanut butter, chunky, vitamin and mineral fortified||1 tbsp||0.08|\n|Meatballs, meatless||1 cup||0.0|\n|USDA Commodity, Peanut Butter, smooth||1 tbsp||0.0|\n|Soymilk, chocolate and other flavors, light, with added calcium, vitamins A and D||1 cup||8.75|\n|Soymilk, original and vanilla, light, with added calcium, vitamins A and D||1 cup||3.89|\n|Soymilk, chocolate, with added calcium, vitamins A and D||1 cup||7.29|\n|Beans, great northern, mature seeds, raw||1 cup||10.98|\n|Broadbeans (fava beans), mature seeds, cooked, boiled, with salt||1 cup||4.93|\n|Chickpeas (garbanzo beans, bengal gram), mature seeds, cooked, boiled, without salt||1 cup||6.56|\nI'm on a blood thinner (anticoagulant/antiplatelet) such as Warfarin - How does Vitamin K work with my blood thinner?\nWarfarin (Coumadin) works by decreasing the chemical reactions Vitamin K makes in your body. This increases the time it takes for a clot to form. Hence, \"thinning\" your blood.\nIf you take Warfarin, you may need to limit and/or monitor your Vitamin K intake. This is because Vitamin K can affect how these drugs work.\nIdeally you should consume the same amount of Vitamin K daily.\nHowever, Vitamin K does not influence the action of other blood thinners, such as heparin or low molecular weight heparins (Lovenox, Xaparin, Clexane, Fragmin, or Innohep).\nCan Vitamin K affect my INR?\nINR stands for International Normalized Ratio. INR is a standardized way to measure how long it takes your blood to clot.\nThe lower your INR, the quicker your blood clots (the \"thicker\" your blood gets). Too low of an INR indicates risk for clotting problems.\nThe higher your INR, the slower your blood clots (the \"thinner\" your blood gets). Too high of an INR indicates risk for bleeding problems.\nWith an increase in Vitamin K, your INR could drop.\nAlternatively, a decrease in Vitamin K intake may increase your INR.\nAs a side note, other things, like medications, antibiotics, and herbal products may also influence your INR.\nWhat if I suddenly eat a food with a lot of Vitamin K?\nIf you are on a blood thinner like Warfarin (Coumadin) then you should alert your healthcare provider, because your blood thinner dosage may have to be adjusted to counteract the change in your body's clotting activity.\nWhere does Vitamin K come from?\nVitamin K is often found in food. Leafy green vegetables such as kale, spinach, and broccoli usually contain the most amount of Vitamin K.\nVitamin K is also produced by bacteria in your intestines and is contained in vitamin supplements.\nWhy is Vitamin K important?\nBlood clots are formed through a series of chemical reactions in your body. Vitamin K is essential for those reactions.\nVitamin K is known as the clotting vitamin, because without it, blood would not clot.\nVitamin K increases the chemical reactions in your body needed for your blood to clot. The more Vitamin K you take, the more chemical reactions your body makes for your blood to clot. Hence your blood gets \"thicker\".\nAlso, some studies suggest that it helps maintain strong bones in the elderly.\n- Fast Foods, Fried Chicken, Drumstick, Meat Only, Skin And Breading Removed\n- Babyfood, Meat, Chicken Sticks, Junior\n- Chicken, Broilers Or Fryers, Breast, Meat Only, Cooked, Roasted\n- Bologna, Chicken, Pork, Beef\n- Chicken, Broilers Or Fryers, Dark Meat, Drumstick, Meat Only, Cooked, Roasted\n- Soup, Chicken, Canned, Chunky, Ready To Serve\n- \"Chicken, ground, raw\", NDB 5332, U.S. Department of Agriculture, Agricultural Research Service. Nutrient Data Laboratory. USDA National Nutrient Database for Standard Reference. Nutrient Data Laboratory Home Page, http://www.ars.usda.gov/ba/bhnrc/ndl. Accessed October, 2014.\nNutrition CalculatorAmount per serving (Chicken, Ground, Raw)\n|Calories 40.04||Calories from fat 20.41|\n|Vitamin K||0.23 µg|\n|Vitamin B-6||0.14 mg|\n|Vitamin B-12||0.16 µg|\n|Niacin (Vitamin B-3)||1.56 mg|\n|Riboflavin (Vitamin B-2)||0.07 mg|\n|Vitamin K||0.23 µg|\n|Vitamin E||0.08 mg|\n* = this food has ingredient(s) with missing nutrition information\nMissing Nutrient Information:\n- Vitamin D\nTrack your Vitamin K for free","How many vitamins in Whole-grain Cornmeal\nYour body needs vitamins in adequate intake to work properly.\nNevertheless How many Vitamins in can I find in this food? Discover here the amounts present in each of the listed vitamins and useful facts about them.\nSome of the vitamins found in Whole-grain Cornmeal are: Vitamin A (214 IU), Vitamin B-9 (25 mg) and Vitamin B-3 (3.63 mg).\nVitamin A is a fat-soluble vitamin whose absorption goes through the digestion process. Subsequently, this vitamin can be used for body functions or sent for storage in the liver and fat cells.\n214 IU of Vitamin A can be found on every 100 grams of Whole-grain Cornmeal, the 7% of the total daily recommended Vitamin A intake.\nThe American Heart Association recommends obtaining health benefits of vitamin E antioxidant. Vitamin E is a group of eight compounds called tocopherols and tocotrienols which reduces cholesterol and the risk of developing diabetes, Alzheimer's disease, and cancer.\nIn 100 grams of Whole-grain Cornmeal, you can find 0.42 milligrams of Vitamin E. It provides the 3% of the daily recommended value for the average adult.\nVitamin K, also called Phylloquinone, offer protection against health problems like Osteoporosis, Brain health problems, Arterial calcification, varicose veins, and specifics cancer diseases -Prostate cancer, lung cancer, liver cancer, and leukemia.\n0.3 micrograms of Vitamin K can be found on every 100 grams of Whole-grain Cornmeal, the 0% of the total daily recommended Vitamin K intake.\nVitamin B1 is one of the eight water-soluble B vitamins. it plays an essential role in the production of energy from food, the conduction of nerve impulses and synthesis of nucleic acids.\n100 grams of Whole-grain Cornmeal contains 0.38 milligrams of Vitamin B-1, that’s the 25% of the daily recommended value for an adult.\nThe main functions of vitamin B2 (riboflavin) are connected to its role as a helper the body to convert vitamin B6 and vitamin B9 into active forms, neutralize ‘free radicals’ that can damage cells and produce energy converting food into glucose.\nIn 100 grams of Whole-grain Cornmeal, you can find 0.2 milligrams of Vitamin B-2. It provides the 12% of the daily recommended value for the average adult.\nVitamin B3 is one of the water-soluble B vitamins. It is also known as niacin (nicotinic acid) and plays an important role in the disease risk reduction of diseases like Cancer and Diabetes.\nIn 100 grams of Whole-grain Cornmeal, you can find 3.63 milligrams of Vitamin B-3. It provides the 18% of the daily recommended value for the average adult.\nVitamin B5 is known as pantothenic, is really nice strengthening the immune system, enhance the level of hemoglobin in the human body and assists the liver in metabolizing toxic substances.\n100 grams of Whole-grain Cornmeal contains 0.42 milligrams of Vitamin B-5, that’s the 4% of the daily recommended value for an adult.\nFolic acid (Vitamin B9) is essential for the proper functioning of the body and healthy living. It plays an important role in maintaining healthy digestive system, hair, skin, kidneys and eyes.\n100 grams of Whole-grain Cornmeal contains 25 micrograms of Vitamin B-9, that’s the 6% of the daily recommended value for an adult.\nMinerals in Whole-grain Cornmeal\nMinerals are inorganic substances required in small amounts by the body for a variety of different functions. Your body needs larger amounts of some minerals, such as calcium, to grow and stay healthy. Other minerals like copper or iodine are called trace minerals because you only need very small amounts of them each day.\nSome of the minerals found in Whole-grain Cornmeal are: Potassium (287 mg), Phosphorus (241 mg) and Magnesium (127 mg).\nThis vital mineral is best known to strengthen bones, teeth, the heart, and slash your risk of developing a number of diseases like hypertension or seizures.\nIn 100 grams of Whole-grain Cornmeal, you can find 6 milligrams of calcium. It provides the 1% of the daily recommended value for the average person.\nIron is an essential element for almost all living organisms as it participates in a wide variety of highly complex metabolic processes including deoxyribonucleic acid (DNA) synthesis, and oxygen/electron transport.\n100 grams of Whole-grain Cornmeal contains 3.45 milligrams of iron, that’s the 19% of the daily recommended value for one person.\nAn adequate intake of potassium is important to maintain normal body growth, control the acid-base balance, build proteins, regulate digestive functioning, build muscle, and control the electrical activity of the heart.\n287 milligrams of potassium can be found on every 100 grams of Whole-grain Cornmeal, the 6% of the total daily recommended potassium intake.\nMagnesium is an essential element for energy storage in the body’s cells. This mineral provides energy for almost all metabolic processes, being necessary for more than 300 chemical reactions in the human body.\nIn 100 grams of Whole-grain Cornmeal, you can find 127 milligrams of magnesium. It provides the 32% of the daily recommended value for the average adult.\nNext to calcium, phosphorus is the most abundant mineral in the body and an important role in activities for different body parts like the brain, kidney, heart and blood. Health benefits of phosphorous include cellular repair, protein formation, hormonal balance, improved digestion, proper nutrient utilization, and healthy bone formation.\n241 milligrams of phosphorus can be found on every 100 grams of Whole-grain Cornmeal, the 24% of the total daily recommended phosphorus intake.\nThe optimal sodium intake allows the creation of electrolytes and an essential ion present in the extracellular fluid (ECF). However, high levels of sodium in the body are associated with high blood pressure and hypertension.\n100 grams of Whole-grain Cornmeal contains 35 milligrams of sodium, that’s the 2% of the daily recommended value for one person.\nZinc is an really vital mineral for the human body as it helps in regulation of the cells production in the immune system. The health benefits of Zinc include reduction of stress levels, control of diabetes, digestion, proper functioning of immune system, and energy metabolism.\n100 grams of Whole-grain Cornmeal contains 1.82 milligrams of zinc, that’s the 12% of the daily recommended value for one person.\nCopper is an essential trace mineral present in all body tissues. This Mineral regulate various physiologic pathways, such as iron metabolism, connective tissue maturation, neurotransmission and energy production.\n0.19 milligrams of copper can be found on every 100 grams of Whole-grain Cornmeal, the 10% of the total daily recommended copper intake.\nManganese mineral is important in the healthy bone structure metabolism and formation -helping to create essential enzymes for building bones- play a key role in the proper functioning of the thyroid gland.\n0.49 milligrams of manganese can be found on every 100 grams of Whole-grain Cornmeal, the 25% of the total daily recommended manganese intake.\nSelenium is an essential trace mineral that the body needs to stay healthy. Scientists and researchers suggests that Selenium prevent certain cancers such as stomach, colon, bladder, lung, skin, esophagus, and prostate.\nIn 100 grams of Whole-grain Cornmeal, you can find 15.5 micrograms of selenium. It provides the 22% of the daily recommended value for the average adult.\nCalories in Whole-grain Cornmeal\nWe need an average of 2,000 calories per day to maintain body functions. 100 grams of Whole-grain Cornmeal have 362 calories, the 18% of your total daily calorie needs.\nYounger people generally need more calories than older people. There are various gender and age groups to calculate the average Calories intake per day.\nA Sedentary women aged 14 to 25 years needs between 1,800 and 2,000 calories daily. However, a sedentary women aged 26 to 50 need 1,800 calories, while high active women with the same age need 2,200 calories.\nFats and Cholesterol\n100 grams of Whole-grain Cornmeal contain the 6% of your total daily needs: 3.59 grams of total fat.\nAn average adult needs 65 grams of total fat per day. 65 grams fat equals to the 30% of calories consumed by humans and represents the estimated daily needed for a 133-lb. person to maintain her or his weight. For a 167-lb. person the estimated daily needed are 80 grams fat.\nThe AHA (American Heart Association) recommends limiting your daily cholesterol intake to less than 300 milligrams. Less than 200 if you are at a high risk of heart disease.\nThe AHA (American Heart Association) recommends limiting your daily saturated fat intake to less than 130 milligrams.\n100 grams of Whole-grain Cornmeal contain the3 of your total daily needs saturated fat, exactly 0.5 grams.\nMonounsaturated fatty acids\nPolyunsaturated fatty acids\nData Facts Table of Whole-grain Cornmeal"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:52bd4cac-bc0b-4563-b9e9-5b225e23d7c2>","<urn:uuid:3e9db625-3a0c-429c-86da-7dd9e5b188b3>"],"error":null}
{"question":"I want to make my own protein treatment at home. Can you explain what ingredients are best for damaged hair, and tell me if claims about 'all-natural' treatments are true?","answer":"For damaged hair, several effective protein-rich ingredients include: coconut oil (rich in healthy fats and proteins, perfect for severely damaged hair), eggs (best for heat-damaged hair, containing protein and unique enzymes), Greek yogurt (high in protein and lactic acid for cleansing), and avocado (repairs hair cuticle and strengthens strands). However, it's important to note that while these ingredients are natural and beneficial, claims about '100% natural' hair treatments are typically misleading. According to industry experts, there are no truly 100% natural hair products on the market today that meet minimum safety and performance expectations. Even products labeled as 'natural' or 'naturally-sourced' often undergo extensive chemical processing to make them effective for hair care.","context":["Protein treatment for hair has been proven to be an excellent way to fill in the gap between routine hair care and environmental damage. The environment, including the air we breathe and the water we bathe or swim in, contains toxins like heavy metals and other pollutants that can quickly damage hair. This damage can be hard to notice. In fact, most individuals do not recognize their hair is damaged until it ceases to hold styles the way it used to or it breaks off completely. Nevertheless, protein treatments for hair must be done a certain way and at a certain frequency to produce the best results. These steps can look a little different for everyone depending on their personal hair needs, but this article covers the basics of what you need to know to get started.\nWhat is a Protein Treatment for Hair?\nAs its name implies, a protein treatment is a conditioning mixture of ingredients that are high in protein. Upon application to the hair, it binds the cuticle layer and deposits protein into the cuticle. Many plant and animal products contain protein, so you can easily find a number of different protein treatment products for sale in stores and online. You can also make your own protein treatment at home which is often more affordable and convenient.\nProtein treatments benefit the hair because hair consists mostly (about 91 percent) of a protein called keratin. However, keratin can deteriorate within the hair strand following harsh events like chemical processing, color treatment, bleaching, straightening, and curling. Essentially, any heat or chemical applied to hair overtime does cause damage and leaves gaps in the protein that normally coats hair. Protein treatments therefore serve as a quick repair to restore those gaps and enhance the strength of the hair strand.\nHow will I know when I need a Protein Treatment?\nLike the rest of the body, your hair will tell you when it is in need of some protein. These signs are usually most obvious when you are cleaning or grooming your hair. For instance, if your hair appears dull or lifeless following a heat or chemical treatment, then that is a good indication that your hair needs a protein treatment. Other signs that hair needs protein include:\n- Hair that feels dry and brittle\n- Hair that breaks off easily or fills your hairbrush\n- Wet hair that looks limp or stringy and feels gummy to the touch\n- Wet or dry hair strands that do not bounce back toward the head when stretched\nAll of these signs reveal that hair has lost its vitality and elasticity meaning it has lost protein. Fortunately, these effects can be reversed and the protein can be restored with a protein treatment. It is just important not to do protein treatments for too long or too often, because too much protein in the hair can make it dry and brittle leading to further breakage.\nHow do Protein Treatments benefit hair?\nProtein is an essential nutrient for cellular growth and development in the body and your hair cells are no different! Consuming a diet rich in protein nourishes hair from the inside, but protein treatments offer a way to nourish hair from the outside. Overall, the restorative protein provided by treatments for hair benefits it by:\n- Making hair stronger\n- Softening hair texture\n- Locking moisture into hair\n- Enlarging hair strands for more body\n- Stimulating hair growth for more volume\n- Giving hair an overall thicker appearance\nWhatever your hair type, protein treatments will enhance your natural hair structure. This is especially helpful for individuals who have chemically treated their hair but wish to restore it back to normal. However you wish to style your hair, protein treatments make hair more resilient to withstand styling and just more healthy in general.\nProtein Treatment for Hair: The Best Ingredients and How to Use Them\nWhen purchasing protein treatments for hair commercially, you will typically find them categorized one of the following four ways:\n- Protein Packs\nThese are intended for minorly damaged hair (think daily sun exposure) and should be used every one or two months.\n- Light Treatments\nThese are intended for slightly damaged hair (think extended sun exposure or friction to the hair) and can also be used every one or two months. Occasionally, these protein treatments may be labelled as a “leave-in conditioning mask.”\n- Deep Penetrating Treatments\nIntended for moderately damaged hair (think minimal heat styling) and to be used more frequently, like every two weeks.\n- Reconstructing Treatments\nSometimes simply called “reconstructors,” these treatments are for severely damaged hair (think extended heat styling or color treatments). These should be used every one to two weeks.\nSome individuals have been known to use protein treatments on their hair as often as two or three times a week. While that frequency may be necessary for some, it is highly ill-advised for most. If you have never used a protein treatment before, then it is best to start out slow and see how your hair responds to the treatment. This may look something like doing a protein treatment only once a month or once every two weeks.\nProtein treatment for hair is not a perfect science and in fact is personalized to individuals, their hair types, and their hair needs. Accordingly, many people resort to making their own protein treatments at home. This not only saves money, but also allows you to pick and choose the ingredients that you believe will produce the best results for your hair.\nAt Home Treatments\nContain a high-fat content and consists of a lot of protein and nutrients. This is ideal for improving hair health. Avocado repairs damage to the hair cuticle while strengthening hair strands. It also adds moisture to areas of the hair that are dry, brittle, and at the greatest risk of breakage.\nCoconut oil as well as coconut butter, offers a rich supply of healthy fats and proteins. This combination is perfect for moderately or severely damaged hair that has already experienced breakage and is in need of deep moisture.\nConsidered the best protein treatment for heat damaged, natural hair, contains protein as well as enzymes not found in other protein treatments. For fine hair, use the whole egg; for frizzy or oily hair, use only the egg whites.\nNot only good for the body and gut health, but also hair health. Like other dairy products, Greek yogurt stands as an unrivaled source of protein. Yet, what makes Greek yogurt perfect as a protein treatment for hair is its high level of lactic acid which cleanses the hair of any pollutants or chemicals that may still be adhering to it. The fat in yogurt also provides a moisturizing effect for added shine.\nThis sandwich condiment, contains egg as it main ingredient as well as lemon juice and vinegar. The egg provides protein and enzymes while the lemon juice brightens hair and the vinegar removes any buildup of hair product, chemicals, or pollutants on the hair. When massaged into the scalp, these ingredients make mayonnaise a great treatment for dandruff as well.\nContains vitamins A and E, two fat-soluble vitamins that easily penetrate hair cells and lock in moisture. This oil is lightweight, however, so it nourishes hair without weighing it down. Olive oil also eliminates frizz, a common complaint of people with curly hair.\nFull of antioxidants and nutrients which naturally promote hair growth. On the other hand, raw honey is a natural humectant meaning it attracts moisture. Thus, this ingredient will alleviate dry hair and keep it moisturized.\nUnrefined Shea Butter\nOffers a rich supply of essential fatty acids and antioxidants ideal for moisturizing hair and protecting it from damage. Shea butter can also fight inflammatory scalp conditions which may affect hair growth and shine if left untreated.\nHow to Apply\nPerhaps the best part of making your own protein treatment for hair at home is that there are no rules! You can opt to purchase certain ingredients listed above and combine them or simply use what you have on hand from this list. And if any of their aromas bother you, you can just add a few drops of vanilla or your favorite essential oil to mask the smell, then follow these steps:\n- Wet hair thoroughly with warm water.\n- Apply protein treatment to hair focusing on its strands and ends.\n- Cover hair with a plastic cap and allow treatment to soak in for 30 to 45 minutes.\n- Remove cap and rinse hair with cool water. Shampoo and condition hair as normal.\nYou can warm the protein treatment before applying it to hair to enhance its penetration but avoid this if you include egg as the egg will scramble in your hair. Also, do not leave the treatment in for longer than 45 minutes as it will harden and cause hair to break off. Finally, some individuals shampoo their hair first and then use their protein treatment as their conditioner which is perfectly fine. So, mix things up and enjoy your beautiful results!\nBernard, S. (2016, November). DIY protein treatment and signs your hair needs protein. Retrieved from https://curlmix.com/blogs/curlmix/protein-treatment\nOfficioso, A., Tortora, F., & Manna, C. (2016). Nutritional aspects of food toxicology: Mercury toxicity and protective effects of olive oil hydroxytyrosol. Journal of Nutrition & Food Sciences, 6:539. doi:10.4172/2155-9600.1000539\nPowell-Smith, M. (2017, July). Home protein treatment for hair. Retrieved from https://www.livestrong.com/article/191634-home-protein-treatment-for-hair/\nPowell-Smith, M. (2017, July). Olive oil & mayonnaise for hair. Retrieved from https://www.livestrong.com/article/201254-olive-oil-mayonnaise-for-hair/\nViviscal. (2018). Protein for hair growth. Retrieved from https://www.viviscal.com/hair-care/protein-hair-growth","Lee Hunter, Ph. D.\n“Natural”/”Organic” Hair Care Ingredients- Facts Frequently asked questions about a very confusing topic\nSince ancient Egyptian times, natural ingredients have been used as wonderful moisturizing and conditioning agents for hair. That fact is still true today as we all use natural things like coconut oil and panthenol (vitamin B) to achieve excellent moisturizing in products for skin and hair. However, Marketing claims with the term “natural” have created a great deal of confusion due to the fact that many of these claims are inaccurate and purposely misleading.\nI want to clear up some of the information “haze” with straight, honest FACT by laying out the science-based answers to some of the questions that I am asked most frequently about “natural” and “organic” ingredients and their use in hair care products.\n“Natural” has become a very common statement and claim made by hair products manufacturers. There is a belief that “natural” equals “good”. Is this generally true? The answer is yes and no. There is no question that many natural materials make excellent conditioning ingredients for shampoos and conditioners. However, at the same time, many of the most irritating and even dangerous materials on earth are also natural; disease- causing bacteria and viruses; plant toxins such as poison oak; allergens like pollen are excellent examples. Obviously, we cannot assume that just because something is “natural” that is good for us as an ingredient in the products we use.\nWhat does “Organic” mean? “Organic” refers to ingredients that are derived purely from vegetable sources. In other words from plants. An example would be aloe vera. Ingredients that are derived from non-vegetable sources are called “Inorganic”. An example would be silicone.\nIs it possible or practical to formulate “all-natural” or “all-vegetable” hair care products?\nNo. To my knowledge, there are no 100% natural hair products on the market today that meet the minimum safety and performance expectations of stylists and consumers. Virtually all of the hair products that I am aware of that claim to be “all natural” are not 100% natural or organic. There are many ingredients that are used in hair products that make them non-organic. Silicone is the most common inorganic element used that is inorganic; not organic and not vegetable sourced..\nWhat about “Vegan” hair products?\nAgain, the answer is No. Vegan is a term that refers to food and it specifically defines a 100% “natural vegetable” food diet that also excludes secondary products from animals such as eggs and dairy. Since no hair products are 100% “natural vegetable,” I would say they cannot be “vegan”. The use of the term “vegan” with respect to hair products is mis- leading and just another attempt to say “natural”. Applying food nutritional terms like “vegan” to non-food categories like shampoo creates confusion and is simply incorrect and mis-leading.\nWhat does “Naturally-Sourced” mean? If ingredients in products are called “naturally sourced” does it mean that they are “natural”?\nIn most instances, naturally-sourced ingredients are very far from being “natural” by any definition because most of them are synthesized by an extensive chemical manufacturing process involving strong acids and other chemicals including petrochemicals (derived from petroleum). Many very important and useful ingredients in hair products are manufactured starting with natural ingredients and other ingredients, but the final product is no longer natural. Since one of the starting materials is “natural”, then some product manufacturers deceptively refer to the finished raw material as “naturally-sourced.” This is untruthful and purposely misleading. I am not saying that the finished “unnatural” ingredients are bad; in fact they are normally very good. It’s just not accurate to imply that they are “natural” by calling them “naturally-sourced.”\nCoconut oil is one of the most common natural starting materials in the manufacture of raw materials used in hair conditioners and shampoos. Many excellent detangling conditioning ingredients (look for quaternerary amines on the ingredient label) are made through extensive chemical processing that involves many steps, starting with coconut oil.\nAnimal Protein Ingredients. Animal Protein ingredients are not used by any important hair care product lines that I know of today; and they have not been used for over twenty years! Therefore any reference to animal proteins as possibly being used by competitive hair products would be totally mis-leading. No hair products have them!\nKeratin Protein. Most hair stylists have been taught that human hair contains a very high percentage of Keratin Protein. Most protein like human skin is soft, but human hair is hard due to the high concentration of Keratin Protein. It is the Keratin Protein in hair that contains the disulfide bonds that are so important to permanent waving and straightening. When hair has been damaged and is missing protein, it is Keratin Protein that is most effective for reconstructing the hair. The best non-animal source of Keratin Protein is wheat which explains why most hair products contain wheat protein.\nProtein Ingredients. Virtually all protein ingredients contained in shampoos and conditioners today are made by very extensive chemical processing starting with natural materials like wheat grain and soy beans. (Look for the term “hydrolyzed” in the name, which indicates that the protein ingredient has been processed to make it work in hair.) If the wheat grain and soy beans were not so extensively processed chemically, they would not have any beneficial effect at all for conditioning and restructuring hair because the proteins that they contain consist of very large (too large) molecules that have no effect on hair.\nSoy Protein. Soy is a good natural source of protein, but the technology for processing soy to obtain good effective Keratin Protein has not been developed as well as for wheat protein at this time. This is why almost all manufacturers, including most “natural lines”, use wheat protein. (The largest selling “natural line” in the Salon industry uses wheat protein and Keratin amino acids according to their ingredient labeling.)\nWhat is the significance of Gluten-free hair products?\nGluten from wheat is a significant food allergen; not a significant external skin allergen. I have personally researched the issue of gluten as an external allergen extensively since the most effective reconstructors in the industry all use protein sourced from wheat. What I have found regarding the allergic effect of gluten from shampoos and reconstructors is that it is a very, very minor issue. First of all external exposure from a hair product is logically much less important than internal ingestion as a food. This is obvious. Next, the concentration of wheat protein in hair products is far lower by a factor of 50 to 100 times or more than in bread and other foods. Thirdly, and most importantly, the very rigorous chemical hydrolyzation process use to make usable protein in hair products substantially changes the chemical nature of the gluten into a completely different form that is not an allergen at all! Further on the issue of allergic responses to hair products with or without gluten, the main culprit is usually some ingredient in the fragrance of the product involved. Therefore, the “gluten-free” claim is something that is only significant in regard to food, not hair products. I believe that it is as mis-leading and deceptive to use “gluten- free” as a hair care claim as it is to state that products are “vegan”. Think of the relevance of a car manufacturer stating that their new sedan was safer because it was caffeine-free!\nShampoo Surfactants. The chemical processes for manufacturing many lather and cleansing agents (surfactants) used in shampoos start with the natural material coconut oil. Examples of such ingredients that can be found on the labels of the products are: sodium lauryl ether sulfate, Sodium Lauryl Sulfoacetate, Disodium Laureth Sulfosuccinate, Cocamidopropyl Hydroxysultaine, Cocamidopropylamine Oxide, Sodium Lauroyl Sarcosinate, Sodium Lauryl Sulfoacetate, Sodium Lauroyl Sarcosinate, Sodium Cocoyl Isethionate, Cocamidopropyl Hydroxysultaine, Cocamidopropylamine Oxide\nIn all of these examples, the actual ingredients used in shampoos may be called “naturally-sourced,” but they are far from “natural” since they have been chemically processed and converted into “unnatural” materials. In fact, in most instances the chemicals required for successful processing are very harsh materials like sulfuric acid and sodium hydroxide; and the “pieces” of molecules that are added on to the coconut oil molecule to make them useful and effective ingredients, are not necessarily natural materials themselves. In fact, they are frequently petroleum-based chemicals. This chemical processing does not make them unsafe or bad in any way; it just makes the reference “naturally-sourced”, or “all-vegetable” very misleading and deceptive if the manufacturer is obviously trying to lead the stylist or customer to believe that it is actually “natural” or “vegan”.\nWhat is the significance of “sulfate-free” products? Are they safer or healthier in any way? Are products that are not sulfate-free bad for hair color?\nProducts that contain sulfate surfactants are not a health safety issue. This has been verified by the CTFA and the FDA. No responsible scientist questions this. If the safety of sulfate surfactants is questioned by a competitive manufacturer of shampoo, they are not being honest! Period!\nColor-safe? Just like any other surfactant ingredients that lather and clean, sulfate surfactants must be formulated properly to be color-safe. Just because a shampoo contains a sulfate surfactant, it does not mean that it is not color-safe. The key to using sulfate surfactants most effectively is to formulate with the pH of the shampoo near neutral pH of 7.0; which is the same pH range as the body’s natural fluids such as blood, sweat and tears. I call the range around pH 7.0 the “Neutral Zone.” Shampoos with sulfate surfactants that are formulated in the neutral zone are more color-safe than the leading sulfate-free shampoos according to extensive repeated shampoo studies that we have performed. In fact, both shampoos were good for color fastness; but we have found that the sulfate-free shampoos that we tested did not clean as well as “neutral-zone” sulfate shampoos; and they were susceptible to build-up of conditioning and styling ingredients with multiple uses by consumers at home. Typically, consumers who use sulfate-free shampoos regularly find it necessary to trade off to a more thorough cleaning shampoo at least weekly to eliminate the build-up; then return to using the sulfate-free shampoo.\nAre styling polymers good or bad? The answer is that polymers are very good. In fact, the very substance of our skin and hair is made of natural collagen and protein polymers. Keratin protein that is the very backbone of hair is a polymer. Virtually all of the “hold ingredients” of styling products are polymers. Starch and natural gums are polymers, but when they are adapted for ingredients in styling products, they are extensively processed chemically in order to make them into useful styling ingredients. Most styling gels and pastes and mousses and sprays in the salon industry all use styling polymers that have been chemically processed, including the products that refer to their styling ingredients as starches or gums or other “naturally sourced” materials. This includes virtually all of the styling products in the “natural” lines that I am aware of in the industry today.\nIs “plastic” in hair products good or bad? “Plastic” is good! “Plastic” is a term used to describe a broad range of polymers. The main criteria that defines a “plastic polymer” is that it is “formable” into any desirable shape. This feature of some special “plastic polymers” is very desirable for hair styling products! Some examples of “plastic” styling polymers are as follows: PVP/VA; Octylacrylamide/Acrylates/Butylaminoethyl Methacrolate Copolymer; Butyl Ester of PVM/MA, PVP; and there are hundreds more. Incidentally, not only are these polymers “plastic”, all of them are not “natural” or “vegetable” or “vegan” by any possible definition. There are some natural “plastic” polymers that are used in hair styling products as well like Dehydroxantham gum. Since it is a “formable polymer”, it is “plastic” too!\nWhat is the significance of “paraben-free”? This is another attempt at deceptive marketing. Parabens have been used as very effective and safe preservatives in hair and skin products for over fifty years. In the past ten years, there have been some questions raised about the safety of the parabens. These questions have been researched extensively with in-depth scientific safety studies by top scientists for the CTFA (Cosmetic Toiletries Fragrances Association) and the FDA (Food and Drug Association) and they have found the parabens to be safe for use in cosmetics, including hair products. The CIR (Cosmetic Ingredient Review Committee) which is a committee of top scientists under the authority of the CTFA and FDA, has certified the parabens as safe and effective for use in cosmetics. Unfortunately, some companies in our industry, without a conscience, will take single articles of negative information that have been totally disproven; and ignore the evidence of disproof; and use the negative information to say that the parabens are unsafe. This is very unscrupulous and irresponsible! Especially when it comes to trying to use the word “Cancer” to sell shampoo! All of us in society need to focus honestly on the search for the causes of cancer; and the cures for cancer; without confusing the issue with inaccurate and mis-leading information. Distorting the issue of Cancer in order to sell shampoo is totally without any Integrity!\nConclusion. In conclusion, “natural” ingredients are mostly very good for hair products. Natural materials also make wonderful starting materials for the chemical manufacture of ingredients for hair products. However, it is important to know the true facts about “natural” and other misleading claims that are made regarding issues like “naturally- sourced”, “sulfate-free”, “gluten-free”, “paraben-free”, “polymers” and “vegan” in hair products in order to be a well-informed stylist and consumer with integrity.\n“Science Makes a Better Hairstylist”\nDr. Lee Hunter\nDr. Lee Hunter is President and CEO of ProDesign. He has had thirty-seven years of successful and distinguished experience in the personal care products industry leading R&D groups for several major corporations. Dr. Hunter is generally recognized as one of the world’s experts in the science of hair and personal care product development. Dr. Hunter holds a BS degree in Mathematics and Chemistry; and a Ph. D. in Physical Chemistry from Iowa State University."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:1ba7d8d0-dd6d-445b-9a8c-e41388970cc8>","<urn:uuid:e46fb56a-aa4d-4a85-ab4c-5bd0f9e3154a>"],"error":null}
{"question":"how long wetland permit process takes oregon vs alaska?!","answer":"In Oregon, the permit processing times are clearly defined: Individual Permits take up to 120 days, General Authorizations take up to 30 days, and General Permits take up to 40 days. In Alaska, while the permits are free, the timing can be less predictable - the documents indicate that due to demand and limited staffing, US Army Corps personnel may not visit sites as quickly as desired, and the time required may exceed expectations. If faster wetland determinations are needed in Alaska, applicants may need to hire private consultants to help with the process.","context":["The information here is intended for guidance, and should not replace any information provided by the US Army Corps of Engineers, or the US Environmental Protection Agency, the primary entities responsible for administration of section 404 of the Clean Water Act.\nMy site is wet, what does that mean?\nA substantial portion of the Cook Inlet Lowlands is wet and these maps (links below) are intended to help identify areas likely to present problems for the builder, the neighbors, and valuable resources such as moose habitat and salmon streams if the areas are not well-managed.\nWetlands are not always obvious. You may visit the Kenai Peninsula Borough Interactive Parcel Viewer web site to get an idea whether or not your site is wet. Follow the directions to get set-up, then click on “Wetlands”, under “Map Display” to view a wetland map along with parcel lines. You may also download a GoogleEarth file [link to http://cookinletwetlands.info/Downloads/CookInletWetlands.kmz] that shows Cook Inlet wetlands over the satellite imagery that Google Earth uses.\nIf your property, or a property that you may be considering for purchase is mapped as wet, then you should evaluate your decision to build or buy carefully. Three conditions might apply: 1) Your site may not actually be wet. The map was made at a scale describing a much larger area than most parcels, so the wetland boundaries may not exactly match with your property lines, particularly with small wetlands, or with properties at the edge of wetlands. 2) If your site is actually wet, then building will be more difficult than on high and dry ground. Driveways will require more fill material and maintenance, septic systems will be more expensive and prone to failure, and dry basements may be impossible to construct. 3) If your site is wet, and you decide to build or buy anyway, you will need a permit if you need to place fill in the wet part. Permits may be simple if your project is small, or permits may be very involved, or even denied, if your project is large and causes impacts to nearby property owners or high value resources such as salmon spawning streams.\nEven if your site is not a wetland that is jurisdictional under section 404 of the Clean Water Act, you might encounter wet building conditions. This is especially true where the wetland maps show wetlands nearby (see the above links). For example, a water table that is two feet below the surface all year will not be jurisdictional, but still may present difficult building problems during foundation, road, and septic system construction.\nWhat do the different wetland names mean?\nWetlands are not all alike therefore they are assigned different names, for example Kettle, Discharge Slope, and Depression. The different names are intended to reflect the different ways in which wetlands are of value to society. Some values include flood moderation, well-head protection and wildlife habitat. Increased flooding, decreased water quality, and loss of wildlife led to the regulation of placing fill material in wetlands.\nBecause wetlands are of value for different reasons, large projects requiring substantial fill are assessed in detail. The different wetland names aid in the assessment. Wetland assessment in Alaska is in its infancy. The abundance of different wetland types and the pristine nature of Alaska wetlands require an approach to assessment that is fundamentally different from the approaches used in the rest of the US. This wetland classification and mapping is a first step in developing an approach appropriate for Alaska.\nIf the site is a wetland and you plan to place any fill material in the wetland you will need a permit. Permits are free, and many are covered under what are known as Nationwide permits. These permits cover common, small-scale activities such as driveways and house sites.\nThe three tiers in the permit process are, in order: Avoidance, Minimization, and Mitigation. Can you complete your project while avoiding wetland fill? If you cannot complete your project without avoiding fill, can you minimize the amount of fill needed? Once minimized, how can you mitigate for the loss of wetland area? Mitigation examples include wetland banking, or purchasing other wetland property for conservation. If you substantively address these issues in your permit application, the process will proceed more smoothly than if you do not.\nThe US Army Corps often will visit your site to make a jurisdictional determination (JD). In order to perform a jurisdictional determination, they will require a plan; they will not perform speculative JDs. A plan can be a clear, simple drawing.\nBecause of demand and limited staffing, US Army Corps personnel may not visit your site as soon as you would like. Although the permit is free, the time required may exceed your expectations. If you need a wetland determination faster that the Army Corps can provide a jurisdictional determination, you may need to hire someone to help you through the process. The Army Corps web site provides a list of consultants who request listing (653k .pdf file updated October 2013).\nVisit the US Army Corps informative web site: Do I Need a Permit?\nWhat Is A Wetland?\nThere are two terms used: wetland and upland, upland is used to mean the opposite of wetland. In the Cook Inlet area, any place where the water table is within about a foot of the surface for more than a couple of weeks of the growing season for more than half of all years generally qualifies as a wetland under the jurisdiction of section 404 [http://cookinletwetlands.info/Downloads/sec404.htm] of the Clean Water Act of 1974. The major exception is where the wetland is surrounded by upland- i.e. not connected to Cook Inlet or another navigable-in-fact water body through other wetlands, lakes, or streams. Wetlands that are surrounded by uplands were considered jurisdictional until about 2001, and they may again become jurisdictional. In sandy soils the water table needs to be closer to the surface, about six inches, for a couple of weeks of the growing season. In the absence of a site visit, the growing season can be defined using the 50% probability of the temperature being 28 degrees F or higher in a report generated at a Natural Resources Conservation Service Water and Climate Center website that uses climate data specific to the site of interest. The growing season can also be defined during a site visit based on the emergence of green plants, at the beginning, and when plants turn brown and deciduous trees drop their leaves, at the end. Very generally, the beginning is often around the first of May, and the end around the first of October in the Cook Inlet Lowlands.\nHow Do I Identify a Wetland?\nSome wetlands are tricky to identify, especially those that barely meet the requirements described above. For example, if a site supporting a water table 8 inches below the surface for three weeks of the growing season is visited outside of those three weeks, wetland determination might be perplexing. Wetlands mapped with the map unit WU [http://cookinletwetlands.info/Ecosystems/WU.html] and in the Discharge Slope [http://cookinletwetlands.info/Ecosystems/DischargeSlope.html] Ecosystem can be the most difficult to accurately identify.\nIf a site is included on either the GoogleEarth [http://cookinletwetlands.info/Downloads/GoogleEarthDownloads.html] or Kenai Borough Parcel Viewer [http://www2.borough.kenai.ak.us/GISDept/ags.html] map that you may have used to get to this page, it still might not meet jurisdictional criteria. Wetlands mapped as Depressions [http://cookinletwetlands.info/Ecosystems/Depression.html] or Spring Fens [http://cookinletwetlands.info/Ecosystems/SpringFen.html] are the primary examples of sites that may not meet jurisdictional criteria. On the other hand, A SITE NOT ON THE MAP MAY STILL MEET JURISDICTIONAL CRITERIA AND REQUIRE A PERMIT. Although every effort is made to map all of the wetlands that meet jurisdictional criteria, the maps are simply good guides, not the final word.\nMost wetlands are straightforward to identify. A few key technical characteristics help identify difficult wetlands outside of the period when a seasonally high water table is not close to the surface, for example during late July during a drier-than-average year. The plants and soils present are most important, although some other clues might indicate a seasonally high water table. The full procedures for identifying jurisdictional wetlands in Alaska are described in the 2007 Alaska Regional Supplement and the 1987 Wetland Delineation Manual. These extensive technical manuals include procedures and data sheets to help determine whether or not a site is a jurisdictional wetland. The procedures require significant technical experience identifying soil, plant, and hydrologic indicators.\nDOWNLOADS: Mapping files and literature\nTECHNICAL RESOURCES: Wetland mapping metadata, delineation manuals, Plant indicator status, Hydric soil indicators","The Department of State Lands issues two types of permits and authorizations:\n- Removal-fill permits for removal or fill activity in waterways and wetlands\n- Proprietary waterway authorizations for use of state-owned waterways\nRemoval-fill activity on state-owned waterways requires both.\nThe information on this webpage pertains to removal-fill permits only. For information on obtaining a waterway authorization (for a dock, floating home or marine industrial facility for example), go to the Use of State-Owned Waterways page.\nOregon's Removal-Fill Law (ORS 196.795-990) requires people who plan to remove or fill material in wetlands or waterways to obtain a permit from the Department of State Lands. This permit is broadly referred to as the “Removal-Fill Permit.” The law applies to all landowners, whether private individuals or public agencies.\nThe purpose of the law, enacted in 1967, is to ensure protection and the best use of Oregon’s water resources for home, commercial, wildlife habitat, public navigation, fishing and recreational uses.\nIn most cases, a permit is required if an activity will involve filling or removing 50 cubic yards or more of material in a wetland or waterway. For activities in state-designated Essential Salmonid Habitat, State Scenic Waterways and compensatory mitigation sites, a permit is required for any amount of removal or fill.\nRemoval-Fill Guide: Detailed information on process, timelines and requirements\nThe Removal-Fill Guide is designed to help applicants understand the process, timelines and other important topics related to the Department of State Lands' administration of Oregon's Removal-Fill Law. It is organized into nine chapters:\n- Chapter 1: Working with the Aquatic Resource Management Program\n- Chapter 2: When is a Permit Required?\n- Chapter 3: What Activities are Exempt?\n- Chapter 4: Planning Ahead\n- Chapter 5: How to Apply for a Permit\n- Chapter 6: Processing the Removal-Fill Permit Application\n- Chapter 7: Emergency Permits\n- Chapter 8: Compensatory Mitigation Planning for Wetlands and Tidal Waters\n- Chapter 9: Monitoring the Compensatory Wetland Mitigation Site\nThe guide addresses existing laws and rules governing removal-fill activities in Oregon, and provides practical tips for complying with Department of State Lands' regulations. It explains agency practices, but does not take the place of or override regulations. The reader is cautioned to consult agency regulations first, and to rely on this guide to help understand those regulations and complete permit applications. Consultation with agency staff early in the project's development is strongly encouraged.\nRemoval-Fill Guide December 2016\nTo navigate the document more easily, be sure to use “bookmarks” in Adobe Reader.\nPlease note: Guide updates are made on a periodic basis. If you print or save this guide to your own computer, be sure to periodically check this website to make sure you are using the most recent version of the guide. The current version date is posted on the lower left corner of the Guide cover page.\nWorking with the Aquatic Resource Management Program\nThe Department of State Lands is organized into three programs: Aquatic Resource Management, Business Operations and Support Services, and Common School Fund Property. In addition, DSL oversees the South Slough National Estuarine Research Reserve in Charleston in partnership with the National Oceanic and Atmospheric Administration (NOAA).\nThe removal-fill permit program is administered by the Aquatic Resource Management Program (ARM) whose mission is to conserve and protect waters of the state, including wetlands. The program provides a variety of services, including wetland determinations, wetland delineation report review, responding to wetland land use notices, conducting pre-application meetings, and providing assistance for removal-fill permit application processing.\nThe Aquatic Resource Management Program is organized in five regional teams: Metro, Northwest, Midwest, Southwest and Eastern. Each team is comprised of:\n- Aquatic Resource Coordinator responsible for removal-fill permitting activities.\n- Jurisdictional Coordinator responsible for preparing wetland determinations and reviewing wetland delineation reports.\n- Proprietary Coordinator responsible for authorizing activities on state-owned waterways.\nRemoval-Fill Guide: Chapter 1 – Working with the Aquatic Resource Management Program\nWhen is a permit required?\nOregon's Removal-Fill Law (ORS 196.795-990) requires any person who plans to \"remove or fill\" material within \"waters of the state\" to obtain a permit from the Department of State Lands. Removal means taking rock, gravel, sand, silt, other inorganic substances, and large woody debris from the bed or banks of a waterway, or their movement by artificial means within the bed or banks, including channel relocation. Fill means the deposit by artificial means of any material (organic or inorganic) at any one location in the bed or banks. Waters of the state include wetlands on private and public land.\nTypes of \"waters of the state\" and jurisdictional limits:\n- Pacific Ocean: extreme low tide to 3 miles out\n- Tidal Bays and Estuaries: highest measured tide or upper edge of wetland\n- Perennial Streams, Lakes and Ponds: to ordinary high water\n- Intermittent Streams: to ordinary high water\n- Wetlands: wetland boundary as determined by delineation report\n- Artificial Ponds and Ditches: ordinary high water\n- Artificial Wetlands: wetland boundary\n- Reservoirs: normal operating pool level or upper edge of adjacent wetland\nFor most waters, a permit is required if a project will involve 50 cubic yards of fill and/or removal (cumulative) within the jurisdictional boundary. For activities in designated Essential Salmonid Habitat waters, State Scenic Waterways and designated compensatory mitigation sites, a permit is required for any amount of removal or fill. Removal is calculated on an annual basis. Fill is calculated on a cumulative basis.\nRemoval-Fill Guide: Chapter 2 - When is a Permit Required?\nSome activities in waters of the state are exempt from permit requirements of the Removal-Fill Law. Unless otherwise stated, the exemptions do not apply to State Scenic Waterways.\nEach exemption has specific side boards and limitations. It is important to thoroughly review the exemptions before assuming an activity is exempt. You are strongly encouraged to contact an Aquatic Resource Coordinator for help in understanding these exemptions.\nExempt activities include:\n- State Forest Management Practices\n- Fills for Construction, Operation and Maintenance of Hydroelectric Dams and Water Diversion Structures\n- Navigational Servitude (Maintenance of the Navigational Channel)\n- Maintenance or Reconstruction of Water Control Structures\n- Maintenance or Emergency Reconstruction of Roads and Transportation Structures\n- Prospecting and Non-Motorized Activities within Essential Salmon Habitat and State Scenic Waterways\n- Fish Passage and Fish Screening Structures in Essential Indigenous Anadromous Salmonid Habitat (ESH)\n- Change in Point of Diversion for Surface Water\n- Certain Removal of Large Wood Debris\n- Certain Voluntary Habitat Restoration Activities\n- Agricultural Exemptions\n- Special Situations: Railroads, Tribal Lands and Environmental Remedial Actions\nRemoval-Fill Guide: Chapter 3 – What Activities are Exempt?\nA well-planned project will result in an easier and faster permitting process. Important steps in the planning process include:\nIdentifying regulated waters on the project site. Early identification of regulated waters and their jurisdictional boundaries is essential for informed project planning. National and local wetland maps are helpful tools for early identification of wetlands, but they are not conclusive. While lakes and rivers are easily identifiable, regulated intermittent streams, channelized streams, ditches and ponds can be more difficult, and require additional investigation.\nRetaining professional consultant services. Most projects involving wetlands and waterways require the technical expertise of wetland or environmental consultants to determine wetland boundaries, prepare functional assessments and develop mitigation plans.\nExploring alternatives to avoid and minimize impacts. Applications for removal fill permits must include a consideration of alternative sites, designs and construction methods showing that the proposed project is the practicable alternative with the least impact to wetlands and waterways.\nPlanning to mitigate for unavoidable impacts. If some impacts to wetlands or waterways are unavoidable, the applicant must propose mitigation to replace the functions and values lost as a result of the project.\nPre-design permit scoping. Most projects in wetlands and waterways require approval from several local, state and federal agencies. Early identification of all the permits and their requirements is essential to avoid costly redesign and project delays.\nPre-application meetings. The Department offers pre-application meetings to assist applicants in planning ahead for a smooth permitting process.\nRemoval-Fill Guide: Chapter 4 – Planning Ahead\nHow to apply for a permit\nThere are four types of permits available to conduct work in wetlands and waterways:\nIndividual Permits (IPs) are issued for projects that:\n- Have more than minimal adverse effects to waterways and wetlands\n- Are more complicated and often involve more than one removal-fill activity\n- May involve a substantial mitigation obligation\n- Do not qualify for any of the General Authorizations or General Permits\nIP applicants use the Joint Permit Application. The processing timeline is up to 120 days.\nGeneral Authorizations (GAs) are an expedited process for nine specific types of removal-fill activities that have minimal adverse effects on wetlands and waterways:\n- Certain Minimal Disturbance Activities within Essential Salmon Habitat (ESH)\n- Piling Placement and Removal within ESH\n- Temporary Impacts to Non-Tidal Wetlands\n- Waterway Bank Stabilization\n- Certain Transportation-Related Activities\n- Removing and Disposing of Sediment Behind Tidegates and within Hydraulically Closed Perimeters\n- Waterway Habitat Restoration\n- Wetland Ecosystem Restoration\n- Recreational Placer Mining\nGA applicants use the General Authorization Notification Form. The processing timeline is up to 30 days.\nGeneral Permits (GPs) authorize a group of activities that are substantially similar in nature, recurring or ongoing, and have predictable effects and outcomes. There are currently five GPs available for use by the public:\n- Transportation-Related Structures\n- Minor Removal-Fill Impacts to Certain Non-Tidal Wetlands\n- Impacts to Vernal Pool Wetlands and Other Waters of the State in Jackson County, Oregon\n- Maintaining Drainage to Protect Agricultural Land\n- Navigational Access Maintenance Dredging\nGP applicants use the Joint Permit Application. The processing timeline is up to 40 days for most GPs.\nEmergency Permits (EPs) are rapid-approval authorizations for emergencies that pose a direct threat to human health, safety or substantial property, and where prompt removal-fill action is required to address the threat.\nEP applicants use the Emergency Permit Application. Approval is given as quickly as possible in emergency situations.\nRemoval-Fill Guide: Chapter 5 – How to Apply for a Permit\nProcessing the application\nGeneral Authorization Notifications\nThe Department reviews the GA notification within 30 days of receipt to confirm that it is complete and eligible.\nIndividual Permit and General Permit Applications\nStep 1: Application Completeness Review: (up to 30 days for IPs/up to 15 days for GPs) The application is reviewed for completeness and applicable permit type. A completeness review letter is sent to the applicant documenting the review. If the application is deemed incomplete, a new complete application is required.\nStep 2: Public Review Period: (30 days for IPs/15 days for GPs) If the application is complete, the public review period is initiated. A notice is sent to other agencies, adjacent property owners and other parties inviting comment on the application.\nStep 3: Final Review: (up to 60 days for IPs/up to 10 days for GPs) Comments relevant to the decision-making process are considered. The applicant is invited to address relevant comments and any unresolved technical issues by providing additional information or revising the project.\nStep 4: Permit Decision: The entire record is evaluated against the criteria for permit issuance and a permit is approved or denied. If more time is needed to address issues, the applicant may request an extension of the decision deadline.\nPermit Renewal and Transfer\nPermits may be issued for up to five years and may be renewed upon request. Before an IP expires, DSL will notify the permittee of the opportunity to renew the permit. Most GAs are issued for three years and are not renewable. Most GPs are issued for five years and are not renewable.\nModifying the Permit\nModification of an Individual Permit or a General Permit may be requested by the permittee or initiated by the Department.\nSpecial Permit Situations\nBy law, projects governed by the Corrections Facilities Siting Authority, Environmental Quality Commission pertaining to solid waste landfills, Energy Facility Siting Council and the Economic Recovery Review Council follow a removal-fill permit process that is different than the standard IP process.\nA permit or authorization decision may be appealed by the applicant or third parties that are “aggrieved” or “adversely affected” by the authorization decision. Applicants may appeal an incompleteness determination. Appeals are adjudicated through the contested case hearing process.\nRemoval-Fill Guide: Chapter 6 – Processing the Removal-Fill Permit Application\nWithin the context of the Removal-Fill Law, an emergency is a natural or human-caused circumstance that poses an immediate threat to public health, safety or substantial property, including cropland. If the actions necessary to alleviate the threat involve 50 cubic yards or more of removal or fill below a waterway’s ordinary high water elevation or in wetlands (or any amount of removal or fill in designated Essential Salmon Habitat (ESH) or a State Scenic Waterway (SSW) a DSL permit is required and may be authorized as an expedited emergency permit (EP).\nDSL applies all of the following considerations to assess whether an activity in wetlands or a waterway is eligible for an Emergency Permit (EP):\n- Does the nature of the threat allow enough time to obtain some other form of permit or is prompt action required to reduce or eliminate the threat?\n- Does the emergency pose a direct threat to public health or safety or substantial property, including but not limited to a dwelling, transportation structure, farm or cropland?\n- Is the proposed project the minimal amount necessary to reduce or eliminate the threat and does it minimize, to the extent practicable, adverse impacts to wetlands and waterways?\nProcedure for Obtaining an Emergency Permit\nStep 1: The applicant must collect information including location; nature and cause of the threat; the condition of the waterway; and what action is necessary to alleviate the immediate threat. Remedial actions must be limited to what is necessary to make repairs or prevent irreparable harm, injury or damage to persons or property.\nStep 2: Contact DSL to initiate the energy permit process.\n- During Business Hours: 503-986-5200 (west of the Cascades) 541-388-6112 (east of the Cascades)\n- After Business Hours: Oregon Emergency Response: 1-800-452-0311\nStep 3: Submit the energy permit application materials as directed by the DSL Aquatic Resource Coordinator and as time allows. If time allows, DSL may conduct a site visit or ask another designated agency to do so.\nStep 4: Qualifying activities will be issued a written permit as soon as key information is provided. DSL can issue a verbal approval in advance of the written approval where it is necessary to protect public health, safety or property.\nAfter the emergency, DSL staff may visit the site upon completion of the emergency work, and may require that the project be modified after the initial emergency work is completed or require mitigation to compensate for any impacts to the affected wetland or waterway. A subsequent permit may be required to conduct remedial work.\nRemoval-Fill Guide: Chapter 7 – Emergency Permits\nYou may wish to hire a private consultant who specializes in wetlands and waterways regulation to assist you with conducting a wetland delineation and/or removal-fill permit application and mitigation plan. Information to help you hire a qualified wetland consultant may be found in the Wetlands in Oregon fact sheet.\nMany wetland professionals working in Oregon are certified as a Professional Wetland Scientist (PWS) or Wetland Professional in Training (WPIT) by the Society of Wetland Scientists’ Professional Certification Program. To be certified as a PWS or WPIT, a person must meet education and experience requirements, and adhere to a code of ethics and professional practice.\nRemoval-Fill Guide: Chapter 4 – Planning Ahead\nTopics of interest"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:3d92f0fa-b7c7-4b84-b6b5-1580f0886786>","<urn:uuid:5a7427fc-16c6-434d-a8cb-6c7c5371b660>"],"error":null}
{"question":"Did Conrad Hal Waddington pass away before or after James Taylor?","answer":"Conrad Hal Waddington passed away much earlier than James Taylor. Waddington died on September 26, 1975 in Edinburgh, Scotland, while James Taylor passed away on April 2, 2020.","context":["- Open Access\nIn memory of James Taylor: the birth of Galaxy\nGenome Biology volume 21, Article number: 105 (2020)\nJames Peter Taylor, the Ralph S. O’Connor Professor of Biology and Computer Science at Johns Hopkins University (JHU), passed away on April 2, 2020. He was 40 years old. James was an exceptional scientist, colleague, mentor, and community builder, who worked at the intersection of biology and computer science. His life’s pursuit was to understand how genomic and epigenomic information is processed during normal development and dysregulated in disease. As co-leader of the Galaxy (http://galaxyproject.org)  and AnVIL (http://anvilproject.org) Projects, a major thrust of James’ career aimed to support the work of others, especially to empower those with limited resources. His impact was broad, as innumerable scientists worldwide benefited from his leadership, mentoring, and scientific contributions.\nJames completed a BS. in Computer Science (Magna Cum Laude) at the University of Vermont in 2000. After spending 3 years as a senior software engineer in Vermont, he joined the Ph.D. program in Computer Science at the Pennsylvania State University in the Center for Comparative Genomics and Bioinformatics under the supervision of Professors Webb Miller and Francesca Chiaromonte. His Ph.D. work focused on developing novel machine learning approaches for identifying functional elements in the genome , leveraging the wealth of new data from ENCODE (https://www.encodeproject.org/) and the alignments of newly assembled vertebrate genomes .\nCreating the Galaxy\nDuring this time at Penn State, James worked closely with me (Anton Nekrutenko) and others to start the Galaxy Project, a comprehensive web platform for open and reproducible computational data analysis. The first software commit to the project repository was on June 1, 2005, by James. Today, Galaxy needs no introduction to anyone working in genomics, but at the time was a major advance above the ad hoc command line bioinformatics analysis that dominated the field. The initial version introduced support for accessing remote data resources and visualizing the results . The project grew to incorporate thousands of analysis tools into one unified graphical user interface, accessible to anyone via a web browser. The Galaxy Project remains a landmark achievement and has forever changed the way scientists analyze and share data.\nAfter completing his Ph.D. in 2006, James worked for 2 years as a visiting member of the Courant Institute for Mathematical Sciences at New York University. During these 2 years, Galaxy became one of his principal projects as James coded several of its iconic features, including the three-pane interface, the “noodly” workflow editor, and the dynamic genome browser Trackster. In 2008, James started his laboratory at Emory University in the Department of Biology and the Department of Mathematics & Computer Science. He was promoted to Associate Professor with tenure in 2013, shortly before his move to JHU where he was promoted to Professor in 2018.\nIt was at Emory University, and later JHU, where the Galaxy platform exploded in popularity, driven by the growth of high-throughput sequencing data and large-scale cloud computing. This combination of technologies has proven to be transformative to the field, and the Galaxy Project has reached a wide audience of scientists evidenced by thousands of citations. Today, thousands of scientists around the world use Galaxy daily.\nThe Galaxy Project is not only a software platform but also a scientific community. James’ dedication to accessible, reproducible, and transparent research promoted a community of researchers that extended far beyond the original development team. Scientists, often working completely independently from the founders, have taken Galaxy into entire new research domains. The strength of the Galaxy community is also seen every year at the community-run conference that brings hundreds of participants together to share their latest contributions and applications.\nJames was an ardent and principled advocate for open science, especially open access to scientific data and open-source software. James said that software may come and go, including even Galaxy, but the metadata that Galaxy collects will ultimately be his most valuable contribution to science. This metadata enables anyone to observe all analysis steps and reproduce entire analyses, providing the bedrock for future discoveries. Without such transparency and rigor, he explained, the entire field will suffer.\nBeyond the Galaxy\nWhile James is widely known for his development of the Galaxy Project, he made numerous other contributions to science and education. James collaborated with many experimentalists to analyze Hi-C data and interrogate the 3D organization of the genome. At Emory, James worked to understand how DNA-binding proteins shape nuclear architecture as cell fates are specified . At JHU, James collaborated to decipher the mechanisms of the mysterious “A” and “B” compartmentalization of the genome in relation to the nuclear lamina . He applied his knowledge of the genome to identify “buttons” that promote gene regulation between chromosomes . James’ curiosity and collegiality led to new scientific directions as he evaluated ribosome profiling data to identify A and P sites , analyzed long-read transcriptome data to characterize development in worms , and interpreted transcriptome data from human retinal organoids to understand how our eyes develop , among many other projects. No matter the question, approach, or organism posed to him, James was always up for a new scientific challenge.\nJames’ love of science was matched by his passion for teaching. At JHU, he completely transformed and revitalized the curriculum within the graduate biology program to require training in computational and quantitative research for all Ph.D. students. This was rooted in his recognition that all subfields of biology are increasingly data-rich and quantitative. For many of the students, James’ “boot camp” was their first introduction to such techniques; as with a military boot camp, the students were left mentally and physically exhausted at the end of the day. Ultimately, however, they all appreciated how it made them stronger and more empowered scientists. James’ passion for teaching extended to the annual Computational Genomics course at Cold Spring Harbor Laboratory that he co-taught with David Hawkins and William Pearson.\nGalaxy, and every aspect of James’ life, benefited tremendously from James’ leadership style. Rather than an authoritarian top-down approach, he led by example, contributing code and technical oversight with exceptional mastery and precision. While he generally had a laid back personality, he was always willing to fight for his students, friends, and colleagues. Whenever I (Schatz) felt stuck about a particular administrative or logistical issue, James fired back about how the university administration should support us even more. I also knew that whenever I was not in the room, he would be there to advocate for me on my behalf. He offered these gifts to everyone, which promoted deep friendships and community for all of us around him.\nThank you James\nJames was always kind, friendly, and generous, and we will miss him dearly. He is survived by his wife Meredith Greif, a sociology professor also at Johns Hopkins. We all will strive to carry on his vision in his absence.\nIf we could talk with him one last time, we would say: Thank you, James, on behalf of your community, for being a friend, a leader, a colleague, a mentor, a student, a scientist, a programmer, and an advocate. Thank you for embracing your bioinformatics community and sharing resources in the spirit of accessibility and scientific progress. Thank you for sharing your strengths in selfless ways and for dedicating your life’s work to further scientific research in genomics and beyond. Thank you for caring, participating, and leading the way. You leave behind many teams and communities, many people who worked on the things that you started, and many who thought that they would have more time to work with you on projects and reach new scientific heights. Please know that we will go forward and continue what you started, keeping you close, building on your work, and expanding on the many foundations that you provided. We will try to be better friends, leaders, colleagues, mentors, students, scientists, and advocates for each other, because we know, through your work and your many examples, that this is what you wanted us to do.\nGoecks J, Nekrutenko A, Taylor J, Galaxy Team. Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences. Genome Biol. 2010;11:R86.\nTaylor J, Tyekucheva S, King DC, Hardison RC, Miller W, Chiaromonte F. ESPERR: learning strong and weak signals in genomic sequence alignments to identify functional elements. Genome Res. 2006;16:1596–604.\nMiller W, Rosenbloom K, Hardison RC, Hou M, Taylor J, Raney B, et al. 28-way vertebrate alignment and conservation track in the UCSC Genome Browser. Genome Res. 2007;17:1797–808.\nGiardine B, Riemer C, Hardison RC, Burhans R, Elnitski L, Shah P, et al. Galaxy: a platform for interactive large-scale genome analysis. Genome Res. 2005;15:1451–5.\nPhillips-Cremins JE, Sauria MEG, Sanyal A, Gerasimova TI, Lajoie BR, Bell JSK, et al. Architectural protein subclasses shape 3D organization of genomes during lineage commitment. Cell. 2013;153:1281–95.\nZheng X, Hu J, Yue S, Kristiani L, Kim M, Sauria M, et al. Lamins organize the global three-dimensional genome from the nuclear periphery. Mol Cell. 2018;71:802–15.e7.\nViets K, Sauria MEG, Chernoff C, Rodriguez Viales R, Echterling M, Anderson C, et al. Characterization of button loci that promote homologous chromosome pairing and cell-type-specific interchromosomal gene regulation. Dev Cell. 2019;51:341–56.e7.\nMartens AT, Taylor J, Hilser VJ. Ribosome A and P sites revealed by length analysis of ribosome profiling data. Nucleic Acids Res. 2015;43:3680–7.\nRoach NP, Sadowski N, Alessi AF, Timp W, Taylor J, Kim JK. The full-length transcriptome of C. elegans using direct RNA sequencing. Genome Res. 2020;30:299–312.\nEldred KC, Hadyniak SE, Hussey KA, Brenerman B, Zhang P-W, Chamling X, et al. Thyroid hormone signaling specifies cone subtypes in human retinal organoids. Science. 2018;362. https://doi.org/10.1126/science.aau6348.\nWe would like to thank Alexis Battle, Jeremy Goecks, Robert Johnston, Ben Langmead, Jeff Leek, Rajiv McCoy, Kelly Moffat, and the Galaxy team for their careful edits and suggestions. We would also like to thank the entire bioinformatics community for their outpouring of support.\nThe authors declare that they have no competing interests.\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\nRights and permissions\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.\nAbout this article\nCite this article\nNekrutenko, A., Schatz, M.C. In memory of James Taylor: the birth of Galaxy. Genome Biol 21, 105 (2020). https://doi.org/10.1186/s13059-020-02016-0","Conrad Hal Waddington\n|Birthplace:||Evesham, Worcestershire, UK|\n|Death:||Died in Edinburgh, City of Edinburgh, UK|\n|Managed by:||Carlos Federico (Cantarito) Bung...|\nMatching family tree profiles for Conrad Hal Waddington\nAbout Conrad Hal Waddington\nFrom Wikipedia, the free encyclopedia\nConrad Hal Waddington Born 8 November 1905 Evesham, Worcestershire, England Died 26 September 1975 Edinburgh, Scotland\nFields Developmental biology, Genetics, Paleontology Institutions Cambridge University, Christ's College University of Edinburgh Wesleyan University Centre for Human Ecology Alma mater Cambridge University Known for Epigenetic landscape, canalisation, homeorhesis, genetic assimilation, chreod Influences Alfred North Whitehead Influenced Jean Piaget, Sanford Kwinter, Gregory Bateson, Margaret Mead\nConrad Hal Waddington CBE FRS FRSE (1905–1975) was a developmental biologist, paleontologist, geneticist, embryologist and philosopher who laid the foundations for systems biology. He had wide interests that included poetry and painting, as well as left-wing political leanings.\n* 1 Life * 2 Epigenetic landscape * 3 Waddington as an organiser * 4 References * 5 Selected works o 5.1 Books o 5.2 Papers * 6 External links\nWaddington, known as \"Wad\" to his friends and \"Con\" to family, was born to Hal and Mary Ellen (Warner) Waddington, 8 November 1905. Until nearly three years of age, Waddington lived with his parents in India, where his father worked on a tea estate in the Wayanad district. In 1910, at the age of four, he was sent to live with family in England including his aunt, uncle, and Quaker grandmother. His parents remained in India until 1928. During his childhood, he was particularly attached to a local druggist and distant relation, Dr. Doeg. Doeg, who Waddington called \"Grandpa\", introduced Waddington to a wide range of sciences from chemistry to geology. During the year following the completion of his entrance exams to university, Waddington received an intense course in chemistry from E. J. Holmyard. Aside from being \"something of a genius of a [chemistry] teacher,\" Holmyard introduced Waddington to the \"Alexandrian Gnostics\" and the \"Arabic Alchemists.\" From these lessons in metaphysics, Waddington first gained an appreciation for interconnected holistic systems. Waddington reflected that this early education prepared him for Alfred North Whitehead's philosophy in the 1920s and 30s and the cybernetics of Norbert Wiener and others in the 1940s.\nHe attended Clifton College and Sidney Sussex College, Cambridge. He took the Natural Sciences Tripos, earning a First in Part II in geology in 1926. He took up a Lecturership in Zoology and was a Fellow of Christ's College until 1942. His friends included Gregory Bateson, Walter Gropius, C. P. Snow, Solly Zuckerman, Joseph Needham, and J. D. Bernal. His interests began with palaeontology but moved on to the heredity and development of living things. He also studied philosophy.\nDuring World War II he was involved in operational research with the Royal Air Force and became scientific advisor to the Commander in Chief of Coastal Command from 1944 to 1945. After the war he became Professor of Animal Genetics at the University of Edinburgh. He would stay at Edinburgh for the rest of life with the exception of one year (1960–1961) when he was a Fellow on the faculty in the Center for Advanced Studies at Wesleyan University in Middletown, Connecticut. His personal papers are largely kept at the University of Edinburgh library.\nWaddington was married twice. His first marriage produced a son, C. Jake Waddington, professor of physics at the University of Minnesota, but ended in 1936. He then married Justin Blanco White, daughter of the writer Amber Reeves, with whom he had two daughters, mathematician Dusa McDuff and anthropologist Caroline Humphrey.\nIn the early 1930s, Waddington and many other embryologists looked for the molecules that would induce the amphibian neural tube. The search was, of course, beyond the technology of that time, and most embryologists moved away from such deep problems. Waddington, however, came to the view that the answers to embryology lay in genetics, and in 1935 went to Thomas Hunt Morgan's Drosophila laboratory in California, even though this was a time when most embryologists felt that genes were unimportant and just played a role in minor phenomena such as eye colour.\nIn the late 30's, Waddington produced formal models about how gene regulatory products could generate developmental phenomena, showed how the mechanisms underpinning Drosophila development could be studied through a systematic analysis of mutations that affected the development of the Drosophila wing (this was the essence of the approach that won the 1995 Nobel prize in medicine for Christiane Nüsslein-Volhard and Eric F. Wieschaus). In a period of great creativity at the end of the 1930s, he also discovered mutations that affected cell phenotypes and wrote his first textbook of developmental epigenetics, a term that then meant the external manifestation of genetic activity.\nWaddington also coined other essential concepts, such as canalisation, which refers to the ability of an organism to produce the same phenotype despite variation in genotype or environment. He also identified a mechanism called genetic assimilation which would allow an animal’s response to an environmental stress to become a fixed part of its developmental repertoire, and then went on to show that the mechanism would work. He thus demonstrated that the ideas of inheritance put forward by Jean-Baptiste Lamarck could, in principle at least, occur.\nIn 1972, Waddington founded the Centre for Human Ecology.\nWaddington's epigenetic landscape is a metaphor for how gene regulation modulates development. One is asked to imagine a number of marbles rolling down a hill towards a wall. The marbles will compete for the grooves on the slope, and come to rest at the lowest points. These points represent the eventual cell fates, that is, tissue types. Waddington coined the term Chreode to represent this cellular developmental process. This idea was actually based on experiment: Waddington found that one effect of mutation (which could modulate the epigenetic landscape) was to affect how cells differentiated. He also showed how mutation could affect the landscape and used this metaphor in his discussions on evolution—he was the first person to emphasise that evolution mainly occurred through mutations that affected developmental anatomy.\nWaddington as an organiser\nWiki letter w cropped.svg This section requires expansion.\nWaddington was very active in advancing biology as a discipline. He contributed to a book on the role of the sciences in times of war, and helped set up several professional bodies representing biology as a discipline.\nA remarkable number of his contemporary colleagues in Edinburgh became Fellows of the Royal Society during his time there, or shortly thereafter.\nWaddington was an old-fashioned intellectual who lived in both the arts and science milieus of the 1950s and wrote widely. His 1960 book \"Behind Appearance; a Study Of The Relations Between Painting And The Natural Sciences In This Century\" (MIT press) not only has wonderful pictures but is still worth reading.\nWaddington was, without doubt, the most original and important thinker about developmental biology of the pre-molecular age and the medal of the British Society for Developmental Biology is named after him.\n1. ^ Robertson, Alan. 1977. \"Conrad Hal Waddington. 8 November 1905–26 September 1975.\" Biographical Memoirs of Fellows of the Royal Society 23, 575-622. Pp. 575-76. 2. ^ Waddington, C. H. 1975. The Evolution of an Evolutionist. Ithica, NY: Cornell University Press. Pg. 2. 3. ^ Robertson, Alan. 1977. \"Conrad Hal Waddington. 8 November 1905 — 26 September 1975.\" Biographical Memoirs of Fellows of the Royal Society 23, 575-622. Pg 577. 4. ^ Robertson, Alan. 1977. \"Conrad Hal Waddington. 8 November 1905 — 26 September 1975.\" Biographical Memoirs of Fellows of the Royal Society 23, 575-622. Pp. 579-580. 5. ^ Yoxen, Edward. 1986. \"Form and Strategy in Biology: Reflections on the Career of C. H. Waddington.\" In A History of Embryology, edited by T. J Horder, J. A Witkowski, and C. C Wylie. Cambridge: Cambridge University Press. Pp. 310-11. 6. ^ \"Guide to the Center for Advanced Studies Records, 1958 - 1969\". Wesleyan.edu. http://www.wesleyan.edu/libr/schome/FAs/ce1000-137.html. Retrieved 2010-04-04. 7. ^ Robertson, Alan. 1977. Conrad Hal Waddington. 8 November 1905 — 26 September 1975. Biographical Memoirs of Fellows of the Royal Society 23, 575-622. P. 578 8. ^ Goldberg, A. D., Allis, C. D., & Bernstein, E. (2007). Epigenetics: A landscape takes shape. Cell, 128, 635-638. 9. ^  Hall BK. 2004. In search of evolutionary developmental mechanisms: the 30-year gap between 1944 and 1974. J Exp Zool B Mol Dev Evol. 2004 Jan 15;302(1):5-18. 10. ^ Robertson, Alan. 1977. Conrad Hal Waddington. 8 November 1905 — 26 September 1975. Biographical Memoirs of Fellows of the Royal Society 23, 575-622. P. 585.\nSelected works Books\n* Waddington, C. H. (1939). An Introduction to Modern Genetics. London : George Alien & Unwin Ltd. * Waddington, C. H. (1940). Organisers & genes. Cambridge: Cambridge University Press. * Waddington, C. H. (1941). The Scientific Attitude, Pelican Books * Waddington, C. H. (1946). How animals develop. London : George Allen & Unwin Ltd. * Waddington, C. H. (1953). The Epigenetics of birds. Cambridge : Cambridge University Press. * Waddington, C. H. (1956). Principles of Embryology. London : George Allen & Unwin. * Waddington, C. H. (1957). The Strategy of the Genes. London : George Allen & Unwin. * Waddington, C. H. (1959). Biological organisation cellular and subcellular : proceedings of a Symposium. London: Pergamon Press. * Waddington, C. H. (1960). The ethical animal. London : George Allen & Unwin. * Waddington, C. H. (1961). The human evolutionary system. In: Michael Banton (Ed.), Darwinism and the Study of Society. London: Tavistock. * Waddington, C. H. (1966). Principles of development and differentiation. New York: Macmillan Company. * Waddington, C. H. (1966). New patterns in genetics and development. New York: Columbia University Press. * Waddington, C. H., ed. (1968–72). Towards a Theoretical Biology. 4 vols. Edinburgh: Edinburgh University Press. * Waddington, C. H., Kenny, A., Longuet-Higgins, H.C., Lucas, J.R. (1972). The Nature of Mind, Edinburgh: Edinburgh University Press (1971-3 Gifford Lectures in Edinburgh, online) * Waddington, C. H., Kenny, A., Longuet-Higgins, H.C., Lucas, J.R. (1973). The Development of Mind, Edinburgh: Edinburgh University Press (1971-3 Gifford Lectures in Edinburgh, online) * Waddington, C. H. (1977) (published posthumously). Tools for Thought. London: Jonathan Cape Ltd.\n* Waddington C. H. 1942. Canalization of development and the inheritance of acquired characters. Nature 150:563-565. * Waddington, C. H. 1953. Genetic assimilation of an acquired character. Evolution 7: 118-126. * Waddington, C. H. 1953. Epigenetics and evolution. Symp. Soc. Exp. Biol 7:186-199. * Waddington, C. H. 1956. Genetic assimilation of the bithorax phenotype. Evolution 10: 1-13. * Waddington, C. H. 1961. Genetic assimilation. Advances Genet. 10: 257-290. * Waddington, C. H. 1974. A Catastrophe Theory of Evolution. Annals of the New York Academy of Sciences 231: 32-42.\n* NAHSTE Project Record of C.H. Waddington * Induction and the Origin of Developmental Genetics - works by Salome Gluecksohn-Schoenhimer and Conrad Hal Waddington * Epigenetics News\nConrad Hal Waddington's Timeline\nNovember 8, 1905\nEvesham, Worcestershire, UK\nSeptember 26, 1975\nEdinburgh, City of Edinburgh, UK"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:c36ce3b8-0819-4b42-8d69-84e94f023726>","<urn:uuid:c44521fb-90eb-4fb8-918d-e1e93a4530b0>"],"error":null}
{"question":"What inspired Farid Rueda's artistic development and how does he represent Mexican culture in his work?","answer":"Farid Rueda's artistic development was significantly influenced by his move to Xochimilco, México City at age nine, where he had greater access to galleries and art institutions. He studied at ENAP (National School for Visual Art) but left before graduating to focus on his personal expression. His entry into street art was encouraged by the artist Seher, with whom he later collaborated. Rueda's work is heavily influenced by Mexican culture, but he takes a unique approach to representing popular cultural elements without falling into clichés. His artistic influences are diverse, including artists like John Baizley, Stuntkid, James Jean, Alphonse Mucha, Gustav Klimt, and José de Ribera. He creates works that are tied to Mexican legends, verses, or famous sayings, but presents them in a fresh, innovative way that helps viewers appreciate cultural aspects they might have taken for granted.","context":["Mexico is a country with an extensively rich heritage and culture. People of this nation are very proud of their legacy and they have every right to be since their history is amongst the richest in the world. One such proud man is Farid Rueda, a Mexican street artist known for painting graffiti full of his country's cultural references. However, the way he depicts these themes is not what you would expect - Rueda figures out new concepts of representing Mexican popular culture without turning it into a cliché. He is primarily known for his murals and other large-scale pieces, but he has been known to paint smaller works as well.\nRueda was born in Morelos, officially titled as a Free and Sovereign State of Morelos. Mexican pride runs deep in these lands, so it's not surprising to see how much affection this artist has for his country. When young Farid turned the age of nine, his family moved to Xochimilco, México City. This was the crucial time for his development as this transit meant Rueda had much more art at his disposal - Xochimilco offered much more galleries and art institutions. He entered the famous ENAP (Escuela Nacional de Artes Plásticas or National School for Visual Art). Although he did learn a lot while studying at this university, Rueda ultimately decided he was not satisfied with the ENAP's program and made a tough choice to leave without graduating. This, however, meant he could completely devote to his personal expression full time without interference. At about that time when he was leaving ENAP, Farid met the famous artist Seher, who was the first one to encourage him towards pursuing a career in street art. In the beginning, he was a bit hesitant, but eventually said yes and teamed up with his new friend. They started working together on several projects and this can be identified as a true beginning of Farid Rueda's art. From then it was obvious that his career and style will be based on vivid colors. As was clued beforehand, Farid chose to paint elements of his country's culture and heritage, but only in a new way, uniquely his - yet still continually tied to some Mexican legend, verse or famous saying.\nThis young graffiti painter admits that he is very much influenced by such artists as John Baizley, Stuntkid, James Jean, Alphonse Mucha, Gustav Klimt and José de Ribera. As you can see, he finds inspiration in the most diverse styles and moments of art history. Farid Rueda uses various techniques when trying to achieve his artistic goals. Naturally, as is the case with many graffiti artists, he had to go through many mediums before he became effective at wall painting - he mastered acrylic oil painting, drawing, watercolors and engravings. All of the above helped Rueda while he was developing his own personal style - especially the masterful usage of color. A signature of Rueda's work is a technique of kaleidoscopic multicolored patterns. He is also very prone to changing and evolving artistically - an important feat by his opinion. The artist once stated: Painting a wall requires quick work and a constant artistic evolution. I don’t like to work on one piece more than five days, since I usually get bored very fast and my mind is already processing the next painting. Most recently, Rueda is dedicated to public space interventions, as well as Easel painting (a type of mid-size painting that is painted on an easel, as opposed to a fresco wall painting or miniature that are created sitting at a desk, but also on an angled support) and digital art, while at the same time he subsequently writes short stories that he also illustrates. It's easy to see just how much he got from the decision to leave ENAP and devote all his free time to creating all sorts of stuff.\nOver the course of the years, Rueda worked alongside some very famous fellow graffiti artists, such as the likes of Saner and LeSuperDemon. Combining styles of these visionaries made sure we got some extremely interesting results and pieces that were lucky enough to have the best out of every author combined inside them. No matter on which project Farid was working on, the main color characteristic was never brought to question. This is without a doubt his most renowned trademark. It should be noted that Farid Rueda is a part of the no-galleries wave and does not believe graffiti should ever be taken down and brought inside museums or such. It would be equal as destroying the pieces, as if you would amputate an arm and then expect it to continue living on. Such actions also destroy a vital part of graffiti identity - it changes its relationship with the viewers. Rueda once said: When my work is exhibited in galleries, people are instantly “programmed” to believe that what they see is art - even though sometimes they don’t understand it. It is different on the street, the critics are all over the world and artists get to connect with all of the viewers, beyond their tastes and knowledge in the matter and that is the biggest compliment in this line of work.\n[caption id=\"attachment_234535\" align=\"aligncenter\" width=\"855\"] Farid Rueda - Wings of destiny[/caption]\nSure, the main goal of Rueda's graffiti is to entertain both us and the artist, but we should not neglect giving credit to their national note. The things he paints are all well established and people instantly recognize them, but when we get used to them and know about them for all our lives, it's easy to start looking at them as redundant stereotypes. We stop appreciating them to the fullest, we start taking them for granted. However, when someone shows them to us in a different light, in an edition we 've never seen them in before, we kinda feel a little click happening inside us. We become aware of how much we need to take care of aspects that make us what we are. Rueda makes this happen to us - and in addition, he does this through some of the most visually impressive graffiti pieces we've seen in a long time.\nFeatured Image: Farid Rueda - Artist in front of his work - Photo Credits Farid Rueda\nAll Images © Farid Rueda"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:07e2c0d7-b2ca-467a-a730-d7db8ed3c5f5>"],"error":null}