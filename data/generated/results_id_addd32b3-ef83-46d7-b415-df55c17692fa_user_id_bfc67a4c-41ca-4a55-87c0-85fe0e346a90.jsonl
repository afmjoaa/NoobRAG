{"question":"What are the vaccination requirements and waiting periods for dogs at pet grooming salons compared to German Shepherd training clubs?","answer":"For pet grooming salons, dogs must have up-to-date vaccinations before being accepted, and new clients should wait a couple of weeks after shots while regular clients need to wait a couple of days. For puppies, they must have had their last set of shots at least a week before the appointment. At German Shepherd training clubs, puppies can only join after their 3rd DHPPI vaccination including leptospirosis, rabies (DHPPi + L+R), and kennel cough. Both establishments specifically require kennel cough vaccination, and proof of vaccinations must be presented.","context":["By CeCe Koplin\nThe daily routine in the grooming salon should include more than merely accepting as many dogs as possible, grooming them, and giving them back to their owners in stylish, fluffy cuts. Every groomer and support staff member must be well informed as to their roles in ensuring every pet is safe from disease.\nWhether your salon grooms a couple of dogs a day or sees 50 on a busy Saturday, just one sick dog can infect all of the others. In addition, if the salon is not thoroughly cleaned, the affected areas could continue to infect dogs visiting your shop for days.\nAs a groomer, you are responsible for the prevention of spreading contagious disease to pets groomed in your facility. The only way to accomplish this is for the salon to abide by strict policies. The policies should outline what pets will be accepted as well as a staff duty roster with guidelines for rigorous sanitation techniques. The guidelines should also include how your staff can protect themselves by washing hands, using gloves, and other methods designed to prevent them from contracting a zoonotic disease. Zoonotic diseases are spread from animal to human through contact with infected urine, feces, and bodily secretions or, in some cases, even breathing in infectious agents.\nDisease control begins long before you meet or even touch an owner’s pet. When your clients call in to make appointments, the client record must be reviewed to check that vaccinations are up to date. In addition to vaccination records, it is helpful to have the contact information of the veterinarian. As a courtesy, you could offer to call the veterinary clinic when the records show that the animal’s shots have expired. When you add a new client, make sure to inform the owner that she must bring her pet’s vaccination records or the pet will not be accepted.\nThere are several reasons to never accept a dog if he has had vaccinations that day. The dog will be unhappy after the veterinary visit, and he could experience tenderness or a reaction at the vaccination site, which could make the dog harder to groom. In some cases, the groomer might be blamed for symptoms of soreness or stress. Most importantly, the shots will need time to take effect and support the dog’s immune system. As mentioned above, your shop should have a defined policy regarding vaccination dates when scheduling appointments. For example, when you have a new client, the waiting period should be a couple of weeks after the shot. If your regular client is on time with the shots, then a couple of days after the vaccinations should be sufficient.\nThe age of the pet is also very important and should always be taken seriously. If the pet is a puppy or a senior, his resistance to infection might be lower than an adult dog’s. This is also the case with a pet that has had a recent surgery. In the case of a new puppy, your shop should have a policy that states puppies must have had the last set of shots at least a week before the appointment. Elderly animals more than 10 years old and pets with a surgery in the past week should have a release from their veterinarian.\nOnce the appointment has been set and the dog arrives at the salon, a staff person using a check-in list should speak with the pet owner and conduct an examination of the dog. When clients are allowed to drop and run, meaning a dog has not had a proper check in, the potential for problems in the salon arise.\nThe check-in examination should include looking for the following:\n- Visible signs of a possible\n- medical condition\n- Eyes – red, swollen eyes\n- Ears – red, tender to the touch,\n- and odoriferous\n- Rear – sores or leakage\n- Sensitive areas\n- Fleas or little black dots\n- of flea droppings\n- The condition of the coat\n- for grooming\nIf you recognize a sign that indicates the pet might be ill, you should never actually diagnose the problem. Instead, simply state you recognize there may be something out of the norm and recommend that the owner seek the assistance of a veterinarian. Most owners become very concerned when they did not detect a problem with their pet, so be gentle. The discussion with clients should be discreet to not embarrass them.\nIf you noticed any cautionary signs that a pet might be ill, be sure that all affected areas in the salon are disinfected afterwards. The fewer areas they are exposed to the better. The reception check-in areas should be equipped with a cleaning kit that includes a spray bottle with a disinfecting solution (one part bleach to 30 parts water), paper towels, clean rags, and small garbage bags to contain waste.\nEach staff member’s daily routine should include cleaning procedures based on their area of responsibility. The groomers must keep their workstations clean by disinfecting used tools, wiping down their table, and disposing of all hair between each client session. The table base, floor, and nearby walls should also be wiped with the cleaning solution daily.\nThe bathers should follow the same tasks as above, as well as disinfecting the tub after each bath. It is important to have all cages, crates, and cage banks thoroughly disinfected between clients. In addition, all large containment units and equipment should have wheels or casters for easier cleaning beneath and behind them. Devices such as vacuum cleaners, clipper-vacuuming machines, and other tools that suck up hair should be emptied daily.\nThe reception area and the areas outside the entrance should also be cleaned daily. These areas are sometimes overlooked and can become marked and re-marked by your furry visitors.\nBy following these guidelines and instilling mandatory policies and procedures, you can ensure your salon is doing all it can to not share infectious diseases between pets.\nLead Grooming Program Manager\nAnimal Behavior College","Algoa Bay GSD Club offers specialized training for German\nshepherds in order to keep the dog’s body and mind stimulated and make use of\nthe full potential of your dog. German shepherds fall in the category of working\ndogs and if they are not exercised and worked they are likely to develop\ndestructive behavior out of boredom like digging up your garden or eating your\nfurniture. The training at Algoa Bay Club is geared towards helping your dog to\nbecome a balanced family protection dog. All protection work is done as a sport;\nwe do not offer home protection training or any kind of training to make dogs\nOur club training hours are every Saturday from 13:30 to about 17:00. Please\nnote that depending on the amount of participants classes can run longer or\nshorter and therefore we do not provide exact time tables for the classes.\nInformation is sent out via our club emailing list, so please make sure that you\nare added to the list once you have joined the club.\nWe welcome you to visit our training, so that you can get\na better impression whether the training we offer suits your needs. There is no\nobligation to join the club immediately. We actually encourage that you visit us\nat least 3 times before you join in order for you to be able to make a decision\nwhether our kind of training is the right one for you and your GSD. You can\nbring your puppy with you when the final vaccination has been administered after\n12 weeks. Please note that we require all dogs to be vaccinated against kennel\ncough so please contact your vet and check whether this vaccination has be done\nbefore bringing your dog to training.\nIf you have any questions, please contact one of our\ncommittee members, they will be more than willing to assist you. Our training is\nbased on a so- called “blue point plan”, which means that every dog has a career\nplan and via a blue point it can be tracked in which stage your dog currently\nis. Please address all general queries to email@example.com\nMobile (or Whatsapp)\n081 795 6631\nHow to join the club\nIn order for you to become a club member, you also have to\nbe a member of the German shepherd Dog Federation of South Africa, with which we\nare affiliated with. If you own a German shepherd that is registered on the\nbreed register, you apply for membership with both club and federation.\nThe secretary of the club will be able to provide you with\nmembership forms and all information regarding fees and membership rules. Club\nmembership fees are paid annually and include all training by the club.\nAdditional levies apply for entering trials and competitions.\nIf your German shepherd is not registered on the breed\nregister, then it has to be registered on the identification register of the\nFederation. For this purpose it has to be made identifiable via either tattooing\nor micro chipping. Then you can apply for membership with both club and\nOur training program\nPlease note that our instructors are dedicated members of\nour club who volunteer their time without payment. You can join our training at\nany time through the year, as you will receive individual attention by the\ntrainers. It is important to understand that the trainers at the club on\nSaturdays will teach you how to train your dog, but you need to put work in\nduring the work on your own as well.\n1. Puppy teasing and socializing\nPuppy teasing is meant to build drive in your dog via\nencouraging him to chase a cloth or a sausage like cushion. This is the first\nstep towards protection work and we encourage everyone to join this exercise\nfrom the age of 4 months. It also helps your dog to build focus during training\nas all puppies are being worked together on the field. Don’t worry if your puppy\nis not too interested into the cloth but rather the other dogs. This is normal\nin the beginning as your puppy has to deal with being surrounded by many people\nand dogs and has to process a variety of new impressions. The puppy teasing is\nconcluded by socializing of the puppies on the field which helps your dog to\nbuild confidence around other dogs and people.\n2. Puppy obedience (beginners class)\nIn puppy obedience you will be taught how to teach your\ndog simple commands like sit, down and stay as well as heel work. A puppy’s\nattention span is very short and the class is centered on making it fun for your\npuppy so that it will be happy to work for you. It is essential that you bring\ntreats like soft food (eg viennas) and a toy so that your puppy gets rewarded\nevery time it gets the exercise right. Working together with your dog will build\na strong bond with your dog.\n3. Intermediate obedience\nFrom about six months of age your puppy will develop into\na teenager and start testing you. Simple commands that it easily obeyed to in\npuppy class now seem forgotten. Your puppy instructor will let you know when you\nare ready to move from the beginner’s class into the intermediate obedience. You\nwill learn in this class the pattern that you and your dog will have to walk in\nthe Begleithund trial. This class is also for members that after having passed\nthe Begleithund trials still wish to continue further with obedience without\nhaving to spend the amount of time required to train for IPO.\n4. BH training – obedience leading to\nBH = Begleithund = companion dog trial\nIn order to enter a BH (Begleithund) trial, your dog has\nto be a minimum of 15 months old. You will be required to perform a specific\nsequence of exercises including heel, sit, down, walking through a group of\npeople in a figure of eight, stay and a recall. Those exercises have to be\nperformed both on and off leash. Through the exercise a second dog has to be in\na down position watching the exercises without reacting to them. The second part\nof the trial is a temperament test in a busy area where your dog has to show\nthat it can deal with passengers, cars, bicycles and other dogs without\naggression or fearful behavior. Upon passing of the trial, your dog will be\nawarded the title Begleithund = companion dog.\nAD – endurance\nThe endurance trial is a 20 km track which your dog has to\nbe able to run next to your bicycle. The minimum age for entering the trial is\n16 months and your dog has to have passed the Federation hip dysplasia scheme\nand be awarded a grading of A. X-rays can be done from a minimum of 12 months of\nage. The endurance trial is the first step towards breed qualifications for your\ndog. Training for this is not done during training hours on Saturdays. The\ninstructors will help you by advising you how to train for this trial on your\nown and members often meet to train for this trial together.\n6. Protection training\nand Breed survey\nThe protection training offered at the club will prepare\nyou for the protection training required in the IPO trial as well as passing a\nbreed survey. A breed survey is a breed qualification in which the dog has to\npass a short protection work routine as a temperament test and then receives a\nbreed description by a breed surveyor which will be entered into its offspring’s\npedigree. Dogs have to pass the endurance trial successfully, their DNA has to\nbe profiled and male dogs are also required to have passed a BH before entering\nthis trial. Upon passing this trial dogs are awarded the title Breed survey (Angekoert)\nwhich is valid for 2 years. After 2 years a breed survey for life has to be\npassed which leads to the permanent awarding of the title breed surveyed.\n7. Breed show training (ring craft)\nA ring is set up on the field and dogs have to be shown in\ndifferent speeds so that they can be compared against the breed standard. A\nBreed grading can only be awarded in an official show with a breed judge\npresent. A handler will be showing your dog while your job will be to attract\nyour dog’s attention so that it will be willing to walk towards you in different\nspeeds required. Only dogs registered on the Federation breed register can be\nshown and bred with.\nIPO formerly known as Schutzhund consists of the three\nparts of tracking, protection and obedience. Dogs have to be a minimum of 18\nmonths old to be able to enter a trial. Tracking is taught through the year\nwhenever the need arises that enough members want to start with it again. The\nprotection work includes finding the helper in a hide, “hold and bark”, and\ntransporting the helper in front of the dog to the judge. The obedience is an\nextended version of the BH which also includes a send-away and transporting a\nwooden dumbbell over a jump and an A-frame like structure. For more information\nplease refer to your training supervisor.\nIn agility you teach your dog to maneuver through an\nobstacle course via hand signals. Obstacles include tunnels, weaving poles, see\nsaws and jumps. Agility is open to all members that have passed the BH\nqualification and do not want to participate in IPO training due to dogs’\nabilities or time that has to be spent training. Agility is a fun way of keeping\nyour dog stimulated and you will learn a different approach of teaching your dog\nwith hand signals as well.\no Beach walks\nOnce a year the whole club takes your dogs together to the beach and socializes\nthem in exercises on the beach. This is usually followed by a braai in one of\nthe parking spots by the beach so that the humans can socialize afterwards as\no Year end function\nIn November of every year the club hosts the year end function to which all\nmembers and their families are invited. The food is catered for by the club and\nmusic is provided by one of our members who is a DJ. As an entry levy we require\nall members to bring some dog food or a tin of dog food which the club donates\nto one of the local animal shelters\nRules during training hours for everyone’s safety:\nSafety first. Make sure that you are wearing appropriate\nshoes and clothing and that you have the correct gear for your dog (leash,\ncollar or harness) so that you can manage your dog and avoid incidences between\nAll Dogs and puppies should be kept on a leash except under direct supervision\nof one of the trainers.\nAlways watch around you when handling your dog for other\ndogs and owners. Not every dog likes every other dog the same as not all people\nget along. Don’t be disappointed if your dog doesn’t get along with everyone\nelse dogs. Socialization time is under supervision of the trainers that know the\ndogs and can handle the situation if the need arises.\nDuring protection work training all other dogs and\npuppies have to be put into trailers, vehicles or travel containers which are\nprovided by the club. The dogs are very excited after the protection work, so\nmake sure that they have a free path back to their vehicle.\nWe encourage you to walk your dogs at the outskirts of the fields so they can\nrelieve themselves before training. Carry packets with you so you can pick up\nBitches in season have to be announced to the training\nsupervisor before training starts and they have to train last after all other\ndogs have been worked. No bitches in season may enter the training field before\nall other dogs have worked.\nAll dogs and puppies have to be up to date on their\nvaccinations including kennel cough. Proof of vaccinations has to be presented\nto the club secretary. Puppies are only permitted to training after their 3rd DHPPI\nvaccination including leptospirosis, rabies (DHPPi + L+R) and kennel cough (KC).\nPlease notify your veterinarian that you require the kennel cough vaccination\nbecause of frequent exposure to other dogs at training as it is not included in\nthe standard vaccinations.\nPlease bring water, water bowl, treats and a toy, adequate collar and leash\nwith you for training. If you are unsure which collar is suitable for your dog\nplease consult with one of the committee members.\nYou are welcome to bring guests and your children to the\nclub, as we train in a family environment. We also have a jungle gym on the\nPlease teach your guests and children to not approach any of the other dogs\nwithout getting the permission of the owner in order to avoid accidents. Teach\nyour children not to approach any of the dogs in the trailers or put their hands\ninto the compartments. The trailers are a dog’s protected space and it cannot be\npredicted how they might react.\nNo alcohol is permitted to be consumed by people handling\ndogs during the training hours.\nTreats and toys are very important for training as the\ntraining is reward based. Don’t expect your puppy to just work for you because\nit loves you. The bond between dog and owner develops during training.\nPlease communicate any ideas or improvements you would\nsuggest to one of the committee members. Feedback on the good and the bad is the\nonly way that we can give you the best service. Let us know if you would like to\nget more in\nLastly, enjoy training your dog and the time you spend\ntogether. Reward and praise your dog when he gets it right and don’t get\nfrustrated if he doesn’t get it at first. Simply try again. Dog training is all\nabout repetition and persistence."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:ef18842a-68e7-462a-999f-c468246cc59b>","<urn:uuid:4e997e3a-9e6c-40ca-8d2a-a775a5f73e14>"],"error":null}
{"question":"How do sacred Tibetan sand mandalas and Murano glass art compare in their impermanence?","answer":"While both are intricate art forms, they have contrasting approaches to permanence. Sand mandalas are intentionally temporary - they are dissolved after completion to teach Buddhist concepts of impermanence and non-attachment. The dissolution ritual involves destroying the mandala and pouring the sand into water. In contrast, Murano glass art is created to be lasting and permanent, with pieces being preserved and collected over centuries. Murano glass works from earlier periods are still highly sought after today and displayed in museums, demonstrating their enduring nature.","context":["What is a Sand Mandala?\nA sand mandala is a two dimensional representation of an enlightened being’s place of residence and everything that is contained within it. When the Buddha taught the tantras (an advanced meditation practice), he took the form of the enlightened being whose Tantra he was teaching and emanated the complete mandala of that enlightened being. The mandala is an expression of the state of complete enlightenment and is used as an aid to meditation.\nJust seeing a mandala creates a great store of positive energy and makes one’s mind peaceful and clear. Understanding it fully means understanding the whole path to enlightenment. Each part of the mandala is rich in symbolism and reminds the meditator of the insights, states of mind and feelings he or she is trying to accomplish.\nChenrezig (the Buddha of Compassion.) embodies enlightened compassion. If each of us could become more compassionate there would be greater harmony and less conflict in our world. The kind of compassion embodied by Chenrezig is unbiased and wishes to free all living beings, without exception, from the suffering they experience. To develop compassion two factors are essential. First we must fully acknowledge our own suffering because only then will we understand that all other ordinary living beings are suffering too. The other factor is the ability to see all living beings as near, dear and lovable. Compassion will then arise quite spontaneously.\nMany people who have seen and heard His Holiness the Dalai Lama speak have been moved by the universality and compassionate nature of his words. Tibetan people consider His Holiness the Dalai Lama as an emanation of Chenrezig, the Buddha of Compassion.\nThe exact proportions and all the details are laid down in ancient Buddhist texts on the creation of mandalas. The monks carefully follow the canonical iconography because every part of the mandalas symbolises different aspects of the teachings and the realisations of the enlightened being whose mandala it is.\nOnly monks who show a special interest and aptitude are chosen by senior monks with expertise in construction sand mandalas are taught to carry on the tradition. Since each mandala is extremely complex, monks specialise in the construction of only one or two different kinds. Each chosen monk carries out two years of intensive training during which they have constructed the mandala again an again until they know the whole design by heart. When making a mandala the design is initially set down in chalk on the base before the sand is applied. If a mistake is discovered, the monk will cover the wide end of the chakpu (funnel) with a piece of cloth and suck the offending sand up into it. That part is then redrawn.\nSignificance of the Colours\nJust as the exact portions and detail are laid out in the design so are the colours. Each symbol has its exact place and colour. The colours blue, white, yellow,red, green, black, brown, orange, light blue, light yellow, light red and light green are used. In the practice of tantra, white, yellow,red and blue-black are associated respectively with peaceful, increasing, powerful and fierce activity. Such activity is not used for personal purposes but exclusively in order to help other living beings.\nTools and Materials\nThe metal funnel used is called a chakpu. When this ridged funnel is rubbed with a piece of horn, the coloured sand inside trickles out in an even flow. A wooden scraper, or shinga, is used to straighten the edges and tidy up stray grains of sand. The fact that both the funnel and the horn are needed in the process reminds us that nothing has independent existence but that everything arises in dependence on a multitude of factors.\nThe sand used in the mandala is made of crushed limestone dyed with pigments. In Tibet natural pigments were used in this process but the pigments used now are purchased from India. The monks themselves collected the stones and crushed them to form sand, which is then sifted with the use of screens in order to obtain three grades: fine, medium and coarse. The monks carefully wash and dry the sand before colouring it.\nIt is essential for the monks to remain constantly mindful and attentive throughout the whole process of construction. As they work, they try to arouse feelings of love, compassion and altruism and as they create the different parts of the mandala they contemplate their symbolism. Their wish is to give happiness to those who see it, the kind of happiness which creates positive energy.\nOften people ask how do the monks sit so still for so long, Years of practice! Day to day activities in the monastery involve long periods of sitting while studying, chanting and meditating. They often begin this at a very early age. Because they are fully absorbed in what they are doing, they are able to maintain their physical posture for a long time. It is, however, good for them to take a break periodically, during which a massage is often greatly appreciated!\nDissolving of the Mandala\nA core teaching of Buddhism is that all produced things, namely whatever comes into existence through causes and conditions, are impermanent. The dissolution of the beautiful and fragile mandala, which is the result of many hours of careful work, is meant to awaken in the mind the understanding of impermanence and non-attachment. After the mandala has been completed and its purpose fulfilled, the monks send back to their abodes the deities who had been invited to enter it. The monks run their vajras through the mandala and ‘destroy’ it. Many westerners find the destruction of the mandala almost shocking, a direct contradiction to the western ideal of having a material result at the end of a process.\nThe rituals accompanying the dissolution of the mandala include a washing ceremony to cleanse the living beings and their environment. Traditionally, the sand used for creating the mandala is poured into a river or the sea and offered to the nagas ( water spirits): non-human beings who inhabit water and who are said to possess fabulous wealth. Polluting earth or water angers these creatures, who may then cause skin diseases and other illnesses, whereas this kind of pure offering pleases them. The offering is made with the prayer that the place where the mandala was created and it’s surroundings, as well as all beings who live there may enjoy peace, prosperity and good health.\nSee more photos of the Medicine Mandala created by our monks Geshe Jamyang Sherab and Karma Gyasey, Whakatane 2014, in Our Gallery.","|Antiques Digest||Browse Auctions||Appraisal||Home|\nSince the beginning of times man has been enchanted, and mesmerized by glass, perhaps due to its transparent nature? One might believe glass lends itself toward being magical and supernatural. For a good example, the crystal ball. It is used to gaze into, and perhaps see what the future holds... Glass has the magical means to capture your attention. The prisms in a crystal chandelier appear ice like, and shoot a rainbow of color which reflects on all objects around it. Glass is synonymous with beauty. Murano glass is certainly a good example of this type of magical glass.\nOver a thousand years ago the glass blowers in Venice Italy began producing some of the most glorious works of glass, Murano glass. Murano is a small group of islands lying on the edge of the Adriatic Sea in the lagoon of Venice, about 3,000 meters north of the larger group of islands comprising the city of Venice.\nDocumentation written by a Benedict Monk, by the name of Dominic, gives good evidence that the origin of glassblowing in Venice goes back to before the first millennium. Domenico produced phials for use in the home. Today Venetian glass production is at its pinnacle, and is world renowned for its quality and form. Today Murano glassblowers use the same technology to create their wonderful works of art.\nTourist visit daily at the Murano Factory to watch as the glassblowers create wonderful works of art glass. It may appear that time has stood still. The master glassblowers remain committed to the tradition, and turn out some of the most enchanting glass in the world. The glassblower’s pipes are made in machine shops on the island of Murano as they were from the conception of Murano Glass.\nIn 1291 the government of Venice put a banned on the glass furnaces in Venice. Hence the glassblowing was relegated to the Island of Murano. It is believed by historians that this all came about due to fear of fires, which could result from the use of the glass furnaces. Many of the structures of the time were wooden; this caused great concern among the citizens. Another train of thought was that the move would isolate the master glassblowers, and prevent them from sharing their valuable techniques in glassblowing with other European glass makers. The glassblowers were kept virtual prisoners on the island. The Venetian government did not want the glassblowers’ methods to leave the island. Murano glass was soon to become the leading source of fine glass through out Europe, and a major trade income for the Republic of Venice.\nMurano glass was well known for it being exquisite, yet utilitarian. The mirrors for instance, were intricately decorated and beautiful. The glassblowers of Murano are well known for a wide variety of glass Item's.\nToday Murano glass still holds it place in the glass industry. The island and people of Murano produce a wonderful selection of glass items. From vases, perfume bottles, to glass jewelry. It is well sought after, especially the older pieces. These older pieces can still be found. You may even find pieces on the Internet, there are many Web sites that sell Murano glass. You may want to try your luck on an on-line auction.\nIf you are lucky enough to visit Venice, don't miss going to Murano to see the glassblowers show. An easy way to reach the island is by water taxi (vaporetto).The taxis are paid for by the Murano factories, in hopes of having many tourists visit and buy their glass. When you get off the taxi at the taxi landing, you will be within close proximity to the Murano Museo Vetrario, the glass museum. This is well worth the tour; you will learn the history of Murano glass along with the techniques used by the artist. The glassblowers put on a wonderful show. You will most likely want to buy a trinket to take home. The glass ranges any where from glass bon bons for $1 to $5, to magnificent chandeliers for anywhere from $400 to $8,500. There is something for everyone, of every age. Murano glass is truly beautiful, and can add that little bit of sparkling magic to your home.\nBelow is a small sampling of estimated auction prices for Murano glass:"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:35dd81cb-ae8e-4ae6-bb2a-2c172c887318>","<urn:uuid:aa50564c-950b-4345-8037-18114c4f9d55>"],"error":null}
{"question":"What are the key differences between a closed shop arrangement and a non-compete clause in terms of their restrictions on worker employment?","answer":"Closed shop arrangements and non-compete clauses differ significantly in their employment restrictions. A closed shop requires workers to be members of a specified union as a precondition for employment, affecting their ability to get hired in the first place. This practice was banned by the 1947 Taft-Hartley Act. In contrast, a non-compete clause is a contractual agreement that prohibits employees from working for competitors or starting competing businesses after leaving their current employer. Non-compete clauses remain legal in many states, though they're unenforceable in some states like California, Oklahoma, and North Dakota. While closed shops restricted initial employment based on union membership, non-compete clauses restrict future employment based on competition with the former employer.","context":["CLOSED SHOP refers to a union security clause in labor-management contracts that stipulates that all persons who are to be employed must be members of a specified union as a precondition for such employment.\nThe closed shop was a dominant feature of early unionism in the United States, a natural outgrowth of the guild features of craft organization of work. The focus of the guild was on the maintenance of the quality of output through strict enforcement of apprenticeship standards. Many early unions stipulated that employers could hire only fully certified journeymen and would be subject to penalty if they failed to do so. Craft members, moreover, were subject to fines if caught working with persons not members of the union. The strong fraternal character of early unions helped buttress such arrangements, which seemed justified (at least to members) by the attention they gave to sustaining the quality of work by preserving the integrity of craft skills. Such arrangements also boosted wages by restricting the size of the pool of available workers. Although seldom made contractually explicit, closed shop arrangements were pervasive throughout the early twentieth century and were a source of considerable controversy and conflict.\nIn 1935, the National Labor Relations Act legislated a major intrusion of public policy into collective bargaining in an effort to reduce the widespread industrial conflict. Major provisions, which the newly created National Labor Relations Board (NLRB) was to implement, were aimed at reducing strikes over union recognition. Appropriate bargaining units were to be defined by the board; a secret-ballot vote was then to be taken under board supervision in the matter of union representation. A union gaining more than half of that vote was to be certified by the board as the exclusive bargaining agent for that unit. The employer was then obligated to bargain in good faith with that union, and the union was obligated to equally represent all persons in the bargaining unit, whether members or not.\nThere were obvious advantages to the union movement in shifting the locus of decision making about union recognition from the economic to the political arena. In securing the right to exclusive representation for at least a year following certification, the union had the opportunity to extend its influence over the bargaining unit. One logical extension of such recognition was to strengthen the union's membership base and its revenue flow. Rather than overtly pursuing an exclusionary policy involving a closed shop with a union that limited membership, most unions preferred to adopt an inclusionary posture. They negotiated union security clauses to expand rather than to restrict membership. The ultimate result was a growth in closed shop arrangements.\nHowever, the closed shop arrangement could be used against the worker as well as against the employer. Expulsion from the union meant loss of job rights, and there were several reasons why a union might expel a member. A worker might be expelled for refusing to adhere to the production ceilings established for piece-rate operations. The union might undertake selective retaliation against dissidents within the union political structure. Or, retaliation might follow a member's support of another union vying for representation rights in the shop. In brief, with a closed shop, the union was no longer a private fraternal organization. It controlled the job. It was a dispenser of bread.\nInitial assaults against union exclusionary policies took the form of conspiracy charges—that the monopolistic privileges accruing to union members increased product prices, reduced production, curtailed employment, and diminished wages in nonunion industries because of the additional flow of labor squeezed out of \"protected\" sectors. The 1947 Taft-Hartley Act amendments to the National Labor Relations Act were designed to remedy these ills by banning the closed shop. The public policy behind Taft-Hartley, as well as the 1959 Landrum-Griffin amendments to the National Labor Relations Act, was to restrict traditional union control over the point of ingress into the labor market. Obeisance to the union movement was not to be a requisite for favored treatment in pay or promotions within the plant. The economic status of the worker was to reflect the bilateral influences of both employer and union, not the unilateral discretion of the union. Nonmembers and members were to be treated as persons with undifferentiated status in the distribution of collective-bargaining gains. Controversy diminished during the late twentieth century as unions adhered to a new doctrine: employers have the \"freedom\" to hire nonunion employees, just as workers have the freedom to refuse to work with nonunion employees.\nAlso affected by public policy and union stance were alternative forms of union security, to be sharply distinguished from the closed shop. A favored union clause, now illegal, is one in which the employer openly identifies his partiality to a union and encourages membership in that organization. An agency shop allows the union to collect agency fees or service fees from workers, while not requiring the formality of membership. These fees cover union expenses associated with collective bargaining, and are justified by the union's obligation to bargain for all employees in the bargaining unit regardless of union affiliation. A 1980 amendment to the National Labor Relations Act provides that workers with religious objections cannot be fired for failing to pay service fees to a union.\nAnother form of union security is the union-shop agreement. Union-shop agreements formerly specified that workers in a union were to maintain membership affiliation as a condition of employment, with escape periods typically provided during the term of the contract. The National Labor Relations Act still permits contract provisions that require employees to join the union within thirty days of hire. However, in 1985 the Supreme Court held that contracts may not limit a worker's ability to resign from the union. Union-shop agreements can no longer require maintenance of union membership. In addition, several states have also enacted right-to-work laws that prohibit union-shop agreements altogether.\nIn short, changes in labor law and its judicial interpretation over the course of the twentieth century have undermined the ability of unions to bargain for contract provisions that enhance their security and their ability to discipline members.\nHanson, Charles Goring, Sheila Jackson, and Douglas Miller. The Closed Shop: A Comparative Study in Public Policy and Trade Union Security in Britain, the USA, and West Germany. New York: St. Martin's Press, 1981.\nRustin, Bayard. \"Right to Work\" Laws; A Trap for America's Minorities. New York: A. Phillip Randolph Institute, 1967.\nSchiller, Reuel E. \"From Group Rights to Individual Liberties: Post-War Labor Law, Liberalism, and the Waning of Union Strength.\" Berkeley Journal of Employment and Labor Law 20, no. 1 (1999): 1.\nPaul E.Sultan/c. p.\nA shop in which persons are required to join a particular union as a precondition to employment and to remain union members for the duration of their employment.\nThe federal National Labor Relations Act (NLRA) (29 U.S.C.A. §§ 151 et seq.) protects the rights of workers to organize and bargain collectively and prohibits management from engaging in unfair labor practices that would interfere with these rights. Popularly known as the wagner act, the NLRA was signed into law by President franklin d. roosevelt on July 5, 1935.\nAmong the workers' rights legalized by the NLRA was the right to enter into a \"closed shop\" agreement. It differs from a union shop, in which all workers, once employed, must become union members within a specified period of time as a condition of their continued employment. Closed shop agreements ensured that only union members who were bound by internal union rules, including those enforcing worker solidarity during strikes, were hired.\nAs world war ii ended a decade after the NLRA was enacted, unions sought to make up the pay cuts caused by wage freezes during the war, resulting in a rash of strikes. Many people viewed these strikes as economically destructive, and union practices, such as closed shop agreements, became increasingly unpopular. Critics of the closed shop contended that it allowed unions to monopolize employment by limiting membership or closing it altogether. They also argued that the closed shop allowed unions to force unwilling individuals to give them financial support.\nIn response to these criticisms, Congress amended the NLRA in 1947, with the adoption of the labor-management-relations act (29 U.S.C.A. §§ 151 et seq.). Known as the taft-hartley act, this law placed many restrictions on union activities. It limited picketing rights, banned supervisory employees from participating in unions, and restricted the right to strike in situations where the president of the United States and Congress determined that a strike would endanger national health and safety. The Taft-Hartley Act prohibited secondary boycotts, wherein a union incites a strike by employees of a neutral or \"secondary\" party, such as a retailer, in order to force the secondary party to cease doing business with the party with whom the union has its primary dispute, such as a manufacturer. The Taft-Hartley Act also allowed individual states to ban the union shop by passing right-to-work laws that prohibited employees from being required to join a union as a condition of receiving or retaining a job.\nSection 8(a)(3) of the Taft-Hartley Act specifically outlawed the closed shop but did allow a collectively bargained agreement for a union shop, provided certain safeguards were met. Under the union shop proviso, a union and an employer could agree that employees must join the union within thirty days of employment in order to retain their jobs. Section 8(a)(3) stated, in relevant part,\nIt shall be an unfair labor practice for an employer—… (3) by discrimination in regard to hire or tenure of employment or any term or condition of employment to encourage or discourage membership in any labor organization: Provided, that nothing in this subchapter, or in any other statute of the United States, shall preclude an employer from making an agreement with a labor organization …to require as a condition of employment membership therein on or after the thirtieth day following the beginning of such employment or the effective date of such agreement … if such labor organization is the representative of the employees…. Provided further, that no employer shall justify any discrimination against an employee for nonmembership in a labor organization (A) if he has reasonable grounds for believing that such membership was not available to the employee on the same terms and conditions generally applicable to other members, or (B) if he has reasonable grounds for believing that membership was denied or terminated for reasons other than the failure of the employee to tender the periodic dues and the initiation fees uniformly required as a condition of acquiring or retaining membership.\nSome observers believe that the abolition of the closed shop helped to minimize racial discrimination by unions. The Wagner Act allowed unions to effectively shut out black employees from employment opportunities and benefits by simply refusing them membership. The Taft-Hartley Act curtailed this practice by prohibiting the negotiation of security agreements that limited employment opportunities to union members.\nBaker, Joan E. 1989. \"NLRA Section 8(a)(3) and the Search for a National Labor Policy.\" Hofstra Labor Law Journal 7 (fall).\nBallam, Deborah A. 1995. \"The Law As a Constitutive Force for Change, Part II: The Impact of the National Labor Relations Movement on the U.S. Labor Movement.\" American Business Law Journal 32.\nDevaney, Dennis M., and Susan E. Kehoe. 1993. \"The NLRB\nTakes Notice to the Max in Paramax.\" Hofstra Labor Law Journal 11 (fall).\nGlick, Carol A. 1989. \"Labor-Management Cooperative Programs: Do They Foster or Frustrate National Labor Policy?\" Hofstra Labor Law Journal 7 (fall).\nLarson, Reed. 1999. Stranglehold: How Union Bosses Have Hijacked our Government. Special abridged ed. Ottawa, Ill.: Jameson Books.\nMihlar, Fazil, ed. 1997. Unions and Right-to-Work Laws: The Global Evidence of their Impact on Employment. Vancouver: Fraser Institute.\nPlass, Stephen A. 1992. \"Arbitrating, Waiving, and Deferring\nTitle VII Claims.\" Brooklyn Law Review 58 (fall).\nTurner, William D. 1994. \"Restoring Balance to Collective Bargaining: Prohibiting Discrimination against Economic Strikers.\" West Virginia Law Review 96 (spring).\nA closed shop was a workplace in which anyone who hoped to gain employment had to first join a labor union. Closed shop requirements remained one of the most aggressive methods a labor union could use to maintain its power among a company's workforce. A less radical form was a \"union shop,\" in which nonunion workers could join the workforce provided they joined the union within a certain period of time. Conversely, a workplace where workers freely belonged to a union or remained nonunionized was called an \"open shop.\"\nLabor unions first became powerful during the Industrial Revolution of the nineteenth century when workers banded together for improved pay and working conditions. During the Great Depression of the 1930s, economic conditions became so difficult that the federal government passed laws such as the National Industrial Recovery Act of 1933 and the National Labor Relations Act of 1935. These acts gave workers the right to bargain collectively (as a single group) with management and required management to negotiate with duly elected union officials. However, during the remainder of the 1930s and in the 1940s some unions in the Northeast and Midwest, the regions with the most heavy industries and the most unions, began requiring that prospective employees be union members before a company could hire them.\nAfter World War II (1939–45) and the damaging labor strikes of 1946, attempts were made to rein in the growing power of the U.S. labor union, culminating in the Taft-Hartley Act of 1947. The act sharply limited the circumstances in which closed shops were legal and enabled state governments to outlaw union shops if they chose. However, even after the Taft-Hartley Act became law many workplaces continued to be informal closed shops. In such workplaces there was no \"union only\" requirement written anywhere in the labor agreement, but only workers who were already members of the union were ever hired. In some workplaces union workers would simply refuse to work with anyone who was not already a member of the union—this practice is a \"de facto\" closed shop. Closed shops are most common in industries where the company allowed the union to hire workers and where workers were employed by a specific company for a short time, as in the construction industry or among longshoremen.\nA workplace is a closed shop if, by virtue of a labor contract, only the members of a particular union may be hired. After passage of the tafthartley act (1947), the closed shop was replaced by the \"union shop\" wherein one must join the union after being hired.\nDennis J. Mahoney","What is a non competition clause in an employment contract?\nNon-Competition Clause. What is a non-competition clause? A non-competition (or non-compete) clause is a passage in an employment contract which purports to prohibit employees from working for another employer or starting their own business which competes with their employer during and after employment.\nCan a non-compete clause extend the reasonable notice period?\nAbacus Management, 2014 BCSC 938 (CanLII), the court considered the presence of a non-competition clause in extending the reasonable notice period. Accordingly, employers should not just blindly by boiler-plate insert into their employment contracts a non-compete clause for each and every employee.\nWhat happens if you violate a non compete clause?\nLike all legal agreements, a non-compete clause is only as meaningful as a court’s willingness to enforce it. If you violate your non-compete clause, your employer can take the matter to court (although not all do so).\nIs the non-compete clause unenforceable in California?\nNoncompete clauses are unenforceable in some states such as Oklahoma and North Dakota, whereas in California, for example, employers who require a non-compete clause can even be sued. Before signing, research the laws in your state.\nWhat does no compete mean?\nNon Compete Meaning: Everything You Need to Know. The non-compete meaning is a contractual agreement that exists between employer and employee that states that employee agrees not to use any information gained.3 min read.\nWhat is Employment Non compete?\nEmployment Non Compete Agreement Law and Legal Definition. A non-compete agreement is a promise by an employee not to compete with his or her employer for a specified time in a particular place. The agreement may cover such actions, among others, as opening a competing business or using customer information for business leads.\nWhat is a non competition clause?\nIn contract law, a non-compete clause (often NCC), or covenant not to compete (CNC), is a clause under which one party (usually an employee) agrees not to enter into or start a similar profession or trade in competition against another party (usually the employer). Some courts refer to these as “restrictive covenants.”.\nWhat is a non compete agreement?\nNon-Compete Agreement. What is a Non-Compete Agreement? A non-compete agreement is a contract between two parties, usually two individuals or one company and one individual, in which one of the individuals promises not to compete with the other individual or company once their relationship with the company has ended.\nWhat happens when you sign a non-compete agreement?\nNon-compete agreements can prevent workers from getting a job in their field if they leave a position after signing such an agreement. Non-compete agreements are signed when the relationship between employer and employee begins. They give the employer control over specific actions of the former employee—even after that relationship ends.\nAre there non-compete agreements in the state of Florida?\nThe enforceability of non-compete agreements in the state of Florida is quite common. Some law firms build their law practice around these agreements and represent employees, employers and potential new employers of an employee currently bound by a non-compete agreement.\nHow long can a non compete clause be enforced?\nGenerally, it should not be longer than one year. Most courts refuse to enforce any non-compete clause longer than a year. It is submitted that to be on the safe side, a non-compete clause should be six months. That is not to say that certain very long non-compete clauses will not be enforced.\nWhat does non compete clause mean?\nAre non compete agreements enforceable?\nNon-competition agreements are only enforceable to the extent they are reasonable in both geographic scope and time duration."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:ace5e338-364f-4c61-b2a0-b0660dbd968e>","<urn:uuid:eb8fb404-ed77-41ed-994f-0f8f7f44b0f6>"],"error":null}
{"question":"What are the historical patterns and research findings regarding the relationship between popularity and risky behavior among teenagers?","answer":"According to research from the Annenberg Public Policy Center of the University of Pennsylvania, young people strongly connect risky behavior with popularity. The study found that approximately 75 percent of teens believe their popular peers are more likely to engage in drinking alcohol, smoking cigarettes or marijuana, or gambling compared to unpopular students. The study also revealed that many teens believe popular students drink and smoke, while noting these substances are easily accessible. This combination of popularity and accessibility creates what experts call a dangerous mix, as popular kids shape the norms that influence the attitudes and behaviors of their peers.","context":["The teen years are tough. Help your teen deal with the inevitability of peer pressure by learning what it’s like … again.\nThe desire to fit in can be overwhelming for kids who look to model the examples of popularity they see on TV and in magazines. They can easily equate being part of a specific group with social status, personal accomplishments and good fortune. Fitting in – or feeling as though you don’t fit in – can affect a child’s self-esteem, grades and communication and leadership skills.\nWhile the pressures of popularity greatly increase with teens in high school, children begin forming social groups and standards as early as the first grade. They gravitate towards classmates for a variety of reasons such as personality, ability and appeal.\nAttending school, sports practice or extra-curricular classes may seem brutally unpleasant to a child who feels he doesn’t “belong.” The added stress of the physical changes that puberty brings often sends teens and ‘tweens in search of a social group to feel safe in. Some try to blend into the melting pot of styles, ideals and opinions represented in the school halls in the hopes of not being viewed as different or original. Others opt for a contrasting strategy of intentionally trying to stand out hoping somehow to fit into a crowd of “originals” or “social misfits.”\nWhat’s Learned in School\nLiz Maurin, a high school foreign language teacher, has seen how overpowering the quest for popularity can be. Unfortunately, she has seen the situation turn ugly. “Kids resort to behaviors that border on dangerous just to get the attention of a member of the opposite sex or to break into a clique,” says Maurin. “They’ve learned how to manipulate situations and words just to be popular.”\nIt can be difficult for adults to navigate through the various pressure situations kids face. Spreading rumors, telling lies or being intentionally hurtful are just a few of the dilemmas our children face daily to gain recognition among their peers.\nMaurin has seen some of her students teeter on the verge of a breakdown from the pressure to get into the “in” crowd. “Kids will intentionally ruin their grade point averages because they don’t want to be considered too smart,” she says. “They’ll defy parents, teachers and counselors just to go along with what their group is doing.”\nIn a study at the Annenberg Public Policy Center of the University of Pennsylvania, researchers supported what Maurin sees in the halls of her school. They learned that young people connect risky behavior with popularity.\nThe study also found that nearly 75 percent of teens believe their peers who are perceived as popular are more likely to engage in drinking alcohol, smoking cigarettes or pot or gambling than their “unpopular” ones. “Young people know that cigarettes, marijuana and alcohol are easily accessible, and many believe that the popular kids drink and smoke cigarettes or marijuana,” says Kathleen Hall Jamieson, director of the Annenberg Center. “Since popular kids shape the norms that influence the attitudes and behaviors of those their age, this combination of popularity and accessibility is a dangerous mix.”\nCountering the Pressure\nWhether it’s experimenting with teen drinking, sexual activity or contemplating an embarrassing round of truth or dare, you can help your child develop a strong mental and emotional constitution to weather the storm of popularity pressure.\n“Providing a stable support network is the first step in overcoming peer pressure” says child advocate specialist Diana Derby. “Kids need to know they have options to the pressured choices they face among their peers.”\nMaintaining open lines of communication with your child will help him to make clear and safe choices. Talking about the circumstances and decisions you faced as a teen are helpful, but listening objectively to his scenarios will give you valuable insight into his life.\nUnderstanding what he views as important will provide a starting point. Whether making the football team or cheerleading squad or being invited to a party or dance is the priority, it’s important to understand what your child is attempting to accomplish socially.\nIf your daughter’s looking to replace her junior high look with one that’s more mature and suited to high school, you’re a more stable adviser to help her apply make-up than a friend in the bathroom between classes. And when it comes to harmful substances, Derby recommends talking to your child about the tastes, effects and consequences of them in order to satisfy curiosities he might otherwise explore as a result of pressure from friends. “Be honest about the consequences of decisions he might make out of pressure to fit in” Derby adds.\nIt’s Good to Have Options\nChildren battling the pressure to be popular need a positive support structure. Cheryl Browne-Ojei, Ph.D., works to provide at-risk children a safe haven to express themselves while feeling they belong to a group of their peers. She helps kids build self-esteem through positive situations and examples.\nGiving a child who feels he doesn’t fit in the chance to positively impact a situation helps his confidence soar. He’ll be more likely to stand up for himself at school or sports practice. Teachers like Liz Maurin have seen that children who exude high self-esteem and confidence in their decision to not give into pressure often become “founding fathers” of their own social group.\nThe opportunity to gain support from extended family members and friends also boosts esteem and resilience to pressure. Having the option to shoot hoops with an older brother and his friends from college gives your teen an appealing “out” to participating in a drinking contest all in the name of fitting in.\nEncourage your kids to pursue hobbies, sports interests or creative outlets to meet peers with similar interests. Sometimes the chance to spend time talking with a buddy about the round of weekend football games or attending dance class with a friend helps teens navigate through pressures to fit in.\nIf you take a mental trip back in time to your days in junior high and high school, you’ll remember how vital it felt to belong to a group – whichever group that happened to be. Recognizing those insecurities and social anxieties are what teens and ‘tweens still experience today and will help you help your child cope with the pressure he faces to be popular.\nGina Roberts-Grey is a licensed clinical social worker and freelance writer.\nWhen in doubt, check a book out. There are plenty of books available to help you and your teen through the popularity pressures.\nWhy Doesn’t Anybody Like Me?: A Guide to\nRaising Socially Confident Kids\nBy Hara Marano\nThe Complete Idiot’s Guide to\nSurviving Peer Pressure for Teens\nBy Hilary Cherniss and Sara Jane Sluke\nHow to be Popular\nBy Jennifer McKnight-Trontz\nQueen Bees and Wannabes: Helping Your Daughter Survive Cliques, Gossip, Boyfriends and Other\nRealities of Adolescence\n(Three Rivers Press)\nBy Rosalind Wiseman"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:7f391797-8644-4aeb-9ea8-d85e200104c7>"],"error":null}
{"question":"What are the storage benefits of pasteurized goat milk, and what health risks does unpasteurized (raw) milk pose to consumers?","answer":"Pasteurized goat milk offers significant storage advantages, lasting up to 6 months in the freezer when stored properly at the bottom to shield from warm air. For refrigerated storage, pasteurized goat milk can last between 3-10 days. However, raw milk poses serious health risks as it can contain harmful bacteria that cause symptoms like vomiting, diarrhea, abdominal pain, fever, headache and body aches. In severe cases, raw milk consumption can lead to pneumonia, blood-stream infections, kidney failure, meningitis, chronic liver disease or heart disease. These risks are especially dangerous for pregnant women, children, the elderly, and people with weakened immune systems. Since 1993, over 70 outbreaks from raw milk consumption have been reported nationwide, affecting over 1,500 people and causing 185 hospitalizations and 2 deaths.","context":["Goat milk is a good resource during emergencies. Goat milk is fantastic source that protein. It can likewise be a basic ingredient for dairy assets like cheese.\nYou are watching: How long can goat milk sit out\nThe longevity the goat milk, both raw and also pasteurized, relies on numerous factors. Refrigerated goat milk can last anywhere between 3 days to 6 days. Top top average, goat milk have the right to last indigenous 3 to 10 job in the fridge. Pasteurized goat milk have the right to last approximately 6 months in the freezer.\nThe method you take care of goat milk upon harvest mainly affects the longevity. There space two main factors that impact how lengthy goat milk lasts: cleanliness and also pasteurization.\nThe cleanliness of the goat, the udders, and also your working an are largely affect the longevity the the milk. Make certain to harvest from a clean goat. Her udder must appear clean v no indicators of infection or pus. Milk the goat in a clean environment. Wash your hands prior to milking the goat. The containers and also equipment you usage must also be washed prior to milking.\nBefore you to water the milk right into the storage container, strain the milk for any type of clumps, hair, dirt, or bugs. Usage a disposable milk filter or a stainless-steel strainer. It’s advisable to use glass jars or bottles due to the fact that they’re more resistant to bacterial growth. Lock also very easy to sterilize. For every rinse, use 2 tablespoons of 3% hydrogen peroxide dissolved in water come clean the glass containers.\nAfter straining and also storing, chill the milk immediately to protect against the growth of microorganisms that cause spoilage. The temperature need to be kept in between 35 come 38 degrees. Avoid any fluctuations in the temperature, which way that you have to be continual in its setting. Make sure to store the milk the end of straight sunlight or harsh fluorescent lights.\nPasteurization helps expand the milk’s shelf life. This eliminates a number of harmful bacteria and makes the milk for sure for consumption, particularly for kids. The just downside is that it also kills the an excellent bacteria that your body can benefit from. It can also alter the flavor of the milk.\nYou can only drink life milk if you room a hundreds percent certain that the goat is healthy. If not, pasteurize the milk to extend its shelf-life and to make it safe for consumption.\nPasteurized milk deserve to last increase to 6 months in the freezer. To accomplish this maximum longevity, make certain to ar the milk in ~ the bottom that the freezer. This will certainly shield that from the warmth air the will go into the freezer every time you open up the freezer door.\nHow to Pasteurize Goat Milk in ~ Home\nPlace the milk in glass jars or twin boilers. Place it within the pasteurizer or canner and also then heat it to 165 levels Fahrenheit for just fifteen seconds. Cool the milk automatically by put the milk in a container, and then placing the container in an ice bath. You deserve to do this in the sink by filling it up with water and some ice. Keep the milk container spanned to prevent water from obtaining in.\nMake certain to avoid placing the jars in the refrigerator or freezer right away together the sudden change in temperature may cause the glass come break. Put the heat milk straight in the fridge will likewise make the cooling down procedure so lot longer, hence giving the microbe a opportunity to grow and to cause spoilage. Save the milk in the refrigerator once cooled.\nHow To gain Goat Milk\nNot every goats create milk. Milk is exclusive come female goats or does. They require to get pregnant an initial and give birth come babies before they can develop milk. There will be a most milk instantly after giving birth yet the amount will certainly dwindle transparent the year.\nThe ideal time come harvest goat milk is throughout the feather which is the usual mating season. You deserve to milk a doe while she is pregnant. You simply need to let her dry up 2 months before she’s due to give birth so the she can make room because that nutritional make reservation that will certainly nourish she offspring.\nWhen the infant goats are currently two mainly old, make sure to separate them native the mommy goat during the night so that the goat can replenish that is milk supply. When the infant goats are eight mainly old, you can now milk the mom goat both during day and night.\nThe ideal milking goats space dairy breeds choose Nubian, Alpine, La Mancha, Oberhasli, Saanen, Sable, Toggenburg, and also Nigerian Dwarf.\nSee more: Cpt Code For Pectoralis Major Tendon Repair Pectoralis Major\nHow much Milk do Goats Produce?\nDuring peak production, a goat can develop up to fifty percent a gallon that milk every day. That totals to fifteen gallons per month. About five to six months after providing birth, the lot of milk will go down to about six cup per day. The complete will it is in eleven gallons per month. At the 8th to nine month after birthing, the amount will go under to 7 gallons per month.","The Dangers of Drinking Raw Milk\nWhat is raw milk?\nRaw milk is milk from cows, sheep or goats that has not been pasteurized to kill harmful bacteria.\nWhat does the New York State Department of Health recommend about the consumption of raw milk or raw milk products?\nThe New York State Department of Health strongly recommends that people DO NOT CONSUME any raw milk or raw milk products. The New York State Department of Health recommends consuming only milk and milk products that have been pasteurized.\nWhat are the recommendations from other agencies about consuming raw milk or raw milk products?\nThe federal Centers for Disease Control and Prevention (CDC), the Food and Drug Administration (FDA), the United States Department of Agriculture (USDA), the American Academy of Pediatrics and other medical, veterinary and scientific organizations recommend consuming only pasteurized milk and milk products.\nWhat is pasteurization?\nPasteurization is the process of heating milk to a high enough temperature for a long enough time to kill disease-causing bacteria contained in the milk and has been used safely for over 100 years. Pasteurization of milk became widespread in the United States by 1950. Pasteurization is the only way to ensure that milk products do not contain harmful bacteria.\nDo products made from raw milk carry dangerous bacteria?\nYes. Other foods made with raw milk include soft cheeses, sour cream, yogurt and ice cream. Any food made with raw milk can contain dangerous bacteria and consuming these foods can make you very sick.\nWhat kinds of harmful bacteria can raw milk contain?\nCan these bacteria be especially dangerous to certain people?\nYes. The bacteria in raw milk can seriously affect the health of anyone who drinks raw milk or eats foods made from raw milk. The bacteria can be especially dangerous to pregnant women, children, the elderly and people with weakened immune systems.\nWhat symptoms can people have if they become ill from drinking raw milk with these bacteria?\nMost commonly, bacteria in raw milk can cause vomiting, diarrhea (sometimes bloody), abdominal pain, fever, headache and body aches. In some instances, people can develop pneumonia, blood-stream infections, kidney failure, inflammation of the nervous system (meningitis), chronic liver disease or chronic heart disease from drinking raw milk. While some people will have mild illness from bacteria in raw milk, others are at much higher risk of life-threatening illness, especially pregnant women, children, the elderly and people with weakened immune systems (such as people with cancer or HIV infection or recipients of organ transplants).\nHow many people in the United States have become ill from consuming raw milk or raw milk products?\nSince 1993, over 70 outbreaks of human illness from consumption of raw milk have been reported nationwide, affecting over 1,500 people and causing 185 hospitalizations and 2 deaths. The actual number of illnesses associated with raw milk likely is far greater.\nWhat should I do if I become ill after drinking raw milk or eating a product made with raw milk?\nIf you or someone you know becomes ill after consuming raw milk or products made from raw milk, see a doctor or health care provider immediately, especially if you are pregnant or at higher risk for developing severe illness.\nDoes pasteurizing milk reduce its nutritional value?\nNo. The pasteurization process does not change the nutritional value of milk.\nDoes pasteurization cause disease, developmental problems or behavioral problems?\nNo. Pasteurization has never been shown to cause disease or other health problems.\nDoes pasteurization cause lactose intolerance or allergic reactions?\nNo. Pasteurization has never been shown to contribute to lactose intolerance or other allergic health problems.\nHow does New York State regulate the sale of raw milk?\nIn New York State, raw milk may only be sold at dairy farms that hold a permit from the New York State Department of Agriculture and Markets. Permitted farms are required to maintain proper sanitation, animal health, packaging procedures, monthly inspections, routine sampling and testing and post signs that warn that raw milk does not provide the protection of pasteurization.\nWhere can I see a complete copy of the rules and regulations regarding raw milk sales in New York?\nRequirements for the Production, Processing, Manufacturing and Distribution of Milk and Milk Products: www.agriculture.ny.gov/DI/Laws%20in%20PDF/PART2_milk_control_law.pdf.\nWhere can I get additional information about the risks of consuming raw milk?\nVisit the following resources:\n- The Dangers of Raw Milk: Unpasteurized Milk Can Pose a Serious Health Risk - U.S. FDA\n- Raw Milk Fact Sheet - FDA & CDC\n- Health Benefits, Risks, and Regulations of Raw and Pasteurized Milk, Valente B. Alvarez and Francisco Parada-Rabell - The Ohio State University Extension\n- Milk, Cheese, and Dairy Products, Myths About Raw Milk - FoodSafety.gov\n- Food Safety and Raw Milk - Food Safety at CDC"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:77f9ac7c-3861-45be-b971-adaea9a202a4>","<urn:uuid:67336dd8-d6e3-4310-9720-3303eef98581>"],"error":null}
{"question":"What are the benefits of monitoring cooling fluid flow rates accurately, and what problems can arise from using mechanical flowmeters? 🤔","answer":"Accurate monitoring of cooling fluid flow rates offers several benefits: it helps reduce operating costs since excessive flow means unnecessary pumping and water treatment expenses. For instance, operating at 160 lpm versus 80 lpm doubles pumping costs. Additionally, proper monitoring helps protect equipment life and reduce downtime. However, mechanical flowmeters can be problematic as they are more susceptible to unsafe failure modes compared to electronic flowmeters. They may indicate flow when no flow is present, which doesn't protect the equipment and could pose significant safety hazards. Furthermore, mechanical components like flow floats can become deformed or affected by scale buildup, leading to false readings.","context":["Have you ever arrived at a customer site and noticed something wasn’t quite right? Maybe the controller says the system conductivity is well above your set point but the blowdown valve is closed. That doesn’t make sense. Or maybe the cooling tower system is shut down but the blowdown valve is open. There’s definitely something very wrong. Did someone change the controller set point? Did the valve fail? Is the controller malfunctioning? Should I call Lakewood? You can certainly call us, we’re happy to help. The first thing we’re going to ask is “Do you have flow”?\nIf you’re in the mechanical room you might see/hear the condenser pump and know it’s on. Or you’re on the roof and you can see/hear water spraying down in the tower. Those are good indications that there is actual flow in the cooling tower system. On the contrary, it’s easy to tell if the system is not operating and there is no flow. The next question we’ll ask is, “Does the controller think there’s flow”?\nBelow is a schematic of a simple cooling tower system. The larger piping around the outside is the main cooling tower or condenser “loop.” For the cooling tower to work at all, the condenser pump must be running. The smaller piping and devices on the inside comprise the cooling tower water treatment system. We’ll be focusing on the sample line.\nThe main component of the sample line is the plumbing assembly, which performs two functions. The first is housing the system conductivity sensor. The second is sensing flow. The controller will not operate if it does not sense flow.\nFlow Switch Operation\nThe image below shows the parts that make up the flow switch. The float sits in the upper half of the plumbing assembly. The float sight is secured by the top lock-ring. The molded end of the reed switch fits into a recess in the back of the plumbing assembly. The float contains a magnet that forces the reed switch to close when raised to the upper position. The top of the float is also visible in the sight when raised.\nWhat Causes a False Flow Status?\nUnder normal operation, flow through the plumbing assembly lifts the float to the top of the plumbing assembly, resulting in a reed switch closure that tells the controller there is flow. The specified flow rate range for the float to operate is 1 to 5 GPM. We recommend at least 2 GPM for reliable float movement. If the flow rate is too low, the float will not raise enough to engage the reed switch. More than 5 GPM can damage the float, causing it to deform and possibly get stuck in the float sight. Such situations result in incorrect flow indications to the controller.\nThe most common cause of a false flow reading is a buildup of scale in the plumbing assembly. Such buildup can prevent the float from rising enough, resulting in a false “NO FLOW” indication. We recommend using a small brush to clean the interior of the plumbing on a monthly basis.\nAnother cause is a chemical reaction with the backflow prevention o-ring, pictured below. This is located inside the plumbing where the flow float is seated. If chemicals have interacted with the o-ring, over time it may swell, preventing the float from dropping all the way down. This could result in a false “FLOW” indication. The short term fix for this issue is to remove the o-ring, but it should be replaced to maintain backflow prevention.\nAs mentioned above, if the flow float becomes deformed it will no longer drop down into the plumbing, resulting in a false “FLOW” indication. Replacing the flow float will solve this problem.\nIf none of these steps fix the issue, it may be time to replace the magnetic reed switch in your plumbing. Remove the reed switch from the back of the plumbing. Hold the flow float directly against the reed switch. If the flow light does not come on (Model 140) or the “NO FLOW” alarm doesn’t clear (Model 1575/3175), the reed switch has failed.\nHow Lakewood Can Help\nRegular cleaning of the flow switch portion of the plumbing assembly should result in many years of reliable operation. However, if you ever notice that the controller flow status does not match actual conditions, you now know a few things to check. All of the components that make up the flows witch are readily available and easy to replace.\nCall us at (800) 228-0839.","Using Flowmeter Technologies in Process Cooling Service\nDifferent types of flowmeters meet a variety of needs in process cooling applications.\nThe design of process cooling systems typically focuses on the equipment that will actually do the cooling. Much is said and done about the type, size and materials of heat exchangers, cooling towers, refrigeration systems, cooling jackets and other cooling equipment.\nOnce design and selection are complete, consideration should be given to monitoring the flow of process cooling fluid through the equipment. In many installations, failure to monitor these flows reliably can reduce equipment life and increase downtime. In some installations, catastrophic equipment damage can result and produce negative impacts on cost and production as well as affect personnel safety.\nChoosing a Process Cooling Flowmeter\nFortunately, cooling systems are relatively forgiving in the sense that the flow of process cooling fluids can safely vary over a relatively wide range of flows. For example, assume that a piece of equipment requires 80 liters per minute (lpm) of cooling water to satisfy its worst-case process conditions, so the equipment will function properly when the process cooling flow rate is 80, 100 or 120 liters per minute or more. However, it will be more expensive to provide the cooling water needed to operate at the higher flow rates.\nThis range of acceptable flow rates means that the flowmeter does need not be overly accurate. For example, prudently setting the flow rate at 100 lpm would provide a 20 lpm safety margin in the above application to allow the heat exchanger to operate properly even if the flowmeter measures up to 20 percent higher than actual. In this application, a flowmeter that measures within 20 percent of the measured cooling water flow rate might, theoretically, be acceptable. However, installing a flowmeter with better accuracy specified as a percent of the measured cooling water flow might be more pragmatic to ensure sufficient cooling water flow. Be sure to note that these accuracies are percentages of the measured flow — not percentages of full scale or percentages of the flowmeter capacity.\nWhile this example may seem to show that cooling system flowmeters may not need to be that accurate, it may be beneficial for these flowmeters to actually be more accurate than the minimum. Providing more cooling water than is necessary costs money because the water needs to be treated and pumped through the cooling water system. In this application, the pumping cost of providing cooling water flow of 160 lpm to the equipment is twice that of operating at 80 lpm and 60 percent more than operating at 100 lpm. Installing a superior flowmeter that measures flow within 5 percent of the actual flow rate would theoretically allow operation at 85 lpm and further reduce the cost of pumping. Nonetheless, it might be pragmatic to actually operate the equipment somewhere above 90 lpm to provide an additional safety margin for abnormal operating conditions.\nWhile accuracy may be desirable, it is perhaps more important that cooling system flowmeters operate reliably and not fail. It should be clearly stated that many flowmeters have unsafe failure modes in which the flowmeter can measure a seemingly normal flow rate under no-flow conditions. A flowmeter that indicates flow when no flow is present does not provide protection for the equipment and can potentially pose a significant personnel safety hazard. Unsafe failure modes can occur in both electronic and mechanical flowmeters. However, flowmeters that use mechanical principles are typically more susceptible to fail unsafe than are flowmeters based on electronic principles.\nProcess Cooling Flowmeter Types\nThere are many flowmeters that can be used in process cooling applications. Perhaps the simplest device is a visual sight flow indicator where the operator can observe the turning motion of the indicating rotor in the flow. This device does not actually measure flow, but higher flow rates will turn the rotor faster. In time, operators will get a sense of when the rotor turns slowly, thereby indicating a potential problem.\nVisual sight flow indications are subjective in that different operators will interpret the rotor speed differently. As a result, the actual process cooling flow rates are typically set significantly higher than necessary to ensure that all of the operators recognize low flow conditions before the flow is actually too low. Using the example above, the operators will likely not be able to determine if the flow falls below 80 lpm when normal operation is at 85, 90 or 100 lpm. The system may have to be operated at (say) 160 lpm in order for all of the operators to reliably detect low flow.\nGlass-tubed and plastic-tubed float variable-area flowmeters are similar to visual sight indictors in that the fluid is visible to the operator. Float variable-area flowmeters have a float that rises when flow increases. Vane-style variable-area flowmeters have a vane that increases its rotation when the flow is increased. The operator can read the flow rate by using the float height or vane position in conjunction with graduations on the flowmeter. Variable-area flowmeters are commonly used on small pipes under 1 to 2\".\nVariable-area flowmeter accuracy is usually specified as a percentage of full scale, so be careful determining the desired flow rate to ensure adequate process cooling. Using the continuing example, a variable-area flowmeter with a full-scale flow of 200 lpm and an accuracy of 5 percent of full scale would have an absolute accuracy of ±10 lpm. Setting the process cooling flow rate at 90 lpm would appear to be reasonable to ensure adequate cooling. However, a higher setting should be used to account for other factors than can affect the measurement such dirt and coating.\nIn a bypass arrangement, a differential pressure flowmeter element is in the main flow of a larger pipe main and a variable-area flowmeter. The differential pressure element passes the overwhelming majority of the flow. Calculations are performed to determine the relationship between the flow through the bypass and the total flow so that the total flow rate can be inferred from bypass flow measurement.\nVortex-shedding flowmeters utilize a bluff body in the flow stream to create vortices that are similar to the vortices that are created downstream of a rock at the surface of a flowing river. The frequency of vortex generation is proportional to the fluid velocity — with the caveat that no vortices are formed at low flow rates. Vortex-shedding flowmeters in process cooling applications usually can be sized to operate high in their measurement range so this constraint is typically not an issue. In addition, their relatively robust construction with no moving parts makes them rugged and reliable.\nMany of the flowmeters described are relatively simple devices, but their operation can be labor intensive, energy intensive and prone to subjective results. Further, many are only active when they are actually observed by the operator. At best, observations may be performed hourly for only a few seconds. At worst, observations are made sporadically, perhaps once a month or less.\nVariable-area (vane and float) and differential pressure flowmeters are available with transmitters that can provide continuous process cooling flow measurements for monitoring and alarming process cooling flows. Vortex-shedding flowmeters are electronic and can inherently provide continuous measurements.\nFlowmeters with transmitters provide objective measurements that are not subject to varying degrees of operator discretion, and they can provide continuous protection, which enables the operator to focus on more productive work. For example, an operator may actually look at a local process cooling indicator for a few minutes (or seconds) during an 8-hr shift. This relatively low coverage increases the chance that an operator will miss a transient low flow event or perhaps not notice an event before equipment damage occurs. By contrast, a control system can monitor and alarm a more sophisticated process cooling flowmeter with a continuous measurement signal and detect all events that occur during the 8-hr shift when they occur. As a result, the operator is better able to address the event immediately, before the event affects the process. In addition, the operator can focus on other important activities with the time saved by not having to walk around to observe the local indicators.\nProcess cooling flowmeters are an important part of plant operation because they protect expensive plant equipment and plant personnel. Without these seemingly mundane instruments, much of the plant equipment could be in jeopardy if it is not operating safely and efficiently. The choice of flowmeters available for process cooling service is large, but visual sight flow indicators, variable- area flowmeters (vane and float), differential pressure flowmeters and vortex-shedding flowmeters represent pragmatic selections to ensure that process cooling flows are sufficient to protect equipment and personnel."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:0d40309a-c857-499c-870f-506fe4c201c3>","<urn:uuid:7be933a1-55c5-46a3-a422-2dc819eb7019>"],"error":null}
{"question":"What are the specific risks of nighttime road construction work, and how do sleep patterns affect worker safety in these situations?","answer":"Nighttime road construction carries significant risks, with 37% of work zone fatalities occurring at night due to factors like drunk or sleepy drivers, faster traffic speeds, and increased truck traffic. Poor lighting in work zones can lead to trips and falls, with shadows concealing hazards. Regarding sleep patterns' impact on safety, workers getting less than 7.5 to 8.5 hours of sleep accumulate a sleep debt that affects performance - losing one hour of sleep creates a 5-hour sleep debt after 5 days. This fatigue manifests in slower reaction times, decreased ability to absorb critical information, diminished judgment, and reduced ability to judge distance and speed - all crucial factors for worker safety in nighttime road construction.","context":["“Pressure from the driving public to reduce traffic congestion and delays associated with road maintenance and repairs have made our members toiling in work zones at night a common sight. Unfortunately,this adds to the risks that are always present when a jobsite is alongside a busy highway,” says LIUNA General President Terry O’Sullivan.\nBureau of Labor Statistics data shows that 37 percent of work zone fatalities occur at night. Some believe these tragedies happen because there may be more drunk or sleepy drivers on the road, because traffic is faster at night and because truck traffic is often higher.\nRegardless of why, it is important to have good signage and traffic control devices at night to properly warn motorists and regulate traffic through the zone,” O’Sullivan says. “It is also important for workers to be clearly visible to motorists. High-visibility garments and well-lit work zones are essential to worker safety and health.”\nANSI standards and the DOT’s Manual of Uniform Traffic Control Devices require Class 2 garments for day work and Class 3 garments for night work. Class 3 garments have reflective material on both pants and sleeves, which makes it easier for motorists to identify the worker as a person because they can see the legs and arms moving. Garments now use “retro reflective” material which reflects light from oncoming headlights very well. This is referred to as “passive illumination.” These materials get dirty, though, and they need to be cleaned or replaced periodically to maintain effectiveness.\nHowever, workers can be invisible if headlights are not shining on them directly. For this reason, many companies are now using vests and hardhats with LED lighting on them. This is called “active illumination.” Lighted vests and hardhats can be seen from a great distance and can flash or change colors. The only issue to address is battery life. Batteries will normally last a full shift but need to be recharged each night.\nAt a minimum, workers must be outfitted with ANSI-approved, clean, passively illuminated work gear and provided active illumination gear when at a high risk of runovers.\nWork Zone Lighting\nMaking sure workers are visible is not the only lighting concern in work zones. Construction jobs can be hazardous work and poorly lit nighttime worksites increase worker exposures to common construction hazards. Many injuries from trips and falls occur at night in poorly lit work zones. Poor lighting often causes shadows that can hide holes and tripping hazards.\nTo address nighttime hazards, every night job needs to have a lighting plan. Balloon lighting can provide more diffuse lighting that results in less glare and fewer shadows. Light towers are normally set up to light the work area effectively, but they must be positioned to avoid creating glare for drivers. If flaggers are used at night, a light tower needs to be dedicated to the flagger station. Backup generators are needed in case of a power failure.\nCombining high-visibility garments with sufficient work zone lighting creates a safer environment for both workers and motorists. The LHSFNA’s OSH staff can assist contractors in developing effective night work zone safety plans. For assistance, call 202-628-5465.\n[Scott Schneider is the LHSFNA’s Director of Occupational Safety and Health.]","Physical and mental fatigue both reduce a worker’s ability to safely perform essential driving-related duties. They’re a leading contributing cause to vehicle crashes – right up there with distractions, speed, and impairment. Insufficient quantity and quality of sleep are the two most common causes of fatigue.\nHow Fatigue Impacts Drivers\nPhysical fatigue results from strenuous activities that can exhaust your muscles. You may be unable to respond as quickly or as effectively as usual when driving.\nMental fatigue is the greater concern for most drivers. It decreases the ability to perform key driving tasks.\nEven an extra fraction of a second in reaction time can be the difference between a near miss and a serious, costly crash.\nRisks to drivers who are mentally and/or physically fatigued include:\n- Increased tendency to take risks\n- Increased likelihood of forgetting or ignoring normal checks or procedures\n- Decreased ability to absorb critical driving information and respond to it\n- Diminished judgment when deciding what actions to take to address a hazard\n- Reduced problem solving abilities and manual dexterity\n- Reduced ability to judge distance, speed, and time\nMain Causes of Fatigue\nPoor sleep and a lack of sleep are the most common factors contributing to driver fatigue. They can disrupt the natural 24-hour sleep/wake cycle, known as a circadian rhythm. Factors in work and everyday life can also contribute to driver fatigue. These include:\nWork Tasks, Environment, and Schedule\nIt doesn’t matter if workers are driving or not. They can be fatigued by any part of their job that is repetitive, boring, or strenuous. Complex tasks, and sustained mental or physical effort, also can cause fatigue. Driving for long hours requires constant concentration, for example.\nThe workplace environment – in a motor vehicle or elsewhere – can make drivers drowsy. Temperature, vibration, and light and noise levels all affect our alertness. So do humidity and low stimulation.\nEven a worker’s schedule can create fatigue. Night shifts, back-to-back shifts, overtime, and rotating shifts can affect the sleep/wake cycle. Working long or irregular hours can throw off circadian rhythms too.\nBeing Awake for Long Hours\nMedicationsSome prescription medications and over-the-counter medicines contain caffeine or other stimulants that can interrupt normal sleep patterns. The list includes heart, blood pressure, and asthma drugs. Pain relievers, cold decongestants, antihistamines, and diet pills also can affect sleep. Some medications can induce drowsiness.\nStressDemanding workdays can leave drivers feeling stressed out, frustrated, and exhausted. Stress from a driver’s personal life also takes its toll on driving performance.\nGetting less than 7.5 to 8.5 hours of sleep every night can leave drivers fatigued. Losing one hour of sleep each night creates a sleep debt of 5 hours after 5 days. Drivers need an equivalent amount of restorative sleep to make up for it.\nSleep apnea, insomnia, night terrors, and other disorders greatly reduce sleep quality.\nWarning Signs of Fatigue\nFatigue has many common symptoms but is difficult for drivers to self-assess. Tell-tale signs include the following:\n- Feeling sleepy, drowsy, or exhausted\n- Sore, heavy, droopy, or blood-shot eyes\n- Slower than normal reflexes and reaction times\n- Impatience or irritability\n- Aching, stiff, or sore muscles, or cramps\n- Lack of motivation\n- Daydreaming, decreased ability to focus or concentrate"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:599cf2d0-69b5-469a-9d8c-5a1ea0a07854>","<urn:uuid:e7a4e028-0b37-4d70-94b9-22802fb2d720>"],"error":null}
{"question":"Please outline the key security features that distinguish trusted hardware implementations in paralysis proofs versus digital timestamping, specifically regarding their resistance to compromise.","answer":"Trusted hardware and digital timestamping employ different security approaches. In paralysis proofs, trusted hardware (specifically Intel SGX) uses protected enclaves that even the computer's operating system cannot access, retaining control of a master key to the funds and remaining secure even if the computer is hacked. The hardware acts as a replacement for traditional trusted third parties like lawyers or banks. Digital timestamping, conversely, doesn't rely on hardware or keys at all for its security. Instead, it uses mathematical linking and widely witnessed summary numbers, making it immune to key disclosure. Furthermore, digital timestamping can maintain security through certificate renewal even as computational capabilities advance, while trusted hardware solutions remain dependent on the physical security of the enclave.","context":["Owning cryptocurrency comes with its own set of challenges. One of the biggest of those challenges is managing the private keys that enable you to spend funds. Lose your private keys, and your money is gone.\nIn a business environment, a common way to manage funds owned by multiple people is via what’s called a multisignature (multisig) address, a type of smart contract requiring two or more parties to sign off on a transaction to move the funds.\nThis can be problematic, however. Let’s say you have a three-of-three multisig that requires you and two business partners to sign off on a transaction. If one person dies, disappears or becomes incapacitated, those assets become frozen — a risk some might feel uncomfortable with when dealing with tens of thousands of dollars or more.\nOne way to ameliorate that risk might be to opt for a two-of-three multisig, where only two instead of all three individuals need to sign off on a transaction. But that’s not a complete solution either. Two players could conspire against the other one and run off with the money.\nWhat now? If your funds are on the Ethereum blockchain, you could write a smart contract that would allow you to free the funds if one person in your trio disappeared.\nHowever, Bitcoin with its limited scripting language makes things more difficult. “This seems like an unsolvable problem if you think about the traditional tools,” said Ari Juels, a professor at Cornell Tech and co-director of the Cornell Initiative for Cryptocurrencies and Contracts (IC3).\nIn a paper titled “Paralysis Proofs: How to Prevent Your Bitcoin from Vanishing,” researchers Fan Zhang, Phil Daian, Iddo Bentov and Ari Juels from the IC3 outline how to deal with what happens when a party is unable, or unwilling, to sign off on a multisig transaction in Bitcoin. The solution involves a combination of blockchain technology and trusted hardware — Intel SGX, in this case.\nTrusted hardware allows you to run code inside a protected enclave. Even a computer’s own operating system is unable to access data inside an enclave, so if your computer were to be hacked, the code in the enclave would remain secure.\nIC3’s solution proposes replacing a trusted third party, such as a lawyer or a bank, who would put money in an escrow, with a trusted hardware solution that retains control of a master key to the funds.\nIf one of the three people in the contract dies, the other two initiate a “paralysis proof.” That proof is based on a challenge sent to the missing third person. If the missing person responds to the challenge, the money stays put. If the missing person does not respond, the trusted hardware releases the funds to the remaining two players.\nTrusted hardware is only part of the solution, however. If the third person were to try and respond to the challenge request with an indication she is still alive, conceivably, the other players could intercept that message. To ensure that does not happen, the second half of IC3’s solution involves sending the message via the blockchain, which provides a tamper-proof and censorship-resistant medium.\n“By combining these two [methods], we can achieve the exact properties we’re after,” Juels explained to Bitcoin Magazine. “We can enable trusted hardware to determine whether or not somebody is alive, and there is no way to prevent a relevant message from getting transmitted if it is coming through the blockchain.”\nHow It Works\nPut simply, this is how to achieve a paralysis proof as outlined by the IC3 researchers:\n- Two players suspect a third is dead, so they post a challenge on the blockchain. The challenge consists of a tiny “dust” UTXO that the third person must spend within a certain period of time, say 24 hours, to prove she is alive.\n- The two players also get a “seize” transaction they may post to the blockchain later to collect the funds, if the third person does not respond to the challenge.\n- If the third person sends back a response by spending the UTXO, the game is over; the two others are not able to take control of the funds.\n- Alternatively, if the third person does not return an “alive” signal by spending the UTXO before the time-out, then the two others can use the “seize” transaction to take control of the funds.\nThis not the only use case for a paralysis-proof system. Juels thinks the solution would work well in any situation that called for a controlled access to private keys that could not otherwise be maintained on a blockchain. “It is actually a very general scheme you could use for lots of other purposes,” he said.\nFor instance, a paralysis-proof system could be used as a dead man’s switch for control over the release (or decryption) of leaked information or a journalist’s raw materials. It could also be used in numerous ways to control daily spending limits from a common pool of money or as a conditioned expenditure based on an outside event (as reported by an oracle), like a student getting good grades or a salesperson meeting a sales quota.\n“Basically, you can a rich set of conditions around the expenditure of money using the fact that a trusted hardware kind of acts like a trusted third party,” said Juels.","7.11 What is digital timestamping?\nConsider two questions that may be asked by a computer user as he or she views a digital document or on-line record:\n- Who is the author of this record - who wrote it, approved it, or consented to it?\n- When was this record created or last modified?\nIn both cases, the question is about exactly this record - exactly this sequence of bits. An answer to the first question tells who and what: Who approved exactly what is in this record? An answer to the second question tells when and what: When exactly did the contents of this record first exist?\nBoth of the above questions have good solutions. A system for answering the first question is called a digital signature scheme (see Question 2.2.2). A system for answering the second question is called a digital timestamping scheme. Such systems are described in [BHS93] and [HS91].\nAny system allowing users to answer these questions must include two procedures. First, there must be a signing procedure with which (1) the author of a record can ``sign'' the record, or (2) any user can fix a record in time. The result of this procedure is a string of bytes that serves as the signature. Second, there must be a verification procedure by which any user can check a record and its purported signature to make sure it correctly answers (1) who and what? or (2) when and what? about the record in question.\nThe signing procedure of a digital timestamping system often works by mathematically linking the bits of the record to a ``summary number'' that is widely witnessed by and widely available to members of the public - including, of course, users of the system. The computational methods employed ensure that only the record in question can be linked, according to the ``instructions'' contained in its timestamp certificate, to this widely witnessed summary number; this is how the particular record is tied to a particular moment in time. The verification procedure takes a particular record and a putative timestamp certificate for that record and a particular time, and uses this information to validate whether that record was indeed certified at the time claimed by checking it against the widely available summary number for that moment.\nOne nice thing aboutdigital timestamps is that the document being timestamped does not have to be released to anybody to create a timestamp. The originator of thedocument computes the hash values himself, and sends them in to the timestamping service. The document itself is only needed for verifying the timestamp. This is very useful for many reasons (like protecting something that you might want to patent).\nTwo features of adigital timestamping system are particularly helpful in enhancing theintegrity of a digital signature system. First, a timestamping systemcannot be compromised by the disclosure of a key. This is because digitaltimestamping systems do not rely on keys, or any other secret information,for that matter. Second, following the technique introduced in [BHS93],digital timestamp certificates can be renewed so as to remain valid indefinitely.\nWith these featuresin mind, consider the following situations.\nIt sometimes happensthat the connection between a person and his or her public signature key must be revoked. For example, the user's private key may accidentally be compromised, or the key may belong to a job or role in an organization that the person no longer holds. Therefore the person-key connection must have time limits, and the signature verification procedure should check that the record was signed at a time when the signer's public key was indeed in effect. And thus when a user signs a record that may be checked some time later - perhaps after the user's key is no longer in effect - the combination of the record and its signature should be certified with a secure digital timestamping service.\nThere is another situation in which a user's public key may be revoked. Consider the case of the signer of a particularly important document who later wishes to repudiate his signature. By dishonestly reporting the compromise of his private key, so that all his signatures are called into question, the user is able to disavow the signature he regrets. However, if the document in question was digitally timestamped together with its signature (and key-revocation reports are timestamped as well), then the signature cannot be disavowed in this way. This is the recommended procedure, therefore, in order to preserve the non-reputability desired of digital signatures for important documents.\nThe statement that private keys cannot be derived from public keys is an over-simplification of a more complicated situation. In fact, this claim depends on the computational difficulty of certain mathematical problems As the state of the art advances - both the current state of algorithmic knowledge, as well as the computational speed and memory available in currently available computers - the maintainers of a digital signature system will have to make sure that signers use longer and longer keys. But what is to become of documents that were signed using key lengths that are no longer considered secure? If the signed document is digitally timestamped, then its integrity can be maintained even after a particular key length is no longer considered secure.\nOf course, digital timestamp certificates also depend for their security on the difficulty of certain computational tasks concerned with hash functions (see Question 2.1.6). (All practical digital signature systems depend on these functions as well.) The maintainers of a secure digital timestamping service will have to remain abreast of the state of the art in building and in attacking one-way hash functions. Over time, they will need to upgrade their implementation of these functions, as part of the process of renewal [BHS93]. This will allow timestamp certificates to remain valid indefinitely.\n- 7.1 What is probabilistic encryption?\n- Contribution Agreements: Draft 1\n- Contribution Agreements: Draft 2\n- 7.2 What are special signature schemes?\n- 7.3 What is a blind signature scheme?\n- Contribution Agreements: Draft 3\n- Contribution Agreements: Final\n- 7.4 What is a designated confirmer signature?\n- 7.5 What is a fail-stop signature scheme?\n- 7.6 What is a group signature?\n- 7.7 What is a one-time signature scheme?\n- 7.8 What is an undeniable signature scheme?\n- 7.9 What are on-line/off-line signatures?\n- 7.10 What is OAEP?\n- 7.11 What is digital timestamping?\n- 7.12 What is key recovery?\n- 7.13 What are LEAFs?\n- 7.14 What is PSS/PSS-R?\n- 7.15 What are covert channels?\n- 7.16 What are proactive security techniques?\n- 7.17 What is quantum computing?\n- 7.18 What is quantum cryptography?\n- 7.19 What is DNA computing?\n- 7.20 What are biometric techniques?\n- 7.21 What is tamper-resistant hardware?\n- 7.22 How are hardware devices made tamper-resistant?"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:8bc1adfc-2903-49a9-8b5c-ffbe58678d0e>","<urn:uuid:695161c6-68c2-4643-97c7-1a7e83e46b24>"],"error":null}
{"question":"What are the key differences between swing and mambo as upbeat wedding dance choices?","answer":"Swing and mambo represent distinct upbeat wedding dance styles with different characteristics. Swing dance is based on a downward bounce, transfer of center of gravity, and redirection of momentum. It encompasses various styles including jitterbug, jive, boogie woogie, and Lindy hop, originating in the United States in the 1920s. In contrast, mambo is a fast, energetic Latin style dance that is more staccato in nature. It uses faster tempo Latin music and is more complex than other Latin dances like the rumba. While swing is characterized by its American origins and bouncy, energetic movements, mambo emerged in the 1940s with Cuban influences and requires more time to master due to its complex staccato movements and Latin rhythms.","context":["The vows have been recited, the rings have been exchanged, the cake has been cut, and now it is time to head to the dance floor. The newlyweds are now about to perform their first dance as husband and wife. This is one moment that has caused much anxiety during the wedding planning. “What song do we choose?” nervously asks the bride. “What dance do we do?” anxiously wonders the groom. This moment can be avoided by meticulous wedding planning. Choosing the song ahead of time along with the appropriate ballroom dance will have the happy couple looking forward to their first dance as a married couple, instead of dreading it.\nCassandra and Matt have been planning their upcoming nuptials down to the very last detail. While deciding not to use a ballroom dancing instructor, they still have gone to great lengths to choose the perfect song for their first dance together as husband and wife. They have also chosen the songs for the father-daughter dance and the mother-son dance. Deliberating as far out as six months in advance of her wedding day, Cassandra has made her decision. She will dance her first dance with her husband to Tenerife Sea by Ed Sheeran. She will also dance with her father to the song I Loved Her First by Heartland while the groom will dance with his mother to Forever Young by Rod Stewart. All it took was a little planning and forethought but now the stress of the first wedding dances is all over but the performance on the big day!\nI. Choose Your Wedding Song\nDepending on the couple, this step can come very easily or it can be very difficult for the couple to decide. The key is to make the chosen song meaningful for both bride and groom. Additionally, you may choose your first dance song based on the dance style that you wish to perform. Several song examples are given below to help guide you in deciding what type of dance style might be appropriate for the type of song and its melody.\nSong selections for their first dance chosen by famous couples instantly make headlines. For example, Prince William and Kate Middleton danced their first dance as the United Kingdom’s newest royal couple to Elton John’s Your Song. Chelsea Clinton and Marc Mezvinsky blessed their marriage with the song At Last by Etta James. Leaving nothing to chance, the soon-to-be Mrs. Mezvinsky called upon “Dancing with the Stars” professional Maksim Chmerkovskiy to choreograph a routine so their first dance as husband and wife would be flawless. Finally, Jenna Bush and Henry Hager began their marriage with a first dance song called Lovin’ In My Baby’s Eyes by Taj Mahal.\nII. Most Popular Wedding Dances\nThe four most popular dances performed at weddings are the foxtrot, swing, waltz, and rumba. While this list is by no means exhaustive, it covers the vast majority of dances that you will encounter at most weddings. This section will explore each dance style and give song examples for each style.\nThe foxtrot is a smooth, progressive dance characterized by long, continuous flowing movements across the dance floor. The style is a very popular at weddings because most find it easy to learn. Some foxtrot song selections are It Had to Be You by Frank Sinatra and Unforgettable by Natalie Cole.\nSwing dance is a relaxed and grounded dance based on a downward bounce, transfer of center of gravity, and redirection of momentum. While some may find it complicated at first, many find it to be the most fun after learning the steps. Some swing song selections are I Can’t Help Falling In Love by UB40 and How Sweet it is to be Loved By You by Marvin Gaye.\nThe romantic waltz is one of the most popular ballroom dances of all time. Considered by many dance professionals as the backbone dance of the ballroom, the waltz is the basis for many dances. A truly romantic dance, the waltz is comprised of soft, round, flowing movements. Some waltz song selections are Power of Love by Celine Dion and Unchained Melody by The Righteous Brothers.\nThe rumba is often referred to as the grandfather of the Latin dances. It is a dance that tells a story of love and passion between a strong, male lead and a somewhat submissive female partner. Full of sensual movements, the rumba is considered by many to be the sexiest of the ballroom dances. Some rumba song selections include Love Me Tender by Elvis Presley and Time After Time by Cyndi Lauper.\nIII. Consider Choreographing Your First Dance\nAfter you choose your song, consider working with a professional ballroom dance instructor to perfect your first dance as husband and wife. Ballroom dance instructor and studio owner Kelle Chancellor underscores this point by stating that when a couple has, “Taken the time to learn even a simple routine together, it shows [they] have taken the time and effort to make every moment of [their] wedding special.”\nIn reference to styles of dance, Kelle believes that one of the easiest styles to learn is the rumba. She describes it as a basic box step with an easy rhythmic sway that comes naturally to most couples. Another popular wedding dance that Kelle teaches is the waltz. Just like the rumba, both dances are slower and fit the romantic style and rhythm of most wedding songs. If a couple chooses a more upbeat tune, Kelle would most likely teach a foxtrot or a swing dance. Regardless of a couple’s song choice, an experienced ballroom instructor can accommodate most song’s tempo with the appropriate dance. So don’t be shy, hire a ballroom instructor and impress your entire wedding party with your fabulous moves!\nIV. Father-Daughter Wedding Dance Songs\nAnother consideration is learning a dance style and choosing the music for the father-daughter dance. This dance occurs directly after the official “wedding dance” of the bride and groom. The same popular dance styles are appropriate for this dance as well. For example, you could do the waltz to Butterfly Kisses by Bob Carlisle or I Loved Her First by Heartland. You could also dance the rumba to the song Father and Daughter by Paul Simon. These are just three examples of popular Father-Daughter Wedding Dance songs. There are hundreds of songs and many accompanying dance styles from which to choose.\nChelsea Clinton, daughter of former United States President Bill Clinton, chose to dance the foxtrot with her father to The Way You Look Tonight by Frank Sinatra. On the other hand, Jenna Bush, daughter of former President George W. Bush, danced the rumba with her father to You Are So Beautiful by Joe Cocker.\nV. Mother-Son Wedding Dance Songs\nJust like with the Father-Daughter Dance, if you choose to include a Mother-Son Dance, you should choose a special song and then learn the appropriate dance style for that song. A popular Mother-Son Dance song and accompanying dance style is What a Wonderful World by Louis Armstrong where you would dance the waltz. You could also dance the rumba to Bette Midler’s Wind Beneath My Wings or Eric Clapton’s Wonderful Tonight. Again, these are just three of the more popular suggestions for this particular dance. The song choices are as plentiful as the choices for the Father-Daughter Wedding Dance songs.\nVI. Sum It Up!\nChoosing the right song and style of dance are very important decisions that should be given deliberate thought by the bride and groom. After all, the first wedding dance is a memory that will last a lifetime. It also sets the stage for the upcoming dancing and remainder of the wedding celebration by the wedding party and guests. There are so many choices of songs and dances that it is essentially impossible for a couple to go wrong with their choice. As long as the couple chooses from their heart, their choice will be matrimonial perfection.","Wedding dance styles for the bride and groom’s first dance, father-daughter dance, mother son wedding dance and dancing at the reception include waltz, foxtrot and slow dancing but in recent years many more dance styles have become popular. Some couples choose a romantic, slow song, others opt for a spirited, energetic song or a mash up (mix) starting slow and romantic then breaking into a fast dance or freestyle.\nWe chose the best wedding first dance routines from the web with dance styles including traditional music like waltz, slow dance or foxtrot to the swing, Lindy hop or jitterbug, as well as, Latin selections like rumba, mambo, salsa and some mash up routines.\nWatch/listen to Best 25 First Dance Wedding Songs\n(Photo Art of Emotion’s “Best Dance Ever” 2013, see below)\nThe Different Types of Wedding Dance Styles\nWaltz Wedding Dance Style (classic, fast)\n(Recommended Waltz Dance Music Picks)\nThe Waltz dance is one of the most popular wedding dance styles. The waltz is a great choice for a wedding first dance. It is a 3/4 time rhythm, which differentiates it from other four beat rhythms. This dance is a smooth, fluid dance that normally moves around the floor in a counter clockwise direction. There is an additional rhythm called the Hesitation that is used in combination with three count or six count patterns in the waltz. There are a variety of waltz dance variations including: American Waltz, International, Country Western, Cajun, French and Viennese waltz and there are classic versions and contemporary versions of waltz.\nWaltz Wedding Dance Styles (Contemporary, fast)\nA Thousand Years by Christina Perri (Fast Waltz)\nThe waltz is composed of box steps and turning patterns that rotate both clockwise and counterclockwise. The waltz started in the mid-nineteenth century and was considered scandalous because of the facing embrace, in its day. The first waltzes were danced to Strauss music, which were fast, referred to as Viennese waltz (tempo) today. This is an enduring favorite among the different wedding dance styles for couples first dance. Read more about the different types of waltz styles here!\nSlow Wedding Dance Styles\nThinking Outloud by Ed Sheeran (a slow dance)\nSlow Dance (or Nightclub Two Step)\nThe slow dance (or nighclub two step) is a more recent popular wedding dance style of music and dancing. It is also a very popular dance genres for wedding first dance since they are slow and romantic. There is music which does not fit into any of the ballroom slow dances: waltz, foxtrot and rumba. These songs are slower than the tempos for the ballroom dance genres. Choosing one of these types of songs means dancing either a traditional slow dance, which includes side steps and pivots or one might choose a Nightclub Two Step depending on the music.\nNightclub Two Step was developed by a Buddy Schwimmer, a dance studio owner, dancer, promoter that was part of the Golden State Teachers Association in Southern California. The nightclub two step has evolved over the years and can be done starting with a rock step on counts 1&, followed by a side step on count 2 or some start with the side step on count one. A slow dance or nightclub two step is a great choice for a sensual, slow wedding first dance.\nFoxtrot Wedding Dance Styles\nLove by Michael Buble\nThe Foxtrot dance is a smooth, progressive dance that moves around the dance floor to a 4-beat rhythm with a combination of 6 or 8 beat patterns. It is an elegant wedding dance style that is perfect for a larger dance floor and a smooth medium tempo music especially big band style music or some of the contemporary artists like Michael Buble.\nThe foxtrot dance developed in the early part of the 20th century from other dance genres and popularized by Vernon and Irene Castle. The foxtrot has continued in its popularity among both social ballroom dancers and dancesport enthusiasts.\nSwing Wedding Dance Styles (Jitterbug, Lindy Hop)\nSing Sing Sing by Louis Prima (Swing dancing)\nSwing dance is a term used to refer to a group of dances that includes the jitterbug, jive, boogie woogie, shag, Lindy hop, Balboa, West and East Coast swing. This is a fantastic choice for a wedding first dance if you are looking for an energetic wedding dance style for your wedding!\nSwing Wedding Dance Styles (Shag)\nStagger Lee by Lloyd Price (Swing dance)\nSwing dancing is all American as the swing originated in the United States, in Harlem at the Savoy Ballroom in the 1920’s following the Charleston and in conjunction with the Balboa and other swing forms like the origin swing dance, the Lindy Hop. The swing is a great and more energetic than the previous wedding dance styles.\nJitterbug Wedding Dance Styles\nSing Sing Sing by Benny Goodman (Jitterbug)\nSwing Wedding Dance style (Mix)\nSwing music “Fly Me To the Moon” by London Swingfonia\nRumba Wedding Dance Style\nSway by Michael Buble\nThe rumba dance (also Rhumba) is danced to Latin music that has is fluid and varies but averages about 140 beats per minute. It is rhythmic, sensual and romantic so it is a great choice for a wedding first dance. Also, the American style box rumba is slower and easier than other forms of Latin dance like mambo, salsa and cha cha. The rumba is easy to learn as it is composed of a box step and a variety of break steps (rock steps).\nThe history of the rumba dance is elusive since it derives from a group of other dances that originated in different countries. The term “Rumba” (also Rhumba) is used to refer to a group of rhythmic dances of Spanish and African roots that originated in Cuba. The American ballroom rumba developed from some of these early Cuban “son” dances in the early 20th century. The word used to mean “party” but later in the 1920’s and 1930’s came to refer to a dance genre. The early ballroom rumba was done to faster music, e.g. Peanut Vendor but later the International style Latin dancers danced to slower “bolero” son music. The rumba is a romantic dance style danced to slower music with a Latin flair.\nMambo Wedding Dance style\nMambo (or Salsa)\nThe mambo dance is a fast, energetic Latin style dance. Wedding couples choose this dance often because of the movie, Dirty Dancing, and the mambo that Patrick Swayze danced with Jennifer Grey in the movie to the song, “I’ve Had the Time of My Life,” by Bill Medley & Jennifer Warnes. The mambo dance uses a faster tempo Latin music and is more staccato than the salsa. It is a more complex dance than the rumba and requires more time to become an accomplished mambo dancer.\nThe mambo dance originated in the 1940’s and was popular in Cuba, Mexico City and New York but eventually spread across the globe and was popular for several decades until it evolved into the salsa in the mid-1970’s. It is still danced today especially in American rhythm competitions. The Latin dances have become more popular in recent years among the various wedding dance styles!\nThe salsa dance is a rhythmic Latin dance that has continued in popularity since the 1970’s. Choosing a salsa song to dance as a wedding first dance is an exciting option. This dance is sensual, fast paced and rhythmic. It requires more time to learn than a rumba or basic swing dance.\nThe salsa dance originated in New York with influence from Cuba and Puerto Rico. It is derived from cha cha and mambo. There are unique styles of salsa in different regions of the world including: Cuban, Miami, Colombian, Los Angeles and New York.\nWatch and read more about the salsa dance here.\nMashup Wedding Dance styles\nLove Never Fails by Brandon Heath (Slow, Freestyle, Swing)\nWedding Mixed Songs Mashup Style\nUnchained Melody by Air Supply\nWedding Dance Mash Up Style\nThe mash up wedding dance has become popular in the last few years with brides and grooms. A mash up is a choreographed routine to more than one song. I could be two, three or more different types of music. For instance, a mash up might include a slow romantic song like a waltz, then an energetic swing dance followed by a classic Michael Jackson. Moreover, a mash up is a great way to include several of your favorite wedding dance songs. Lastly, a mash up keeps everyone’s attention during the wedding first dance.\nWedding Dance Music\n- Check out DanceTime’s Recommended Wedding Songs\n- Watch Listen to Popular Wedding Reception Music\n- Watch/Listen to Top 25 First Dance Wedding Songs\n- Watch/Listen to Best 25 Father Daughter Dance Songs\n- Watch / Listen to Mother Son Wedding Dance Songs\nMore Wedding First Dance Information:\n- Watch/Read Complete Guide to Wedding Dance Lessons\n- Watch some Wedding Dance Fails (humor)\n- Read more about the Wedding Dance\n- Additional Wedding Dance FAQ’s"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:0f7af162-6c04-41a5-9c95-4d37f6f3e249>","<urn:uuid:49c195cd-95f7-4776-99c7-c4d6df9ca1d8>"],"error":null}
{"question":"How does the efficiency of a small transmitting loop antenna compare to an isotropic antenna in terms of radiation patterns?","answer":"Small transmitting loops and isotropic antennas have fundamentally different radiation characteristics. The small transmitting loop can achieve enhanced efficiency through its construction, particularly when using open-ended copper tubing that creates two parallel conductors (outer and inner surfaces) that can nearly double the effective surface area. This parallel current flow contributes to the magnetic field generation. In contrast, an isotropic antenna is a theoretical concept that radiates equally in all directions with 100% efficiency and a uniform gain of 1 dB in all directions of spherical space. The small loop's radiation is primarily driven by its magnetic field component, making its pattern more directional than the perfectly uniform pattern of an isotropic antenna.","context":["Small transmitting loop enthusiasts search for explanations of why their antennas are so fantastic.\nOne of those fantastic explanation is from KK5JY:\nI have spent some time thinking about this discrepancy, and how to account for it within the typical ham home-made loop. This is not to say that I am asserting this as correct, but I suspect there are straightforward reasons why the efficiency of a small loop of typical construction could be better than the classic formulae predict.\nOne simple possibility has to do with construction. Many loop designs, mine included, use open-ended copper tubing for the radiating element. Mechanically, this means that the loop itself actually has two conductors, wired in parallel. One is the outside of the loop conductor, and one is the inside of the loop conductor. The reason for this is skin effect. Anybody who has run high power RF into a coaxial cable that is poorly matched to a balanced antenna is familiar with the “feedline radiation” effect, where the shield of the coaxial cable forms two conductors, with current flowing on both. In the loop case, The outer and inner surfaces of the loop conductor are connected together at the ends, so the two conductor shells carry current in parallel. Depending on the difference in diameter of the two surfaces, the effective increase in surface area can be almost 100%, roughly doubling the surface area of the main element. “But the inner conductor is shielded from the environment by the outer conductor,” someone might object. This is true for the electrical field, but not the magnetic field, which just happens to be the largest component of the EM near-field created by this type of antenna. A small loop is driven almost completely by the magnetic field generated by the driven element, and the lines of magnetic flux cut both the inner and outer surfaces of the main (large) loop, inducing current flow into each one, independently, and the two are able to create a combined magnetic field around the antenna.\nContinue reading Exploiting waveguide mode of the loop conductor in a small transmitting loop\nThis article documents measurement of the calibration of an IC-7300 S-meter in SSB mode using a continuous sine wave at 1kHz tone frequency.\nThere has been a long standing convention that S-meters are calibrated for 50μV in 50Ω to be S9, and S-points laid out at 6dB per S-point. IARU Region 1 formalised this with Technical Recommendation R.1 which defines S9 for the HF bands to be a receiver input power of -73 dBm (equivalent to 50μV in 50Ω).\nA test was conducted where a Standard Signal Generator was connected to the receiver and slowly increased from -125dBm in steps of 1dB and the point at which the S-meter display segments lit was noted.\nAbove is a chart of the error between the S meter indication and the value per IARU Region 1 Technical Recommendation R.1. Continue reading IC-7300 S-meter calibration accuracy\nI have a Kenwood R5000 that is now 30+years old and warrants a check of its health.\nR5000s are infamous for VCO problems, the early production used ‘yella glue’ to stabilise the VCO components and that decomposed into corrosive components that damage the electronic parts. Repair is not usually economically rational.\nThis is one of the later model R5000s that used the hard white adhesive which has remained stable.\nThe R5000 is built on phenolic PCB and operates at relatively high temperature for a simple receiver, reflecting the power consumption of synthesisers of the 1980s.\nAbove, the case temperature is up to 20° above ambient over the power transformer (upper right of pic). Continue reading Kenwood R5000 thermals\nA correspondent has been tearing his hair out trying to replicate my VSWR plots of some STL.\nAbove is an example where the Z0 has been set to 0.0901847Ω which is the feedpoint impedance of the loop at resonance. Continue reading 4NEC2 plots of STL VSWR\nThe ‘net abounds with calculators for design of small transmitting loops (STL), and most estimate the voltage impressed on the tuning capacitor. Most of these calculators give an incorrect estimate.\nThis article describes a measurement based approach to estimating the capacitor voltage for a STL.\nContinue reading Estimating the voltage impressed on the tuning capacitor of a small transmitting loop\nThe ‘net abounds with articles describing easy to build low cost small transmitting loops (STL).\nThis article describes measurement of a STL for 4MHz using RG213 coaxial cable for the main loop and its tuning capacitance, and a smaller plain wire loop for transformation to 50Ω. Continue reading A QRP small transmitting loop evaluation\nPrecise RF have announced two small transmitting loops for amateur radio, this article looks at the Precise High Gain Loop.\nThe antenna is described at (Precise RF 2017).\nAbove is an extract from a table in the brochure comparing the subject antenna to some others.\nOn a quick scan, the standout figure is gain of 2.8dBd presumably at a loop height of 4.57m (15′), and without qualification of frequency. Elsewhere in the brochure there is a note that 80m requires an optional ‘resonator’… presumably a larger loop.\nLets review the meaning of dBd\nThe ITU Radio Regulations (ITU 2012) gives us a definition for antenna gain that captures the meaning of dBd that is accepted by most regulators and industry world wide. Continue reading Precise RF small transmitting loop\nAs the popularity of low cost, low end antenna analysers increases, client software appears to enhance the capability of the analyser.\nThe SARC-100 is one of these low end analysers, it and its many close derivatives are marketed under various model names.\nThe sign of reactance discusses a major weakness of these and many other low end instruments in that they do not ‘measure’ the sign of reactance, displaying the magnitude of reactance and leaving it to the user to solve the sign problem.\nSM6WHY is one of the many who have produced software for the SARC-100 that purports to solve the sign of reactance problem. He gives this graphic on his website to demonstrate the capability of his software used with a SARC-100 (which does not sense the sign of reactance).\nAbove is part of the graphic he offers. Though the image is poor quality, the VSWR plot appears smooth and quite typical of that which might be obtained by measuring an antenna system near its VSWR minimum.\nHowever the accompanying Smith chart plot which has points plotted with both negative and positive reactance is inconsistent with the VSWR plot and appears flawed. Continue reading The sign of reactance – SM6WHY’s take\nShunt matching a loaded HF whip with just a VSWR meter gave a direct answer and supporting explanation to an online poster’s question about optimising an 80m loaded mobile vertical with shunt matching, specifically the inductor needed and an adjustment procedure.\nThe original poster clearly had the impression that this improvement of the original VSWR=1.3 would make a large difference.\nThe only other option for me is to remove the shunt and set my swr back to 1.3:1 and not be able to communicate.\nContinue reading Shunt matching a loaded HF whip – discussion\nThis is a republication of an article posted on VK1OD.net Jun 2012.\nThis article presents a derivation of the power at a point in a transmission line in terms of ρ (the magnitude of the complex reflection coefficient Γ) and Forward Power and Reflected Power as might be indicated by a Directional Wattmeter. Mismatch Loss is also explained. Continue reading Power in a mismatched transmission line","- What is the gain of isotropic antenna?\n- How do you calculate directivity?\n- What is directivity and gain of antenna?\n- What is meant by isotropic antenna?\n- What is bandwidth in antenna?\n- Where is horn antenna used?\n- What is antenna gain formula?\n- What is the minimum value of directivity?\n- Is higher antenna gain better?\n- Are high gain antennas worth it?\n- Why is antenna gain important?\n- Does antenna gain affect reception?\n- What is meant by directivity?\n- Is a higher dBi Antenna better?\n- Which antenna has highest gain?\nWhat is the gain of isotropic antenna?\nAn isotropic antenna is a theoretical antenna that radiates equally in all directions – horizontally and vertically with the same intensity.\nThe antenna has a gain of 1 dB in the spherical space all around it and has an efficiency of 100%..\nHow do you calculate directivity?\nDirectivity is the ratio of the radiation intensity in a given direction from the antenna to the radiation intensity averaged over all directions (IEEE 1993, p. 362). Notes: (1) The average radiation intensity is equal to the total power radiated by the antenna divided by 4p (area of sphere in steradians).\nWhat is directivity and gain of antenna?\nDirectivity is the measure of the concentration of an antennas’s radiation pattern in a particular direction. Directivity is expressed in dB. The higher the directivity, the more concentrated or focussed is the beam radiated by an antenna. … Gain is the product of directivity and efficiency.\nWhat is meant by isotropic antenna?\nAn isotropic antenna (also known as an omnidirectional antenna) emits the signal uniformly in all directions. In other words, at distance d from the antenna, in any direction, the transmitted signal power is the same (Figure 5.1).\nWhat is bandwidth in antenna?\n– Bandwidth The bandwidth of an antenna refers to the range of frequencies over which the antenna can operate correctly. The antenna’s bandwidth is the number of Hz for which the antenna will exhibit an SWR less than 2:1. The bandwidth can also be described in terms of percentage of the center frequency of the band.\nWhere is horn antenna used?\nHorn antennas are commonly used as the active element in a dish antenna. The horn is pointed toward the center of the dish reflector. The use of a horn, rather than a dipole antenna or any other type of antenna, at the focal point of the dish minimizes loss of energy (leakage) around the edges of the dish reflector.\nWhat is antenna gain formula?\nAntenna gain is usually defined as the ratio of the power produced by the antenna from a far-field source on the antenna’s beam axis to the power produced by a hypothetical lossless isotropic antenna, which is equally sensitive to signals from all directions.\nWhat is the minimum value of directivity?\nThe numerical value of D always lies between 1 and ∞. The idealized isotropic antenna radiates equally in all the directions, so its beam area ΩA = 4π sr. This is the lowest possible directivity (D = 1). All actual antennas have directivities greater than 1 (D > 1).\nIs higher antenna gain better?\nSince an antenna does not make power, increasing gain in one direction will decrease propagation in another. … On an open and flat highway, a high gain antenna will be better… 3 dB, 6 dB, etc. If your desired coverage area is hilly then a ¼ wave omnidirectional antenna will be better.\nAre high gain antennas worth it?\nIn discussions of how to improve wireless range and coverage, the subject of higher-gain antennas usually comes up. Higher-gain antennas seem to be a better choice than looking for routers with higher transmit power because antenna gain applies to both transmit and receive signals.\nWhy is antenna gain important?\nAntenna gain indicates how strong a signal an antenna can send or receive in a specified direction. … If the comparison is to an ideal (text-book pattern, lossless) antenna radiating or receiving energy equally in all directions, the gain is measured in dBi (decibels-isotropic).\nDoes antenna gain affect reception?\nWhen transmitting, a high-gain antenna allows more of the transmitted power to be sent in the direction of the receiver, increasing the received signal strength. When receiving, a high gain antenna captures more of the signal, again increasing signal strength.\nWhat is meant by directivity?\nIn electromagnetics, directivity is a parameter of an antenna or optical system which measures the degree to which the radiation emitted is concentrated in a single direction. … An antenna’s directivity is a component of its gain; the other component is its (electrical) efficiency.\nIs a higher dBi Antenna better?\nThe higher the dBi number of the antenna, the higher the gain, but less of a broad field pattern, meaning that the signal strength will go further but in a narrower direction, as illustrated in the diagram below.\nWhich antenna has highest gain?\ndBd – “decibels relative to a dipole antenna”. Note that a half-wavelength dipole antenna has a gain of 2.15 dBi. Hence, 7.85 dBd means the peak gain is 7.85 dB higher than a dipole antenna; this is 10 dB higher than an isotropic antenna."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:48d1184d-99de-4c39-b2c7-6b5d73feacc6>","<urn:uuid:3174cc05-c86a-47e4-b87a-61ffaa77a85a>"],"error":null}
{"question":"How does proper gravel extraction technique differ from risky practices, and what are the economic implications of sand and gravel mining?","answer":"Proper gravel extraction requires several safeguards: never mining deeper than the water elevation at the time of removal, maintaining a 50-foot undisturbed buffer at the top of high banks, keeping a 20-foot buffer between mining equipment and stream bank vegetation, avoiding mining from riffles, and not relocating or straightening stream channels. Risky practices include mining too deep, which steepens the channel and causes erosion, stockpiling material in the channel, and washing gravel too close to the stream. Regarding economics, sand and gravel, despite their low unit value, are major contributors to national economic well-being. They are among the most accessible natural resources and serve as basic raw materials for the construction industry. The industry is significant enough that concrete mix trucks transport an average of 16.2 tons per delivery and must complete delivery within about 1.5 hours.","context":["Mining Gravel and Protecting Streams\nOwners of streamside land have always faced flooding and erosion due to natural events, but damages caused by in-stream mining should not be an additional threat to personal property.\nMore than 500 in-stream mining sites exist in Missouri. Considering the potential harm any one gravel mining operation can cause, it is important that gravel mining occur only with proper safeguards.\nMissouri's streams are vulnerable to huge problems caused by gravel mining. These waterways have formed within their valleys over thousands of years. During this period, the stream meandered across its flood plain. Because this movement of the stream channel happens very slowly over many years, natural erosion occurs at a rate to which the stream can adjust.\nThe characteristics of a given stream are not formed on hot summer days when there is little water flowing in the channel. Instead, our streams are carved out during periods when the stream channel is flowing at least half full. During high flow, the water has enough power to cause changes.\nStreams are a series of alternating deep areas called pools and shallow areas called riffles. Riffles are high areas of the stream bottom that control the slope of the stream. It's because riffles help control the slope of the stream that they work to control erosion.\nGenerally speaking, erosion occurs on outside bends and silt, sand and gravel deposition occurs on the inside bends. This process produces the sinewy characteristics that we are accustomed to seeing as we float, fish or swim in our favorite stream.\nGravel mining often results in piles or pits that, during high water events, can rapidly increase the erosive process in streams.\nAlthough many of our streams have plenty of gravel to spare, we also have many streams which cannot afford to have gravel removed from them. To ensure you are mining from a stream that has ample gravel, look for some key characteristics. Streams with excess gravel generally have gravel bars with little or no vegetation growing on them. The rocks are generally small (less than three inches in diameter) and are loosely packed.\nGravel bars that are vegetated or where the rocks are tightly packed (not easily loosened when kicked) are characteristic of healthy streams with just the right amount of gravel. These should not be disturbed.\nWhen practical, rock aggregate should be acquired from non-stream sources such as nearby rock quarries, but if you must remove sand or gravel from a stream or its flood plain, at least do it in ways that will not damage your property or your neighbor's property.\nWithout a doubt, the worst damage caused by gravel mining is the extensive erosion that results when the mining operation makes the slope of the stream channel steeper than it was before mining. When a stream channel is made steeper, the water flows faster; and the faster it flows, the more power it has to cause erosion. In these situations, the bottom of the stream channel erodes away first, and then the stream banks fall in and wash away.\nIf the gravel mine is a pit dug in the stream channel and the miner continues to take gravel over a long period of time, the erosion can move far upstream and cause extensive property damage to many streamside landowners. Because of these potential problems, gravel should never be mined deeper than the water elevation at the time of removal. If the stream channel is dry, mining should not be deeper than the elevation of the stream bottom at the site. If you don't mine too deep, the natural slope of the channel will not steepen, and the risk of serious erosion damage to neighbors will be reduced.\nGravel should never be removed from riffles because breaking up the riffle threatens channel stability and important habitats for fish and other aquatic life.\nGravel miners need to get their equipment through the stream corridor and into the stream channel, but the wooded corridor along the stream protects the waterways and, itself, needs to be protected. This forested area slows erosion, filters excess nutrients and sediments, baffles powerful flood flows and provides important habitat for aquatic and terrestrial plants and animals. It also protects the waterway from our other activities in the flood plain and watershed and keeps stream temperatures cooler with its shade.\nWhen mining gravel, maintain an undisturbed buffer at least 50 feet wide at the top of the high bank and that extends for the length of the excavation site. Construct access points from the high bank into the channel to minimize erosion of both the access road and stream banks. Make sure you replant areas disturbed for access once excavation is complete.\nIt's also important to leave a 20-foot wide buffer from which mining equipment is restricted between the mined area and stream bank vegetation. Keeping mining equipment out of this area assures that the stream will not change its course as a result of the mining. It will also prevent eroded material from causing siltation problems downstream and will protect the roots of plants that prevent bank erosion.\nWhen gravel mining, never relocate or straighten stream channels. Doing so can cause instability that leads to excessive erosion of the streambed and banks.\nOnce mining is finished, unused material should be returned to the removal site and smoothed to mimic the original contours of the bar. Unused material should not be stockpiled in the channel, placed against the stream banks or deposited in a stream side wetland. Stockpiling material in the channel obstructs high stream flow, which can increase stream bank erosion. Pushing material against stream banks may actually increase erosion at the site. Remember, any sand, gravel, silt or other sediment eroded from one place will deposit somewhere else and may cause you or your neighbor serious problems.\nWater quality is always a primary concern, so fuel, oil and other wastes should not be stored in the channel. Sudden high flows from rain storms may cause spills.\nFish, macro-invertebrates and other stream creatures rely heavily on the stream bottom to maintain healthy populations. The stream bottom provides food, spawning habitat, a place to protect eggs, nursery habitat and shelter from predators. It only makes sense that gravel mining can be harmful to these stream dwellers.\nThe smallest particles of sand and soil carried by a stream are called \"fines.\" This is what makes a stream look muddy after a heavy rain. Normally, these fines settle as the water level in the stream falls after a rain and no harm comes from their presence. If we do something to cause an excessive amount of fines, then the water remains muddy and the bottom may become covered with this silt, causing many problems for fish and other aquatic life. We can prevent some of the risk by avoiding mining during the spawning season.\nA common practice in gravel mining is to wash the gravel to remove these fines. Sand and gravel washing as well as gravel crushing and sorting should occur far enough away from the channel so that the warm, stagnant, silty wash water cannot enter the stream. This will protect water quality and prevent sedimentation (silting) of important stream bed habitats.\nUsing proper techniques and safeguards, it's possible to excavate sand and gravel without increasing erosion and with little or no damage to important habitats of aquatic plants and animals. If you have questions about proper ways to excavate sand and gravel from stream channels contact the Missouri Department of Conservation for guidance and a free brochure.","Although significant amounts of sand and gravel are used for fill, bedding, subbase, and basecourse without processing, most domestic sand and gravel are processed prior to use. The processing of sand and gravel for a specific market involves the use of different combinations of\nSome sand is also used as a scouring agent, traction sand in rail transportation, lining for high-temperature furnaces, and in the manufacture of metallurgical alloys. Thus, one aspect of sand and gravel mining that is not often realized is that many sites are simply sand mines .\nSince both contain sand and gravel, it is assumed that the material is consistent between the two pits. Two other test pits, C and D, are dug. The new pits are 300 feet apart. If all the test pits show sand and gravel, it is assumed that the entire area, 300 feet by 300 feet contains sand and gravel.\nBecause of the instability of sand and gravel, the pit face should never be allowed to get higher than 20 to 25 feet for safe extraction. For deposits of 65 to 100 feet, benches or steps are often used\nAlong with their uses in concrete, sand and gravel are also commonly used for landscaping, road bases and coverings, unpaved roads, fill, asphalt, roofing shingles, water filtration, and to provide traction on snowy and icy pavement. The Production Process. The weathering of rocks over many years produces sand and gravel naturally.\nUses. Sand and gravel are used for road construction, for mixing with asphalt, as construction fill, and in the production of construction materials like concrete blocks, bricks, and pipes. It is also used to make roofing shingles, used on icy roads in the winter, for railroad ballast, and water filtration.\nThe extraction of sand and gravel from river beds, banks and floodplains is driven by human needs for raw materials for concrete, glass and paint making, and construction works. Direct extraction of alluvial material from river channels causes far greater impacts than floodplain extraction. According to Rinaldi et al. 2005, the effects of bed ...\nConstruction sand and gravel, one of the most accessible natural resources and a major basic raw material, is used mostly by the construction industry. Despite the low unit value of its basic products, the construction sand and gravel industry is a major contributor to and an indicator of the economic well-being of the Nation.\ncycles of erosion and deposition of sand and gravel. The extraction of sand and gravel from rivers, streams, floodplains and channels conflict with the functionality of river ecosystems. Some of the disturbance is from the mining methods and machineries used. The most common environmental impact is the alteration of land\nC.M.G. Vivian, L.A. Murray, in Encyclopedia of Ocean Sciences Second Edition, 2009 SandGravel Extraction Introduction. Sand and gravel is dredged from the seabed in various parts of the world for, among other things, land reclamation, concreting aggregate, building sand, beach nourishment, and coastal protection. The largest producer in the world is Japan at around 80100 Mm 3 per year ...\nSand and gravel is mixed with cement to produce concrete for transport in mix trucks for local use. Mix trucks transport on average about 8 cubic yards or 16.2 tons of concrete each and must deliver the finished concrete customers within about 1.5hrs.\nSep 21, 2016 A gravel pit is a type of open-pit mine used for the extraction of sand and gravel aggregate from a deposit near the surface of the earth. Sand and gravel serve a variety of purposes across a whole bevy of industries, including in the mixing of concrete for road surfacing and in the production of other construction-related materials.\nSand and gravel mining refers to the actual process of removal of sand or gravel from a place of occurrence. The increase in demand for sand and gravel for construction purposes has placed immense pressure on the environment where these resources occur. Miners employ different methods of extraction\nABSTRACT For thousands of years, sand and gravel have been used in the construction of roads and buildings. Today, demand for sand and gravel continues to increase. Mining operators, in conjunction with cognizant resource agencies, must work to ensure that sand mining is conducted in a responsible manner. Excessive in-stream sand-and-gravel mining doc, pdf\nIn Minnesota, sand and gravel mining is increasingly viewed as a temporary use to be followed by another land use that is compatible with the surrounding landscape. The need to reclaim gravel pits and the demand for technical information on the subject was the motivation for this handbook.\nSand and gravel resources are plentiful throughout the world. However, because of environmental regulations, geographic distribution, and quality requirements for some uses, sand and gravel extraction is uneconomical in some cases. The most important commercial sources of sand and gravel\nExtraction of sand and gravel for construction aggregate is the largest mining industry in most . Freshwater Gravel Mining and Dredging Issues . Freshwater Gravel Mining and Dredging Issues, Fish ..\nland and uses Land uses in the area consist of sand and gravel extraction, agriculture principally cattle grazing with minor cropping and forestry. Rural residential premises are also located in the surrounding area. The property is bordered by the Inglis River to the West. Across the river there are a number of rural residential properties.\nJul 02, 1996 Under the zoning ordinance, mining, sand and gravel extraction is expressly designated a conditional use in that zone. Wright County, Minn., Zoning Ordinance 604.4 1995. Thus, such a use is deemed consistent with the public health, safety, and general welfare and consonant with the goals of the locales comprehensive plan.\nfrom the extraction of sand and gravel. Analytical results indicate that every day, approximately 600 ft 3 of rocks and 37,500 ft 3 of sands have been extracting commercially from the study area\nNov 08, 2019 Sand, however, is the most-consumed natural resource on the planet besides water. People use some 50 billion tonnes of aggregate the industry term for sand and gravel\ntypes, including special use properties. Based on the above findings, the most appropriate method of valuing sand and gravel property is the income approach. For this property type, valuation experts should use the same valuation process that is used by owneroperators when buying or leasing land, if only to reflect the\nSand amp Gravel Mining in the US industry outlook 2021-2026 poll Average industry growth 2021-2026 x.x lock Purchase this report or a membership to unlock the average company profit margin for\nMining water use is water used for the extraction of minerals that may be in the form of solids, such as coal, iron, sand, and gravel liquids, such as crude petroleum and gases, such as natural gas. The category includes quarrying, milling of mined materials, injection of water for secondary oil recovery or for unconventional oil and gas ...\nworked out mineral sites within the sand and gravel resource in the Trent, Lower Derwent and Lower Dove valleys i.e. the study area. 1.10 The Minerals Local Plan through Policy MP21 makes provision for sand and gravel working by allocating specific preferred areas the study sites where there is a strong presumption in favour of extraction. The\nSand and gravel are widely used throughout the U.S. construction industry, but their extraction can significantly affect the physical, chemical, and biological characteristics of mined streams. Fisheries biologists often find themselves involved in the complex environmental and regulatory issues related to instream sand and gravel mining. This paper provides an overview of information ...\nSand and gravel deposits and bedrock may be mined or quarried to produce raw materials known as aggregate. Aggregate is necessary to manufacture concrete, asphalt, and other products. These products are the building blocks for our homes, businesses, roads, and bridges. Certain types of rock may be used as decorative stone. The United States produces about 17.6 billion dollars\nFor use as construction sand and gravel Mining Raw Material Transport Raw Material Storage Ground Material Storage Product Storage 3-05-027-60 1 2 3 1 1 Emission point PM emissions Combustion product emissions Organic emissions 1 2 3 1 1 1 11.19.1-4 EMISSION FACTORS 1195 Figure 11.19.1-2. Process flow diagram for industrial sand and gravel ...\nthe extraction of the sand and gravel should occur in phases e.g. extract sand or gravel from the first ph ase up to five acres, start extraction from the next phase up to five acres, while concurrently reclaiming the first phase five acres. This sequence of operation\nSep 04, 2021 Illegal sand and gravel extraction a concern. Praneeta Prakash Multimedia Journalist praneeta.prakashfbc.com.fj PraneetaFBCNews. September 4, 2021 340 pm. Source Fijian Government An increase in illegal sand and gravel extraction in the Navua area has prompted the Ministry of Lands and Mineral Resources to raise more awareness.\nSand and gravel mining or aggregate mining is an important part of Nebraskas economy. Sand and gravel have a variety of uses including road building. construction. concrete production. landscaping. glass manufacturing. sand casting in iron and steel foundries. snow and ice control.\nThe extraction of sand and gravel on the BCS has strongly increased over the past few years figure 3. In 1976, a sediment volume of 29,000 m was extracted this volume had risen to 3.2 million m in 2012."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:7606786b-9f45-4c3e-b13b-06f71147c7ba>","<urn:uuid:27192b39-a6b5-455a-b031-3ec48b2da391>"],"error":null}
{"question":"How do natural disasters like cyclones impact COVID-19 response efforts compared to measles vaccination campaigns?","answer":"Both COVID-19 and measles vaccination responses face significant challenges from natural disasters, but in different ways. For measles campaigns, the Red Cross uses mapping technology to efficiently identify population settlements and monitor vaccination coverage, allowing teams to adjust resources and return to missed areas. In contrast, cyclones during COVID-19 directly disrupt response efforts by challenging social distancing in cyclone shelters and threatening health infrastructure. For example, in India and Bangladesh, cyclones Amphan and Nisarga complicated authorities' ability to maintain both social distancing and protect vital health infrastructure needed for COVID-19 response. The situations demonstrate how natural disasters can compound existing health crises, though organizations have developed different technological solutions to address these challenges.","context":["Data: A vital tool for disaster response\nEugene and Agnes find their way around a neighborhood in Rwanda and fill their base map with features like water points, medical facilities, and pieces of land that are prone to erosion.\nAid workers in the Philippines checked up-to-date paper and digital maps before delivering humanitarian aid every morning. When Typhoon Haiyan made landfall, the Red Cross and the Humanitarian OpenStreetMap team (HOT) asked volunteers to build a map of storm-affected towns and 1,700 people answered the call. The Red Cross loaded the updated maps onto relief workers’ GPS devices—it not only saved them time navigating to villages while delivering relief supplies, but also helped teams to assess damage.\nIn the hours and days after any disaster, humanitarian organizations like the Red Cross seek answers to a few key questions: Where were people during the disaster? How many people are affected? What are their primary needs?\nRed Cross and Red Crescent teams on the ground can’t always answer these questions on their own. Thanks to technology, collaboration from around the world, and data crunching, answers are coming more quickly. This empowers teams—who are working in often very difficult environments—to better assist people in need.\nFor several years, the Red Cross has been working on innovative mapping projects to help communities prepare for and respond to disasters. Updated maps can expedite the delivery of emergency supplies, determine where help is needed most, and even track the spread of diseases like Ebola. After Typhoon Haiyan in the Philippines and the Nepal earthquake, disaster responders used crowd-sourced mapping data to navigate their way to people in need and assess places with the most damage.\nToday, the American Red Cross and the International Federation of Red Cross and Red Crescent Societies (IFRC) are announcing another innovation in the field: a collaboration with Facebook around Disaster Maps that uses aggregated Facebook data to show where communities are located after a disaster, where they are moving, and where they are checking in as ‘safe.’\nUsing anonymized Facebook data, the Red Cross hopes to see where families sheltered the storm and when/if they are returning to devastated areas. This data—combined with other datasets—might be able to help the Red Cross better target relief supplies to the families and communities most in need during the critical days after large-scale disasters.\n“Today, we are introducing disaster maps that use aggregated, de-identified Facebook data to help organizations address the critical gap in information they often face when responding to natural disasters. We believe that this information will help response organizations paint a more complete picture of where affected people are located so they can determine where resources are needed and where people are out of harm's way,” remarked Molly Jackman, Public Policy Research Manager, Facebook. “We’re grateful for the help of our partners—UNICEF, American Red Cross and IFRC Red Crescent, and the WFP—who have worked with us to identify what data would be most helpful and how it could be put to action in the moments following a disaster.”\nThis isn’t the first time that the Red Cross has partnered with Facebook on understanding how increasingly accurate maps can address important data gaps when responding to emergencies.\nCrowd-sourced maps do good around the globe\nAccurate maps play a critical role in understanding communities and neighborhoods— especially for populations at risk of emergencies. While much of the world has been mapped to incredible detail, millions of people in developing countries live in communities that do not exist on any digital maps. This leaves them less visible to decision-makers and makes it more difficult to provide assistance during crises.\nOver the past decade, humanitarian organizations—including the Red Cross and Red Crescent—have added open-sourced maps to their arsenal of disaster preparedness and response. These new tools are helping emergency responders deliver aid more quickly and support volunteers to fight diseases like measles.\nThrough the Missing Maps project, the American Red Cross and other humanitarian organizations are using the power of crowdsourcing to trace buildings and roads from satellite imagery in order to create detailed base maps. This information is added to OpenStreetMap—a free and editable world map. Local volunteers then use this information on the ground. They literally walk around neighborhoods and add detail to the maps, such as health facilities, water points, and schools.\nThrough this process, the American Red Cross and its partners have engaged more than 28,000 volunteers to put 40 million people on the map. Mapping has helped with efforts to prevent malaria, develop a water pipeline, vaccinate against measles and support disaster preparedness.\nThese results are noteworthy, but the process can be made more efficient. In a rural context, volunteers often scan through huge areas of satellite imagery to search for rural hamlets and villages. A lot of volunteer time is spent finding something to map rather than doing the actual mapping. It can be very difficult to locate accurate, timely, and detailed population information for many countries. This information plays an important role in program planning.\nFor these reasons, the American Red Cross is excited to explore the use of Facebook’s population datasets for its projects.\nFighting measles with maps\nThe Red Cross recently utilized Facebook data for an upcoming measles vaccination campaign in Malawi. Measles is extremely contagious and remains a major cause of mortality for young children in many countries. As part of the Measles & Rubella Initiative, the American Red Cross and other partners are supporting a vaccination campaign to immunize more than 7.5 million children across the country in June—and the Red Cross’s mapping team is conducting pilot efforts to integrate mapping into the work.\nThe first step for teams was developing a rich base map for Malawi. At the beginning of planning, the Red Cross used Facebook data to identify population settlements across the country—and to identify areas which were already detailed in OpenStreetMap. This helped teams differentiate between areas that needed to be mapped by local volunteers and areas that could be skipped (where nobody lived). This increased efficiency dramatically.\nMuch of Malawi is rural, so concentrating on population settlements allowed us to filter out 97.1% of the total land area that we sought to map. This technique reduced our mapping area from 94,080km2 to 2,745 km2.\nVolunteers could then spend their time mapping communities instead of searching through acres of uninhabited areas; they were able to complete the mapping in a fraction of the normal time.\nThe base map data will support monitoring activities in the field. During the measles vaccination campaign, monitors from the national government, Red Cross, and other local partners will visit areas where vaccinations took place the previous day. They will identify areas that are especially at-risk and conduct spot checks: performing randomized surveys, locating children in public places to get a sense of whether the area was covered successfully. This information allows local health staff to identify areas where children may have been missed—and means that staff can make more informed decisions about whether to adjust resources and return to those areas again.\nRather than collect monitoring information using a traditional paper-based method, monitors will use mobile phones equipped with a data collection app that transmits information to the Cloud. The results will feed into a dashboard with an interactive map (created using the new base map data) and figures that show the results as they are collected. This means health staff and partners across the country will have access to real-time information about areas that need more attention during the campaign.\nThis is more than innovation. It’s saving lives.\n“Accurate maps empower Red Cross and Red Crescent teams to carry out humanitarian missions around the world. Maps help us in so many ways – from distributing relief supplies to preparing communities for disasters,” said Jono Anzalone, Vice President of International Services for the American Red Cross. “By sharing anonymized location, movement, and safety check data with the American Red Cross, Facebook is helping us sharpen the essential tools we need for targeting communities in need, delivering aid, and fighting disease,” he remarked.\nAbout the American Red Cross:\nThe American Red Cross shelters, feeds and provides emotional support to victims of disasters; supplies about 40 percent of the nation's blood; teaches skills that save lives; provides international humanitarian aid; and supports military members and their families. The Red Cross is a not-for-profit organization that depends on volunteers and the generosity of the American public to perform its mission. For more information, please visit redcross.org or cruzrojaamericana.org, or visit us on Twitter at @RedCross.","World Food Programme (WFP)\nIn responding to COVID-19, governments must not lose sight of the importance of building resilience to extreme weather\nBy Gernot Laganda, Chief of Climate and Disaster Risk Reduction, United Nations World Food Programme\nThe ongoing COVID-19 pandemic is testing governments’ abilities to manage risk as never before. Livelihoods are stretched to breaking point, with a staggering 130 million additional people at risk of slipping into severe hunger before the end of the year.\nCountries face not only the pandemic itself but also collisions with other regional and global problems. This includes the climate crisis, which disrupts responses to the coronavirus around the world and exacerbates the unfolding economic recession.\nOver the past few months, in tandem with the outbreak, extreme weather has hit vulnerable countries around the world with increasing severity. In the Pacific Islands, for instance, the coronavirus response has been undermined by tropical cyclone Harold, which wiped out roads, runways and food reserves in Vanuatu, the Solomon Islands, Fiji and Tonga.\nIn East Africa, heavy flooding and locust invasions have put 90 million hectares of cropland at risk, driving people from their homes and compounding a regional food crisis that is already affecting close to 30 million people.\nCyclones Amphan and Nisarga have hit India and Bangladesh, challenging authorities to maintain social distancing in cyclone shelters and protect the health infrastructure that is so vital in managing not only the COVID-19 outbreak, but also the impact of increasingly ferocious heatwaves.\nThese climate hazards keep reminding us that we do not live in a single-hazard world. The world is dynamic and interconnected, and the biggest threats to societies do not emerge one at a time. They materialize in parallel, reach across national borders, and compound each other.\nThis goes for pandemics, global financial crises and cyberattacks as much as for climate shocks and stresses which are becoming important ‘risk multipliers’ as the earth warms — driving a range of new problems such as conflict and the breakdown of agricultural value chains.\nMounting hazards can quickly make households vulnerable to new risks. Given the multiple effects one crisis can have on people’s incomes and assets, their abilities to cope with new and additional problems changes very rapidly.\nIn Bangladesh, WFP and its partners are helping the Government prepare for the impacts of the upcoming flood and cyclone season while grappling with the pandemic. Building upon experience from last year, when WFP facilitated cash payments to 4,500 families before they were affected by the peak of the monsoon floods, the organization has been working with the UN Office for the Coordination of Humanitarian Assistance (OCHA) to scale up “forecast-based financing” — a mechanism to pre-empt climate shocks and bolster the resilience of communities — to address the rapid changes in vulnerability.\nMany people who were not considered vulnerable in 2019 are now vulnerable, having experienced the health and economic consequences of COVID-19. Involving these people in preventive cash transfer programmes helps the government manage two hazards at the same time.\nWhile immediate steps can be taken with humanitarian aid to minimize loss of life from individual hazards, governments require longer-term strategies and systems to adapt to the realities of a riskier world.\nWhile a vaccine may be found for COVID-19, there is no vaccine for runaway climate change. Long after the pandemic is brought under control, smallholder farmers will keep pointing to dried-out fields and empty silos as climatic conditions become ever more extreme and unpredictable.\nDroughts, floods and storms will be aggravated by less common hazards such as pest infestations, heatwaves, biodiversity loss and conflicts over resources. Such new realities will come to be seen as even more destructive than the global health crisis we are experiencing now. For that reason, they must be acknowledged now and integrated into national adaptation plans and systems, so that countries are ready for the things to come.\nConfronted with such new and emerging realities, what can humanitarian organizations contribute? For one, humanitarians have decades of experience grappling with risk. They understand how crises unfold, how governments are forced to repeatedly absorb the same types of shocks, and how much it costs — both in human and financial terms — when action is taken late.\nHumanitarians understand the importance of risk-reduction and risk-transfer programmes, even though these are still largely underfunded at a global scale. And in a context of increasing risk-multipliers, humanitarian institutions can be effective partners for governments to operationalize risk-informed development — helping countries to hardwire nature-based solutions, climate risk insurance, social protection and safety nets, early-warning systems and emergency preparedness into planning and investment decisions.\nDealing with the COVID-19 crisis has forced many governments to reflect on the realities of the climate crisis. This is often talked about as a ‘global emergency’, but concrete actions do not necessarily follow international climate negotiations.\nAt a time when hazards cross borders, and in when these hazards create a domino effect of losses and damages in national economies, only well-prepared national systems are able to handle a riskier and more uncertain future.\nBouncing back from COVID-19 presents an unprecedented opportunity to unlock massive resilience benefits — provided governments do not launch new fiscal or financial incentives that perpetuate the status quo, and they recognize the importance of shifting from entrenched practices of fighting fires to a more forward-looking one of managing new types of risk."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:a6da3951-3d0d-41e3-ad5f-a1f1d9725a88>","<urn:uuid:858496a7-5276-44ed-be55-fbc7fcecd562>"],"error":null}
{"question":"As a music history student, I'm curious: who had more control over their work - Bach with his cello suites or Verdi with Piave's librettos?","answer":"Verdi exerted significantly more control over his collaborative work than Bach did. Verdi completely dominated his librettist Piave, who became 'scarcely more than an instrument in his hands.' Verdi determined the dramatic structure and overall architecture of his operas, with Piave serving essentially as a tool to implement Verdi's vision. In contrast, Bach composed his cello suites with relative artistic freedom at Prince Leopold's court, where he was mainly expected to produce secular instrumental music, but the compositional decisions were his own. The key difference is in the collaborative nature - while Bach worked independently, Verdi actively controlled and often had Piave's work revised by others, though they maintained a friendship despite Verdi's demanding nature.","context":["A Bit of History\nFew scholars doubt that Western music was better off for the release of a certain “Bach, Johann Sebastian” from the county jail in Weimar where he had languished, in unsuitable company, for the better part of a month in the autumn of 1717. Court organists can be a stroppy crew at the best of times, and court music directors even more so. But Bach, court organist and music director at the court of the Duke of Saxe-Weimar, had pushed ducal patience to the limit.\nThe cause of all this workplace turmoil was a job offer that Bach had received from the Duke’s brother-in-law, Prince Leopold of Anhalt-Köthen. In his rush to pack his bags and cancel his magazine subscriptions, it appears that Bach had failed to observe the finer points of court etiquette – like getting official permission to leave – and several weeks in hoosegow was Officialdom’s response.\nNow, readers of a no-nonsense mindset will no doubt be wondering just where all this is leading, and the answer is simple: it leads to the six suites for solo cello that Bach composed at the court of Prince Leopold in or around 1720.\nThe Prince, you see, was a Calvinist. He had no need for the type of liturgical warbling that composers at Catholic courts were required to produce en masse, as it were. But the Prince was indeed a music-lover. He is said to have played the harpsichord, the violin, and perhaps also the viola da gamba. When the orchestra at the court of Prussia was dissolved in 1714, Leopold eagerly scooped up the best orchestral players to form the core of his own musical establishment and made instrumental music the centrepiece of his princely entertainments.\nBach’s move from Weimar to the court of Prince Leopold, then, pointed his compositional activities firmly in the direction of secular music, and it was to his tenure as the Prince’s Kapellmeister from 1717 to 1723 that we owe such works as the Sonatas and Partitas for solo violin, the 6 Brandenburg Concertos, first book of the Well-Tempered Clavier – and the Six Suites for Solo Cello.\n* * *\nNo autographed manuscript of the cello suites has survived, although numerous copies were made, the most authoritative being that of Bach’s second wife, Anna Magdalena, made c.1730. After Bach’s death, these works seemed to have gone underground, passed from hand to hand among musicians of an antiquarian bent until the first printed editions began to appear in the 1820s. But even during the 19th century these works were viewed more as studies for practice in the studio rather than masterpieces for performance in the concert hall.\nAll that changed in the 1930s as a result of the pioneering work of one man, the Spanish cellist Pablo Casals (1876-1973), who did for the Bach Cello Suites what Glenn Gould did for the Goldberg Variations. Having been intrigued by a 19th- century edition he found in a thrift shop in Barcelona, Casals began to study the cello suites seriously and performing them in public. Then in 1936 he recorded Suites 1 & 2 at the Abbey Road Studios in London and by 1939 had produced the first complete recording of the whole set.\nFrom this point on the Bach Cello Suites joined the repertoire of cellists around the world and Casals’ recordings from the 1930s are still an important point of reference for cellists performing today, alongside another milestone in their history: Yo-Yo Ma’s recording of the complete set that won him a Grammy Award in 1986.\nThe Baroque Dance Suite\nBach’s time at the court of Anhalt-Köthen had one lasting influence on his compositional life: it instilled in him a love of the dance, as evidenced by the number of dance suites he composed while there.\nThe Baroque suite, a collection of dances all in the same key, was the ideal DJ party mix for an evening of toe-tapping entertainment among the European middle to upper classes with a taste for international musical culture. In its standard form it presented a buffet-style sampling of the major musical styles of Europe: the moderately-paced German allemande, the more animated French courante (or its peppier Italian variant, the corrente), the slow and stately Spanish sarabande, and the leap-loving English jig, or to use its posh French name, gigue.\nAdditional optional dances known as galanteries were often added to ease the transition between the normally grave sarabande and the frequently raucous gigue. Among these insertions were the courtly minuet (or menuet in French), the hot-trotting gavotte, and the heartbeat-quickening bourrée. Many suites also began with a prelude, meant to establish the key in listener’s ear, and to allow the performer to warm up his fingers by playing passagework in a stable rhythmic pattern.\nAll of the dances following the prelude are composed in binary (two-part) form. The task of the first part is to find its way to the key of the dominant (five scale tones up from the home key) and land on a satisfying cadence there in its final bar. The job of the second part is then to find its way back to the original key and lay down an even more satisfying cadence – a kind of “Honey, I’m home!” gesture – to let you know that the piece is now finally over. The fact that each of these two parts is normally played twice seemed to matter little to the Baroque ear.\nOne other practice worthy of note is that of returning to the first of the minuets, gavottes or bourrées after playing the second (contrasting) one, giving a rounded A-B-A form to this brace of optional inserted dances.\n* * *\nDance suites were a popular genre of keyboard music in the Baroque period but writing for a solo instrument like the cello, that could play only a single melodic line, posed distinct challenges. Keeping the listener from nodding off meant writing musical lines that constantly engaged the ear in new ways, mixing it up with scale figures that alternate with broken chords, passages on the lowest strings trading off with melodic climaxes high up on the fingerboard, and above all with salty dissonances finding resolution in satisfying cadences.\nBut hold on. How do you play harmonies – which is to say chords – on an instrument that only plays a single melodic line? Multi-string chord-playing is possible, of course, but writing multiple stops in every bar is a sure way to send your performer into physio looking for multiple finger splints. The answer is to imply the harmonies you want your listener to hear by slyly emphasizing – and frequently returning to – important fundamental chord notes and tendency tones so that one actually begins to hear a multi-voiced harmonic structure beneath all the fancy filigree. This is how harmonic tension and anticipation is created and when done well you find yourself expecting a certain chord pattern to follow another one – even if neither is stated outright.\nThis the monetary magic of Quantitative Easing applied to harmonic voice-leading.It’s the fluttering veils of Gypsy Rose Lee suggesting far more than the eyes of her audience are actually seeing. And Bach was an unsurpassed master at this compositional sleight-of-hand, this aural perceptual “dance within the dance.”\nA Few Recommendations\nWhile every listener will have his or her favourites from among the 42 individual dance movements in this collection of suites, the following have etched their way into my musical memory in a way that I cannot, in all honesty, fail to mention.\nThe opening Prelude of the Suite No. 1 in G has almost become synonymous with Baroque cello music itself. Its nobility of sentiment far transcends what one might expect to admire in a simple repetitive pattern of broken chord figures and connecting scales. The key of G is important here, as the bottom two strings, low G and the D above it, are open strings on the cello and Bach plays to the natural resonance of these two strings in crafting this prelude. The result is a rocking, undulating pattern of tones that evokes a sense of being at peace with the world.\nBach’s sense of sonic resonance is operating at a high level, as well, in the massive build-up of sound in the Prelude of the Suite No. 3 in C major, but this one puts you through the ringer. It features the same rocking pattern of wide-stretching broken chords, made all the more sonorous by the stabilizing presence of the low G used as a pedal tone beneath increasingly dissonance harmonies striving above it.\nFor sheer grit and dogged resolve it would be difficult to beat the headlong thrust of the Courante from the Suite No. 2 in D minor. This dance turns the cello into a veritable street fighter with bravado to spare. The perky lilt of the Courante from the Suite No. 6, however, makes this same dance form into a real toe-tapper by simply arranging 8ths and 16ths in the right pattern of leaps and scales.\nAmong the sarabandes, that of the Suite No. 2 D minor wins the prize for wringing the greatest amount of expression out of a single, slow melodic line. But the Sarabande from the Suite No. 5 in C minor is memorable in a different way. Consisting entirely of 8th notes leaping widely over the entire range of the instrument, it manages nonetheless to tell a gripping story full of harmonic tension and much anticipated tension release.\nThere really is no contest among the galanteries. The Bourrée from the Suite No. 3 in C major has been a favourite since my early adolescence, probably because of the number of popular arrangements that have been made of it. Its easy- going mood and self-evident harmonic drive make it the sort of thing you hum to yourself in the shower. Almost as hummable is the Bourrée from the Suite No. 4 in E flat, with its wonderfully symmetrical phrases.\nThe gigue with the street cred to really jig it up big time is the one from the Suite No. 2 in D minor. The huge leaps in this movement give this dance movement a specially memorable swagger that stays in the memory long after it has finished.\nAnd finally, a special note of admiration is due to the cellist himself, who in the Suite No. 6 in D will be playing, on a four-stringed cello, a piece originally written for a five- stringed instrument!\nDonald G. Gíslason 2016","Francesco Maria Piave\nPiave's career spanned over twenty years working with many of the significant composers of his day, including Giovanni Pacini (four librettos), Saverio Mercadante (at least one), Federico Ricci, and even one for Michael Balfe. He is most well known as Giuseppe Verdi's librettist, for whom he was to write 10 librettos, the most well-known being those for Rigoletto and La traviata.\nBut Piave was not only a librettist: he was a journalist and translator in addition to being the resident poet and stage manager at La Fenice in Venice where he first encountered Verdi. Later, Verdi was helpful in securing him the same position at La Scala in Milan. His expertise as a stage manager and his tact as a negotiator served Verdi very well, but the composer bullied him mercilessly for his pains over many years.\nLike Verdi, Piave was an ardent Italian patriot, and in 1848, during Milan's \"Cinque Giornate,\" when Radetzky's Austrian troops retreated from the city, Verdi wrote to Piave in Venice addressing him as \"Citizen Piave.\"\nTogether, they worked on ten operas between 1844 and 1862, and Piave would have also prepared the libretto for Aida when Verdi accepted the commission for it in 1870, had he not suffered a stroke which left him paralyzed and unable to speak. Verdi helped to support his wife and daughter, proposing that \"an album of pieces by famous composers be compiled and sold for Piave's benefit\". The composer paid for his funeral when he died nine years later in Milan aged 65 and arranged for his burial at the Monumental Cemetery.\nPiave's librettos for Verdi\nFrom the beginnings of their working relationship in 1844, scholars such as Gabriele Baldini see Verdi's overall influence upon the structure of his work take a big leap forward when he notes:\n- Working with Piave was Verdi's first opportunity to work with himself. [...] The composer completely dominates and enslaves the librettist, who becomes scarcely more than an instrument in his hands...[Piave's] libretti are in fact those best suited to Verdi's music [....] simply because, in detail as well as in general shape, Verdi himself composed them.\nThis statement suggests that, almost for the first time, the composer was going to be the one who determined \"that drama essentially consisted of the arrangement of pieces and the clarity of the musical forms..[so that]..he began to become aware of the structure and architecture of musical composition, something which was not even clearly hinted at during the period with Solera. The composer began to control the overall dramatic arc of the drama and no longer would he \"suffer under\" such librettists as Temistocle Solera, who wrote the libretti for five Verdi operas beginning with Oberto and up to Attila in 1846.\nAn example of the pressure which Verdi exerted on Piave was in the struggle to have the Venetian censors approve Rigoletto: \"Turn Venice upside down to make the censors permit this subject\" he demanded, following that up with the admonition not to allow the matter to drag on: \"If I were the poet I would be very, very concerned, all the more because you would be greatly responsible if by chance (may the Devil not make it happen) they should not allow this drama [to be staged]\"\nNonetheless, another Verdi scholar notes that \"Verdi always harried him unmercifully, often having his work revised by others [as in the case of Simon Boccanegra] [but] Piave rewarded him with doglike devotion, and the two remained on terms of sincere friendship.\" Piave became \"someone Verdi loved\".\nIn following Salvadore Cammarano as Verdi's main mid-career librettist, Piave firstly wrote Ernani in 1844, and then I due Foscari (1844), Attila (1846), Macbeth (the 1847 first version), Il Corsaro (1848), Stiffelio (1850), Rigoletto (1851), La traviata (1853), Simon Boccanegra (the 1857 first version), Aroldo (1857), La forza del destino (the 1862 first version), and Macbeth (the 1865 second version).\nLibrettos by Piave\n- Crispino e la comare, directed by Vincenzo Sorelli (1938)\n- Rigoletto, directed by Carmine Gallone (1946)\n- La signora delle camelie, directed by Carmine Gallone (1947)\n- The Force of Destiny, directed by Carmine Gallone (1950)\n- Rigoletto e la sua tragedia, directed by Flavio Calzavara (1956)\n- La traviata, directed by Mario Lanfranchi (1968)\n- Rigoletto, directed by Jean-Pierre Ponnelle (1982)\n- La Traviata, directed by Franco Zeffirelli (1983)\n- Macbeth, directed by Claude d'Anna (1987)\n- Giuseppe Verdi's Rigoletto Story, directed by Gianfranco Fozzi (2005)\n- Baldini 1970, pp. 70 - 74\n- Werfel and Stefan 1973, p. 262, referring to a letter of 1 August 1869 from Verdi to publisher Léon Escudier requesting him to furnish his own contribution to the album\n- Verdi to Piave, 6 May 1850, in Phillips-Matz 1993, p. 265\n- Verdi to Piave, 29 November 1850, in Phillips-Matz 1993, p. 270\n- Black 1998, p. 999\n- Phiilips-Matz 1993, p. 644\n- List of operas for which Piave wrote the libretto taken from opera.stanford.edu Retrieved 9 September 2013\n- Baldini, Gabriele (1970), (trans. Roger Parker, 1980), The Story of Giuseppe Verdi: Oberto to Un Ballo in Maschera. Cambridge, et al: Cambridge University Press. ISBN 0-521-29712-5\n- Black, John (1998), \"Piave, Francesco Maria\" in Stanley Sadie, (Ed.), The New Grove Dictionary of Opera, Vol. Three, pp. 999. London: Macmillan Publishers, Inc. ISBN 0-333-73432-7 ISBN 1-56159-228-5\n- Budden, Julian (1996), Verdi. New York: Schirmer Books (Master Musicians Series). ISBN 0028646169 ISBN 9780028646169\n- Kimball, David (2001), in Holden, Amanda (Ed.), The New Penguin Opera Guide, New York: Penguin Putnam, 2001. ISBN 0-140-29312-4\n- O'Grady, Deidre (2000), Piave, Boito, Pirandello: From Romantic Realism to Modernism (Studies in Italian Literature). Edwin Mellon Press. ISBN 978-0-7734-7703-2 ISBN 0-7734-7703-9\n- Phillips-Matz, Mary Jane (1993), Verdi: A Biography, London & New York: Oxford University Press. ISBN 0-19-313204-4\n- Werfel, Franz and Stefan, Paul (1973), Verdi: The Man and His Letters, New York: Vienna House. ISBN 0-8443-0088-8\n|Wikisource has original text related to this article:|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:b92ee249-82a1-4511-b80c-ce4643e2dd17>","<urn:uuid:ef76b8ca-e87f-4541-ad38-87b6069389d5>"],"error":null}
{"question":"For my SEO strategy, what are the key differences between using Google Search Console versus SEMRush Site Audit for detecting and monitoring website indexing issues?","answer":"Google Search Console and SEMRush Site Audit offer different capabilities for monitoring indexing issues. Google Search Console is a free tool that specifically shows 404 errors generated by your website and allows you to submit sitemaps and examine structured data. You can view crawl errors through the Crawl Errors section. In contrast, SEMRush Site Audit provides more comprehensive analysis, running 20 different checks focused on crawlability and indexability. It performs automatic weekly audits and generates extensive data about site health. SEMRush can be set up by adding a New Project and running a Site Audit, after which it will show a detailed list of issues, including broken links and other indexing problems.","context":["To gain a competitive advantage in Google, you must deal with two key factors to shape your search rankings - crawlability and indexability. Without testing for these factors, you'll find it extremely hard to outrank the competition.\nSo, you’ve built a great website, created amazing content, used a good SEO strategy and curated backlinks from blogger outreach. However, you're still finding it really hard to rank in Google. You may ask yourself...\n- is my site crawlable?\n- is my site indexable?\nI'll teach you how to make your site more crawlable and more attractive to the search index. Start by running a crawl test below...\nTest Website Crawlability\nRun a quick crawlability test.\nFind critical issues affecting your site’s indexability in Google.\nHow Does Google Crawl Websites?\nGoogle has 3 core components:\nThe crawler is also known as a spider, Googlebot and user agent.\nThe crawler’s job is to discover new web content by following links. It follows each link, then follows the links on newly discovered web pages, and so on and so forth.\nThe crawler then brings new content back to Google’s database for cataloging, referred to as indexing.\nWhat Does Crawlability Mean?\nThe ease of or ability for Google to crawl your website content, discover all site links and their destination pages without encountering dead-ends.\nWe’d like to assume that all your links lead to their destinations and your site is easily crawlable. But, if the spider has trouble crawling your site you’ll risk a low ranking.\nWhat Does Indexability Mean?\nThe ability for Google to catalog your website content properly for relevant keyword search terms.\nSo, crawling of your site directly affects how the search engine indexes your pages.\nHow to Influence Crawlability and Indexability\nCrawlability is influenced by the technical and structural aspects of your website environment.\nGoogle may stop crawling if it discovers broken links, technical issues or an inefficient site layout.\nThe goal is to create an efficient site setting to influence the spiders’ ability to crawl your site.\nEfficient crawling starts with good internal linking, site structure and no crawl errors.\nYour website should be a well-connected network of web pages that link to one another in a logical structure.\nYour web pages need to be reachable via a hyperlink, otherwise, you risk undiscoverable pages.\nThe crawler can’t index pages it doesn’t find.\nAs I mentioned, your site should be inter-connected with relevant page to page links. The crawler (or site visitor) should be able to access any page within 1-2 clicks (3 max). Pages nested too deep presents a poor site structure and a bad user experience.\nTo help Google understand your content better, the site structure must have link relationships around core topic pillar pages that link to related sub-topics commonly referred to this as content cluster.\nThen to help Google even further you must have those sub-topics link back to the core topic showing content priority. See the content cluster example below (from our HubSpot Content Strategy Tool) showing the core topic linking to sub-topics.\nFailure to create link relationships leads to undiscoverable pages and content the crawlers have difficulty indexing (classifying).\nFix Crawl Errors\nIf the search engine follows a link but cannot access the page while crawling, there won’t be anything new for indexing. Your web server may return any of the following HTTP errors: 500, 502, 503, 404, etc.\nCrawl errors will show up in Google’s Search Console (previously Google Webmaster Tools). So, you’ll want to fix them right away.\nFix Broken Links\nBroken links occur when moving or renaming web pages. Short of making a sitewide search and replace, you may create a dead-end link unintentionally. The crawler can’t access pages from a broken link. Generally, you'd see a 404 error - page not found.\nFix Redirect Loops\nA redirect is a server rule where the server will send a user to page B when page A is requested.\nMore specifically, a redirect loop happens when multiple (conflicting) redirect rules. I.e. redirect rule #1 says Page A points to Page B and redirect rule #2 says Page B points to Page A.\nSimilar to a broken link, a redirect loop may occur when moving content or renaming page URLs. The crawler can’t access neither Page A nor Page B.\nForms and Scripts\nCrawlers can’t access content restricted behind a form. You may have content accessed via a login form or gated content requiring a form submission before displaying.\nOutdated technology or third-party scripts can restrict the crawler and prevent indexing.\nHow to Improve Crawling and Indexing\nI’ve mentioned that linking, structure and errors will influence the crawling and indexing of your site. Now, let’s discuss how we can improve the efficiency of the crawl and create a healthy environment for indexing.\nCrawler Access with Robots.txt\nRobots.txt is a utility file living within your site and crawled by Google. It has special block/allow indexing instructions which helps Google's \"crawl efficiency\" and \"indexing accuracy\". Note, Meta Tags can also deliver per page instructions on a case-by-case basis.\nPage Load Speed\nFaster loading websites yield a better user experience and improves the bots crawling rate.\nBut, note that increased crawl rate doesn’t always mean better indexed search results. Google considers over 200 factors when determining your search engine rankings.\nA sitemap lists important web pages of your site, while telling the search engines about your content. The sitemap also gives valuable metadata like last page update. A few ways to keep sitemaps organized and crawlable:\n- Update XML sitemap regularly *\n- Eliminate duplicate pages ***\n- Redirect pages properly (when deleting or renaming) **\n- Ensure canonicalized pages *\n- Use consistent, search engine friendly URLs\n- Use a UTF-8 encoded sitemap *\n- Check for sitemap errors regularly ***\n* Feature of Yoast SEO free plugin\n** Feature of Yoast SEO premium plugin\n*** Google Search Console\nNothing attracts search engines more than authoritative, high-quality content. But, not all content is created equal. Remember that it must meet the organic keyword litmus test and provide something of value to the consumer.\nPrevent Duplicate Content\nThe same content found on multiple URLs of your website. It can occur on any site especially ecommerce stores and blogs. A few examples:\n- mysite.com/nike-air-max/ and mysite.com/sneakers/nike-air-max/\n- mysite.com/my-cool-blog-post/ and mysite.com/my-category/my-cool-blog-post/\nGoogle doesn’t know your preferred URL which may impact crawling and indexing. It’s easily fixed with the rel=“canonical” Tag telling Google your primary URL.\nCrawlability Testing and Index Monitoring Tools\nGoogle SEO Tools\nUse Google’s go-to list for SEO tools. Here are a few popular ones:\n- PageSpeedInsights to analyze pages for speed and usability improvement suggestions.\n- Mobile-Friendly Test is another great tool to show mobile performance.\n- Google Search Console provides rich insights into your site's crawlability and indexing. A place to submit your XML sitemap, examine structured data and much more.\nSEO Site Audit\nRun a site audit regularly to maintain good SEO health. A site audit tool will give you a comprehensive overview of your site’s overall health allowing you to stay on top of problems.\nSEMrush offers the most comprehensive set of tools and is our SEO secret weapon. The SEMrush Site Audit provides extensive data running 20 different checks that focus on the ability to crawl and index your site. We use this tool to run automatic weekly audits so we’re always optimizing.\nGet yourself a good set of tools and test your website often.\nOf course, no tool will make a bit of difference if you don’t follow through on its suggestions so, be diligent in your efforts. If you do, you’ll improve your website's crawlability and gain favor in the search engines.","Table of Contents\nTable of Contents\nA broken link is a link on a website that no longer works. This can be due to the page it was linking to being deleted, moved, or renamed. Broken links can hurt your SEO because they prevent search engines from being able to crawl and index your site properly.\nBroken links can hurt your SEO in several ways. First, they prevent search engines from being able to crawl and index your site properly. This can lead to lower rankings and less traffic. Second, broken links can create a poor user experience, which can lead to people bouncing off of your site and going elsewhere. Finally, broken links can make it difficult for people to navigate your site, which can also lead to lower traffic levels.\nIf you have broken links on your website, the best thing you can do is fix them as soon as possible. You can do this by redirecting the old URL to the new one using a 301 redirect. You can also use a plugin like Broken Link Checker to help you find and fix broken links on your website.\nBroken links negatively affect the user experience on your website. When users click on a broken link, they are taken to an error page instead of the content they were expecting to find. This creates a poor user experience, which can lead to people leaving your site and going to another one that does work. In addition, search engines view broken links as a sign that your website is not well-maintained and will penalize your site accordingly.\nThe bounce rate is the percentage of visitors who leave your site after viewing only one page.\nIf a user clicks on a broken link, they will be taken to an error page. This increases the bounce rate because the user has left your site without viewing any other pages and lost out on content that might have been interesting to them.\nA typo in the URL is when a user incorrectly types in the URL of a website.\nIt can happen for a variety of reasons, such as when a user mistypes the URL, or when they click on a link that has been incorrectly copied.\nThe best way to fix it is to redirect the incorrect URL to the correct one.\nA page that has been deleted is an error page that is displayed when a user tries to access a webpage that no longer exists.\nThere are a few ways that this can happen. Maybe you accidentally deleted the page, or maybe you changed the URL and forgot to redirect the old one. Either way, it results in the same thing: users trying to access your page get an error message instead.\nThe first thing you need to do is figure out why the page was deleted in the first place. If it was an accident, then you can just recreate the page and be on your way. But if it was intentional (for example, if you changed the URL), then you need to set up a redirect from the old URL to the new one so that users will end up where they’re supposed to go.\nA page that has been renamed is a page on your website that has had its URL changed. This can happen for a number of reasons, such as when you change the name of the page or move it to a new location.\nThere are a few ways that a page can be renamed. The most common way is through a change in the URL structure of your website. This can happen if you change the domain name of your site, move to a new hosting provider, or make changes to the way your pages are organized. Other times, it can happen if you simply change the name of the page itself.\nIf you have renamed a page on your site, it’s important to update any links that point to that page so that they still work. You should also set up redirects from the old URL to the new one so that visitors and search engines are directed to the correct location.\nThere are a few reasons why your domain name might change. The most common reason is that your website has outgrown its old domain and you need to upgrade to a new, more powerful one. Other reasons include changes in your business model or a merger or acquisition with another company.\nIf you do need to change your domain name, the process is actually quite simple. First, you’ll need to purchase the new domain and set up hosting for it. Once that’s done, you can use a 301 redirect to point all of the old pages on your old domain to the new pages on your new domain. This will tell search engines that your content has moved and ensure that anyone who clicks on an old link will be taken to the right page on your new site.\nIf you don’t properly redirect your old pages to your new domain, you could lose all of the SEO value that those pages have built up over time. You’ll also risk confusing and frustrating visitors who click on links that no longer work.\nIf you’re looking to improve your website’s SEO, Google Search Console is a great free tool to use. One of the many things it can do is show you any 404 errors your website has generated. This means that if someone visits a page on your website that doesn’t exist, they’ll see a 404 error page. To find out about any 404 errors your website has generated, log into Google Search Console and go to Crawl > Crawl Errors. From here, you can see a list of all the 404 errors on your website.\nIf you’re looking for a desktop program that can crawl your website and find broken links, Screaming Frog is a great option. It’s available for both Windows and Mac, and it’s very easy to use. Just enter your website’s URL into the program and click Start. Then click Response Codes and filter Client Error. The program will then crawl your website and generate a list of all the internal links it finds. You can then export this list as a CSV file.\nSEMRush Site Audit is a great tool for finding broken links on your website.\nWhat you need to do is to Add a New Project > Site Audit. Once the SEO audit is completed, you will be shown a list of issues, including the broken links on your website.\nThere are a few ways that you can test your links to see if they are working. One way is to use an online link checker tool, such as Google Search Console, SEMRush Site Audit, etc. Another way is to manually check each link yourself by clicking on them and seeing if they take you to the correct page.\nA link checker tool helps you check for broken links on your website. It can also help you find out if there are any redirects or errors when people try to visit your site.\nTo use a link checker tool, simply enter the URL of your website into the tool and it will scan the site for any broken links. If any are found, the tool will provide you with a report detailing where the broken links are and how to fix them.\nThere are several benefits of using a link checker tool, including:\nA typo is a mistake made when typing the URL, usually a spelling mistake. You can use a spell checker to check for typos, such as Screaming Frog.\nA typo in the URL is simply entering the wrong URL in your browser’s address bar – if you type www.example.com/page instead of www.example.com/paeg, you’ll probably end up at a 404 error page.\nIf you’ve clicked on a link and arrived at a 404 error page, it’s likely that the page has simply been deleted.\nTo make your page live again, you can use Google Sites and simply restore your deleted page.\nIf you want to redirect an old URL to a new URL, you should use a server-side 301 redirect. This is the best way to ensure that users and search engines are directed to the correct page.\nOnce you’ve added your 301 redirects, be sure to test it out to make sure it’s working properly. You can also use Google Search Console’s Fetch as a Google tool to submit your new URL and request that Google crawls it.\nOnce you’ve found the broken link, simply delete it from your website. If the link was in your navigation menu, you may need to update your menu structure. If the link was in the body of a post or page, you can simply delete it or replace it with a working link.\nBroken links can negatively affect your website’s search engine optimization (SEO) by preventing search engines from crawling and indexing your pages. They can also cause users to leave your site if they click on a broken link and are taken to an error page.\nFirst, fix the broken links on your website. Next, if you have a blog or other kinds of external content outside of your website; then try to remove those links from it."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:7b74abc4-56e6-4596-9511-810a8f6a76f9>","<urn:uuid:33ac6549-a89d-4cf5-a2b7-2ba8a3ec6d06>"],"error":null}
{"question":"How do organic and non-organic farming methods compare in terms of certification costs and environmental sustainability?","answer":"Regarding certification, organic farming carries significant costs and risks - farmers pay about 30% more for organic certification and face higher waste due to pest damage. However, from an environmental perspective, organic farming practices are more sustainable for soil health. Organic methods encourage building healthy soil through practices like crop rotation and minimal tillage, while creating wildlife havens for beneficial insects and birds. In contrast, artificial fertilizers used in non-organic farming can suppress soil biodiversity. That said, some non-certified farmers still practice sustainable methods - for example, farms like Taves Family Farms choose not to get organic certification but may still use environmentally conscious growing practices.","context":["“Gardening is not a rational act.”—Margaret Atwood\nThis land is strewn with the innards and skins of those who did not survive. I would weep, but for the fact of knowing that many more endured and lie in a metal colander in my kitchen sink. What does one do with 500 cherry tomatoes?\nGardening is so much work. The tilling, the fertilizing, the seeding. My feelings toward gardening mimic the Grinch’s Christmas sentiment, “Noise, noise, noise, NOISE!”\nThat is why I outsource my farming. And I am not alone. In Canada, more than 2 million metric tonnes of field vegetables find their way from farmers to retailers each year.\n“There’s a reason we have tractors and guys working 50 acres of land,” says Loren Taves, owner of Taves Family Farms in Abbotsford, BC. “I think people would be surprised to learn about how fragile bringing a perfect food product to the market actually is and the complexity of how hard [farmers] try to mitigate risks.”\nA passion for the earth\nTaves’ family has been farming for 40 years. While my relationship with gardening is an annual six-week commitment, after which we are both thrilled to amicably part ways, Taves—and thousands of farmers like him—are fuelled by their passion for the earth, and the process. His appreciation of homegrown produce was seeded at a young age.\n“We would have a dinner in the middle of August, and everything on the table, we grew. There was a sense of pride in that. Everything we ate came from my blood, sweat, and tears.”\nI may not have a talent for the agricultural arts, but I do talk to my own children about healthy eating and wholesome food. They are part of a generation that is growing up (with the help of water, just enough sunshine … and pizza) already understanding terms such as “buy local” and “organic.” It’s important for younger consumers to understand the word “apple” doesn’t only refer to smartphones.\nIncreasing education and awareness\n“I certainly think there always needs to be more education. I think this past year, especially with COVID-19, and even the year before, with so many food recalls and outbreaks, that people are beginning to feel they need to look into it a lot more. But I think people are becoming a lot more aware,” says Ann Higgs, general manager at Atlantic Grown Organic, the wholesale branch of the Schurman Family Farm on Prince Edward Island.\nHiggs emphasizes the importance of understanding not only where your food comes from but also how often our produce is ping-ponged across North America.\n“They hear that things come from California. They think that it’s oftentimes a direct market, that it comes straight from California to PEI. In fact, that produce is exchanged at multiple locations back and forth throughout the US before it ends up in Canada, and then again in Canada before it reaches its final home.”\nPriority = buy local\nTaves and Higgs agree that the priority for all consumers should be to buy local. Not only is it a more environmentally sound choice, but it also keeps dollars within local communities. Taves says that when he sells to neighbourhood consumers, he can then, for example, “go into town to get my vehicle fixed.” As he explains, “Because <you> spend money here, I can spend money in the community. So, it rolls around and around. That’s a good thing.”\nMany retail customers gravitate to organic foods as a way of investing in a healthier planet. In Canada, the organic food market is a $5 billion dollar industry. The Schurman Family Farm is entirely organic, although Higgs emphasizes that they regularly partner with other farmers who do not carry that certification.\nQuality, proximity, and trust\nFor Higgs, quality and proximity trump labels. “We only buy from farmers we trust and that we know have the same core morals; that’s really what we’re looking for. So even if it’s not organic, we know it’s still grown in a sustainable, healthy, beneficial way.”\nTaves echoes that sentiment. His business does not carry the organic certification, and that is by choice. “With that certification comes a very high cost, and a lot more risk. You usually pay about 30 percent more for organic. Quite often there is a lot more waste in organics, because you couldn’t quite keep out the bugs, or something else happens. You end up watching your crop wither away.”\nTaves and Higgs encourage consumers to feel comfortable with their choices, regardless of the label. They would rather that effort be spent asking your grocer if they carry local foods, or even better, shopping at your local farmers’ market. That is the best way to encourage a green, healthy economy.\nFor anyone looking for local crushed tomatoes, you’ll find me in my backyard, cleaning my boots.\nUnderstanding farm to table\nHow to encourage local farming and a healthy environment:\n- Buy from your community farmers’ market.\n- Ask your grocer for local produce.\n- Grow what you can manage in your backyard or on your balcony.\n- Become part of a community garden.\n- Find farms with home delivery in your neighbourhood.","It is no surprise that food choices affect health, but they can also have a major impact on the planet. The good news is that making better food choices for health reasons helps protect the environment from many of the damaging impacts of intensive farming practices. Here are three ways improving diets also helps safeguard the earth:\n1. Fossil Fuel Reduction: Raising animals industrially requires vast amounts of natural resources that are rapidly depleting. According to Professor Steve Boyan of the University of Maryland Baltimore County, “the modern factory farming system is a prolific consumer of fossil fuel”. Today, instead of grazing on grass, many cows in the United States are raised on feedlots and consume a steady diet of corn. As much as 25 tons of corn are dumped every hour on large lots and each bushel requires 4.5 liters of oil to produce the fertilizer used to grow it. Boyan’s estimates show that a 544-kilogram factory-raised cow will have consumed 1,075 liters of oil in her lifetime.\nA diet rich in plant-based foods helps curb fossil fuel use. According to Boyan, for example, substituting beans for beef uses less than four percent the amount of fossil fuel to produce the same amount of energy. Additionally, mainly eating plant-based food and only occasionally meat can lower the risk of heart disease and other chronic illnesses.\n2. Water conservation: According to U.N. Water, 70 percent of global water withdrawals are used for agriculture. As underground aquifers are depleting faster than they can be replenished, water conservation is imperative. Furthermore, groundwater is increasingly becoming polluted as untreated animal waste and agricultural chemicals seep into waterways. Sixty-five percent of California’s population is threatened by pollution to their drinking water from dairy cow manure, according to Boyan.\nFor every pound of beef one forgoes, between 9,500 to 19,000 liters of water are saved. According to the Barilla Center for Food & Nutrition (BCFN), switching from a meat-based diet to a sustainable Mediterranean model, rich in produce and legumes, could reduce a consumer’s water consumption by up to 50 percent.\n3. Soil protection: Healthy soil is the foundation of successful agriculture. Yet, according to the Soil Association, evidence suggests that using artificial fertilizers suppresses the rich diversity of life in soil needed to keep it vibrant. Organic farming, on the other hand, encourages building healthy soil through practices like crop rotation, intercropping, cover cropping, and minimizing tillage. The U.N. Food and Agriculture Organization (FAO) points out that these practices improve soil health and retention, as well as create a more stable farm system. Additionally, organic farming encourages a diverse ecosystem to maintain soil fertility and to keep pests under control naturally. These farms in turn become wildlife havens for beneficial insects and birds.\nChoosing organic produce can reduce exposure to chemical residue from pesticides. According to the U.S. Department of Agriculture (USDA), organic produce carries significantly fewer pesticide residues than conventional produce. The Soil Association further indicates that organic produce has health benefits, including higher levels of Vitamin C, trace minerals, and anti-oxidants that prevent cancer."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:6dad14c1-23c9-4615-a254-f294d9784e8e>","<urn:uuid:ea9753c0-ce2b-40bf-bdc9-b50daf46330a>"],"error":null}
{"question":"What are the timing differences between purchasing last-minute tickets at Broadway versus Vienna Opera?","answer":"For Broadway shows, last-minute tickets can be purchased at TKTS booths which operate from 3 p.m. to 8 p.m. Monday through Saturday, and Sunday until the latest curtain time. In contrast, at the Vienna State Opera, standing tickets go on sale 80-120 minutes before the performance starts at the dedicated Stehplätze ticket office. Additionally, the Staatsoper allows day-before purchases for standing tickets if you have a federal theatre card, while Broadway's TKTS only sells for same-day shows or next day's matinees at the South Street Seaport location.","context":["Most “Broadway” shows are presented in theaters in the general Times Square neighborhood, although only 4 of the 39 “Broadway” theaters are actually on the street called Broadway. This is a huge part of the New York City tourism scene, and seeing at least one play or musical in the area can be a great idea even for those of us who are not traditional theater fans.\nTickets have been going way up in price in recent years, but there are a few ways to get cheaper tickets, even at the last minute, although normally only for the less-popular shows of the moment. The prime seats now can have a face value of well over $100 each, however it’s usually possible to get a seat for something less popular for close to $20 at the TKTS office (described below). These shows are quite a spectacle, and even those who mock them should at least make a point of seeing one once in order to validate their future mocking.\nSome quick definitions before we go on:\n- Broadway Theater — A house with 500 or more seats that generally hosts plays and musicals. There are currently 39 such theaters in New York City, although not all have something running at any given time. Except for one about a mile away in Lincoln Center, all these theaters are within a few blocks of Times Square. With only rare exceptions, every production you’ve ever heard of is playing at a “Broadway Theater.” The smallest of these has 597 seats and the largest has 1,935. Most have close to 1,200 seats.\n- Off-Broadway Theater — Again, this has nothing to do with addresses. Off-Broadway is officially any theater with between 100 and 499 seats. Many are within the Times Square area, but others are down in the Village and elsewhere. Off-Broadway theaters are almost always cheaper to attend, and some of them are put on by non-profit organizations. Occasionally, productions will begin life as Off-Broadway and then move to a larger theater after some success. Avenue Q and Rent have done this, as well as older hits such as Hair and Little Shop of Horrors. Blue Man Group has continued its entire run in an Off-Broadway theater in the East Village.\n- Off-Off-Broadway — These theaters hold fewer than 100 people, and are generally small, experiment productions, mostly downtown rather than near Times Square. Tickets are usually quite inexpensive, and many amateur productions fit into this category. There is a movement to re-brand this as “Indie Theater” instead of Off-Off-Broadway, and that seems like a decent idea and a far less clumsy and confusing name.\nMost all Broadway shows operate on exactly the same schedule, with 8 performances per week. Obviously you’ll want to check on the ones you are interested in to confirm.\nTuesday — Saturday evenings: 8 p.m.\nWednesdays and Saturdays: 2 p.m.\nSundays: 3 p.m.\nYou can buy tickets for all Broadway shows by telephone or online in advance, as well as from each theater’s box office all the way up to show time. Of course, the most popular shows can be sold out for weeks in advance, but occasionally they release seats on the day of the show, even for the big hits.\nDOWNLOAD OUR TRAVEL GUIDES\nGetting discount tickets\nAn outfit called the Theatre Development Fund has been running booths called TKTS since 1973 as a way to fill seats for performances that might otherwise go unfilled. There are two TKTS offices:\n- Times Square — This one used to be in the center of the intersection, but it’s currently been moved to the Marriott Marquis Hotel on 46th Street between Broadway and 8th Avenue while the main booth is dramatically expanded.\n- South Street Seaport — This booth replaced the one that used to be in the World Trade Center lobby until September 11, 2001.\nThese booths accept cash and traveler’s checks, but no credit cards. Outside you’ll see a list of all the shows they have tickets available for, which they offer at discounts of between 10 and 50% for that day’s shows only, or for the following day’s matinee at the Southstreet Seaport location. Not surprisingly, you’ll normally only see tickets available for the less popular shows at the TKTS booths, but sometimes the hits will have a new block of empty seats available as well. Well over half the shows sell at least some tickets through these booths, so it’s always worthwhile going by.\nEvening shows – Monday — Saturday 3 p.m. to 8 p.m., Sunday 3 p.m. until the latest curtain time of shows being sold (Sunday evening shows are rare, though)\nMatinees — Wednesdays and Saturdays 10 a.m. to 2 p.m., Sundays 11 a.m. to 3 p.m.\nLines here are often long, especially at the Times Square location.\nOther ways of getting tickets\nThere are dozens of small ticket agencies that deal in Broadway show tickets in addition to concerts and sporting events. Of course, prices tend to be quite high through these agencies, but they do tend to have tickets for the hottest shows, even at the last minute.\nThere are also scalpers stationed in front of some sold-out theaters. They usually operate discreetly so you might have to look around a bit.\nYou can also try looking for tickets on Craigslist under the Tickets category. You’ll mostly see sports and concert tickets, but occasionally you’ll see an offer for some cheap tickets by a local who can’t make it that night. If you’ve got computer access while in town, it’s worth a quick look.","It was Molière who said, “Of all the noises known to man, opera is the most expensive”.\nTurns out our French playwright was wrong. At least in Vienna.\nIf you thought a ticket to The Magic Flute would cost more than an actual magic flute, I have some good news: opera in Vienna is priced for everyone.\n- Cheaper seats may obviously sell out fast\n- …but check for returns on the day\n- …and look for the remarkably inexpensive standing space tickets\n- See also:\nVisiting the opera is one of my recommended authentic Vienna experiences. You can, of course, spend a three-figure sum on a seat. But you don’t have to.\nAt the Staatsoper, for example, I’ve recently seen seats for the 2022/2023 season as cheap as €16 for some productions.\nSo what’s the catch (apart from the possibility of a restricted view)?\nNice as low prices are, the three main Vienna opera houses don’t have unlimited capacities. So you usually need to book early if you want to buy the inexpensive seats.\nThe Staatsoper (state opera house) is the most popular venue, and ticket sales and pre-bookings typically start as soon as the season previews are out.\nHowever, pre-bookings for later productions may be oversubscribed, and opera-hungry locals may also snap up the cheap tickets for redistribution to their private operatic circle of friends.\nEven if a Staatsoper performance is seemingly sold out when you search for tickets, my opera-going friend suggests you try the ticket offices on the day in case of returns.\nYou might be lucky, too. International travel is still relatively low in 2022, which may free up space for those activities (like a visit to the Staatsoper) that might normally be sold out.\nEven in “normal” times, I once got two tickets to Madame Butterfly just a month in advance for €30 total direct from the Staatsoper website (albeit with restricted views).\nImagine: two tickets to one of Puccini’s famous works for about the cost of a cappuccino, double espresso and four pieces of cake in a neighbouring coffee house.\nThe standing ticket solution\nAnother way to experience Viennese opera cheaply is through a standing-room ticket (a “Stehplatz” ticket).\nStaatsoper standing tickets\nEssentially, you have two options for getting hold of one of the 400+ standing tickets available for each performance at the Staatsoper:\n1. Register for a (free) federal theatre card\nAn Austrian Federal Theatre card allows you to purchase a standing ticket from a contingent online or at the box office from 10am the day before the performance for either €4 or €5, depending on where you stand. I used this system to see La Bohème and, most recently, Carmen (with Elīna Garanča!).\n2. Buy a standing ticket on the day\nRemaining standing tickets go on general sale on the day of the performance.\nHere’s how that works for the 2022/2023 season…\nYou go to the dedicated “Stehplätze” ticket office (“Stehplatz-Kasse”) on the Operngasse side of the state opera house for the evening performances. That’s the southwest corner of the building.\nThis ticket office opens 80-120 minutes before the start of a performance, when you can buy standing-only tickets for that day’s production. The tickets cost:\n- €13 for the Balkon area\n- €15 for the Galerie area\n- €18 for the wonderful Parterre area\nCheck the Staatsoper service pages for the latest situation on standing tickets.\nIf you can, get a Parterre ticket: these have some of the very best views in the house!\nIn previous seasons, you could only buy one ticket per person. So everyone who wants to attend should be present when you buy the tickets, just in case.\nWhatever method you use to buy your standing ticket, you get to see a performance in one of the world’s most prestigious opera houses for not much more than the cost of your average cinema ticket.\nNow for some info and insider tips for those standing at the Staatsoper:\n- If all you want is a taste of the Vienna state opera experience, this is a cheap way to do it. Another alternative, however, is to take a guided tour (which makes more financial sense now standing ticket prices have increased from the previous season)\n- If the idea of standing for four hours waiting for Isolde to finally keel over is not your idea of fun, fear not. The Staatsoper provides upholstered supports for you to lean on. Not only that, but small, unobtrusive monitors supply you with English subtitles to the libretto\n- I’ve been to the Staatsoper several times and picked up cheap standing-only tickets 30 minutes before the performance started. But…\n…it pays to get there early for more popular productions or those featuring the top stars. I tried twice to get standing tickets for Cavalleria Rusticana and failed both times because of the queues. That’s why I now have one of those Federal Theatre cards.\n- Standing positions in the opera house are numbered, so you don’t need to reserve your place with a scarf or similar\n(Previously, you could “reserve” standing room by hanging something across the relevant balustrade or upholstered support. Equally, you often found places already reserved in this way.)\n- A standing ticket entitles you to use the intermission bars just like any visitor. You can go to a bar before the performance and preorder drinks for the interval to speed up the process\nOther opera houses\nAt the Theater an der Wien, standing tickets are currently unavailable. The main house is undergoing renovations until autumn 2024, and performances have moved to other locations that don’t have that standing facility.\nAt the Volksoper, you order standing tickets (if available) just like any other ticket and they typically cost around €3 to €8.\nAll-in-all it seems opera need not be as expensive as you might think.\nSo take that, Molière.\nP.S. Here a few tips on what to wear."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:f1f3ca23-c18f-4b96-bb66-0a12aefe37df>","<urn:uuid:a825d719-4970-4533-aaca-61e539807b6b>"],"error":null}
{"question":"I'm studying historical glasswork - how did gender roles differ between Tiffany Studios and the Eldridge Street Synagogue project?","answer":"At Tiffany Studios, there was a clear gender division in the work - floral lamp patterns were created by women under Louis Comfort Tiffany's supervision, while men at the foundry created the simpler geometric shades. In contrast, for the Eldridge Street Synagogue's window, the project was led by a female collaborative team of artist Kiki Smith and architect Deborah Gans, who worked together regardless of the design elements.","context":["Kiki Smith is an artist best known for sculpture and largely black-and-white or pale-colored prints inspired by feminist themes or Catholicism. She is not the first person one would think of to design an imposing stained glass window for an historic Orthodox synagogue. So it came as something of a surprise when the Museum at Eldridge Street announced November 23, that Smith, along with architect Deborah Gans, had been commissioned to do just that for the landmark Eldridge Street Synagogue building.\nThe window, on the eastern wall of the 120-year-old synagogue, has been missing since 1944, when the then cash-strapped congregation chose to have it removed because it was proving too costly to maintain. No records were kept of the original design, so Smith and Gans came up with a totally new concept that they hope will complement the eclectic interior, which is already a mix of architectural styles that includes Moorish, Renaissance, and Gothic. “I don’t have such a big ego that I had to make something completely confrontational,” said Smith. “You want to make something new but you want to be pragmatic. You don’t need to make it nostalgic, but at the same time it can reference what is already there.”\nSmith has experience of working with stained glass. But the collaboration with Gans, who Smith met when Gans designed her house, was crucial because of Gans’ experience working on commissions and her technical knowledge for the construction and framing of what is essentially a 16-ft glass wall.\nThe pair have asked the museum not to release sketches of the 16-ft circular window because the design has not been finalized. But they both said that it will continue the pattern of the surrounding wall and ceiling domes — a sky-blue background peppered with gold, five-pointed stars. At the center of the window will sit a Star of David, radiating out towards the wall in a swirl, like the stars, dust and gas that emanate from the center of a galaxy.\nGans said that she and Smith sat in the women’s gallery of the synagogue contemplating the eastern wall for some time. “There was a kind of sky with a field of stars already imprinted on the skin of the synagogue,” she said. “We wanted to extend that into the opening and then have it transformed by the presence of light.”\nThe Eldridge Street Synagogue, founded on the Lower East Side in 1887, was the first great Orthodox synagogue built in America by East European Jews. But it fell into disrepair after the majority of the community either died or moved to the suburbs. Today, a small congregation, Congregation Kahal Adath Jeshurun still uses the premises to pray.\nThe Museum at Eldridge Street is a non-profit which has its roots in a movement to preserve the synagogue that began in the 1970’s. In 2007, it announced — prematurely it seems — the completion of an almost 20-year, $18.5-million renovation of the synagogue. The window in the eastern wall is the final piece in the puzzle.\nAccording to synagogue minutes, the original window was a continual financial burden. It had a wooden frame, rather than a terra cotta frame like the stained glass window on the façade, and it demanded constant repair. It was long thought that a 1938 hurricane that struck New York destroyed the window. But museum deputy director Amy Stein-Milford said the hurricane merely damaged it.\nIn 1944, the congregation decided to replace the window with plain glass blocks arranged in a pillar formation. A December 19, 1944, letter from Knauer & Christensen, the firm that installed the blocks, states that the company would “remove the existing stained glass window as best as possible, saving the stained glass, and depositing same where directed by you within the premises.” No one knows if or how this directive was carried out.\nThe only record of the window that remains are documents in the synagogue archives and oral histories. Stein-Milford said that one document mentions the window’s original circular shape while congregants of the day remembered that its design was similar to the grand rose window on the synagogue façade.\nThough Smith has worked with stained glass many times in the past, it has never been on this scale. She said that she was also unused to designing something for a specific purpose. “I usually work from my own necessity,” she said, “not in response to situations in the world already.” Nevertheless, there were many aspects that drew Smith to the project. She said that she is very interested in religious and spiritual space. And much of her work in the past has made “loose and convoluted” references to the Old Testament.\nSmith and Gans’ original concept for the window was to emulate one of the synagogue’s 11 ceiling domes. They had hoped to make the window curve outwards in a dome shape, but Gans said the cost was prohibitive — the window is already budgeted at $400,000. Instead, the Star of David at the center of the window, which will measure about two feet in diameter, will project outwards slightly, giving it a three-dimensional aspect.\nThe stained glass has also been a complicating factor. Traditional stained glass comes in small sheets, of approximately 12 inches square, that are usually held together by lead. To avoid using lead for this window, individual stained glass plates will be glued onto one large piece of glass. Once the window is finished it will be mounted in the wall next spring. Then, one of the longest-running restorations in the city’s history will finally be complete.","“Infinite endless labor makes the masterpiece”\n-Louis Comfort Tiffany\nAt Century Studios, reproductions of Tiffany lamps are made using the methods and techniques employed by Tiffany Studios at the beginning of the 20th Century. Floral lamp patterns were created and executed by a team of women at Tiffany Studios under the direct supervision of Louis Comfort Tiffany himself, while the simpler geometric shades, considered more masculine, were created by men at the Studios’ foundry location.\nEach lamp created at Century Studios is completely crafted by hand. Shade patterns range from small geometric designs to large intricate floral lamps, which can have as many as 2000 individual pieces of glass. Production time to complete a single shade will vary from 30 to 300 hours, depending on the complexity of the design. Century Studios lamps are created with the same care and attention to detail as the Tiffany originals and are sure to become treasured heirlooms to be passed down to future generations.\nWhen Tiffany Studios closed in 1933 almost all of the production materials used to create their lamps were discarded. Modern glass artists must therefore glean information from existing works which were created by the studio. Designs are traced from original lamps, and turned into working patterns for creating a reproduction. Many Tiffany shade patterns have sectional repeats which will create the full 360° design. There may be three repeats of a section, or possibly two, four, six, nine, even twelve repeats for a full lamp shade. Some Tiffany designs have no repeats.\nMeasurements are taken and a form is created which is the same size and shape as the inside of the original Tiffany shade. Tiffany Studios created prospective new forms in plaster. Once a shape and pattern were approved, the lamp form was turned in wood. Wooden forms are heavy, problematic to store, and because of their weight, are difficult to work with. A number of Tiffany-accurate forms made of fiberglass are available commercially to todays lamp artist. At Century Studios, we also create our own Tiffany-accurate forms in fiberglass.\nOnce the flat pattern and three dimensional form are created, the pattern is drawn onto the form to check the accuracy and glass selection can begin.\nOver the last 30 years, there have been a handful of American glass manufacturers who have created excellent hand rolled Tiffany reproduction sheet glass. Tiffany Studios manufactured its own glass and also used glass created by various makers such as the Kokomo Opalescent Glass Company, which is still in business. American hand-rolled sheet glass differs from European glass in color, texture and transparency. While most European glass is referred to as Cathedral (transparent), American made reproduction glass is usually Opalescent (stops the light and is not completely transparent).\nTiffany Studios used many kinds of opalescent glasses in their lamps; flat, textured, transparent, ring mottle, streaky, fracture, confetti, and drapery are all descriptions of glasses used to create specific effects in the shades. The best hand rolled, opalescent glasses can have as many as five distinct colors in one sheet.\nThe following photos will show the construction of a lamp from start to finish. The most important aspect of reproducing a Tiffany lamp is the selection and layout of the glass. This is the stage where the artistry of a Tiffany pattern will come to life. At this stage, the artist is creating. After this step, the glass artist is constructing.\nWhen beginning a project, the pattern is studied and appropriate glass is chosen at a light table. Since the appearance of opalescent glass will vary when viewed with different light sources, the light source of the light table must be the same as that used to illuminate the completed lamp. For example, some purple glass will look purple in daylight, but will appear brown in incandescent light. Modern compact fluorescent lights will also change the appearance of a sheet of glass. Clear and frosted lightbulbs must be considered, as frosted will flatten the look of some glasses while clear bulbs will provide more sparkle.\nEach pattern piece is positioned on the sheet of glass and cut by hand to fit the pattern. Original Tiffany pattern pieces were constructed from thin sheets of copper and cut around the outside edge. We use transparent mylar patterns to lay out the pieces. The mylar patterns are held to the glass using a “tacky wax” that has been rubbed over the surface of the glass. Some artists prefer to trace around each pattern piece and cut on the drawn lines.\nThe glass surface is scored around the pattern piece with a glass cutter, and will break along the score. Other tools used to help cut the glass pieces to size include a grozing plier, running pliers and nippers.\nThe cut pieces are laid out on a piece of glass and examined on the light table. This flat layout is studied and adjusted until all the pieces of glass are cut and fit and the artist is satisfied that the coloration is correct.\nA thin copper foil is then wrapped around the outside edge of each piece in the lamp. This copper foil is the surface which the solder will adhere to in the next step, and this will form the structure of the lamp. Tiffany Studios used sheet copper which was spread with a thin layer of wax as an adhesive. Since the mid-1970’s there has been copper foil with an adhesive on the back available to todays glass artist.\nOnce all the pieces of glass are foiled by hand (our most complex shade designs consist of over 2000 individual pieces), everything is transferred onto the fiberglass form. The workers at Tiffany Studios would often have to hold the pieces onto their wooden forms using steel pins until they were tack soldered in place. With a fiberglass form, the pieces are held in place with wax, and once everything is set on the form, the soldering begins.\nUsing a lead/tin solder and a soldering iron, the pieces of glass are connected together to form a single lamp shade. The “lead line” between the pieces is usually soldered so that there will be a uniform slight bead to the line. If too little solder is used, the lead line will look concave and the edges of the foil will peel back during cleaning. A proper bead takes many hours of practice and patience to achieve.\nTiffany shades have sturdy brass rings set into the top of each shade. These are sized to mate with different sized wheels. These wheels are screwed onto the lamp bases or chandelier fixtures and will support the shade. The ring is leveled and soldered in place at the top of the shade.\nOnce the outside of the shade is soldered and the upper ring is installed, the fiberglass form is warmed, the wax melts and the shade is removed from the form. Shades which have an undercut are removed in two pieces along a lead line that has not been soldered together. The lower portion of the shade is then reattached to the upper. Soldering continues on the inside of the shade until every lead line is finished. Larger shades will be reinforced with copper wires soldered in place inside the shade, conforming to the path of the lead lines. These reinforcing wires are not seen when the lamp is finished, but provide additional stability to larger pieces.\nFor shades with a flat lower edge, a brass rim is soldered into place at the bottom of the shade. The rim provides strength and stability to the shade and gives each shade a visually even lower edge. Shades with irregular lower edges will have a half round heavy copper wire soldered in place, following the undulating contours of the shade.\nOnce the soldering is finished, the shade ring and rim are filed for smoothness. The shade is then cleaned, and ready for patina.\nTiffany Studios offered a variety of patinations on their lamps. The patina on a lamp shade colors the lead lines so that the shade will match the metal finish on the base or chandelier fixture.\nThe standard verdigris (green/brown with red highlights) patina on a Tiffany shade is achieved by copper plating the lamp shade. The copper plate adheres to the lead-tin solder and not the glass. The lead lines are then aged in a multi-step chemical process which first darkens the copper, then brings up the green color.\nOnce the patination is complete, the patina on the lead lines needs to be sealed. The surface of the entire shade is covered with a thin lacquer and the shade can then be waxed to further tone the patina if desired. Tiffany Studios used many different lacquers during their years of lamp construction. The finished shade is then brought together with the lamp base to complete the lamp."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:3407c23f-dbf6-430d-b04b-ebb4771175a1>","<urn:uuid:613a0ae8-3d52-48db-ad7e-c8f2c45feffc>"],"error":null}
{"question":"What are the similarities between the Widmanstätten pattern in meteorites and the internal patterns found in cat's eye marbles, and how can they help identify their authenticity?","answer":"The Widmanstätten pattern in meteorites and cat's eye marbles both feature distinctive internal structures, but they're formed very differently. Cat's eye marbles contain different-colored blades or vanes inside clear glass, with black vanes being unusual. The Widmanstätten pattern in meteorites like Muonionalusta consists of intersecting bands of kamacite and taenite minerals, formed when the material cooled very slowly through red-hot temperatures. While cat's eye patterns are deliberately manufactured, the Widmanstätten pattern is a natural formation that can only occur under specific conditions - cooling at a rate of 100-6600°C per million years. This pattern is one of the easiest ways to authenticate iron meteorites, as these conditions cannot be replicated in a laboratory and rarely occur on Earth.","context":["Marbles have been made of all kinds of materials throughout history. At first they may have been simple round stones or clay balls. More recently they have been made of actual marble, clay, porcelain, glass and steel.\nThe process for making marbles has changed over the years as new materials and technologies spread. The names and kinds of marbles you will find today have a lot to do with how the marbles were made, who made them, and how they were played. If you want to understand marbles, you should know about all of the different kinds of marbles.\nThese marble names refer to categories of marbles.\nAgates or Aggies - By the middle of the nineteenth century, marbles made of agate had become so popular that the word aggie, a nickname for agate, came to be used for all stone marbles. Many were quarried and ground in Germany and then exported to America and other countries. Aggies were often colored with black, gray, green, blue and yellow mineral dyes.\nAlleys or Allies - get their name from alabaster, which is a soft stone related to marble. Alleys have come to mean very good marbles, or marbles in general.\nBenningtons - got their name from Bennington pottery in Vermont, which made some spotted pottery that resmebled these marbles. Benningtons are blue or brown glazed marbles that aren't completely round. A Bennington has a circular unglazed spot that results from its touching another marble while still wet with glaze.\nBumboozer - a large marble or agate or glass.\nCat's Eyes - Clear marbles with different-colored blades or vanes inside. It is unusual to have black vanes inside this type of marble.\nChinas - Marbles made of china or porcelain clay. There are both glazed and unglazed chinas.\nClearies - Clear glass marbles made of a transparent single color throughout.\nClouds - End of day marbles with colored flecks of glass that aren't stretched, which look like clouds floating over the core.\nComics or Comic Strips - Marbles with comic book characters on the surface. Only made for a brief time period, so they are rare.\nCommoneys or commies - This name refers marbles that are very common. originally, clay marbles were the least expensive marbles. Beginning around 1840, a factory in Ohio was producing clay marbles at a rate of 100,000 per day. Glazed or unglazed, they were colored in tans, reds, and browns of the clays they were made. The nickname commies originated then with a shortened form or “commoneys” because they were common, every day marbles children used for play.\nCorkscrews - Marbles with 2 or more colors in spriral designs. In corkscrews, the spirals rotate around the marble from one pole to the other, but they do not meet.\nGlassies or Puries - Clear, brightly colored glass marbles.\nImmies - glass marbles streaked with color so they look as if they were made of real aggate. Immie is short for immitation.\nMilkies - opaque, milky white marbles.\nOnion Skins - End of day marbles in which colored flecks of glass are stretched so that the core has may swirls, resembling an onion.\nPeewees - Small marbles, usually less than 1/2 inch wide.\nAntique Commies are still fairly common. They are still inexpensive and within reach of the average marble collector.\nCrockery Marbles - Most crockery or stoneware marbles were brown with a blue glaze. They are called Benningtons because their glaze resembles that of the brown and blue glazed Bennington ware pottery produced in Bennington Vermont during the nineteenth century.\nAntique cane-cut glass marbles - though some speculate that glass spheres produced near ancient Rome were used as marbles, the earliest glass toy marbles were made in Germany in the middle of the nineteenth century. In 1846, a glassworker in the town of lausche invented the marbelschere, or marble scissors, a tool that rounded a marble in one step.\nLatticinio core – akes its name from the italian word for “net” and refers to the open network of narrow strands of milky, white glass that appears in the center. Divided core and Ribbon core – These two closely related swirls make up about 20 percent of antique swirls. Both have ribbons of color near the center which spiral from end to end.\nsolid core marbles\nLutz – Golden veins of jewel like glass sparkle vividly in these hand made swirls. Aventurine, a yellow glass containing small copper crystals, give lutz marbles their phosphorescent brilliance. Lutzes are the crown jewels of marble collecting and are prized for their beauty and rarity.\nColored glass coreless swirls – it was not possible to use colored glass ribbons with a colored glass marble since their interior colors wouldn't be seen, or if they were visible their colors would be muddy or unclear. As a result, colored glass marbles were coreless and were decorated with either bands or swirls of white near the surface, or color applied to the surface.\nClam broths – also known as clams, these are amongst most popular of collectible marbles. They take their name from the chowder white opaque glass from with they are made. They characteristically have many thin outer swirl lines of contrasting color running from pontil to pontil.\nGooseberries – gooseberries are an example of a colored glass marble. They have numerous thin white threats distributed evenly around the surface of the marble.\nOpaque glass swirls – less translucent than colored glass swirls, opaque glass swirls are decorated with lines, bands and swirls on their surfaces.\nIndian Swirls – also known as indians, these opaque are made of black glass with outer bands of colored glass. They were named by authors of a marble book who mistakenly claimed that the marbles came from India.\nSwirls - could be handmade or machine made. The handmade ones have bands or strands running from end to end.\nSteelies - ball bearings used as marbles. Many ball bearings are used for industrial purposes.\nPeppermint swirls – these popular red, white and blue swirls were made around 1876 to commemorate the American centennial. Although designs vary, each marble was fashioned from a clear core of glass surrounded by a thin layer of white glass decorated with blue bands and red stripes. The most valued peppermints are sometimes called flags.\nOnionskins – Although this cane-cut swirl usually has at its center a clear glass core, it appears solidly colored because the clear core is covered by a thin layer of opaque color and then covered again by a thin layer of clear glass. Extremely popular and highly prized, onionskins take their name from the layering of glass, like layers of an onion. in contrast to end of day marbles, onion skins have two pontils. The base color, usually white or yellow, was applied by rolling clear glass marble in powdered glass. Accent colors were added by rolling the heated piece over fragments of crashed glass, creating the speckled effect. There are various types of onionskins: single color, speckled, and segmented. Sometimes mica was added to the glass, thus increasing its value. Onionskins were known to exist from the beginning of the cane-cut marble industry. An early example, dated between 1850 and 1860 was unearthed in the excavation of an old privy in New Orleans.\nMicas – Mica was added to many kinds of marbles. however, the marbles called micas are those clear or colored glass marbles with no designs in which mica flecks are suspended. The flecks of mica in the marbles add sparkle and glitter when placed in bright light. Micas are made of clear, blue, green, amber and red glass. The rare red micas are much sought after by collectors.\nEnd of day - End of day marbles were fashioned from the glass crumbs left over at the end of a workday. Traditionally, they were not sold but were given as special treats to neighborhood children. no two end of day marbles are alike. To make an end-of-day marble, the worker gathered a small amount of glass at the end of a rod and rolled it over a powdered colored glass that served as a base color. this was heated in the furnace and then rolled again over powdered glass this time the days leftover scraps of colored glass, which adhered to the hot surface of the base color.\nClouds – like end of day marbles, these marbles were individually made. They are clear glass spheres with bits of colored glass suspended within. The interior colors, blue, red, yellow, white, or green – are in the shape of a hot air balloon and seem to float like a cloud in the transparent marble. In come clouds, bits of colored glass were set within other colored pieces and required special skill to produce. Clouds are rare and valued by collectors.\nSulphides – Sulphides are clear glass spheres with white or silvery figures suspended in their centers – animals, birds, human figures, numbers or other figures. They were produced in Germany from the mid-nineteenth century until the end of World War One and they may have also been made in England and the United States.\nTransparent Swirls – There are six classes of transparent swirl that describe their features. Some have a solid core. Others have a latticino core, divided core, lobbed core, or no core at all. All of them are made of transparent glass with the core and swirls of solid or transparent colored glass.","This little chunk of crystalline metal is a tiny slice of a meteorite — a rock that fell from the sky. When one says that, the next natural question is, “how do you know it’s a meteorite?” (We will get to that.) But what is really staggering is not just that we know, but how much we know about it and its history. And what a long history it is.\nThis specimen is a 68 gram sample cut from a fragment of the Muonionalusta meteorite. According to our best current understanding, the parent body that Muonionalusta came from was one of the earliest bodies to take shape during the formation of our solar system. It began as a protoplanet (or planetisimal) that accreted within the protoplanetary disk that would eventually become our solar system. It accreted over the course of roughly the first million years after the beginning or our solar system. (That is to say, during the first million years after the very first solids condensed from the protoplanetary disk.) The parent body had an iron-nickel “planetary” core, 50–110 km in radius, that was eventually exposed by collisions that stripped away most of its insulating mantle. It cooled very slowly over the next 1-2 million years. It is estimated (with startling precision) by Pb-Pb dating that the body crossed below a temperature of ~300 °C at 4565.3 ± 0.1 million years ago, just 2-3 million years after the solar system began to form. For the next four billion years, it led a largely unremarkable existence as an asteroid (minor planet) until it broke apart (possibly due to a major collision) about 400 million years ago. Then, one fine day roughly one million years ago, a large fragment entered the earth’s atmosphere, breaking into hundreds (perhaps, thousands) of smaller fragments that rained down in a shower of fire upon what is now northern Sweden and Finland. Four ice ages transported the surviving meteorite fragments across the Swedish tundra, until their first discovery (and naming after the nearby Muonio river) in 1906.\nBut, how do we know all of that?\nThe Widmanstätten Pattern\nThe first piece of the puzzle is the crystalline structure of the material itself. Meteorites fall into a few broad categories including iron meteorites, stone meteorites (the most common kind), and interesting mixtures between the two.\nIron meteorites are composed of iron-nickel alloys, and some, like this one, display a curious feature called a Widmanstätten pattern. A Widmanstätten pattern is comprised of intersecting lamellae (bands) of kamacite and taenite — two nickel-iron minerals with different nickel-iron ratios. These crystals formed in the material when it was cooling through the “dark red hot” temperature range. The size of the lamellae depends strongly on how slowly the material cooled through that temperature range. In order to form macroscopic lamellae like these, the material had to be cooling at a rate in the range of 100 – 6600 °C per million years. (Reference). These conditions have existed only very rarely on Earth and cannot be created in a laboratory. In fact, about the only imaginable conditions that would create large masses of red-hot nickel-iron alloys that cooled at a rate of order one degree per millennium would be the core of a small protoplanet. (It couldn’t be the core of a large planet; Earths’ own core is cooling at a rate of ~100 °C per billion years!)\nWhile the vast majority of meteorites do not exhibit a Widmanstätten pattern (because they are stone meteorites, too rich or poor in nickel, or cooled at the wrong rate), the presence of a macroscopic pattern is one of the easiest ways to be sure (at least beyond a reasonable doubt) that a given object is indeed a meteorite.\nAlthough the crystal pattern looks “triangular” from the side, iron meteorites with a Widmanstätten pattern are octahedrites, as the crystal structure forms along planes parallel to the faces of an octahedron. (There are four unique orientations, as opposite faces of an octahedron are parallel.) Let’s look at a common example of an octahedron for reference:\nIn our sample, you can easily pick out three of the four planes, by tracing bands from the edges of the “triangles” on the top surface down over the corners. Less obvious is that the fourth plane is approximately parallel to the top surface. The “gray areas” on the top surface that appear to lack lamellae are actually places where the surface has been cut right through the center of one of the lamellae.\nBecause the crystal structure is three dimensional, a cut from a different direction might yield a very different looking Widmanstätten pattern. Noting that an octahedron is like two pyramids stuck together, imagine cutting the “cap” off of one of the pyramids of Egypt. The planes that are cut meet at right angles, and thus if this meteorite were cut from a different angle, one would see the bands meet in a 90° grid, rather than in a set of equilateral triangles.\nIt is worth noting that even if the Widmanstätten pattern is present in a meteorite, the bands are not immediately visible if you simply slice into it. A cut and polished section of iron meteorite looks like any other piece of polished metal until you etch the surface to reveal the crystalline pattern. In some cases, terrestrial weathering performs the same “etching” function, allowing one to even see the bands on the exterior of the meteorite.\nTracing and dating the parent body\nWhile traditionally iron meteorites were categorized and grouped by the size of their (or lack of) Widmanstätten patterns, modern analysis now groups them by their chemical properties including proportions of trace elements such as gallium, germanium, and iridium. The data clusters together into 12 groups, each of which represents a distinct parent body and the meteorites that came from it. A 13th group of meteorites (about 15% of the total) represents meteorites that came from all other parent bodies. This is remarkable — of all iron meteorites that fall to Earth, we can trace upwards of 85% of them to the particular parent body (planetisimal) that they came from.\nMuonionalusta is a “group IVA” (roman numeral 4A) meteorite, and its parent body is generally referred to simply as the “IVA parent body.” Examining samples of group IVA meteorites from all over the world — notably including the famous Gibeon meteorite — begins to tell a story not just about an individual meteorite, but about that parent body and its characteristics. The distribution of widths of the Widmanstätten patterns in group IVA meteorites gives the distribution of cooling rates in the parent body, which is one of the factors needed to calculate the size of that parent body when it was cooling.\nBut this, of course, is only the tip of the iceberg. Radiological dating (particularly lead-lead dating) tells us not how fast but when it cooled, and cosmic ray exposure data tells us about how the body broke apart 400 million years ago.\nYep, it’s really old.\nIf you should happen to pick up a piece of this material, it’s likely the oldest thing that you’ll ever touch. It’s a piece of the oldest known “differentiated body” in our solar system.\nIt is not quite the oldest known solid matter in our solar system. That honor belongs to certain meteorites called carbonaceous chondrites that contain inclusions (up to 4.568 billion years old) of those very first grains to accrete within the presolar nebula that would eventually become our solar system. None the less, it does date to within several million years of the formation of our solar system, and is older than the earth itself. (Aside: Earth is generally regarded to be ~4.55 billion years old. An exact date is hard to nail down, since Earth likely accreted from smaller planetisimals over the course of 30-40 million years.)\nLet’s put that age into a little perspective. You might know that the Great Pyramid of Giza is very old. After all, it was already truly ancient — 2500 years old — by the time that the last pharaohs (Cleopatra et al.) were ruling Egypt, and it is 4500 years old today. But this little chunk of metal is one million times as old as that.\nGetting a piece\nThere has been a boom in finding pieces of the Muonionalusta in recent years, thanks to industrious souls who brave the mosquitos of Sweden to survey the land with giant metal detectors and take great pictures of all the meteorite fragments that they find. See here and here for some great pictures and examples.\nThe good news for those of us who do not brave the mosquitos is that they are selling them in neat little cut and etched pieces for as little as a few dollars each. The going rate is $1-2 per gram. What a price for a chunk of the oldest matter that you can hold in your hand."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:76a56909-fe7f-4592-b5ba-c89c283744dc>","<urn:uuid:a71a6b61-2fb1-4068-8fd9-3e7a2d8e5c1b>"],"error":null}
{"question":"How can schools establish an effective mentoring program for education support professionals?","answer":"To establish an effective ESP mentoring program, start by creating an 8-hour orientation for all new school employees. Then, match new ESPs with mentors who guide them throughout their first year. Mentors should meet with mentees at their school and maintain contact at least twice monthly through in-person meetings, phone calls, or emails. The program should include opportunities for relationship building through events like luncheons, and focus on helping ESPs understand their roles, establish personal and professional goals, and become active leaders. Training topics should be tailored to specific ESP careers, covering areas like understanding IEPs and role-specific responsibilities.","context":["Everyone has first day jitters, but for many, jitters can quickly escalate into to first day fright when they start a job with absolutely no training or guidance. That’s been the trend for education support professionals (ESPs), many of whom start their first day of school with only a few introductions and maybe a perfunctory tour, only to be left to figure out the rest on their own.\n“Most times ESPs don’t even know where the bathroom is let alone who to go to with problems,” says Judy Near, a retired health technician who was 2012 NEA ESP of the Year and one of three Colorado ESPs who organized the Canon City ESP Association (CCESPA). “They need guidance on all the do’s and don’ts, they need to get a sense of the school’s culture, and they need someone to simply help them get up to speed and relieve their stress.”\nShe partnered with the school district’s Human Resources director to create an 8-hour orientation for all new school employees, whether they were NEA members or not. Next they created a mentoring program so new ESPs could be matched with a mentor to guide them through their first year.\nA Stronger Voice\nThe result: well prepared staff who felt welcomed and valued, and a stronger voice for all ESPs.\n“Any time you give people the opportunity to learn it gives them voice,” says Near. “But when you give ESPs a voice and an opportunity to help other support staff know their value, then mentoring becomes invaluable.”\nA stronger voice for ESPs leads to greater job satisfaction and lower turnover, which is the chief reason mentoring is critical for anyone working with students.\n“We all know that kids get attached to the adults they see at school, they develop a comfort level with them and feel secure with consistency and familiarity,” says Near. “That’s the biggest win from training and mentorship – it allows our ESPs to feel welcomed and valued which leads to longevity so our kids don’t see someone new every day or every year.”\nAnother outcome of ESP mentoring programs is increased professionalism and growth, according to Kathy Ellis, president of the Red Clay Paraprofessionals Association in Delaware, the first ESP mentoring program to be launched in the state.\n“The mentoring and trainings we offer are designed by us, for us; they’re tailored to our careers, with topics like understanding your role as a one-on-one paraeducator or a classroom paraeducator, understanding the IEP, and staying in compliance,” she says. “The paras provide the training and orientation, so we are demonstrating the professionalism that all ESPs strive for and we are guiding our colleagues along their educational journey so that nobody becomes stagnant.”\nMentoring program participants receive an orientation and then are assigned a mentor who works with them throughout the year, meeting them at their school and staying in touch at least twice a month in person, by phone or by email. They continue their relationships at luncheons and other events, and most stay friends beyond the official mentorship term.\n“It’s about making connections and building a relationship,” says Ellis.\nMore Value, More Respect\nAnother key element in the mentoring program is building self-confidence and self-respect, says Quanyet Gibbs, vice president RCPA. Too often she hears members say “I’m just a para” or “I’m just an ESP,” but that line of thinking undermines the vital contributions they make to student lives.\n“Sometimes we’re shortchanged by the word ‘para’ or ‘teacher’s aide’,” she says. “There’s a stigma that must be overcome. We have bachelors and master’s degrees, and we are every bit as important as other educators. Mentoring reinforces that fact.”\nMentees are asked to create and then reach personal and professional goals and are held accountable to them along the way. Mentors also demonstrate how ESPs can be active leaders, which in turn encourages mentees to become more active and to recognize and prepare for their own leadership opportunities.\n“When you know better, you do better -- with yourself, your colleagues, and your students,” says Gibbs. “We have to know to grow.”\nRecognize Personal Strengths\nOlive Giles, a school secretary and vice president of the Princeton Regional Educational Support Staff Association (PRESSA) agrees that mentoring allows support staff to grow in unique ways. Sometimes it allows them to learn about their own skill sets they didn’t know they possessed. For example, somebody who likes to talk a lot might not know about their persuasive skills that could be useful in organizing or negotiating. Or someone who has knowledge about the best materials for the gymnasium floor, the safest cleaning products, or the most environmentally friendly food practices in the cafeteria could be useful on the school’s sustainability committee.\nBut Giles says that perhaps the most important element of mentoring is knowing that you’re not alone.\n“Starting a new job in a new school is never easy, but it’s so helpful to know that there’s somebody to guide you, who knows what you’ll be going through in the weeks, days, hours and minutes of your day-to-day routines,” she says.\nJust as RCPA launched the first ESP mentoring program in Delaware, PRESSA is the first ESP program in New Jersey and they are looking at replicating the program throughout the state.\nFor other locals trying to launch their own ESP mentoring program, Giles offers this advice: Look for the outspoken, the curious and those not afraid to take initiative and try new things. Recognize that it takes time, baby steps, tweaks and evolution. And in the words of a pin she proudly wears as a front office ESP, “If at first you don’t succeed, try doing what your secretary told you to do the first time.”\nThe National Education Association believes that mentoring programs are a means of enhancing the professional expertise of employees and retaining quality educators. Since December 2018, NEA has trained and supported 53 local associations from 25 state affiliates in building high-quality ESP peer mentoring programs. If you would like to learn more about how to establish an ESP mentoring program, contact us at [email protected] or visit nea.org/espmentoring."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:8adefbdf-3b7f-4cee-8a40-689616c0934b>"],"error":null}
{"question":"Looking at two significant industry transformations in modern history, how do the deregulation of the freight transportation market in the 1980s compare with Siemens' impact on telecommunications in the 1840s?","answer":"Both events marked revolutionary changes in their respective industries. The freight deregulation in the 1980s transformed the industry from a highly regulated space run by a small number of monopolies into an open market with millions of shippers, hundreds of thousands of carriers, and numerous brokers coordinating between them. Similarly, Siemens' innovations in the 1840s revolutionized telecommunications through the development of a superior pointer telegraph that automatically controlled synchronization between transmitter and receiver, representing an entirely new solution in electric communications. Both transformations led to significant industry growth - the freight industry evolved into an $800-billion market, while Siemens grew from a startup into an international electrical conglomerate with 6,500 employees and 20 million marks in annual sales by 1892.","context":["When asked to simplify the $800-billion freight transportation market, DAT’s Chief Scientist Chris Caplice puts it simply: “At the end of the day, everything moves on a truck.”\nWhile stalled boats packed with shipping containers may have dominated headlines over the last year due to supply chain issues, those shipments still have a long way to go to reach their final destination of warehouses, stores, and eventually, your front door.\n“These shipments get broken down into smaller and smaller pieces,” Chief of Analytics Ken Adamo said. “Eventually, it all rolls down to trucking.”\nThis is where the logistics start to get a bit more complex.\n“Just before DAT was founded, the freight industry was deregulated,” Caplice said. “Before the 1980s, it was a highly regulated space run by a small number of monopolies that operated in certain geographies. When it was deregulated, suddenly there were millions of shippers trying to buy transportation, hundreds of thousands of available carriers, and all of these brokers in the middle trying to orchestrate it all.”\nShippers, carriers, brokers. What’s the connection?\nAccording to Caplice, one of the main challenges in the industry has always been for shippers and brokers to find carriers who have the capacity to carry the right amount of cargo at the right time for the right price. This is the issue DAT was built to solve in 1978, by providing a freight marketplace that connects all three parties, creating more efficient transportation options. Ultimately, that means more goods moving faster.\nFast forward to 2022. The Covid-19 pandemic and a mighty e-commerce boom have spurred new advancements in the industry, ushering in an era of increased public interest and burgeoning digitization. To Chief of Analytics Ken Adamo, this acceleration of new technology and increased awareness of the supply chain makes now an especially exciting time to join the field.\n“It’s a great time to be in the industry because the toothpaste isn’t going back in the tube,” Adamo said. “DAT inspired this digital frontier 44 years ago, and it’s why we’re on the front lines of this digital boom in the supply chain industry today. I’m really excited to be a part of it.”\nTo learn more about where the North American supply chain has been, and where it’s heading, Built In connected with Adamo, Caplice, and Director of Product Management Sarita Benjamin. The trio of industry veterans filled us in on the impact of DAT’s work, how it affects people across the United States, and why, in the world of logistics, all roads lead to trucks.\nCan you tell us a bit more about how DAT’s platform works?\nDirector of Product Management Sarita Benjamin: We enable shippers and brokers to find the right carrier for their needs, and ensure they trust those carriers. We provide all of the tools for our brokers, carriers, and shippers to move freight using our digital marketplace, and to ensure they never have to “drive empty.” We want all three parties to be able to build relationships with one another, find the right match, expand their networks, and do business on our platform.\nAnother aspect of what we do is provide access to brokers. If a shipper or carrier hasn’t worked with a specific broker, we give them tools to onboard with these brokers, and in turn, enable brokers to grow their networks. Brokers look at increasing capacity to ensure they have access to as many carriers as possible so that they always have loads moving. They come to our platform to build those relationships and expand their networks.\nChief Scientist Chris Caplice: We also help customers understand what is going on in the market, and help them see if they’re doing something wrong, like quoting prices above the market rate. We also work in predictive information, where we predict what rates will be going forward.\nThat rate-casting is really helpful because it helps shippers, carriers, and brokers understand what the market rate will do, which allows them to plan for the future. Finally, there’s a prescriptive side to data science, which helps people understand how they can improve relationships with other parties.\nChief of Analytics Ken Adamo: Let’s say someone created an app that was far better than Uber, in terms of how intuitive it was and how much cheaper the prices were. Why wouldn’t someone use it? Because Uber has millions of cars at their disposal, and this new app might only have hundreds or thousands.\nWhen people use DAT, they’re assured they’re going to find that kind of high capacity. For us, those are table stakes because you won’t get far in this business without density, and you certainly can’t scale. On top of that density, we add high quality, an ease of use, and the type of creature comforts that make our product sticky and easy to come back to.\nWe’ve heard a lot about the supply chain issues brought on by the pandemic. How does this impact the freight industry?\nCaplice: All of the problems that were exacerbated by the pandemic have always been there. It all just suddenly became more apparent. Finding capacity has always been an issue in the industry, but it just got worse over the last two years since so much change was being introduced.\nBefore this age of uncertainty, shippers would typically come up with a shipping plan about once a year, thinking they could map everything out. That hasn’t been possible during the pandemic. Now, there’s more of a need to execute shipping dynamically and intelligently. The expertise has moved from creating plans to becoming more adept at execution. Now, there are more brokers, there’s an increasingly dynamic market, and shippers, carriers, and brokers are becoming more responsive and need more information. That’s where we come in, as we’re able to provide them with the information they need to make better decisions in real time.\nAdamo: A lot of shifts in the industry started with the e-commerce boom, and Covid-19 has really just poured gasoline on that fire. When the pandemic hit, we saw more of a shift from traditional brick-and-mortar to e-commerce and direct-to-consumer products. Now, transportation networks like density: whether it’s freight or airlines, shippers want ways to consolidate their shipping, and they also want to branch out. That’s really difficult to do, especially with the rise in e-commerce. When businesses get deliveries, it’s usually hundreds or thousands of packages. If you’re without data in that situation, you’d be pretty lost.\nWe really saw the pandemic accelerate a digital revolution in the industry. For example, there used to be a system that involved “trip packs,” which is a stack of paperwork you’d finish after you made your delivery as a truck driver. But what happens to that system when you can’t get out of your truck cab due to Covid-19? It’s hard to believe, but the trucking industry was that far behind. It only deregulated two years after the airline industry, so this is the equivalent of all of us still using paper boarding passes on planes.\npeek into the rise of digital solutions in freight logistics\nDAT has a tremendous amount of data. What’s the impact of all of that information?\nAdamo: We partner with more than 1,200 companies that essentially give us a bunch of data. We anonymize, aggregate, and analyze it, then feed it back to our customers in a way that adds a lot more value than they could ever derive from using their own data or research individually. What our shippers want to know is what the market will bear, and that they’re not overpaying. Many frontline brokers are operating in very entry-level positions. We provide them with the data and insights they need to get better at their jobs, get up to speed quickly, and have a competitive advantage.\nA couple of years ago, we launched our first predictive tool which forecasted how much it would cost to move a shipment in a certain location. Let’s say a particular shipment weighing 35,000 pounds has a two-day lead time. Instead of just listing a bunch of carriers, we provide carriers based on a shipper’s activity that might be a good match. So, we’re moving up from descriptive analytics to predictive analytics, and adding a lot of insight.\nWhat are some new tools DAT is working on?\nBenjamin: Currently, we’re working on integrating the shipper, broker, and carrier experiences to make them more seamless and holistic. Our No.1 priority is the booking experience. We want to enable brokers to book loads 24/7, not just during business hours. We’re also looking into eliminating the need for shippers or brokers to pick up the phone and negotiate a rate for one specific load, which can take up to 30 phone calls. We are figuring out how we can give them access to a network with more tech-savvy carriers, by analyzing the typical carriers or brokers they work with, and giving them the ability to match with them.\nAnother goal is to provide our carriers with the most up-to-date loads that are available to them, so they never have to drive empty. As soon as they finish a specific leg, they come to our freight-matching solution to see the next load they can get. DAT’s aim is to eventually start pushing loads to them, based on their historical behavior. That way, they always trust that we can take them to their next location, and they don’t have an empty truck. From a standpoint of integrating cost data, we’re trying to ensure we give both brokers and carriers the rates they need to have the information to negotiate and book their load at the price that’s suited for them.\nThe road to increased sustainability\nIn a quickly growing industry, what makes DAT stand out from the competition?\nAdamo: DAT has been around for 44 years, so what really sets us apart is our expertise in the industry. We have folks on our product team who have been doing this work for three decades. We also have relationships with all of the top firms in the industry, whether you’re a shipper, broker, or carrier. We have a working relationship with every truck you see going down the highway with a recognizable name, along with 99 out of 100 of the top brokers.\nWhen you combine our people, our relationships, and the absolute most data in the industry, that’s what differentiates us.","On this day in economic and business history...\nSiemens (NASDAQOTH: SIEGY ) was founded in Berlin on Oct. 1, 1847.\nFounder Werner von Siemens was determined to develop new ideas in telegraphy, which was still in its infancy -- Samuel Morse had first publicly demonstrated long-distance telegraphy in the United States only four years earlier. In the winter of 1846, Siemens successfully developed a new prototype device, which his namesake company explains in its historical archives:\nThe cornerstone of [Siemens'] career was the idea of building a pointer telegraph out of cigar boxes, tin plate, pieces of iron and a bit of insulated copper wire. The device was far superior to the apparatus in common use until then, because it no longer worked like a clock mechanism. Instead it automatically controlled synchronization between the transmitter and the receiver -- an entirely new solution in electric communications.\nSiemens collaborated on the device's construction with his friend Johann Georg Halske, a mechanic he had met at the local Physics Society. Halske was won over by the new device's potential, but the two tinkerers lacked the capital to establish a venture of the proper scale to produce it. Siemens convinced his wealthy cousin, Johann Georg Siemens, to be his financial backer, and the three men established the \"Telegraphen-Bauanstalt von Siemens & Halske,\" or \"Siemens & Halske Telegraph Construction Company,\" on Oct. 1, 1847. Two weeks later, on October 12 -- now considered the company's \"Founding Day\" -- the company began operations in Berlin.\nWerner von Siemens led the company to fantastic success until his death in 1892. By this point, the start-up had become an international electrical conglomerate with 6,500 employees worldwide and 20 million marks in annual sales -- it was easily a multibillion-dollar company by modern standards, though accurate conversion records of pre-World-War-I German currencies are very difficult to find. Along the way, Siemens helped wire the world, and the company's accomplishments included laying the first Indo-European and transatlantic telegraph lines.\nWerner von Siemens himself invented the first working electrical dynamo (in 1867), the first electric locomotive (in 1879), and the first electric streetcar and elevator (in the early 1880s). His wide-ranging electrical achievements made him something of a Thomas Edison of Germany, a comparison made all the more apt by the fact that several of his key breakthroughs -- particularly the dynamo -- helped Edison build General Electric into an electrical-manufacturing giant of ultimately greater global scale. The electrical unit of conductance, the siemens, is named in honor of his contributions to human knowledge of electrical engineering.\nThe birth of a new metal market\nThe Pittsburgh Reduction Company, predecessor of Alcoa (NYSE: AA ) , was incorporated on Oct. 1, 1888 , roughly two years after founder Charles M. Hall's discovery of the first effective way to produce aluminum in large quantities. Thus Alcoa became the first true aluminum company ever created, and thanks to Hall's aluminum extraction patent -- granted half a year later -- it had a legal monopoly over this revolutionary new process for nearly two decades. This patent defensibility no doubt helped 24-year-old Hall assemble $20,000 in seed funding (equal to nearly $500,000 today) for the world's first aluminum plant in Pittsburgh, which was already becoming known as a major steelmaking town.\nAlcoa embodied the youthful high-tech mindset of Silicon Valley decades before anyone even considered building computers, with recent graduates Hall and Arthur V. Davis -- only 21 when he became Alcoa's first employee in 1888 -- guiding the company in its early years. Hall was an idealistic Steve Wozniak to the more business-minded Davis' Steve Jobs, and the inventor continued his role as Alcoa's head of research while Davis stepped into the corner office. By the early 1890s demand for Alcoa's aluminum necessitated expansion, and within a decade of Alcoa's formation the company operated three plants and had managed to reduce the cost of aluminum by 95.5%. Aluminum, once so rare that it was prized above gold, was becoming a metal used by the whole world, rather than just the elites.\nThe Pittsburgh Reduction Company changed its name to the Aluminum Company of America in 1907. Hall continued to serve as the company's vice president of research until his death in 1914, by which point the price of aluminum had fallen to $0.18 a pound, a 99.4% reduction in price from the roughly $32-per-pound price it had commanded before Hall's birth. Alcoa's position remained so dominant for so long that the U.S. Justice Department filed an (unsuccessful) antitrust suit against the company in 1938. After fending off this suit, Alcoa joined the Dow Jones Industrial Average (DJINDICES: ^DJI ) in 1959. After the removal of Bethlehem Steel in 1997, Alcoa became the sole metals-industry representative on the index for over 15 years, a position it finally relinquished in 2013.\nWorldwide aluminum production, which was negligible before Alcoa's creation, reached a worldwide total of 43.9 million tons 120 years after the company was incorporated by one ambitious 24-year-old with one revolutionary idea.\nThe disc that launched a trillion free-trial mailers\nSony (NYSE: SNE ) launched the CDP-101, the world's first CD player, on Oct. 1, 1982. For the first time in a century, media had a digital format and a device from which to access it, three years after the first public demonstration of compact discs. The CD player and the CDs it played were both crazy expensive by modern standards -- the CDP-101 cost roughly $900 at the time, and the limited selection of 113 albums retailed for anywhere from $15 to $20 each, which would be equivalent to a price range of $35 to $45 today. But the CD nonetheless represented a way forward for the music industry, which was at the time limited to formats that were either portable but prone to wearing out, or durable but too large to carry.\nA CD's storage capacity was initially determined in part by the size of Beethoven's Symphony No. 9, which was one of the first albums released at launch. Only 20,000 CDP-101s sold in 1982, but the success of the 1985 Dire Straits album Brothers in Arms -- the first CD to sell more than a million copies -- paved the way for a widespread industry transition to digital formats. Some 400 million CDs were pressed in 1988, and by the 25th anniversary of the CDP-101's launch, some 200 billion CDs had been sold around the world.\nPutting a ceiling on American borrowing\nThe first U.S. debt ceiling was put into place on Oct. 1, 1917, with the passage of the Second Liberty Loan Act. This act, one of a series of revenue-raising measures to finance the U.S.' entry into World War I, offered $3 billion worth of Liberty Bonds to the public at a 4% interest rate. More importantly for the nation's long-term fiscal picture, this act rolled up the unused borrowing capacity of previous revenue-raising efforts into one aggregate limit -- a debt limit, now commonly known as the debt ceiling.\nThis limit restricted the amount the U.S. could borrow only under this particular act, but for several decades, later revenue-raising legislation simply amended the Second Liberty Loan Act to increase its capacity. Existing bond offerings made under earlier legislative edicts retained their own separate borrowing limits until June 20, 1939, with the passage of the Public Debt Act, which placed all U.S. borrowing into the same aggregate pool, thus creating the debt ceiling as we now know it today.\nWant to learn more about the U.S. debt ceiling, from its origins in 1917 to the present day? Click here to read a complete history, or click here for an interactive history on the growth of the U.S. debt ceiling.\nThe Truth About the Debt and the Debt Ceiling\nThe U.S. government has piled on more than $10 trillion of new debt since 2000. Annual deficits topped $1 trillion after the financial crisis. Millions of Americans have asked: What the heck is going on? Is it really time to reconsider this whole \"debt ceiling\" thing? The Motley Fool's new free report, \"Everything You Need to Know About the National Debt,\" walks you through with step-by-step explanations about how the government spends your money, where it gets tax revenue from, the future of spending, and what a $16 trillion debt means for our future. Click here to read the full report!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:8e9fbce4-d822-465e-8a6d-3b4664f679c8>","<urn:uuid:eb0f9ea4-1c96-4908-a857-60a31dfd9c72>"],"error":null}
{"question":"Can both DTA HTI and SA80 rifles be used for NATO ammo types?","answer":"Yes, both rifles can use NATO ammunition, but they use different calibers. The SA80 fires the standard NATO 5.56 x 45 mm round, while the DTA HTI can be configured for various NATO calibers including .50 BMG (12.7x99mm NATO). The DTA HTI is also convertible between multiple other calibers like .416 Barrett, .408 Cheytac, and .375 Cheytac.","context":["By David Crane\ndefrev (at) gmail (dot) com\nAll photos and video contained in this article were shot by DefenseReview.com, and are copyrighted. DefenseReview.com owns the copyright on these photos. The photos and video clips embedded below were shot with a Canon PowerShot S90 10-megapixel digital camera (still camera with video capability).\nThe following article is property of DefenseReview.com (DR) and is copyrighted material. If you are reading this article on another website other than DefenseReview.com, please email us the website address/URL (where the unauthorized DR article reprint is located) at defrev (at) gmail (dot) com. Thank you.\nMay 3, 2012\nTwo days ago, Desert Tactical Arms (DTA) released a presse release on the DTA HTI (Hard Target Interdiction) Sniper Rifle Chassis / DTA HTI Conversion Kit modular bullpup, bolt-action anti-materiel/sniper rifle system becoming available for purchase by civilian tactical shooters. The new tactical rifle system will be available in .50 BMG, .416 Barrett, .408 Cheytac, .375 Cheytac calibers, and, being modular weapon system, will be convertable between all of them. However, Defense Review doen’t know if the weapon can be ordered in .50 BMG configuration for $4630.00 to $4,830.00 USD from the jump, or whether the DTA HTI Conversion Kit will will also have to be purchased for an additional $2,385.00 to $2,485.00 USD. We’ll try to find out and update this article ASAP.\nAs it happens, DTA President/CEO Nick Young took DefenseReview through the DTA HTI Sniper Rifle Chassis system at SHOT Show 2012, and we shot some photos and video of it. The weapon looked and felt good. The DTA HTI anti-materiel/sniper rifle appears to be a beefed-up version of the company’s legacy DTA SRS/PSR (Stealth Recon Scout/Precision Sniper Rifle) Sniper Rifle Chassis system, of which DR is already a fan.\nData and Specs from the DTA website:\nThe HTI sniper rifle maintains exceptional accuracy at extreme distances with qualified ammunition.\n1. Match grade free-floating, and fluted barrels, chambers, and crowns\n2. High quality match trigger\n3. Repeatable return-to-zero barrel mounting system\nQuick Caliber Conversion\nThe HTI Sniper rifle is available in .50 BMG, .416 Barrett, .408 Cheytac, and .375 Cheytac. Both cartridges have excellent accuracy at extreme distances and deep penetration on hard targets. A sniper now has the option to fire high-precision/low-recoil .375 Cheytac and switch to .50 BMG when you need to deliver Armor Piercing, Tracer, or Incendiary payload ammunition.\nThe HTI was designed to operate under the harshest conditions and abuse. It utilizes high-impact polymers, aircraft grade aluminum (7075-T6), ultra high-strength steels, and the durable coatings. The monolithic receiver serves as a full-length mounting chassis, eliminating the need for any sort of bedding interface. Ergonomic stock panels attach directly to the receiver. The HTI sustains its accuracy and reliability in virtually any environment, including subzero arctic temperatures, extreme desert heat and dust, and wet jungle environments.\nThe HTI’s bullpup design makes it the most compact and portable Hard Target sniper rifle in the world, 12 pounds lighter, 12 inches shorter, and far more accurate than the US M82A1 50 BMG rifle currently in service.\n.50 Browning Machine Gun (BMG)\n.50 BMG: 45 3/8 in (114.3 cm)\n.416 Barrett: 45 3/8 in (114.3 cm)\n.408 Cheytac: 45 3/8 in (114.3 cm)\n.375 Cheytac: 45 3/8 in (114.3 cm)\nWeight with Conversion Kit .50 BMG: 20.25 lb (9.18kg)\n.416 Barrett: 20.25 lb (9.18kg)\n.408 Cheytac: 20.25 lb (9.18kg)\n.375 Cheytac: 20.25 lb (9.18kg)\nChassis Weight 8.2 lb (3.7 kg)\n.50 BMG: 29 in (73.66 cm)\n.416 Barrett: 29 in (73.66 cm)\n.408 Cheytac: 29 in (73.66 cm)\n.375 Cheytac: 29 in (73.66 cm)\nRate of Twist:\n.50 BMG: 1 in 13 inches\n.416 Barrett: 1 in 12 inches\n.408 Cheytac: 1 in 13 inches\n.375 CT: 1 in 11.5 inches\nDTA HTI Sniper Rifle Chassis: $4630.00 to $4,830.00 USD\nDTA .50 BMG Caliber Conversion Kit: $2,385.00 to $2,485.00 USD\nCompany Contact Info:\nDesert Tactical Arms (DTA)\nP.O. Box 65816\nSalt Lake City, UT 84165\nEmail: Military Sales: [email protected] (Dave Liwanag)\nEmail Law Enforcement Sales: [email protected] (Mike Davis)\nEmail Dealer Support: [email protected] (Ben Romney)\nEmail Training – [email protected]\nEmail Warranty – [email protected]\nEmail Marketing – [email protected]\n© Copyright 2012 DefenseReview.com. All rights reserved. This material may not be published, broadcast, rewritten or redistributed without receiving permission and providing proper credit and appropriate links.\nLewis Machine & Tool LMT LM8MWS (also written LM8 MWS) 16″ “Slick Receiver” Monolithic Rail Platform 7.62mm NATO/.308 Win. Tactical AR-10/SR-25-Type Battle Rifle/Carbine Upper Receiver(s) with Lightweight Modular Rail System\nMICOR Defense Leader 50 Ultra-Compact, Lightweight Bullpup Semi-Auto .50 BMG (12.7x99mm NATO) Sniper/Anti-Materiel Rifle and PNW Arms Weapons Science .50BMG Ammo at NDIA Infantry Small Arms Systems Symposium 2011: Potential Long-Range Lethality Game-Changer Combo for 21st Century Infantry Warfare (Photos and Video!)","What Is The SA80 Rifle?\nFor more than 30 years, the L85 or SA80 variant has been the standard issue rifle of the British Armed Forces, it replaced the L1A1 Self Loading Rifle (SLR).\nOnce dubbed the ‘civil servant’ by troops amid complaints over its reliability - the SA80 has been the go to rifle for the British Armed Forces on operations all across the world to this day.\nThe first prototypes were created in 1976, with production of the A1 variant starting in 1985. There was excitement that the Armed Forces were soon to be given the world's most advanced rifle, made - and designed - in Britain.\nHowever, the L85 A1’s life came with some teething problems, with soldiers fighting in the desert of Iraq complaining of what they saw as flaws with the weapon.\nComplaints included criticisms over the reliability of the mechanism holding the magazine in place, robustness of the firing pin and complaints about how it fired from the left shoulder, plus other issues about the safety catch.\nAfter many of the issues with the A1 were raised, there was a significant upgrade package in the early 2000’s by Heckler & Koch. Then in came the L85 A2 variant which still remains in service as of 2019.\nWhat Calibre Is SA80?\nThe rounds or 'bullets' the SA80 fires is the standard NATO 5.56 x 45 mm round.\nWhere Are SA80’s Made?\nOriginally designed and produced by the Royal Small Arms Factory at Enfield Lock, North London. In 1988, production of the rifle was transferred to the Nottingham Small Arms Facility owned by Royal Ordnance (later British Aerospace, Royal Ordnance; now BAE Systems Land & Armaments).\nHow much Does The SA80 Cost?\nPrice per rifle not known, thought to be around £1,000.\nFreedom of information request response from the Ministry of Defence dated 2015 states:\n“From an accounting perspective, the value of the SA-80 family of weapons currently held by the MOD is £193.8M. It is currently forecast that the repair and maintenance of the SA-80 family over the next ten years will cost £94M. The current out of service date is 2030.”\n4.98 KG with loaded magazine and optical sight.\nSA80 Muzzle Velocity?\n940 metres a second.\nEffective Range Of The SA80?\nIs The SA80 Any Good?\nThe L85A2 is a magazine-fed, gas-operated rifle locked by a rotating bolt, engaging in lugs behind the breech and carried in a machined carrier running on two guide rods; a third rod controls the return spring. It is capable of firing in both single shot and fully automatic.\nMajor problems with the A1 were ironed out, including a new cocking handle which was designed to deflect the empty cartridges when fired. This improvement meant fewer rounds became lodged in the chamber causing stoppages - a huge problem with the A1 variant.\nThe A2 has now been widely used for well over a decade, with relatively little problems reported during the more recent operations for the British Armed Forces fighting in Iraq and Afghanistan.\nThen came a debate about the calibre of round. Did the 5.56mm NATO round pack enough punch?\nSome reportedly said that, while on operations, the 5.56mm round could not drop enemy combatants in some situations.\nThey argued the previous standard issued rifle, the SLR’s 7.62mm round provided a more sufficient level of firepower on the battlefield.\nThis led to rumours that the SA80 would be replaced altogether.\nHowever, this was short-lived when the Ministry of Defence agreed a contract with Heckler & Koch in 2017 to upgrade a substantial number of L85A2 rifles to the new L85A3.\nAccording to data released by the Ministry of Defence, some 27 million 5.56mm rounds were fired from either the standard SA80 A2 assault rifle and Lightweight Machine Gun (LMG) during the Afghanistan conflict.\nFive thousand A2’s have been upgraded to the A3 thus far.\nThe project will cost an initial £5.4 million and the British Army is set to receive up to another 44,000 upgraded L85A3’s over the next five years. Although the deal will not see the whole British Army SA80 A2 inventory upgraded.\nWhen it was announced by Defence Minister, Guto Bebb, who was responsible for procurement at the time, he said:\n“This multi-million-pound upgrade will give our Army a lighter, more hardwearing, better-camouflaged combat rifle so our soldiers can perform on the frontline of some of the most dangerous locations across the world.”\nChanges to the rifle include a more durable hardwearing coating, it is 100g Lighter than the A2 and easier to handle, with a streamlined foregrip which also comes with a new sight that is smaller and requires fewer batteries.\nThe A3 variant was first issued in 2018 with several new improvements - fixing the issues with over-rotation of the selector lever, adding a new upper receiver.\nA new custom for-end from H&K has been added with a full-length top rail which improves optic mounting and the rifle is also cerakoted in 'Flat Dark Earth' colour, to improve camouflage.\nThe rifle’s barrel is also free-floating - which improves accuracy.\nThe Grenadier Guards, who were the first infantry battalion to fire the new weapon system, put some of the new features to the test when they recently deployed on three separate operational tours on Op Toral to Kabul, Op Trenton to South Sudan and Op Shader in Iraq.\nWill The SA80 Be Replaced?\nWhen Defence Minister Guto Bebb announced the SA80 A2 assault rifle would be upgraded into the A3 model, he said it was so that the weapon could remain in service until at least 2025.\nSo, anyone thinking they might see a change of rifle before then, think again.\n*Headline Picture: MoD/Crown Copyright*"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:a8b8504c-f0d5-43f8-a6e5-132c6d871634>","<urn:uuid:a9e96117-b217-48ad-8568-1047a3a65aa6>"],"error":null}
{"question":"What historical evidence demonstrates Jewish commitment to religious aesthetics versus preservation during persecution?","answer":"Jewish commitment to religious aesthetics is demonstrated through the principle of hiddur mitzvah, where Jews would pay up to one-third more than normal price for beautiful ceremonial objects, even those of modest means would invest in the most beautiful etrog or Shabbat foods. This aesthetic commitment extended to creating beautiful Torah scrolls, Hanukkiyah, and other ceremonial objects. In contrast, during times of persecution, such as in the Nazi era, Jews demonstrated their religious commitment through preservation under extreme circumstances. This is evidenced by instances like Moshe Winterter creating a shofar in a forced labor camp in 1943 despite risk of death, and the Jewish community's distress over the desecration of Torah scrolls, which were misused as lining, purses, and insulation by the Nazis. Both aspects show deep religious devotion, expressed differently according to circumstances.","context":["The sources delineate the minimum requirements of the mitzvot [commandments]. A sukkah must have certain dimensions and must be constructed in a particular manner. The cup for Kiddush must be large enough to hold a specified minimum amount of wine. While some may be satisfied with minimum standards, the Jewish tradition recognizes and encourages the addition of an aesthetic dimension.\nBeauty enhances the mitzvot by appealing to the senses. Beautiful sounds and agreeable fragrances, tastes, textures, colors, and artistry contribute to human enjoyment of religious acts, and beauty itself takes on a religious dimension. The principle of enhancing a mitzvah through aesthetics is called Hiddur Mitzvah.\nThe concept of hiddur mitzvah is derived from Rabbi Ishmael’s comment on the verse, “This is my God and I will glorify Him” (Exodus 15:2):\n“Is it possible for a human being to add glory to his Creator? What this really means is: I shall glorify Him in the way I perform mitzvot. I shall prepare before Him a beautiful lulav, beautiful sukkah, beautiful fringes (tzitzit), and beautiful phylacteries (Tefillin).” [Midrash Mechilta, Shirata, chapter 3, ed. Lauterbach, p. 25.]\nThe Talmud [Shabbat 133b] adds to this list a beautiful Shofar and a beautiful Torah scroll which has been written by a skilled scribe with fine ink and fine pen and wrapped in beautiful silks.\n“In keeping with the principle of hiddur mitzvah,” Rabbi Zera taught [Bava Kama 9b], “one should be willing to pay even one third more [than the normal price].” Jewish folklore is replete with stories about Jews of modest circumstances paying more than they could afford for the most beautiful etrog to enhance their observance of Sukkot, or for the most delectable foods to enhance their observance of Shabbat.\nThe Midrash suggests that not only are mitzvot enhanced by an aesthetic dimension but so is the Jew who observes it:\nYou are beautiful, my love, you are beautiful, through mitzvot . . . beautiful through mitzvot, beautiful through deeds of loving kindness, . . . through prayer, through reciting the “Shema,” through the mezuzah, through phylacteries, through Sukkah and lulav and etrog… [Midrash Song of Songs Rabbah 1.15].\nThere seems to be reciprocity of beauty through the agency of mitzvot: the Jew becomes beautiful as he/she performs a mitzvah. “But, conversely, Israel ‘beautifies’ God by performing the commandments in the most ‘beautiful’ manner…”\nThere are many ways to apply the principle of hiddur mitzvah. For example, one might choose to observe the mitzvah of kindling Hanukkah lights with a cheap, stamped tin Hanukkiyah (Hanukkah menorah) or one might make an effort to build one by hand or to buy a beautiful one. Some families might prefer an oil-burning Hanukkiyah, rather than one that uses the standard candles, in order to relate their observance of the mitzvah more closely to the times of the Maccabees, Certainly the mitzvah of lighting Hanukkah candles is fulfilled with any kind of Hanukkiyah, but by applying the principle of hiddur mitzvah, one enriches both the mitzvah and him/herself.\nVarious companies distribute free Haggadot (the plural of Haggadah, the Passover seder guide) to their customers before Passover. These Haggadot generally contain the entire traditional text and of course may be used at the family seder. But a family who is motivated by the concept of hiddur mitzvah will want to use one of the beautifully edited and illustrated Haggadot readily available today. Similarly, beautiful matzah covers, seder plates, and Kiddush cups should be used. These may be family heirlooms, or ones created by contemporary artists, or ones designed and executed by the children in religious school. The whole celebration is enriched when care is taken in the selection or creation of ceremonial objects.\nHiddur mitzvah means taking the time and making an effort to create or acquire the most beautiful ceremonial objects possible in order to enrich the religious observance with aesthetic dimension.\nPronounced: ETT-rahg, Origin: Hebrew, a citron, or large yellow citrus fruit that is one of four species (the others are willow, myrtle and palm) shaken together as a ritual during the holiday of Sukkot.\nPronounced: hahv-DAHL-uh, Origin: Hebrew, From the root for “to separate,” the ceremony marking the end of Shabbat and the beginning of the week.\nPronounced: KID-ush, Origin: Hebrew, literally holiness, the blessing said over wine or grape juice to sanctify Shabbat and holiday.\nPronounced: LOO-lahv (oo as in boo), Origin: Hebrew, a bundle of branches representing three species — willow, myrtle and palm — which are shaken together with the etrog on Sukkot.\nPronounced: muh-NOHR-uh, Origin: Hebrew, a lamp or candelabra, often used to refer to the Hanukkah menorah, or Hanukkiah.\nPronounced: MIDD-rash, Origin: Hebrew, the process of interpretation by which the rabbis filled in “gaps” found in the Torah.\nPronounced: MITZ-vuh or meetz-VAH, Origin: Hebrew, commandment, also used to mean good deed.\nPronounced: SAY-der, Origin: Hebrew, literally “order”; usually used to describe the ceremonial meal and telling of the Passover story on the first two nights of Passover. (In Israel, Jews have a seder only on the first night of Passover.)\nPronounced: SOO-kah (oo as in book) or sue-KAH, Origin: Hebrew, the temporary hut built during the Harvest holiday of Sukkot.\nPronounced: TALL-mud, Origin: Hebrew, the set of teachings and commentaries on the Torah that form the basis for Jewish law. Comprised of the Mishnah and the Gemara, it contains the opinions of thousands of rabbis from different periods in Jewish history.\nPronunced: TORE-uh, Origin: Hebrew, the Five Books of Moses.","In part two of this three-part series entitled, Yom Kippur: Unity, we will examine artifacts relating to the shofar and Torah. We will see how they display the Jewish people’s close connection to God, as well as the unity seen among God’s people.\nSymbols Found in Archaeology and History:\nIn part one of this three-part series, we looked at the Holy Day known as Yom Kippur, as well as symbols related to it. The two most commonly used symbols for Yom Kippur found in the archaeological and historical record that we will examine being, the shofar, and the Torah…\nThe importance of the shofar in Jewish culture in the land of Israel is seen not only in artifacts found within Jerusalem—such as the Temple Mount parapet stone examined in part one of this series—but also, throughout various synagogues dotting Israel. The image of the shofar having been used to adorn Torah scrolls, walls, and even floors in the form of mosaics, as seen below… is a constant reminder to the Rabbi and all who entered of the importance of the shofar in terms of holiness and as a reminder of man’s connection with God. For\nwhen God breathed life into man the soul was brought into being, and the symbolic cry of that moment is uttered through the breath of man sounding the shofar. This connection with God and creation is one of the many reasons we see the shofar throughout the Jewish archaeological record.\nYet, while Israel has the oldest and largest collection of archaeological finds originating from the Jewish people, going easily back to the First Temple period, other countries around the world have also felt the influx of Jewish artifacts over the centuries that have passed.\nThe burial plaque shown below originates from Venosa, Italy, a city over 1,000 miles from Jerusalem. Yet, in such a distant land we find evidence of a Jewish population—likely due to extended Roman occupation of Israel which culminated in the destruction of the Second Temple. However, not only was there a Jewish population in Italy, there was a Jewish population that, despite the trials they had faced, we're still focused on God. Specifically, we find, that in the case of this burial plaque, there is a shofar, menorah, and palm—Holy symbols of faith, love, and loyalty to God. Symbols important enough for the Jewish population to use not only in life but also in death.\nStill, even in years not so long past, the Jewish people have left their mark upon the world, not only by what they have done but by the items they have left behind. The shofar pictured above was made in 1943 by Moshe Winterter (Ben-Dov); yet, why is such a relatively new artifact important?\nWell, the shofar was crafted by Moshe Winterter (Ben-Dov) in a forced labor camp in Poland, known as Skarżysko-Kamienna. Moshe, in 1943, was approached by Rabbi Yitzhak Finkler to make the shofar for the upcoming new year. At first, Moshe refused… to be caught would mean death. Eventually, he agreed, and by Rosh Hashanah, the shofar was completed, but only after many attempts to bribe a guard to bring a ram’s horn suitable for the Holy task it was to perform. The Jewish inmates gathered together to hear the shofar blast—a sound most Holy.\nWhile the shofar is one of the more common symbols of Yom Kippur and is often found in the archaeological record, the Torah is just as important, if not more so. The Torah is God’s Word—it is law, it is life, and it guides the lives of those who follow it. God’s Word is the instruction for the observance, not only of the Ten Commandments but of the Lord’s Feasts and holy days such as Yom Kippur.\nFor these reasons and more, the Torah is commonly found depicted on everything from Temple items to Jewish cemetery carvings, such as the one shown below. This tattered and virtually worthless—monetarily—stone, comes from a Jewish gravesite in Turek, Poland, that had presumably been standing since the late 1800’s with only minor wear. A number of tombstones such as this one from the desecrated\nTurek Jewish cemetery was broken and used as paving stones for the courtyard of the local Third Reich headquarters, ‘Organization Todt.’\nThis piece of the tombstone installed in the late 1800’s indicated that the person buried there was a reader and lover of Torah; the Torah having traversed thousands of miles to be read in Poland by Jews who loved God. The importance of the Torah is evident by the reverent display for one who loved and held regard for God’s Word.\n“Hear the word of the Lord, O house of Jacob and all the families of the house of Israel.”—Jeremiah 2:4\nStill, the Torah is not mere carven images. No, many are made of parchment and ink—one example is shown right. This Torah was desecrated by the Nazi’s before the end of 1944, along with the synagogue it resided in. The Jewish community would have, according to their reverence for the Word, always kept the Torah protected by a cloth covering when not in use and placed it within a cabinet—ark—especially made for it. They would never have allowed God’s Word to be misused had they the power to stop it. God’s Word being loved by the Jewish people the world over.\nSometimes, as shown above, right, Torah scrolls were simply stolen for research by the Nazis into ‘The Jewish Question.’ Other times, as shown below, God’s Word was misused in an industry—as lining, purses, wallets, toys, insulation, etc. The Torah, which was loved and never disrespected by Abraham’s children, was continually misused by those who did not understand the importance of the Word nor the Jewish roots of the faith.\nYet, while many artifacts are seemingly humble, others are not. Such as the golden medallion found at the southern wall of the Temple Mount in Jerusalem…\nIn the final part of this three-part series entitled, Yom Kippur: Unity, we will continue to examine artifacts to gain a fuller picture of Yom Kippur and the Jewish roots of the faith. We will discover how Yom Kippur brings unity to the Jewish community. And finally, we will discover how Gentile Believers can benefit from the lessons our Jewish brothers and sisters have taught and continue to teach us… as well as the benefits of the Jewish and Christian faiths being brought together."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:c367f35f-c7d9-45a3-baf2-ab2073861776>","<urn:uuid:3f28b74a-56d7-4a06-bb7a-ee6174130f3c>"],"error":null}
{"question":"What was the purpose and design of the Arctic schooner Bowdoin built in 1921?","answer":"The Bowdoin was an 88 ft. gaff rigged two-masted schooner specifically designed by William Hand to withstand pack ice on northern voyages. Built at Hodgdon Brothers Shipyard in East Boothbay, Maine, it was the only auxiliary schooner ever built in the US specifically for Arctic exploration. Between 1921 and 1954, it made 26 voyages to the Arctic, logging more than 200,000 miles with over 300 crewmembers who gathered information on Arctic ornithology, biology, anthropology, geology, meteorology, and oceanography.","context":["Luther Holbrook Collection\n[Luther G. Holbrook--home movies], 2269\nCreator(s)Luther G. Holbrook\nCredit: Luther Holbrook Collection, Northeast Historic Film. Crew on board schooner Bowdoin off the shores of Labrador, summer, 1934.\nCredit: Luther Holbrook Collection, Northeast Historic Film. Eskimo skins a seal, Labrador, 1934.\nPrimary Format and Extent\nfilm (1,750 ft.) : si., b&w ; 16 mm.\nCollection Date Range\nThe Luther Holbrook Collection contains 4 reels of 16 mm. film shot by Luther Holbrook. Footage depicts the 1934 voyage of the schooner Bowdoin from Portland, Maine, to Labrador and Newfoundland, Canada, offering views of coastal Maine, lighthouses, ice floes, ice bergs, fishing, sled dogs and wildlife. On board footage depicts the crew at work, sea birds, and the landscape and seascapes as the crew traveled. Highlights of the collection include footage of Admiral Donald MacMillan in Nain, Labrador, the Inuit village where he would later fund the MacMillan-Moravian School for the Inuit; and Bobbie, guide to the scientific party left for ten days in the Button Islands, hunting and skinning seals. Note: The film in this collection has some severe emulsion damage. Viewing can be difficult at times, but content is not diminished.\nLuther Gardner Holbrook (1912-1979) was born in Walpole, MA, and graduated from Bowdoin College in 1934. He obtained his master's degree in business from Harvard in 1936. After becoming assistant dean at Harvard Business School, he joined T. Mellon & Sons in Pittsburgh, where he eventually became a vice president and governor. He also served as a vice president of Richard K. Mellon and Sons, serving as an advisor to the Mellon family until his death. He served on many community and corporate boards both in Pittsburgh and the Blue Hill, Maine, area, where he and his wife had a summer home. In the summer of 1934 Holbrook joined other recent Bowdoin graduates on the Arctic summer cruise on the Bowdoin with Admiral Donald Macmillan. To learn more about that cruise, see \"The Arctic Schooner Bowdoin: A Biography\" by Virginia Thorndike, a chapter of which is devoted to the 1934 cruise (in donor file). WorldCat On this 4,500 mile three month cruise to the Gulf of St. Lawrence, Labrador and Baffin Island, Macmillan discovered what is now named on nautical charts Bowdoin Harbor in Northern Labrador. The main ornithological goal was study of the group of islands in the middle of the Hudson Strait known as \"The Buttons\" to the Eskimos, the Putjak or \"Stepping Stones.\" Study of plants was at Cape Mugford, Labrador. Dr. Alfred Gross of Bowdoin College was the ornithologist, and Dr. David Potter of Clark University was the botanist on board. Schooner Bowdoin is an 88 ft. gaff rigged two-masted schooner that was designed by William Hand and launched in 1921 at Hodgdon Brothers Shipyard, East Boothbay, Maine. She was built to withstand pack ice on northern voyages. Bowdoin is the only auxiliary schooner ever built in the US specifically for Arctic exploration and the only surviving historic vessel in the US associated with Arctic exploration (except the nuclear submarine Nautilus). She made 26 voyages to the Arctic between 1921 and 1954, and served as a US Navy patrol ship in World War II. Except for the time as a US Navy ship, she was captained by Adm. Donald Macmillan until he retired in 1954. Bowdoin logged more than 200,000 miles, with more than 300 crewmembers who gathered information on Arctic ornithology, biology, anthropology, geology, meteorology, and oceanography. Thereafter it was housed at Mystic Seaport, then restored by the Schooner Bowdoin Association, and sailed out of Camden, Maine, as a charter boat. She was turned over to the Maine Maritime Academy in Castine in 1989. She was designated a National Historic Landmark in 1989 and has since sailed to Labrador, Greenland, Newfoundland and other Arctic sites as a training vessel for the Maine Maritime Academy. Holbrook Collection resources The Arctic Schooner Bowdoin: A Biography, by Virginia Thorndike, 1995 WorldCat Arctic Odyssey: The Life of Rear Admiral Donald B. MacMillan, by Everett S. Allen, 1962 WorldCat The Bowdoin College Peary MacMillan Arctic Museum and Arctic Studies Center houses the Donald MacMillan collection of over 5,000 black and white photographs, as well as glass lantern and 35 mm. slides, motion picture films, and objects he collected in Greenland, Labrador, and Baffin Island. More information can be found at\nSpecial Collections and Archives, at the Hawthorne-Longfellow Library at Bowdoin College houses the MacMillan papers, as well as journals and diaries of some participants of various expeditions.\nAn online exhibit using photographs of the Bowdoin (including one of the 1934 expedition) posted by the Peary Macmillan Arctic Museum and Arctic Studies Center can be found at\nFacts about the history of the Schooner Bowdoin can be found at: and\nThere is an obituary of Holbrook from the Bowdoin College magazine in the donor file.\nNortheast Historic Film\nThe Collection is open for research.\nCondition Governing Reproduction and Use\nAuthorization to reuse and/or reproduce must be obtained from Northeast Historic Film. See http://www.oldfilm.org/research for more information.\nEncoded archival description\nItems in this collection: 4\nShowing 1 - 4 of 4:\n1) [Luther G. Holbrook—home movies] Reel 1\nViews of the schooner Bowdoin tied to the dock in Portland, Maine, June 16, 1934. Many visitors are on board, and the dock is crowded with visitors and family members of the crew on de...more\n2) [Luther G. Holbrook—home movies] Reel 2\nViews of a rocky shoreline with wave crashing over the rocks. In Battle Harbour, Newfoundland and Labrador, a small iceberg has been towed in, and pieces are hauled up onto the dock wi...more\n3) [Luther G. Holbrook—home movies] Reel 3\nView of Inuit at the wheel of the Bowdoin (perhaps the same as seen in Reel 2). Views of a tent camp with Inuit families and dogs occupying the tents on a rocky shoreline. Dogs are s...more\nPost new comment"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:8c4972d9-3380-460b-8817-26ee17071b61>"],"error":null}
{"question":"How does the German education system integrate both practical and theoretical learning pathways from secondary education through higher education, and what flexibility exists for students to switch between these paths?","answer":"The German education system offers multiple integrated pathways combining practical and theoretical learning. After primary school, students can attend different secondary schools: Hauptschule (until grade 9), Realschule (until grade 10), or Gymnasium (until grade 12). Hauptschule graduates can pursue vocational apprenticeships, while Realschule graduates can either continue to Oberschule for Abitur or start vocational training. The Gesamtschule allows students to switch between these tracks based on improving grades. In higher education, students can choose between traditional universities for academic studies or Fachhochschulen for practically-oriented courses in fields like Engineering and Economics. Additionally, students can combine university studies with practical training through the 'duales Studium' program, integrating company-based training with academic studies.","context":["Vocational training system in Rhineland-Palatinate\nDo you want to complete vocational training? In Germany, there is a special way to do so: the dual vocational training (duale Ausbildung). Nationwide, there are currently around 330 recognised professions providing vocational training in fields of skilled crafts and trades, manufacturing, services, agriculture or the public service sector. Additionally, there are training occupations to become a doctor’s assistant, pharmacy assistant, a lawyer’s- or tax advisor’s assitant. The dual training system is not only a perfect starting point for a successful career but also offers many different opportunities for further development.\nWhat is dual vocational training?\nIn a dual vocational training system, practice-orientated content taught at the company and school content take turns. During your training you will be employed at a company from the very beginning and will familiarize yourself with the operational practice. At the same time, you gain theoretical knowledge at vocational school that you will put into practice when working. During your training, you will receive a salary (“training allowance”) from your company from the day you start working. The professions taught meet high-quality requirements as they follow nationwide standards.\nHow does dual vocational training work?\nThe dual vocational training takes place at two locations: at the training company and at vocational school. You are an employee of your training company throughout the period of the training. The training usually takes between two and a half and three years, depending on the profession.\nThe practical part of the dual vocational training is predominant: You spend around two thirds of your training’s total at the company you are trained at. Depending on the company’s size, you will pass through various departments. Hence, you will receive comprehensive insight of the company and be able to work on different activities and tasks. The in-company part of your training is regulated by the so-called training regulations (“Ausbildungsordnung”). It determines how your training is structured in terms of content and time.\nYou receive theoretical lessons at the vocational school. Lessons take place either once or twice a week or through block teaching. Block teaching is a form of teaching requiring you to be at school several weeks in a row. During this time, you will also take exams. Vocational school will teach you general as well as job-related contents in German, Physical Education or Economic and Social studies. The various subjects are taught according to the syllabus applying to your field of training.\nAfter the first half of the vocational training, you must pass an intermediate examination to show what you have learned at school and how you put it into practice at the company. The vocational training is completed by passing a final exam held in German language.\nVideo: Dual vocational training\nSpecial types of vocational training\nIn some training professions that do not count as dual training occupations, you spend less time at the company than in others. Among others, this applies to the fields of foreign languages as well as health and social services, especially nursing. In these professions, both theory and practice are taught at specialised vocational schools. The practical application takes place in longer periods within businesses or care facilities. Depending on the profession learned, school training takes one to three years and is provided at state or private schools. Some professions may require a specific school-leaving certificate. At a private vocational school, you generally must pay a tuition fee. You usually do not receive any payments during these types of trainings. However, this does not apply to training occupations in the field of healthcare. As you will complete longer practical periods at hospitals or nursing homes, you will receive a salary during your training there.\nStudies accompanied by vocational training (“Duales Studium”)\nYou can also combine the dual vocational training with a course of studies at university in Rhineland-Palatinate. In this case, you would complete your university studies alongside the training or integrate practical periods in a company into the course. You can find information on dual studies in Rhineland-Palatinate on the website \"Duale Hochschule\".","WHY STUDY IN GERMANY\nEducation system in Germany\nFirst and Secondary Education\nCompulsory education in Germany is from the age of 6 to 15 years. School children are in primary school (Grundschule) for four years in most of the federal states, apart from Berlin and Brandenburg where primary school finishes after grade 6. There are different types of secondary schools, starting with grade 5 or 7 and finishing with grade 10 or 12 with different school leaving certificates.\nThe Hauptschule (lower secondary school) is till grade 9 and with the certificate for taking a vocational apprenticeship. Upper secondary school (Realschule) completes with grade 10, students can then chose to continue with the Oberschule and take the Abitur (A-Level/baccalaureate) or they start a vocational apprenticeship. At a Gymnasium, students finish after grade 12 (until recently, it used to be after grade 13) with their Abitur which is the entry qualification for higher academic education at universities or colleges. The Fachabitur is a special version of the Abitur, taking more practical subjects and already qualifying oneself in a practical field, for example social studies. Students with a Fachabitur can study at colleges and polytechnics, but not at universities.\nThere is also a mixed version, the Gesamtschule (secondary state school) which includes all three school types, depending on the development of the student's qualifications. So, a student with improving grades at the end of a school year can change from Hauptschule to Realschule or to Gymnasium. The education plan can vary between the Ministries of Education of each federal state, but generally, secondary education is compulsory and free.\nThere are also different types of higher education institutions divided into: universities (Universitäten, Technische Hochschulen/Technische Universitäten, Pädagogische Hochschulen), and colleges of art and music (Kunsthochschulen and Musikhochschulen), and Fachhochschulen (colleges of applied sciences). All these institutions are undergoing a reorganisation since the early 1990s. With the introduction of the internationally comparable Bachelor, Master and Ph.D. programmes, the qualification of a new generation of academics and scientific study is the focus of future development.\nMoreover, the institutions of higher education are made more efficient by granting them further freedom in organisational matters and the chance to shape an individual profile and evoking more competition. As the primary and secondary education system, the higher education system is also subject to decisions and programmes of the governments of the federal states.\nFachhochschulen (colleges of applied sciences), offer a range of practically oriented study courses such as Engineering, Economics, Social Work, Public and Legal Administration and Health and Therapy. A Diplom degree can be achieved after 8 semesters of studying and a finally successful examination. Students then get the title of Diplom-Ingenieur (FH). The initials \"FH\" are added to the Diplom degrees pointing to the diploma of a Fachhochschule.\nUniversities in Germany\nUndergraduate studies were until recently the basic studies (Grundstudium) of a Diplom or Magister programme, generally taking four semesters (2 academic years) and finishing with an intermediate examination (Diplom-Vorprüfung, Zwischenprüfung). Students are then enabled to follow their studies in the second stage of Hauptstudium, taking another 4 semesters with the 5th being the preparatory semester for taking the final exams, the Diplomprüfung or the Magisterprüfung or State Exam (for Law and subjects for becoming a teacher).\nThe new graduation system of the Bachelor as an undergraduate program instead of the basic studies program has already been introduced in Germany with the aim of achieving an internationally competitive degree and studying in a condensed, shortened time of 3 years.\nThe advanced studies (Hauptstudium) form the second stage to the final examination, takes five semesters at least. The final exams still are the Diplom and Magister, but they are slowly replaced by the Master degree. The Magister study involves either two equally weighed major subjects or a mixture of one major and two minor subjects. According to the new graduation system, after having completed the Bachelor's studies, a Master of Arts/Science is the successfully achieved title after two years of studying.\nA Doctoral degree can only be achieved at universities. The time of doctoral studies, the Promotion, has duration of 2 to 4 years of independent scientific research, the public presentation and defence of the thesis. The Diplom/Erstes Staatsexamen/Magister Artium/Master of Arts/Science are the preconditions for taking Doctoral studies.\nThe closing dates for applications to the International offices are usually July 15 for the following winter semester and January 15 for the following summer semester. If your application is late even by one day, it is not going to be processed.\nAs soon as you have received your notification of admission and passed the language test, you need to register at your chosen university or college. Please direct your queries to the Registrar's office (studentensekretariat) in good time so as to wrap up the formalities and paperwork long before the session is due to start.\nYour first port of call upon arrival in Germany must necessarily be the International office which will provide you with all the basic information you need to arrange the initial days of your stay in that country. Subsequently you must get yourself registered at the Resident Registration office and finally with the Alien'sRegistration Authority.undefined\nWe investigate the relationship between remittances and migrants' education both theoretically and empirically, using original bilateral remittance data. At a theoretical level we lay out a model of remittances interacting migrants' human capital with two dimensions of immigration policy: restrictiveness, and selectivity. The model predicts that the relationship between remittances and migrants' education is ambiguous and depends on the immigration policy conducted at destination. The effect of education is more likely to be positive when the immigration policy is more restrictive and less skill-selective. These predictions are then tested empirically using bilateral remittance and migration data and proxy measures for the restrictiveness and selectivity of immigration policies at destination. The results strongly support the theoretical analysis, suggesting that immigration policies determine the sign and magnitude of the relationship between remittances and migrants' education."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:4fb1d995-f4c0-4d17-8e3a-609affd67d5b>","<urn:uuid:d65c5c70-6d94-48a8-814b-93d133c166d6>"],"error":null}
{"question":"How has drug development and regulation evolved historically, and what are the current challenges in managing pharmaceutical contamination in water sources?","answer":"Drug development has evolved significantly since the early 1900s, when only a few substances like ether, morphine, and digitalis were widely used. The field expanded particularly after World War II with the development of antibiotics, synthetic drugs, and various therapeutic agents. Drug regulation began with the Pure Food and Drugs Act of 1906, leading to more stringent controls through the Food, Drug, and Cosmetic Act of 1938. Meanwhile, pharmaceutical contamination has emerged as a modern challenge, with wastewater from pharmaceutical facilities being highly polluted due to organic pollutants. Current regulations vary globally - some countries require environmental impact assessments before drug production, while others, like India and China, have less stringent controls, resulting in higher levels of pharmaceutical contamination in their waterways.","context":["drugs, substances used in medicine either externally or internally for curing, alleviating, or preventing a disease or deficiency. At the turn of the century only a few medically effective substances were widely used scientifically, among them ether, morphine, digitalis, diphtheria antitoxin, smallpox vaccine, iron, quinine, iodine, alcohol, and mercury. Since then, and particularly since World War II, many important new drugs have been developed, making chemotherapy an important part of medical practice. Such drugs include the antibiotics, which act against bacteria and fungi; quinacrine and other synthetics that act against malaria and other parasitic infections; cardiovascular drugs, including beta-blockers and ACE inhibitors; diuretics, which increase the rate of urine flow; whole blood, plasma, and blood derivatives; anticoagulants such as heparin and coumarin; various smooth-muscle relaxants such as papaverine, used in heart and vascular diseases; smooth-muscle stimulants; immunologic agents, which protect against many diseases and allergenic substances; hormones such as thyroxine, insulin, and estrogen and other sex hormones; psychotherapeutics such as antianxiety drugs and antidepressant drugs; cortisone and synthetic corticosteroid drugs used in treating inflammatory diseases such as arthritis; vitamins and dietary minerals; antidotes for poisons; and various drugs that act as stimulants or depressants on all or various parts of the nervous system, including analgesics, narcotics, amphetamines, and barbiturates (see also anesthesia; psychopharmacology; hallucinogenic drug).\nSee also drug resistance; drug poisoning; drug addiction and drug abuse.\nSources of Drugs\nDrugs are obtained from many sources. Many inorganic materials, such as metals, are chemotherapeutic; hormones, alkaloids, vaccines, and antibiotics come from living organisms; and other drugs are synthetic or semisynthetic. Synthetics are often more effective and less toxic than the naturally obtained substances and are easier to prepare in standardized units. The techniques of genetic engineering are being applied to the production of drugs, and genetically engineered livestock that incorporate human genes are being developed for the production of scarce human enzymes and other proteins (see pharming).\nPharmacopoeia and Drug Safeguards\nStandards for drugs and tests for their identity, quality, and purity are given in the U.S. pharmacopoeia, first published in 1820 and at first revised every 10 years, later every 5 years. The British publish a similar pharmacopoeia. The National Formulary published by the American Pharmaceutical Association gives the composition, description, method of preparation, and dosage for drugs; the Physician's Desk Reference is a privately published compilation of information supplied by drug companies about their drug products, published yearly. The scientific study of drugs, their actions and effects, is pharmacology.\nLegislation to safeguard drug purchasers began in the United States with the Pure Food and Drugs Act of 1906; this was superseded by the more inclusive and more stringent federal Food, Drug, and Cosmetic Act of 1938. Such laws are enforced by the Food and Drug Administration. The 1962 Kefauver-Harris amendments to the Food, Drug, and Cosmetic Act increased the authority of the Food and Drug Administration to regulate testing and marketing of new drugs. There are two marketing classes of drugs: ethical drugs, for which prescriptions are needed, and proprietary drugs, which are sold over the counter without prescription. Many of the latter, such as mouthwashes, gargles, and cold preparations, are only slightly, if at all, effective in curing ailments.\nSee B. Barber, Drugs and Society (1967); C. B. Clayman, ed., American Medical Association Guide to Prescription and Over-the-Counter Drugs (1988); A. Burger, Drugs and People: Medications, Their History and Origins, and the Way They Act (rev. 1988); United States Pharmacopeial Staff, The Complete Drug Reference (1995).\n\"drugs.\" The Columbia Encyclopedia, 6th ed.. . Encyclopedia.com. (November 17, 2017). http://www.encyclopedia.com/reference/encyclopedias-almanacs-transcripts-and-maps/drugs\n\"drugs.\" The Columbia Encyclopedia, 6th ed.. . Retrieved November 17, 2017 from Encyclopedia.com: http://www.encyclopedia.com/reference/encyclopedias-almanacs-transcripts-and-maps/drugs\nEncyclopedia.com gives you the ability to cite reference entries and articles according to common styles from the Modern Language Association (MLA), The Chicago Manual of Style, and the American Psychological Association (APA).\nWithin the “Cite this article” tool, pick a style to see how all available information looks when formatted according to that style. Then, copy and paste the text into your bibliography or works cited list.\nBecause each style has its own formatting nuances that evolve over time and not all information is available for every reference entry or article, Encyclopedia.com cannot guarantee each citation it generates. Therefore, it’s best to use Encyclopedia.com citations as a starting point before checking the style against your school or publication’s requirements and the most-recent information available at these sites:\nModern Language Association\nThe Chicago Manual of Style\nAmerican Psychological Association\n- Most online reference entries and articles do not have page numbers. Therefore, that information is unavailable for most Encyclopedia.com content. However, the date of retrieval is often important. Refer to each style’s convention regarding the best way to format page numbers and retrieval dates.\n- In addition to the MLA, Chicago, and APA styles, your school, university, publication, or institution may have its own requirements for citations. Therefore, be sure to refer to those guidelines when editing your bibliography or works cited list.","The growing rate of pharmaceutical waste has become a large environmental and public health concern in the United States and around the globe. There has not only been an increase in prescription drug usage, but also a lack of serious regulation on the matter. The project that I wish to conduct will identify the most commonly found synthetic hormones in waterway systems, and identify how to properly filter these hormones out of waterways to ensure the safety of both humans and aquatic life. I wish to inform the public on the risks of pharmaceutical dumping into various waterways, and how it can affect a multitude of aspects of our environment and health. I find the topic fascinating because there seems to be a lax attitude when it comes to properly disposing of pharmaceuticals. Working in the pharmaceutical industry has made me become more curious on what happens to the drugs that I supply to consumers when they leave my hands. I feel as though I am an intermediate between the production of pharmaceuticals and the disposal of them, and I wish to know what occurs in these steps in more detail. Specifically focusing on the sex hormone analogs that are disposed of will allow me to analyze the risks of disposal processes from start to finish.\nIf you need assistance with writing your essay, our professional essay writing service is here to help!Essay Writing Service\nThe presence of hormones in surface and drinking water has become a growing concern as of late. These compounds are first released to the aquatic environment from wastewater treatment plants, and have been found in various samples of water sources. (Lin & Reinhard, 2004). Different sources of research have demonstrated the effects of these contaminants, and how they are specifically detrimental to aquatic life. Although we have a slight understanding on the effects of aquatic life, we still do not know how these mass-produced sex hormones will affect human life. The use of synthetic hormones has become popularized around the globe, and have become essential to so many individuals living today. A progression in chemistry techniques, specifically in analytical chemistry have provided scientists with the tools to analyze different compounds at smaller concentrations in water, which assists us in understanding the severity of the issue (Kuster et al., 2008). The image below shows the sources and fate of pharmaceutical substances in the environment. As shown below, there are many different sources of drug waste that come from humans, whether the source be from a hospital, a farm, or a home. We create this waste in so many different ways, and this is why I believe it is so important to take these matters more seriously before the issue becomes uncontrollable in its interference with wildlife.\nEnvironmental estrogens are a form of endocrine disrupting chemicals and can affect the function of the endocrine systemin many different animal species. Change in function can have a large (possibly detrimental) influence on growth, development, and reproduction (Al-Ansari et al., 2010). Estrogens that have been flushed into waterways are shown to cause many atypical biological responses in many aquatic species. Various estrogens are now known to cause disruption of the endocrine systems of fish, and can actually alter their reproductive systems drastically (Jarošová, 2014).Aquatic species are not the only individuals affected by this issue, as bioassays have shown that the estrogenic, androgenic, and progestagenic trigger levels can be determined through testing, and human health has to now be considered as well (Brand et al., 2013). These calculated values can allow scientists to assess if the risk to human health is large enough to take severe action, or if additional examination is required to determine the steps that we should take to solve the issue. The topic of pharmaceutical contamination is a difficult topic to discuss because it is a problem that has many complexities involved in it. There are a lot of factors that contribute to the issue, and there is a lack of regulation in some of these factors that will be discussed (Wu & Janssen, 2011).\nA study which was conducted on the assessment of the amounts of estrogens in drinking water observed the normal intake in children and adults, and also observed the intake of estrogens in drinking water to assess if this additional level vastly higher or lower than the dietary intake (Caldwell et al., 2010). In short, the study concluded that the total estrogens in water are not causing adverse effects in US populations, for now. We cannot completely predict the future disposal of estrogens and other hormones in water systems, so an accurate estimate for the impact level that they may have on humansis nearly impossible at this time. In pharmaceutical industrial environments, much of the wastewater produced is from cleaning the different types of equipment, and although a minuscule amount of wastewater is produced in these processes, it is extremely polluted due to the high amounts of organic pollutants being utilized in the facilities (Ashfaq & Khatoon, 2014). In my project, I would like to identify and explain several different methods of wastewater treatment and reuse. There has not been a single type of technology that can fully remove pharmaceutical residue from wastewater, and this is another issue that must be thoroughly explained. (Gadipelly, 2014). After analyzing multiple studies, I will find the best recommendations that prove to be useful for the treatment of water that has been tainted with pharmaceutical waste. Specifically, I will discuss the elimination of steroidal sex hormones by water treatment. One type of promising treatment for pharmaceutical wastewater is nanofiltration. It is a promising technique used for water treatment, because it separates micropollutants and ions from streams (Bodzek & Dudziak, 2006). Nanofiltration can remove almost all estrogens in wastewater, leaving only a small percentage behind.\nOverall, the estrogenic activity in water systems is still low. In both India and China there are large amounts of drugs found in waterways, and these include both beta blockers and antibiotics. The regulations governing India and China are low in comparison to other places around the world. Some countries must assess the possible environmental damage that a specific drug will make on the environment before mass production occurs. After this assessment, if a drug proves to not be extremely damaging to the environment, it will enter the market. (Corcoran, Winter, & Tyler, 2010). If we ever want to change the fate of the world’s waterways, we must take the regulation of pharmaceutical waste more seriously. The dumping of waste in waterways causes detrimental changes in biological responses in aquatic life forms, and must be addressed properly before it is too late. This study that I wish to conduct will look at sex hormones and their effect on aquatic life, while also viewing the issue at a higher, human-based level as well. Not only do I wish to further understand the severity of the issue, but I also hope to identify the specific methods in which we can decrease these hormonal levels in waterways.\n- Al-Ansari, A. M., Saleem, A., Kimpe, L. E., Sherry, J. P., McMaster, M. E., Trudeau, V. L., & Blais, J. M. (2010). Bioaccumulation of the pharmaceutical 17α-ethinylestradiol in shorthead redhorse suckers (Moxostoma macrolepidotum) from the St. Clair River, Canada. Environmental Pollution, 158(8), 2566-2571.\n- Ashfaq, A., & Khatoon, A. (2014). Evaluating toxicological effects, pollution control and wastewater management in pharmaceutical industry. Int J Curr Res Aca Rev, 2, 54-65.\n- Bodzek, M., & Dudziak, M. (2006). Elimination of steroidal sex hormones by conventional water treatment and membrane processes. Desalination, 198(1), 24-32.\n- Brand, W., de Jongh, C. M., van der Linden, S. C., Mennes, W., Puijker, L. M., van Leeuwen, C. J., ... & Heringa, M. B. (2013). Trigger values for investigation of hormonal activity in drinking water and its sources using CALUX bioassays. Environment international, 55, 109-118.\n- Caldwell, D. J., Mastrocco, F., Nowak, E., Johnston, J., Yekel, H., Pfeiffer, D., ... & Anderson, P. D. (2010). An assessment of potential exposure and risk from estrogens in drinking water. Environmental health perspectives, 118(3), 338-344.\n- Corcoran, J., Winter, M. J., & Tyler, C. R. (2010). Pharmaceuticals in the aquatic environment: a critical review of the evidence for health effects in fish. Critical reviews in toxicology, 40(4), 287-304.\n- Creusot, N., Aït-Aïssa, S., Tapie, N., Pardon, P., Brion, F., Sanchez, W., ... & Budzinski, H. (2014). Identification of synthetic steroids in river water downstream from pharmaceutical manufacture discharges based on a bioanalytical approach and passive sampling. Environmental science & technology, 48(7), 3649-3657.\n- Gadipelly, C., Pérez-González, A., Yadav, G. D., Ortiz, I., Ibáñez, R., Rathod, V. K., & Marathe, K. V. (2014). Pharmaceutical industry wastewater: review of the technologies for water treatment and reuse. Industrial & Engineering Chemistry Research, 53(29), 11571-11592.\n- Jarošová, B., Bláha, L., Giesy, J. P., & Hilscherová, K. (2014). What level of estrogenic activity determined by in vitro assays in municipal waste waters can be considered as safe?. Environment international, 64, 98-109.\n- Kuster, M., de Alda, M. J. L., Hernando, M. D., Petrovic, M., Martín-Alonso, J., & Barceló, D. (2008). Analysis and occurrence of pharmaceuticals, estrogens, progestogens and polar pesticides in sewage treatment plant effluents, river water and drinking water in the Llobregat river basin (Barcelona, Spain). Journal of hydrology, 358(1-2), 112-123.\n- Lin, A. Y. C., & Reinhard, M. (2005). Photodegradation of common environmental pharmaceuticals and estrogens in river water. Environmental Toxicology and Chemistry: An International Journal, 24(6), 1303-1309.\n- Lipari, J. M. (1983). U.S. Patent No. 4,383,992. Washington, DC: U.S. Patent and Trademark Office.\n- Nikolaou, Anastasia & Meric, Sureyya & Fatta, Despo. (2007). Occurrence patterns of pharmaceuticals in water and wastewater environments. Analytical and bioanalytical chemistry. 387. 1225-34. 10.1007/s00216-006-1035-8.\n- Wu, M., & Janssen, S. (2011). Dosed without prescription: A framework for preventing pharmaceutical contamination of our nation’s drinking water.\nCite This Work\nTo export a reference to this article please select a referencing stye below:\nRelated ServicesView all\nDMCA / Removal Request\nIf you are the original writer of this essay and no longer wish to have your work published on UKEssays.com then please:"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:2d072704-d1ab-48ec-9ffa-f94dbdd0c75e>","<urn:uuid:5fbc7ff6-51bf-4c31-892f-d1e4e25ee2a2>"],"error":null}
{"question":"As someone passionate about environmental certification, which zoo was certified as carbon neutral first: Cheyenne Mountain Zoo or Wellington Zoo?","answer":"Wellington Zoo was certified as Toitū carbonzero in 2012. While Cheyenne Mountain Zoo has multiple environmental programs and initiatives, there is no mention of carbon neutrality certification. Therefore, Wellington Zoo was the first of these two to achieve carbon neutral certification.","context":["For the Animals. For the Earth.\nIn addition to our commitment to the exhibition and conservation of endangered animal species, Cheyenne Mountain Zoo also strives to be a green business. That’s why we have multiple programs for onsite recycling and conservation of energy and natural resources.\nNot only do we adhere to tight conservation standards here at our home, but we also try to help you do the same by providing comprehensive conservation information and resources. It is our hope that you will join us in taking action—for the good of us all.\nWhat YOU can DO.\nRecycle. Stop the Waste.\nThere are lots of ways you can make a difference in our natural world—and recycling is one of the easiest.\nEven recycling your aluminum cans saves more energy than you might know:\n- A used aluminum can is recycled and back on the grocery shelf as a new can in as little as 60 days.\n- Making new aluminum cans from used cans takes 95 percent less energy, and 20 recycled cans can be made with the energy needed to produce one can using virgin ore.\n- Recycling one aluminum can saves enough energy to keep a 100-watt bulb burning for almost four hours or to run your television for three hours.\n- Throwing away an aluminum can wastes as much energy as pouring out half of the can’s volume of gasoline.\n- Last year, 54 billion cans were recycled, saving the energy equivalent of 15 million barrels of crude oil—America’s entire gas consumption for one day.\nDiscover more ways your recycling can help the environment—and the Zoo:\nCarpool, ride a bicycle or use public transportation whenever possible. If you do drive, here are a few tips to help your vehicle run more efficiently:\n- Keep your engine tuned up and performing to its standards.\n- Replace air filters regularly to maintain fuel efficiency.\n- Keep tires inflated to achieve the best fuel efficiency.\n- Avoid unnecessary idling and car trips whenever possible.\nEliminate water waste so there’s enough to go around. Here are a few things you can do at home to preserve our planet’s water supply:\n- Turn off the faucet while you shave, brush your teeth and lather up your hands.\n- Wash only full loads of laundry to save water and electricity.\n- Fill the kitchen sink with soapy and clean water when washing dishes by hand, instead of letting the water run.\n- Completely fill the dishwasher before running it to save water and electricity.\n- Take short, five-minute showers instead of baths to save about 40 gallons of water.\n- Keep an eye out for plumbing and irrigation leaks, and then fixing them promptly.\n- Plant only native, drought-tolerant plant species throughout your home landscape and use mulch to minimize evaporation.\n- Irrigate efficiently through wise sprinkler head selection, which can ensure that water is directed to exactly where it is needed and control the amount of water put on the ground at one time.\n- Water deeply, not frequently. In new landscapes, wean new plants off of frequent waterings after their second year and give periodic deep waterings instead.\n- Use a bucket of soapy water or shut-off nozzle for your hose when washing your car.\nDonate Your Vehicle\nCall Vehicles for Charity at 1 866.628.CARS (2277) or complete the online donation form at www.vehiclesforcharity.org.\nPlease select Cheyenne Mountain Zoo as the recipient of the proceeds from the sale of your vehicle. Paperwork and arrangements for towing your vehicle will be handled at no expense to you. For more information, call 719-633-9925, x115, or e-mail email@example.com.\nProceeds from the salvage sales will help the Zoo!\nGreen Consumer Action.\n- GET A LIVE TREE! – Believe it or not, a live tree is actually a relatively eco-friendly choice, so long as you’re conscious about where it goes once the holidays are over. According to the National Christmas Tree Association, nearly all cut holiday trees are grown on tree farms – meaning their stock is replenished yearly and forests aren’t hurt by choosing a cut tree. Go to earth911.org and enter your ZIP code to find out where to have your tree recycled. Or even better, get a LIVE one and plant it !\nFake trees are a different story, requiring a significant amount of energy and petroleum-based materials to manufacture. Plus, artificial trees are often manufactured overseas and shipped thousands of miles before they reach our living rooms.\n- BE BRIGHT! – Instead of buying more standard holiday lights to replace bad strings, opt for energy-efficient light strings. When they’re made using light-emitting diode bulbs, LEDs, they’re 90% more efficient than traditional holiday lights. LEDs also last longer – up to 10,000 hours compared with 5,000 hours for standard incandescent bulbs. AND- you can go one better by getting light strands with a small SOLAR panel to power those LEDs!!\n- REDUCE, REUSE, RECYCLE, REPURPOSE – This tip is an oldy but a goody. It just requires being a responsible consumer, user, and disposer.\nREDUCE – Once you have pared down your consumption, be sure to buy responsibly. Look for things made of recycled materials, that support your local economy, with minimal packaging, or that help support conservation causes.\nREUSE – Be creative about how and when to reuse.\nWhat you can’t reuse, RECYCLE! Visit the EPA’s Reducing and Reusing Basics for more information on how to conserve during the holidays and year-round.\nIf you are an online shopper, check out links below for some great environmentally conscious gift items and ideas:\n- BORROW FROM NATURE – Think of how your grandmother or great or even great-great grandmother decorated during the holiday – with natural evergreen boughs cut from evergreen trees (holly, pine, magnolia) handmade ornaments, and bowls of fruit or pine cones. With a backdrop of seasonal poinsettias and cyclamen they create a warm, fragrant and welcoming feel – and they aren’t made of petroleum and chemicals and shipped from across the world.\n- GIFT WRAP – Start your own recycling program for wrapping.\n- Use old posters, comics, colorful shopping bags, old calendars, even old maps are cool wraps!\n- Design your own gift-wrap by using a paper grocery or department store bag and adding decorations such as drawings, stamped patterns, or pictures cut from magazines.\n- Let the kids do the designing. It will keep them busy on stormy days.\n- If you do use store bought wrapping paper, buy the kind with recycled content (the more post consumer, the better).\n- When you receive gifts, be sure to save the ribbons and bows. For additional tips on how to reduce your gift wrapping waste, visit http://www.ciwmb.ca.gov/publiced/Holidays/.\nRecycle Cell Phones & Printer Cartridges\nUsed Cell Phones\nRecycle your old cell phones at the Zoo—and we’ll all benefit. The Earth will have fewer toxic, heavy metals in its landfills. The Zoo, in partnership with Eco-Cell, will get $1 to $50 per phone to put toward conservation efforts. And you, will receive $2 off the regular Zoo admission price for each cell phone you turn in to us for recycling. Limit is one discount per cell phone. This offer is not valid for special events, and can not be combined with other offers or discounts.\nOn your next visit, just place your old cell phones in the bins at the Zoo admissions booth. It’s a win for everyone!\nEach of us can make a difference in saving energy. Do your part to conserve energy at home by following these simple energy-wise practices—and save money at the same time:\n- Turn your thermostat up two degrees in the summer and down two degrees in the winter.\n- Turn off the air conditioner when no one is home or install a programmable thermostat.\n- Close curtains or blinds in the summer to keep the sun from heating your house.\n- Replace incandescent bulbs with compact fluorescent bulbs. They last longer, give off less heat and save money on your energy bill. Bulb varieties and availability are expanding all the time.\n- Turn off lights and appliances when they’re not in use and unplug them when you’re gone for long periods of time; standby power still pulls energy.\nItems we purchase in our everyday lives have an impact on the environment. Here are some things to think about:\n- Buy products with certified sustainable palm oil.\nPalm oil is a product in many everyday products, and its production is seriously threatening the lives of orangutans in Southeast Asia. Learn more about the Palm Oil Crisis\n- Select ocean-friendly seafood.\nThough you may be far from the ocean, you can still have an impact on its residents. Whether you’re buying seafood in a store or a restaurant, know which seafood to choose and why. Visit Seafood Watch for more.\n- Stop drinking bottled water.\nBuy a durable water bottle and reuse it instead of using disposable plastic bottles that never decompose in landfills.\n- Try reusable and bio-compostable paper goods.\nOn your next picnic or camping trip, take reusable tableware instead of disposable paper products, or use bio-compostable paper ware.\n- Replace plastic bags with canvas.\nUse canvas tote bags while shopping and reduce the use of plastic and disposable bags.\n- Recycle old cell phones and their batteries.\nInstead of sending your old cell phones—and their toxic metals—to your local landfill, bring them to the Zoo for recycling. Also, coltan, a metal in cell phone batteries, is mined in endangered gorilla habitat, contributing to their decline. Visit Eco-cell for more.\n- Refill or recycle printer cartridges.\nReduce waste by recycling your used printer cartridges instead of throwing them away. Buy recycled cartridges, too, and close the loop!\n- Choose recycled paper products.\nBuy recycled paper towels and toilet paper to close the loop on the recycling process.\nWaste Disposal & Compost\nThink Twice about Trash.\nAvoid polluting our environment by disposing of your household waste items appropriately.\n- Reduce, reuse and recycle whenever possible. Learn about recycling in El Paso County, Colorado. View El Paso County Recycling Directory PDF .\n- Dispose of items containing mercury with care. Mercury appears in many household items such as fluorescent light tubes, mechanical thermostats, silver-bulb thermometers, watch batteries and clothes irons. Visit El Paso County Hazardous Waste to learn more about disposing of them properly.\n- Practice responsible medication disposal to help reduce their environmental impact.\nNationally learn more at http://water.epa.gov/scitech/swguidance/ppcp/upload/ppcpflyer.pdf.\nFor Colorado Springs area drug disposal information visit CHSP’s Colorado Clean Program.\n- Reduce or avoid the use of pesticides on your lawn. If you do use them, follow their directions carefully.\n- Go organic! Compost food items and use them on your garden as fertilizer. Learn more at www.howtocompost.org.\nGet the Scoop on Poop.\nDoo you know the best way to keep annoying deer away? From our yard to yours, Zoo Doo is made from Cheyenne Mountain Zoo big cat feces and sold by the pound. Gardeners swear by this all-natural deer deterrent to protect their plants and trees. Even better, your purchase supports the zoo!\nWhat’s in Zoo Doo?\nZoo Doo contains Cheyenne Mountain Zoo tiger, leopard and African lion feces. Mountain lion feces is not used to prevent attracting mountain lions to your yard. Please note, Zoo Doo is a deer deterrent, not a fertilizer.\nDoes it smell?\nYou may notice an initial odor, however, it’s generally unnoticeable to humans after a short time. The effect on deer lasts much longer.\nHow long does it last?\nThe effects of Zoo Doo vary. Some gardeners may only need to purchase Zoo Doo once a year, while others may need to purchase more after a few weeks.\n$2.00/pound; 15-pound minimum\nAvailable Tuesday – Saturday, by appointment only.\nCall 719-633-9925 x 150","Wellington Zoo: Leading the way with the Sustainable Development Goals\nSustainability and care for the environment is ingrained into the very foundations of Wellington Zoo.\nOpened in the Wellington suburb of Newton in 1906, it was New Zealand’s first zoo, and has carried that forward thinking and ground-breaking approach ever since. This ethos led them to take part in Toitū Envirocare’s Sustainable Development Goals materiality assessment and be a part of a leading group of New Zealand organisations aligning their strategic actions with sustainable outcomes.\nThe Zoo has a well-established sustainability strategy based around the trinity of environmental, social and financial responsibility. They are keenly aware of the state of the planet, with climate change and environmental destruction impacting animals and their habitat as well.\n“We look after animals from all over the world whose existence is in danger from climate change, so it’s always been very important to us to make sure we do what we can”, says Amy Hughes, Wellington Zoo’s General Manager Communication, Experience and Conservation.\n“We really feel like we have to walk the talk. It’s hard to promote conservation and ask our visitors to do something for the planet, if we are not doing it ourselves”.\nWellington Zoo have also been Toitū carbonzero certified since 2012, and the programme forms a core part of their environmental strategy. However, in 2018 they decided to formalise their broader focus on sustainability and take the first step to embedding the UN Sustainable Development Goals (SDGs) into their business through a materiality assessment with Toitū Envirocare.\nThe UN SDGs are framework of 17 global goals agreed by than 190 world leaders at a historic summit in 2015. A blueprint for tackling the world’s most pressing social, economic, and environmental challenges, the goals are connected under three overarching themes: mitigating climate change, ending extreme poverty and fighting inequality and injustice.\nThe global nature of the goals was part of the appeal to the Zoo, who were determined to take a local approach to the global challenges. Throughout the process, they also discovered that conservation partners within their global network were interacting with the SDGs, giving them a shared framework for discussion.\n“We really liked the idea of a universal language and goals, that helped give us a framework of where to go in the future”, says Amy.\nAs part of the materiality assessment, the Zoo first mapped their current initiatives against the 17 goals and were surprised at how well they scored. “One of the biggest surprises, once we sat down with the list of the SDGS, was how much we were already doing. It gave us a new perspective, that there were things we’re doing that we wouldn’t think was contributing to something like zero poverty, but actually by paying a living wage we’re contributing to that”.\nThe Zoo particularly wanted to identify a short list of goals that were relevant to them as an organisation, and where they could set and measure aspirational targets. “We didn’t want to approach it with what we were already doing”, Amy says.\n“We wanted to challenge ourselves and consider our aspirations and where we want to be operating as an organisation, rather than what are we already doing that happened to fit in those SDG boxes”.\nThey also surveyed both staff and customers about what they considered were important to the Zoo, and what goals were important to them as individuals, running several staff workshops to capture the range of opinions. Amy believes this exercise was the most helpful to get multiple perspectives on what SDGs the Zoo can, and should, influence.\n“It was an opportunity to really step back and see what other people thought, it has been really good to have our choices underpinned by those external voices”.\nThe Zoo identified a number of SDGs to work on: Life on Land, Life Below Water, Climate Action, Responsible Consumption and Production, Quality Education, and Sustainable Cities and Communities. Amy felt strongly that including Sustainable Cities and Communities was an opportunity for the Zoo to showcase their leadership in the space as they continue their sustainability journey.\n“We have been operating for 113 years - we are part of the community. I think we can contribute more to our city and community in terms of sustainability, and really lead the way”.\nThe next step for the Zoo will be setting targets around the six goals and identifying how to progress the goals in a meaningful way. It’s a process that will help the Zoo stay accountable to their stakeholders: staff, customers and the animals that they care for. Those three key groups also allow the Zoo to translate their initiatives and progress in a way that is meaningful and concrete.\n“For example, when our staff deliver messages about using FSC-certified wooden products, we show how it relates to issues of deforestation, so customers can link their experience seeing a chimp or a tiger with the products they use or buy. It really helps us connect people to animals and then to the bigger conservation and sustainability picture”.\nAs for other companies who might be considering using the SDGs to guide their sustainability journey, Amy has one message - just start.\n“The starting is the key point. Whether it’s looking at the SDGs or something else, anything that helps you start is a good thing. I would suggest no more than four or five goals if you are starting out and understand how your organisation can make it work for them. You could pick one, say we’re going to do everything that we can do, and have it grow from there”.\nNeed help with embedding the SDGs in your organisation?\nSpeak to our expert team to find out how Toitū Envirocare can help.\nFor the latest in sustainability best practice stories, news, views and events, sign up to our mailing list."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:114bdb4a-c9fc-4dcc-b555-0eb11448ac58>","<urn:uuid:1a150467-21c9-44e1-9667-248497d05177>"],"error":null}
{"question":"What are the key architectural features of Renaissance buildings, and how do modern restoration projects approach the preservation of historical structures?","answer":"Renaissance buildings were characterized by several distinct features: symmetrical square or rectangular shapes, symmetrical facades along the vertical axis, Roman-style columns, arches and domes inspired by Roman and Greek architecture, and flat ceilings. In contrast, modern restoration approaches focus on balancing preservation with new elements. Rather than completely demolishing historic structures, some projects incorporate old features into new constructions. For example, some successful conservation projects preserve period features while adding modern elements, creating a fusion of past and present. One notable example involved preserving an 18th-century cottage's original timbers, including its decay, cobwebs, and birds nests, within a new high-performance envelope, effectively creating a building with two walls, windows, and roofs.","context":["During the Renaissance architects began to look back to the Romans and Greeks for inspiration when designing buildings. Much of Renaissance architecture style was taken from Ancient Rome and Greece and then altered to fit their current lifestyle.\nSt. Peter's Basilica is a prime example of Renaissance architecture (Photo by Wolfgang Stuck)\nBrunelleschi was considered the first Renaissance architect. Some historians consider the start of the Renaissance to be 1419, when he won the commission to build the dome above the cathedral of Florence. This dome was an ambitious undertaking as it was to be the largest dome built since the Pantheon in Ancient Rome, which had been built 1500 years earlier.\nThe dome designed by Brunelleschi\n(Photo by Enne via Wikimedia Commons)\nThe entire dome, including the lantern on top, would take much of Brunelleschi's life to complete. The gold ball at the top weighed nearly two tons by itself. It also took over four million bricks to construct the dome. Brunelleschi also had to invent new ways of lifting heavy objects high into the air, which would later be used by other architects.\nBrunelleschi also designed two churches in Florence; the church of San Lorenzo and the church of Santo Spirito. These churches were built with symmetry and order. Many more churches throughout Europe would mimic this basic design in the coming years.\nFeatures of Renaissance Buildings\nRenaissance architecture had some distinct features that were fairly common to major construction:\nSquare - Many buildings were built as square or rectangle symmetrical shapes.\nFront - The front or \"façade\" of the buildings were generally symmetrical around the vertical axis.\nColumns - They used Roman type columns.\nArches and Domes - Arches and domes were popular. This was again taken from Roman and Greek architecture.\nCeilings - The ceilings of buildings were generally flat. Previously in the Middle Ages ceilings were often left open.\nExamples of Renaissance Buildings\nBasilica of St. Peter - This is perhaps the most famous building built during the Renaissance. Several architects worked on the design for the building including Michelangelo. It has the largest interior of any Christian church in the world and is considered by many to be the greatest Christian church building. It took 120 years to complete from 1506 to 1626.\nThe Sistine Chapel - A chapel that is part of the official residence of the Pope in Vatican City, this building is most noted for its ceilings painted by Michelangelo.\nPalazzo Pitti - Originally built in 1458 for Florence banker Luca Pitti, this palace later became part of the Medici family empire.\nPalazzo Farnese - A palace from the High Renaissance built in Rome for the Farnese family.\nEl Escorial - This majestic building was built in the late 1500s as the palace of the King of Spain. It is laid out in orderly symmetric squares as shown in the picture below. Some believe that the floor plan was to mimic Solomon's Temple.\nEl Escorial from above\nPhoto from the Madrid Tourist Consortium\nLicensed under the Creative Commons 2.0 Generic license\nPazzi Chapel - This chapel is said to be a masterpiece of the simple form of the architecture of the time. It is thought that the original design was by Filippo Brunelleschi even though the building wasn't finished until nearly 20 years after his death.","The restoration of historic buildings is a constant challenge for everyone in the architectural community. Often, the question is whether or not to restore them at all, as demolishing the structures entirely and starting from scratch can be more economical and time-effective. If it is decided that the existing structure should be retained, what aspects of it should be kept? Of course, that depends on the overall condition of the building and any historical merit it might have that’s worth preserving. Sometimes, these buildings are in good enough condition to have their characteristic period features highlighted and combined with new elements, resulting in incarnations that are altogether new. These are often the most successful conservation and preservation projects, when old and new come together to embody both the times gone by and the now under a single roof.\nA recent project by David Connor Design and Kate Darby Architects has done exactly that by preserving an old cottage within a new construction in England’s West Midlands. The collaborative team is responsible for conserving the cottage’s 18th-century timbers, which were in a severe state of decay. Instead of restoring the rotting structure, the concept behind the build was to keep everything exactly as it was and to incorporate it into a new construction. The designers said, “The strategy was not to renovate or repair the 300-year-old listed building, but to preserve it perfectly. This would include the rotten timbers, the dead ivy, the old birds nests, the cobwebs, and the existing dust. The ruin would be protected from the elements within a new high-performance outer envelope. This means that in most places there would be two walls, two windows and two roofs, old and new.”\nThe new scheme sees the cottage enveloped in a gabled structure with feature fenestration (including a generous vertical window in one of the walls) and a black corrugated metal skin. The cottage now forms part of a house that also incorporated an existing stable on the land into itself, which now functions as a studio for the architects and designers.\nThe effect of the old cottage’s subsumption into the new home is startling in its juxtaposition of old and new. Certain period features are retained in several projects, but it’s rare to see centuries-old growth and decay worked into a brand new design. There is a beauty in the coupling of the ancient rafters and warped beams with fresh, whitewashed walls and a new steel frame, which has been carefully inserted into the cottage to support the existing one. The furnishings are minimal and straddle the boundary between antique and contemporary themselves, with wood burning stoves, simple metal framed couches and armchairs, and stainless steel kitchen units bringing flashes of modernity into the space.\nThis preservation project has been a personal and industry success for its designers, who have won a number of awards throughout 2017, including the RIBA West Midlands Regional Award, the West Midlands Small Project of the Year, and the Architect’s Journal Small Projects Award."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:698a984c-cd63-45f5-8cac-1630ffafbe8d>","<urn:uuid:de6daa36-80e8-4346-a16c-3abf6b3a9b03>"],"error":null}
{"question":"What role does oxygen play in pipe corrosion, and how does it affect marine structures?","answer":"In pipe corrosion, oxygen participates in depolarization by reacting with hydrogen gas surrounding the cathode: hydrogen gas + oxygen forms water. This removal of hydrogen gas accelerates the corrosion process, making water high in dissolved oxygen more corrosive. In marine environments, oxygen's presence in marine atmospheres, sea spray, and splash zones increases the aggressiveness of salt attack. The differential concentration of oxygen at the waterline or in salt spray droplets creates cells where attack concentrates in areas with lowest oxygen concentration. Additionally, crevices that allow water and chlorides but exclude oxygen become anodic and acidic, becoming hidden starting points of corrosion.","context":["Corrosion is an electrochemical reaction involving the movement of\nelectrons. Let's first consider a more familiar electrochemical\nreaction - that which occurs when electricity comes out of a battery.\nIn a battery, electrons build up in the negative end, also known as the\nanode. The positive\nknown as the cathode, is\nattractive to electrons due to its positive charge. If the two\nends of the battery are connected with a conductive object, such as a\nmetal wire through which electrons can flow, the electrons will flow\nfrom the anode to the cathode as an electric current. The battery\nand the wire make up what is known as an electrolytic cell, which is a device\nwhich causes an electric current to flow.\nCorrosion in a metal object, such as a pipe, acts in the same\nmanner. A negative area of metal (the anode) is connected to a\npositive area (the cathode) by the pipe wall itself. As a result,\nelectrons can flow from the anode to the cathode.\nIn addition to the anode, the cathode, and the connecting conductive\nmaterial, the electrochemical reaction requires one more element - the\nelectrolyte. The electrolyte\nis a conducting solution, which in the case of a pipe is the water\nwithin the pipe with its dissolved salts. (In a battery, the\nelectrolyte is found within the battery - the \"battery acid\".)\nthe electrons from the cathode, making the cathode maintain a positive\ncharge which draws more electrons to it.\nSo, in summary, any electrochemical reaction requires four elements,\nall of which must be in contact - the anode, the cathode, the\nconductive material, and the electrolyte. In the battery, the\nanode and cathode are the two ends of the battery, the conductive\nmaterial is a wire or other object touching both ends, and the\nelectrolyte is found inside the battery. In the case of corrosion\nof a pipe, the anode, cathode, and conductive material are all found in\nthe pipe wall while the electrolyte is the water within the pipe.\nIf any of these\nfour elements, which make up the corrosion\ncell, are absent or are not touching each other, then corrosion\nIn the last section, we discussed the electrical side of the\nelectrochemical reaction occurring during corrosion. In order for\nthe flow of electrons to occur, however, chemical reactions must also\nbe happening. In this section, we will consider the chemical\nreactions which occur in an iron pipe as it corrodes. Other types\nof pipes will\nhave different, but homologous, chemical reactions driving their\nThe main force behind corrosion is the tendency of iron to break\ndown into its natural state. The iron found in pipe is elemental\niron (Fe0) which is unstable and tends to oxidize, to join with oxygen or\nother elements. In nature, this oxidation produces an iron ore\nsuch as hematite (Fe2O3), magnetite (Fe3O4),\niron pyrite (FeS2), or siderite (FeCO3). In\ncorrosion, the result of this oxidation is rust, Fe(OH)2 or\nOxidation of the elemental iron occurs at the anode.\nthe elemental iron breaks down as shown below. In this reaction,\nelemental iron leaves the pipe, so pits form in the pipe's surface at\nElemental Iron →\niron + Electrons\nFe0 → Fe2+\nThe reaction produces ferrous iron and two electrons.\nelectrons are then able to flow through the pipe wall to the\nMeanwhile, the ferrous iron reacts with the water (the electrolyte) in\nthe pipe to produce rust and hydrogen ions.\nFerrous iron + Water ↔\nFerrous hydroxide + Hydrogen ions\nFe2+ + 2H2O ↔\nThe rust builds up a coating over the anode's surface.\nhydroxide may then react with more water to produce another form of\ncalled ferric hydroxide (Fe(OH)3). These layers of\nrust are what creates the tubercles we mentioned earlier.\nTubercles can become problematic because they decrease the\ncapacity of the pipe and can be dislodged during high water flows,\nresulting in red water complaints. But in the corrosion process,\nthe tubercle actually slows the rate of corrosion by cutting the anode\noff from the electrolyte. When the tubercle becomes dislodged and\nthe anode comes in contact with water again, the corrosion rate\nThe electrons from the breakdown of elemental iron flow through the\npipe wall to the cathode. There, they leave the metal and enter\nthe water by reacting with hydrogen ions and forming hydrogen gas:\nHydrogen ions + Electrons ↔\n2H+ + 2e- ↔\nHydrogen gas will coat the cathode and separate it from the water in a\nprocess called polarization.\nJust as the buildup of a tubercle breaks the connection between the\nanode and the electrolyte and slows the corrosion process, polarization\nbreaks the connection between the cathode and the electrolyte and slows\nDissolved oxygen in the water is able to react with the hydrogen gas\nsurrounding the cathode:\nHydrogen gas + Oxygen ↔\n2H2 + O2 ↔\nThis reaction is called depolarization. Depolarization removes the hydrogen\ngas surrounding the cathode and speeds up the corrosion process.\nSo, you can see why water high in dissolved oxygen is more corrosive.\nThe Electrochemical Reaction\nBy combining the electrical and chemical reactions discussed above, we\ncan see what is\nreally happening during corrosion of a pipe.","Year upon year the cost of marine corrosion has increased until it is estimated today at 4 % of the Gross National Product. An enlightened approach to materials selection, protection and corrosion control is needed to reduce this burden of wasted materials, wasted energy and wasted money. These notes have been compiled by Members of the Marine Corrosion Forum to help marine designers, engineers, and equipment users, understand the causes of marine corrosion and the way in which protective systems and more resistant materials can be used to reduce or entirely eliminate sea water corrosion problems.\nMany different types of destructive attack can occur to structures, ships and other equipment used in sea water service. The term 'aqueous corrosion' describes the majority of the most troublesome problems encountered in contact with sea water, but atmospheric corrosion of metals exposed on or near coastlines, and hot salt corrosion in engines operating at sea or taking in salt-laden air are equally problematical and like aqueous corrosion require a systematic approach to eliminate or manage them.\nCorrosion by sea water, aqueous corrosion, is an electrochemical process, and all metals and alloys when in contact with sea water have a specific electrical potential (or corrosion potential) at a specific level of sea water acidity or alkalinity - the pH.\nThis typical diagram shows the regions where the metal will freely corrode; the region of passivation where stable oxide or other films form and the corrosion process is stifled; the region of pitting corrosion where the corrosion potential of the metal exceeds that of its oxide; and the region of immunity where the metal is normally fully safe to use. More resistant alloys mean less corrosion, metals like gold platinum and tantalum can resist virtually all corrosion, but for marine service the final choice will always be a compromise with cost.\nMost corrosion resistant metals rely on an oxide film to provide protection against corrosion. If the oxide is tightly adherent, stable and self healing, as on many stainless steels and titanium, then the metal will be highly resistant or immune to corrosion. If the film is loose, powdery, easily damaged and non self repairing, such as rust on steel, then corrosion will continue unchecked. Even so, the most stable oxides may be attacked when aggressive concentrations of hydrochloric acid are formed in chloride environments.\nSea water, by virtue of its chloride content, is a most efficient electrolyte. The omni-presence of oxygen in marine atmospheres, sea spray and splash zones at the water-line, and sometimes surprisingly at much greater depths, increases the aggressiveness of salt attack. The differential concentration of oxygen dissolved at the waterline or in a droplet of salt spray creates a cell in which attack is concentrated where the oxygen concentration is lowest. Crevices which allow ingress of water and chlorides but from which oxygen is excluded rapidly become anodic and acidic and are hidden start points of corrosion.\nThere are five main methods for controlling the tendency of metals to corrode in sea water:\nUse of non metallic materials including composites may offer a solution for some applications.\nSea water, if not destructive enough on its own, has several powerful allies assisting the breakdown of metals and non metals alike. Living allies in sea water also enhance its destructive power. Microbiological organisms, clusterings of weed, limpets as well as deposits of sand, silt or slime not only exclude oxygen but often create locally corrosive conditions under these deposits which aggravate attack. Coatings and composite structures can experience rapid degradation. Sulphate reducing bacteria, left undisturbed in marine silt or mud deposits, will produce concentrations of hydrogen sulphide which are particularly aggressive to steel and copper based alloys.\nPitting attack in stagnant sea water may be as much a problem as impingement, erosion or cavitation attack at higher velocities. The highest water velocities, at the tips of propellers or in pumps can result in bubbles of entrained air imploding with sufficient energy to remove metal or break up composites. Called cavitation, this noisy and aggressive mechanical destruction must be corrected by design, or if it cannot be eliminated, countered by the selection of suitably resistant alloys.\nHigh levels of stress in service, or residual stress from manufacturing may result in selective corrosion of more highly stressed regions of an otherwise corrosion resistant structure. In the aggressive marine environment even the more resistant alloys may be affected by hydrogen-induced cracking, or by chloride or sulphide stress corrosion cracking. Choosing the right material for corrosion resistance also requires careful attention to component design, selection of manufacturing processes, installation and operation.\nLet's now look at a simple example. A ship made from bare mild steel will quickly rust.\nProtection by painting\nPainting the ship isolates the steel from the corrosive media. The paint must also be resistant to the marine environment and the application strictly controlled to ensure full and effective coverage of the steel. Regular inspection and repair of the coating may be necessary to achieve reliable and lasting protection.\nSacrificial anodes enable the potential of the system to be changed and will provide temporary protection to steel exposed by wear or damage of the protective coating. Systematic location of the anodes is critical to their overall effectiveness. They must likewise be regularly serviced and replaced when spent.\nInside the ship inhibitors which modify the corrosion process may effectively prevent attack in bilges and other areas where sea water will collect and stagnate. Reliable systems to monitor and maintain the correct concentration of the inhibitor are an essential aspect of this prevention strategy.\nIn practice ships are rarely made just from a single metal or alloy. Modern engineering systems use a wide range composites and of metals and alloys, some more, some less resistant to marine corrosion than steel. The more resistant alloys may aggravate the attack on adjacent unprotected less resistant alloys. This galvanic effect is not always confined to separate metals, some alloys improperly processed in manufacture or fabrication carry the seeds of their own destruction in their microstructures which contain phases so widely separated in corrosion potential that without further overall protection by coating, anodes or inhibitors, selective attack of the less resistant phase is inevitable.\nUsing corrosion resistant alloys\nCould ships and other marine structures be made from more corrosion resistant materials? Depending on design factors including the severity of the application and the levels of strength, damage tolerance, reliability, safety and life required, components and systems can be manufactured from composites, or from stainless steels of increasing resistance, or from copper based alloys such as cupro-nickel or nickel aluminium bronze, nickel alloys or titanium, using these materials exclusively or in conjunction with each other or less resistant alloys. Protection for the least resistant alloys by anodes, or impressed potential, requires careful control of the system potential to avoid the possibility of hydrogen uptake by the more highly corrosion resistant alloys such as super duplex steel and titanium.\nKey factors in prevention of marine corrosion are design, selection of materials, construction, use and maintenance. Failings in any one of these may lead to a total failure to prevent attack, which once started may cost far more to correct or eliminate than any notional savings on materials achieved at the outset. In a recent survey corrosion was found to be responsible for 30% of failures on ships and other marine equipment. These are expensive errors arising from the selection and use of unsuitable materials and are compounded by ever increasing penalties on vessels, civil and military for breakdown and unnecessarily short intervals between outages for major repairs. On offshore platforms the cost penalty for replacement of failed equipment is several times that required for a similar onshore facility, and this does not take into account any losses of oil or gas production.\nWhere to get help\nThe many types of marine corrosion, their possible interaction, and the need to review the whole system when considering changes, means that getting help and advice from marine corrosion specialists and materials and coatings experts is particularly important. Members of the Marine Corrosion Forum include such specialists as well as product and systems suppliers and end users. Regular meetings review and update the wide range of options available to designers and users to overcome new or long term marine corrosion problems. You are welcome to attend a meeting as a guest, or to become a member of the Marine Corrosion Forum yourself."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:5ae6f1bd-ee25-430f-af64-73a8e6444eb9>","<urn:uuid:9540ede7-3fd3-4bd6-b15a-073d9bb00532>"],"error":null}
{"question":"How does local device storage compare to cloud storage in terms of persistence and security features?","answer":"Local device storage, like the Cache API, offers device-level persistence where data is retained across sessions and browser tabs within a particular device. Cloud storage provides global persistence across sessions and devices, making it more robust for data retention. However, cloud storage faces greater security challenges, requiring additional protective measures like end-to-end encryption, secure HTTP access with SSL encryption for data transfers, and role-based access controls to prevent internal threats. Local backups are also recommended as a security measure against ransomware attacks on cloud-stored data.","context":["It’s important to choose the right storage mechanisms, both for local device storage and for cloud based server storage. A good storage engine makes sure your information is saved reliably, reduces bandwidth, and improves responsiveness. The right storage caching strategy is a core building block for enabling offline mobile web experiences.\nThis article provides a brief foundation for evaluating storage APIs and services, after which we’ll provide a comparison table and some general guidance. In the near future, we plan to add resources for understanding selected storage topics in greater depth.\nLet’s start by understanding some of the dimensions by which we can analyze data storage for web apps. Later, we’ll use this framework to enumerate and evaluate the many storage options available to web developers.\nThe model for storing units of data determines how data is organized internally, which impacts ease of use, cost and performance of storage and retrieval requests.\nStructured: Data stored in tables with predefined fields, as is typical of SQL based database management systems, lends itself well to flexible and dynamic queries, where the full range of query types may not be be known a priori. A prominent example of a structured datastore in the browser is IndexedDB.\nKey/Value: Key/Value datastores, and related NoSQL databases, offer the ability to store and retrieve unstructured data indexed by a unique key. Key/Value datastores are like hash tables in that they allow constant-time access to indexed, opaque data. Prominent examples of key/value datastores are the Cache API in the browser and Apache Cassandra on the server.\nByte Streams: This simple model stores data as a variable length, opaque string of bytes, leaving any form of internal organization to the application layer. This model is particularly good for file systems and other hierarchically organized blobs of data. Prominent examples of byte stream datastores include file systems and cloud storage services.\nStorage methods for web apps can be analyzed according to the scope over which data is made persistent.\nSession Persistence: Data in this category is retained only as long as a single web session or browser tab remains active. An example of a storage mechanism with session persistence is the Session Storage API.\nDevice Persistence: Data in this category is retained across sessions and browser tabs/windows, within a particular device. An example of a storage mechanism with device persistence is the Cache API.\nGlobal Persistence: Data in this category is retained across sessions and devices. As such, it is the most robust form of data persistence. An example of a storage mechanism with global persistence is Google Cloud Storage.\nDevelopers should choose an API best suited to their problem domain; however, they should also take into account the fact that standardized and well established APIs are preferable to custom or proprietary interfaces, because they tend to be longer lived and more widely supported. They may also enjoy a broader knowledge base and a richer developer ecosystem.\nOften, it is important for a collection of related storage operations to succeed or fail atomically. Database management systems have traditionally supported this feature using the transaction model, where related updates may be grouped into arbitrary units. While not always necessary, this is a convenient, and sometimes essential, feature in some problem domains.\nSome storage APIs are synchronous in the sense that storage or retrieval requests block the currently active thread until the request is completed. This is particularly onerous in web browsers, where the storage request is sharing the main thread with the UI. For efficiency and performance reasons, asynchronous storage APIs are to be preferred.\nIn this section we take a look at the current APIs available for web developers and compare them across the dimensions described above.\n|API||Data Model||Persistence||Browser Support||Transactions||Sync/Async|\n|File system||Byte stream||device||52%||No||Async|\n|cloud storage||byte stream||global||100%||No||Both|\nAs noted above, it’s wise to choose APIs that are widely supported across as many browsers as possible and which offer asynchronous call models, to maximize interoperability with the UI. These criteria lead naturally to the following technology choices:\nFor offline storage, use the Cache API. This API is available in any browser that supports Service Worker technology necessary for creating offline apps. The Cache API is ideal for storing resources associated with a known URL.\nFor storing application state and user-generated content, use IndexedDB. This enables users to work offline in more browsers than just those that support the Cache API.\nFor global byte stream storage: use a Cloud Storage service.\nThis combination satisfies the basic storage needs for many mobile web apps.\nDebugging storage in Chrome DevTools\nCheck out the following docs to learn more about using Chrome DevTools to inspect and debug your web storage API of choice. APIs not mentioned here are either not supported in DevTools or are not applicable.\nIf you're using multiple storage APIs, check out the Clear Storage feature of DevTools. This feature lets you clear multiple stores with a single button click. See Clear service workers, storage, databases, and caches for more information.\nWhere to go next…\nNow that we’ve reviewed some of the relevant ways to think about storage mechanisms and compared the most popular APIs and services available today, we'll be adding more content soon to dive more deeply into one or more topics of interest:","There are two sides to every coin, and nowhere is that more evident than on your cloud server. The exact same attributes that make cloud storage servers so cost-effective and convenient also make them much more difficult to secure.\nIn the cloud, maintenance and upgrade management falls entirely to your cloud hosting provider. On one hand, this frees up internal resources, meaning less time (and money) is spent on routine maintenance. On the other hand, you don’t have control over server configurations and upgrades, which could spell trouble where your business security is concerned.\nSimilarly, the same virtualization technology that allows you to rapidly deploy new cloud servers also puts you at risk for data breaches and other cybercriminal events. In cloud computing, physical servers are split into virtual machines, which means other organizations could theoretically access the data stored on them—especially if your provider is lax with security controls.\nThese issues highlight just how diligently business IT support teams must work to secure cloud storage servers and databases. Beating hackers at their own game requires robust, thorough security strategies like those described below.\nEnd-to-end data encryption\nImplementing encryption solutions is one of the most crucial moves you can make to protect your data from leaks and ransomware attacks. Most cloud storage services automatically encrypt data while in transit; however, once that data is saved to your cloud server, there’s no guarantee that it’s secure. And even if a third-party cloud storage service does encrypt the data stored on its servers, the company ultimately holds the key to that information, not you. In other words, if that third party is compromised, your data could go down with it.\nThese facts make a good case for implementing some kind of encryption method before you store data in the cloud, but regardless of whether you use a cloud storage service or have a separate cloud environment, protecting your data with encryption software offers security against brute-force attacks, data leaks and ransomware. Your business IT support provider should be able to help you design an encryption technique for your cloud storage solutions—for instance, at MyITpros, we offer whole-disk encryption for our cloud services.\nSecure data transfers\nKeep in mind that data is not only at risk when it’s sitting on cloud storage servers, it’s also vulnerable when in transit (i.e. while being uploaded, downloaded or moved on your server). Although most cloud service providers encrypt data transfers as a rule, this is not always a given.\nTo ensure data is protected while on the move, make certain that transfers go through secure HTTP access and are encrypted using SSL. Your business IT support provider should be able to help you obtain an SSL certificate and configure your cloud service to use it. You may also want to install HTTPS Everywhere on all devices that connect to your cloud.\nLocal data backups\nThe cloud often lulls business owners into a false sense of security where data integrity is concerned. After all, if one of the main cloud benefits is that your data is backed up automatically, there’s no need to save it locally, right?\nNot necessarily. Hackers know that many businesses don’t save data locally, and they exploit this to their advantage when they launch ransomware attacks. Without local backups, you might feel pressure to surrender large sums of money to get your data back.\nHowever, the FBI recommends that you don’t pay ransoms. Not only is there no guarantee that hackers will play fair and return your data (these are criminals, after all), paying up could brand you as an easy target and make you more likely to be hacked in the future. Backing up your data locally will give you the confidence you need to refute a ransomer’s fee.\nDistributed denial-of-service protections\nYou may already be familiar with distributed denial-of-service (DDoS) attacks in which a hacker drowns your server, website or application with multiple requests for data, essentially rendering it useless. Cybercriminals have been launching denial-of-service attacks for at least 20 years, but today’s access to bots and IoT devices makes it even easier for hackers to coordinate the attacks through multiple systems, hence the term “distributed.”\nYou can fight back by building multi-layered protections into your networks and systems. Using web application firewalls, intrusion protection systems (IPS), load balancers and other tools, you’ll be able to better detect and prevent DDoS attacks and handle high-volume requests that might otherwise paralyze your network. A good managed service provider will be intimately familiar with these controls and able to add them to your infrastructure and servers.\nHackers are constantly at work, which means your IT support provider must be, too. To keep your company’s data, applications, websites and networks secure, you’ll need to stay one step ahead of cybercriminals.\nEssentially, this boils down to identifying system weaknesses before they cost you. You may want to engage your business IT support team in performing a vulnerability assessment, which will involve your provider testing your cloud storage networks to locate weaknesses that may allow hackers in and then developing a plan to address these. Performing these assessments regularly keeps your networks like a shark: always swimming.\nAn unfortunate truth about security threats is that they don’t necessarily come from outside a business. Internal team members with access to sensitive data on the cloud can wreak havoc in their own right, whether they take the form of disgruntled employees stealing confidential data for malicious purposes or negligent personnel accidentally exposing information housed in the cloud.\nRole-based access controls (RBACs) help you regulate the access given to various employees, allowing you to designate which servers and files individual users can open, edit or copy. Administrators can assign roles and privileges to users based on need, authority and the employee’s position within the company. Implementing these controls may also be required to stay compliant with statutory and regulatory requirements for your industry.\nSo what if there are two sides to the cloud computing coin? With the right cloud security controls, the odds will be in your favor every time!"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:7103c55e-e25e-4825-9dab-1dcd6063569b>","<urn:uuid:7485cb1f-5a98-4332-a04e-ffa03d3c8686>"],"error":null}
{"question":"I'm getting started with yoga poses and want to understand their deeper purpose. Could you explain how physical postures benefit both body and mind?","answer":"Yoga āsanas (physical postures) work on multiple levels. On the physical level, they massage internal organs to release toxins, improve blood circulation and lymphatic drainage, release tension in nerves and muscles, and increase strength and flexibility. On the mental level, āsanas purify the mind by bringing it into the present moment - for example, balancing poses require complete mental focus. Additionally, the postures purify the nadis (subtle energy pathways) and improve the flow of prāna (energy) in the body. The ultimate purpose is to create a supple, healthy body and pure mind that can sit comfortably in meditation.","context":["The Eight Limbs of Yoga by Claudia Blaxell\nThere is no better place to discover the wisdom of the body-mind connection than on our yoga mats, where the physical postures or āsanas we do cultivate strength, flexibility and vibrant health, as well as an awareness of the psychological effects of the practice. However, yoga entails much more than stretching, twisting and balancing.\nEight limbs of yoga were first described by Patañjali in his Yoga Sutras over five thousand years ago. Aimed at the regular person, they are practical steps you can take to reach enlightenment – a sustained and profound happiness.\nToday we take a look at the eight step plan of yoga in the hope that you can deepen your yoga practice and liberate yourself from suffering. Read on, absorb the teachings, do a bit of self-inquiry, and create positive change in your life!\nRestrain your actions by not harming others (ahimsā), being truthful (satya), not stealing (asteya), being sexually appropriate (bramacharya) and not being greedy (aparigraha).\nEnsure the actions you take toward your own body and mind cultivate purity (sauca), contentment (santosha), self-discipline (tapas), self-study (svādhyāya) and devotion (ishvara pranidhana).\nĀsana literally means ‘comfortable, steady seat’. But the āsanas or physical postures we practice are only comfortable and steady if the mind and body are free of toxins. When we feel stiffness, tension or pain in the spine, legs, hips or hands it brings our awareness to areas of the body that need our loving attention. In this way we work towards creating a supple healthy body and pure mind that can sit comfortably in meditation. A well sequenced āsana practice works on multiple levels. On a physical level, it squeezes and milks our internal organs, releasing them of toxins; improves blood circulation and lymphatic drainage; releases tension in the nerves and muscles; and increases strength and flexibility. On a mental level āsanas purify the mind by bringing it into the present moment. If you’ve ever tried balancing on one leg while stretching the other toward the ceiling, you will know it is near impossible with an agitated mind! Āsanas also purify the network of subtle energy pathways in the body known as nadis, and improve the flow of energy or prāna.\nPrāṇāyāma refers to specific breath control techniques designed to nourish the quality and flow of prāṇa in the body. Central to prāṇayāma is the notion that the breath is inextricably linked to the mind. When practiced appropriately, over time, prāṇayāma cultivates a steady mind and a higher state of awareness. It also expands the prāna that pervades the body through the nadis, strengthening our aura or energy field. Nāḍī śodhana or alternate nostril breathing is suitable for the beginner and advanced student alike. It clears the nadis known as ida (feminine energy) and piñgalā (masculine energy), promoting a calm, clear and balanced mind.\nWithdrawl of the senses is an important part of yoga because the input we get from the external world through the sense organs pulls our attention wildly from one thing to another, causing an agitated mind. When the sense organs are withdrawn from objects that cause unwanted thought waves to arise, the mind is more easily stilled. So take some time each day to turn off your television and phone, close your eyes and just be. Sense withdrawl can take place on the yoga mat, too. Simply closing your eyes in tadāsana or when bringing your head to your knee in seated poses such as janu śirāsana or paścimottanāsana, promotes inner focus and a quiet mind. With consistent practice over time, prātyahāra happens automatically during yoga practice; your awareness moves within, unaffected by the external world.\nDhāraṇā means ‘to hold’. Fixing the mind exclusively on one object of concentration cultivates focus, creating the conditions necessary for your thought waves to go in one direction instead of in many different directions. The object of concentration can be anything, from an external object such as a candle flame or a point on the floor, or something internal such as the breath or a mantra. On the mat, particularly during balances, it is helpful to have a ‘drishti’ or point of focus where the gaze rests (a) so that you don’t fall over, and (b) to focus and engage the mind so you can move into a state of deep concentration. Each asana has a specific drishti. For example in trikonāsana the gaze is up along your raised arm. In virabhadrāsana II the gaze is along the middle finger of your front outstretched hand. In vṛkṣāsana the gaze is softly fixed at a point on the floor in front of you. Using drishtis, where appropriate, intensifies concentration, a necessary precursor for meditation.\nDhyāna is the state of meditative absorption that happens when you can effortlessly hold the focus of dhāranā. When you stop identifying with your thoughts and the fluctuations of the mind, you come to rest like a lotus flower floating tranquilly on the surface of a pond. At this point you go into a time warp and merge with consciousness, no longer aware of your body or the external world. The mind is clean, and with clear perception can reflect your soul or true self, happy and free.\nWhen all mental activity ceases and you become ‘one’ with your environment, making no distinction between yourself and the objects you experience, then there is samādhi – bliss, ecstasy! The mind completely merges with the true self, the all-pervading pure consciousness that exists in us all, which is who we really are. Reaching a state of samādhi is what we are working towards and is an attainable goal in this lifetime. So keep up your practice and make time each day to tune into the divine presence that is you, and all around you.\nClick RSS feed on right side to get next 2 instalments of this blog direct to your inbox. If you are using Safari you will need to download a free RSS app.\nShare this Post"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:660f862d-0684-4377-9408-67ab24164848>"],"error":null}
{"question":"What are the key differences between WCAG 2.0 and WCAG 2.1 in terms of accessibility improvements for mobile users versus PDF users?","answer":"While WCAG 2.1 introduced specific improvements for mobile users including support for touch interactions, complex gestures, and preventing unintended activation of interfaces, PDF accessibility guidelines focus more on structural elements like proper document formatting, tag trees, and reading order. WCAG 2.1 expanded mobile-specific provisions while maintaining backwards compatibility with WCAG 2.0, whereas PDF accessibility guidelines emphasize document structure through elements like headings, lists, and proper text formatting to ensure accessibility across different platforms.","context":["PDF Accessibility Guidelines\nThis guide assists HFC create accessible and usable PDF documents for various audiences. Increasing the accessibility of web content allows HFC to provide information to users with disabilities such as blindness and low vision, deafness and hearing loss, learning disabilities, cognitive limitations, limited movement, speech disabilities, and photosensitivity. In addition, these guidelines help improve the usability of content in general.\nHFC uses an official form template that was developed to ensure PDF accessibility and HFC brand integrity. All forms must be created in or converted to this template before the College can host them on the HFC website. If you are having difficulty creating or modifying a form for accessibility, please contact Rachel Ford, Web Accessibility Manager, regarding training sessions.\nPDF is a format designed to specify printable pages. As a result, PDF content is optimized for the size of the paper upon which it is printed and not optimized for web viewing. PDFs are thereby –more difficult to use and navigate on the web than HTML content.\nIt is extremely important to decide if the content that you wish to use on the web should be in PDF format. As a general rule, content should be placed on a web page and not in a PDF except in the following circumstances:\n- The content is a document that will be downloaded and printed; and/or\n- The content is a document with five or more pages that require presentation in a linear fashion. Examples include manuals or textbooks.\nIf you decide that your content must be available in PDF format, use this guide to help you properly prepare your PDF for the web and ensure accessibility.\nThe easiest way to create accessible PDFs is to make the source document as accessible as possible. If you are using Microsoft Word to create source documents, the most important step to ensure accessibility is to structure documents well before converting to PDF.\nTo structure Word Documents properly, please adhere to the following:\nKeep it Simple: Avoid floating objects such as frames, text boxes, or images with text-wrapping. Keep the layout of your document as simple as possible.\nSet the Language: Set the language that the document is written in by going to File > Options > Language. In the dialogue that opens up, choose English as the language for all of the options.\nDocument Properties: After saving the document, go to File > Info and click on Properties. In the dropdown menu, select Advanced Properties. Once Advanced Properties is open, fill in the relevant information and specify a title for the document.\nUse Headings: Use the heading styles in Word to indicate headings. Do not increase font size or use the bold setting. These merely create the appearance of a heading and provide no structure to the document.\nText Formatting/Size Use a minimum size of 12pt type and make sure that the text contrasts well with the background. The W3C recommends a 4.5:1 contrast ratio. Also, do not use color to emphasize text—this adds nothing to the document structure. Use styles, such as strong (which looks like bold) or emphasis (which looks like italics) instead. Styles can be found with Headings in the \"Home\" tab of Word.\nMake Text Readable: Use left-aligned (not justified) text and avoid having large blocks of capitalized or italicized text. Avoid underlining as well, unless it's a hyperlink.\nUse Lists: Use bulleted or numbered lists when appropriate. Do not use glyphs or other punctuation (or images) to group related items or mimick lists.\nLayout: Use columns to organize layouts. Do not use spaces, tabs, or tables to organize information on the page.\nData Tables: If you have to display data, use tables with column headings and always include a title or alt for the table. Try to keep the table layout as consistent as possible to make it easier for users to navigate.\nImages: Make sure to add text descriptions to all images used in the document. The descriptions should include all of the information contained in the image. Depending on the version of Word, there may be one or two fields for alt text. If there are two fields, place alt text in the field labeled \"Description\".\nTable of Contents: Use Word's built-in feature to automatically generate a clickable table of contents. Do not create your own.\nLinks: All links should be descriptive (i.e., they should include information about the link and not merely read \"click here.\")\nAccessibility Check: To ensure that documents are accessible, run the accessibility checker in Word. Go to File > Info and click on the Inspect Document button. Then in the dropdown menu, select Check Accessibility. A pane will show up on the right-hand side of the page that lists any remaining issues.\nAbiding by these guidelines for creating Word documents will provide adequate structure for the PDF conversion process and reduce the amount of subsequent editing needed to the PDF.\nConverting to PDF\nOnce the source document is structured properly, it can be converted to PDF from Microsoft Word. To do this, go to the Acrobat tab and click Preferences. Make sure \"Create Bookmarks\", \"Add Links\", and \"Enable Accessibility and Reflow with tagged Adobe PDF\" are selected. This will ensure that Adobe Acrobat picks up on the accessibility structure built into the document. Once preferences are changed, click Create PDF. Once the PDF is created, you can do some minor editing in Adobe Acrobat Pro as instructed below.\nCheck Tag Tree: If your source document was well structured, there should be minimal editing required. However, it is always good to check. In Acrobat, go to View > Show/Hide > Navigation Panes and click Tags. This will bring up a panel that contains the tag tree. Go through the tree and make sure that all content in the document is tagged. If there is untagged content, remove it in Acrobat or modify it in the source document.\nRemove Empty Tags: Delete any empty tags in the tag tree.\nReading Order: Check that the document flows in the correct order by going to View > Show/Hide > Navigation Panes and clicking Order. If content is out of order, simply drag it into its correct place in the tag tree. Do not rely on the visual presentation of information in the page to guarantee reading order. Use View > Zoom > Reflow to check the reading order visually (remember to uncheck this if you want to go back to editing.)\nCheck Document Language: Make sure that the document language is set by going to File > Properties > Advanced. If a language is not selected, select it here from the menu.\nCheck Images: Check that all images have an alt text description. You can see this is the Order panel. If there are images with missing alt text descriptions, go back to the source document and add them.\nCheck Data Tables: If your source document has data tables, use the Tags Panel to make sure that they are tagged correctly.\nCheck Links: Make sure that all active links are tagged correctly in the Tags Panel and work correctly.\nDisplay Document Title: To display the document title instead of the file name, go to File > Properties > Initial View and select Document title from the Show drop down box.\nThere are other tools in Acrobat Pro available to ensure accessibility. Go to Tools > Accessibility and select Full Check to check the entire document for issues. The Accessibility tool also gives users the ability to correct missing alt text and correctly tag form fields from within Acrobat Pro.\nAvoid using scanned documents. If you have scanned a document that you want included in a PDF for the web, it must be recreated (using the proper structuring described above) in a publishing program such as Microsoft Word and converted to PDF.\nTesting for Accessibility\nTo ensure that your document is accessible and functions properly, visit the NVDA website and download their open source screen reader application. This will allow you to double-check the order of your document and ensure that it will be read correctly by such devices.\nPlease note that while third-party applications are available for installation on home computers, they must be installed by ITS on HFC systems. If you need NVDA installed to your HFC computer please submit a request ticket to ITS.\nAdditionally, Adobe Acrobat Pro has a Read Out Loud function that you can use by going to View > Read Out Loud > Activate Read Out Loud. This is similar to a screen reader and will give you a good idea of how your document might be read by someone using a similar device.","Web Content Accessibility Guidelines (WCAG) 2.1 is now a W3C Recommendation. This is an evolution of W3C’s accessibility guidance, including expansion of mobile, low vision, and cognitive and learning provisions. It maintains W3C’s accessibility guidance, while maintaining W3C’s standard of implementable, technology neutral, objectively testable and universally applicable accessibility guidance.\nPublication as a W3C Recommendation finalizes the development process and indicates that the W3C considers the updated guidelines ready for implementation on web content. A WCAG 2.1 press release is available.\nFor users of mobile devices, WCAG 2.1 provides updated guidance including support for user interactions using touch, handling more complex gestures, and for avoiding unintended activation of an interface. For users with low vision, WCAG 2.1 extends contrast requirements to graphics, and introduces new requirements for text and layout customization to support better visual perception of web content and controls. For users with cognitive, language, and learning disabilities, WCAG 2.1 improvements include a requirement to provide information about the specific purpose of input controls, as well as additional requirements to support timeouts due to inactivity. This can help many users better understand web content and how to successfully interact with it.\nAs with WCAG 2.0, following these guidelines will continue to make content more accessible to a wider range of people with disabilities, including blindness and low vision, deafness and hearing loss, limited movement, speech disabilities, photosensitivity, and learning disabilities and cognitive limitations. Following these guidelines can also make websites more usable for all users.\nTransition from WCAG 2.0\nWCAG 2.0 remains a W3C Recommendation. It was designed to be a highly stable, technology-agnostic standard, with informative supporting resources. The Working Group has taken care to maintain backwards compatibility of WCAG 2.1 with WCAG 2.0. All the criteria from WCAG 2.0 are included in WCAG 2.1, so web sites that conform to WCAG 2.1 will also conform to WCAG 2.0. As with WCAG 2.0, WCAG 2.1 will be supported by an extensive library of implementation techniques and educational materials, including Understanding WCAG 2.1 and Techniques for WCAG 2.1. These resources have been redesigned and moved from their previous locations to allow the Working Group to update them on an ongoing, instead of periodic, basis.\nW3C encourages organizations and individuals to use WCAG 2.1 in web content and applications, and to consider WCAG 2.1 when updating or developing new policies, in order to better address the needs of more web and mobile users with disabilities.\nProcess and timeline\nThe Accessibility Guidelines Working Group (AG WG) met an ambitious timeline and completed the work on schedule. Previously, WCAG 2.0 had taken many years to develop, partly because of its goals to be both technology neutral and future-proofed. For many years after the completion of WCAG 2.0, the Working Group focused on supporting those guidelines through updates to Understanding and Techniques. Over time, though, new technologies and use cases emerged which, while still within the scope of WCAG 2.0, may not have been directly addressed.\nTo better address a range of issues, the Working Group began to explore updated guidance initially on extensions, and then shifted to a full-fledged dot-release. By this time, the need for new guidance, particularly to address the needs of users of mobile devices, users with low vision, and users with cognitive or learning disabilities, had become more urgent. A timeline was set for WCAG 2.1 that would allow its guidance to be finalized in 18 months, and requirements set to keep its new success criteria within the established WCAG 2.0 framework.\nInitial proposals for new success criteria were developed by the Working Group, including task forces focusing on specific areas, which also considered many suggestions for improvement that had been submitted by the public over the years. Once an initial set of proposals was established, the Working Group considered how to incorporate them into the guidelines. Candidate success criteria needed to be clear, realistic both to implement and to evaluate, useful to users, and non-redundant. These characteristics are determined by consensus of the Working Group after careful scrutiny and evaluation. This high bar means that many good suggestions needed to be deferred to future versions of guidelines in order either to await technology advances or provide more time to refine the guidance.\nUltimately, 17 new success criteria were added to WCAG 2.1. Once the final set of success criteria were chosen, they were tested in implementations across different types of websites and web content to ensure they were implementable. We want to thank the implementers worked hard on a short timeline to help the Working Group demonstrate implementability of the success criteria, including ones that were at risk.\nMany people hoped WCAG 2.1 would provide more new guidance than it does. The requirement of compatibility with WCAG 2.0 along with the aggressive timeline limited what could confidently be added to it. WCAG 2.1 provides important and timely guidance but is still only a step—the Working Group expects to develop another dot-release, WCAG 2.2, to expand the new coverage even further. WCAG 2.2 may be developed under a similar timeline and requirements set than WCAG 2.1 was, though we plan to refine the process to address process challenges experienced during the development of WCAG 2.1.\nIn addition to a further dot-release of WCAG 2, the Accessibility Guidelines Working Group has been working in parallel on a more major revision to accessibility guidelines, which would not have the same structure as WCAG 2. Beyond web content, these new guidelines are intended to incorporate guidance for user agents and other tools so requirements that depend on tool support are more clear for authors, and address issues of conformance and testability in a different way from WCAG 2. This is a major multi-year project, which is the reason additional updates to WCAG 2 are needed in the meantime. The plan for new accessibility guidelines (which go beyond simply web content) are still being shaped and while not formally named, the project has been code-named “Silver”. Development has been taking place in the Accessibility Guidelines Working Group via the Silver Task Force, in close collaboration with the Silver Community Group to support broader participation and incubation. Input from broad perspectives is critical to this work, and people representing a broad set of stakeholder groups, including those who work in non-English language environments, are invited to participate.\nAlthough the completion of WCAG 2.1 is a major milestone, there is obviously plenty of additional work to do. In addition, W3C is coordinating with national and international regions updating their standards and policies, including the current update of the European Norm (EN) 301 549, and discussions to update the Web accessibility standard in China. The work depends on input from participants and public comments.\nThe Accessibility Guidelines Working Group participation page provides general information about how to participate in the Working Group, and the instructions for commenting on WCAG 2 documents provides information about how to comment on ongoing work. We hope WCAG 2.1 is received as a useful update to web content accessibility guidance and look forward to collaboration on development of further updates.\nSource: W3C Blog"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:6ea8f4bc-64e6-46d2-983b-26714e2302f5>","<urn:uuid:7acd3912-aac8-4452-80ba-ad73721f886c>"],"error":null}
{"question":"What are obsidian's physical properties, and how do scientists date obsidian artifacts?","answer":"Obsidian is a volcanic glass formed when volcanic lava contacts water, typically appearing dark green to black due to iron and magnesium content, though red and clear variants exist. While scientists can precisely determine obsidian's geographical origin through chemical analysis, dating the material has proven problematic. The obsidian hydration dating method, developed in the mid-20th century, measures water absorption in the material but is unreliable because factors like temperature and humidity affect absorption rates - even a 1-degree Celsius difference can change hydration rates by 10%. Instead, archaeologists typically date obsidian artifacts by their archaeological context and relative dating methods, such as the age of surrounding sediment layers.","context":["2011-03-01 05:44:10 • ID: 1018\nObsidian during the Stone Age of East Africa and the Levant\nThis is a pyramidal core from a late neolithic site in Anatolia.\nObsidian, a volcanic glass, is formed when volcanic lava is coming in contact with water. Iron and magnesium usually give the obsidian a dark green to black color but dark green, red, or even clear variants are also known.\nObsidian is an excellent raw material for the production of sharp stone tools. Other trace elements, such as rare-earth elements, scandium, rubidium, cesium, tantalum, thorium and uranium can be used for geochemical analysis.\nIndeed, Obsidian from each volcano has a unique chemical fingerprint, which can be used for securely provenancing the raw material source of an Obsidian artifact.\nNon-destructive X-ray fluorescence analytical methods are often used successfully for this purpose.\nObsidian is therefore an optimal material for the assessment of the size of exploited territories, the evaluation of spatial networks among groups and the identification of particular mobility patterns.\nThe Rift valley in East Africa is one of the few African areas with abundant obsidian sources. Sources of high quality volcanic glass are present in Ethiopia, in Kenya, close to the Lake Naivasha basin and Mount Eburru.\nMinor sources of are found in the east of the Lake Turkana and in the southern in the Suguta Valley Melka Konture, located 50 km south of Addis Abeba is the only known example of obsidian use during the Oldowan. The raw material came from a source, about 7 km away from the archaeological site.\nDuring the Acheulean, the intense use of obsidian has only been documented at Melka Kunture and at Kariandusi (Kenia; 0.7 –1.0myr BP). A few pieces of worked obsidian have been recorded at the Kenyan Acheulean sites of Kilombe, (0.7 myr BP) and at Olorgesailie (0.9 myr PB).\nAt Olorgesailie the nearest source of volcanic glass is 26 km away from the main site. At Gadeb 8E (Ethiopia; 0.7-1.48 myr BP) only 4/222 bifaces were made from obsidian. The nearest source of obsidian is located 100 km to the West.\nBeginning with the MSA, Obsidian was frequently used in East African sites, mostly within a 50-km radius of the sources. Occasional very long distances have been documented between the source and the site of Obsidian knapping.\nFor example some stone tools from the Nasera Rock Shelter, Tanzania have been sourced to an obsidian outcrop 240 km away. Porc- Epic Cave, Ethiopia yields artifacts exhibiting a distance of 250 km from site to source.\nSome authors claim, that these large distances are unique for the MSA compared with the Middle Paleolithic in Europe, but maybe the data are biased by the secure provenancing and high “visibility” of Obsidian compared to other raw-materials.\nIt has to be remembered, that such long distances have been also occasionally observed in Europe (Micoquian of the Kulna Cave in the Moravian Karsts).\nRecently new 40Ar/39Ar geochronological data revealed that the advanced MSA at Gademotta dates back at least 276,000 years. These dates are much older than technologically comparable MSA ensembles from elsewhere. I\nIt has therefore been suggested that MSA technology evolved diachroneous in different places in Africa. One reason for the sophisticated technique used at Gademotta could be the abundance of high quality Obsidian near this site.\nDuring Late Stone Age lithic assemblages in East Africa, Obsidian is generally the dominant raw material for the production of stone tools.\nWhile volcanic glass is not important during the Middle and early upper Paleolithic in the Levant, it becomes gradually more important during the Geometric Kebaran with ever increasing frequency.\nAn excellent page about the Obsidian “Trade” in the Near East can be found as external link\nResources and images in full resolution:","Shiny and sharp, obsidian is enjoying a bit of a pop culture moment. It plays a central role in HBO’s hit fantasy series Game of Thrones, now wrapping its final season. Called dragonglass on the show, obsidian is one of only two substances that can cut down White Walkers, malevolent otherworldly warriors.\nIn the real world, the volcanic glass reveals the human story in a way no other material can.\nOur evolutionary ancestors used obsidian for toolmaking for more than a million years. Thanks to the material’s unique chemical attributes, archaeologists can determine the geographical origin of even small pieces. But that’s only part of the story.\nArizona State University archaeological scientist Andrew Zipkin says knowing where our distant ancestors collected obsidian allows researchers to ask much broader questions, such as where early humans traveled, and why.\n“It’s easy to source obsidian and determine where it came from, but that’s only the first step, because that’s chemistry, not archaeology,” says Zipkin. “The ultimate goal is to understand what motivated these people to collect it from that location.”\nGetting To The Point\nObsidian artifacts turn up at archaeological sites going back at least as far as 1.7 million years ago, when an early member of the genus Homo made tools with it at the Ethiopian site of Melka Kunture.\nAround the world, the prehistoric record is littered with obsidian scrapers, choppers and all-purpose hand axes. Early toolmakers likely chose the volcanic glass because it flakes predictably — it can be shaped more easily than other materials — and the result is a razor-sharp edge.\n“The fresh edge of an obsidian flake is just a few dozen atoms thick,” says Ellery Frahm, an archaeological scientist at Yale University. “When viewed under a microscope, a steel surgical scalpel would look like a dull and badly abused ax next to an obsidian flake.”\nObsidian is also brittle, a bonus for hunters.\n“An obsidian projectile point creates a lot of damage because it’s sharp and also likely to break inside the animal,” says Albuquerque-based geoarchaeologist M. Steven Shackley, professor emeritus at the University of California, Berkeley. He adds: “If you want to create damage, you want to use obsidian.”\nThe material’s bold appearance — shiny and usually black, though red and other colors occur — may have made it attractive for symbolic or aesthetic reasons as well. Whatever its appeal, early humans sought it out. Despite its frequent use throughout prehistory, the raw material is not common.\n“Obsidian is rare most places in the world, and it takes the right kind of volcanic eruption to create it,” says Frahm. “The lava needs to be highly viscous — or sticky — to form glass. A high amount of silica is required to get that sticky lava.”\nWhile this high-silica lava is still below ground, minerals from surrounding rock leach into it, adding different elements specific to that location. When it finally erupts, if it reaches the surface fast enough, the lava will cool quickly and turn into uniform glass before its unique chemical mix has a chance to organize itself into crystals.\n“When that happens, all the elements are frozen inside that glass like a snapshot,” says Shackley. “That’s why we can distinguish all these different sources.”\nX Marks the Source\nDetermining the source of a piece of obsidian means analyzing the chemistry of the artifact and then matching it to a database of geochemical signatures unique to individual sources, called flows.\nFor decades, archaeologists have had few options for that analysis. Most of the equipment is expensive and limited to lab settings. The most precise methods also require destroying the material to be analyzed and, as Shackley notes dryly, “for some reason, people in museums get really upset when you break their artifacts into tiny little pieces.”\nThat’s why non-destructive X-ray fluorescence (XRF) emerged as the most popular method for sourcing obsidian. Though not the most exacting analysis, it’s particularly good at identifying strontium, rubidium and other elements that are frequently key ingredients in a flow’s signature.\n“XRF is a beam technology,” says Zipkin. “It hits the target atom, knocks electrons out of orbit, exciting them, and then, as they drop back down [into normal orbit], they emit characteristic energy that the device measures.”\nLab-based XRF devices have gotten smaller over the years: “The first XRF [machine] I used in the ’80s filled a room,” says Shackley, who is director of the Geoarchaeological XRF Laboratory. “Now the equipment sits on a desktop, a little bigger than a breadbox.” Outside the lab, the technology has seen even more impressive downsizing.\nThe first commercial portable XRF (pXRF) devices arrived in the 1990s, intended for industrial applications such as exploratory mining and quality control in cement manufacturing. They soon found their way into the hands of many an archaeologist. In those early adoption years, enthusiasm for the new tool’s potential sometimes outpaced scientific rigor, and results were not always reliable.\nMethods and standards across the field have since improved, as have the portable devices, which continue to get cheaper and more precise. Today’s pXRF devices — which “look like a combination of a ray gun and a hair dryer,” says Zipkin — run less than $40,000.\n“One can put it in a carry-on bag and bring it almost anywhere in the world,” says Frahm. “No longer do we have to request permission to export a few artifacts to a distant lab. Instead, we can work where the artifacts are, whether in a museum, in a field lab, or even at an archaeological site itself.”\nHe adds: “In only 10 or 20 seconds, we can know where a particular obsidian artifact originated, hundreds, thousands, or even hundreds of thousands of years ago.”\nDates That Don’t Hold Water\nWhile the tools to determine the source of obsidian become ever more user-friendly, obsidian hydration, a method used to date the material, remains problematic.\nDeveloped in the mid-20th century, the method takes advantage of the fact that an obsidian surface starts absorbing atmospheric water as soon as it’s exposed to the air. To date the artifact, researchers take a cross-section and look at the hydration rim, a gauge of how far water has penetrated into the volcanic glass.\n“It’s a great idea, but it’s almost impossible to put into action,” says Zipkin, who calls the results “really just an educated guess.”\nThat’s because the speed of moisture penetration is affected by numerous factors, including temperature and humidity. A difference in temperature of 1 degree Celsius, for example, can change the hydration rate by 10 percent; a single event such as a forest fire roaring past the artifact’s location might reset the hydration rim completely.\nMost archaeologists instead date obsidian artifacts by context — what else was found with it at the site — and relative dating methods, such as the age of the layer of sediment in which it was found.\nTracking Ancient Travel\nAs groups of hunter-gatherers moved across prehistoric landscapes, collecting obsidian and leaving behind flakes of it after making or resharpening tools, they created maps of their movement that archaeologists can follow with ever greater precision.\nTracing the paths obsidian traveled with early humans, says Frahm, can reconstruct how people “made use of their surroundings and met their subsistence needs through mobility across the landscape and connections with other groups.”\nIn 2018 in Science, for example, Zipkin and colleagues published a trio of papers about finds, including obsidian artifacts, at the Kenyan site of Olorgesailie. The obsidian pieces, more than 300,000 years old, came from multiple flows up to 70 miles away: a distance significantly greater than the average territory of hunter-gatherer groups. This means that the obsidian collectors may have either traveled into another group’s territory or traded with them for the material. Both scenarios suggest that humans were cognitively capable of complex social interactions and planning long-distance expeditions more than 200,000 years earlier than once thought.\nObsidian continues to tell us more about not only ourselves, but our closest evolutionary kin.\nIn February, for example, in the Journal of Archaeological Science: Reports, researchers described obsidian artifacts up to 73,000 years old, made of raw material from the Baksan River valley. The location is the only known obsidian source in the Northern Caucasus — part of a rugged stretch of mountainous land straddling southern Russia and the Republic of Georgia.\nThe artifacts were found at sites up to 150 miles from Baksan and, based on style, were made by different, culturally distinct groups of Neanderthals. It’s the latest blow to the idea that Neanderthals were less mobile and less capable of networking than early modern humans.\nEkaterina Doronicheva, lead author of the paper and an archaeologist at the Laboratory of Prehistory in St. Petersburg, Russia, says the Baksan obsidian source was probably a zone of contact between different populations: “We can assume the existence of cultural contacts between these regions . . . and that local Neanderthal groups were part of developed social networks.”\nAs technology improves and archaeologists turn up additional sites, obsidian will remain the glass through which we see our deep history.\n“It’s a bit like being Sherlock Holmes,” says Frahm. “We are trying to wring every last bit of information out of these objects that were simply tossed aside in the past.”\nGemma Tarlach is senior editor at Discover. This story originally appeared in print as \"The Real Dragonglass.\""],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:b11eabc3-7f77-457e-92c8-8bc5020be7a2>","<urn:uuid:7dadf55a-b88b-49bb-8e16-af622bc0ab6b>"],"error":null}
{"question":"Which produces larger eggs relative to body size: the Brown-headed Cowbird or the Kiwi?","answer":"The Kiwi produces much larger eggs relative to its body size. A Kiwi egg may equal 15-20 percent of the female's body mass. In contrast, Brown-headed Cowbird eggs are smaller, allowing them to be successfully deposited in other birds' nests, where they often hatch a day before the host birds' eggs and the chicks grow to be two to three times larger than their foster parents.","context":["THE \"BLACK VAGABOND\"\nCome April each year, we're always delighted as the first spring migrants begin appearing at Hilton Pond Center. Blue-gray Gnatcatchers, Eastern Phoebes, Indigo Buntings, and Ruby-throated Hummingbirds are among our earliest arrivals, and there's always a big spike in the number of Chipping Sparrows visiting our feeders--although we haven't determined if these little rusty-caps migrate in or are local residents with sudden yearning for white millet. Another species that seems to crave millet is one whose presence we welcome because of its fine plumage but would rather not have around due to its lifestyle. We speak here of a \"Black Vagabond\"--the Brown-headed Cowbird--a social parasite whose proclivity for depositing eggs in other birds' nests can have significant impact on songbird populations.\nAll text & photos © Hilton Pond Center\nBrown-headed Cowbirds (male, above) have been seen around Hilton Pond in all months of the year, but never predictably nor in large numbers. During cold weather they tend to congregate with other blackbirds, so it's not unusual a few times each winter to have a flock of a thousand Common Grackles, Rusty Blackbirds, and cowbirds descend on the property to plow through dead leaves in search of seeds and invertebrates. Usually, about 95% are grackles and sometimes a few European Starlings are in the mix. When spring approaches, these foraging flocks disintegrate as former participants start hanging with their own kind. Most of the blackbirds eventually pair off, but Brown-headed Cowbirds have a different social system--one in which both sexes are promiscuous. In fact, we've found one of the best ways to catch male cowbirds is to use live females as bait. Many times a female in one of our ground traps have attracted the attention of a half-dozen or so males who got snared themselves when they tried to get at a potential mate.\nIt may be that a female cowbird (above) HAS TO have more than one male, for in a given breeding season she lays an egg a day for perhaps 10-12 days, takes a few days off and lays a dozen more, and then recycles once again before finishing with a total of up to three dozen eggs. This fecundity is much greater than typical passerines and is a significant accomplishment for a bird that doesn't even build a nest. It seems the female Brown-headed Cowbird is quite adept at watching another bird construct a nest into which she places her own cowbird egg before moving on to lay her next day's egg in some OTHER victim's nest. Indeed, the cowbird's scientific name alludes to this failure to establish its own nest as a home base and to its appearance; the generic name Molothrus means \"vagabond,\" while the species epithet ater is Latin for \"black,\" referring to body plumage of the male.)\nAlthough some birds remove cowbird eggs from their nests, many such as vireos and warblers simply incubate the cowbird egg with their own. The cowbird egg develops--often getting a head start by hatching a day ahead of its nestmates--and the cowbird chick quickly becomes the dominant bird in the brood. Since surrogate parents feed the aggressive cowbird first, it grows more rapidly and achieves maximum size--perhaps two or three times that of its foster mother and father. If you're a diminutive warbler, it may take all your energy to raise this giant, gluttonous interloper--especially since a cowbird fledgling (left) will continue to beg for food and might prevent foster parents from having a second brood. This scenario has caused birds such as the once-common Yellow Warbler to undergo significant population reductions--so much so that some songbird species have vanished from parts of their original range.\nBirdwatchers and environmentalists sometimes debate whether Brown-headed Cowbirds are \"native\" to the Carolinas, or whether human activity has drawn them in from elsewhere. We frequently refer to them as \"buffalo birds\" to emphasize they likely originated in the Great Plains, where they followed American Bison from place to place, eating insects stirred up by grazing herds. (As a reflection of this, Lewis and Clark referred to cowbirds as \"buffalo-peckers.\") However, there WERE expanses of prairie in the Carolina Piedmont--especially in the vicinity of the modern-day counties of York (SC) and Mecklenburg (NC); there also were a good many bison in the Carolinas prior to the arrival of European settlers. It's quite interesting that when the Brown-headed Cowbird was first described by science, the description was based on a specimen collected in South Carolina by early French explorers and written up by naturalist Louis-Jean-Marie Daubenton (1716-1800). He called the cowbird Troupiale, de la Caroline--the Carolina Oriole--an appropriate name because brightly colored orioles, like cowbirds, are in the Blackbird Family.\nEven before Daubenton, Mark Catesby in his 1731 edition of Natural History of Carolina, Florida, and the Bahama Islands rendered a female \"Cowpen Bird\"--shown above right with a male \"Towhe-bird.\" Catesby wrote:\nNOTE: We wonder if Catesby depicted together the Eastern Towhee (which he called Passer Niger, Oculis Rubris or \"black bird with red eye\") and the Brown-headed Cowbird (Passer Fusca or \"dusky bird\") because he thought they were somehow related. In reality, towhees are sparrows (Emberizidae) and cowbirds are blackbirds (Icteridae), but because both have black bills that are more or less conical, these two ground-feeding birds might look superficially similar.\nObviously, based just on the work of Catesby and Daubenton, there were at least small populations of cowbirds present in Colonial America, but we suspect across the eastern U.S. they are much more common today than 275 years ago. Humans have altered the landscape significantly, cutting down dense forest and replacing it with farmland and grazeland more suitable to cowbirds. Most important, habitat fragmentation has enabled cowbirds to enter areas where they did not occur historically; not only is there more space but now they can parasitize nests of new species they never encountered on the Great Plains or Piedmont Prairies. Unlike prairie nesters, these new victims--especially woodland breeders--did not evolve with cowbirds as social parasites, so they likely have no natural defenses against such parasitization.\nAlthough some birders have knee-jerk reactions against the cowbird's parasitic behavior, having the bird in the hand gives a different perspective. The seemingly black dorsal plumage of the male Brown-headed Cowbird becomes a metallic abstraction (above), with shades of cobalt blue and green glinting like gun steel. The female's back feathers (below)--more loosely structured--are drab by comparison, but even they have hints of greenish iridescence. Nonetheless, the overall mousey gray-brown color of the female cowbird undoubtedly makes her less noticeable as she spies on potential nests in which to place her eggs.\nSo how did Brown-headed Cowbirds become social parasites in the first place? One hypothesis is that following buffalo herds made cowbirds true wanderers; such a lifestyle interfered with nest-building and made it advantageous to be able to lay eggs that other species would end up tending. However, other kinds of birds also have been known to lay an egg in the nest of foster parents, and none of them follow grazing animal herds. It seems more likely social parasitism arose because gravid female birds have to put the egg somewhere; if a female is far from her own nest when her egg is ready--or if her nest was destroyed by a predator or weather--the female might seek out another's nest for the deposit. If her chick then survives under care of foster parents, over time such serendipitous egg-laying might become the norm and, eventually, a necessity. Any bird that lays an \"extra\" egg in the nest of another pair is technically a social parasite; cowbirds merely take the behavior to the extreme, including not ever building a nest of their own.\nThere's no question their non-nest-building lifestyle has enabled Brown-headed Cowbirds to do pretty well in a changing environment. Experts with Partners In Flight estimate there are 56 million cowbirds in the U.S., Canada, Mexico, and parts of the Caribbean, placing them in the category of \"Least Concern\" with regard to survivability. And many cowbird individuals are assertive--witness our need to wear a leather glove to photograph one especially aggressive male (below left)--which means they get at least their share of food when they flock together with other blackbirds and starlings. Females are careful observers of other species when they need nests in which to lay their eggs, but cowbirds are even more resourceful than one might think--as discovered recently by Jeffrey Hoover and Scott Robinson. The two ornithologists described a \"cowbird mafia,\" i.e., female cowbirds that \"trash\" nests from which the host bird has removed a cowbird egg. Such behavior \"encourages\" protective host birds not to mess with a cowbird egg lest their own future progeny get roughed up. Furthermore, some female cowbirds destroy a nest and steal the host's eggs BEFORE laying their cowbird eggs, thereby forcing the host to build a new nest. Since second clutches are typically smaller, this may mean fewer host bird nestlings are present to compete when the cowbird finally lays her own egg in the newly constructed nest.\nLove 'em for the color and unusual gurgling song, or hate 'em because they lay eggs in the nests of other birds, one has to admire Brown-headed Cowbirds for their resourcefulness and survival skills. With 56 million of them scattered around the Western Hemisphere, we suspect they are here to stay, so we might as well study them a little more closely to see what other secrets they might reveal. To that end we've banded 361 cowbirds at Hilton Pond Center since 1982, with 90 of those captured between January and June 1988; none ever returned in a later year or showed up elsewhere.\nOne thing we wonder is whether--with all those male cowbirds trying to breed promiscuously with all those females--who actually gets to mate? Can younger, second-year males--identifiable in-hand by the pale and sometimes ragged condition of their underwing coverts (above)--still impress a female when they spread their wings in courtship display, or do only older males have the right moves to win over a female long enough to copulate? To us these are interesting questions whose answers might be easier to acquire at Hilton Pond if our Brown-headed Blackbirds weren't such vagabonds with no place they call home.\nAll text & photos © Hilton Pond Center\nComments or questions about this week's installment?\nBe sure to scroll down for an account of all\nThanks to the following fine folks for recent gifts in support of Hilton Pond Center for Piedmont Natural History and/or Operation RubyThroat: The Hummingbird Project. Your tax-deductible contributions allow us to continue writing, photographing, and sharing \"This Week at Hilton Pond.\"\nIf you ever shop on-line, you may be interested in becoming a member of iGive, through which nearly 700 on-line stores from Barnes and Noble to Lands' End will donate a percentage of your purchase price in support of Hilton Pond Center and Operation RubyThroat. We've just learned that for every new member who signs up and makes an on-line purchase within 45 days iGive will donate an ADDITIONAL $5 to the Center. Please sign up by going to the iGive Web site. It's a painless and important way for YOU to support our work in conservation, education, and research.\n\"This Week at Hilton Pond\" is written & photographed\nYou may wish to consult our Index of all nature topics covered since February 2000. You can also use our on-line Hilton Pond Search Engine at the bottom of this page.\nFor a free, non-fattening, on-line subscription to\nMake direct donations on-line through\nNetwork for Good:\nLIKE TO SHOP ON-LINE?\nDonate a portion of your purchase price from 500+ top on-line stores via iGive:\nUse your PayPal account\nto make direct donations:\nFreeze Damage at Hilton Pond\nAll text & photos © Hilton Pond Center\nSPECIES BANDED THIS WEEK:\n* = New species for 2007\nWEEKLY BANDING TOTAL\nYEARLY BANDING TOTAL (2007)\n26-YEAR BANDING GRAND TOTAL\nNOTABLE RECAPTURES THIS WEEK\nChipping Sparrow (2)\nAmerican Goldfinch (7)\nNorthern Cardinal (4)\nEastern Towhee (1)\nHouse Finch (1)\nDowny Woodpecker (1)\nWhite-throated Sparrow (1)","The egg has long been a symbol of rebirth and renewal, which goes a long way toward explaining the connection between eggs and the holiday of Easter. In honor of the upcoming Easter holiday, I thought I’d devote this week’s column to some “egg-citing” egg trivia. I’ll try to avoid any additional “egg-sasperating” puns.\nOf course, the familiar Easter egg has traditionally been provided by chickens, although the eggs of other birds, such as ducks, geese and turkeys, are occasionally incorporated into such festivities as egg fights and egg hunts.\nProducing eggs encased in a thin calcium shell is one of the ways that the birds are different from other lifeforms. For example, mammals carry their eggs inside the body with the exception of the oddball echidnas and the platypus. Amphibians lay eggs, but their eggs are soft and must usually be deposited in the water to ensure they do not dry out. Insects also lay eggs. It’s only the birds, however, and a few reptiles that have evolved the hard-shelled egg as a more durable means of reproduction.\nThe shape and size of those eggs varied greatly. Among the world’s 10,000 species of birds, the ostrich lays the largest eggs of any bird. Closer to home, the California condor almost certainly lays the largest eggs of any U.S. bird species. According to the website, All About Birds, eggs of the California Condor eggs are about 4.5 inches long and almost 3 inches wide. These whopper eggs weigh about 11 ounces. By contrast, a large chicken eggs weighs only two ounces.\nThe eggs produced for one nesting attempt are referred to as a clutch. The number of eggs per clutch varies among different species. Among songbirds, some rather small birds lay large clutches of eggs. For instance, the kinglets, which are tiny birds barely bigger than hummingbirds, are champion egg layers. The ruby-crowned kinglet can lay as many as a dozen eggs in a clutch, while the golden-crowned kinglet may lay as many as 11 eggs per clutch. The house wren, which is also a rather diminutive bird, can lay as many as 10 eggs. Several North American wrens produce large clutches of eggs. The marsh wren and sedge wren are known to lay as many as 10 eggs per clutch. The winter wren is almost their equal with clutch sizes that can include nine eggs. Of course, these same birds may lay more average clutches of between three and six eggs.\nThe sora, a small, secretive species of rail, lays 10 to 12 eggs in a nest well-concealed in marsh vegetation. The sora has been known to produce exceptional clutches with as many as 18 eggs.\nWaterfowl are known to be good egg layers. The mallard hen may lay a clutch of eight to 13 eggs. The redhead hen typically lays only seven to eight eggs, but has parasitic tendencies that include depositing some eggs in the nests of other redheads. On occasion, multiple redhead hens get a little compulsive about slipping their eggs into a communal “dump” nest. These type of nests have been found containing as many as 80 or more eggs, but such clutches are impossible for a single hen to incubate and the eggs are usually lost. The wood duck, which will nest in specially designed bird houses placed near a source of water, can lay as many as 14 eggs in a single clutch.\nOther birds concentrate their efforts on laying only a single egg or perhaps a pair of eggs. Many species of albatross lay only a single egg. The parents will dedicate a long period incubating the egg and then tend to the needs of the solitary offspring once the egg hatches.\nHummingbirds typically lay a pair of eggs. The poor female is soon abandoned by her mate and must build a nest, incubate her two eggs, and care and feed her young without any paternal assistance whatsoever. Hummingbirds, having high metabolisms, would find it impossible to feed themselves and any more than two young in a nest.\nPenguins lay only a few eggs. Many species lay a pair of eggs, but the king penguin and emperor penguin are single-egg producers. In their harsh environment, these penguins would find meeting the needs of more than one offspring at a time quite impossible.\nLet’s talk color. Eggs come in a variety of colors. Some eggshells also feature intricate patterns and splotches.\nThe killdeer, which usually lays four eggs, produces buff-colored eggs with dark mottling on the shell. These eggs blend remarkably with gravel and other rocks, which helps the ground-nesting killdeer hide their nests from would-be predators.\nThe American robin is famous for producing a clutch of beautiful blue eggs. The coloration of the eggs have even given rise to the descriptive phrase “robin’s egg blue.” This particular shade of blue is described as a variable one that leans to greenish-blue that is paler than turquoise and more blue than aqua.\nThe American robin’s blue eggs are not unusual among the thrushes, the group of birds of which the robin can claim kinship. For instance, the Eastern bluebird’s eggs are pale blue or sometimes white. The wood thrush produces eggs that are more to the turquoise shade of blue while the veery’s eggs can vary between green and pale blue.\nThe blue tint to the eggs of robins and other thrushes is caused by a pigment that gets applied to the shell as the female lays the eggs. It’s like the female robin has an internal egg-dyeing mechanism. In an article published in May of 2012, Science Daily reported that a study conducted by Queen’s University also found that the brighter blue the egg, the more the male robin will apply himself to caring for his offspring.\nAmong the birds that use my birdhouses for nesting, I’ve always thought the eggs of Carolina chickadees are exquisite. The eggs are pale white with a hint of pinkish coloration. A fine mottling of brown spots dot the shell. The amount of mottling can vary from egg to egg in the same clutch. These tiny eggs produced by a tiny bird are kept safe and sound in a nest of moss and other plant materials with a soft lining of animal hairs. Chickadees lay between three and 10 eggs, but between five and eight eggs per clutch seems more usual.\nAs mentioned, the ostrich lays the largest egg. Ostrich clutches are also impressive. The wild African ostrich, the largest bird in the world, lays 12 to 18 eggs. The ostrich has been domesticated, however, and hens have been conditioned to produce more eggs than would ever be expected in the wild.\nThe ostrich belongs to the ratite family, which includes other large birds such as the emu, rhea and cassowary, as well as five species of kiwi, which are considerably smaller than other ratites. The kiwi does have one interesting claim to fame when it comes to eggs. Kiwi are notable for laying eggs that are extremely large in relation to their body size. A kiwi egg may equal 15 to 20 percent of the body mass of a female kiwi. Perhaps not surprisingly, most kiwis lay only a single egg per clutch. The brown kiwi, however, normally lays two eggs per clutch.\nAepyornis, which was a giant, flightless ratite native to Madagascar and now extinct, produced the largest egg of any bird. Also known as the elephant bird, Aepyornis produced an egg with a volume equal to slightly more than 150 chicken eggs. These giant eggs boasted a circumference of 3 feet, 3 inches and reached about 13 inches in length. Research indicates that humans drove these enormous birds into extinction. One theory is that humans feasted so heavily on the giant eggs produced by Aepyornis that the birds were unable to sustain their species.\nHumans have long turned to eggs as a source of nourishment, but we do not feed exclusively on eggs. Animals that feed primarily on eggs are classified by experts as ovivores. Some ovivores include fish, snakes, insects and, yes, birds. Some birds have become quite adept at preying on the eggs of other birds. Blue jays and American crows are known for robbing nests for both eggs and nestlings of other birds.\nThe bird egg has become firmly interwoven into human culture and traditions. According to the website Aghires.com, estimates indicate that about 180 million eggs are purchased each year in the United States specifically for the Easter holiday. Chicken hens must feel really overworked at this time of the year.\nOf course, there are also the Easter traditions of chocolate and peanut butter eggs. I suppose that eases the pressure slightly on the overworked hens.\nI’m reminding readers that I want to hear from them when they see their first hummingbird of spring. Email me your observations at firstname.lastname@example.org or post them on my Facebook page at http://www.facebook.com/ahoodedwarbler. Please include the date and the approximate time of your sighting.\nObservations will be accepted through Sunday, April 18. Winners will be announced in this column on April 28."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:93782998-674e-4ce7-b7e3-38dc16fe7ad9>","<urn:uuid:a8250970-9e4c-41e5-bc28-e7b7b1a21677>"],"error":null}
{"question":"How is acromial apophysiolysis treated in adolescent athletes?","answer":"Treatment of acromial apophysiolysis in adolescents begins with conservative measures, including a rest period of 2-3 months with complete cessation of pitching or other sports activities. This is combined with physical therapy with ice and oral anti-inflammatory drugs. If these conservative measures fail, operative treatment may be considered. Open reduction and internal fixation has been successfully performed in competitive adolescent athletes with os acromiale. Additionally, anterior acromial bone fragments have been successfully removed through arthroscopic surgery.","context":["Clinical History: A 16 year-old female presents with shoulder pain and stiffness for 2 months. The symptoms are getting worse. She reports no specific injury. The pain started when she increased her softball activities and overhead weightlifting. What are the findings? What is your diagnosis?\nAcromial apophysiolysis (os acromiale in an adolescent)\nThe growth plates of the upper extremities in pitchers and other athletes are susceptible to injury and repetitive stress, such as in little leaguer’s shoulder and elbow, which may lead to deformity, chronic pain and disability. Repetitive traction forces related to pulling of the deltoid on the developing acromion may result in failure of fusion of the acromion, also known as acromial apophysiolysis, and formation of an os acromiale which may or may not be symptomatic.1 The diagnosis of an os acromiale is not commonly made in patients younger than 25 years, because it has been thought that the age range of acromial fusion is from 18 to 25 years.2 Other studies have shown that the acromion is fused in most children by the age of 16 years.3 It is therefore possible to develop an os acromiale at a younger age than what has generally been thought, which has important implications for imaging diagnosis and treatment.\nDifferentiation between the normal developing acromion and stress changes at the acromial growth plate on MR imaging can be challenging. This Web Clinic showcases the main differences and pitfalls in diagnosis.\nEpidemiology and clinical presentation\nAcromial apophysiolysis was reported in 2.6 % of patients aged 15-25 years presenting with shoulder pain in a recent study.1 In another study which included only adolescents, 8 % of the patients had similar findings.4 Risk factors include repetitive stress and especially throwing more than 100 pitches per week (baseball in male patients and softball in female patients).1 Other athletes such as competitive swimmers and football players are also at risk.5,6 The patients typically present with superior shoulder pain and/or tenderness over the acromion.1\nNormal development of the acromion on MRI\nIn younger children, <10 years old, the acromial process has the same shape as those of older children and adults, but has homogeneous signal similar to cartilage (Fig. 3). The relatively large portions of the acromion and distal clavicle that are not yet ossified could give the false appearance of acromioclavicular separation on radiographs (Fig. 4). The ossified portion of the acromion is often hyperintense on water sensitive MR images due to the presence of a high concentration of red marrow, which could be misinterpreted as marrow edema.7\nIn children aged 10-14 years, the ossification of the acromion takes place in an asymmetrical fashion with the leading anterior margin of the ossification being U-shaped on axial images (Fig 5). The chondro-osseous junction has a lobulated configuration.7\nThe secondary ossification centers of the distal acromion vary in number, and appear between the ages of 10 and 14 years. The individual centers can be difficult to evaluate due to their small size, irregular margins, and partial volume averaging. Usually, they form in the anterior and lateral aspects of the cartilaginous acromial process and have signal similar to fat on MRI (Fig. 6,7).7 The heterogeneous signal on MRI in the region of normal ossification centers should not be mistaken for an acromial fracture, which is typically associated with marrow edema (Fig.8).\nGradually, as the centers coalesce, there are three major foci of ossification which form: the preacromion, the mesoacromion and the meta-acromion (Fig.9). Detailed analysis of the ossification and fusion of the acromion in anatomic studies and with MRI has revealed an arrangement that is somewhat different from the original theory of the side by side, parallel orientation of ossification centers.4,8 Initially, the fusion of the preacromion and the mesoacromion takes place, followed by the fusion of the meta-acromion and the basi-acromion.8\nComplete fusion occurs by the ages of 18-25 years according to most studies; however some study reported complete fusion in most children a few years earlier. Overall, the skeletal maturation in girls is earlier than in boys.\nA special region of interest is the interface where the primary and secondary ossification centers of the acromion fuse, because this is a site of potential failure of fusion and formation of an os acromiale. The normal boundary between the secondary ossification centers and the rest of the acromion is normally curved and lobulated. It typically extends obliquely and posterolaterally into the acromion towards the posterior angle (Fig. 10), because of a differential growth pattern. A thin physeal scar is sometimes present at the site of fusion and is easily differentiated from a fracture in most cases due to the absence of marrow edema (Fig. 11).\nMRI findings of acromial apophysiolysis\nThe diagnosis of failure of fusion of the acromion in an adolescent can be challenging. Shoulder radiographs may be normal or show only mild contour irregularity and sclerosis of the acromion at the growth plate. MRI allows more detailed analysis, especially on axial images, regarding the orientation and margins of the growth plate, as well as the marrow signal. In apophysiolysis, the growth plate tends to be linear and transversely oriented with irregular margins (Fig. 12), whereas in the normally developing acromion the growth plate is arched and oblique, and has uniform, lobulated margins (Fig. 10).4 Marrow signal alterations in acromial apophysiolysis include diffuse marrow edema and small foci of hyperintense signal on water sensitive images adjacent to the growth plate (Fig 12, 13). Marrow edema at an unfused ossification center (os acromiale) has been shown to be more common in adults than in teenagers, which may reflect a greater degree of instability of the ossicle in adults.4 The nature of the focal regions of signal abnormality is unclear, but is thought to be related to displaced growth cartilage. The most common level of failure of fusion is between the meta-acromion and mesoacromion. A less frequently seen level of failure is at the distal acromion, between the mesoacromion and preacromion.9\nFollow up imaging after a minimum of 2 years in a group of patients diagnosed with acromial apophysiolysis showed development of an os acromiale in 86 %. It was not clear from the study if the ossicles were unstable.1\nThe subsequent risks of shoulder impingement and rotator cuff tears are discussed in the Radsource Web Clinic, August 2007.\nTreatment of adolescents with acromial apophysiolysis/os acromiale consists of conservative measures such as rest for a period of 2-3 months with cessation of pitching or other sports activity, physical therapy with ice, and oral anti-inflammatory drugs.1,5 If refractory to conservative measures, operative treatment may be considered. Open reduction and internal fixation has been performed successfully in competitive adolescent athletes with os acromiale.6,10 In addition, anterior acromial bone fragments have been excised arthroscopically with good results.11\nNormal red marrow in the acromion in young children may be misinterpreted as marrow edema. The irregularity of individual secondary ossification centers, heterogeneous signal of coalescing ossification centers and physeal scars may present additional pitfalls.\nAcute injury to the acromion resulting in acromial contusion and even fractures may resemble the imaging findings in acromial apophysiolysis/os acromiale.\nAcute injury to the acromioclavicular joint in a teenager is often associated with diffuse marrow edema which may simulate the MR imaging appearance of acromial apophysiolysis in the setting of an open acromial growth plate (Fig 14 ).\nThe MR imaging findings of the developing acromion can be confusing due to the presence of a number of secondary ossification centers that vary in morphology and timing of fusion. Recent studies have shown normal fusion of the acromial apophysis at a younger age (16 years) than was previously considered (18-25 years), thus an acromial ossicle should not be generally ignored and called normal in adolescents. Insult to the immature acromion such as repetitive stress in a teenage athlete can result in a delay of or even complete failure of fusion with development of an unstable os acromiale, which is associated with shoulder impingement and rotator cuff tears. Knowledge of the normal stages of the acromial development and abnormalities that occur with physeal stress injury on MR imaging will aid in the prompt and accurate diagnosis, as well as treatment of these patients.\n- Roedl JB, Morrison WB, Ciccotti MG, Zoga AC. Acromial apophysiolysis: superior shoulder pain and acromial nonfusion in the young throwing athlete. Radiology 2015;274(1): 201–209. ↩\n- Scheuer L, Black S, Christie A. The pectoral girdle. In: Developmental juvenile osteology. San Diego, CA: Elsevier Academic Press, 2000; 244–271 ↩\n- Flecker H. Roentgenographic observations of the times of appearance of epiphyses and their fusion with the diaphyses. J Anat 1932;67(pt 1):118–164.3. Medline ↩\n- Winfeld, Matthew, et al. “Differentiating os acromiale from normally developing acromial ossification centers using magnetic resonance imaging.” Skeletal radiology 44.5 (2015): 667-672. ↩\n- Frizziero, Antonio, et al. “Painful os acromiale: Conservative management in a young swimmer athlete.” Journal of sports science & medicine 11.2 (2012): 352. ↩\n- Sassmannshausen, G., T. C. Wilson, and S. D. Mair. “Operative stabilization of an unstable os acromiale in an adolescent football player.” Orthopedics 26.5 (2003): 509. ↩\n- Kothary, Pratik, and Zehava Sadka Rosenberg. “Skeletal developmental patterns in the acromial process and distal clavicle as observed by MRI.” Skeletal radiology 44.2 (2015): 207-215. ↩\n- Macalister, Alexander. “Notes on acromion.” Journal of anatomy and physiology 27.Pt 2 (1893): 244-1. ↩\n- Liberson, Frank. “Os acromiale—a contested anomaly.” The Journal of Bone & Joint Surgery 19.3 (1937): 683-689. ↩\n- Demetracopoulos, Constantine A., et al. “Surgical stabilization of os acromiale in a fast-pitch softball pitcher.” The American journal of sports medicine 34.11 (2006): 1855-1859. ↩\n- Pagnani, Michael J., Chad E. Mathis, and Corey G. Solman. “Painful os acromiale (or unfused acromial apophysis) in athletes.” Journal of shoulder and elbow surgery 15.4 (2006): 432-435. ↩"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:3eba7e4b-56f7-453f-830b-a520e7471541>"],"error":null}
{"question":"How do face offs work differently in men's vs women's lacrosse?","answer":"In men's lacrosse, face offs involve two squatting players at the center of the field with the ball placed between their sticks. Wing area players can release when the whistle blows, while other players must wait until possession is gained or the ball crosses the goal line. In women's lacrosse, it's called a 'draw' where two centers have their sticks pressed together back-to-back with the ball between them. When the umpire calls 'draw', they push the ball up and out while players around the circle (attack wings, defense wings, 3rd Homes and 3rd Men) sprint for the descending ball.","context":["Face Off Terms\nLINE UP – This term represents the pre-game lining up of starting teams on the field. Each team lines up across from one another, with their left shoulder facing the side of the field being defended. The goalies will stand with his back to the goal he is defending, and the referee will instruct the goalies to meet at mid-field to shake hands. After this the players take their position for the face-off.\nMARK UP – Lining up directly next to your opponent on the face-off wing, with the intention of defending the other player and not allowing him to get an easy ground ball.\nPLAY UP – Lining up on the offensive half of the face-off wing. The intention of this alignment is to put us in a position to start a fast break opportunity off the face-off.\nPLAY DOWN – Lining up on the defensive side of the face-off wing. The intention of this alignment is generally to prevent a fast break by the opponent.\nSTRONG SIDE – Represents the rake side (left side) of the face-off man or the ball carrier.\nWEAK SIDE – Represents the right side of the face-off man or the ball carrier.\n1-3-2 – This will be our general offensive setup. In this structure there will be 2 Midfielders near the top of the restraining box, and one on the crease. The Attackmen will be set up with one at X (X is the attack position directly behind the goal) and one each on either side of the goal, about 10 yards off the goal pipe and 2 yards above the goal from the GLE. Other common offensive formations from X are 1-4-1 and 2-1-3\nCREASE – This is the circular line surrounding the goal, and is intended to protect the goalie. No offensive player is ever allowed inside this area; the result is a change of possession or the negation of score. Defensive players may run through the crease, for example when covering their men, but not if they have possession of the ball.\nCUT/POP/V-CUT – The act of making a move on the defender for the purpose of getting open for a pass. This usually entails stepping toward the defender to make him move one way, then quickly popping away in the opposite direction, at a slant, to create space to easily get open and catch the ball.\nDODGE – This is the act of making as move with the ball. A dodge can be used to simply change direction while in possession of the ball, or to make a move to the goal by attempting to beat your defender.\nFEED – The act of passing to an open or cutting teammate for the purpose of assisting on a goal.\nGOAL LINE EXTENDED (GLE) – This stands for Goal Line Extended. It’s the theoretical line that extends from the goal line to the sideline.\nISO – Short for isolation, this is the act of intentionally drawing your defender away from the goal with the intent to beat him one-on-one to become a shooter or feeder.\nPICK – This is the act of stepping in front of the defender of another player so that your teammate can get open for a pass & shot. As is basketball, a moving pick is a violation.\nSHOW – This term is an instruction for the named player or position to get in a better position to receive a pass or to appear to be in position to defend.\nX – This represents the area directly behind the goal, and is a common area for attackers to initiate scoring opportunities.\n“GET IN THE HOLE” – The coach will call this when we’re playing defense in an unsettled situation and he wants all defenders to sprint back to the inside of the restraining box in front of the goal (the hole) and play defense “inside / out”. (See the philosophy section for explanation on “Inside / Out”)\n“NUMBER UP” – All defensive players should call out the number of the man they are covering.\n“I’VE GOT BALL” – This should always be called out by the defender who is covering the man with the ball.\nOFF BALL DEFENDER- These are the defenders closest to the ball carrier, but not defending the ball carrier. If you are an Off Ball Defender, you must be prepared to do two things: TALK (tell the ball defender where you are) and SLIDE (get ready to cover the ball carrier if he beats our defender).\n“BACK LEFT”– This should always be called out by the Off Ball Defender who is left of the man covering the ball. “Help Left” should be called repeatedly to ensure the defender of the ball that he has back-up to his left in the event he gets beat.\n“BACK RIGHT” – This is the same concept for the Off Ball Defender to the right side of the man covering the ball. Call out “Help Right” repeatedly.\n“STICKS UP” - All defenders should play with their sticks in the air blocking passing lanes. The coach will call this if he senses that the defense is playing with sticks facing the ground or at the side.\n“CLEAR THE CREASE” – Called out by the goalie and indicates that there is a ground ball in the crease area and all opponents should be physically (and legally) cleared out so that we or the goalie can get possession of the ground ball.\n“CUTTERS/CHECK STICKS” – This indicated that someone is making a cut through the crease area with the intent to receive a pass and score. Crease defenders should be ready to check the stick of their opponent when this is called. Stick and body checks are legal if done within 5 yards of the ball without slashing. At the youth level body checks resulting in a player being knocked to the ground are illegal.\n“DROP-IN” – You are playing your man too far from the goal. You should back off your man and put yourself in a position to slide and help your teammates.\n“HOLD” – The goalie will call this when an offensive player with the ball is getting too close to the goal and is a potential shooter. This call should alert the ball defender to force the ball carrier out of shooting range.\nRED “#” – This will be called when the coach wants the man covering the ball to aggressively defend the man with the ball with the intent to take the ball away. The coach will call RED and then the number of the defender guarding the man with the ball. Example: RED 4 (#4 defends his man and the adjacent defenders shut down the outlet passes). The defenders adjacent (right & left) to the man covering the ball should shut down their men, closely defending them with the intent of keeping them from getting a pass from the man with the ball.\n“SLIDE” – This is the act of leaving your man to defend the ball if the defender adjacent to you was covering the ball and has been beat. This term also applies to filling in for a fellow defender who has left his man to play the ball.\n“I’M HOT” –This is what the defender should call to indicate he will be making the slide.\n“BOX in ONE” – This will be our general man down defense – when we lose a player to a penalty and have a 6 on 5 situation (or worse). We will often have 4 long sticks and 1 short stick on our Man Down Defense. BOX stands for having the 4 long sticks forming a square in front of the crease with a defender in the top Right, Top Left, Bottom Right and Bottom Left positions. ONE stands for having the short stick in the center of the box covering potential cutters and any offensive player standing in the crease area (usually called “String”).\nTransition Game Terms\n“BREAK!” or “CLEAR!” – This is called out by the goalie after a save is made. It should alert all players to break out for an outlet pass now that we have possession.\nRIDING – This is the concept of defending the opposing team after they gain possession in their defensive half of the field by a change of possession or after a save by the opponent’s goalie.\nCLEARING – This is the concept of getting the ball out of the defensive zone into our offensive half of the field after a change of possession or save by our goalie.\n“GET IN THE HOLE!” – The coach will call this when we’re playing defense in an unsettled situation and he wants all defenders to sprint back to the inside of the restraining box (the hole) and play defense “inside / out”. (See the Defensive Philosophy section for explanation on “Inside / Out”)\n“[I GOT] BALL” – The ball is on the ground and you’re going to go after it.\n“[I GOT] MAN” – The ball is on the ground and you are playing the man to give your teammate a better opportunity to get the ground ball.\nMAN UP/MAN DOWN – This describes the situation where a team needs to play minus one player for a period of time due to a penalty. Technical fouls are served for 30 seconds and personal fouls one minute. Other infractions such unsportsmanlike conduct or an illegal stick can result in longer penalties the discretion of the official(s).\nMIDDIES! – Hearing this indicates that we want to substitute our midfield line. If you are a midfielder, hustle on/off the field.","Your Guide to the Fastest Game on Two Feet\n- ATTACK: The attackman's responsibility is to score goals. He generally restricts his play to the offensive end.\n- MIDFIELD: The midfielder's responsibility is to cover the entire field playing both offense and defense.\n- DEFENSE: The defenseman's responsibility is to defend the goal. He generally restricts his play to the defensive end of the field.\n- GOAL: The goalie's responsibility is to protect the goal and stop the opposing team from scoring.\nMen's lacrosse is a contact game played by ten players: a goalkeeper, three defensemen, three midfielders and three attackmen. The object of the game is to shoot the ball into the opponent's goal. The team scoring the most goals wins.\n- Each team must keep at least four players, including the goalie, in its defensive half of the field and three in its offensive half Three players (midfielders) may roam the entire field.\n- Generally, high school games are 48 minutes long, with 12 minute quarters. Each team is given a two minute break between the first and second quarters, and the third and fourth quarters. Halftime is ten minutes long.\n- Teams change sides between periods. Each team is permitted two timeouts each half. The team winning the coin toss chooses the end of the field it wants to defend first.\n- Men's lacrosse begins with a face-off. The ball is placed between the sticks of two squatting players at the center of the field. The official blows the whistle to begin play. Each face-off player tries to control the ball. The players in the wing areas can release; the other players must wait until one player has gained possession of the ball or the ball has crossed the goal line.\n- Center face-offs are also used after a goal and at the start of each quarter.\n- Players may run with the ball in the crosse, pass and catch the ball. Only the goalkeeper may touch the ball with his hands.\n- A player may gain possession of the ball by dislodging it from an opponent's crosse with a stick check, which includes the controlled poking and slapping of the stick and gloved hands of the player in possession of the ball.\n- Body checking is permitted if the opponent has the ball. However, all contact must occur from the front or side, above the waist and below the shoulders. An opponent's crosse may also be stick checked if it is within five yards of a loose ball or ball in the air.\n- If the ball or a player in possession of the ball goes out of bounds, the other team is awarded possession of the ball. If the ball goes out of bounds after an unsuccessful shot on goal, the player nearest to the ball when and where it goes out of bounds is awarded possession.\n- An attacking player cannot enter the crease around the goal, but may reach in with his stick to scoop a loose ball\nThe penalty for a personal foul is a one to three minute suspension from play and possession to the team that was fouled. Players with five personal fouls are ejected from the game.\nSLASHING: Occurs when a player's stick contacts an opponent in any area other than the stick or gloved hand on the stick.\nTRlPPlNG: Occurs when a player obstructs his opponent at or below the waist with the crosse. hands. arms. feet or legs.\nCROSS CHECKING: Occurs when a player uses the handle of his crosse to make contact with an opponent.\nUNSPORTSMANLIKE CONDUCT: Occurs when any player or coach commits an act which is considered unsportsmanlike by an official, including taunting. obscene language or gestures. and arguing.\nUNNECESSARY ROUGHNESS: Occurs when a player strikes an opponent with his stick or body using excessive or violent force.\nILLEGAL CROSSE: Occurs when a player uses a crosse that does not conform to required specifications. A crosse may be found illegal if the pocket is too deep or if the crosse was altered to gain an advantage.\nILLEGAL BODY CHECKING: Occurs when any of the following actions take place: (a) body checking of an opponent who is not in possession of the ball or within five yards of a loose ball: (b) avoidable body check of an opponent alter he has passed or shot the ball; (c) body checking of an opponent from the rear or at or below the waist; (d) body checking of an opponent by a player in which contact is made above the shoulders of the opponent. A body check must be below the neck, and both hands of the player applying the body check must remain in contact with his crosse.\nILLEGAL GLOVES: Occurs when a player uses gloves that do not conform to required specifications. A glove will be found illegal if the fingers and palms are cut out of the gloves, or if the glove has been altered in a way that compromises its protective features\nThe penalty for a technical foul is a thirty second suspension if a team is in possession of the ball when the foul is committed. or possession of the ball to the team that was fouled if there was no possession when the foul was committed.\nHOLDING: Occurs when a player impedes the movement of an opponent or an opponent's crosse.\nINTERFERENCE: Occurs when a player interferes in any manner with the free movement of an opponent, except when that opponent has possession of the ball, the ball is in flight and within five yards of the players, or both players are within five yards of a loose ball.\nOFF SIDES: Occurs when a team does not have at least four players on its defensive side of the midfield line or at least three players on its offensive side of the midfield line.\nPUSHING: Occurs when a player thrusts or shoves a player from behind.\nSCREENING: Occurs illegally when an offensive player moves into and makes contact with a defensive player with the purpose of blocking him from the man he is defending.\nSTALLING: Occurs when a team intentionally holds the ball. without conducting normal offensive play, with the intent of running times off the clock.\nWARDING OFF: Occurs when a player in possession of the ball uses his free hand or arm to hold, push or control the direction of an opponent's stick check.\nWhat is the object of lacrosse?\nThe object is to put the ball into your opponent's goal.\nHow does the game begin?\nA lacrosse game begins with a face off at the mid-field line at the X spot in the center of the field.\nWhat is a face off?\nA face off consists of the two center players at the mid-field line crouching down and placing their sticks on the ground so that the heads of the sticks have their backs to each other. The official then places the ball on the ground between the heads of the sticks, steps back and blows a whistle which signals to the players they can fight for possession of the ball.\nWhen are face offs used?\nAt the beginning of a game, at the beginning of each quarter and after each goal is scored.\nHow many men are there on a lacrosse team?\nSquads range from 25 to 30 men normally.\nHow many men are there on the field for one team?\nThere are ten men consisting of one goaltender, three defense men, three mid-fielders, and three attack men.\nWhat are the goaltender's special privileges?\nHe uses the largest stick on the field with a maximum width of 12 inches. He is the only one allowed to use a stick this large. He cannot be checked if he has gained possession of the ball within the crease are nor is an opponent allowed in the crease area.\nWhat is defined as \"in the crease area\"?\nA goaltender is considered in the crease as long as he has one foot on or within the 18-foot diameter circle. If he lifts his foot up and puts t back down while in the possession of the ball, it is called \"out and in\" and he loses possession of the ball.\nHow long can a goaltender stay in the crease with the ball?\nA goaltender has four seconds to step out of the crease or throw the ball to a teammate. If he does not do this, he loses possession of the ball.\nTHE LACROSSE FIELD\nWhat is the mid-field line?\nThis line divides the field exactly in half. At the beginning of a game, at the beginning of each quarter and after each goal is scored, the ball is faced off at the mid-field line at the X spot.\nWhat are the wing areas?\nThese two lines indicate where the two outside mid-fielders must stay until the official blows his whistle to start a face off.\nWhat is the crease area?\nA goal crease is a circle 18 feet in diameter that marks an area where an offensive player can never enter under any circumstances except one.\nWhat is the one exception that allows an offensive player to enter the crease area?\nIf an offensive ball player should fall into the crease such that he lands with his feet outside the crease and both hands on his stick within the crease in a push up position he may then get up and out of the crease with no stoppage of play.\nWhat are the restraining areas?\nThese areas mark where all the players other than the three players who are the mid-field line must stay in during a face off until either team has gained possession of the ball. In the defense restraining area there are three defense men plus the goaltender. In the offensive area there are three attack men. Leaving the restraining areas before the referee signals possession will result in loss of the ball.\nHow big is a lacrosse goal?\nThe front of a lacrosse goal is a perfect square, six feet by six feet.\nHow To Play Women's Lacrosse\n- A game begins when the two centers from each team \"draw\" at the center of the field: a ball is placed between their two sticks pressed together back-to-back. When the umpire calls \"draw,\" the centers attempt to control the ball when they push the ball up and out of the circle -- the area around the face-off. (Think of the tip-off in basketball.)\n- Then, the players around the circle -- usually the attack wings, defense wings, 3rd Homes and 3rd Men from both teams -- sprint for the descending ball. Once control is attained by a team, it works pretty much like some other sports: players run and pass the ball to push it down field toward the goal.\n- Cradling is the method by which a player holds the ball in the stick's pocket. Unlike men's lacrosse, women's sticks may not have a deep pocket in which to hold the ball securely; a player \"cradles\" the ball to keep it in the pocket. Cradling uses centripetal force -- the force generated by moving something in a circle -- to press the ball into the back of the pocket. (You can feel centripetal force at the amusement park when a ride spins and pushes you out from the axis around which you're turning.)\n- To learn to cradle, hold a pen or pencil with your right fist around the top, and the left hand around the bottom (for lefties, reverse it -- left hand on top.) Now bring both fists and the pen to your right shoulder, keeping the pen vertical. Then bring it to your left shoulder, keeping the pen vertical. Although you won't be able to see the centripetal force at work using this example, very basically, this is cradling.\n- When a player has an opening to the goal, she shoots the ball by pushing the head of the stick forward, and pulling the the shaft back. The shots can be extremely accurate and fast.\n- Passing is the fastest way to get the ball down field, but it can also be one of the hardest things to do. Releasing the ball with speed and accuracy can take LOTS of practice to make it effective.\n- Passing is done in the same manner as shooting, but catching the pass is often the hardest part. Not only does the ball have to land in your stick, but you must also learn to put the catch immediately into a cradle to gain control of the ball and prevent yourself from being checked.\n- Checking is the technique in which a series of short, sharp, controlled strikes to an opponent's stick is used to force a player carrying the ball to drop it.\n- A player can check the head or shaft of the stick, or body check.\n- Body checking sounds like a player would strike an opponent's body, but it's actually accomplished when a defender sticks close to her opponent in an effort to intimidate the player into dropping the ball, or changing the opponent's path towards the goal.\n- There are 12 players on each team, including the goalie.\n- Attack positions are: Center, Right Attack Wing, Left Attack Wing, 3rd Home, 2nd Home, 1st Home\n- Defense positions are: Right Defense Wing, Left Defense Wing, 3rd Man, Cover Point, Point, Goalie\n- Player Equipment: Stick, Cleats, Mouthguard, Numbered shirt and kilt or shorts, and Padded Gloves (optional)\n- Goalie Equipment: Helmet with face-mask and throat protector, Padded Gloves, Arm Pads, Chest Pad, Leg Pads, and goalie stick\n- The Field: There are four types of demarcation lines around the goal: the circle, the arc, the fan, and hash marks. The circle envelopes the goal cage and no one but the goalie is allowed in the circle. The goal is guarded by a single goalie and measures about 6 feet by 6 feet. The field has no boundaries, but is usually enclosed by existing borders, such a trees, a track or fences.\n- Before the game begins, the umpire checks every stick (except the goalie's) for legality. The most common illegality in a stick is that its pocket is too deep. The strings at the bottom of the stick's head can be pulled to tighten the pocket.\n- If a player commits a foul, the umpire blows the whistle and play stops. The player fouled wins or retains the ball, while the player who fouled her is moved several yards behind or to the side of the player she fouled.\n- If a major foul is committed in the arc by the defense, the umpire blows the whistle, and a \"free shot\" on goal is taken by the player fouled. All of the defense players are required to clear the arc to the border closest to which they were standing when the whistle blew.\n- The attack player who was fouled takes her place at the hash mark closest to which she was standing when she was fouled. The defense must move away at least four meters from the fouled player. When the umpire blows the whistle again, the player can take a shot on goal or pass while the defense moves in.\n- There are no boundaries to the field, but if a ball enters an area that is dangerous, unplayable or not clearly visible to the umpire, the player who retains it or is closest to it (if the ball has been grounded), at the umpire's whistle wins it. The player then waits for the second whistle to begin play again, either by running with or passing the ball.\n- When the umpire blows the whistle because a foul has occurred, or the ball has gone \"out of bounds\" all players must stop and check all forward movement. Play resumes and the players can move when the umpire blows the whistle again.\n- Checking -- the method by which a player knocks the ball from another's stick -- is prohibited when it is: directed toward the face"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:0cd5819b-1fe8-458b-b34e-8ce9b5e6dca0>","<urn:uuid:d616729f-4e04-4618-be38-5a779c1f2e59>"],"error":null}
{"question":"Can foreign nationals self-petition for an NIW, and what forms must be processed sequentially?","answer":"Yes, foreign nationals can self-petition for a National Interest Waiver without employer sponsorship. They can file their labor certification directly with USCIS along with Form I-140 Petition for Alien Worker. In the case of employment-based green cards, the process requires sequential processing of multiple forms - the employer must file an I-140 Immigration Petition for Alien Worker first, and then the worker must submit Form I-485 to adjust status to permanent residence when a visa number is available.","context":["A basic overview of the visa is provided here. If you have further inquiries as to the application process or whether or not this is the correct route for your needs, please don't hesitate to contact us.\nThe National Interest Waiver (NIW) is made available to foreign nationals of exceptional ability in the sciences, arts or business and advanced degree professionals in order to supply a procedure for bypassing the EB-2 visa's burdensome labor certification process when it is viewed as being in the national interest.\nIndividuals seeking an NIW may also self-petition in that they are not required to have sponsorship by an employer, and may file their labor certification directly with United States Citizen and Immigration Services (USCIS) along with their Form I-140 Petition for Alien Worker.\n1. Qualification as a Person of Exceptional Ability in the Sciences, Arts or Business or Advanced Degree Holder\nTo be classified as a person with exceptional ability, the applicant must provide at least three of the following:\n- An official academic record showing the foreign national has a degree, diploma, certificate or similar award from a college, university, school or other institution of learning relevant to the area of exceptional ability.\n- Letters documenting at least ten years of full-time experience.\n- Any license or certificate necessary for practice of the profession.\n- Evidence of high commanded salary or compensation for services demonstrative of exceptional ability.\n- Membership in professional associations.\n- Documents proving recognition by peers, government officials, professional or business organizations for significant achievements and contributions to the field.\n- USCIS may also accept other comparable evidence of eligibility if the above standards are not applicable.\nTo qualify as a person holding an advanced degree, the applicant must be in possession of a master’s degree or bachelor’s degree (with at least five years of post-bachelor degree experience).\n2. The occupation is in the national interest\nThe term “national interest” is not defined by the statute, but the USCIS Administrative Appeals Office has provided a set of factors that are considered to be significant criteria for evaluating foreign nationals and their supposed benefit to the national interest of the U.S.\nThese factors may be, but are not limited to:\n- Improving the U.S. economy.\n- Improving the wages and working conditions of U.S. workers.\n- Improving education and training programs for American children and under-qualified workers.\n- Improving health care.\n- Providing affordable housing.\n- Improving the environment.\n- The request of an interested agency within the U.S. government.\n3. Unique Knowledge And Abilities\nThe applicant must possess unique knowledge or abilities that set him or her apart from other professionals within the field, and the applicant will utilize these qualities in ways that will significantly benefit the U.S.\n4. A Labor Certification Under Normal Procedure would Adversely Affect The Nation\nIt must be persuaded that the national interest would be adversely affected if a labor certification under normal EB-2 procedure were required. The foreign national must submit sufficient proof that the contribution is significant and that the time taken for the typical labor certification process would significantly harm the U.S. national interest.","How long does it take to process an application for permanent residence in the United States, or a “green card?” You might be surprised by how difficult it is to find a reliable answer to this common question. U.S. Citizenship and Immigration Services (USCIS)—the agency that adjudicates applications for permanent residence and other immigration benefits—provides a range as a way to estimate the time needed to process an immigration application.\nThe agency introduced a pilot program in March that changed how USCIS estimates these time ranges for four of its most popular types of application. The change follows longstanding criticism about inaccurate processing times from federal oversight offices, elected officials, and stakeholders. Applicants and immigration practitioners have reported that USCIS’ posted processing times do not reflect the actual time it takes a case to reach completion.\nPreviously, USCIS published processing times for all types of applications and petitions as a single figure in months, a specific date, and even in relation to a goal processing time.\nThe agency now uses an automated methodology in an attempt to more accurately estimate how long it will take to process certain common immigration benefit filings. According to USCIS, an application for permanent residence (Form I-485) will take anywhere from 7 months to 33 months to process. The time range fluctuates depending on the office location, basis for the filing, and other factors.\nThe pilot program only applies to the following four immigration forms:\n- N-400, Application for Naturalization\n- I-90, Application to Replace Permanent Resident Card\n- I-485, Application to Register Permanent Residence or Adjust Status\n- I-751, Petition to Remove Conditions on Residence\nAlthough the calculation method being piloted may improve accuracy in some ways, concerns remain. The pilot program includes only four of the many fee-based immigration forms USCIS adjudicates. Additionally, the ranges are still estimates, have broad variation, and do not reflect the complexity of many cases.\nFor example, “in the case of a foreign national applying for an employment-based green card, an employer must file an I-140 Immigration Petition for Alien Worker and the worker must also submit a Form I-485 to adjust status to permanent residence, when a visa number is immediately available.” USCIS will process these forms sequentially—meaning the time it takes to adjudicate each form and related steps must be added together to get an approximate estimate of processing time. USCIS processing time methodology does not account for such complexity.\nUSCIS provides time ranges as processing time estimates for other immigration filings as well, however there is significantly less transparency about the agency’s calculation method.\nAccessing this information is particularly important given the longstanding backlog of filings at USCIS. An application or petition that allows a person to work or travel internationally may be pending for several months to many years, leaving applicants—or employers petitioning for potential or current employees—in limbo for indeterminant times.\nAccurate processing time estimates can significantly affect the lives of applicants, employers, and the local communities they support. USCIS should prioritize transparency in its methods while improving the accuracy of processing times. Doing so not only supports the agency’s mission but would support economic and social stability in the United States—a benefit for everyone.\nFILED UNDER: featured, green card, processing times, USCIS"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:0a1bbc13-23ec-447b-8aab-b104296bbfcc>","<urn:uuid:792c3725-77ae-478f-8e01-158d83689dcb>"],"error":null}
{"question":"I'm researching motorcycle technology. What advanced features does the KTM 390 Duke's display system have, and how does its TPMS system work with tire maintenance?","answer":"The KTM 390 Duke features a TFT display that functions as an instrument cluster and can be operated via handlebar buttons. It can be synchronized with smartphones through the KTM MY RIDE app. As for the TPMS system, it monitors tire pressure and alerts riders of pressure deviations. The sensors typically last 4-6 years and require special nickel-plated valve cores for proper function. The system can fail due to various factors including overheating, improper mounting, battery issues, or corrosion from road salts and moisture.","context":["The KTM 390 Duke is a performance naked motorcycle in the above 350cc segment. The overall design of the motorcycle is aggressive and sharp as it is based on its elder sibling, the 1290 Super Duke R. The front profile of the motorcycle features a split LED headlamp which renders the 390 Duke a sporty look.\nThe fuel tank is muscular and the extending shrouds enhance the sporty appeal of the 390 Duke. The exposed split trellis frame reflects the raw performance of the motorcycle. The motorcycle also gets a new side-mounted exhaust cannister which blends well with the overall styling.\nThe all-new tail section of the KTM 390 Duke is sharp and edgy with the new LED tail light, split grab rails and the tail-tidy design. The new 390 Duke decals are neatly laid out and the orange colour on the fuel tank, trellis frame and alloy wheels add to the looks of the motorcycle.\nThe KTM 390 Duke is powered by a 373.2cc liquid-cooled, fuel injected, single-cylinder engine with a maximum power output of 42.90bhp at 9,000rpm and a peak torque output of 37Nm at 7,000rpm. The engine is coupled to a 6-speed gearbox.\nThe power-packed 373cc engine is the main highlight of the 390 Duke. The engine is refined and delivers an instant burst of power as soon as you twist the throttle.\nThe vibrations are well contained throughout the rev range. The motorcycle can easily reach triple-digit speeds in no time thanks to the short gear ratios.\nThe KTM 390 Duke is a fun-to-ride motorcycle and the tubular trellis frame aids in superior handling. The performance of this motorcycle is the main reason for its success in India.\nFuel efficiency is not the forte of KTM 390 Duke. With the high compression 373cc engine tuned for outright performance, the motorcycle returns an average mileage of around 23kpl.\nThe KTM 390 Duke is a feature loaded motorcycle. Up front, the motorcycle gets sharply designed split LED headlamp with boomerang-shaped LED DRLs. Another prominent highlight of the 390 Duke is the TFT display which also doubles up as the instrument cluster. The display can be operated via buttons on the left side of the handlebar. The display can be synced to the user's smartphone via KTM MY RIDE app.\nThe motorcycle also features ride-by-wire throttle and slipper clutch for smooth downshifts. The split tubular trellis frame aids in superior handling. The seats are wide and comfortable for long rides. The suspension duties are handled by upside down WP forks at the front and WP monoshock suspension at the rear. The suspension setup is stiff for spirited riding.\nThe KTM 390 Duke is equipped with 320mm disc up front and 230mm disc at the rear to bring the motorcycle to a halt. ABS is offered as standard. The kerb weight of the motorcycle stands at 163kg and it is equipped with a 13.5-litre metal fuel tank.\nThe KTM 390 Duke is one of the best motorcycles in the above 350cc segment. With its brute performance and aggressive styling, it is an excellent package for its price tag. The only issues with the motorcycle are the poor NVH levels and heating. But it should not be a deal breaker as it gets premier cycle parts and the build quality is top-notch. Overall it is a very good motorcycle for those who are looking for an affordable high-performance motorcycle.\n|Calliper Type||Front-4-Piston , Rear-Single Piston Calliper|\n|Front Brake Size||320 mm|\n|Front Brake Type||Disc|\n|Front Suspension||Open Cartridge WP upside Down|\n|Front Tyre Size||110/70 x 17|\n|Front Wheel Size||17 inch|\n|Rear Brake Size||230 mm|\n|Rear Brake Type||Disc|\n|Rear Suspension||WP Monoshock|\n|Rear Tyre Size||150/60 x 17|\n|Rear Wheel Size||--|\n|Chassis Type||Split Trellis Frame, Powder Coated|\n|Ground Clearance||178 mm|\n|Kerb Weight||163 kg|\n|Seat Height||830 mm|\n|Clutch||PASC Antihopping Clutch, Mechanically Actuated|\n|Cooling System||Liquid Cooled|\n|Fuel Delivery System||Fuel Injection|\n|Max Power||42.9 bhp @ 9,000 rpm|\n|Maximum Torque||37 Nm @ 7,000 rpm|\n|No. of Gears||6|\n|Spark Plugs||1 Per Cylinder|\n|Transmission Type||Chain Drive|\n|Valves Per Cylinder||4|\n|0 to 60 kmph||--|\n|60 to 0 kmph||--|\n|Fuel Efficiency Range||310 Km|\n|Fuel Tank Capacity||13.5 litres|\n|Reserve Fuel Capacity||--|\n|Antilock Braking System||Yes|\n|Brake/Tail Light||LED Tail Lamp|\n|Digital Fuel Guage||Yes|\n|Electric System||12V DC|\n|Headlight Bulb Type||--|\n|Headlight Type||LED Head Lamp|\n|Low Battery Indicator||Yes|\n|Low Fuel Indicator||Yes|\n|Low Oil Indicator||Yes|\n|No. of Tripmeters||2|\n|Start Type||Electric Start|","Ride-On is safe to use in combination with most TPMS or Tire Pressure Monitoring System sensors, provided that they are hermetically sealed. Ride-On is a liquid and if it gets inside the sensor, this may affect its efficacy negatively. Always check with your dealer if your sensor is hermetically sealed.\nTPMS sensor monitor your tire pressure and alert you when they register a deviation from the recommended pressure. They are an added security measure when you hit the road. Want to know more? Check our selection of TPMS sensors in the Ride-On shop.\nRide-On and TPMS sensors\nRide-On is designed to stay on the inner surface of tires keeping the product from coming into contact regularly with the TPMS sensors. Furthermore, TPMS sensors are normally sealed. In electronics, potting is a process of filling a complete electronic assembly with a solid or gelatinous compound for resistance to shock and vibration, and for exclusion of moisture and corrosive agents. Thermo-setting plastics or silicone rubber gels are often used. Even if you submersed the TPMS sensor in Ride-On (or any other liquid or containment commonly found in tires), this coating would prevent the Ride-On from harming the sensor electronics or batteries.\nIf your sensors are not sealed, then we do not recommend the use of Ride-On with them. Although the use of Ride-On with these types of sensors does not always create issues, we as a manufacturer do not recommend using our product in applications with TPMS Systems without potted electronics. Even moisture contained in the compressed air can enter the electronics and over time create issues not related to any tire sealant. We recommend that you check with your dealer or manufacturer to determine whether your TPMS sensor has potted electronics and batteries.\nPossible problems with Honda motorcycles\nIt has recently come to our attention that the TPMS sensors on late model Honda Goldwings (2009, 2010, 2012) are not sealed with an epoxy coating. Just using your hands, you can snap open these sensors. This leaves the sensor’s innards (battery and electronics) particularly vulnerable to any moisture/vapor or liquid. Therefore, we recommend that all of our dealers and customers refrain from installing Ride-On in late model Honda Goldwings (2009, 2010, 2012, and newer) until further testing proves our product’s compatibility. Also, certain KTM 1190 and 1290 Adventures may have unsealed (non-potted) electronics and therefore should avoid the use of our sealants.\nUnless you own a late model Honda Goldwing, you should have no problems using Ride-On in conjunction with your TPMS equipped vehicle(s). However, should a TPMS sensor fail, as they do from time to time, we recommend that you take your motorcycle to a Ride-On dealer for servicing. Ride-On washes out easily and leaves no residues. When requesting a warranty claim on your sensors, there is no need to volunteer that there was ever any substance in your tires.\nTPMS manufactures have broad policies in regard to the injection of foreign substances inside tires containing their sensors. Simply put – these substances automatically void the sensor warranty. They are not concerned with testing individual products (sealants, balancers, liquids, powders, beads, etc.) to see whether or not these substances actually cause TPMS sensor failures. These policies are created to minimize warranty replacement costs. Let the TPMS sensor warranty administrator examine the failed sensor to determine the actual cause. YOU DO NOT WANT TO GIVE THE WARRANTY ADMINISTRATOR A REASON TO AUTOMATICALLY VOID YOUR WARRANTY! Particularly when there are many reasons why TPMS sensors fail.\nCommon causes of TPMS failures\nAccording to TPMS Sensor Manufacturers, common causes of TPMS Sensor failures are:\n- Overheating – often caused by continuing to ride on a tire that is low on air or flat.\n- Installing the incorrect valve core – TPMS sensors require a special nickel-plated valve core instead of the regular copper or brass valve core.\n- Sensor Battery Issues – The batteries in TPMS sensors can become discharged over time or leak acid and cause a short.\n- Typical Road hazards – collisions, potholes, strong impacts, curbs, etc. can cause sensor damage – Sensors contain delicate electronics that are subject to failure.\n- Improper mounting or dismounting of a tire can lead to damage of a TPMS sensor.\n- Over-tightening a new sensor valve\n- Corrosion – Sensors can be damaged by corrosion from road salts, moisture, missing valve caps, or galvanic corrosion from the use of dissimilar metals.\nThe number one reason why TPMS sensors fail is due to aging batteries.\nTPMS sensor batteries on motorcycles typically last from 4-6 years. As batteries age, they leak acid.\nWhy to Batteries Leak Acid?\nAll batteries gradually self-discharge (whether installed in a device or not) and dead batteries will eventually leak. Extremely high temperatures can also cause batteries to rupture and leak (such as in a car during summer).\nThe reason for leaks is that as batteries discharge — either through usage or gradual self-discharge — the chemistry of the cells changes and some hydrogen gas is generated. This out-gassing increases pressure in the battery. Eventually, the excess pressure either ruptures the insulating seals at the end of the battery, or the outer metal canister, or both. In addition, as the battery ages, its steel outer canister may gradually corrode or rust, which can further contribute to containment failure. Once a leak has formed due to corrosion of the outer steel shell, potassium hydroxide absorbs carbon dioxide from the air to form a feathery crystalline structure of potassium carbonate that grows and spreads out from the battery over time, following along metal electrodes to circuit boards where it commences oxidation of copper tracks and other components, leading to permanent circuitry damage. The leaking crystalline growths can also emerge from seams around battery covers to form a furry coating outside the device, that corrodes any objects in contact with the leaking device. When the batteries on potted TPMS sensors leak acid, the pressure generated causes a bulge or even rupture of the potting material.\nIn conclusion, we would like to point out that literally thousands of tires have installed Ride-On with TPMS sensors without any issues. If in the future any more such instances arise with other motorcycles makes and models that may have compatibility issues with Ride-On, we will add that additional information to our website. Please make sure to visit www.ride-on.eu/support/tpms for more details.\nAs always, ride safe and Ride-On."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:8a599d6b-f334-4a88-8777-d36523a4c93e>","<urn:uuid:c9ba827c-3f04-4201-9d4f-d057a9ef7b6a>"],"error":null}
{"question":"How does the size of Chonburi province compare to Thailand's largest province in terms of land area?","answer":"Chonburi province, with an area of 4,363 km2, is significantly smaller than Thailand's largest province by area, which is Nakhon Ratchasima at 20,736 km2. This means Chonburi province is roughly one-fifth the size of Nakhon Ratchasima.","context":["Chonburi (Thai: ชลบุรี, RTGS: Chon Buri, [tɕ͡ʰōn bū.rīː] (\nLocation within Thailand\n|Coordinates: 13°13′N 101°11′E|\n|Settled||c. 7th century, as Phrarot city|\n|Founded as city||1897–1932|\n|Founded as province||1933|\n|Governing body||Chonburi Provincial Office|\n|• Governor||Phakkhrathon Thianchai|\n(since October 2016)\n|• Province||4,363 km2 (1,685 sq mi)|\n|Elevation||50 m (160 ft)|\n|• Density||351.9/km2 (911/sq mi)|\n|• Density rank||10th|\n|Human Achievement Index|\n|• HAI (2017)||0.6613 \"high\"|\n|Time zone||UTC+07:00 (ICT)|\n|ISO 3166 code||TH-20|\nThe word chon originates from the Sanskrit word जल; jala meaning 'water', and the word buri from Sanskrit पुरि; puri meaning 'town' or 'city'. Hence the name of the province literally means 'city of water'.\nChonburi is the territory that is known since Dvaravati, Khmer Empire and Sukhothai Kingdom. Chonburi was initially only a small agricultural town and a small fishing community scattered around. In Ayutthayan period, Chonburi was classified to commodore class city. According to the Triphum map, it appeared the important towns from north to south such as Bangsai (บางทราย; today is a sub-district of Chonburi), Bangplasoi (บางปลาสร้อย; today is a downtown of Chonburi), Bangphrarua (บางพระเรือ; Today is a sub-district of Si Racha) and Banglamung (บางละมุง, today is a district of Chonburi Province) Although it is a small town, it enriches natural resources both on land and at sea. There were agriculture and fishing from past. Moreover, they contacted with the Chinese sailing who came to trade with Siam.\nChonburi is the territory that has been settled since prehistoric period. Important Neolithic town, Khok Phanom Di that located in Phanthong river lowland (บริเวณที่ลุ่มริมฝั่งแม่น้ำพานทอง; Today is Phanthong and Phanat Nikhom) was found by archeologist in 1979. An archaeologist found beads, bracelets, the pottery which made pattern by taking a rope into the wet soil and also polished stone axes to harvest, to hunting, to chasing. It can be supposed that Chonburi area had been located by prosperous ancient town such as Phra Rot, Sri Phalo and Phaya Rae.\n- Rattanakosin Period\nIn the reign of Rama III, Indha-asa of Vientiane has taken a number of immigrants to Siam. The Siamese King allowed them to establish habitat between Chonburi and Chachoengsao (about Phanat Nikhom area in present).\nThe provincial tree and flower is the \"New Guinea rosewood\" (Pterocarpus indicus, called Mai Pradu in Thai).\nThe province is on the Bay of Bangkok, the northern end of the Gulf of Thailand. The Khao Khiao mountain range stretches from the northwest to the southeast of the province. The plains of the north were long used for farming. Laem Chabang, between Chonburi and Pattaya, is one of the few deep-water harbours of Thailand.\nThe provincial permanent legal population rose at nearly four percent annually from 1,040,865 in 2000 to 1,554,365 in 2010. There is a large floating population of long-term residents (non-Thai) without permanent status, on perpetual tourist visa and/or migrant workers (legal or not), as well as heavy, short term tourist influxes.\nChonburi Province consists of 11 districts (amphoe). These are further subdivided into 92 subdistricts (tambon) and 710 villages (muban). As of 31 December 2018 there are: 1 Chonburi Provincial Administrative Organisation - CPOA (ongkan borihan suan changwat chonburi), 1 Pattaya City Special Local Government, 2 City municipalities (thesaban nakhon) and 10 Town municipalities (thesaban mueang). Further there are: 35 Subdistrict municipalities (thesaban tambon) and 50 Subdistrict Administrative Organisations - SAO (ongkan borihan suan tambon).\n|— Districts —|\n|1||Mueang Chonburi||เมืองชลบุรี||335,063||18 tambon — 107 muban|\n|2||Ban Bueng||บ้านบึง||103,377||8 tambon — 52 muban|\n|3||Nong Yai||หนองใหญ่||23,625||5 tambon — 24 muban|\n|4||Bang Lamung||บางละมุง||315,437||8 tambon — 72 muban|\n|5||Phan Thong||พานทอง||69,429||11 tambon — 76 muban|\n|6||Phanat Nikhom||พนัสนิคม||124,637||20 tambon — 185 muban|\n|7||Si Racha||ศรีราชา||301,799||8 tambon — 73 muban|\n|8||Ko Sichang||เกาะสีชัง||4,560||1 tambon — 7 muban|\n|9||Sattahip||สัตหีบ||165,492||5 tambon — 40 muban|\n|10||Bo Thong||บ่อทอง||50,318||6 tambon — 47 muban|\n|11||Ko Chan||เกาะจันทร์||37,670||2 tambon — 27 muban|\n- Via the Bangkok-Chonburi-Pattaya Motorway (Hwy 7) The motorway is linked with Bangkok's Outer Ring Road., (Hwy 9) and there is also another entrance at Si Nakharin and Rama IX Junction.\n- Via Bang Na-Trat Highway (Hwy 34) From Bang Na, Bang Phli, across the Bang Pakong River to Chonburi there is a Chonburi bypass that meets Sukhumvit Road, (Hwy 3, passing Bang Saen Beach, Bang Phra, Pattaya and Sattahip.\nChonburi is about 120 kilometres (75 mi) by road from Suvarnabhumi Airport (BKK), the country's largest international airport. By road, it is accessed from Sukhumvit Road and Motorway 7 from Bangkok. Chonburi is also served by scheduled flights via U-Tapao International Airport (UTP) which is 45 minute drive south of the city.\nThe main road through Chonburi is Thailand Route 3, also known as Sukhumvit Road. To the northeast it connects to Bangkok and to south it connects to Rayong Province, Chanthaburi Province and Trat Province. Route 344 leads east to Klaeng (which is also on Route 3). Route 7 runs parallel to Route 3 but bypasses the densely populated coastal area, connecting to the beach resort city of Pattaya.\nMany hospitals exist in Chonburi, both public and private. Chonburi has one university hospital, Burapha University Hospital. Its main hospital operated by the Ministry of Public Health is Chonburi Hospital. Hospitals operated by other organisations such as the Thai Red Cross Society (Queen Savang Vadhana Memorial Hospital), and the Royal Thai Navy (Queen Sirikit Naval Hospital) are also found in the province.\n- Graduate School of Public Administration, National Institute of Development Administration (GSPA)\n- Interior College (IC)\n- Panyapiwat Institute of Management (PIM)\nHuman achievement index 2017\nSince 2003, United Nations Development Programme (UNDP) in Thailand has tracked progress on human development at sub-national level using the Human achievement index (HAI), a composite index covering all the eight key areas of human development. National Economic and Social Development Board (NESDB) has taken over this task since 2017.\nProvince Chonburi, with an HAI 2017 value of 0.6613, takes the 6th place in the rankings. This is \"high\" between the values of 0.6246 and 0.6885.\n|Map with provinces and HAI 2017 rankings|\nChonburi Buffalo Race (งานประเพณีวิ่งควาย) In Ban Bueng and Nong Yai Districts. The animals are dressed outrageously or with creatively by owners. Assembled in the courtyard in front of the town hall, the buffaloes partake in racing, or take part in physical fitness and fashion contests. The Chonburi Buffalo Race festival started more than 100 years ago. Usually, the races will be complemented with booths selling locally made items, stage performances, games and beauty contests. The annual Buffalo Race, held around the 11th lunar month, normally in October. It takes seven days and takes place on the field in front of the city and provincial government offices. The highlight of the festival is the buffalo race which is on the last two days. This race is 100 meters–long. The prize for the first nose past the finish line is a trophy and some money.\nSongkran day in bangsaen or \" Ko Phra Sai Wan Lai Bangsaen\" is a tradition that has been held continuously for a long time, covering ten years, at Bang Saen beach and Laem Thaen, Saen Suk Subdistrict, Mueang District, Chon Buri Province. Between April 16-17 of each year. The highlight of this event contest. Which will be provided for the contestants to build a sand Buddha at Bangsaen beach In which each Buddha sand arch There is a magnificent decoration. Combined with the sea atmosphere and Thai decorations , this place has become one of the most beautiful Songkran festivals in Thailand. In addition, there are many interesting activities awaiting in the event. Such as merriting alms to monks, bathing Buddha images, pouring water on the elders, traditional sporting events, sea boxing competitions, oyster sheep competitions, selling seafood and local food, selling local products (OTOP) ), Concerts from famous artists etc.\nReports (data) from Thai government are \"not copyrightable\" (Public Domain), Copyright Act 2537 (1994), section 7.\n- Advancing Human Development through the ASEAN Community, Thailand Human Development Report 2014, table 0:Basic Data (PDF) (Report). United Nations Development Programme (UNDP) Thailand. pp. 134–135. ISBN 978-974-680-368-7. Retrieved 17 January 2016, Data has been supplied by Land Development Department, Ministry of Agriculture and Cooperatives, at Wayback Machine.\n- \"ร่ยงานสถิติจำนวนประชากรและบ้านประจำปี พ.ศ.2561\" [Statistics, population and house statistics for the year 2018]. Registration Office Department of the Interior, Ministry of the Interior. stat.bora.dopa.go.th (in Thai). 31 December 2018. Archived from the original on 2 April 2019. Retrieved 20 June 2019.\n- ดัชนีความก้าวหน้าของคน ปี2560 [Human Achievement Index - HAI year 2017] (PDF). social.nesdb.go.th (Report) (in Thai). National Economic and Social Development Board (NESDB). 2017. pp. 62–63. ISBN 978-974-9769-33-1. Retrieved 14 September 2019, Maps 1-9\n- \"About Chon Buri\". Tourism Authority of Thailand (TAT). Retrieved 31 May 2015.\n- \"Chonburi\". THAILEX Travel Encyclopedia. Archived from the original on 2015-11-27. Retrieved 31 May 2015.\n- \"History\". สำนักงานการท่องเที่ยวและกีฬาจังหวัดชลบุรี. Retrieved 2019-05-23.\n- http://cbi.onab.go.th/index.php?option=com_content&view=article&id=327&Itemid=206 Religion in Chonburi\n- https://www.chonburilocal.go.th/public/history/data/index/menu/22 Basic information of the local government in the Chonburi province\n- https://www.dla.go.th/work/abt/index.jsp Thesaban - 14 June 2562 (2019)\n- \"Chon Buri sees 9mn visitors in 2012\". The Nation. 8 April 2013. Retrieved 2 October 2018.\n- สำนักงานคณะกรรมการวัฒนธรรมแห่งชาติ, ประเพณีวิ่งควาย (1994). ชีวิตไทยชุดบรรพบุรุษของเรา.กรุงเทพฯ: คุรุสภาลาดพร้าว, 2013\n- \"Chonburi buffalos race Oct. 14-20\". Pattaya Mail. 2013-09-06. Archived from the original on 10 June 2015. Retrieved 31 May 2015.\n- \"Chonburi Buffalo Racing\". Tourism Authority of Thailand (TAT). Retrieved 19 April 2019.\n|Wikimedia Commons has media related to Chonburi Province.|","|Provinces of Thailand|\n|Alt Name:||(Thai: จังหวัด)|\n|Territory:||Kingdom of Thailand|\n|Current Number:||77 provinces|\n|Population Range:||174,000 (Mae Hong Son) – 5,702,000 (Bangkok) (2022)|\n|Area Range:||414km² Samut Songkhram – 20736km² Nakhon Ratchasima|\n|Government:||Provincial/Special Administrative Divisional government|\nThe provinces of Thailand are administrative regions of the government of Thailand. The country is divided into 76 provinces (Thai: [[:wikt:จังหวัด|จังหวัด]],, in Thai pronounced as /t͡ɕāŋ.wàt̚/) proper, with one additional special administrative area (the capital, Bangkok).   They are the primary local government units and act as juristic persons. They are divided into amphoe (districts) which are further divided into tambon (sub districts), the next lower level of local government. Each province is led by a governor (ผู้ว่าราชการจังหวัด phu wa ratchakan changwat), who is appointed by the central government. Bangkok, the sole special administrative area, combines the tasks of the provinces with that of a municipality, including having an elected governor.\n|Population (December 2022)||Area (km2)||Population density||Namesake town/city||HS||ISO||FIPS|\n(special administrative area)\n|Thai: อำนาจเจริญ||402,000||3,290||115||Amnat Charoen||ACR||TH-37||TH77|\n|Thai: อ่างทอง||301,000||950||294||Ang Thong||ATG||TH-15||TH35|\n|Thai: บึงกาฬ||450,000||4,003||106||Bueng Kan||BKN||TH-38||TH81|\n|Thai: ชัยนาท||331,000||2,506||131||Chai Nat||CNT||TH-18||TH32|\n|Thai: เชียงใหม่||1,820,000||20,107||79||Chiang Mai||CMI||TH-50||TH02|\n|Thai: เชียงราย||1,315,000||11,503||113||Chiang Rai||CRI||TH-57||TH03|\n|Thai: กำแพงเพชร||748,000||8,512||86||Kamphaeng Phet||KPT||TH-62||TH11|\n|Thai: ขอนแก่น||1,826,000||10,659||169||Khon Kaen||KKN||TH-40||TH22|\n|Thai: แม่ฮ่องสอน||174,000||12,765||23||Mae Hong Son||MSN||TH-58||TH01|\n|Thai: มหาสารคาม||1,000,000||5,607||172||Maha Sarakham||MKM||TH-44||TH24|\n|Thai: นครนายก||224,000||2,141||122||Nakhon Nayok||NYK||TH-26||TH43|\n|Thai: นครปฐม||955,000||2,142||430||Nakhon Pathom||NPT||TH-73||TH53|\n|Thai: นครพนม||698,000||5,637||127||Nakhon Phanom||NPM||TH-48||TH73|\n|Thai: นครราชสีมา||2,703,000||20,736||128||Nakhon Ratchasima||NMA||TH-30||TH27|\n|Thai: นครสวรรค์||997,000||9,526||111||Nakhon Sawan||NSN||TH-60||TH16|\n|Thai: นครศรีธรรมราช||1,602,000||9,885||158||Nakhon Si Thammarat||NRT||TH-80||TH64|\n|Thai: หนองบัวลำภู||481,000||4,099||125||Nong Bua Lam Phu||NBP||TH-39||TH79|\n|Thai: หนองคาย||536,000||3,275||160||Nong Khai||NKI||TH-43||TH17|\n|Thai: ปทุมธานี||1,142,000||1,520||766||Pathum Thani||PTE||TH-13||TH39|\n|Thai: พังงา||243,000||5,495||49||Phang Nga||PNA||TH-82||TH61|\n|Thai: พระนครศรีอยุธยา||812,000||2,548||322||Phra Nakhon Si Ayutthaya||AYA||TH-14||TH36|\n|Thai: ประจวบคีรีขันธ์||530,000||6,414||88||Prachuap Khiri Khan||PKN||TH-77||TH57|\n|Thai: ร้อยเอ็ด||1,295,000||7,873||166||Roi Et||RET||TH-45||TH25|\n|Thai: สระแก้ว||608,000||6,831||83||Sa Kaeo||SKW||TH-27||TH80|\n|Thai: สกลนคร||1,200,000||9,580||121||Sakon Nakhon||SNK||TH-47||TH20|\n|Thai: สมุทรปราการ||1,324,000||947||1,420||Samut Prakan||SPK||TH-11||TH42|\n|Thai: สมุทรสาคร||567,000||866||675||Samut Sakhon||SKN||TH-74||TH55|\n|Thai: สมุทรสงคราม||209,000||414||467||Samut Songkhram||SKM||TH-75||TH54|\n|Thai: สิงห์บุรี||198,000||817||255||Sing Buri||SBR||TH-17||TH33|\n|Thai: สุโขทัย||615,000||6,671||89||Sukhothai (Sukhothai Thani)||STI||TH-64||TH09|\n|Thai: สุพรรณบุรี||891,000||5,410||156||Suphan Buri||SPB||TH-72||TH51|\n|Thai: สุราษฎร์ธานี||1,101,000||13,079||81||Surat Thani||SNI||TH-84||TH60|\n|Thai: อุบลราชธานี||1,903,000||15,626||120||Ubon Ratchathani||UBN||TH-34||TH75|\n|Thai: อุดรธานี||1,608,000||11,072||143||Udon Thani||UDN||TH-41||TH76|\n|Thai: อุทัยธานี||342,000||6,647||50||Uthai Thani||UTI||TH-61||TH15|\nSee also: List of provincial governors in Thailand. Thailand's national government organisation is divided into three types: central government (ministries, bureaus and departments), provincial government (provinces and districts) and local government (Bangkok, Pattaya, provincial administrative organisations, etc.).\nA province, as part of the provincial government, is administered by a governor (ผู้ว่าราชการจังหวัด) who is appointed by the Minister of Interior. Bangkok, as part of the local government, is administered by a corporation called Bangkok Metropolitan Administration. The corporation is led by the Governor of Bangkok (ผู้ว่าราชการกรุงเทพมหานคร) who is directly elected by the citizens of Bangkok.\nThe provinces are named by their original main city, which is not necessarily still the most populous city within the province today. Also, in several provinces the administration has been moved into a new building outside the city.\nMany provinces date back to semi-independent local chiefdoms or kingdoms, which made up the Ayutthaya Kingdom. The provinces were created around a capital city (mueang), and included surrounding villages or satellite towns. The provinces were administered either by a governor, who was appointed by the king or by a local ruling family, who were descendants of the old kings and princes of that area and had been given this privilege by the central king. De facto the king did not have much choice but to choose someone from the local nobility or an economically strong man, as against these local power groups the administration would have become impossible. The governor was not paid by the king, but instead financed himself and his administration by imposing local taxes himself. Every province was required to send an annual tribute to Bangkok.\nThe provinces were divided into four different classes. The first-class were the border provinces. The second-class were those that once had their own princely house. Third-class were provinces that were created by splitting them from other provinces. Fourth-class were provinces near the capital. Additionally tributary states like the principalities of Lan Na, the Laotian kingdoms of Vientiane and Luang Prabang, Cambodia, or the Malay sultanate Kedah were also part of the country, but with more autonomy than the provinces. In this Mandala system the semi-independent countries sometimes were tributary to more than one country.\nNew provinces were created when the population of an area outgrew the administration, but also for political reasons. If a governor became too dominant in a region former satellite cities were elevated to provincial status, as was the case with Maha Sarakham province.\nReforms of the provincial administration started in the 1870s under increased pressure from the colonial states of the United Kingdom and France. Agents were sent, especially to border areas, to impose more control on the provinces or tributary states.\nAt the end of the 19th century King Chulalongkorn reformed the central government. In 1892 the ministry, which previously had many overlapping responsibilities, was reorganized with clear missions as in Western administrations. Prince Damrong Rajanubhab became minister of the Ministry of the North (Mahatthai), originally responsible for the northern administration. When the Ministry of the South (Kalahom) was dissolved in 1894, Prince Damrong became Minister of the Interior, responsible for the provincial administration of the whole country.\nStarting in 1893 the already existing commissionaireships in some parts of the country were renamed \"superintendent commissioner\" (khaluang Thesaphiban), and their area of responsibility was called a monthon. In strategically important areas the monthon were created first, while in other areas the provinces kept their independence a bit longer. Several smaller provinces were reduced in status to an amphoe (district) or even lower to a tambon (sub-district) and included in a neighboring province, sometimes for administrative reasons, but sometimes to remove an uncooperative governor.\nIn some regions rebellions broke out against the new administrative system, usually induced by the local nobility fearing their loss of power. The most notable was the Holy Man Rebellion in 1902 in Isan. It was initially a messianic doomsday sect, but it also attacked government representatives in the northeast. The provincial town Khemarat was even burned by the rebels. After a few months the rebellion was beaten back.\nAfter 1916, the word changwat became common to use for the provinces, partly to distinguish them from the provincial capital city (mueang or amphoe mueang), but also to stress the new administrative structure of the provinces. When Prince Damrong resigned in 1915, the whole country was divided into 19 monthon (including the area around Bangkok, which was under the responsibility of another ministry until 1922), with 72 provinces.\nIn December 1915 King Vajiravudh announced the creation of regions (phak), each administered by a viceroy (upparat), to cover several monthon. Until 1922 four regions were established; however, in 1925 they were dissolved again. At the same time several monthon were merged, in an attempt to streamline administration and reduce costs.\nThe monthons were dissolved when Thailand transformed from an absolute monarchy into a constitutional monarchy in 1932, making the provinces the top level administrative division again. Several smaller provinces were also abolished at that time. During World War II, several provinces around Bangkok were merged. These changes were undone after the war. Also the occupied area from French Indochina was organized into four provinces: Phra Tabong, Phibunsongkhram, Nakhon Champasak and Lan Chang. The current province of Sukhothai was at first known as Sawankhalok. It was renamed Sukhothai in 1939 (which is why the railway system goes to Sawankhalok city and not Sukhothai city). The province, Kalasin, was reestablished in 1947 after having been dissolved in 1932.\nIn 1972 Phra Nakhon and Thonburi provinces were merged to form the special administrative area of Bangkok, which combines the tasks of the provinces with that of a municipality, including having an elected governor.\nStarting in the second half of the 20th century some provinces were newly created by splitting them off from bigger provinces. In 1975, Yasothon province was split off from Ubon Ratchathani. In 1977, Phayao province was created from districts formerly part of Chiang Rai. In 1982, Mukdahan was split off from Nakhon Phanom. In 1993 three provinces were created: Sa Kaeo (split from Prachinburi), Nong Bua Lamphu province (split from Udon Thani), and Amnat Charoen (split from Ubon Ratchathani). The newest province is Bueng Kan, which was split off from Nong Khai effective 23 March 2011.\n|Kabin Buri||Kabin Buri||1926||Merged into Prachinburi province|\n|Sukhothai (before 1932)||Sukhothai Thani||1932||Merged into Sawankhalok province. However, the province's name and location of capital was changed back to Sukhothai in 1938.|\n|Lom Sak||Lom Sak||Merged into Phetchabun province|\n|Thanyaburi||Thanyaburi||Merged into Pathum Thani province|\n|Kalasin||Kalasin||Merged into Maha Sarakham province, Split out again in 1947|\n|Lang Suan||Lang Suan||Merged into Chumphon province|\n|Takua Pa||Takua Pa||Merged into Phang Nga province|\n|Sai Buri||Sai Buri||Merged into Pattani province (except Bacho District which was merged into Narathiwat province)|\n|Phra Pradaeng||Phra Pradaeng||Merged into Samut Prakan province (except Rat Burana District which was merged into Thonburi province)|\n|Min Buri||Min Buri||Merged into Phra Nakhon province (Nong Chok District was merged into Chachoengsao province first then reallocated back in 1933)|\n|Samut Prakan (before 1943)||Samut Prakan||1943||Merged into Phra Nakhon province (except Ko Sichang District which was merged into Chonburi province). The part of Phra Nakhon was split out again in 1946|\n|Nakhon Nayok||Nakhon Nayok||Merged into Prachinburi province (except Ban Na District which was merged into Saraburi province). Split out again in 1946|\n|Samut Sakhon||Samut Sakhon||Merged into Thonburi province. Split out again in 1946|\n|Nonthaburi||Nonthaburi||Merged into Phra Nakhon province (except Bang Kruai District, Bang Yai District, Bang Bua Thong District which was merged into Thonburi province). Split out again in 1946|\n|Phra Nakhon||Phra Nakhon||1971||Merged to form the current Bangkok|\n|Territory||Capital||Period||Fate||Today part of|\n|Salaween Territory||Chiang Mai||1802–1892||Karenni State and Shan State, British Burma|\n|Kawtaung Territory||Chumphon||1769–1864||Mergui British Burma||Thanintharyi Myanmar|\n|Miawadi Territory||Chiang Mai||1768–1834||Thaton British Burma|\n|Sip Song Ju Tai||none||1779–1888|\n|Chiang Khaeng (Muang Sing)||Muang Sing||1892–1893||Shan State British Burma and Haut Mekong French Indochina|\n|Luang Phrabang||Luang Phrabang||1778–1893||Luang Phrabang French Indochina|\n|Chiang Khouang||Chiang Khouang||1828–1893||Tran Ninh French Indochina|\n|Borikhan Nikhom||Borikhan Nikhom||1828–1893||Vientiane French Indochina|\n|Kham Kert||Kham Kert||1828–1893||Khammouane French Indochina|\n|Kham Meun||Kham Meun||1828–1893||Khammouane French Indochina|\n|Nakhon Phanom||Nakhon Phanom||1893||Partitioned between Nakhon Phanom and Khammouane French Indochina|\n|Mukdahan||Mukdahan||1893||Partitioned between Mukdahan and Savannakhet French Indochina|\n|Khemmarat||Khemmarat||1893||Partitioned between Khemmarat and Salavan French Indochina|\n|Nakhon Champassak||Nakhon Champassak||1780–18261829–1904||Partitioned between Det Udom and Bassac, Attapeu, Stung Treng French Indochina|\n|Kham Thong Luang||Kham Tong Luang||1829–1893||Salavan French Indochina|\n|Salawan||Salawan||1829–1893||Salavan French Indochina|\n|Attapeu||Attapeu||1829–1893||Attapeu French Indochina|\n|Sitadon||Sitadon||1829–1893||Bassac French Indochina||Champassak Cambodia|\n|Saen Pang||Saen Pang||1829–1893||Stung Treng French Indochina||Stung Treng Cambodia|\n|Chiang Taeng||Chiang Taeng||1829–1893||Stung Treng French Indochina||Stung Treng Cambodia|\n|Chaiburi||Chaiburi||1893–1904||Luang Phrabang French Indochina|\n|Khukhan||Khukhan||1907||Partitioned between Khukhan and Kampong Thom French Indochina|\n|Sangkha||Sangkha||1907||Partitioned between Sangkha and Battambang French Indochina|\n|Siemmarat||Siemmarat||1845–1907||Siem Reap French Indochina||Siem Reap Cambodia|\n|Phanom Sok||Phnom Srok||1845–1907||Siem Reap, Battambang French Indochina|\n|Sisophon||Sisophon||1845–1907||Battambang French Indochina|\n|Phra Tabong||Phra Tabong||1769–1907||Battambang French Indochina||Battambang, Banteay Meanchey Cambodia|\n|Prachankiriket||Prachankiriket||1855–1904||Pursat and Kampot, French Indochina||Pursat and Koh Kong, Cambodia|\n|Penang||Penang||1786–1867||Penang British Malaya|\n|Lan Chang||Sama Buri||1941–1946||Luang Prabang, French Indochina||Sainyabuli and Luang Prabang,|\n|Phra Tabong||Battambang||1941–1946||Battambang, French Indochina||Battambang and Pailin, Cambodia|\n|Phibunsongkhram||Sisophon||1941–1946||Battambang, Siem Reap, Kompong Thom and Stung Treng, French Indochina||Banteay Meanchey, Oddar Meanchey and Siem Reap, Cambodia|\n|Nakhon Champassak||Champasak||1941–1946||Kompong Thom, Stung Treng and Bassac, French Indochina||Preah Vihear and Stung Treng, Cambodia|\n|Kedah, British Malaya||Kedah,|\n|Perlis, British Malaya||Perlis,|\n|Kelantan, British Malaya||Kelantan,|\n|Trangkanu||Kuala Terengganu||1786 –1909|\n|Terengganu, British Malaya||Terengganu,|\n|Saharat Thai Doem||Chiang Tung||1943–1945||Karenni State and Shan State, British Burma|\n|Tanaosi||Tanaosi||until–1767||Dawei Konbaung Dynasty||Thanintharyi Myanmar|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:ee2a6ead-1f14-4c9c-acd6-c1f24ef8efae>","<urn:uuid:000eef64-9c18-4e5a-97b2-6fe781d9d59f>"],"error":null}
{"question":"What is the difference between leak testing considerations for metals versus non-metals?","answer":"Metal and non-metal materials require different considerations in leak testing. Metal pieces, such as cast iron motor housing, require attention to seals and components with known pressure limitations, and certain metal pieces like windings and heat exchangers tend to expand mechanically after the filling phase according to the introduced pressure, requiring special pre-filling techniques at higher pressures to manage expansion/relaxation. In contrast, non-metal containers like glass and plastic components are suitable for specific methods like the spark coil technique, which uses electromagnetic radiation to generate glow discharge, though this method is limited to non-metal containers and must be avoided due to radio disturbances.","context":["To introduce a detailed description of the several kinds of automatic leak test equipments under pressure, it is necessary to define some characteristics that are common to the different working principles.\nEvery described system has in common the necessity to create a dump or pressure difference between the area considered tight and the outside of this body.\nThis phase is called filling phase.\nGenerally the filling can be made both with positive pressure and with negative one, both with pressure (or depression) applied from the inside or from the outside of the piece under test.\nAfter this phase we will have an settling phase, necessary to stabilize the pressure or the flow values of leak measurement.\nOnly at the end of these two phases we will have the execution of the real leak measure, in the different strategies that we will analyze in detail. We report, to be clear, a graph with a typical trend of the pressure during a leak test (pressure decay).\nThe strategy of filling, that is if it is from the inside of the piece (more general case) or from the outside (bell), the type of filling and therefore of pressure or depression and the value of this pressurization, must be selected for each case, analyzing the piece to be tested. For this selection, the first parameter we have to consider is the pressure value we have to use to make the filling, therefore the test.\nConsidering the use of common industrial compressed air, this value can be included in more common cases between -1 Bar and 10 Bar, and in case of leak test together with breaking or explosion test this value can arrive also over 40 Bar.\nIn spite of what you can assume intuitively, the use of high pressure values degrades the overall performance of the test, because if on one side the value of the leakage measured is increasing proportionally, that is, however, proportional to the pressure or flow measures, the use of high pressure complicates the trend of the filling phase and of the following settling phases or stabilization ones. Therefore, usually, it is better to prefer tests and filling made at a low pressure (less than 1 bar).\nThe use of a filling in depression can, for example, better the tightness of the piece during the test phases. In case of jars or of pieces with a large \"open\" section, for example engine oil \"pan\" or halves of housing, a simple soft rubber base is enough to make the piece tight, without having to use excessive contrast forces.\nThe filling in depression can be distorted in case of tests on pieces of plastic soldered, because the depression tends to make sticky and then to \"glue\" the faulty welding. In case of pieces of plastic soldered, the high pressure helps to expand the possible defect, then the test made at a pressure between 3 or 8 bars, can join to a leak test, any test of strength of the soldering. Particular attention should be placed when the piece to be tested is composed by \"non-linear\"\" tight mechanism such as valves or leaf springs and tests have to be made or at a much lower or much higher pressure than the operating point of these valves.\nOn mechanical pieces such as cast iron motor housing or of motorcycle transmissions you have always to consider the presence or the absence of seals or of any components guaranteed up to a known pressure. The specifications of tests for pieces for gas and kitchen indicate the leak at low pressures, usually 150 mBar.\nA very important note is for those metal pieces that are used to expand after filling phase under pressure. These pieces, such as windings, heat exchanger etc, tend to expand mechanically at the end of the filling phase, gradually according to the introduced pressure.\nConsidering the cases in which these elements have to be tested at a quite high pressure necessarily (4..7 Bar), and where the expansion cannot be compensated by the settling phase, only with time of prohibitive length, the use of a pre-filling at a higher value than that one of the test itself allows to obtain excellent results of expansion/relaxation, limiting the total testing time drastically.\nSynthetically, the choice of the pressure value at which you have to make the test, has to be similar from one side to the real working pressure of the component, considering each time the pros and cons of different pressure levels.\nThe choice of a filling in \"bell\", and therefore form the outside of the piece, usually in depression, is discussed here below in its proper paragraph. The gas used is common to every kind of filling and it is in most cases at compressed air. This air has to be intended as a filtered one, obviously without any oil, and dehumidified.\nIn case you use industrial air of a general purpose circuit, the application of a cylinder or of a local expansion vessel to the leak test equipment will better the characteristics of temperature changing between the air and the piece itself. Instead of the air you can use some gas with smaller atoms, such as helium, because they increase the leak fluidity and they emphasize the sensitivity of the test.\nFinally it is necessary to consider the use of inert gas such as nitrogen, in case of tests in components already treated with explosive or flammable elements, such as tests on car gasoline branches or on components for fuels generally.","Table Of Contents\n- What is Leak Testing?\n- Leak Testing Methods\n- Leak Testing Considerations\n- Leak Testing Equipment\n- Leak Testing Standards and Codes\n- Key Takeaways\nInspectors conduct leak testing to ascertain whether a system or object is operating within a predetermined leak limit.\nWhen an object has a flaw, such as a hole, crack, or other type of flaw, the liquid or gas it is holding can leak out. This is known as a leak.\nPressure is used in leak testing to identify these flaws so that they can be fixed during routine maintenance procedures.\nLeak tests are typically carried out on items that are used to hold or transport liquids or gases.\nOne of the most commonly employed inspection techniques is leak testing.\nIt qualifies as a Non-destructive Testing (NDT) method since inspectors can use it without causing long-term alterations to or harm to the object they're checking.\nWhat is Leak Testing?\nLeak testing is the process where inspectors apply pressure to an object to locate defects that are causing leaks.\nWhen anything leaks out of a container, it goes from a high-pressure area to a low-pressure area.\nLeak testing makes use of this phenomenon by closely observing the flow and utilising pressure to create flow towards lower pressure, or the location of leaks.\nWhat circumstances call for leak testing? most often when testing closed systems for bugs.\nThe success or failure of a leak test depends on the object being tested.\nDifferent types of materials and objects may respond differently to the high pressures that are typically employed in leak testing to force a liquid or gas out of a defect, revealing its presence and location.\nLeak Testing Methods\nSome of the most popular leak test techniques are listed below.\n1. Spark Coil Technique\nThe electromagnetic radiation that generates glow discharge in nearby evacuated ampoules is produced using the spark coil approach by using a high voltage or Tesla coil and sparkling point.\nTypically, it is only feasible in non-metal containers, such as glass and plastic components or tubes.\nWe can observe plasma inside the tested element as we draw the leak antenna along it. As we approach the leak, a sharp arc passage between the plasma and antenna appears.\nThe fault patch is quite distinct, and a knowledgeable individual can infer the interior pressure from the plasma's colour.\nThis straightforward method, however, has a number of downsides since, in addition to its limited applicability, it must also be avoided due to radio disturbances.\n2. Pressure Change Method\nPressure gauges, which are frequently used to track system performance, are employed in the pressure change approach.\nA solvent, such as acetone or something similar, can be squirted over suspected leak spots while you keep an eye on the gauge for a pressure spike that happens when the solvent enters the leak.\nThis method has some drawbacks, including low sensitivity, the potential for solvent freezing to temporarily stuff a leak, and the potential for solvents to destroy vacuum grease and elastomer gaskets.\n3. Overpressure Methods\nThe tested element must be filled with fluid or gas to perform overpressure procedures.\nTypically, water from domestic installations is used as a fluid.\nThe wet portions of the exterior surface reveal significant leakage as well as smaller ones up to around I mbarl/s.\nIn a gas testing procedure, the vessel is immersed in water and overpressured by a certain amount (depending on the material and thickness of the wall). Gas bubbles start to escape from leaks.\nLeaks up to 10-3 mbarl/s can be found in this way. The suspected points should be sprayed with a soap solution if the vessel is too large for immersion.\nThis time, we can observe the bubbles exiting if there is a leak. This technique can be used for very big systems and can detect leaks up to 10-5 mbarl/s.\n4. Halogen Leak Detectors\nThe system must be pressured with a gas containing an organic halide, such as one of the Freons when using halogen leak detectors in the detector-probe mode (to 10-3 mbarl/s).\nNext, a sniffer probe sensitive to traces of the halogen-containing gas scans the system's exterior.\nThe theory is based on the enhanced emission of positive ions (K or Na) brought on by the abrupt appearance of halide composition.\nThe metric for leak size is the ion current. Halogen detectors can also be used in reverse mode, which involves connecting an evacuated vessel to the detector and spraying freon into it.\nIn this way, its performance is used in rough, medium, and high vacuums and is up to 10-7 mbarl/s.\n5. Dye Penetrant Method\nThe dye penetrant method is a modification of a method used to detect weld flaws and metal fissures.\nIt makes use of a fluid with low viscosity and rapid surface movement.\nWhen a leak is suspected, this fluid is painted on one side of the wall, and after some time, it is discovered on the opposite side.\nThe test is straightforward, inexpensive, leaves records, and has a sensitivity of up to 10-6 mbarl/s.\nLeak Testing Considerations\nLeakage inspections have some special considerations as an NDT approach because they necessitate the application of pressure to an object in order to detect leaks.\nBelow is a summary of important considerations.\n1. Acceptable Leak Rate\nWhen doing leak testing, it's critical for inspectors and maintenance staff to be aware of the permissible leak rate for a given item or system.\nNot every leak needs to be fixed; others may only need more observation or possibly no action at all.\nThere are usually regulations outlining permissible leak rates for certain goods and toxins in various businesses.\n2. Manufacturing Considerations\nBefore performing a leak test, it’s important to consider the function for which a system, part, or object was originally made.\nThe target use case for a given object may require the manufacturer to have created it in such a way that it will either retain or allow liquids to pass through it.\nFor example, a car part may be designed specifically so that gases can’t escape from it, or an IV may be designed to keep liquids inside it.\n3. Medium Considerations\nWhen organising a leak test, the substance that the object is intended to hold must be taken into account. The sizes of molecules vary among various substances.\nKnowing the difference between a flaw that would be considered acceptable and one that would be large enough to let a particular liquid or gas escape is crucial when conducting a leak test.\nPressure is a relevant factor since various compounds will react differently to various pressure ranges.\nWhile a pressure range that is too low could produce ambiguous findings, a pressure range that is too high could potentially harm the object being tested.\nLeak Testing Equipment\nHere are some examples of the equipment types that are frequently used for various leak testing techniques.\n1. Air Leakage Inspection Devices\nInspectors can view data from ongoing leak tests on displays attached to air leak testing equipment.\nThese tools can be applied to numerous leak testing techniques, including vacuum decay, pressure decay, burst, chamber, and others.\n2. Compact Pressure Decay Leak Tester\nInspectors can limit the amount of connection volume required for the test by placing this small leak tester next to the fixtures being used for the test.\nDue to the volume reduction, the leak test's duration can be shortened, and its sensitivity raised.\n3. Large Display Leak Tester\nLarger display leak testers, like this one from Zaxis (called the 7i), have larger screens, more internal storage, larger test volumes, and faster testing.\nLeak Testing Standards and Codes\nInspectors use leak standards to contrast various leak systems or to establish the parameters of their leak test by simulating a leak in the component under test.\nFor code-based inspections, leak testing is frequently employed, and most nations that employ this type of testing for inspections will have a standard for leak testing.\nHere are a few of the leak testing codes that are more frequently used.\n1. ASME Section V Article 10 Leak Testing (Pneumatic and Hydrostatic)\nIn the ASME Boiler and Pressure Vessel Code, Section V, Article 10 provides detailed requirements and guidelines for conducting both pneumatic and hydrostatic leak tests on pressure vessels, piping, and other components.\n2. API 570 Inspection, Repair, Alteration, and Rerating of In-Service Piping Systems\nThe American Petroleum Institute (API) standard API 570 includes requirements for leak testing of piping systems in the petrochemical and refining industries.\nIt outlines procedures for conducting tests and evaluating the results.\n3. ISO 9712 Non-destructive Testing – Qualification and Certification of NDT Personnel\nISO 9712 is an international standard that includes provisions for the certification of personnel involved in Non-destructive Testing, including leak testing.\nIt outlines the qualifications and requirements for individuals performing leak tests.\n4. MIL-STD-750E Test Method Standard for Semiconductor Devices – Test Method 1071.1 Leak Detection\nMIL-STD-750E is a military standard that specifies test methods for semiconductor devices.\nTest Method 1071.1 covers leak detection, outlining procedures and criteria for leak testing in semiconductor manufacturing.\nLeak testing considerations, including acceptable leak rates, manufacturing considerations, and medium considerations, help tailor the testing approach to the specific object and its intended use.\nThe choice of pressure levels and understanding the properties of the substance being tested are crucial factors.\nVarious types of leak testing equipment, such as air leakage inspection devices, compact pressure decay leak testers, and large display leak testers, enable inspectors to conduct tests efficiently and accurately, depending on the application.\nIn essence, leak testing is a vital non-destructive testing method that ensures the safety and reliability of systems and objects that handle liquids and gases, contributing to overall quality control and maintenance procedures in various industries.\nInspectors use leak testing to determine if a system or object operates within a specified leak limit.\nLeaks occur when objects have flaws like holes, cracks, or other defects that allow liquids or gases to escape.\nIt is commonly used for items that handle or transport liquids or gases and is a Non-destructive Testing (NDT) method.\nLeaks occur as substances flow from areas of high pressure to low pressure.\nPressure is used to create flow towards areas of lower pressure, revealing the location of leaks.\nLeak testing is typically used for closed systems to check for defects.\nInvolves monitoring pressure gauges while introducing a solvent to spot pressure spikes caused by leaks.\nFills the tested element with fluid or gas, allowing gas bubbles to indicate leaks.\nIt's essential to know the permissible leak rate for an item or system, as not all leaks require immediate action.\nConsider the object's original design and intended use, as it may need to retain or allow specific substances to pass.\nDifferent substances have varying molecule sizes, affecting what constitutes an acceptable flaw.\nPressure is a critical factor, as various compounds react differently to different pressure ranges.\nReduces connection volume and enhances sensitivity for faster testing.\nProvides larger screens, more storage, and faster testing capabilities.\nLeak standards are used to compare systems and establish test parameters.\nCommon leak testing codes include ASME Section V Article 10, API 570, ISO 9712 , and MIL-STD-750E.\nQ: What is leak testing in NDT?\nA: Leak testing in Non-destructive Testing (NDT) is a method used to detect and evaluate the presence of leaks or unintended fluid or gas escapes in a sealed or pressurised system.\nIt is a non-destructive way of assessing the integrity of a component or system to ensure it doesn't allow substances to leak, which could be hazardous or result in operational issues.\nQ: What is an example of a leak test?\nA: An example of a leak test is the use of a pressure decay test. In this method, a component or system is pressurised to a specified level, and the pressure is monitored over a set period.\nIf the pressure drops, it indicates the presence of a leak. Another example is the bubble test, where a liquid or gas is applied to the surface of a component, and the formation of bubbles indicates a leak.\nQ: Why do we need leak testing?\nA: Leak testing is essential for several reasons:\nSafety: It ensures that pressurised systems do not leak potentially dangerous substances, preventing accidents or environmental harm.\nQuality Control: It verifies the quality and reliability of components or systems, reducing the risk of product failures.\nCompliance: Many industries have strict regulations and standards that require leak testing to meet safety and environmental requirements.\nCost Reduction: Early detection of leaks can prevent costly repairs or product recalls.\nQ: What is a leak and why is it used?\nA: A leak is the unintended passage of a substance (such as gas or liquid) from a contained space to the external environment. It is used as a term to describe a flaw or failure in a sealed system or component. Leak testing is used to identify and quantify these leaks to ensure the integrity and safety of the system or product.\nQ: What is the difference between a Hydrotest and a leak test?\nA: Hydrostatic testing (Hydrotest) and leak testing are both methods used to assess the integrity of pressurised systems, but they differ in their approach and purpose.\nHydrostatic Testing (Hydrotest):\nMethod: A hydro test involves pressurising a system or component with a liquid, typically water, to a predetermined pressure level.\nPurpose: It is primarily used to check for structural integrity and evaluate the strength of the component or system. It ensures that the item can withstand the expected operating pressure without permanent deformation.\nMethod: Leak testing involves pressurising a system or component with gas or liquid and monitoring for the presence of leaks.\nPurpose: The primary purpose of leak testing is to identify and quantify leaks or unintended fluid or gas escapes in a system or component.\nIt ensures that the system or product is free from leaks that could compromise safety, quality, or performance.\nHydrostatic testing focuses on structural integrity, while leak testing focuses on detecting and quantifying leaks in a system or component.\nBoth tests are crucial for ensuring the reliability and safety of pressurised systems in various industries."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:0ba8f779-d359-4a8d-a16f-084d63a68528>","<urn:uuid:5d7551b4-59c3-4c62-9f22-0509ed5c8831>"],"error":null}
{"question":"What topics does Charles Tilly's comprehensive reader cover?","answer":"The reader covers Tilly's contributions to revolutions and social change, war, state making, and organized crime, democratization, durable inequality, political violence, migration, race, and ethnicity, and narratives and explanations. It includes selections from works such as The Vendée, Coercion, Capital and European States, and his work on democracy, poverty, economic development, and migration.","context":["The Negotiating Agreement in Congress Research Grants are aimed at scholars who seek to understand the conditions under which political negotiation can be achieved (or not achieved) in Congress and other legislative arenas. The grants provide up to $10,000 of funding for each awardee, to be used for up to one year of research and writing. Applicants must have a PhD in hand by the application deadline and must hold an affiliation with a college or university based in the United States. For more information, please visit www.ssrc.org/nacg or contact email@example.com.\nDeadline: Sept 15\nEligibility: Applicants must have a PhD in hand by the application deadline and must hold an affiliation with a college or university based in the United States. Additional criteria can be found on our website.\nISA session being organized — “Non-union class struggles from below” — Session of the ISA World Congress of Sociology, July 2018, Toronto. Organized by Marcel Paret (University of Utah and University of Johannesburg)\nWhile many observers lament the declining significance and political power of organized labor, unions were never the only protagonists of resistance from below. Historical accounts include numerous examples of struggles by working classes and other economically marginalized groups. Similar examples of non-union resistance from below are rampant in the contemporary period of widespread economic insecurity. Groups that scholars consider to be especially “precarious” or even “surplus” to global capitalism – the unemployed, part-time and temporary workers, those eking out a living through “informal” activities, etc. – are prominent within these struggles. These struggles from below often connect economic demands to issues of citizenship, nationalism, and community.\nThis session will focus on class struggles from below, broadly defined but excluding struggles by capitalists and elites, that are taking place outside of formal union organizations. While maintaining emphasis on class-related demands and issues such as wages, land, and basic livelihood, relevant struggles may include significant or even dominant non-class dimensions (e.g. citizenship). Informal social networks, community-based organizations, political parties, or other non-union entities are also relevant. The goal is to highlight and contrast non-union class struggles in different parts of the globe, with attention to the influence of varying local, national, and regional contexts.\nRelevant themes may include, but are not limited to:\n- protests and riots by the urban poor;\n- mobilization by, for, and against migrants;\n- struggles by indigenous groups;\n- class dimensions of nationalist movements;\n- Occupy-type movements against austerity and economic inequality;\n- middle class movements;\n- peasant movements and/or struggles against land dispossession;\n- organization by self-employed workers or independent contractors;\n- political party mobilization;\n- workplace resistance by non-unionized workers;\n- worker centers and other community-based worker organizations.\nTo submit a paper to this session, please go to the following link: https://isaconf.confex.com/isaconf/wc2018/webprogrampreliminary/Session10931.html. Click the “Submit an Abstract to this Session” button to upload your submission. You will need to create an account with ISA if you do not have one already.\nThis session will be organized as a roundtable, and is listed in the program under “RC44 Roundtable”. Please direct any questions to Marcel Paret at firstname.lastname@example.org.\nErnesto Castañeda & Cathy Lisa Schneider. 2017. Collective Violence, Contentious Politics, and Social Change: A Charles Tilly Reader. Routledge.\nCharles Tilly is among the most influential American sociologists of the last century. For the first time, his pathbreaking work on a wide array of topics is available in one comprehensive reader. This manageable and readable volume brings together many highlights of Tilly’s large and important oeuvre, covering his contribution to the following areas: revolutions and social change; war, state making, and organized crime; democratization; durable inequality; political violence; migration, race, and ethnicity; narratives and explanations.\nThe book connects Tilly’s work on large-scale social processes such as nation-building and war to his work on micro processes such as racial and gender discrimination. It includes selections from some of Tilly’s earliest, influential, and out of print writings, including The Vendée; Coercion, Capital and European States; the classic “War Making and State Making as Organized Crime;” and his more recent and lesser-known work, including that on durable inequality, democracy, poverty, economic development, and migration. Together, the collection reveals Tilly’s complex, compelling, and distinctive vision and helps place the contentious politics approach Tilly pioneered with Sidney Tarrow and Doug McAdam into broader context. The editors abridge key texts and, in their introductory essay, situate them within Tilly’s larger opus and contemporary intellectual debates. The chapters serve as guideposts for those who wish to study his work in greater depth or use his methodology to examine the pressing issues of our time. Read together, they provide a road map of Tilly’s work and his contribution to the fields of sociology, political science, history, and international studies. This book belongs in the classroom and in the library of social scientists, political analysts, cultural critics, and activists."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:5abbe21a-cf8f-4116-9a3c-4abfddba26a5>"],"error":null}
{"question":"What's the difference between phishing scams targeting tax preparers versus supply chain ransomware attacks in terms of scope?","answer":"While phishing scams targeting tax preparers focus on capturing individual usernames and passwords to access taxpayer data through deceptive emails mimicking IRS correspondence, supply chain ransomware attacks have a much broader impact. For example, in the 2021 Kaseya attack, around 1,500 managed service provider clients were affected simultaneously. Similarly, the SolarWinds ransomware attack impacted 18,000 corporate customers, including Fortune 500 companies and U.S. government agencies, demonstrating how supply chain attacks cause more widespread damage than attacks targeting individuals.","context":["Phishing Scam Targets Tax Preparers To Get To Taxpayers\nFraudsters don’t take holidays. In fact, they tend to be more active this time of year because they believe we are more likely to let our guards down. Instead, I don’t intend on falling for any of their traps, and I encourage you to do the same.\nIt’s A Trap\nWe recently published a blog post with tips to help online shoppers protect themselves against some of the more common tactics used by cyber criminals. From click bait to phishing emails, every link, sponsored post and flashing banner ad is a potential threat and we encourage you to protect yourself at all costs.\nFor example, you likely receive regular electronic correspondence from companies, organizations, groups and other reputable groups. In fact, you probably willingly provided them with your email address. You may even trust these contacts so much that you never thinking twice about whether their email is valid, and that’s what criminals are counting on. Nobody is immune.\nRead Also: Who Is That Email Really From?\nA current scam finding its way into inboxes across the country is targeting tax preparers. The email, which is supposedly being sent by the IRS, looks legit and includes the agency’s letterhead, logo and copyright language, among other information designed to add credibility to the piece. But there’s a problem – this email is not official IRS correspondence. Instead, it’s being sent by cyber criminals who are looking to capture usernames and passwords to gain access to taxpayers’ sensitive data.\nWe’re Not Falling For It\nThe American Institute of CPAs reached out to the IRS to verify whether the email in question is, indeed, a phishing scam. The government agency confirmed that the email was a scam and were quick to advise recipients to delete the message immediately.\nThis is just one example of a phishing scam in action. Emails like these are distributed every day and, oftentimes, they come from trusted businesses, organizations or people. As cyber threats continue to be rampant in our society, we must never allow ourselves to become complacent.\nWhat You Can Do\nHere are some tips to help keep you safe.\n- Do It Yourself – Never click on hyperlinks found within the body text of the email – especially if you received the message from an unknown sender. If you do want to check the validity of an offer or content, manually type the URL into your web browser. Same results, less risk.\n- ‘S’ For Safety – If confidential information is being traded, take a look at your address bar to make sure it reads “https” rather than the standard “http” to be sure the web page you are visiting is, indeed, secure.\n- If It Pops, Run – Sometimes, the best and easiest strategy you can take to protect yourself from scammers is to configure your computer’s settings and buy and install the proper tools. We recommend disabling all popups, keeping an updated antivirus, use anti-spam and anti-spy software and install and maintain a firewall. Cyber criminals are always looking for ways to get around these measures, but they still provide you with a great first defense.\n- Watch Your Back With A Backup – We keep a lot of irreplaceable items on our computers and, to many, the thought of permanently losing their data, photos and other documents is terrifying. One way to take the power away from the scammers is to create and maintain a backup of your data – especially when considering the very real threat of ransomware. That way, if something were to happen, you wouldn’t lose these vital items.\n- Education Is Power – These criminals are slick and they are always finding new ways to take what belongs to you. So, one of the absolute best ways to guard against an attack is to educate yourself on current cybercrimes, identity theft trends and tactics being used by fraudsters.","Financial Costs of a Ransomware Attack and Breaking the Attack Chain Ransomware is a type of malware that typically utilizes encryption to impede or restrict admittance to information until a payoff is paid.\nFor organizations that experience the ill effects of a ransomware attack, the blow-back to income is in many cases more terrible than the size of the payoff and regardless of whether to pay it. The monetary harm can be far reaching and go a long ways past how much the payment.\nThe Financial Costs of a Ransomware attack can be huge. In addition to the ransom, businesses lose business due to downtime. These losses can quickly compound and spiral out of control. For example, one ransomware attack affected Maersk and left the company unable to operate for weeks. The company estimates that the downtime cost them $300 million.\nSpecialists suggest that organizations don’t pay ransoms as it gives cybercriminals a thought process to proceed. Organizations that really do wind up paying the payoff are frequently disheartened with the outcomes.\n- The information they recuperate is harmed.\n- The aggressors request more cash.\n- The aggressors disappear, and they don’t recuperate their information.\nLate investigations by Sophos and Pao Alto put the normal ransomware attack costs at somewhere in the range of $570,000 and $812,360.\nAs cybercriminals now utilize hilter kilter encryption strategies, having the option to unscramble the information is profoundly impossible. If you would rather not pay the payment, you will either need to recuperate the information from reproductions or reinforcements or lose it through and through.\nAt the point when you experience a ransomware attack, it is smarter to pick up and move on and follow your occurrence reaction plan. In the event that you have a viable recuperation plan set up, you might have the option to recuperate your information with negligible disturbance, and you won’t have to pay the payment. A recuperation plan typically includes five stages: survey, moderate, answer, convey, and hindsight.\nCounteraction is in every case better compared to attempting to manage the broad harm a ransomware attack can cause. Figure out more about how to diminish the gamble of turning into a ransomware casualty in any case at Discernment Point.\nCyber Insurance Academy\nThe cyber insurance industry is in a state of flux as more organizations are exposed to ransomware attacks. These attacks see hackers infect an organization’s computer network and demand money in return for control. These attacks have resulted in a massive increase in ransom payments, increasing by three-fourths to $412 million by 2020. In response, the cyber insurance industry has started an educational program to prepare students for such attacks.\nCyber insurance could take a cue from other forms of insurance. One professor at King’s College London studied the phenomenon of kidnap for ransom insurance and discovered that the insurance company’s “disruptive bargaining” strategy helped reduce kidnap gangs’ demands.\nWhile ransomware is becoming increasingly widespread, some insurers are beginning to reconsider their policy and stop covering ransom payments. For example, AXA, which insures several large French companies, has decided to stop covering payments to ransomware attackers for future policyholders. This move has come in response to government pressure.\nGovernments are eager to provide adequate cyber insurance coverage but don’t want insurers’ solvency to suffer. The failure in either direction could lead to a financial burden on governments. Cyber insurance companies are increasingly working with outside firms to vet their insureds’ security protocols and procedures.\nBy restoring your computer and all of its data with NeuShield, you can stop ransomware attacks from destroying your information. Ransomware typically attempts to encrypt and wipe a disk, but NeuShield protects your data by restoring it to the original state. It does this by creating an undetectable overlay over your data. The attacker only has access to the data that is in the overlay – all of your original files are preserved. Moreover, NeuShield can be restored to a previous state, allowing you to regain access to your information quickly and easily.\nAnother key aspect of defending your computer is breaking the attack chain. By understanding the structure of cyber attacks, you can identify and block them before they start. The attack chain is also known as the kill chain, and it is originally a military concept. It describes the methods of malware infiltration, deployment, and execution. Basically, breaking the attack chain means to prevent the attacks before they begin, but it is not as easy as it sounds. Whether you are a small or large business, the idea of breaking the attack chain is important and a vital part of cyber security.\nCybercrime has continued to evolve rapidly, and the scope of its attacks increases. As a result, future attacks will be much harder to detect and respond to. This arms race between attackers and defenders is becoming more apparent. In many ways, this is why cyber insurance premiums have skyrocketed.\nWhile traditional endpoint security can prevent the majority of cyberattacks, it may not be enough. Malware has become so sophisticated and evasive that traditional signature-based endpoint security cannot keep up. As a result, organizations need to employ a multi-layered endpoint protection strategy to combat the latest threats. By deploying a multi-layered endpoint security strategy, you can stop threats across multiple attack chains.\nAn innovative multistakeholder approach can effectively disrupt the financial capabilities of malicious actors and help reduce the global impact of ransomware attacks. Such an approach would leverage information-sharing and pooled resources to assess the costs and organizational vulnerabilities of ransomware.\nRansomware is a highly disruptive and costly cyberattack that can lead to crippling downtime and substantial productivity losses. The costs of downtime and recovery are enormous – some estimates estimate that they are 50 times higher than the ransom demands. The downtime from a ransomware attack can affect a business for months and may cause it to file for bankruptcy.\nThe recovery process from a ransomware attack is complicated and requires all hands on deck. Depending on the size and scope of the attack, it may involve internal teams, incident response companies, forensic experts, and even the assistance of local and federal law enforcement agencies. Each step in the recovery process carries its own set of costs. Some companies may choose to pay the ransom instead of dealing with the recovery process, avoiding the financial consequences of losing customer data.\nThe impact of ransomware attacks is becoming increasingly widespread and complex. As a result, CISOs are losing confidence in the ability to mitigate ransomware attacks. Moreover, 73 percent of respondents said that failure to mitigate the risk of cyberattacks could expose organizations to fines and legal action. Cybersecurity Ventures estimates that ransomware attacks will cost $265 billion by 2031, which makes it crucial for organizations to prepare for the costs of these attacks.\nRansomware supply chains have become more sophisticated. As a result, cybercriminals are now targeting companies with extensive digital networks. This means that ransomware supply chain attacks will become more prevalent in the future. The SolarWinds ransomware attack, for example, should serve as a warning to all companies with global supply chains. This attack affected 18,000 corporate customers, including Fortune 500 companies and U.S. government agencies.\nIn January 2022, the BlackCat ransomware group infected 233 gas stations in Germany and forced the oil company Shell to reroute supplies. The attack used two vulnerabilities in two different software applications to encrypt data and exfiltrate intellectual property. The resulting disruptions rendered more than half of the organization’s systems inoperable for 48 hours, forcing Shell to hire security experts to restore access to their systems. The attack was so widespread that German intelligence services feared that the attackers had penetrated the networks of gas stations and oil companies to steal information. In Baltimore, the ransomware attack affected the city’s official email servers and rendered critical systems inaccessible.\nMany small and medium-sized companies have limited resources to protect themselves from ransomware. Security is costly and time consuming, so they often put off investing in it in favor of other critical business requirements. Unfortunately, the longer they wait to secure their networks, the more expensive it will be to repair the damage. This negative feedback loop has left many organizations unprepared for attacks and paved the way for predatory ransomware groups.\nThe costs of ransomware attacks can be staggering. In the United States, companies face billions of dollars in ransomware losses every year. As a result, ransomware has become a top concern for businesses, affecting both organizations and consumers. In addition to the financial burden of downtime, ransomware can damage a company’s reputation, and cause customers to lose trust in it.\nThe cost of ransomware attacks is escalating – a single attack can cost up to $265 million. Those figures are staggering, and many companies that have been affected go out of business within a year of being infected. Fortunately, there are ways to mitigate the risk of a ransomware attack.\nThe financial costs of a ransomware attack can be staggering. The Cybersecurity Ventures report predicted that ransomware attacks would cost more than $5 billion in 2017, up from $325 million in 2015. This represents a 15X increase in just two years, with a projected total of $8 billion in 2018 and $11.5 billion in 2019. By 2021, ransomware attacks are expected to cost $20 billion, and every 11 seconds, an average business will be hit by ransomware.\nIn addition to the financial cost, ransomware attacks can also have a huge impact on an organization’s business. For example, an attack on the Colonial Pipeline Company caused a panic buying of fuel on the East Coast because a compromised password had given access to their IT system. The attack resulted in the shutdown of the company’s operational technology networks and IT systems for several days. Fortunately, the company was able to recover a significant portion of the $4.4 million ransom.\nIn addition to monetary costs, the recovery and downtime costs associated with a ransomware attack are also enormous. This is why it is essential to seek outside legal counsel when dealing with ransomware. A seasoned attorney will be able to guide you through the process and minimize your risk.\nTrend Micro has also recently discovered a new vulnerability impacting e-commerce websites. In April 2021, the company found that BIQS software was vulnerable to an XSS vulnerability, which could allow threat actors to inject malicious code on the servers. In August, the company also discovered that Atlassian Confluence servers were vulnerable to a local file inclusion vulnerability, allowing threat actors to insert arbitrary code on its servers.\nDowntime and labor costs\nWhile your frameworks are down, you will experience monetary misfortunes. Most associations require essentially a week and frequently significantly longer to recuperate information. Until it is reestablished, your entire situation is probably going to be disabled. Client information is essential to maintaining a business easily, and without it, you will fight to sell items, administration clients and substantially more. A regular efficiency misfortune can really depend on 20% during free time.\nIn a 2021 ransomware attack, the Kaseya assault, around 1,500 oversaw specialist organization clients were impacted. This shows how store network assaults cause more broad harm than assaults against single people.\nIT groups frequently need to stay at work past 40 hours to reestablish frameworks, and there is normally an overabundance of work all through an association because of an absence of admittance to information. Extra counseling or expert help might be expected to determine information issues.\nThe cost to brand reputation\nA harmed brand notoriety is difficult to fix, and this can have a broad monetary effect. Any bad exposure about an information break can influence the relationship with clients as well as with representatives, financial backers and different partners. Research from the Public Digital protection Coalition shows that around 60% of little to medium organizations leave business in no less than a half year of encountering an information break.\nThere’s a developing pattern for cybercriminals to take steps to uncover delicate information they exfiltrate before encryption. Where the information is strategic, for example, in medical clinics, government or crisis call focuses, this can really hurt.\nIn certain enterprises, clients can guarantee direct pay for an information break. Scripps Wellbeing, retail goliath Target, and gas organization Frontier Pipeline are only a portion of the organizations that have confronted legal claims.\nMost cases are privately addressed any remaining issues as organizations would rather not face extended court fights. Administrative and legitimate fines can be especially high for the spilling of individual wellbeing information, monetary data like charge card subtleties, and actually recognizable data.\nData loss and collateral damage\nYou might lose an information totally due to a ransomware attack. The deficiency of information might address many long stretches of work. Regardless of whether you can reestablish records from reinforcements, there’s an opportunity they were not supported totally or accurately. Today there are ransomware variations that likewise target reinforcement frameworks so you can’t reestablish information.\nYou should figure out how cybercriminals accessed your frameworks. There are numerous ways they can do as such, from conveying phishing messages and setting up counterfeit sites to straightforwardly going after programming weaknesses.\nContaminated machines might need to be totally reformatted, and programming reinstalled. You will likely need added assurance to ensure another information break doesn’t happen.\nIn the ongoing monetary circumstance with expansion and downturn, every one of the costs of a ransomware attack might cause a huge monetary misfortune. In 2020 different reports demonstrated that the normal expense of tidying up after a ransomware attack could depend on $1.85 million. In the event that you don’t tidy up your information and fix any fundamental issues, you could gamble with another assault.\nStep by step instructions to prevent ransomware attacks\n- Having security frameworks set up, representative preparation, and powerful design the executives are a portion of the ways of forestalling ransomware attacks.\n- Keeping awake to date with the most recent working software is vital.\n- Ensure you have total and exceptional reinforcements as they can assist you with recuperating information.\n- Stay up with the latest, and remember to apply security patches.\n- Persistently look at security to ensure you have the right estimates set up.\nIT experts need to adopt a protection strategy as once programmers get inside your association, limiting the damage can be hard. You want to safely safeguard each channel, with email frequently being quite possibly of the most weak one.\nCybercriminals keep on utilizing perpetually complex methods to convey ransomware by means of email. You want to search for cutting edge email security arrangements that utilization quick and successful unique filtering. Arrangements ought to likewise can identify dangers covered somewhere inside happy.\nRansomware can be monetarily harming to organizations in various ways, including pay-off costs, personal time costs, work costs, notoriety harm and legitimate expenses. Associations need to investigate their network protection safeguards. Distinguishing and managing likely dangers and channels, for example, email and cloud coordinated effort apparatuses, can assist with alleviating ransomware attacks.\n- Also Read: Price In India Emo Robot What Is The Cost?\n- Also Read: Kbm 25 Com Know The Latest Authentic Details!\n- Also Read: Is My Derma Dream Legit? Authentic Review!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:5146d52d-aaa7-4bf2-85b2-ddd8d19da972>","<urn:uuid:a4aad484-a3a3-4984-8feb-404e3a6bba70>"],"error":null}
{"question":"What are the typical dimensions of modern industrial wind turbines? I'm researching renewable energy infrastructure.","answer":"Modern industrial wind turbines stand in excess of 150 meters tall, with blades that are 60 meters long. These blades can rotate with tip speeds up to 300 km/h and can weigh up to 15 metric tons.","context":["Silent behemoths supporting 60-meter blades that rotate with tip speeds up to 300 km/h and weigh up to 15 metric tons, industrial wind turbines are modern engineering miracles. These sentinels of electric power often stand in excess of 150 meters tall and must withstand decades of harsh environmental conditions found offshore, in coastal regions and on mountaintops.\nIndustrial wind turbines cost roughly $1.2 million/MW to build based on a 1- to 3MW turbine. Installation costs increase the investment by a factor of 1.2 to 1.35 for onshore projects, with offshore installation costs being significantly higher. Turbine manufacturers and owners are constantly looking for ways to reduce manufacturing and maintenance costs and increase profitability by shortening production cycles, increasing production volume, and simplifying maintenance requirements. Figure 1\nAdhesives, sealants, lubricants and surface treatments play critical roles in the life, health and financial soundness of wind turbines. These materials are used during every phase of manufacturing, installation and day-to-day operation.\nTurbine Manufacturing and Assembly\nFor blade and nacelle production, gigantic molds are first treated with semi-permanent mold release agents that allow large-scale composite parts to be easily removed from the mold. Blade halves and nacelle body components are bonded together and sealed using structural adhesives such as two-part polyurethanes that prevent crack propagation, micro-cracking and fatigue, and ensure the long-term integrity of the structure. Two-part polyurethanes also fill voids found on the molded assemblies (see sidebar on polyurethane technology).\nTwo component polyurethane adhesives and MS polymer sealants are used to permanently bond components such as access doors, rain deflectors and gurney flaps to the blades. Color-matching, weather-resistant MS polymers and high performance sealants protect and seal the blade and nacelle interior and exterior from moisture and environmental contaminants.\nWhen metal tower components are manufactured, surface treatments such as coatings, conversion coatings and cleaners/degreasers prepare the surface to improve corrosion resistance and paint adhesion. These large parts are then ready for assembly.\nOn the tower, sealants prevent moisture from penetrating in through tower section breaks and prevent corrosion on load support plates, platforms, bolt heads, ladder frames and other metal surfaces. Anaerobic threadlockers lock and seal large threaded fasteners. Structural adhesives are used to bond and secure ladders and other components.\nAnaerobic adhesives play critical roles throughout the turbine assembly, locking and sealing threaded fasteners found on the base, tower, nacelle and blades. Anaerobic materials are widely used in hub, bearing and the gearbox assembly where they retain pitch and yaw bearings, and seal gearboxes, flanges and hydraulic fittings. Anti-seize lubricants protect power train splines, mounting bolts and exposed fasteners.\nThroughout the turbine, heavy duty solvent-based and aqueous cleaners remove dirt and residues from composite and metal parts and prepare them for installation and operation in the field.\nDuring installation, epoxy grout materials are used to create a level, secure base for tower assembly. High strength epoxy grouts bond to steel, concrete and other construction materials and withstand high torque loads. Urethane sealants bond, seal and waterproof tower bases. Cables that route out of the turbine to deliver electricity must be sealed to stop moisture/water from entering the turbine, preventing corrosion. Highly flexible silane modified polymers demonstrate good adhesion to many substrates and create a soft, elastic seal. Figure 2\n|Polyurethane Adhesive Technology for Rotor Blade Bonding|\n|Until recently, most wind blade manufacturers have used GL-certified two-component reactive epoxy resins to bond load-carrying structures like rotor blades. While epoxies offer excellent adhesion, shear strength and chemical/heat resistance, they are expensive to process, take a considerable length of time to cure completely (slowing the production cycle time), and generate extreme exotherm during cure, which may lead to crack formation. These limitations increase the risk for warranty claims and field repair, and can contribute to ultimate blade failure.\nA new high performance polyurethane adhesive technology (from Henkel Corporation, Macroplast® UK 1340™) is consistently contributing to the assembly of highly efficient wind turbines. This adhesive satisfies the specific mechanical requirements for use in the wind power industry, improves the long term reliability of rotor blades and makes rotor blade production faster and less expensive.\nNew PUR technology provides excellent static and fatigue strength, excellent toughness, and resists crack propagation, while significantly improving the efficiency of rotor blade production. The new PUR requires fewer curing steps than epoxies, resulting in reduced assembly costs and 15 to 30 percent shorter production cycles. This improves payback time on critical investments such as molds and factory facilities, and decreases the number of required production lines.\nAdditionally, the new PUR rapidly develops sufficient green strength for demolding, enabling demolding in a partially cured state followed by a freestanding postcure — a further lever to reduce production cycle time and costs. In addition to blade bonding, two component polyurethane adhesives can be used to attach components to the rotor blade, for nacelle assembly, and for securing the ladder to the tower assembly.\nGL requirements for adhesives primarily relate to shear strength, long-term durability, creep behavior and glass transition. The adhesive’s physical properties are temperature-dependent. Within a temperature range known as glass transition (Tg), the adhesive’s mechanical properties change considerably from brittle or glass-like at low temperatures to flexible or rubbery-elastic at the high end of the range.\nFor rotor blades, GL requires a Tg of at least 65°C to prevent bond crep or relative movement of the substrates and achieve rigidity at higher ambient temperatures. However, typical polyurethane adhesives offer a range of only -30 to 45°C, depending on the desired elasticity.\nOffering breakthrough Tg better than typical polyurethanes, Macroplast® UK 1340™ is the only adhesive in its class to satisfy GL’s requirements. Extensive tests have also demonstrated a tensile shear strength exceeding 20 MPa in the -40 to +80° C temperature range and a Tg of 65°C and higher. This improved tensile fatigue strength allows wind blades to better handle deflection across the length of the blade and dynamic load and stress on the adhesive bond line, reducing the risk of damage that may require repair or replacement.\nThe two-component PUR consists of a resin and a hardener. After mixing, pot life ranges from 30 to 90 minutes at 20°C, but can be adapted as required for a specific manufacturer’s production process without the disadvantage of partially overheating the adhesive joint. Manufacturers can maximize throughput without increasing stress in the part or the potential for stress cracking associated with high exotherm.\nThe new PUR adhesive generates much lower exotherm of up to 75°C maximum when compared to the 120ºC - 150ºC exotherm of epoxies. Reducing exotherm benefits the process in two ways. First, when composite materials are bonded, stress cracking caused by excessive thermal loading may weaken the rotor blade as a whole. This risk is significantly reduced if the reaction temperature is lower. Second, high temperature polymerization is always accompanied by changes in volume. Low heat emissions and lower thermal loading during chemical crosslinking reduces heat related shrinkage in the bond line. Controlled shrinkage results in a more durable bond over time.\nThe heat generated from an exothermic reaction will vary depending on the quantity of adhesive undergoing cure. In areas where larger amounts of adhesive are applied, temperatures get much hotter than in those areas with less adhesive volume.\nOn a single rotor blade there are considerable differences in the quantity of adhesive applied and, therefore, considerable differences in stress. At the interfaces between such stress fields, mechanical flaws will occur, unless the stress is relieved through elaborate tempering. This is where polyurethane systems with low-temperature exothermic reactions have big advantages, particularly when applied in thick films.\nFrom the moment a turbine is assembled and begins to turn, it is exposed to environmental hazards. Lightning, turbulence, sand, rain, hail, snow and bird-strikes all contribute to wear and damage to the blades and nacelle. Corrosion affects the aesthetics and eventually compromises the strength of the tower, while erosion damages the concrete foundation, causing cracks, chips and spalling.\nComposite blade tips commonly experience micro-cracking and structural cracking that can be significant and require installation of a new tip or a structural patch. Bird and lightning strikes can penetrate the blade and require repair to the core material, the blade substrate and the blade surface. Pitting and wear caused by weather and environmental elements can decrease the performance and efficiency of the wind turbine.\nHigh viscosity, structural polyurethane putties are hand applied to the eroded edges of the blade to fill pitting and wear damage. Fast-curing, abrasion-resistant putties are used as a repair system along with polyurethane hand lay-up resins and polyurethane structural bonding adhesives, for damage caused by lightning or bird strikes. Cartridge dispensed two-component structural polyurethane adhesives bond patches for damaged tips. To reduce the chance of subsequent lightning strikes, lightning diverter strips designed to transmit and ground lightning away from the blades, can be applied to blade surfaces using a structural adhesive. Working together, these adhesives and sealants return the blades to their original smooth and wind-resistant design and allow the blades to rotate again with little downtime.\nOn and in the nacelle, sealants are used to protect the generator and motor housing, panels, hinges, service doors, manholes and exterior appliances such as wind indicators, lights, rails or cable breakthroughs from moisture ingress and corrosion. Anaerobic materials protect yaw bearings and keep gear boxes operating efficiently and reliably. Anti-slip coatings create walking surfaces with good traction so that maintenance workers will not slip in cold, wet and icy conditions outside the nacelle or slippery, lubricant and coolant-coated surfaces inside the nacelle.\nThe tower assembly must be treated on an ongoing basis with maintenance chemicals to keep it strong and solid throughout the long life of the turbine. High flexibility adhesives and sealants ensure the tower sections stay together and seal out water and chemicals that can cause corrosion and enter the tower assembly. Chemically resistant coatings and galvanizing compounds protect the metal towers from corrosion and damage. Threadlocking and structural adhesives keep accessories such as ladders and platforms in place and prevent threaded fastener failure.\nTo ensure that blades achieve maximum aerodynamic efficiency, they must be regularly cleaned of contaminations such as algae, dirt and sand. Water-based cleaners quickly cut through grime and reduce the effort and time required for cleaning. By applying specially formulated coatings, maintenance crews can reduce the likelihood of new contaminants sticking to the blades and can increase the turbine’s total power production until the next scheduled cleaning.\nOn the base of the turbine, damage and cracks in concrete pads will deteriorate over time from exposure to outside elements. Repairing damaged areas using crack fillers and fast-fixturing concrete repair products increases the life of the concrete structure and helps it resist future damage.\nBy incorporating adhesives, sealants and surface coatings from start to finish in wind turbine production, manufacturers can produce more robust turbine components and longer-lasting assemblies. Automated processes shorten production cycles, increase production volume and reduce manufacturing costs. And stronger, more reliable turbine components mean less maintenance when the turbine is assembled and in operation in the field.\nDuring installation and maintenance, wind farms that use adhesives, sealants, lubricants, surface treatments and cleaners top to bottom on their turbines simplify and speed installation, minimize downtime and ensure a safe work environment. The turbines are more efficient, more reliable, and provide more energy over the expected lifespan."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:63ff226a-0c2b-4aee-89b8-e279e7b54337>"],"error":null}
{"question":"What are the key functional differences between a stereo microscope and a compound microscope in terms of specimen viewing and applications?","answer":"A stereo microscope and compound microscope differ significantly in their specimen viewing capabilities. The stereo microscope has only two sets of lenses and is designed to view opaque objects where light doesn't pass through the specimen, allowing surface observation of dissection specimens up to 300 times magnification. In contrast, the compound microscope requires translucent specimens that allow light to pass through them, has multiple lens sets, and can achieve up to 1,000 times magnification. The compound microscope is primarily used for observing microscopic specimens, while the stereo microscope is specifically used for visualizing opaque objects that cannot be viewed using a compound microscope.","context":["The image at the left is that of a dissecting or\nstereo microscope. Notice that it has only two\nsets of lenses, including the eyepiece. The\nspecimen to be observed is an opaque object (light\ndoes not pass through it). The observer sees\nthe surface of the dissection specimen or other specimen\nbeing studied. This specimen is placed in a\ncontainer on the stage of the microscope.\nBiologists use the light microscope to observe microscopic\nspecimens. This microscope is also called the\ncompound microscope is given its name because it has more than\ntwo sets of lenses. It has an eyepiece lens (or ocular)\nand two or more sets of objective lenses (this microscope has\nthree lenses) on a nosepiece that usually revolves.\nThis kind of microscope is also called a light microscope as\nit requires a source of light to pass through the specimen.\nThe specimen observed with this kind of microscope is usually\nmicroscopic and has to be translucent (allows light to pass\nthrough it). The specimen to be observed is placed on\nthe stage of this microscope.\nParts of the Light\n- eyepiece or ocular\n- body tube\n- fine adjustment knob\n- high power objective\n- low power objective\n- mirror (many microscopes have a\n- coarse adjustment\n- stage clip\n- inclination joint\nFunctions of the Light Microscope Parts\neyepiece (ocular) -\nwhere you look through to see the image of your specimen.\nbody tube-the long tube\nthat holds the eyepiece and connects it to the objectives (not\nfine adjustment knob-small,\nround knob on the side of the microscope used to fine tune the\nfocus of your specimen after using the coarse adjustment knob\npart of the microscope at the bottom of the body tube; it\nholds the objectives\nhigh power objective --\nused for high power magnification of the specimen (the longer\nlow power objective --\nused for low power magnification of the specimen\namount of light going through to the specimen\nlight or mirror-source\nof light usually found near the base of the microscope; makes\nthe specimen easier to see\ncoarse adjustment knob\n-- used for focusing on low power\narm-part of the\nmicroscope that is grasped when one carries the microscope\nclips on top of the stage which hold the slide in place\n(The specimen is placed on the stage for viewing.)\ninclination joint -is\nused to tilt the microscope\nMicroscope Usage Rules\n- Always carry the microscope with two hands - one on the\narm and one underneath the base of the microscope. Hold it\nup so that it does not hit other objects.\n- Do not touch the lenses. If they are dirty, ask the\nteacher for special lens paper or ask your teacher to clean\nthe lenses for you.\n- If using a microscope with a mirror, do not use direct\nsunlight as the light source. Blindness can result. If using\na microscope with a light, turn off light when not in use.\n- Notify teacher if a slide or cover slip breaks. Students\nshould not handle broken glass.\n- Always clean slides and microscope when finished. Store\nmicroscope set on the lowest power objective with the\nnosepiece turned down to its lowest position (using the\ncoarse adjustment knob). Cover microscope with dust\ncover and return it to storage as directed by your teacher.\nAbout the Compound Microscope\nAlways begin focusing on the lowest possible power.\nRemember to center the specimen you\nare observing in the field of\nview before switching to a higher power. Make\ncertain that you\nmove the objectives away from\nthe specimen when focusing so their is no collision between\nthe objective being used and\nthe slide/cover slip which may damage the objective lens.\n2. As you switch from low to high power, the\nfield of view becomes darker. To deal with this\nthe diaphragm needs to be\nopened to allow in more light. (Frequently on\nlow power the\ndiaphragm needs to be partially\nclosed as it is too bright.)\n3. As you switch from low to high power the\nfield of view becomes smaller.\nImages viewed under the light microscope are reversed\n(backward) and inverted (upside down).\nThis is a compound light microscope view of the letter F\nplaced on a slide in its normal position.\nPaper chromatography is a procedure used to separate\nsubstances in a mixture. In the Living Environment/Biology\nlab, this mixture is usually a solution of liquid plant\npigments containing different kinds of chlorophylls and other\ncolored photosynthetic pigments.\nA small concentrated sample of a mixture is placed on the\nchromatography paper above the line of a solvent mixture.\nThe paper is contact with a solvent solution at its bottom.\nThis solvent moves through the paper due to capillary action\nand dissolves the mixture spot. Some parts of the\nsolvent mixture to be separated have a greater attraction for\nthe chromatography paper, so they move a lesser distance,\nwhile other parts of the solvent mixture have a lesser\nattraction, so they move a greater distance up the paper.\nChromatography of a Plant Pigment\nThe specific mixture placed on chromatography paper will\nseparate into consistent patterns as long as the same solvent,\npaper, and amount of time allowed for the separation are not\nchanged.. Different solvents will change the separation\npattern of the mixture. Mixtures that are colored can be\nseparated into component colors by paper chromatography.\nThe Rf value of a pigment is a statistic often computed\nfrom a chromatography separation. Each component\nof a solution. Each pigment in the solution will\nhave a specific Rf for the same solvent when the\nchromatography occurs for a specific length of time.\nCalculation of Rf\n|| distance the pigment travels from\nthe original spot of solvent\ndistance to the wetting front of the solvent\nGel electrophoresis is a procedure used to separate charged\nmolecules of different sizes by passing them through a gel in\nan electrical field. The gel serves to act as a\nsupport for the separation of the molecules of different\nsizes. The gel is usually composed of a jelly-like\nmaterial called agarose which is made from seaweed.\nMolecules such as DNA fragments of different lengths and\nproteins of different sizes are often separated in the gel.\nHoles are created in the gel which serve to hold the\nparticular DNA mixtures to be separated. The\nDNA fragments are then loaded into the wells in the gel.\nSeparation of DNA\ncontains very small holes which act to regulate the\nspeed which molecules can move through it based on\nthe size of the molecules. The smaller\nmolecules will move much more easily through the\nsmall holes in the gel. As a result,\nlarge fragments of DNA lag behind small fragments,\nthus allowing the experimenter to separate these\nmolecules based on their size.\nSometimes molecular weight markers\nare electrophoresed along with the specimen, so the\nexperimenter may know the size of the DNA fragment which has\nbeen separated. Different individuals or organisms form\ndifferent banding patterns in the plate when their DNA has\nbeen separated. DNA is cut into pieces for\nseparation for electrophoresis by restriction enzymes.\nThese enzymes were originally discovered in bacteria and were\nused by the bacteria to defend themselves from invasion by\nother bacteria and viruses.\nSome Uses for\nthe Gel Electrophoresi DNA Separation\n- It may be used to determine an individual's genetic\nrelationship to his or her ancestors, as the more closely\nmatched the banding pattern between two individuals, the\nmore closely they will be genetically related.\nIn theory, no two individuals will form the same DNA\nbanding pattern when the electrophoresis is completed.\n- It may be used to identify an individual that have\ncommitted crimes based on the ability to match the\nsuspects DNA to evidence which has been collected at a\n- It may be used to determine evolutionary\nrelationships between organisms, as organisms with a\ncloser genetic relationship will form more similar\nSetup with Power Supply\nGel Electrophoresis for Separating DNA Molecules (Dr.\nKaren Hughes/University of Tennessee at Knoxville)","A microscope is one of the commonly used equipment in a laboratory setting. A microscope is an optical instrument used to magnify an image of a tiny object; objects that are not visible to the human eyes.\nThere are two types of optical microscopes and these are the simple and compound microscopes. There are various types of microscopes and each type has a specific set of functions.\nThe common types of microscopes are:\n- Simple microscope – It was the first microscope ever created. It was created by Antony van Leeuwenhoek in the 17th century. He combined a convex lens and a holder for specimens. It looks like a magnifying glass because it has the ability to magnify between 200 and 300 times.\n- Compound microscope – It comes with more than one lens and provides better magnification than the simple microscope. A compound microscope is also called a bright field microscope. It can provide magnification by up to 1,000 times.\n- Stereo microscope/dissecting microscope – It can magnify objects by up to 300 times. It is used to visualize opaque objects that cannot be visualized using a compound microscope.\n- Confocal microscope – It uses laser light to scan a dyed sample.\n- Scanning electron microscope – Instead of light, this type of microscope uses electron. This type of microscope is used by researchers in the field of physical, biological, and medical science.\n- Transmission electron microscope – it uses electron to create a magnified image. The samples are scanned in the vacuum and so they require special preparation. What is good about transmission electron microscope is that it provides a high degree of magnification and resolution. It is useful in various fields of sciences such as physical and biological science, nanotechnology, metallurgy, and forensic analysis. (1, 2, 3, and 4)\nPicture 1: The image above is a stereo microscope.\nImage source: made-in-china.com\nPicture 2: The image above is a confocal microscope.\nPicture 3: The image above is parts of scanning electron microscope.\nPicture 4: The picture is a transmission electron microscope.\nImage source: ysjournal.com\nIn this article, we are going to tackle a simple microscope, its parts and functions, and its applications.\nWhat is a Simple microscope?\nPicture 5: The image shows the evolution of a simple microscope.\nImage source: stackpathdns.com\nA simple microscope is also called a magnifying glass because of its convex lens of small focal length. It is used to see the magnified image of an object that is not visible to the human eyes. (4)\nWhat is the principle of a simple microscope?\nIf you place a tiny object within the focus of the simple microscope, a magnified image of the object is formed making it easier for the naked eye peeping through the lens to see the image.\nWhat is the difference between compound microscope and simple microscope?\nAs the name suggests, a simple microscope uses a single lens for magnification while a compound microscope uses various lenses to further magnify the object. (5)\nWhat are the uses of a simple microscope?\n- Watchmaking industry – A simple microscope is commonly used by watchmakers to magnify a small part of the watch.\n- Jewelry making – Jewelry makers use a simple microscope to visualize the magnified view of the small parts of the jewelry.\n- Agriculture industry – A simple microscope is also useful in the agricultural sector. It is usually used to magnify various particles of various types of soils.\n- Palm reading – A simple microscope is used by palmist to visualize the lines of the hands.\n- Dermatology – A dermatologist or skin specialist also uses a simple microscope to check for various skin diseases.\n- Biology – A simple microscope helps in examining and studying microscopic fungi, algae, and other biological specimens that is difficult to visualize using the naked eyes.\n- Other uses – A simple microscope is also useful in other sectors such as enlarging the image of letters of a book, visualizing the details of stamps and engravings, and checking the texture of fibers or threads of a cloth. (5, 6, 7, and 8)\nPicture 6: A simple microscope’s parts and functions – Diagram\nImage source: slidesharecdn.com\nSimple microscope Parts and Functions\nA simple microscope’s parts have two classifications: the mechanical part and the optical parts.\nWhat are the mechanical parts?\nMechanical parts pertain to the parts of the microscope that support the optional parts. They help in the adjustment so as to accurately magnify the object. Mechanical parts include the following:\n- Metal stand – It comes with a base plate and a vertical rod. The metal stand is an important part for it serves as the support of the entire microscope’s part and provides stability to other parts.\n- Stage – The stage of the microscope is a metal plate that is rectangular in shape and fitted to the vertical rod. It comes with a hole in the center that enables the light to pass from below. The stage holds the slide that contains the specimen to be examined for.\n- Slanting wings – Some simple microscopes have a pair of slanting wings that project from both sides of the stage. Slant wings support the hand when manipulating the object. (3, 7, 8, and 9)\nWhat are the optical parts?\nThey are the parts of the microscope that involved passing the light through the specimen and magnify its size. Parts of the optical parts are as follows:\n- Mirror – A simple microscope has a plano-convex mirror and its primary function is to focus the surrounding light on the object being examined.\n- Lens – The biconvex lens is placed above the stage and its function is to magnify the size of the object being examined. By manipulating it (moving up and down by the frame), you will be able to enlarge the image. (1, 8, and 10)\nA simple microscope is a device that only has one lens for magnification. It functions the same way as the magnifying glass. Although it is simple in terms of design and function, it is useful I various fields including medicine, jewelry and watchmaking, and agriculture, to name a few."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:185d45fc-5229-4e7b-8fe1-6c9db02e4e1f>","<urn:uuid:1b00383e-3c28-4459-a2fd-75f90eb28d53>"],"error":null}
{"question":"How do fluorescent lights help conserve energy, and what health risks do they pose due to mercury content?","answer":"Fluorescent lights are 90% more efficient than traditional bulbs and can last up to 10,000 hours compared to 5,000 hours for standard incandescent bulbs. However, they contain mercury, which is highly toxic and can cause serious health effects including damage to the brain, kidneys, and lungs. Even brief contact with mercury can cause immediate health issues like abdominal cramps, eye irritation, loss of appetite, weight loss, skin rashes, and muscle tremors. This is particularly dangerous for unborn and young children whose nervous systems are still developing.","context":["For the Animals. For the Earth.\nIn addition to our commitment to the exhibition and conservation of endangered animal species, Cheyenne Mountain Zoo also strives to be a green business. That’s why we have multiple programs for onsite recycling and conservation of energy and natural resources.\nNot only do we adhere to tight conservation standards here at our home, but we also try to help you do the same by providing comprehensive conservation information and resources. It is our hope that you will join us in taking action—for the good of us all.\nWhat YOU can DO.\nRecycle. Stop the Waste.\nThere are lots of ways you can make a difference in our natural world—and recycling is one of the easiest.\nEven recycling your aluminum cans saves more energy than you might know:\n- A used aluminum can is recycled and back on the grocery shelf as a new can in as little as 60 days.\n- Making new aluminum cans from used cans takes 95 percent less energy, and 20 recycled cans can be made with the energy needed to produce one can using virgin ore.\n- Recycling one aluminum can saves enough energy to keep a 100-watt bulb burning for almost four hours or to run your television for three hours.\n- Throwing away an aluminum can wastes as much energy as pouring out half of the can’s volume of gasoline.\n- Last year, 54 billion cans were recycled, saving the energy equivalent of 15 million barrels of crude oil—America’s entire gas consumption for one day.\nDiscover more ways your recycling can help the environment—and the Zoo:\nCarpool, ride a bicycle or use public transportation whenever possible. If you do drive, here are a few tips to help your vehicle run more efficiently:\n- Keep your engine tuned up and performing to its standards.\n- Replace air filters regularly to maintain fuel efficiency.\n- Keep tires inflated to achieve the best fuel efficiency.\n- Avoid unnecessary idling and car trips whenever possible.\nEliminate water waste so there’s enough to go around. Here are a few things you can do at home to preserve our planet’s water supply:\n- Turn off the faucet while you shave, brush your teeth and lather up your hands.\n- Wash only full loads of laundry to save water and electricity.\n- Fill the kitchen sink with soapy and clean water when washing dishes by hand, instead of letting the water run.\n- Completely fill the dishwasher before running it to save water and electricity.\n- Take short, five-minute showers instead of baths to save about 40 gallons of water.\n- Keep an eye out for plumbing and irrigation leaks, and then fixing them promptly.\n- Plant only native, drought-tolerant plant species throughout your home landscape and use mulch to minimize evaporation.\n- Irrigate efficiently through wise sprinkler head selection, which can ensure that water is directed to exactly where it is needed and control the amount of water put on the ground at one time.\n- Water deeply, not frequently. In new landscapes, wean new plants off of frequent waterings after their second year and give periodic deep waterings instead.\n- Use a bucket of soapy water or shut-off nozzle for your hose when washing your car.\nDonate Your Vehicle\nCall Vehicles for Charity at 1 866.628.CARS (2277) or complete the online donation form at www.vehiclesforcharity.org.\nPlease select Cheyenne Mountain Zoo as the recipient of the proceeds from the sale of your vehicle. Paperwork and arrangements for towing your vehicle will be handled at no expense to you. For more information, call 719-633-9925, x115, or e-mail email@example.com.\nProceeds from the salvage sales will help the Zoo!\nGreen Consumer Action.\n- GET A LIVE TREE! – Believe it or not, a live tree is actually a relatively eco-friendly choice, so long as you’re conscious about where it goes once the holidays are over. According to the National Christmas Tree Association, nearly all cut holiday trees are grown on tree farms – meaning their stock is replenished yearly and forests aren’t hurt by choosing a cut tree. Go to earth911.org and enter your ZIP code to find out where to have your tree recycled. Or even better, get a LIVE one and plant it !\nFake trees are a different story, requiring a significant amount of energy and petroleum-based materials to manufacture. Plus, artificial trees are often manufactured overseas and shipped thousands of miles before they reach our living rooms.\n- BE BRIGHT! – Instead of buying more standard holiday lights to replace bad strings, opt for energy-efficient light strings. When they’re made using light-emitting diode bulbs, LEDs, they’re 90% more efficient than traditional holiday lights. LEDs also last longer – up to 10,000 hours compared with 5,000 hours for standard incandescent bulbs. AND- you can go one better by getting light strands with a small SOLAR panel to power those LEDs!!\n- REDUCE, REUSE, RECYCLE, REPURPOSE – This tip is an oldy but a goody. It just requires being a responsible consumer, user, and disposer.\nREDUCE – Once you have pared down your consumption, be sure to buy responsibly. Look for things made of recycled materials, that support your local economy, with minimal packaging, or that help support conservation causes.\nREUSE – Be creative about how and when to reuse.\nWhat you can’t reuse, RECYCLE! Visit the EPA’s Reducing and Reusing Basics for more information on how to conserve during the holidays and year-round.\nIf you are an online shopper, check out links below for some great environmentally conscious gift items and ideas:\n- BORROW FROM NATURE – Think of how your grandmother or great or even great-great grandmother decorated during the holiday – with natural evergreen boughs cut from evergreen trees (holly, pine, magnolia) handmade ornaments, and bowls of fruit or pine cones. With a backdrop of seasonal poinsettias and cyclamen they create a warm, fragrant and welcoming feel – and they aren’t made of petroleum and chemicals and shipped from across the world.\n- GIFT WRAP – Start your own recycling program for wrapping.\n- Use old posters, comics, colorful shopping bags, old calendars, even old maps are cool wraps!\n- Design your own gift-wrap by using a paper grocery or department store bag and adding decorations such as drawings, stamped patterns, or pictures cut from magazines.\n- Let the kids do the designing. It will keep them busy on stormy days.\n- If you do use store bought wrapping paper, buy the kind with recycled content (the more post consumer, the better).\n- When you receive gifts, be sure to save the ribbons and bows. For additional tips on how to reduce your gift wrapping waste, visit http://www.ciwmb.ca.gov/publiced/Holidays/.\nRecycle Cell Phones & Printer Cartridges\nUsed Cell Phones\nRecycle your old cell phones at the Zoo—and we’ll all benefit. The Earth will have fewer toxic, heavy metals in its landfills. The Zoo, in partnership with Eco-Cell, will get $1 to $50 per phone to put toward conservation efforts. And you, will receive $2 off the regular Zoo admission price for each cell phone you turn in to us for recycling. Limit is one discount per cell phone. This offer is not valid for special events, and can not be combined with other offers or discounts.\nOn your next visit, just place your old cell phones in the bins at the Zoo admissions booth. It’s a win for everyone!\nEach of us can make a difference in saving energy. Do your part to conserve energy at home by following these simple energy-wise practices—and save money at the same time:\n- Turn your thermostat up two degrees in the summer and down two degrees in the winter.\n- Turn off the air conditioner when no one is home or install a programmable thermostat.\n- Close curtains or blinds in the summer to keep the sun from heating your house.\n- Replace incandescent bulbs with compact fluorescent bulbs. They last longer, give off less heat and save money on your energy bill. Bulb varieties and availability are expanding all the time.\n- Turn off lights and appliances when they’re not in use and unplug them when you’re gone for long periods of time; standby power still pulls energy.\nItems we purchase in our everyday lives have an impact on the environment. Here are some things to think about:\n- Buy products with certified sustainable palm oil.\nPalm oil is a product in many everyday products, and its production is seriously threatening the lives of orangutans in Southeast Asia. Learn more about the Palm Oil Crisis\n- Select ocean-friendly seafood.\nThough you may be far from the ocean, you can still have an impact on its residents. Whether you’re buying seafood in a store or a restaurant, know which seafood to choose and why. Visit Seafood Watch for more.\n- Stop drinking bottled water.\nBuy a durable water bottle and reuse it instead of using disposable plastic bottles that never decompose in landfills.\n- Try reusable and bio-compostable paper goods.\nOn your next picnic or camping trip, take reusable tableware instead of disposable paper products, or use bio-compostable paper ware.\n- Replace plastic bags with canvas.\nUse canvas tote bags while shopping and reduce the use of plastic and disposable bags.\n- Recycle old cell phones and their batteries.\nInstead of sending your old cell phones—and their toxic metals—to your local landfill, bring them to the Zoo for recycling. Also, coltan, a metal in cell phone batteries, is mined in endangered gorilla habitat, contributing to their decline. Visit Eco-cell for more.\n- Refill or recycle printer cartridges.\nReduce waste by recycling your used printer cartridges instead of throwing them away. Buy recycled cartridges, too, and close the loop!\n- Choose recycled paper products.\nBuy recycled paper towels and toilet paper to close the loop on the recycling process.\nWaste Disposal & Compost\nThink Twice about Trash.\nAvoid polluting our environment by disposing of your household waste items appropriately.\n- Reduce, reuse and recycle whenever possible. Learn about recycling in El Paso County, Colorado. View El Paso County Recycling Directory PDF .\n- Dispose of items containing mercury with care. Mercury appears in many household items such as fluorescent light tubes, mechanical thermostats, silver-bulb thermometers, watch batteries and clothes irons. Visit El Paso County Hazardous Waste to learn more about disposing of them properly.\n- Practice responsible medication disposal to help reduce their environmental impact.\nNationally learn more at http://water.epa.gov/scitech/swguidance/ppcp/upload/ppcpflyer.pdf.\nFor Colorado Springs area drug disposal information visit CHSP’s Colorado Clean Program.\n- Reduce or avoid the use of pesticides on your lawn. If you do use them, follow their directions carefully.\n- Go organic! Compost food items and use them on your garden as fertilizer. Learn more at www.howtocompost.org.\nGet the Scoop on Poop.\nDoo you know the best way to keep annoying deer away? From our yard to yours, Zoo Doo is made from Cheyenne Mountain Zoo big cat feces and sold by the pound. Gardeners swear by this all-natural deer deterrent to protect their plants and trees. Even better, your purchase supports the zoo!\nWhat’s in Zoo Doo?\nZoo Doo contains Cheyenne Mountain Zoo tiger, leopard and African lion feces. Mountain lion feces is not used to prevent attracting mountain lions to your yard. Please note, Zoo Doo is a deer deterrent, not a fertilizer.\nDoes it smell?\nYou may notice an initial odor, however, it’s generally unnoticeable to humans after a short time. The effect on deer lasts much longer.\nHow long does it last?\nThe effects of Zoo Doo vary. Some gardeners may only need to purchase Zoo Doo once a year, while others may need to purchase more after a few weeks.\n$2.00/pound; 15-pound minimum\nAvailable Tuesday – Saturday, by appointment only.\nCall 719-633-9925 x 150","What is Mercury?\nMercury is a naturally occurring element that can be found throughout the environment. Human activities – such as burning fossil fuels and hazardous waste, and the improper disposal of mercury containing products – have greatly increased the amount of mercury contamination in the environment.\nWhere is Mercury Found Around the House?\nMercury can be liquid or gaseous. In both forms, it’s just as dangerous.\nYou can find mercury in…\n- Fluorescent light bulbs\n- Glass thermometers\n- Some older light switches\n- Older household thermostats\n- Some metallic jewelry\n- Children’s shoes (with flickering lights)\n- Some toys with flashing lights\n- Clothing irons\n- Some clock pendulums\n- Older oil-based paints\n- Button batteries (watch-type batteries)\nFluorescent and High-Intensity Discharge (HID) lamps are excellent energy-efficient choices because they can use up to 50 percent less electricity. However, used fluorescent and HID lamps must be disposed of properly because they contain mercury.\nThe Dangers of Mercury\nMercury is a highly toxic metal that is harmful to both humans and wildlife. Exposure to even small amounts of mercury, over a long period of time, may cause negative health effects including damage to the brain, kidneys, and lungs.\nUnborn and young children are especially susceptible to mercury exposure because their nervous systems are still developing. Whether it is absorbed through the skin, inhaled, or ingested, exposure to mercury should be taken very seriously.\nBrief contact with high levels of mercury may cause immediate health effects:\n- Abdominal cramps\n- Eye irritation\n- Loss of appetite\n- Weight loss\n- Skin rashes\n- Muscle tremors\nProper Storage and Disposal\nProper storage and disposal of mercury-containing products will greatly reduce the risk of exposure in your home. Store products containing mercury in a safe place to prevent breakage.\nCarefully handle and dispose of those products by taking them to the Delta Household Hazardous Waste Collection Facility for free and proper disposal.\nIf There’s a Spill\nAll mercury spills, regardless of size, should be cleaned up immediately and carefully. If the amount spilled is more than two table-spoons, contact the National Response Center at 1.800.424.8802. If a spill is less than two tablespoons:\nDo …keep all pets and children away from the immediate area\nDo …wear rubber or latex gloves when cleaning up a spill\nDo …use cardboard, a squeegee, or an eyedropper to gather and draw up mercury\nDo …properly ventilate the spill area (turn off heaters, and turn up the AC)\nDo …put clean-up materials in a sealable containerDon’t …use a vacuum cleaner or a broom to clean up mercury\nDon’t …pour mercury down the drain\nDon’t …wash mercury-contaminated items in the washing machine\nDon’t …walk around – your shoes could be covered with mercury. Bring mercury-contaminated items to the Delta Household Hazardous Waste Collection Facility.\nDid You Know?\n- Mercury is a naturally occurring liquid metal\n- In its gaseous state, mercury is colorless and odorless\n- A broken thermometer is the most common exposure to liquid mercury\n- Mercury salts are used in some skin-lightening creams, antiseptic creams, and ointments\n- Mercury is a toxic substance that is very harmful to humans\n- 41 states, including California, have issued fish-consumption advisories due to mercury contamination\n- Larger fish have higher concentrations of mercury than small fish"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:114bdb4a-c9fc-4dcc-b555-0eb11448ac58>","<urn:uuid:40cb22a8-21c5-4de0-b618-d531d77d0a75>"],"error":null}
{"question":"What was the critical flaw discovered in Hubble's primary mirror after its 1990 launch, and how was it fixed?","answer":"After Hubble's launch in 1990, NASA discovered that the telescope's primary mirror had a slight flaw that blurred its vision. This was corrected during the first servicing mission in December 1993 by installing two new instruments: the Corrective Optics Space Telescope Axial Replacement (COSTAR), which acted as a contact lens for Hubble's flawed mirror, and the Wide Field and Planetary Camera 2 (WFPC2), which had corrective optics built in.","context":["Of the thousands of working spacecraft orbiting Earth, two were launched with the intention of being serviced while in orbit: NASA’s Hubble Space Telescope and the International Space Station. Hubble was specifically designed for servicing so that as technologies advanced on the ground and components wore out in the hostile environment of space, upgrades and repairs could extend the telescope’s scientific life. Hubble was launched into space in April 1990 with an anticipated lifespan of about 15 years.\nAstronauts visited Hubble five times to replace or repair computers, electronics, batteries, gyroscopes, and insulation, and to change out science instruments with newer, more powerful technologies. These visits left Hubble in renewed condition and with expanded reach into the cosmos. In the year 2020, Hubble marked its 30th year of exploration, a direct result of servicing missions. It continues to conduct ground- breaking science today.\nThe Telescope Workplace\nWhile Hubble was designed to be serviced, space is a dangerous environment, and astronauts are challenged by bulky spacesuits that limit movement and line of sight. Careful preparation and planning went into each extravehicular activity (EVA), or “spacewalk.” Hubble servicing missions required specialized tools and carefully choreographed procedures to ensure that the astronauts could safely and swiftly accomplish many tasks over the course of a spacewalk. Astronauts made their way around Hubble using yellow handrails, whose color indicated they were safe for grasping, while being careful to avoid keep-out zones and no-touch surfaces. Working in pairs, spacewalking astronauts helped each other prevent inadvertent contact with delicate structures. For every hour a spacewalking astronaut spent working on Hubble, they trained and prepared for approximately 10-16 hours on the ground.\nServicing Mission 1 (SM1): Dec. 2-13, 1993\nAfter Hubble’s launch in 1990, NASA learned that the telescope’s primary mirror had a slight flaw that blurred its vision. Space shuttle flight STS-61 was the first opportunity to correct the distortion and service the telescope. Astronauts installed two new instruments: the Corrective Optics Space Telescope Axial Replacement (COSTAR), which acted as a contact lens for Hubble’s flawed mirror, and the Wide Field and Planetary Camera 2 (WFPC2), which had corrective optics built in and replaced the original Wide Field and Planetary Camera instrument. In addition, SM1 included the installation and replacement of other components, including solar arrays and two Rate Sensor Units with gyroscopes. Since the first servicing mission, every instrument added to Hubble was designed to compensate for the mirror flaw, allowing COSTAR to eventually be removed during Servicing Mission 4.\nServicing Mission 2 (SM2): Feb. 11-21, 1997\nSTS-82 made significant improvements to Hubble’s productivity. The installation of two new instruments—the Space Telescope Imaging Spectrograph (STIS) and the Near Infrared Camera and Multi-Object Spectrometer (NICMOS)— extended Hubble’s wavelength range into the near-infrared for imaging and spectroscopy, allowing scientists to probe the most distant reaches of the universe. The replacement of several components, including a Fine Guidance Sensor (FGS), Reaction Wheel Assembly, and solid-state data recorder, increased efficiency and performance.\nServicing Mission 3A (SM3A): Dec. 19-27, 1999\nWhat was originally conceived as a mission of preventive maintenance turned more urgent on November 13, 1999, when the fourth of Hubble’s six gyroscopes failed. At that time, Hubble needed at least three of its stabilizing gyroscopes to conduct science. Hubble went into a dormant “safe mode” while the telescope waited for repairs. NASA split the third servicing mission into two parts, beginning with STS- 103, to more quickly bring Hubble back into operation. The new, improved, and upgraded equipment included six fresh gyroscopes; six battery voltage/temperature improvement kits; a faster, more powerful, main computer; a solid-state data recorder; a new transmitter; an enhanced Fine Guidance Sensor; and new thermal insulation.\nServicing Mission 3B (SM3B): March 1-12, 2002\nDuring the fourth mission to service Hubble, STS-109 astronauts replaced Hubble’s solar panels with rigid and more powerful solar arrays and installed the Advanced Camera for Surveys (ACS) in place of the Faint Object Camera (FOC), the telescope’s last original instrument. They also replaced the spacecraft’s original Power Control Unit (PCU), which had been on the job for 11 years, requiring Hubble to be completely powered down for the first time since its launch in 1990.\nServicing Mission 4 (SM4): May 11-24, 2009\nThe Hubble Space Telescope was reborn after Servicing Mission 4 (SM4). During STS-125, astronauts installed two new scientific instruments: the Cosmic Origins Spectrograph (COS) and Wide Field Camera 3 (WFC3). Two instruments that had experienced electronic failures, STIS and ACS, were revived by creative and complex in-orbit repairs that had not been anticipated when the telescope was designed. With these efforts, Hubble reached the apex of its scientific capabilities. To prolong Hubble’s life, astronauts also installed new batteries, new gyroscopes, a new science computer, a refurbished Fine Guidance Sensor, and new insulation on three electronics bays. Additionally, astronauts attached a soft-capture mechanism to the base of the telescope to assist NASA in safely deorbiting Hubble at the end of its life."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:a82a288a-81b8-43aa-91b4-ca620a19ab11>"],"error":null}
{"question":"What are the security implications of port 22 for SSH connections, and how does this relate to VPS server protection in Linux environments? 🤔 I'm really curious about the historical context and modern security practices!","answer":"Port 22 became the default SSH port when it was allocated by IANA in July 1995, chosen because it was conveniently located between FTP (port 21) and telnet (port 23). While SSH through port 22 is commonly permitted through firewalls, particularly for outbound connections, this default setting can pose security risks. Back-tunneling through SSH can create backdoors into organizations, potentially violating security standards like PCI and HIPAA. For Linux VPS security, it's recommended to change the default SSH port from 22 to a different unused port to prevent hackers from running malicious scripts that target the default port. Additionally, SSH security should be enhanced by implementing measures such as disabling root login, using key-pair authentication instead of password-based authentication, and installing intrusion-detection software like fail2ban or DenyHosts.","context":["ContentsHow SSH port became 22 The story of getting SSH port 22 Changing the SSH port in the server Specifying SSH port number on the command line Configuring SSH access through firewalls Outbound SSH Back-tunneling is a risk Inbound SSH access Enabling SSH access via iptables\nHow SSH port became 22\nThe default SSH port is 22. It is not a coincidence. This is a story of how it got that port.\nWhen I (Tatu Ylonen first published this story in April 2017, it went viral and got about 120,000 readers in three days.\nThe story of getting SSH port 22\nAnyway, I designed SSH to replace both\ntelnet (port 23) and\nftp (port 21). Port 22 was free. It was conveniently between the ports for\nftp. I figured having that port number might be one of those small things that would give some aura of credibility. But how could I get that port number? I had never allocated one, but I knew somebody who had allocated a port.\nThe basic process for port allocation was fairly simple at that time. Internet was smaller and we were in the very early stages of the Internet boom. Port numbers were allocated by IANA (Internet Assigned Numbers Authority). At the time, that meant an esteemed Internet pioneer called Jon Postel and Joyce K. Reynolds. Among other things, Jon had been the editor of such minor protocol standards as IP (RFC 791), ICMP (RFC 792), and TCP (RFC 793). Some of you may have heard of them.\nTo me Jon felt outright scary, having authored all the main Internet RFCs!\nAnyway, just before announcing\nssh-1.0 in July 1995, I sent this e-mail to IANA:\nFrom ylo Mon Jul 10 11:45:48 +0300 1995 From: Tatu Ylonen <firstname.lastname@example.org>\nTo: Internet Assigned Numbers Authority <email@example.com>\nSubject: request for port number\nOrganization: Helsinki University of Technology, Finland\nDear Sir, I have written a program to securely log from one machine into another over an insecure network.\nIt provides major improvements in security and functionality over existing telnet and rlogin protocols\nand implementations. In particular, it prevents IP, DNS and routing spoofing. My plan is to distribute\nthe software freely on the Internet and to get it into as wide use as possible. I would like to get a registered\nprivileged port number for the software.\nThe number should preferably be in the range 1-255 so that it can be used in the WKS field in name servers.\nI'll enclose the draft RFC for the protocol below. The software has been in local use for several months,\nand is ready for publication except for the port number. If the port number assignment can be arranged in time,\nI'd like to publish the software already this week. I am currently using port number 22 in the beta test.\nIt would be great if this number could be used (it is currently shown as Unassigned in the lists).\nThe service name for the software is \"ssh\" (for Secure Shell).\nYours sincerely, Tatu Ylonen <firstname.lastname@example.org> ... followed by protocol specification for ssh-1.0\nThe next day, I had an e-mail from Joyce waiting in my mailbox:\nDate: Mon, 10 Jul 1995 15:35:33 -0700 From: jkrey@ISI.EDU To: email@example.com Subject: Re: request for port number\nCc: iana@ISI.EDU Tatu, We have assigned port number 22 to ssh, with you as the point of contact. Joyce\nThere we were! SSH port was 22!!!\nOn July 12, 1995, at 2:32am, I announced a final beta version to my beta testers at Helsinki University of Technology. At 5:23pm I announced ssh-1.0.0 packages to my beta testers. At 5:51pm on July 12, 1995, I sent an announcement about SSH (Secure Shell) to the\nfirstname.lastname@example.org mailing list. I also posted it to a few newsgroups, mailing lists, and directly to selected people who had discussed related topics on the Internet.\nChanging the SSH port in the server\nBy default, the SSH server still runs in port 22. However, there are occasions when it is run in a different port. Testing use is one reason. Running multiple configurations on the same host is another. Rarely, it may also be run without root privileges, in which case it must be run in a non-privileged port (i.e., port number >= 1024).\nThe port number can be configured by changing the\nPort 22 directive in /etc/ssh/sshd_config. It can also be specified using the\n-p <port> option to sshd. The SSH client and sftp programs also support the\n-p <port> option.\nSpecifying SSH port number on the command line\n-p <port> option can be used to specify the port number to connect to when using the\nssh command on Linux. The\n-P <port> (note: capital P) option can be used with SFTP and\nscp. The SSH port number command line setting overrides any value configured in configuration files.\nConfiguring SSH access through firewalls\nSSH is one of the few protocols that are frequently permitted through firewalls. Unrestricted outbound SSH is very common, especially in smaller and more technical organizations. Inbound SSH is usually restricted to one or very few servers.\nConfiguring outbound SSH in a firewall is very easy. If there are restrictions on outgoing traffic at all, just create a rule that allows TCP port 22 to go out. That is all. If you want to restrict the destination addresses, you can also limit the rule to only permit access to your organization's external servers in the cloud, or to a jump server that guards cloud access.\nBack-tunneling is a risk\nUnrestricted outbound SSH can, however, be risky. The SSH protocol supports tunneling. The basic idea is that it is possible to have the SSH server on an external server listen to connections from anywhere, forward those back into the organization, and then make a connection to some Internal server.\nThis can be very convenient in some environments. Developers and system administrators frequently use it to open a tunnel that they can use to gain remote access from their home or from their laptop when they are travelling.\nHowever, it generally violates policy and takes control away from firewall administrators and the security team. It can, for example, violate PCI, HIPAA, or NIST SP 800-53. It can be used by hackers and foreign intelligence agencies to leave backdoors into organizations\nInbound SSH access\nFor inbound access, there are a few practical alternatives:\nConfigure firewall to forward all connections to port 22 to a particular IP address on the internal network or DMZ.\nUse different ports on the firewall to access different servers.\nOnly allow SSH access after you have logged in using a VPN (Virtual Private Network), typically using the IPsec protocol.\nEnabling SSH access via iptables\nIptables is a host firewall built into the Linux kernel. It is typically configured to protect the server by preventing access to any ports that have not been expressly opened.\niptables is enabled on the server, the following commands can be used to permit incoming SSH access. They must be run as root.\niptables -A INPUT -p tcp --dport 22 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -p tcp --sport 22 -m conntrack --ctstate ESTABLISHED -j ACCEPT\nIf you want to save the rules permanently, on some systems that can be done with the command:\nservice iptables save","Over the past few years, Linux has experienced an escalated growth and has become popular among the users who appreciate an open-source operating system. With Linux, a user has unparalleled flexibility which can aid in developing and altering the system as per their personal needs. Furthermore, Virtual Private Servers (VPS) when installed with Linux have proven to have a more successful relationship and is the preferred choice of many system administrators.\nWhat is VPS?\nA Virtual Private Server (VPS) is a virtual machine that appears to the user as a dedicated server but is installed on a machine serving multiple websites. It runs its own version of operating system and has dedicated resources. All VPS hosting providers rely on a virtualization software which is known as a hypervisor to abstract resources on the physical server and provide the user with access to an emulated Virtual Machine. All virtual machines run their own version of operating system, and this is where Linux comes into the picture.\nSignificance of Linux as an OS for Virtual Machine\nLinux is accompanied with Linux Security Modules framework which makes it secure, however, security depends on how you configure the operating system. It allows the Linux kernel to support a variety of security policies while being neutral to all security implementations. However, Linux VPS needs to be configured to meet your unique security needs and environment and can be preyed upon by hackers.\nThe open-source nature of Linux and the ever-changing requirements of the VPS users have contributed to the popularity of this duo. Nevertheless, security measures must be highlighted and implemented by the users of Linux VPS to ensure their websites are protected.\nPractices to Secure Your Linux VPS Server\n1)Disable Root Login – Secure the foundation of Linux VPS\nIn addition to being scalable, complete root access is one of the reasons why VPS hosting is popular. By default, every Linux administrator has a ‘root’ user or a ‘root’ account option which entitles and empowers the administrator to perform actions on the server.\nDisabling the root user adds another security layer, and can keep hackers at bay. Administrators can still execute root level commands using the ‘sudo’ command. Sudo is a restricted access right given to administrators or authorized users to run root level commands.\nMake sure to create a non-root user and give it proper authorization to execute ‘sudo’command.\nTo disable root login, open /etc/ssh/sshd_config in a Linux text editor like Nano or Vi. Find the parameter ‘Permit Root Login’ and change it to NO.\nIt should look like this –\n2) Keep Your Server OS Updated\nUpdating your system on a regular basis can eliminate security threats and vulnerabilities. It is recommended to update the operating system regularly and install the latest security patches and fixes.\nIf you are using CentOS or RHEL execute the following command to update your system –\nIf you are using Ubuntu or Debian, execute the following command to update your system –\nAlternatively, users can also configure the OS to send yum package notifications for update via email. A time-based job scheduler like Cron automates tasks in a Linux environment and can be setup to apply all available security updates.\n3)Use SSH to Securely Login Remotely\nSSH is also known as secure shell, and it is one of the protocols that is always running on the VPS server. It is used to operate network services securely over an unsecured network. Since SSH is always running, the hackers often eye it.\nThe first step to secure SSH configuration is to change the default port 22 to a different port which is not being used by another service. Changing the default port will prevent hackers to run malicious scripts from directly connecting to the port.\nTo change port number /etc/ssh/sshd_config\nAlternatively, implement the following actions –\n- Deny root access for users logging in from SSH\n- Disable password-based authentication and instead use key pairs for logging in\n- Install intrusion-detection software such as fail2ban or DenyHosts\n4)Ignore ICMP or Broadcast Requests\nInternet Control Message Protocol (ICMP) is an error-reporting protocol network used to generate error messages to the source IP address when certain network problems prevent the delivery of IP packets. Most malicious attacks start with ICMP, which is widely known as ping scan.\nWhen the system responds to ICMP is disabled, it prevents the system from being discovered by a pin request.\nTo disable ICMP and Broadcast requests find /etc/sysctl.conf and add the following lines –\nIgnore ICMP request:\nnet. ipv4.icmp_echo_ignore_all = 1\nIgnore Broadcast request:\nnet. ipv4.icmp_echo_ignore_broadcasts = 1\nReload the Sysctl configuration by entering the following command\nUse ping <your server name> to validate if the system is responding to ICMP requests or not.\nA user-space application program, iptables is used to set up, inspect, and maintain the firewall provided by Linux kernel. A user can set rules for filtering outgoing, incoming, and forwarding packets. It helps in preventing most Denial of Service (DOS) attacks and filters out unwanted traffic.\nIt is vital to disable unused network ports since open ports increase the vulnerability of the VPS server. Use iptables to close all open ports.\nnetstat will display all open ports.\n6)FTP or SFTP – Which to use?\nFTP or File Transfer Protocol is a standard network protocol which is used to move files between client and server on a network. FTP may seem handy to use, but it is an inherently insecure method of accessing the server since all authentications are sent in plain text format without any encryption. Anyone who is monitoring the connection between the user and their server can retrieve the password to the server.\nInstead of using FTP, switch to a more secure alternative like SFTP. The SSH File Transfer Protocol operates with the security of SSH protocol and transfers data with an end-to-end tunnel.\n7)Encrypt Sensitive Data\nAll data transmitted over the network between a server and a client can be monitored. Encrypting sensitive data might come at a price, but it is imperative to use encryption if you are concerned about data theft. Encryption transforms the data into an incoherent code and is inaccessible to anyone but the administrator with appropriate keys or password. Use GnuPG, also known as PGP to encrypt sensitive communication.\n8)Maintain a Strong Password Policy\nNever have empty passwords for user accounts or simple passwords that can be read easily by hackers using brute-force attacks. Make sure users can only login through SSH and enforce using stronger passwords.\nSet up a password policy by editing Pluggable Authentication Manager (PAM) configuration file. The location for PAM file in the following Linux distros –\nIn the above PAM configuration file, add the following lines to implement the use of minimum number of special characters, numbers, and uppercase letters.\npassword requisite pam_cracklib.so retry=2 minlen=9 difok=3 ucredit=2 dcredit=1 ocredit=3\n9)Set File Permissions Meticulously\nEven if the user has implemented security practices mentioned above, vulnerabilities can still exist if the file permissions are incorrect. If the system administrator has given rights to the users for incorrect files, it will make the VPS insecure and prone to vulnerabilities. In Linux, permissions are categorized into three groups, viz. owner, group and all users, and types – read, write, executable. Try providing permissions that are necessary. Review SUIG or SGID permissions, and never set 777 permissions to any file or folder.\nSecuring a VPS server is critical, and it must be the first thing you should do when you buy a VPS hosting plan. The security fixes mentioned above are necessary, but it also depends from user-to-user. One can fine tune these security settings as per their need and configure the VPS accordingly. A secure server is the basis of an unswerving website or application. The process of securing a VPS server is ongoing, and one must keep auditing their system, implement innovative solutions, and discover new practices to be a step ahead than malicious attackers."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:c40b5ef1-0e06-4d5d-aaa9-249764ed585c>","<urn:uuid:aebf7a62-2fa7-4e92-af11-85239824208b>"],"error":null}
{"question":"I want to learn more about HRV monitoring in sports. What is heart rate variability's role in athletic performance, and what technology options are available for measuring it accurately?","answer":"Heart rate variability (HRV) plays a crucial role in athletic performance as it indicates the autonomic nervous system's state. A low HRV suggests sympathetic nervous system dominance, which can lead to overtraining, burnout, poor performance, and increased injury risk. A healthy HRV shows effective regulation of vital signs and blood pressure. For measurement technology, chest strap heart rate monitors like the Polar H7 provide accurate HRV analysis with correlation of 0.99 compared to reference ECG devices. While optical wrist-based monitors can track heart rate well during exercise, they are unsuitable for HRV analysis due to lost data points and smoothing effects. The most reliable HRV measurements require ECG recordings or chest strap monitors that can accurately capture RR-intervals.","context":["The way we feel and how we perform during various activities depends on a lot of different factors. No individual would have the same heart rate all the time, and this phenomenon is described as heart rate variability (HRV).\nWe have all heard about and seen many different heart rate monitors used by athletes and fitness professionals. And they might have helped some of us in tracking their HRV as well.\nHRV is important\nThe autonomic nervous system is so complex that most of the time, it’s unconscious and regulating vital functions without you even being aware of it.\nOne of the most exciting components of this system is heart rate variability (HRV). HRV is the measurement of our heart rate variability as a result of our autonomic nervous system. It’s important to note that the in-between time heartbeats, called the R-R Interval, are not the variable measured, but rather the R-R Interval variation.\nA healthy HRV shows that your heart rate is not varying much throughout the R-R Interval (variation between beats). This means your nervous system effectively regulates and maintains your vital signs, blood pressure, and other body systems.\nA low HRV indicates a more stressed-out nervous system, which might cause an increase in blood pressure or other related body responses.\nWith a low HRV, there is only a weak sympathetic response, usually due to depression, stress, or low blood sugar levels. And it can impact athletic performance both during training and in competition.\nHRV and athletic performance\nWant your athletes to perform better? Improve their HRV. There is a direct correlation between the ability to induce a Heart Rate Recovery (HRR) and athletic performance.\nFor example, if an athlete is more likely to get injured after the last few days of anaerobic training, we might want to consider trying to keep their workload down. At the very least, you can be aware of this and adjust their practice accordingly. It’s a significant benefit having a baseline to use against when other athletes are injured and potentially begin to overtrain.\nWhat a great way to tie HRV together. Not only can you use it as a predictor of future events, but you can also use it to see how your athletes are feeling and whether there may be imbalances in the nervous system.\nThe bottom line is that having a low HRV likely means that the sympathetic nervous system is dominating, resulting in a host of symptoms: over-training, burnout, poor performance, and increased risk of injury.\nThere are times when one branch is dominating (usually the sympathetic), which is a good thing. Like if you’re running a race, you want your body to focus on allocating resources to your legs (sympathetic) instead of digesting food (parasympathetic).\nA higher heart rate variability suggests there’s more room for the sympathetic nervous system to kick in and rev things up; a lower HRV means the parasympathetic nervous system is dominating, which makes it harder to push past your comfort zone.\nParasympathetic vs. Sympathetic\nAlthough HRV manifests as a function of your heart rate, it originates from your nervous system. Your autonomic nervous system, which controls your physiology’s involuntary aspects, has two branches, parasympathetic (deactivating) and sympathetic (activating).\nThe sympathetic nervous system works with the central nervous system to prepare the body for ‘fight or flight’ by increasing blood sugar levels, increasing heart rate, and constricting blood vessels. Some people may experience an increase in blood pressure.\nThe parasympathetic nervous system directly opposes the sympathetic nervous system, slowing heart rate, and increasing digestion. Not only that, it seems to help with pain, speeding up metabolism to remove the unwanted effects of stress.\nHeart rate variability is a good measure of parasympathetic activity. If you don’t have the right amount of parasympathetic activity, your body’s autonomic system can’t respond quickly enough to change. The result is sub-optimal performance.\nHeart Rate Training\nThe easiest way to understand heart rate variability is to listen to your heartbeat. Heart rate is the number of times your heart beats per minute. And it is an exercise intensity metric.\nHeart rate training is an excellent tool for exercise prescription, endurance training, or keeping track of your fitness in real-time.\nBy monitoring your heart rate, you can better understand how hard you are working during exercise. In addition to this, heart rate variability provides a guide on how the heart works during rest. The heart rate variability ratio indicates your heart is going through a regular cycle.\nHRV as a tool to monitor overtraining\nWhen you see something exciting or stressful, a news headline, a fraudulent credit card charge, heart rate increases; breathing increases. It’s the fight-or-flight response. This is the way that your body is meant to function. But when we get triggered to it or train ourselves to make an activity a norm, it becomes the norm, and we ignore it, and we think it’s okay to yell. It’s okay to have negative emotions in social settings.","Overview + Hardware & Software (+data)\nA bit of background first. The cardiovascular system is mostly controlled by autonomic regulation through the activity of sympathetic and parasympathetic pathways of the autonomic nervous system. Analysis of HRV permits insight in this control mechanism , since heavy training is responsible for shifting the cardiac autonomic balance toward a predominance of the sympathetic over the parasympathetic drive.\nA large body of studies demonstrated an association between endurance exercise training and HRV [2,3] (long-term changes in HRV), with more recent studies proposing HRV-based training programs, where daily HRV measurement were used to control training intensity  (short-term changes in HRV). However, a significant amount of cross-sectional studies showed no relation between HRV features and VO2max or other measures of fitness (e.g. heart rate recovery time after a maximal test) [5,6,7]. Even in longitudinal studies [3,8,9], relation between HRV and VO2max are often inconclusive. Some researcher found a significant increase in HRV features following an intervention , while most studies typically report changes in resting Heart Rate, but no changes in HRV [8,9].\nOn the other hand, short-term changes in HRV features, used to assess training load and recovery, seem to be a more reliable measure. Most research was able to show a significant relation between HRV features and training load/performance [10,11], with some studies showing that HRV-guided training can be used to increase VO2max faster .\nIn my research on energy expenditure I developed a methodology which uses heart rate distributions in different contexts to estimate a surrogate of cardiorespiratory fitness and then normalize heart rate, improving energy expenditure estimation accuracy . Then, I investigated time and frequency domain HRV features, to understand if the relation between HRV features in different contexts and fitness could also help in normalizing heart rate and improve energy expenditure estimation accuracy . However, in my cross-sectional analysis I did not find any feature able to go beyond what heart rate could do. These findings, together with most of what is reported in literature, point out that the link between HRV and fitness should be analyzed at the individual level, establishing a personal baseline from which deviations can be representative of changes in training load and fitness level.\nHRV can easily be determined from ECG recordings, resulting in time series (RR-intervals) that are usually analysed in time and frequency domains. I developed two iphone apps to perform HRV analysis, and used them to collect data during trainings and morning orthostatic tests (HRV Logger & HRV4Training).\nThe first app is Heart Variability Logger, a general purpose app which connects to any bluetooth low energy heart rate sensor (bluetooth 4.0, also called SMART) and extracts time and frequency domain features from RR intervals (configurable time window). The app allows all data to be exported (HR, RR-intervals, features, events).\nHRV Logger extracts and stores the following features:\nThe second app is HRV4Training, which is the app I use for short-term HRV analysis. HRV4Training measures Heart Rate and Heart Rate Variability features while guiding you through an orthostatic test (lying down and standing right after waking up), which can be used to determine your training state and prevent overtraining.\nReference device: I used imec's ECG Necklace as reference device, since it can record the full ECG and not only ECG-derived events such as RR-intervals. The ECG Necklace is a low power wireless ECG platform. The system relies on an ultra-low-power ASIC for ECG read-out and achieves up to 6 days autonomy on a 175 mAh Li-ion battery. For these tests, the ECG Necklace was congured to acquire one lead ECG data at 256 Hz. Two gel electrodes were placed on the chest, in the lead II configuration. Data were recorded on the on-board SD card to ensure integrity.\nOther sensors: I used three commercially available bluetooth low energy heart rate monitors:\nBefore starting with short and long-term HRV analysis, I compared three different sensors in order to determine the accuracy and reliability, compared to a reference device able to collect the full ECG. This analysis was performed mainly because I found no up do date study comparing commercially available heart rate sensors to holter monitors, and I had the feeling some of these sensors were not completely reliable for heart rate variability analysis (e.g. optical, wrist based sensors).\nMeasurements at rest\nMost of the features I will be looking at to measure training load/recovery and fitness level are measured at rest (either while lying down or during an orthostatic test). Thus, I first recorded data from the three sensors and the reference system during sedentary activity, to assess the monitor's accuracy.\nThe following plot shows the recorded RR-intervals. As expected, optical wrist-based monitors (mio alpha) are unable to capture RR-intervals with high accuracy. Quite a significant number of RR-intervals is lost even for a short 10 minutes recording. Another issue with the mio alpha is the smoothing effect, probably necessary to deal with motion artifacts. The recording with the Polar H7 is about 5 minutes, while the one using Under Armour's Armour39 is approx 22 mins.\nDetail over 30 RR-intervals:\nCorrelation (full recording):\nMio alpha: 0.77\nPolar H7: 0.99\nThe following plot shows the square root of the mean squared difference of successive RRs (rMSSD), computed over 30 seconds windows. rMSSD is one of the most discriminative features for training load/recovery. As expected, the smoothing effect on the mio alpha significantly reduces the feature's variability (lower rMSSD value, top plot). The other two monitors perform quite well compared to the reference:\nEDIT: the data shown here is actually SDNN.\nMio alpha: 0.23\nPolar H7: 0.97\nBottom line: a chest strap is necessary for accurate heart rate variability analysis. The mio alpha is still a good heart rate monitor, as shown from the last plot, where I used it for about 60 minutes while running (the bottom plot is about 25 minutes from a Polar H7, showing almost perfect overlap with the reference):\nMio alpha: 0.97\nPolar H7: 0.99\nAll data used for these comparisons (reference ECG @ 256Hz and RR intervals recorded from the sensors) is available for download here.\n Aubert, André E., Bert Seps, and Frank Beckers. \"Heart rate variability in athletes.\" Sports Medicine 33.12 (2003): 889-919.\n Tulppo, Mikko P., et al. \"Effects of aerobic training on heart rate dynamics in sedentary subjects.\" Journal of Applied Physiology 95.1 (2003): 364-372. Al-Ani, M., et al. \"Changes in RR variability before and after endurance training measured by power spectral analysis and by the effect of isometric muscle contraction.\" European journal of applied physiology and occupational physiology 74.5 (1996): 397-403.\n Kiviniemi, Antti M., et al. \"Endurance training guided individually by daily heart rate variability measurements.\" European journal of applied physiology 101.6 (2007): 743-751.\n Esco, Michael R., et al. \"The relationship between resting heart rate variability and heart rate recovery.\" Clinical Autonomic Research 20.1 (2010): 33-38.\n Lee, C. Matthew, and Albert Mendoza. \"Dissociation of heart rate variability and heart rate recovery in well-trained athletes.\" European journal of applied physiology 112.7 (2012): 2757-2766.\n Grant, Catharina C., et al. \"Relationship between exercise capacity and heart rate variability: Supine and in response to an orthostatic stressor.\" Autonomic Neuroscience 151.2 (2009): 186-188.\n Loimaala, Antti, et al. \"Controlled 5-mo aerobic training improves heart rate but not heart rate variability or baroreflex sensitivity.\" Journal of Applied Physiology89.5 (2000): 1825-1829.\n Boutcher, Stephen H., and Phyllis Stein. \"Association between heart rate variability and training response in sedentary middle-aged men.\" European journal of applied physiology and occupational physiology 70.1 (1995): 75-80.\n Garet, Martin, et al. \"Individual interdependence between nocturnal ANS activity and performance in swimmers.\" Medicine and science in sports and exercise 36 (2004): 2112-2118.\n Pichot, Vincent, et al. \"Relation between heart rate variability and training load in middle-distance runners.\" Medicine and science in sports and exercise 32.10 (2000): 1729-1736.\n Altini, Marco, Julien Penders, and Oliver Amft. \"Personalizing Energy Expenditure Estimation Using a Cardiorespiratory Fitness Predicate.\" Pervasive Health 2012.\n Altini, Marco, Julien Penders, Ruud Vullers, and Oliver Amft. \"Automatic Heart Rate Normalization for Accurate Energy Expenditure Estimation: An Analysis of Activities of Daily Living and Heart Rate Features.\" submitted to MIM."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:27fa69f7-c000-4988-8fde-869c3ac28264>","<urn:uuid:b15b399a-3157-49e9-87f5-a953415c44ee>"],"error":null}
{"question":"As someone building a luxury yacht, I'm wondering about both the entertainment tech integration and noise reduction capabilities in modern vessels. What solutions are available?","answer":"Modern yacht technology offers comprehensive solutions for both entertainment and noise reduction. For entertainment, systems like those by Videoworks provide centralized AV systems with Creston processors, high-quality Sonance speakers with 5.1 surround sound in owner areas, and James Loudspeaker marine-grade speakers for exterior spaces. The systems are designed with centralized racks to minimize clutter in guest areas. For noise reduction, diesel-electric propulsion systems like the Azipod have proven effective. These systems eliminate traditional shaft, strut, and bearing drive trains by mounting electric motors in external pods. Since the Azipod operates in undisturbed water and lacks bearings and gearboxes, it significantly reduces noise and vibration in the hull. Some vessels also use elastically supported foundations for their generator sets to further minimize vibration.","context":["Videoworks in Italy is at the vanguard of integrating onboard visual and audio entertainment tech with lighting and cybersecurity systems\nHome automation, or Domotics, has become a major trend onshore so it’s little wonder that the boating sector has picked up on it, with firms like Videoworks in Italy at the vanguard of integrating visual and audio entertainment tech with lighting and cybersecurity systems. Must-haves of system integration now include being able to watch at a football match on a large screen with very high resolution, to listen to music with loudspeakers that faithfully reproduce pure sounds, host a party on board, manage lights, blinds, multi-media contents and air conditioning and to browse the internet in a secure and reliable manner. Above all it’s cruicial that all that tech wizardry be wrapped up in a simple package to ensure installation, maintenance and the user interface are as easy as possible. One builder that’s fully embraced the concept is Wider, as witnessed by Videoworks’ work aboard its new 50m Cecilia.\nOne of the key challenges set by the shipyard and the designers was to obtain the best sound quality without audio installations taking up acreas of space. Videoworks created a centralised AV system featuring Creston processors. The audio system uses top-of-the-range equipment, not only in the saloons but in the guest areas as well. The owner’s hall has built-in Sonance speakers and a 5.1 surround system.\nVideoworks then installed James Loudspeaker marine-grade speakers externally so that guests could enjoy the sound experience outside. As well as utilising a Kaleidescape server for films and music to ensure a cinematic film experience was available onboard, Videoworks was also conscious that superyachts are increasingly becoming places people work in, and so created a videoconference system in the main hall and in the owner’s office.\nTo protect the onboard network from IT attacks, Videoworks installed Kerio Control, an all-in-one firewall, antivirus and bandwidth management system, protecting the onboard server with an Intrusion Prevention System (IPS) that monitors all incoming and outgoing communications. A web filter allows administrators to deny or limit access to internet sites, services and applications, protecting users and infrastructure by prohibiting access to harmful sites that could steal the users’ identities and data. In addition to its capabilities as a new generation firewall, the device offers a Load Balancing function that guarantees high speed transmission for the most important data and an optimised Internet connection, distributing traffic via multiple links.\nAt the heart of Videoworks’s solutions is a centralised rack system to avoid local racks distributed throughout the yacht, providing a more ‘clutter-free’ environment. In the cabins and other guest areas, for example, there are only the speakers and TV screens. It also provides additional privacy, as any maintenance required by the crew does not require access to the guest areas.\nVideoworks did not just stop at Cecilia’s technological integration - it also dealt with lighting design and light engineering. Crucial when designing the project was the decision to use various lighting elements, including some customised ones, selected according to the desired atmospheres and the kind of illumination requested by the owners.\nOne of the more unusual elements on the Cecilia is the mixture of lighting ceiling panels with different lenses that ensure full illumination of every part of the room. Day, Night and Soft settings can be selected to make every moment of life on board satisfying. For the exteriors, Videoworks used a special type of illumination with elliptical lenses on the helipad platform and a system of lights for the sundeck’s glass panels, which make the yacht recognisable at night when anchored.","Electric and Diesel – a Match Made in Heaven\nCourtesy of Power and Motoryacht\nRising fuel costs are always a concern. As a result, achieving improvements in fuel economy has become a high priority throughout the marine industry, as it has in many other segments of business. Engine manufacturers have risen to the challenge, delivering sophisticated new power plants that not only burn less fuel but also produce fewer emissions. However, the fact remains that diesel engines will generally run most efficiently when they’re operating near their full rated capacity.\nAnd that poses a problem for recreational as well as commercial craft. Many yachts are fitted with engines capable of delivering speeds of 20, 30, 40 knots or more, yet their owners cruise at far slower speeds most of the time. While they’ll certainly burn less fuel at reduced speed, those big engines are not performing with maximum efficiency at very low load factors.\nThe problem can be even more acute for vessels in commercial service. For example, tugboats have big engines to develop lots of towing power but may spend much of their time operating at well below their maximum towing capacity. Or consider that crew and supply boats in the offshore industry must run at high speed to and from oil rigs that may be 100 miles or more from shore, where they then spend several hours idling alongside the rig while supplies and personnel are transferred. And last but not least, there are cruise ships, floating cities with power requirements that vary substantially, depending on whether the ship is in port or underway.\nOne of the ways that cruise-ship owners, tug-boat operators, and others in the commercial sector have confronted the problem posed by widely varying power requirements is to use diesel-electric propulsion systems. Rather than having a diesel engine drive the propellers directly, a diesel-electric system typically uses multiple diesel-powered gensets to produce electricity, which then powers an electric motor that turns a propeller shaft.\nUsing the diesel engine to make electricity, then using that electricity to drive an electric motor seems like a woefully inefficient process. And if power demand is constant, a diesel-electric drive can be slightly (about five percent) less efficient. But for circumstances where power demand is widely variable, the versatility of the diesel-electric system can yield big dividends, because gensets can be brought on line or shut down as power demand changes.\nOther than efficiency, one of the big advantages of a diesel-electric drive system is that big propulsion engines need not be located in line with the prop shaft; electric motors of the same kilowatt capacity are generally much smaller. This allows the yacht designer more latitude in deciding where to locate the gensets. And, in fact, the propulsion motors do not even have to be located inside the hull. One notable implementation of diesel-electric propulsion is the Azipod, developed by the German firm ABB. The Azipod system utilizes an electric motor mounted externally in a pod beneath the hull. The motor drives a fixed-pitch propeller mounted at one end of the pod, and the entire pod is free to turn 360 degrees. By locating the motors outside of the hull, problems like alignment, noise, and vibration that are associated with a conventional shaft, strut, and bearing drive train are eliminated. Moreover, because the pods can turn, they offer extraordinary maneuverability compared to a normal shaft and rudder system on a boat.\nOne of the early adaptors of Azipod propulsion in the megayacht arena is the German builder Lurssen. It had a client who demanded that his yacht (originally named Air but now named Ice) be as clean and environmentally friendly as possible, with low emissions, minimum vibration, and sound levels like that of a cat on plush carpet. (The yacht’s emissions standards are so stringent, the yard proudly touts her as its response to the Kyoto agreement.)\nTo meet these criteria the yacht was fitted with eight diesel gensets, mounted in pairs on elastically supported foundations located in four separate rooms. The yacht’s power-management system is designed to maintain the gensets operating as close as possible to 95 percent of rated capacity, their peak efficiency. Moreover, the diesel in each genset is fitted with a “soot” cleaning system (not feasible for large main-propulsion engines) that continually cleans the exhaust gas.\nBecause the Azipod has no struts or shafts, it operates in largely undisturbed water, so it creates much smaller pressure pulses on the hull as the propeller turns. That, coupled with the absence of bearings and gearboxes, makes for much less noise and vibration in the hull. After running the yacht for more than 18 months, the captain and the chief engineer have found that the system is easy to maintain, and they are quite satisfied with its performance.\nThe system on Benetti ‘s recently delivered Ambrosia III is similar, but with only two main gensets powering a pair of 1,070-kW Azipod propulsion units. Complementing the main gensets is a pair of smaller units located in a soundproof compartment; the smaller units are used for station keeping and for leisurely cruising at speeds of up to about 9 knots.\nAs long as forward thinking shipyards like Lurssen and Benetti remain open to out of the box power systems, creative solutions can be found. Northern Lights manufactures a line of fully customizable generator sets, up to 545kW – 60 Hz (475 kW – 50 Hz), ready to respond to the challenge.\nFormerly a professor of naval architecture at the University of New Orleans, George Petrie is a professor of naval architecture at the Webb Institute and continues to provide consulting services to small craft designers, ship operators, and other members of the marine industry."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:7c6b75eb-3cfa-4731-92e3-f71706ff7bfe>","<urn:uuid:a4051155-1a08-406b-bc3e-af3215cbeffa>"],"error":null}
{"question":"What's the difference between absolute and relative radiation patterns in antenna measurements?","answer":"Absolute radiation patterns are presented in absolute units of field strength or power, while relative radiation patterns are referenced in relative units of field strength or power. Most radiation pattern measurements are relative pattern measurements, and the gain transfer method is then used to establish the absolute gain of the antenna.","context":["ANTENNA RADIATION PATTERN\n1.1 To plot the radiation pattern of Dipole Antenna in E & H planes on log & linear scales on polar and Cartesian plots.\n1.2. To measure the beamwidth (-3 dB), front to back ratio, side lobe level and its angular position, plane of polarization and directivity and gain of Dipole Antenna.\nAntennas are a fundamental component of modern communication systems. By definition, an antenna acts as a transducer between a guided wave in a transmission line and an electromagnetic wave in free space. Antennas demonstrate a property known as reciprocity, which is an antenna will maintain the same characteristics regardless if it is transmitting or receiving. When a signal is fed into an antenna, the antenna will emit radiation distributed in space a certain way. A graphical representation of the relative distribution of the radiated power in space is called a radiation pattern. The radiation pattern of the antenna is of principle concern when engineering a communications system. Let’s assume that a signal needs to be sent from an antenna on the ground to a satellite in orbit. This would require a radiation pattern with the majority of its radiated power focused into orbit. If the antenna is not engineered to do so, contact cannot be established between the signal source and its target. There are many different ways to manipulate a radiation pattern to meet the demands of a specific task. These concepts are the principle focus of this lab assignment. Implementing this lab assignment, students will examine the radiation patterns of several antennas by hands on field testing. Only the most fundamental antennas were chosen for this lab assignment. This allows us to see visually how the most common types of real-world antenna designs function.\nThe following is a glossary of basic antenna concepts.\nAn antenna is a device that transmits and/or receives electromagnetic waves. Electromagnetic waves are often referred to as radio waves. Most antennas are resonant devices, which operate efficiently over a relatively narrow frequency band. An antenna must be tuned to the same frequency band that the radio system to which it is connected operates in, otherwise reception and/or transmission will be impaired.\nWe often refer to antenna size relative to wavelength. For example: a half-wave dipole, this is approximately a half-wavelength long. Wavelength is the distance a radio wave will travel during one cycle. The formula for wavelength is shown on the next page. Note: The length of a half-wave dipole is slightly less than a half-wavelength due to end effect. The speed of propagation in coaxial cable is slower than in air, so the wavelength in the cable is shorter. The velocity of propagation of electromagnetic waves in coax is usually given as a percentage of free space velocity, and is different for different types of coax.\nBandwidth can be defined in terms of radiation patterns or VSWR/reflected power. The definition used is based on VSWR. Bandwidth is often expressed in terms of percent bandwidth, because the percent bandwidth is constant relative to frequency. If bandwidth is expressed in absolute units of frequency, for example MHz, the bandwidth is then different depending upon whether the frequencies in question are near 150, 450, or 825 MHz A mathematical analysis of bandwidth is provided below.\nPERCENT BANDWIDTH IS DEFINED AS:\nFH is the HIGHEST FREQUENCY IN THE BAND\nFL is the LOWEST FREQUENCY IN THE BAND\nFC = (FH + FL)/2\n2.4 Directivity and Gain\nDirectivity: Given a set of spherical polar coordinates we can determine the power density in watts/ (square meter) for both the antenna being investigated, and the isotropic reference antenna, which is radiating the sane total power. The ratio of these power densities gives the directivity of the unknown antenna in the direction at a distance R from the antenna. If the direction is not specified, the “directivity” is taken to be the maximum directivity of any of the directions of radiation. The quoted definition is: “The directivity of an antenna is defined as the ratio of the radiation intensity in a given direction from the antenna, to the radiation intensity averaged over all directions; The average radiation intensity is equal to the total power of the antenna divided by 4. If the direction is not specified the directivity refers to the direction of maximum radiation intensity”.\nGain: The gain in any direction is power density radiated in direction divided by power density this would have been radiated at by a loss less (perfect) isotropic radiator having the same total accepted input power. If the direction is not specified, the value for gain is taken to mean the maximum value in they provide useful and simple theoretical antenna patterns with which to compare real antennas. An antenna gain of 2 (3 dB) compared to an isotropic antenna would be written as 3 dBi. The resonant half-wave dipole can be a useful standard for comparing to other antennas at one frequency or over a very narrow band of frequencies. To compare the dipole to an antenna over a range of frequencies requires an adjustable dipole or a number of dipoles of different lengths. An antenna gain of 1 (0 dB) compared to a dipole antenna would be written as 0 dBd.\n2.5 Gain Measurement\nOne method of measuring gain is by comparing the antenna under test against a known standard antenna. This is technically known as a gain transfer technique. At lower frequencies, it is convenient to use a 1/2-wave dipole as the standard. At higher frequencies, it is common to use a calibrated gain horn as a gain standard, with gain typically expressed in dBi. Another method for measuring gain is the 3 antenna method. Transmitted and received power at the antenna terminals is measured between three arbitrary antennas at a known fixed distance. The Friis transmission formula is used to develop three equations and\nthree unknowns. The equations are solved to find the gain expressed in dBi of all three antennas.\n2.6 Radiation Patterns\nRadiation Pattern: The antenna radiation pattern is a measure of its power or radiation distribution with respect to a particular type of coordinates. We generally consider spherical coordinates as the ideal antenna is supposed to radiate in a spherically symmetrical pattern. However antennae in practice are not omni directional but have a radiation maximum along one particular direction. For e.g. Dipole antenna is a broadside antenna wherein the maximum radiation occurs along the axis of the antenna. The 3-D radiation pattern of a typical dipole antennais shown in figure 1\nFIGURE 1:- RADIATION PATTERN OF A DIPOLE ANTENNA\n2.7 Absolute and Relative Patterns\nAbsolute radiation patterns are presented in absolute units of field strength or power. Relative radiation patterns are referenced in relative units of field strength or power. Most radiation pattern measurements are relative pattern measurements, and the gain transfer method is then used to establish the absolute gain of the antenna.\n2.8 Near-Field and Far-Field Patterns\nThe radiation pattern in the region close to the antenna is not exactly the same as the pattern at large distances. The term near-field refers to the field pattern that exists close to the antenna; the term far-field refers to the field pattern at large distances. The far-field is also called the radiation field, and is what is most commonly of interest. The near-field is called the induction field (although it also has a radiation component). Ordinarily, it is the radiated power that is of interest, and so antenna patterns are usually measured in the far-field region.\nDistance sufficiently large to be in the far-field, well out of the near-field. The minimum permissible distance depends on the dimensions of the antenna in relation to the wavelength. The accepted formula for this distance is:\nrmin=minimum distance from antenna\nD=largest dimension of antenna\nWhen extremely high power is being radiated (as from some modern radar antennas), the near-field pattern is needed to determine what regions near the antenna, if any, are hazardous to human beings.\nDepending on the radio system in which an antenna is being employed there can be many definitions of beamwidth. A common definition is the half power beamwidth(HPBW). The peak radiation intensity is found and then the points on either side of the peak represent half the power of the peak intensity are located. The angular distance between the half power points traveling through the peak is the beamwidth. Half the power is —3dB, so the half power beamwidth is sometimes referred to as the 3dB beamwidth.\n2.10 Antenna Pattern Types\n2.10.1 Omnidirectional Antennas\nFor mobile, portable, and some base station applications the type of antenna needed has an omnidirectional radiation pattern. The omnidirectional antenna radiates and receives equally well in all horizontal directions. Many of the antennas measured in the laboratory experiment are of this type, because of they are common-place in the real world. The gain of an omnidirectional antenna can be increased by narrowing the beamwidth in the vertical or elevation plane. The net effect is to focus the antenna’s energy toward the Horizon. Selecting the right antenna gain for the application is the subject of much analysis and investigation. Gain is achieved at the expense of beamwidth: higher-gain antennas feature narrow beamwidths . Omnidirectional antennas with different gains are used to improve reception and Transmission in certain types of terrain. A 0 dBd gain antenna radiates more energy higher in the vertical plane to reach radio communication sites that are located in higher places. Therefore they are more useful in mountainous and metropolitan areas with tall buildings. A\n3 dBd gain antenna is the compromise in suburban and general settings. A 5 dBd gain antenna radiates more energy toward the horizon compared to the 0 and 3 dBd antennas to reach radio communication sites that are further apart and less obstructed. Therefore they are best used in deserts, plains, flatlands, and open farm areas.\n2.10.2 Directional Antennas\nDirectional antennas focus energy in a particular direction. Directional antennas are used in some base station applications where coverage over a sector by separate antennas is desired. Point to point links also benefit from directional antennas. Yagi,horn,hellical and panel antennas are directional antennas.\n2.10.3 Antenna Polarization\nPolarization is defined as the orientation of the electric field of an electromagnetic wave. Polarization is in general described by an ellipse. Two often used special cases of elliptical polarization are linear polarization and circular polarization. The initial polarization of a radio wave is determined by the antenna that launches the waves into space. The environment through which the radio wave passes on its way from the transmit antenna to the receive antenna may cause a change in polarization.\nWith linear polarization the electric field vector stays in the same plane. In circular polarization the electric field vector appears to be rotating with circular motion about the direction of propagation, making one full turns for each RF cycle. The rotation may be right-hand or left-hand. Choice of polarization is one of the design choices available to the RF system designer. For example, low frequency (< 1 MHz) vertically polarized radio waves propagate much more successfully near the earth than horizontally polarized radio waves, because horizontally polarized waves will be canceled out by reflections from the earth. Mobile radio systems waves generally are vertically polarized. TV broadcasting has adopted horizontal polarization as a standard. This choice was made to maximize signal-to-noise ratios.\nAt frequencies above 1 GHz, there is little basis for a choice of horizontal or vertical polarization, although in specific applications, there may be some possible advantage in one or the other. Circular polarization has also been found to be of advantage in some microwave radar applications to minimize the \"clutter\" echoes received from raindrops, in relation to the echoes from larger targets such as aircraft. Circular polarization can also be used to reduce multipath. The majority of the antennas utilized in this experiment are vertically polarized because of their predominance in antenna applications."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:4fc3ac9b-1014-4521-a1de-cc54470d239c>"],"error":null}
{"question":"What procedural issues have affected the Guantánamo military commission cases, and how has government monitoring impacted attorney-client confidentiality?","answer":"The Guantánamo military commission cases have been plagued by procedural delays, with cases dragging out for more than a decade despite being originally envisioned as speedy trials. A significant issue arose when defense teams discovered their confidential conversations with clients were likely being monitored by the government. This led to mass resignations of defense attorneys who found what they believed confirmed government monitoring in the detention block room, though the specific details remained classified. When attorneys quit in protest, judges attempted to compel their return, even confining a Marine general for contempt when he refused to force lawyers back. Additionally, the firing of top tribunal officials, including Harvey Rishikof who was negotiating plea agreements, has raised concerns about government interference. Finding replacement qualified lawyers is particularly challenging due to the need for top secret security clearance and willingness to work with special military tribunal rules.","context":["GUANTÁNAMO BAY, Cuba — For years, an expert legal team defended one of the most high-profile accused terrorists in a death penalty case at the military tribunals here. But a courtroom dispute involving classified snooping prompted nearly all of the team to abruptly quit this fall, leaving only a 39-year-old former SEAL turned lawyer with just six years’ experience, and none with a capital case.\nBy many assessments, including his own, the lawyer, Navy Lt. Alaric Piette, is completely unqualified to represent Abd al-Rahim al-Nashiri, a Saudi man accused of orchestrating the bombing of the American destroyer Cole in 2000. Though he was trained to hunt down the most dangerous terrorists in the world, nothing prepared him to defend someone accused of carrying out terrorist acts.\n“On another day, I could have easily taken my client out. I know it seems like a contradiction,” Lieutenant Piette said as he stood in the tropical glare outside the dust-colored court building here, which is ringed by razor wire and sniper netting. “But in a lot of ways being a SEAL and being a defense attorney — you’re doing the same thing. You’re defending the Constitution.”\nNo lawyer with so little experience has ever led a case before the tribunal, and in fact, regulations prohibit it. That the Nashiri case is going forward at all has led many to question whether the tribunals can offer a fair trial, and has cast a harsh light on the already troubled military system, which so far has produced no convictions at trial, despite years of effort.\nPresident Trump has doubled down on Guantánamo, signing an order last week to keep the prison open and vowing in his State of the Union address to send more prisoners to the island. But the tribunals at Guantánamo have repeatedly sputtered, dragging out for more than a decade cases that were originally envisioned to be so speedy that they were set in temporary buildings and tents.\nAs further evidence of the system’s dysfunction, Defense Secretary Jim Mattis fired the top official overseeing the tribunals, Harvey Rishikof, as well as his chief of staff on Monday. A Pentagon spokesman said the change in leadership, which was first reported by The Miami Herald, would not affect continuing cases.\nThe Nashiri case began in 2011 and is still churning through pretrial hearings. So are the trials for those accused of being Sept. 11 collaborators. The judge for the Nashiri case has said he would like to begin picking a military jury by December, which puts the schedule of the case in doubt.\nIn death penalty cases, the military tribunal rules require so-called learned counsel who have tried capital cases before. The team’s former lead counsel had tried 38. Lieutenant Piette has tried none. But the judge in the case has decided to move forward with only the lieutenant — a move that has alarmed a number of legal scholars.\n“He doesn’t come close to being qualified,” said Ellen Yaroshefsky, a professor of legal ethics at Hofstra University. “So a death penalty case is basically going forward without a lawyer. If that is what we think passes as a court system, we’re in big trouble.”\nOne of the people questioning the lieutenant’s decision to stay is the lieutenant himself. His presence in court allows the case to move forward without experienced counsel. “That is clearly a problem, because there is no way I qualify as learned counsel,” he said. “But leaving the client without a lawyer to protect his rights could be even worse. I don’t know if I’ve done the right thing, but I don’t think I really had a choice.”\nThe dispute that prompted the resignations of the rest of Lieutenant Piette’s team started this summer when the defense learned that conversations with their client — conversations that are typically strictly confidential — were likely being monitored by the government.\nThe defense team searched the detention block room at Guantánamo where they met with Mr. Nashiri and spotted something that to them confirmed government monitoring. The original lead defense attorney, Richard Kammen, said in an interview that what he found was classified, so he was barred from disclosing it, even to his client. He objected to the court, but the judge in the case ruled this fall that the client had only limited rights to confidentiality. Mr. Kammen quit the case in protest, saying it was ethically impossible to stay. Two assisting lawyers followed.\n“We were gobsmacked,” said Mr. Kammen, who for years has jousted with the military tribunal, making his appraisal of it clear by wearing a kangaroo pin on his court jacket. “Under the law, we had to quit. We had no choice.”\nBoth the judge and prosecutors were furious at the exodus, which threatened to derail an already slow-moving case. The lead civilian prosecutor, Mark Miller, denounced the defense for what he called “a scorched-earth strategy to obstruct the proceeding by any means, however frivolous, however cynical.”\nThe judge, Air Force Col. Vance Spath, ordered the defense back to court in October. When they refused, he ordered a Marine general in charge of the defense to force them back. The general also refused, and was confined in a trailer next to the razor wire-ringed court in November for contempt. At the most recent hearings in late January, Judge Spath was still trying to compel the lawyers to appear, so far without success.\nIn a federal court, appointing a new experienced lawyer would be straightforward, but Guantánamo is no federal court. Few lawyers qualified to take death penalty cases have both the requisite top secret security clearance and the willingness to work with the special military tribunal rules created by Congress in 2009 for Guantánamo, said Navy Cmdr. Brian Mizer, who in the past has represented multiple detainees at the tribunals.\n“There is a perception that the tribunals are like tilting at windmills,” he said. “Many lawyers don’t want to go near it.”\nMr. Mizer and others said it could take at least a year for a new lawyer to be appointed and get caught up on the case.\nExperienced counsel in a case like Mr. Nashiri’s is critical, Commander Mizer said, because the thicket of charges stemming from a series of attacks is complicated further by evidence gathered through years of torture at C.I.A. black sites.\nBut after Mr. Kammen left, Judge Spath ruled that learned counsel were required only “to the extent practicable,” and pushed forward with pretrial hearings with just the lieutenant at the helm.\nLieutenant Piette, who grew up in Texas and Wisconsin, said he was not easily swayed by long odds. He enlisted in the Navy right after high school in 1997, inspired by his grandfather, who had been a decorated commando during World War II. Despite limited swimming skills and no experience with weapons, he soon graduated from the notoriously punishing SEAL selection course in a year when nearly 90 percent of the class dropped out.\nHe was assigned to a cold-weather warfare team and deployed to Kosovo.\nAfter the U.S.S. Cole and the World Trade Center were attacked, he thought the team would be sent to hunt terrorists. Instead he was deployed again to Eastern Europe. He finished his enlistment without seeing combat. With a young family at home and a growing frustration at the lack of action, he left the Navy at the end of 2003.\nFor years after, he said, he was dogged by regret. SEAL teams began deploying to Iraq and Afghanistan. Three friends were killed in combat. Men he knew shot Osama bin Laden, he said. He worried he had fumbled his chance to make a difference.\nThat changed at Georgetown University’s law school, where he started his degree program thinking he would become a prosecutor, but in his final year found the criminal defense clinic.\nRaised Roman Catholic, he described representing destitute, often mentally ill clients as the moment he really understood the teachings of Jesus.\n“It was the first time since the SEALs I found something really meaningful,” he said. “I was standing between a person and the system. Everything I had learned about training and preparation and perseverance — it clicked.”\nAfter graduating in 2012, he spent five years as a Navy lawyer, working criminal cases at Naval Station Norfolk in Virginia. Last April he was hired to work on the Nashiri case. He had barely started when his whole team quit.\nIn January, the judge repeatedly fumed at the missing defense team, calling it a strategic tactic intended to undermine the trial.\n“Never have I seen such open and notorious rejection of orders from a court,” the judge told the court.\nLieutenant Piette stood before him, respectful but unwavering. As a SEAL member, he said later, he was used to being yelled at.\nDuring hearings over several days in January, the prosecution called witnesses and moved to introduce photos and bags of blast fragments from the attack, which killed 17 sailors. Lieutenant Piette sat silently, spinning his pen in seeming frustration, but passed up dozens of chances to object and cross-examine.\nHe felt staying nearly silent was the only effective strategy for his client, he said. Over the course of two days, the judge asked 37 times for the defense to comment on the admission of evidence. Each time the lieutenant stood and responded, “Defense takes no position other than to object to these proceedings continuing without learned counsel.”\nThough he wanted to argue at length, challenging the very idea that evidence could be admitted without a jury present, he said he knew it would be unethical to even try, and could sink the case. He hoped his refusal to participate would preserve an issue for appeal. Whether it will upend the trial or be a mere footnote in the tribunals will likely not be known for years.\nThe prosecution declined requests for an interview, but in court, an Air Force major on the team denounced Lieutenant Piette’s objections, calling them “shameless, disingenuous and conceited.”\nThe same day, though, Abbe Smith, a law professor at Georgetown who taught Lieutenant Piette criminal defense, put his photo up in her ethics class as an example of a “courageous and ethical representation.”\n“He’s pretty gutsy. This legal train is in motion and he steps out in front to protect his client,” she said in an interview. “I don’t know that all lawyers would do that.”\nMr. Kammen said discussions with Lieutenant Piette about staying were “complicated” and he was not convinced his most junior lawyer did the right thing.\n“If we are obligated to withdraw, isn’t he?” Mr. Kammen said. “He’s a fine lawyer, but this is way beyond what he can do.”\nKeywords clouds text link\nDịch vụ seo, Dịch vụ seo nhanh , Thiết kế website , máy sấy thịt bò mỹ thành lập doanh nghiệp\nVisunhome, gương trang trí nội thất cửa kính cường lực Vinhomes Grand Park lắp camera Song Phát thiết kế nhà thegioinhaxuong.net/\n|aviatorsgame.com ban nhạc||confirmationbiased.com|\n|mariankihogo.com ốp lưng||Giường ngủ triệu gia Ku bet ku casino|\nmặt nạ mặt nạ ngủ Mặt nạ môi mặt nạ bùn mặt nạ kem mặt nạ bột mặt nạ tẩy tế bào chết mặt nạ đất sét mặt nạ giấy mặt nạ dưỡng mặt nạ đắp mặt mặt nạ trị mụn\nmặt nạ tế bào gốc mặt nạ trị nám tem chống giả\n© 2020 US News. All Rights Reserved.","Off the Record: Unlawful Influence on the War Crimes Proceedings\nThis is the second post in a blog series by Dr Kasey McCall-Smith examines some of the crucial legal issues and broader public questions raised regarding the US v. Khalid Shaikh Mohammad, et. al. military commission proceedings against the five men charged with various war crimes and terrorism in relation to the 11 September 2001 attacks on the US. The series is part of her project ‘Torture on Trial’ and funded by a grant from the Royal Society of Edinburgh.\n- Read the first post: Taking a Step Back – A Primer on the International Prohibition against Torture\nIn the 9/11 war crimes trial taking place in Guantánamo, an array of motions have been filed regarding unlawful influence on the US v. Khalid Shaikh Mohammad, et. al.(9/11 case) proceedings. They began with complaints regarding statements by then-President Obama and continue to the present with complaints regarding President Trump, Secretary of Defense Mattis, former Attorneys General Sessions and Holder and CIA Director Gina Haspel. These motions, all based on section 949b of the 2009 Military Commissions Act, cover a range of statements and actions.\nDuring the April-May 2018 proceedings, the influence of current US President Trump was raised as lawyers debated the influence of statements made by Trump as the commander in chief of the US military. The relevant statements focused on the president’s response to the Bowe Bergdahl v. US courts martialand also the 31 October 2017 New York incident where an alleged terrorist drove a van onto a bike path killing eight people. Trump’s statements on the campaign trail and after his election were also potentially problematic for the 9/11case and attacked the integrity of the military justice system. His statements and twitter posts explicitly called into question the administration of justice and constitutional protections in the US. Defence counsel in the 9/11 war crimes tribunal argue that collectively these successive statements by US presidents and other government officials equate to unlawful influence (UI), a concept drawn from provisions in the US Uniform Code of Military Justice prohibiting Unlawful Command Influence (UCI). UI is a concept set out in 10 USC §837 and article 37 of the UCMJ and is deemed the ‘mortal enemy’ of military justice and also violates due process as guaranteed by the US Constitution and the right to a fair trial under Article 14 of the International Covenant on Civil and Political Rights (ICCPR). The concept applies here as the governing law of the trial is the Military Commissions Act 2009 (MCA 2009) – combining rules of military, domestic and international law – and the president is the constitutional Commander-in-Chief of the US military.\nBut it is not merely careless remarks of political leaders that threaten the stability of the trial.The potential impact of alleged UI by Trump as the Commander in Chief was exacerbated when, at the July 2018 proceedings, defense counsel raised the issue of unlawful influence once again based on statements Gina Haspel made under oath during her Senate confirmation hearings for the post of CIA Director earlier in the year. Counsel for Khalid Shaikh Mohammad argued that Haspel’s assertions of his client’s guilt are either coercion or unlawful influence or create the appearance of unlawful influence on the on-going proceedings. Particularly problematic is Haspel’s role as the ultimate original classification authority as CIA Director. In the 9/11case, the government controls all defense access to classified evidence and this issue plagues every step of the commission. It was argued that Haspel’s statements equate to unlawful influence under MCA 2009 §949b(a)(2) and Rule104 of the Rules of the Military Commission, expansive rules governing the applicable procedures in the 9/11 trial.\nThe November 2018 commission proceedings heard argument on a fresh round of UI claims. This time regarding UI by former Attorney General Jeff Sessions and Secretary of Defense Jim Mattis in the firing of the Military Commissions Convening Authority, Harvey Rishikof, who was negotiating plea agreements with several of the 9/11 defendants at the time he was terminated as Convening Authority. As part of its claim, defense counsel heard testimony from the then-acting General Counsel for the Department of Defense, William Castle. In approximately 8 hours of testimony over a secured video line, Mr Castle acknowledged that he had been told by Sessions that there should be ‘no deal’ but insisted that his suggestion to fire Rishikof was solely due to Rishikof’s failure to ‘coordinate’ his office’s actions in accordance with Department of Defense procedure.\nThe cumulative effect of the statements about the defendants, the slow military commissions process or possible influence over the on-going military commission proceedings could result in either a dismissal or the removal of the death penalty if the recently appointed judge in the commission, Keith Parrella, finds that the comments collectively amount to unlawful influence. As explained in court, the President exercises an extensive amount of influence and should not call into question justice administered through proper legal channels, nor should various high-ranking officials seek to exercise influence over military commission proceedings. Even if this particular motion fails on this occasion, the court is on notice that eyes will be watching Mr Trump and his government and continued negative commentary could cumulatively result in abatement of the case at a later date. It has already resulted in the judge authorizing extensive voir dire of any potential military panel in future as a remedy to the previous comments. If the ultimate measure of abatement is taken in future it would no doubt be in accordance with variable applicable rules of law but simultaneously deprive the victims’ family members of the justice they so desperately seek. Tracking the various arguments across the 2018 hearings the message is clear: the government needs stop meddling in the military commissions and let justice run its course."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:76f6a948-eb9a-43c8-800b-692c02f854e4>","<urn:uuid:e29372d2-224a-4d3b-bce0-d8be83d73a2b>"],"error":null}