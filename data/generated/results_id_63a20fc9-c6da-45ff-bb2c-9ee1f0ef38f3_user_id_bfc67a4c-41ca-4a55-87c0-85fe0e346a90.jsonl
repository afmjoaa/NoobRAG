{"question":"What are the key differences between the G7's Climate Club initiative and the UN Ocean Treaty's approach to international environmental cooperation?","answer":"The G7's Climate Club and UN Ocean Treaty represent different approaches to environmental cooperation. The Climate Club, to be established by end of 2022, focuses on industrial sector decarbonization through three pillars: emissions calculation/reporting mechanisms, industrial transformation collaboration, and partnerships for just energy transition. In contrast, the UN Ocean Treaty focuses on marine protection through regulating fishing, preventing pollution, and protecting marine ecosystems. It requires formal ratification by 60 countries to become legally binding and includes specific provisions for marine genetic resources, protected areas, environmental impact assessments, and technology transfer to developing nations.","context":["Group of Seven (G7) leaders, during the G7 Summit in June in Elmau, Germany, agreed to find solutions to issues such as climate change, a just transition, COVID-19 and gender equality. The leaders also confirmed their determination not to compromise on climate change and biodiversity targets, and to reduce dependence on Russian energy, despite heightened energy and food risks resulting from Russia’s invasion of Ukraine, according to the G7 Leaders’ Communiqué (“Communiqué”) .\nJapan will hold the G7 presidency and host the summit in Hiroshima next year. To help advance climate actions of G7 and beyond, here are our recaps of key agreements on climate change at G7 this year.\nⅠ. Key points of Communiqué\nThe Communiqué (original English, Japanese) was put together building on the G7 Climate, Energy and Environment Ministers’ Communiqué (original English, Japanese) from a meeting held May 26 and 27. Key points were as follows.\n1. Strengthen efforts to address climate change in order to limit the temperature rise to 1.5°C\nRecognizing that current global measures are insufficient to meet the goals of the Paris Agreement, G7 countries committed to effectively implement domestic mitigation (greenhouse gas emission reduction) measures to achieve Nationally Determined Contribution (NDC) targets for 2030, and to increase ambition, including for example, by adopting or strengthening sectoral targets, non-CO2 sub-targets, or stringent implementation measures.\n2. Achieve a fully or predominantly decarbonized power sector by 2035, prioritizing a coal phase out\nAcknowledging that an energy supply with strong reliance on energy efficiency and renewable energy is economically sensible, technically feasible, reliable and safe, G7 countries committed to achieving a fully or predominantly decarbonized power sector by 2035. In particular, recognizing that coal power generation is the single biggest cause of global temperature increase, G7 countries committed to prioritizing concrete and timely steps towards the goal of accelerating a phase-out of domestic unabated coal power generation. The G7 countries committed to increasing electricity generated by renewable energies in all sectors, to removing barriers and obstacles that currently hinder or slow down the expansion of renewable energies, and to reducing energy consumption.\n3. End new direct public support for the international unabated fossil fuel energy sector by the end of 2022\nG7 leaders committed to ending new direct public support for the international unabated fossil fuel energy sector by the end of 2022. However, in order to phase out dependency on Russian energy, they acknowledged that as a temporary measure it was appropriate to allow publicly supported investment in the gas sector, if implemented in a manner consistent with climate objectives and without creating lock-in effects.\n4. Commitment to deliver on USD 100 billion funding goal ASAP and finance for adaptation\nG7 leaders renewed their commitment to deliver on the USD 100 billion climate finance mobilization goal (agreed at a United Nations Framework Convention on Climate Change/COP climate conference) as soon as possible and by 2025. They also renewed the commitment to at least double the provision of climate finance for adaptation to developing countries from 2019 levels by 2025. They recognized the urgent need for scaling-up action and support to avert, minimize, and address loss and damage* particularly in vulnerable developing countries.\n* Losses and damages that are already occurring from the impacts of climate change despite adaptation efforts.\n5. Support energy transition while supporting a just transition\nG7 leaders declared to reduce reliance on fossil fuels and accelerate the clean energy transition, they will support developing countries to make just transitions, through partnerships including Just Energy Transition Partnerships (JETPs), supported by the G7 Partnership for Global Infrastructure and Investment (PGII). Following on support for South Africa announced at UNFCCC/COP26, preparations are under way for JETP-related initiatives in Indonesia, India, Senegal and Vietnam.\n6. “Climate Club” will promote decarbonization of the industrial sector\nG7 leaders decided to establish an open and cooperative “Climate Club” by the end of 2022. The Climate Club will aim to promote decarbonization of the industrial sector based on three pillars:\n(1) Strengthen mechanisms for calculating and reporting emissions, and addressing risks of carbon leakage at the international level\n(2) Work collaboratively for industrial transformation to accelerate decarbonization (through the G7 Industrial Decarbonisation Agenda, the G7 Hydrogen Action Pact, expanding the market for green industrial products, etc.)\n(3) Strengthen international efforts through partnerships and cooperation to promote a just energy transition, while promoting climate action and generating socioeconomic benefits\nKey points of G7 Communiqué\n・ Although G7 leadership is far from adequate, the commitment to limit the temperature rise to 1.5°C and to strengthen action, and the commitment to decarbonize the power sector by 2035, with a priority on phasing out coal-fired power generation, will accelerate efforts by G7 countries. This is the first time the G7 has agreed to a phase out of coal-fired power generation.\n・ In terms of international support, the G7 has made progress from last year’s commitment to end direct support for coal-fired power generation to this year’s commitment to end direct support for the fossil fuel energy sector as a whole. G7 leaders confirmed that funds to support developing countries need to be increased for both mitigation (measures to reduce emissions) and adaptation (measures to address climate impacts), but no further consensus was reached.\n・ Developing and developed countries are forming partnerships to support a just transition. The Climate Club, to promote decarbonization of the industrial sector, is a new move aiming to address the carbon leakage problem through international cooperation. It will be important to monitor its progress.\n・ Besides addressing climate change, G7 leaders also committed to conserving or protecting at least 30% of land and 30% of the ocean by 2030, to restoring ecosystems, and to mainstreaming, enhancing, and scaling up the implementation of Nature-based Solutions (NbS).\nⅡ. Japan’s role\nー and the road to the G7 Hiroshima Summit (2023) ー\n1. Japan’s own interpretation\nJapan agreed to the Leaders’ Communiqué as a member of the G7, but it is evident that Japan has some of its own interpretations as to what was agreed. Here we look at two terms where Japan’s interpretation differs significantly from that of other G7 countries.\nThe Communiqué states that G7 leaders commit to achieving a “fully” or “predominantly” decarbonized power sector by 2035.\nThe Japanese government translation of the word “predominantly” in this Communiqué is 大宗 (pronounced taiso, which would mean “main” or “majority”). Common alternative translations of “predominantly” include 大部分 (daibubun, mostly) and 圧倒的 (attoteki, overwhelmingly). Although the agreement does not provide specific figures, a G7 power sector decarbonization scenario for net zero in 2050, published in 2021 by the International Energy Agency (IEA), shows coal-fired power generation at zero in 2035, and gas-fired power generation at only 2% (see figure), so that puts non-fossil fuel power generation at 98% in 2035. Thus, the general interpretation of the word predominantly in the G7 Communiqué would be “almost complete decarbonization.”\nFigure: G7 energy-related emissions and electricity sector milestones in the Net Zero Emissions by 2050 Scenario (IEA)\nSource: IEA report (PowerPoint presentation). Japanese version translated by Climate Integrate.\nConversely, statements at ministerial press conferences and other venues reveal a significant discrepancy between the international community’s concept versus Japan’s interpretation that “predominantly” just means “more than half.”\nTsuyoshi Yamaguchi, then Minister of the Environment: “There is not necessarily a fixed definition of what percentage is meant by ‘predominantly,’ but at least 50% should be acceptable.\n“Transcript of Post-Cabinet Meeting Press Conference by Minister Yamaguchi” (May 31, 2022), in Japanese.\nKoichi Hagiuda, then Minister of Economy, Trade and Industry: “There is no discrepancy with Japan’s schedule for carbon neutrality .“Summary of Post-Cabinet Meeting Press Conference by Minister Hagiuda” (May 31, 2022), in Japanese.\nThe ratio of fossil fuels in the 2030 power generation mix under Japan’s Sixth Strategic Energy Plan is 41%, and the plan for 2035 has not yet been formulated. It makes no sense for officials to state that there is no discrepancy between the G7 consensus and Japan’s schedule when there is still no clear picture of how Japan would achieve derarbonization. To be consistent with the Communiqué, Japan would have to reduce thermal power generation before it can decarbonize the power sector.\nThe Japanese government has translated “unabated coal power generation” as “coal-fired power generation without emission reduction measures”.\nThe Intergovernmental Panel on Climate Change (IPCC) Sixth Assessment Report by Working Group III (SPM36, April 2022, footnote 55), refers to “unabated“ as being “without interventions that substantially reduce the amount of GHG emitted,” and gives the example of “capturing 90% or more from power plants.” Based on this, a power plant that does not have without carbon capture and storage (CCS) equipment to capture and store 90% of its GHG emissions would not fall under the definition of having “interventions that substantially reduce the amount of GHG emitted.”\nMeanwhile, the Japanese government is promoting ammonia co-firing in coal-fired power plants as a so-called “zero-emissions power source,” with a target of 20% co-firing by 2030. In addition, since no coal-fired power plants in Japan are currently equipped with CCUS, it is highly likely that in 2030, there will be no coal-fired power plants in Japan that meet the IPCC’s definition of “interventions that substantially reduce the amount of GHG emitted.” In other words, the Japanese government’s policies are not consistent with the G7 Communiqué. Japan needs to move forward with the domestic phase-out of coal-fired power plants.\n2. Looking toward the G7 summit in Hiroshima in 2023\nThe G7 Summit in 2023 will be held in Hiroshima, under Japan’s presidency. Japan’s role is to step up efforts that are aligned with this year’s G7 Communiqué.\nAs part of efforts to limit the temperature rise to 1.5°C, a global stock take will be held in 2023 to assess the current level of efforts under the UNFCCC. The G7 must build the stepping stones to get there, to work together to further strengthen and accelerate climate actions, and to achieve stronger commitments.\nThe Hiroshima G7 Summit will provide an opportunity to think about peace and nuclear issues. This summit will be an important occasion to accelerate climate actions as a crucial element of protecting peace for humanity. We look to the Japanese government, having the presidency of the 2023 G7 Summit, to build on the 2022 Communiqué, and to play a strong leadership role in achieving consensus to accelerate decarbonization of the electric power and other sectors and to expand assistance to developing countries.\nWritten by Kimiko Hirata, Atsuko Kawaguchi","A historic new international treaty, described as “a monumental win for the protection of the world’s oceans”, will be open for signature by member states beginning September 20 during the high-level meeting of world political leaders at the UN General Assembly (UNGA).\nThe treaty will regulate the world’s wide-open oceans which have been degraded by illegal and over-fishing, plastics pollution, indiscriminate seabed mining, and the destruction of marine ecosystems.\nOfficially known as the Agreement for Biodiversity Beyond National Jurisdiction (BBNJ), the UN Ocean Treaty is the result of almost two decades of negotiations and will be legally binding after ratification by 60 countries from among the UN’s 193 member states.\nThe ratification process includes final approval by heads of government or parliaments –depending on the country’s laws. In the US, presidents can sign treaties, but ratification requires the approval of two-thirds of the Senate.\nThe long-drawn-out discussions on the treaty included four elements of a package that guided the negotiations, namely marine genetic resources (MGRs), questions on benefit-sharing, area-based management tools (ABMTs), marine protected areas (MPAs), environmental impact assessments (EIAs), capacity building and the transfer of marine technology (CB&TT).\nOut of 52 multilateral treaties to be highlighted at this year’s treaty-signing event, 17 are related to the environment, including the BBNJ Agreement.\nA victory for multilateralism\nThe breakthrough Agreement, which was adopted on 19 June 2023, was called “a victory for multilateralism” by Secretary-General António Guterres.\n“The oceans are in crisis,” said Vladimir Jares, Director of the Division for Ocean Affairs and the Law of the Sea, reiterating the importance of the Agreement. He said the UN hopes member states will aim for universal participation, of which the first step is signing the Agreement.\n“Universal participation in these treaties is absolutely fundamental to their success,” David Nanopoulos, Chief of the UN Treaty Section, told reporters on 14 September.\nHe said the Montreal Protocol on Substances that Deplete the Ozone Layer regulates nearly 100 ozone-depleting substances and has been credited with repairing the ozone layer and slowing down climate change.\n“Thanks to universal participation in this treaty, the ozone layer is well on its way to full recovery,” he added.\nIn a new report released September 14, Greenpeace provided a major new analysis of the ocean threats.\nThe 30×30: From Global Ocean Treaty to Protection at Sea report sets out a political roadmap to protect 30% of the world’s oceans by 2030.\nGreenpeace report provides a “shocking extent of threats to ocean health” and calls for urgent protection using the new UN Ocean Treaty\nBetween 2018 and 2022, apparent fishing activity in the high seas rose 8.5% to nearly 8.5 million hours, and in the areas identified for protection under 30×30, the figure rose 22.5%.\nThese trends show reality at sea is moving in the opposite direction to the ambition laid out in the Treaty, Greenpeace said.\nNew treaty consistent with SDGs\nAs well as fishing, the report details how ocean warming, acidification, pollution and the emerging threat of deep-sea mining are placing ever more strain on ocean ecosystems, making clear the urgency of political action to deliver 30×30 using the Ocean Treaty.\nDrifting longlines make up over three-fourths of total apparent high seas fishing activity. Longlining is a destructive fishing method, responsible for high levels of bycatch.\nCurrently, less than 1% of the high seas are properly protected and to reach 30×30 around 11 million KM2 of ocean must be protected every year.\nDr Palitha Kohona, who co- chaired the UN Ad Hoc Working Group on Biodiversity Beyond National Jurisdiction (BBNJ), told IDN that consistent with the UN’s Sustainable Development Goals (SDGs), the new treaty seeks to advance conservation goals as well as benefits sharing and technology transfer.\n“While the enthusiasm of the NGO community for ocean conservation is laudable, we must not forget the need to strike a balance with the needs of millions of those depending on fisheries for their livelihood and protein intake,” he pointed out.\nMillions in the developing world depend on fisheries for their livelihood and they really have no alternative, he argued.\nIn parallel, marine products constitute the main source of protein for further millions in the global South. Dr Kohona is a former Permanent Representative of Sri Lanka to the United Nations and, most recently, Sri Lanka’s Ambassador to China.\nHe noted that in a world threatened by a possible food crisis, the needs of millions dependent on fisheries must be kept in mind.\nHumanity’s relationship with the oceans\n“The needs of the global South may be addressed to some extent by implementing the benefits sharing and technology transfer provisions of the draft treaty with the same enthusiasm demonstrated for marine conservation.”\nWhile keeping all this in mind, he said, “we must applaud the opening for signature of this treaty, which will define another important aspect of humanity’s relationship with the oceans. Most likely, life originated in the oceans, and the oceans continue supporting life.”\nChris Thorne of Greenpeace’s Protect the Oceans campaign said: “The Ocean Treaty was a historic win for nature, but as our report shows, the threats to marine life worsen every day.”\n“The Treaty gives us a powerful tool to protect the oceans, but now governments must urgently ratify the Treaty and deliver ocean sanctuaries to give the oceans space to recover and thrive,” he declared.\nThorne also warned that destructive practices at sea threaten the future of ocean health and by extension, the future health of our whole planet.\nTo give marine life a chance, at least 30% of the oceans must be protected in a network of ocean sanctuaries by 2030.\n“We have just seven years left. Countries serious about ocean protection must sign the Ocean Treaty next week at the UN General Assembly and ensure that it is ratified by the UN Ocean Conference in 2025.”\nThe Greenpeace report also outlines the political steps and actions necessary to establish these ocean sanctuaries using the Treaty.\nAnd it recommends three specific sites on the high seas to be among the first set of ocean sanctuaries due to their ecological significance: the Emperor Seamounts in the Northwest Pacific Ocean, the Sargasso Sea in the Atlantic Ocean, and the South Tasman Sea/Lord Howe Rise between Australia and New Zealand."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:aefbf36a-03ae-453b-8f63-f047f00bd940>","<urn:uuid:143e2ef0-f83c-4fe5-a8f7-6b43deb689e4>"],"error":null}
{"question":"What's the environmental impact comparison between traditional lawn maintenance and wildlife-friendly mowing practices in terms of both biodiversity and resources?","answer":"Traditional lawn maintenance, which covers about 40 million acres in the US, typically requires heavy irrigation and often involves pesticides that harm pollinators and provides no nesting sites. In contrast, wildlife-friendly mowing practices, such as delayed mowing and creating unmowed areas, support diverse species including grassland birds, bees, and other wildlife. Research in Appleton showed that unmowed lawns had five times more bees and three times more unique bee species than mowed areas. Additionally, using manual push mowers instead of gas-powered equipment reduces oil and gasoline usage, decreases VOC emissions, reduces noise pollution, and lessens dependence on fossil fuels.","context":["- October 27, 2016\nNot mowing is a wonderful way to mindfully encourage wildlife; but, that isn’t always an option. Some need to harvest hay, prep fields for planting, or maintain a meadow susceptible to succession by woody plants. When it is time to mow, we want you to know there are simple strategies to consider to minimize negative impacts on wildlife.\nEnsuring that wildlife can use farms and other open grassy areas as habitat is vital in the United States where over 50% of the land is used for some form of farm production. In many areas, the answer is simply one of timing.\nMowing is devastating for many species of animals, but it is most devastating for those, like grassland songbirds, who are laying eggs and raising young in fields that are cut before offspring fledge. The dates for these activities vary by region and species of birds. Vermont researchers found that Bobolinks (Dolichonyx oryzivorus), pictured above, and Savannah Sparrows, (Passerculus sandwichensis), are two species most at risk of population declines due to early mowing practices by farmers in hay fields. In this region, waiting until the first of August, or even better, the end of August ensures higher survival rates for the offspring of these species.\nThe USDA created this guide, pictured above, based on the primary nesting season of birds that can act as a guide to landowners across the United States who are interested in protecting habitat for nesting grassland birds. Most regions recommend delaying mowing until after the first of August, but for some areas the danger-zone persists until the middle of September.\nSeveral people have anecdotally reported that they have success saving nests by practicing the art of close observation of their fields. By walking their fields and monitoring wildlife in the month leading up to their mow-date they are able to locate some nests, mark them, and avoid them when they get on the tractor to cut the hay. This mindful approach to mowing is a great way not only to preserve nests, but also to engage with nature. To formalize this monitoring, you might consider recording your observations in eBird and NestWatch–projects designed to help you track and improve your powers of observation.\nLearn how to find nests: Watch and listen first\nBefore you set off searching for nests, spend some time quietly observing the birds around you; they will often give you important clues about where their nests are located. Not only will listening first tell you what species’ nests may be present, but because male birds sing to mark the boundaries of their territories they will also tell you generally where to search. Watch individual males as they move from point to point and sing, and mark their locations on a map or record the area that you will search. Together, these points will outline the approximate territory surrounding a nest site. Within this territory, look for a female calling to her mate. Watch her from a distance through binoculars; many females will call on their way to the nest or even while on the nest (e.g., grosbeaks). Learn More…\nNew technologies may eventually help solve some of these challenges for farmers. Sensors that can detect nests in fields, like this nest of Savannah Sparrows buried in the tall grass, may eventually be available to farmers allowing them to route around areas where known nests are present.open_in_new\nBirds, of course, aren’t the only wildlife you will find hunkered down in a field. With a little searching in the image above you’ll find another common occupant of grasslands during breeding season. Harvest delay helps save a myriad of wildlife.\nWildlife-friendly mowing at home\nThe video above recommends letting your lawn grow longer than average, perhaps encouraging patches of flowers to bloom for bees and other pollinators. If you have a small lawn, consider checking your grass before mowing for small creatures that might be using the habitat area. When mowing, go slowly, starting from the center of your lawn and working out towards the edges. This provides the opportunity for wildlife to respond to the disturbance and flee to safety outwards, rather than slowly driving them inwards with no escape. Finally, instead of using the mower right up against edges, where wildlife frequently hide, use hand shears in these sections to minimize harming smaller animals like frogs, toads, snakes, spiders, and small mammals.\nUsing a push mower instead of an electric or gas powered mower is likely to benefit wildlife simply because you are moving slower. Aside from helping wildlife, there are other environmental benefits including the elimination of oil, gasoline, and VOC (volatile organic compounds)open_in_new emissions, decreased noise pollution, and reduced dependence on fossil fuels.\nDelaying a harvest, however, may pose challenges for some farmers who need to maximize their productivity by doing multiple hay harvests or those that need to turn over fields in the middle of the season. When you can’t wait, there are other options for “wildlife-friendly mowing.” For instance, you can create prairie strips, or areas that are left unmowed near agricultural fields, as refuges for wildlife that might otherwise find themselves in the mow-zone.open_in_new Prairie strips can be left around the borders of crop or hay fields or they can be used in between rows of areas that are harvested. They become hiding places for wildlife while heavy machinery and people work in the crops, and are resources for pollinators as well.\nThe spaces devoted to “prairie strips” can be rotated seasonally, annually or semi-annually depending on the needs of the farmers. The most important management choice is that they are left undisturbed during nesting season. Bush hogging these strips once in the fall will allow farmers to avoid succession of woody plants and shrubs and minimize the encroachment of invasive species in fields. Bush hogging is done using a rotary mower that hooks onto a tractor and cuts grass at three inches or higher using a dull blade.\nAnother wildlife-friendly mowing strategy is to mow from the center out. The tractor in the image above is doing the exact opposite–mowing inwards–driving any wildlife in that field inwards into an increasingly tighter space where they continue to be in the path of the mower blades.\nLarge properties with open meadows and farms play an important ecological role as habitat. Exploring diverse solutions to helping our farmers maximize their productivity while also protecting wildlife is an important and on-going problem to solve.\nWildlife-friendly Mowing Tips\nAdd it to your Map\nTell us about your mowing practices.\nBegin by selecting the grass habitat(s) on your map. You will know you’ve selected this habitat as it will be outlined in a yellow color.\nThen, click on the green info button and complete the characteristics for your mowing practices. This information will then update your Planning Tool actions and goals for your map.","This is the first week in May, when many bees in the U.S. wake up from their winter hibernation and smell the flowers.\nNow, you can support these essential pollinators in their search for nectar by participating in No Mow May and letting wildflowers grow on your lawn.\n“[W]hen we leave our weeds, or things we would normally call weeds, to grow, those are like little cheeseburgers for our pollinators, and they’re able to get some cheap calories really, really fast and put on some weight that will give them a leg up for the season,” Lawrence University assistant biology professor Israel Del Toro told NPR.\nNo Mow May was first championed by Plantlife in the UK, where it is gaining traction. The group said that a growing percentage of the participants in its Every Flower Counts citizen science survey were choosing not to cut their grass for a month, as The Guardian reported. In 2019, 33.6 percent of flower counters didn’t mow their lawns; by 2021, that number had jumped to 78.8 percent. The 2021 survey counted more than 250 species of wild plants including rarely seen species like adder’s-tongue fern, meadow saxifrage, snakeshead fritillary and eyebright.\n“These results demonstrate that our call to No Mow May has set seed and laid down deep roots,” Plantlife head Ian Dunn told The Guardian. “The results underline how embracing a little more wildness in our gardens can be a boon for plants, butterflies and bees. We are excited by the unfolding dawn of a new British lawn.”\nA new lawn is dawning across the pond as well, and the light is growing from Appleton, Wisconsin. Inspired by the UK efforts, the town’s City Council voted in 2020 to suspend its weed ordinance for the month of May, according to Bee City USA. Researchers at Appleton’s Lawrence University, including Del Toro, found that participating lawns had five times more bees than parks that had been mowed and three times as many unique bee species.\nAfter Appleton’s success, the initiative has continued to spread across Wisconsin, WISN 12 reported. More than 30 cities now participate, mostly in the Midwest, NPR reported.\n“I think there’s an opportunity here to do what’s right for the environment. We’re only doing it for one month, and then by that point, the bees should have come out of hibernation, they should have been able to find their initial food sources,” Glendale, Wisconsin Mayor Bryan Kennedy told WISN.\nGlendale is running a pilot program this year that will apply to private citizens, but not public spaces.\nLawns are actually the largest irrigated crop in the U.S., according to Bee City USA, taking up 2 percent of U.S. land, or around 40 million acres. They require lots of maintenance and tend to harm pollinators because they do not provide nesting sites and are often treated with pesticides.\nHowever, many U.S. cities dictate the height and sometimes the type of grass that homeowners are allowed to grow. Bee City USA offers some recommendations for what people who want to support pollinators without getting in trouble can do:\n- Mow a buffer area of mowed grass around the space where you allow wildflowers to grow.\n- Talk to local officials and health departments about ways to support natural lawns.\n- Recommend a Natural Lawn Registration program or similar that allows homeowners to register their alternative lawn with the health department and avoid fines.\n- Talk to neighbors about why you are leaving the lawn mower in the garage or put up a sign announcing your unmowed lawn is designed to protect pollinators and is not an act of neglect."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:db7139b2-f73a-4dfd-b9a2-b5a758bbfa80>","<urn:uuid:dcddcd4b-623f-4e0c-823b-553d4630d62c>"],"error":null}
{"question":"How does blockchain technology compare to swift payments in terms of processing time and efficiency?","answer":"Blockchain and SWIFT payments differ in their processing times and efficiency. Blockchain transactions occur regularly every couple of minutes, making them relatively fast. In contrast, SWIFT payments typically take longer, usually 2-5 business days to clear, and can occasionally experience further delays due to factors like holidays or payments from slow-to-pay countries. Additionally, while blockchain operates as a decentralized network without a central authority, SWIFT works through intermediary/correspondent banks, where payment orders are sent between institutions' accounts rather than directly transferring funds.","context":["What is blockchain?\nAs name stands for itself, blockchain is a chain of blocks used for storing and transferring information about transactions taking part in the internet. Each block contains information about specific amount of transactions. Once limit is reached, a new block is formed, making a chain. Depending from the type of blockchain, the new blocks appear regularly each couple of minutes.\nThe information stored in blocks can differ. Although it is commonly presumed that is stores data only on cryptocurrency transactions (like Bitcoin), there can be stored different data, like:\n- physical currency transactions\n- stock market transactions\n- purchase/sell transaction of physical assets\n- payment transactions for services any many more.\nHow does blockchain works?\nThe main idea behind the concept of blockchain is to maintain a common accounting book in a digital form (this is why blocks came into existence), which is a decentralized network and spread globally in precisely same copies. It is a peer-to-peer network without central governing authority/body/server managing and verifying transactions. Each computer connected to the blockchain can participate in these actions and see the transactions taking place (in most blockchains transactions are public). Despite the transactions are public, they user can check only his own transactions (all of them). The rest is encrypted by advanced cryptographic tools (hence the prefix crypto- for the digital currencies).\nHow blockchain can be used?\nCurrently blockchain is most commonly used for all sorts of financial transactions, with most popular transaction way - cryptocurrency transfers. The first blockchains and their cryptocurrencies (like Bitcoin and Litecoin) are very limited as speaking of their functionality. Yet the idea of blockchain makes it a very flexible tool, which is capable to literally change the world. In last couple of years, with such projects as Ethereum or Ripple the scope of application of blockchained has widened to the limits of human imagination. Blockchain so far had found its way to be used in banking system, transaction platform, digital signature, document verification, contracts for services, logistics, insurance, healthcare, real estate, ecology, charity and even protection of endangered species. World Economic Forum estimates, that by 2025 10% of global GDP will be stored on the blockchain.\nIs blockchain technology a safe one?\nAs for now, there is no chance of breaking the blockchain cryptography based security. This would require, at the moment we are writing this, combining most of the global computing power on one task - breaking into a single blockchain.\nAs well blockchain records cannot be altered - if someone would try to alter a blockchain in one copy of it, the safety measures (including checking all other copies of records from whole global blockchain) are going to detect that and refuse to accept the forfeited copy.\nIs blockchain a threat to the banking system?\nSome state that blockchain makes it a vital threat to the banking systems, as it gives to many people a chance to simply bypass the traditional bank networks (eg. in case of international money transfers by banks, which are slow and costly).\nStill, blockchain has the potential to make many banks beneficiaries of it. Spanish Santander bank estimates, that full application of blockchain for payments and transactions can even mean tens of billions of USD savings for banking system.\nRipple blockchain was intentionally created to be a tool for banks for cheap and fast transactions. Alternatively, banks can make their own internal cryptocurrency with specific price, benefit from its blockchain and therefore introduce cheap and fast transactions between themselves.\nIs blockchain important?\nWithout any question, blockchain technology has a potential to change our everyday life. When applied properly, it can make data processing (not only in financial sector) much faster, cheaper and safer. We will discuss the practical application of it in details in the next article.","- Are international bank transfers instant?\n- Is Iban enough for international transfer?\n- Can money get lost in a wire transfer?\n- How do I check the status of my swift transfer?\n- How does international money transfer work?\n- Why is wire transfer taking so long?\n- Can I track my international wire transfer?\n- How long does a bank transfer take international?\n- What needed for international bank transfer?\n- Can a international wire transfer be reversed?\n- How does a swift payment work?\n- Can international bank transfers take longer than 5 working days?\n- How long can a bank hold an international wire transfer?\n- How long do international bank transfers take nationwide?\n- What is the best way to transfer money abroad?\n- Do nationwide charge for international bank transfers?\n- Do you need swift code for international transfer?\n- How do I recall an international wire transfer?\n- How long do swift payments take to clear?\n- How do I transfer money abroad with swift code?\n- Can a swift transfer be recalled?\n- How long does a bank transfer take?\n- Why do international bank transfers take so long?\nAre international bank transfers instant?\nThe transfer is not usually instant but you might be able to get the money overseas within 24 hours – depending on the currency and the destination.\nFor a fast international money transfer using a broker, you’ll need to register for an account.\nIt’s not exactly instant but the money could arrive within a day..\nIs Iban enough for international transfer?\nFollowing October 31, 2016, the use of the international bank account number (IBAN) is sufficient and mandatory, the indication of the BIC (SWIFT) code of beneficiary’s bank is not necessary in case of SEPA foreign currency transfer orders.\nCan money get lost in a wire transfer?\nA wire transfer is never lost per se. … A wire transfer is never lost per se. There are literally 100s of scenarios as to why a wire transfer is either not returned or not credited to the end beneficiary. Most of the time it is an administrative (system or human) error in the handling of the wire transfer.\nHow do I check the status of my swift transfer?\nCan I track a transfer using a SWIFT code? Yes. If your transfer isn’t delivered within the window you were promised, you can request a trace on your transaction using the bank’s SWIFT code. A SWIFT code is an ID that banks use when sending wire transfers.\nHow does international money transfer work?\nRather than giving someone your bank account number, then, you use a SWIFT account number and SWIFT does the rest. … Member banks combine a large number of transactions into one big transfer to another bank, and CHIPS settles the score and moves the money.\nWhy is wire transfer taking so long?\nOccasionally, there are delays. If the bank sending the funds makes a mistake, a wire transfer may take longer than expected. Wire transfers can also be disrupted by holidays as well. Be prepared for delays if you’re receiving money from a slow-to-pay country such as Afghanistan or Cuba.\nCan I track my international wire transfer?\nTo find out if an international wire you sent was received, you have a few options. You can contact the recipient and ask directly. Or you can request a trace on the transfer, and your bank will be able to tell you whether the money has been deposited into the recipient’s account².\nHow long does a bank transfer take international?\nUnfortunately, there is no definitive answer to this one. Several factors influence the time it takes for funds to reach an overseas account. However, a standard timeline for most international transfers is about 1 to 4 business days.\nWhat needed for international bank transfer?\nRecipient’s account number and account type (e.g., checking or savings) Recipient routing number. Recipient bank’s SWIFT or BIC code (if applicable) Recipient bank’s IBAN (if applicable)\nCan a international wire transfer be reversed?\nA wire transfer is an immediate form of payment. Once a scammer has obtained the funds you wired in exchange for a check, the wire transfer cannot be reversed, even if the check is fraudulent. … Check the information you include on a wire transfer. One typo could send the money to the wrong person or business.\nHow does a swift payment work?\nSWIFT works essentially the same way. Your money will travel from one country to another, but to do that there are often intermediary/correspondent banks involved. The SWIFT network doesn’t actually transfer funds, but instead it sends payment orders between institutions’ accounts, using SWIFT codes.\nCan international bank transfers take longer than 5 working days?\nFunny enough, it’s the receiving end of an international wire transfer that can often take the most time. … And that’s why, in part, once you send an international wire transfer, it can take up to 5 business days, or in some cases even longer, for the funds to be available in the recipient’s account.\nHow long can a bank hold an international wire transfer?\nTransfers between U.S. and international accounts are completed in 1–5 days. Unlike checks or deposits over $1,500, which can be held by banks for up to 10 days, recipients of large wire transfers don’t have to wait for funds to clear.\nHow long do international bank transfers take nationwide?\nAll other international payments can take 4 working days or longer. there’s no limit on how much you can send. you need to use your current account to send or receive a SWIFT payment – you can’t use a savings account.\nWhat is the best way to transfer money abroad?\nThe best ways to send money abroadBank Transfer. Bank transfers are usually the cheapest option when it comes to funding your international money transfer with TransferWise. … Debit Card. Paying for your transfer with a debit card is easy and fast. … Credit Card. … PISP. … Swift.\nDo nationwide charge for international bank transfers?\nNationwide does not charge a transaction fee for SEPA credit transfers. We will use our standard outbound exchange rate to convert your payment from sterling to euros.\nDo you need swift code for international transfer?\nYou will need to provide your account number and wire transfer routing number. For incoming international wires, you will also need to provide the appropriate SWIFT Code. … Fees and limits may apply, depending on your account type and the type of wire.\nHow do I recall an international wire transfer?\nYou first need to call your bank and let them know the transfer you made was fraudulent and that you are requesting a SWIFT recall to be initiated. You must have all the information about the wire funds transfer in front of you to properly initiate this request.\nHow long do swift payments take to clear?\nOnce your payment has been processed (assuming that you have provided us the correct account details), you will generally receive the money in your bank account in approximately two business days. However, occasionally the transfer can take up to 5 business days.\nHow do I transfer money abroad with swift code?\nEnter the recipient’s bank details. To complete a SWIFT international transfer, you’ll need to provide the following specific information. The name and address of your recipient’s bank. Your recipient’s name, address, and the account type they have with their bank (checking, current, savings, money market, etc.).\nCan a swift transfer be recalled?\nCompleted payments sent via the SWIFT network (priority payments) can be recalled. Additionally, at least five working days must have passed before you can trace a payment.\nHow long does a bank transfer take?\nAs a result, most bank transfers are instantaneous, although in some cases, payment can take up to two hours. It’s important to remember that while Faster Payments aims to provide you with these types of bank transfer times, there’s no guarantee that your payment will be cleared on the same day.\nWhy do international bank transfers take so long?\nWhy do international transfers take so long? Commonly, it’s about the bank’s payment processing. The recipient’s bank need to declare a value date for the transfer and pass it back to the sending bank, and that process will take up to a few days."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:af33cd26-4335-437d-9dfa-22b77f43cfee>","<urn:uuid:241d1da6-929c-42b6-85de-bba7450ee601>"],"error":null}
{"question":"I'm a veterinary student looking to understand PRRS virus transmission. How do herd rollover and indirect transmission methods compare in terms of their approach to controlling the virus?","answer":"Herd rollover is an elimination procedure that involves keeping the premises populated while relying on viral shedding cessation and removing infected animals, typically involving herd closure where no breeding replacements enter for at least 6 months. In contrast, indirect transmission methods involve multiple routes: insects can mechanically transmit the virus up to 2.4km, personnel can spread it through contaminated equipment and clothing, and fomites like farm supplies and transport vehicles can act as mechanical vectors. These indirect routes can be controlled through washing, disinfecting, and drying, particularly for transport vehicles where peroxygens and glutaraldehyde-quaternary ammonium chloride combinations are effective when applied for two hours.","context":["Some key definitions regarding PRRSv infection, control and elimination\n(extracted from Holtkamp et al. 2011, JSHAP v19 n1):\nHerd: The population of animals at a defined premises.\nPremises: Buildings or areas containing pigs at contiguous locations with common employees, management or both.\nInternal multiplication and closed premises: A breeding herd where replacements are born on the premises but are reared at other premises before returning as replacements.\nElimination procedure: Any procedure used to eliminate the PRRSV from a swine herd. Ceasing the entry of PRRSV-positive animals and discontinuing intentional exposure to live virus are necessary elements of all elimination procedures. Here are three broad categories of elimination procedures.\n- Complete depopulation and repopulation: Complete removal of all animals from a premises which are cleaned and sanitized prior to reintroduction of PRRSV-negative breeding replacements. Applies to both breeding herds and growing-pig herds\n- Herd rollover: Any elimination procedure that relies upon cessation of viral shedding in the population and removal of previously infected animals, with subsequent introduction of negative breeding replace- ments. The premises are not completely depopulated in a herd rollover. Typically, herd rollovers involve herd closure (as de!ned below).\n- Incomplete depopulation: Any elimination procedure for a growing-pig herd that relies upon cessation of viral shedding in the population, with subsequent introduction of negative animals and removal of previously infected animals. The premises are not completely depopulated in an incomplete depopulation. Applies to growing-pig herds only.\nInitiation of elimination: For breeding herds, initiation of elimination begins when the last seropositive breeding replacements are introduced or when the last intentional exposure to any live PRRSV occurs in the herd, whichever is later. For growing-pig herds, initiation of elimination begins when the last positive pigs are introduced.\nHerd closure: A procedure where no breeding replacements, positive or negative, are allowed to enter the breeding herd to facilitate cessation of viral shedding in the population. Closure is usually maintained for at least 6 months. Typically done in herds that are eliminating the PRRSV by herd rollover.\nHerd test: The evaluation of a herd based on diagnostic testing of a sample of some (or all) animals in the herd and decision rules to classify the herd as positive or negative.\nWeaning-age pigs: Pigs within 7 days before or 3 days a#er weaning, regardless of age.\nNegative breeding replacement:\nFor premises that are entering external replacements sourced from other breeding herds, including those with internal multiplication and closed herds, or internal multiplication and closed premises that temporarily introduce replacements from outside sources, confirmation that replacements are antibody-negative and not infected requires both of the following conditions:\n- Replacements must originate from AASV Category III or IV breeding herd premises\n- Diagnostic confirmation that negative breeding replacements are seronegative by ELISA and negative for viremia by PCR just prior to entry into the breeding herd\nFor premises that are entering internal replacements, confirmation that replacements are antibody- negative and not infected requires the following condition:\n- Diagnostic confirmation that negative breeding replacements are seronegative by ELISA and negative for viremia by PCR just prior to entry into the breeding herd.","Epidemiology & pathogenesis of the PRRS virus\nEpidemiology & pathogenesis of the PRRS virus\nTransmission between herds\nNOTE: Some of the following data can be also applied to the chapter “Transmission within herds”.\nI. DIRECT TRANSMISSION:\nThe most frequent routes of PRRS virus transmission between herds are the introduction of infected animals and the use of contaminated semen.\nPRRS virus is spread mostly by semen and direct contact with infected animals. In the second case, the highest risk situations are introduction of positive replacements in reproductive herds, or introduction of weaned piglets from different sources (positive and negative) in fattening units. Regarding replacements, besides being a very important source of virus introduction, particularly when they are from an external herd with an unknown or positive PRRS virus status, negative gilts also have a significant role in the circulation of the virus when introduced on a positive/unstable farm; in this last case, they act as a constant flow of susceptible animals, which contributes to the infection being sustained.\nRegarding transmission by other species, feral swine can act as a source of the virus, whereas many other species, including dogs, cats, raccoons, rats, mice, etc. are not susceptible to infection.\nFor more information about the role of semen and direct contact in PRRS virus transmission, please see the section “Transmission between animals”.\nII. INDIRECT TRANSMISSION:\nAs detailed in the section, “Physical and chemical characteristics of PRRS virus”, the virus is fairly labile in the environment. It is important to point out that the virus does not persist in the environment or survive on fomites under dry conditions, and that cold temperatures favour its survival.\nNevertheless, indirect transmission of PRRS virus has been demonstrated by several routes.\n- Insects and rodents: Experimentally, mechanical transmission of PRRS virus has been demonstrated via houseflies and mosquitoes. The virus can survive for a short period on the exterior surface of the insects and in the gastrointestinal tract being the main site of retention of the virus. Some authors suggest that they may be capable of transporting PRRS virus at least 2.4 km from an infected farm. Regarding rodents, all available data indicate that rats and mice are not a reservoir for the disease.\n- Personnel: Hands, coveralls, gloves, boots, etc. of personnel (own and external) can serve as mechanical vectors.\n- Fomites: A number of contaminated fomites can act as mechanical vectors. Examples include any farm supply, external equipment (from electricians, plumbers, carpenters, etc.), needles, etc. It is also worth mentioning the importance of transport vehicles. It has been demonstrated that pigs can be infected through contact with the interior of transport contaminated with PRRS virus. The best solution for eliminating the virus from transport vehicles is washing, disinfecting (peroxygens and glutaraldehyde-quaternary ammonium chloride combinations for two hours are highly effective) and drying.\nb. CONTACT WITH CONTAMINATED RESIDUES AND MEAT:\nIn lagoon effluents the virus can survive and can remain infectious for up to three or eight days at 20ºC and 4ºC respectively. Consequently, the recycling of lagoon water must be considered as a high risk practice. Also, PRRS virus can survive in water for more than one week. Therefore, it is very important to completely dry all surfaces (equipment, facilities, transport vehicles, etc.) after washing and disinfecting. In pig meat, PRRS virus can be detected for at least one week at 4ºC and for months under frozen conditions (-20ºC); uncooked pig meat should not be allowed into the farm.\nc. AIRBORN TRANSMISSION:\nSome authors have claimed that long distances (more than 3 or even 9 km) airborne spread of PRRS virus is possible. However, airborne transmission cannot always be demonstrated. In some cases, airborne transmission of PRRS virus cannot be detected in pigs sharing the same air space (in the same unit). In other cases, it has been demonstrated only for short distances (a few meters). In some countries, it has been estimated that over 1 kilometre beyond the initial outbreak, the probability of becoming infected through area spread is extremely low. In conclusion, in given conditions, methods of indirect transmission such as vectors seem to be more important than airborne spread.\nNevertheless, airborne transmission over short or long distances appears to be isolate specific (it is probably more common with type II strains) and, among other factors, depends on meteorological conditions.\nRisk factors for airborne transmission. Risk increases depending on:\n- Strain: related to virulence, more common with type II.\n- Orography: flat.\n- Proximity to infected farms actively shedding virus via aerosols.\n- Winds: directional winds from infected to uninfected farm of low velocity with intermittent gusts.\n- Temperature: cold temperatures (<5 ºC) increase risk more than warm temperatures.\n- Relative humidity: high relative humidity (>75 %) increases risk more than low relative humidity.\n© Laboratorios Hipra, S.A. All Rights Reserved.\nNo part of this website or any of its contents may be reproduced, copied, modified or adapted, without the prior written consent of HIPRA."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:adc4c265-5c28-4418-bf2c-d18ed9fc8723>","<urn:uuid:1b76aace-2e88-4b9f-8af3-160d0faa197e>"],"error":null}
{"question":"What are the key differences between meteorite classification systems and death risk statistics for space object impacts?","answer":"Meteorite classification systems, as exemplified by the mesosiderite categorization, use detailed compositional and textural criteria, such as the four metamorphic categories (0-3) and groups (A, B, C) based on mineral content like plagioclase abundance. In contrast, death risk statistics for space object impacts are categorized by frequency and severity - ranging from frequent small meteorite falls (causing rare fatalities like the 2016 Tamil Nadu incident) to rare large asteroid impacts (1 in 20,000 death risk for 2 km asteroids). The classification system focuses on scientific characteristics of recovered specimens, while impact risk statistics emphasize practical human safety implications, with asteroid impacts being comparable to electrocution risk but more dangerous than death by fireworks or botulism.","context":["Eleven conjoint fragments with a combined weight of 321 g were found in Western Sahara and subsequently purchased by J. Sinclair and J. D. Cline at the 2019 Tucson Gem and Mineral Show. A type sample was sent to the Appalachian State University in Boone, North Carolina (A. Love) for analysis and classification, and NWA 12860 was determined to be a rare group C3 mesosiderite.\nThe meteorite is a breccia with a modal composition of 26% FeNi-metal, ~58% orthopyroxene, 4% plagioclase, and 1% olivine, along with accessory troilite, chromite, and apatite. Based on the silicate abundances of 93 vol% orthopyroxene and 6 vol% plagioclase, this mesosiderite is consistent with class C. In addition, the recrystallized textures indicate metamorphic stage 3. The meteorite exhibits a low degree of shock and terrestrial weathering.\nBased on the metamorphic textures of the matrix silicates, a scheme was developed (Powell, 1971; Floran, 1978) which assigned the mesosiderite group members into one of four textural categories; 1) minimally recrystallized, 2) moderately recrystallized, 3) highly recrystallized, or 4) intergranular melt rock. However, clear differences in bulk composition among these four categories prompted a reinterpretation of this scheme (Hewins, 1984). Additional discrimination criteria for primitiveness were investigated by Sugiura et al. (2013). They determined that NWA 1878 was more primitive than other mesosiderites in category 1, so it was designated the first metamorphic type 0.\nHewins proposed a further division for the least metamorphosed, at that time category 1, based on plagioclase abundance: a higher abundance for group A1 (24%) compared to a lower abundance for group B1 (21%). A further division of the more highly metamorphosed categories 2 and 3 was based on whether plagioclase or orthopyroxene matrix predominates (groups A2/A3 and B2/B3, respectively). The more basaltic, plagioclase-rich members of class A are enriched in an anorthitic, cumulate eucrite-like component, while the more ultramafic, orthopyroxene-rich members of class B are enriched in a diogenite-like component. The more plagioclase-rich compositional class A contains a larger diopside component and has a lower Mg# than the orthopyroxene-rich compositional class B.\nThrough other studies it was determined that the Ir/Ni ratios (or better still, a plot of Ir/Ni vs. Au/Ni) for matrix metal of mesosiderites is diagnostic for membership in group A or B, reflecting values of 0.000036 or 0.000051, respectively (Wasson and Rubin, 1985). According to Kong et al. (2008), group B may have assimilated a higher proportion of solidified, weakly fractionated (higher Ir, lower Ni and Au) metal compared to group A. Furthermore, the concentrations of Ga and Ge are lower in the metal of category 1 mesosiderites than in metal of more highly metamorphosed mesosiderites (Wasson et al., 1974). This is believed to have occurred as a result of reduction from silicates to metal during metamorphism.\nHewins reinterpreted the metamorphic orthopyroxene-rich groups B2 and B3 as having some melt-rock textures and assigned them to a new igneous group B4, reassigning the previous members of group 4 to A4. However, this reinterpretation has left groups B2 and B3 unrepresented. More recently, Hewins established a group C2 to accommodate the granular texture and very low plagioclase content (05%) of certain paired Antarctic orthopyroxinitic mesosiderites. However, the subsequent identification of igneous clasts in these mesosiderites led to their reassignment to group B4. For a more in-depth treatment, see R. Hewins, Meteoritics, vol. 23 (1988).\nWang and Hsu (2019) used PbPb chronometry to date 53 merrillite crystals associated with FeNi-metal in the Youxi mesosiderite. Based on the low REE abundances in the Youxi merrillite compared to that in eucrites, they contend that it was formed by oxidation of P in metal during the metalsilicate mixing event rather than during magmatic activity. They derived an age of 3.950 (±0.080) b.y. which they consider represents the timing of merrillite development during the mesosiderite-forming event. An equally plausible timing for the metalsilicate mixing event was ascertained by Haba et al. (2019) using high-precision UPb dating of zircons in several mesosiderites. Based on these results they contend that the metalsilicate mixing event occurred 4.52539 (±0.00085) b.y. ago. They propose a scenario in which a hit-and-run collision disrupted the northern hemisphere of Vesta leading to ejecta debris reaccreting to the opposite, southern hemisphere (see schematic diagram below). The deeply buried mesosiderite meteorites were ejected into Earth-crossing orbits by later impacts.\nDiagram credit: Haba et al., Nature Geoscience, vol. 12, #2, p. 512, (2019)\n'Mesosiderite formation on asteroid 4 Vesta by a hit-and-run collision'\nAlthough more than 250 mesosiderites are listed in the Meteoritical Bulletin Database, most have not been subjected to in-depth analyses in order to establish a specific geochemical group and metamorphic type. Notably, NWA 12860 is the second mesosiderite to be classified as group C3 after NWA 12566 (2,900 g) was approved in April 2019. The main masses of NWA 12860 are curated at the Pisgah Astronomical Research Institute in North Carolina. The photo of NWA 12860 shown above is a 3.18 g slice. The top photo below shows one of the larger fragments of NWA 12860, while the bottom photo shows an excellent petrographic thin section micrograph; both are presented courtesy of Anthony Love.\nNWA 12860 105.64 g Fragment\nclick on photo for a magnified view\nThin Section Overview Photo in Plain Light\nclick on photo for a magnified view\nPhotos courtesy of Anthony LoveAppalachian State University, Dept. of Geological and Environmental Sciences","From Bernie Bell\nBy Steve Drury\nIn 1994 Clark Chapman of the Planetary Science Institute in Arizona and David Morrison of NASA’s Ames Research Center in California published a paper that examined the statistical hazard of death by unnatural causes in the United States (Chapman, C. & Morrison, D. Impacts on the Earth by asteroids and comets: assessing the hazard. Nature, v. 367, p. 33–40; DOI:10.1038/367033a0). Specifically, they tried to place the risk of an individual being killed by a large asteroid (~2 km across) hitting the Earth in the context of more familiar unwelcome causes. Based on the then available data about near-Earth objects – those whose orbits around the Sun cross that of the Earth – they assessed the chances as ranging between 1 in 3,000 and 1 in 250,000; a chance of 1 in 20,000 being the most likely. The results from their complex calculations turned out to be pretty scary, though not as bad as dying in a car wreck, being murdered, burnt to death or accidentally shot. Asteroid-risk is about the same as electrocution, at the higher-risk end, but significantly higher than many other causes with which the American public are, unfortunately, familiar: air crash; flood; tornado and snake bite. The lowest asteroid-risk (1 in 250 thousand) is greater than death from fireworks, botulism or trichloroethylene in drinking water; the last being 1 in 10 million.\nChapman and Morrison cautioned against mass panic on a greater scale than Orson Welles’s 1938 CBS radio production of H.G. Wells’s War of the Worlds allegedly resulted in. Asteroid and comet impacts are events likely to kill between 5,000 and several hundred million people each time they happen but they occur infrequently. Catastrophes at the low end, such as the 1908 Tunguska air burst over an uninhabited area in Siberia, are likely to happen once in a thousand years. At the high end, mass extinction impacts may occur once every hundred million years. As might be said by an Australian, ‘No worries, mate’! But you never know…\nHow about ordinary meteorites that come in their thousands, especially when the Earth’s orbit takes it through the former paths taken by disintegrating comets? When I was a kid rumours spread that a motor cyclist had a narrow escape on the flatlands around Kingston-upon-Hull in East Yorkshire, when a meteorite landed in his sidecar: probably apocryphal. But Michelle Knapp of Peeskill, New York, USA had a job for the body shop when a 12 kg extraterrestrial object hit her Chevrolet Malibu, while it was parked in the driveway. In 1954, Ann Hodges of Sylacauga, Alabama was less fortunate during an afternoon nap on her sofa, when a 4 kg chondritic meteorite crashed through her house roof, hit a radiogram and bounced to smash into her upper thigh, badly bruising her. For an object that probably entered the atmosphere at about 15 km s-1, that was indeed a piece of good luck resulting from air’s viscous drag, the roof impact and energy lost to her radiogram. The offending projectile became a doorstop in the Hodge residence, before the family kindly donated it to the Alabama Museum of Natural History. Another fragment of the same meteorite, found in a field a few kilometres away, fetched US$ 728 per gram at Christie’s auction house in 2017. Perhaps the most unlucky man of the 21st century was an Indian bus driver who was killed by debris ejected when a meteorite struck the dirt track on which he was driving in Tamil Nadu in 2016 – three passengers were also injured. Even that is disputed, some claiming that the cause was an explosive device.\nIf you would like to read more of Steve’s blogs …………… https://earthlogs.org/"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:294d3c0d-f536-4950-a765-917e4fd70fb6>","<urn:uuid:5afeea9f-a1ad-4cad-bc40-943c554ef264>"],"error":null}
{"question":"How do professional butchers and home cooks differ in their approach to preparing lamb, particularly regarding technique and timing?","answer":"Professional butchers, like those at Donald Russell butchery, handle lamb with precise techniques, hanging it for up to 10 days for maximum flavor and using specialized tools and chainmail gloves for cutting. In contrast, home cooking approaches, as shown in the Shepherd's Pie recipe, focus more on the preparation and cooking methods, such as slow-cooking the lamb for 8 hours and shredding it by hand. Professional butchers demonstrate speed and precision in their cuts, while home cooking emphasizes careful preparation and extended cooking times to achieve desired results.","context":["OK, let’s face it, making this Shepherd’s Pie is a mammoth undertaking. I made it for a formal dinner party for friends a few months ago. The effort was worth it. Rich, meaty confited lamb with flavour packed duchesse potatoes, red wine and rosemary. What’s not to like?\nIngredients for 6:\nFor the lamb\n- A whole shoulder of lamb, weighing approximately 3kg\n- 1 bottle of dry white wine\n- 1 bulb of garlic\n- 3 sprigs of rosemary\nFor the duchesse potato\n- 1.2 kgs of potatoes, peel and cube.\n- 125g unsalted butter, at room temperature\n- 4 egg yolks\n- 120g grated parmesan\nFor the sauce\n- The reserved pan juices from the lamb\n- Olive oil\n- 1 tablespoon redcurrant jelly\n- 1 shallot, chopped\n- 1 glove of garlic, well crushed\n- 1 teaspoon of roughly crushed rosemary leaves\n- 150 ml of lamb stock (use a very good beef stock if you have no lamb stock)\n- 150 ml good full bodied red wine\n- Unsalted butter, to finish\nFor the herb oil\n- 50 ml groundnut oil\n- 50 ml olive oil\n- ¼ teaspoon of sugar\n- ½ teaspoon of rice wine vinegar\n- 1 tablespoon of finely chopped fresh mint\n- 1 tablespoon of finely chopped fresh dill\n- 1 tablespoon of finely chopped fresh chives\nNow on the day before, put the apron on and start by …\n- First making the herb oil. Blitz all of the ingredients together in processor until the herbs are as fine as possible. Pour into a bowl or jug, cover with clingfilm and refrigerate to allow the flavours to develop,\n- Preheat the oven to 160 degrees Celsius.\n- Place the shoulder of lamb into a large roasting tin, cut the bulb of garlic in half and along with the rosemary and some seasoning, add to the lamb.\n- Add the bottle of white wine to the roasting tin.\n- Wrap the entire roasting tin with several layers of tin foil.\n- Put the lamb into the oven and cook for 8 hours (I usually cook this overnight).\nOn the day …\n- Remove the lamb from the oven and take the shoulder out of the tin.\n- Strain the remaining pan juices and set aside for later.\n- One the lamb is cooled, shred the meat from the bones, removing the garlic, rosemary and any sinew and fat.\n- Place the shredded lamb meat onto clingfilm and roll into a sausage shape – about 5 inches in diameter, allow to cool fully and then place into the fridge to set.\n- To make the duchesse potatoes – place the potatoes into cold, well salted water. Bring to the boil and then simmer until tender.\n- Drain and reserve a little of the water.\n- Into a large bowl, add the cubed butter and parmesan.\n- Push the drained potatoes through a potato ricer into the bowl of butter and parmesan.\n- Stir the potatoes well and make sure all of the butter and parmesan is well mixed.\n- Beat the egg yolks and stir rapidly into the potato mix.\n- If the mixture is too heavy to stir, add a very small amount of the water that you reserved when you drained the potatoes.\n- Set aside to chill.\nConstruct your shepherd’s pies ….\n- Preheat the oven to 180 degrees Celsius.\n- Remove the chilled confit lamb shoulder from the fridge. Cut into 2 inch slices and remove the cling film. Place on a baking sheet.\n- Fill a piping bag with the duchess potato mixture and pipe onto the top of each slice of lamb confit.\n- Brush with melted butter and place into the oven. Cook for 20 minutes, until the confit is warm and the potatoes are golden.\n- Whilst the lamb is cooking, make your sauce:\n- Heat olive oil in a sauté pan and gently free the shallot, garlic and rosemary for a few minutes, until soft.\n- Add the red wine, cook on a high heat to reduce by half.\n- Once reduced, add the pan juices and stock. Reduce by half.\n- Pass the sauce through a fine sieve to remove the shallot, garlic and rosemary.\n- Finish in a small pan by adding the redcurrant jelly, stir until melted. Add a few cubes of chilled butter to enrich the sauce and add a glossy shiny finish.\nAssemble the dish ….\n- Add your red wine sauce to a warmed plate.\n- Place the shepherd’s pie in the centre of the sauce.\n- Add a few drops of herb oil around the edge of the plate.\n- Serve immediately. I like to serve this with a side dish of griddled asparagus, steamed courgettes and petit pois.\nTuck in and enjoy!","Meat-eaters know how great it tastes on a plate, but how many of us know our way around a cow or a lamb? Diana Pilkington gets to know the cuts during a crash course in butchery, and picks up some tips from real-life butcher (and one half of TV's Fabulous Baker Brothers) Henry Herbert. Plus, some tasty meat recipes.\nBy Diana Pilkington\nYou don't expect to walk into your local butcher's shop and see a glamorous TV star behind the counter.\nBut Henry Herbert, one half of Channel 4's Fabulous Baker Brothers, is juggling his TV career with running family business Hobbs House Butchery in Chipping Sodbury, Gloucestershire.\nAnd he has seen such a rise in people who want to learn some basic butchery skills that he's in the process of opening a school to teach them.\n\"There's a thirst for people wanting to learn how to do it themselves,\" he says.\n\"They might not do it every time, but understanding the skill behind it helps you appreciate what the trade involves. It's like when people want to do a bit of DIY at home but won't necessarily do the whole house.\n\"If you cook a leg of lamb that you had boned out yourself, there's kudos in that.\"\nThere can also be financial benefits to getting handy with a knife at home.\nHerbert says: \"A small chicken is about £5. It's about the same price as two skinless chicken breasts, but there's quite a big difference in size.\n\"It's so quick to learn how to chop that chicken up and get two breasts, two legs, wings and a carcass to make a soup, so suddenly you've gone from two meals to five meals. I could teach someone that in five minutes and they've got that for life.\"\nEven if home butchery is not your thing, the star is supporting a campaign to encourage people to use their local butcher and tap into their expert knowledge about which cuts to buy and how to use them.\nAfter all, trained chef Herbert took over his family butcher's in the first place to help keep the trade alive when the shop became vacant.\nThe number of butcher shops in Britain has declined sharply since the Seventies, dropping from 25,300 in 1977 to just 6,811 in 2006. However, according to Eblex, which represents the English beef and sheep industry, the drop in numbers is tailing off and there are around 6,600 today.\n\"I felt it was a real shame to see another butcher shop that had been trading for 150 years close down and become a card shop or a charity shop,\" he says.\n\"I thought even if I can breathe some new life into it and help inspire someone at least I've done something rather than watch it shut down.\"\nA butcher's at how it's done\nI admit it, I love red meat. But I don't think I'm alone in being a bit clueless about how a juicy sirloin steak or comforting Sunday roast correspond to the animals they start out as.\nWith this in mind, I take a trip to the Donald Russell butchery in Aberdeenshire, proud holder of a Royal Warrant, for a tour of the premises and a crash course in butchery skills.\nLed by the aptly-named Steve Lamb, I wander through the ice-cold maturation room, where hundreds of headless carcasses hang side by side. Beef is typically hung for around 28 days to give it maximum flavour, and lamb, which I learn is anatomically very similar to a cow, is hung for up to 10 days.\nThroughout the factory are a staggering number of white-coated people hard at work, some carefully weighing and portioning the steaks, others chucking meat into a mincer, lining pastry with sausage meat or packing up the cuts.\nThey all carry out their tasks with impressive speed and precision. And then it's my turn.\nIn the demonstration room, I watch as butcher Dave Bergin uses a saw and various knives to break down the 'roasting' (a side of beef) into the four main cuts of rib, sirloin, fillet and rump.\nIt is quite a transformation, and what starts out as a generous, multi-coloured bit of fillet, for example, is trimmed down into a sleek piece of pure red meat that resembles a fish to look at.\nNext is the fun part. With my left hand encased in a chainmail glove, I have a go at cutting these newly-butchered slabs into steaks. It's satisfying to sink the knife in, but my task - to chop them to an optimum 220 grams - is not easy, and I keep missing the mark. Fellow butcher Andy Grant, on the other hand, gets it right every time.\nThere's also a baffling array of words to come to terms with. As well as the familiar steaks, I hear terms like \"pave\", \"picanha\" and \"tafelspitz\" bandied about. More confusingly, some are different words for the same thing, but the butchers navigate the language with ease.\nDespite a growing interest from the public in butchery, the team at Donald Russell tell me that they have struggled to find young apprentices to go into the trade.\n\"Nobody wants to get up at 4.30am to come to a cold factory and cut up steaks,\" admits Grant, who has done the job for 20 years. \"But it's given me a good life. It's a job I feel passionate about and I enjoy it.\" Impressed as I am by his skills though, I think I'll leave him to it.\nHere are some meaty recipes for you to try at home.\nSlow-cooked beef with gnocchi\n450g lean boneless shin or chuck steak, cut into 2.5cm cubes\nSalt and freshly milled black pepper\n½tsp cayenne pepper\n2tbsp sunflower oil\n1 large onion, peeled and chopped\n2 large garlic cloves, peeled and finely chopped or crushed\n2 x 400g cans chopped tomatoes\n200ml good, hot vegetable stock\n1 cinnamon stick, halved\n1tbsp light brown sugar\n1tbsp tomato puree\n1 x 400g pack fresh gnocchi\n2tbsp freshly chopped flat-leaf parsley, to garnish\nPlace the beef in a large plastic food bag. Add the seasoning, cayenne and paprika; seal, shake well to coat the beef in the spices.\nHeat the oil in a large non-stick frying pan. Cook the beef for 4-5 minutes in batches until brown on all sides. Transfer to a 1.7l/3pint heatproof casserole pot.\nIn the same frying pan, cook the onion and garlic for 2-3 minutes. Spoon into the casserole pot.\nAdd the tomatoes and stock, cinnamon, sugar and tomato puree. Bring this to the boil, reduce the heat, cover and simmer for 2-2½ hours.\nAdd the gnocchi 10 minutes before the end of the cooking time.\nGarnish with the parsley and serve with crusty bread.\nTip: If preferred, substitute the gnocchi for freshly cooked pasta shapes.\n:: Recipe from www.simplybeefandlamb.com\nSlow-cooked Shoulder of lamb\n1 whole shoulder of lamb (1.75kg)\nSalt and pepper\n2tsp olive oil\n1 onion (chopped)\n4 cloves of garlic (sliced)\n2 sprigs fresh rosemary\n6 sprigs fresh or dried lavender\n5 tomatoes (cut into wedges)\n125ml white wine\n250ml chicken or beef stock\nAllow the meat to come to room temperature. Preheat the oven to 140°C/285°F/Gas 1. Season the lamb shoulder with salt and pepper.\nPreheat a large, flame-proof braising pan. Add oil and butter and brown the meat on all sides until nicely caramelized. Remove the meat from the pan and leave to the side. Add mushrooms, onions and garlic and braise for 5-8 minutes. Return the meat to the pan. Add all the remaining ingredients to the pan and bring to the boil. Cover with the lid and place into the oven and cook for 2½ - 3 hours. After 2½ hours test the meat. It should be tender and sticky.\nWhen the meat is tender remove the pan from oven. Place the lamb on a warm serving platter and allow to rest for up to 20 minutes. Remove the remaining pan ingredients and arrange around the meat for a nice presentation. Use the delicious juices to make a gravy.\nTo serve carve the meat straight from the bone and arrange on preheated plates. Serve with green beans and potato gratin.\n:: Recipe from Donald Russell (www.donaldrussell.com)\nSpiced rib of beef with red wine gravy\nRare: 20 minutes per 450g/1lb plus 20 minutes\nMedium: 25 minutes per 450g/1lb plus 25 minutes\nWell done: 30 minutes per 450g/1lb plus 30 minutes\n1 x 2.7kg lean boneless rib of beef, sirloin or traditional rump roast\nSalt and freshly milled black pepper\n2tsp ground allspice\n2tsp ground mace\n1tsp ground nutmeg\n40g light soft brown sugar\nFor the red wine gravy:\n1tbsp plain flour\n300ml good, hot beef stock\n300ml good red wine\nPreheat the oven to 180-190°C.\nIn a small bowl mix the spices and sugar together. Place the joint on a chopping board; make several slashes over the surface of the joint, taking care not to cut the butcher's string or elasticated meat bands and season. Coat on both sides with the spice mixture. Place the joint on a rack in a roasting tin and open roast for the preferred, calculated cooking time. Cover with foil if browning too quickly.\nTen minutes before the end of the cooking time, remove the joint from the oven and brush with the port. Return to the oven for the remainder of the cooking time.\nRemove the beef from the oven, cover and leave to rest for 15-20 minutes. Meanwhile, to make the gravy; spoon off any excess fat from the roasting tin and discard. Place the tin over a medium heat and sprinkle with the flour. Stir well with a small whisk or spoon, add a little stock and stir again, scraping the base of the pan to release any rich, beefy sediment.\nAdd the remaining stock, wine and any meat juices from the platter. Adjust the seasoning, if required and simmer for 8-10 minutes, stirring occasionally or until reduced to a well-flavoured gravy. Strain before serving.\nGarnish the beef with fresh rosemary leaves and serve with seasonal vegetables and the gravy.\n:: Recipe from www.simplybeefandlamb.com\n:: For more information on Donald Russell, visit www.donaldrussell.com\n:: Henry Herbert is an ambassador for the Quality Standard Beef & Lamb Master Butchery campaign, helping people get the most from their butcher. For more information, or to find out about master butchery classes, visit www.simplybeefandlamb.co.uk/quality-standard"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:8edc74a2-ca6e-49e9-8216-8a756cd07f19>","<urn:uuid:f2af6704-05ab-4233-ad81-2b400aa3c182>"],"error":null}
{"question":"How have both the Conversion of St Paul painting and the Church of Sant'Agostino evolved in their artistic features over time, and what historical transformations have they undergone?","answer":"The Conversion of St Paul painting represented a transformative moment in Caravaggio's artistic development, where he departed from traditional depictions by showing the scene as a witness might have seen it, without heavenly realms or battalions of angels. He introduced his signature style of dramatic light and darkness that would define his later work. The Church of Sant'Agostino has undergone numerous transformations over centuries. Initially built between 1296 and 1446, it was rebuilt on a larger scale during Sixtus IV's pontificate. The church has seen renovations approximately every hundred years since the 16th century, including additions by famous artists like Bernini's high altar design in 1627, Borromini's floor plan in 1661-1662, and Vanvitelli's dome restoration in the 18th century. The most recent renovation was carried out in 1998-2000 by Rome's architectural and artistic heritage authorities.","context":["“The Conversion of St Paul”, Caravaggio, 1602, Santa Maria Del Popolo, Rome. The scenes from the life of St Matthew in Rome’s San Luigi Francesi made Caravaggio famous. He was about 27. Within months, the very eminent Tiberio Cerasi, Treasuer General under Clement VIII, commissioned him to paint St Paul’s conversion and St Peter’s crucifixion for the side walls of the chapel in th“e Augustinian Church of Santa Maria del Popolo for which he had acquired burial rights. In the contract, Caravaggio is referred to as “egregius in Urbe pictor”, in order words, as the most best painter in Rome. The choice of two key scenes from the lives of St Peter and St Paul was hardly a surprising for a Roman side-chapel. This Church, located just inside the northern gate of the city was the first that pilgrims entered on their arrival. But it was unusual to put these two scenes together. The precedent was the two frescoes in the Vatican’s Capella Paolina, painted by Michelangelo for Paul III in 1545. Caravaggio and Cerasi knew that comparisons would be made. But just as St Paul’s conversion was the defining moment of his life, one could argue that these two works mark a similar point in Caravaggio’s development as an artist. Like most artists, Caravaggio would draw on elements seen in the works of others, but in this commission he did something entirely new. In the account of the conversion in the Acts of the Apostles there is the journey, the blinding light, the fall to the ground and the voice saying: “Saul, Saul, why do you persecute me?” Companions are mentioned too. They stand “speechless, hearing the voice but seeing no one” (Acts 9:8). Of course, artists had embellished this rather bare story. Michelangelo’s fresco shows Paul’s companions as a company of soldiers on horseback and Christ descends from the sky surrounded by a battalion of angels in a manner not unlike that of his final judgement in the Sistine Chapel. But Caravaggio simply paints what you might have seen if you were there. He does not attempt to show heavenly realms. He keeps the horse and the mysterious light and lays St Paul flat on his back. To modern eyes the saint is like someone on stage, lit only by a spotlight. But notice that unlike on a stage set, there is no distance between St Paul and the viewer. In the rather small Cerasi Chapel the prone body of St Paul is directly in front of your eyes. The horse is just above you. By showing the horse at an angle he provides a sense of depth in what would otherwise be flat darkness and gives credibility to the extremely foreshortened body of St Paul. The effect is astonishing in that the viewer cannot but identify with saint. Standing in the chapel, the viewer might even raise his or her arms to embrace the same light falling around St Paul. In earlier versions, the horses were war horses and the whole cohort were dressed as soldiers. Here St Paul is an ordinary young Roman soldier. The horse is a beast of burden, which would have been so common on the streets of any town or village and a reminder of home to the pilgrim. There is no saddle, so nothing suggests that St Paul was actually on the horse when he fell. The horse and handler may just be fellow travellers on the same road. I have never handled a horse but I grew up in an area where horse training was big business. One of the things, you notice as you wait to let the handler get the high strung race horse into a gate so that you can pass pass is the bond between the horse and its handler. This is no race horse but you can see this same intimate bond. Neither horse nor handler understand what is happening but they do understand each other. The horse’s hoof is raised so as not to injure the saint; a detail which speaks of the gentle nature of the animal, but also tells us that St Paul has fallen only moments before. The animal will soon move so as to stand on all fours. Modelled in bright colours, the drama emerges from the dark background. Perhaps the most remarkable and novel element is the fall of bright light into a darkened space. This play of light and darkness was to dominate in the rest of Caravaggio’s art. Like a single spotlight on a dark stage, it directs our focus, but for Caravaggio it does far more. His contemporaries did not have our wave theory of light. They took the phenomenon of light to be both natural and divine. In literature and scripture light stood for what we can know: darkness for what we cannot know. From a religious point of view, the interplay of darkness and light evokes thoughts of sin and grace. And since antiquity light was strongly associated with divinity. But Caravaggio’s theatrical lighting also conveys the self-revelation of a God who both incarnate and transcendent, and always beyond our capacity to know him fully. The disjunction and continuity between what we can see and feel here and now, and what we believe we shall see is at the heart of Caravaggio’s art and is central to the life of faith we now live. As St Paul himself says: “For now we see in a mirror dimly, but then face to face” ( 1 Cor 13:8). The Feast of the Conversion of St Paul is on this coming Saturday.\nThe Catholic Chaplaincy serves the students and staff of the University of Edinburgh, Edinburgh Napier University and Queen Margaret University.\nThe Catholic Chaplaincy is also a parish of the Archdiocese of St Andrews and Edinburgh (the Parish of St Albert the Great) and all Catholic students and staff are automatically members of this parish.","The Church of Saint Augustine (Sant’Agostino in Italian) is conducted by the Augustinian Order, and contains the tomb of Saint Monica, Augustine's mother. Its various architects and contributing artists are among the most famous names in Italian history during the Middle Ages.\nFrom about the year 1250, the first Augustinian church and monastery (convento) in Rome was at Santa Maria del Popolo. These were located near the Porta del Popolo, the gate in the Roman wall which opened on to the famous road to Rome that was called the Flaminian Way. This was the edge of the City of Rome. The members of the Order, however, desired to have their main house to be nearer to where the Pope and the general administration of the Church were located.\nThis became more possible in 1286, when the Roman nobleman Egidio Lufredi donated some houses in the area of the Field of Mars to the Order of Saint Augustine. They immediately sought to erect a church and a priory (convento) on the site. In a document dated on 20th February 1287, however, Pope Honorius IV (1285-1287) granted them permission to build a convento only. He did not consent to the building of a church on the land in question because it was adjacent to the church of Saint Tryphon in the Via della Scrofa. Instead, the Pope simply entrusted the Church of Saint Tryphon to the Augustinians. The small Church of Saint Tryphon had several relics. Into it the tomb of Saint Monica, the mother of Augustine, was transferred in 1430 from the Augustinian church in Ostia, the town of her death.\nThe Church of Saint Tryphon was a titular church, i.e., symbolically assigned to a person appointed a bishop who had not been assigned a diocese to lead. The privilege of being a titular church was passed on the Church of Sant'Agostino when that church was built. The older Church of Saint Tryphon was kept as an annex to the Church of Sant’Agostino until finally demolished in 1736. The Augustinians were not totally pleased with the decision of Pope Honorious that denied them the opportunity to build a church. The Pope died, however, on 3rd April 1287. This was only eleven days after he had signed the document for the Augustinians. A change came about nine years later, thanks to Pope Boniface VIII (1294-1303), who was a great friend of the Order. With his consent, on 15th April 1296 the Augustinians lay the first stone of a new church, dedicated to Saint Augustine, on the site where the Church of Saint Augustine Church (Chiesa di Sant'Agostino) stands today. Bishop Gerard of Sabina ceremonially placed the foundation stone. Construction was to last nearly one and a half centuries. It was not completed until 1446, when it finally became possible to celebrate liturgical functions in it.\nThe church was rebuilt on a larger scale in the same century, during the pontificate of Sixtus IV (Pope in 1471-1484). Much of the funds for this construction (i.e., the present church) came from the second Cardinal Protector of the Order of Saint Augustine, William Estouteville, who in his own right was a wealthy man and a blood relative of the French royal family. The design was entrusted to the architects Giacomo (or Jàcopo) di Pietrasanta and Sebastiano Fiorentino. In 1468 the former had executed the restoration of the bridge at the Castel Sant'Angelo, which is still a landmark in Rome. Another architect whose name has been linked to the project is Bacco Pontelli (1450 - 1492), who for Pope Sixtus IV designed the Sistine Chapel (1475 - 1481). Associating Pontelli with Sant'Agostino is uncertain, but he definitely worked on the major renovations of the Augustinian Church of Santa Maria del Popolo in Rome at the direction of Pope Sixtus IV between 1472 and 1479. The design was inspired by the early Renaissance style of \"Santo Spirito,\" (Church of the Holy Spirit) in Florence, designed by Filipo Brunelleschi (1337-1446). Santo Spirito in Florence has been administered by the Augustinians right to the present day.\nConstruction began in 1479, and was finished in 1483 - the year that Cardinal d'Estouteville died. The present orientation of the church on to the Piazza Sant’Agostino was arranged by the Cardinal, who was also the head of the Street Authority, which was the 'planning authority' of Rome. The church was also near the now demolished Palazzo Apollinare, where the Cardinal lived. In funding this church, Estouteville left a lasting monument to himself. It is the finest example of early Renaissance church architecture in Rome. The Renaissance façade, one of the first in this style, is built in travertine stone that is said to have come from the ruins of the Colosseum. The huge lettering on the façade reads: GUILLERMUS DE ESTOUTEVILLA EPISCO.OSTIEN.CARD.ROTHOMAGEN.S.R.E. CAMERARIUS FECIT MCCCCLXXXIII. It states that \"William d'Estouteville, Bishop of Ostia, Cardinal of Rouen, Camerlengo, built this in 1483.\" Above the central door is a painting, The Handing Over of the Augustinian Rule. It was added a later date and, exposed to the weather, it has been damaged by the passage of time. In order for the Augustinians to have proper administrative facilities, the Convent of Sant’Agostino - beside the Chiesa di Sant'Agostino - was expanded. This convento served as General Curia (international headquarters) of the Order.\nIn 1482 more than 100,000 ducats was still needed for the completion of both projects. At the Augustinian General Chapter at Padua in 1482, the Order pleaded for the continued assistance of Cardinal William Estouteville, but his death on 27th January 1483 left the Order with a debt that imposed a severe financial strain. It should be noted that for 140 years during the 15th and 16th centuries there were three Augustinian church venues in Rome, i.e., Santa Maria del Popolo, Sant’Agostino and on the Quirinal Hill the Church of Santa Susanna. The latter was under Augustinian administration from 1448 to 1587 (see Augnet’s pages on Santa Susanna for details.)\nApproximately every hundred years from the 16th century to the present time, the Church of Sant'Agostino has been the object of renovation and further decoration. Early in the 16th century, one of the artists commissioned for the decoration of the church was the young, but already famous, Michelangelo Buonarroti. In the early 16th century, he started painting The Entombment (Burial) of Christ for the Church of Sant'Agostino. He never finished it, and this incomplete work is now in the National Gallery in London. The high altar of the church is the work of the famous sculptor, Gian Lorenzo Bernini (1598 - 1680). He designed it in 1627. It is decorated with a Byzantine icon of the Blessed Virgin, the Madonna of Saint Luke. The icon was moved here from the Hagia Sophia in Constantinople in 1453. The church also houses the famous painting, Madonna of the Pilgrims by Caravaggio (1573-1610), as seen at right. This painting disturbed some people in Rome because it depicted dirt on the feet of the people. For more details of this painting, go to http://www.wga.hu/frames-e.html?/html/c/caravagg/07/42loreto.html\nThe church also contains a fresco by Raphael. Two statues in particular represent Renaissance and Baroque styles: the Madonna del Parto (Mary of childbirth - photo on next page) by Jacopo Sansovino and Saint Thomas of Villanova by Melchiorre Caffà, one of the most talented pupils of Bernini. The statue by Sansovino is clearly inspired by classical models (such as a statue of Apollo) and it is framed in an altar similar to a triumphal arch. The statue of Thomas of Villanova and the poor by Melchiorre Caffà is a perfect example of the Baroque attempt to create a link between the fictitious world of art and real life. The floor plan (layout) as it is today is a result of the work done in 1661. It was drawn by Francesco Borromini (1599-1667) in 1661-1662. A noted Baroque architect, Borromini was esteemed almost as much as Bernini, alongside of whom he occasionally worked. http://en.wikipedia.org/wiki/Francesco_Borromini\nAdjacent to the church, the Convento de Sant’Agostino nearby was restored in the 18th century. (See next page.) The work was completed in 1756. By then, the dome and the cross-vault of the church were in a bad condition, and it was decided to undertake its restoration. Luigi Vanvitelli (1700-1773), who had successfully designed the façade for the Convento di Sant’Agostino, was commissioned to lead the work on the church. Luigi Vanvitelli (1700-1773) was the most famous Italian architect of his day. He had been commissioned as architect of Saint Peter’s Basilica in 1726, and did some consolidation and adjustments to its dome in 1750. In 1732 he had done the façade of the Church of Saint John Lateran, the official cathedral of Rome. Vanvitelli had previously been engaged by the Order of Saint Augustine. He was the architect chosen for the renovations after the thirteenth-century gothic Church of Sant’Agostino in Siena had been devastated by fire in 1747.\nHe was an excellent choice for the dome restoration of the Church of Saint Augustine in Rome. He altered the tower by lowering it, building a new bell chamber, and by adding its small drum and dome. Because in 1751 Vanvitelli had moved to Naples to design the Royal Palace at Caserta for the Bourbon, Charles III, the King of Naples, most of the actual work at Chiesa di Sant’Agostino in Rome was left to Carlo Murena. The church was closed while restorations were carried out, and was reopened in 1763. A new and more spacious sacristy was built at the same time, and the bell tower was altered. Another restoration was carried out under Pope Pius IX (1846-1878); it was completed in 1870. The floor was renewed, and the pillars were strengthened and encased in marble. Frescoes by Pierto Gagliardi were added in the nave, transept, choir and in the chapels.\nThe most recent work was carried out in 1998-2000 by the Soprintendenze di Roma per i Beni Ambientali ed Architettonici e per i Beni Artistici e Storici, the authority responsible for among other things the architectural and artistic patrimony of Rome. Artistic features include the work by Bernini and Caravaggio mentioned above, the chapel and tomb of Saint Monica (picture 2), and a statue of Mary, the Mother of Childbirth. (See picture above.) The most famous Augustinian saints are all represented by chapels and statues, including Nicholas of Tolentino, Thomas of Villanova, and Rita of Cascia.\nThis page has dealt with the Church of Saint Augustine. The next page introduces the former Convento (monastery) of Saint Augustine adjacent to the church.Photo GalleryFor the Augnet gallery on Sant'Agostino Church, Rome, click here.\nSant’Agostino. A comprehensive Wiki website. http://romanchurches.wikia.com/wiki/Sant'Agostino\nSeven images of Sant'Agostino, Rome. http://members.tripod.com/hckarlso/Rome5.html\nChiesa Sant’Agostino, Rome. Excellent description and photographs. Search carefully for Sant'Agostino. http://www.romeartlover.it/Vasi175.htm\nThe Pontificial Parish of St Anne in the Vatican. (Parish website written in Italian). This is NOT Sant'Agostino church. The parish of the Vatican is conducted by the Augustinians. This website contains an excellent photo gallery. http://www.pontificiaparrocchiasantanna.it\nMichaelangelo: The Entombment of Christ. Wikipedia. The painting mentioned in the text above. https://en.wikipedia.org/wiki/The_Entombment_(Michelangelo)"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:a6b1a83d-1abc-4313-8f71-6033febd264a>","<urn:uuid:eac6c192-52d9-41f6-9284-9aa459575a1e>"],"error":null}
{"question":"When comparing the hand manipulation capabilities of ASIMO and the MIT Cheetah 3, which robot demonstrates more sophisticated dexterity for precise tasks such as handling delicate objects?","answer":"ASIMO demonstrates more sophisticated dexterity with its highly functional compact multi-fingered hand, which includes tactile and force sensors in both the palm and fingers. This allows ASIMO to perform intricate tasks like opening water bottles, pouring liquid into paper cups without crushing them, and even making complex sign language expressions. The Cheetah 3, on the other hand, is not described as having any hand manipulation capabilities - it focuses on locomotion tasks such as walking, running, jumping, and maintaining balance through leg movements and algorithmic control.","context":["Robots are doing all kinds of remarkable things nowadays it seems: competing in skiing, therapeutically hugging humans, monitoring crops so that we don’t starve, and of course, performing crazy stunts. But what if these robots had to perform all these tasks without their ability to see, effectively operating “blind”?\nBuilding a “blind” but fully operational robot seems like a difficult (if not paradoxical) task to accomplish, but Massachusetts Institute of Technology engineers have managed to develop one that’s capable of walking, running, jumping, and continuing on-course even when shoved — all without relying on cameras or any external environmental sensors. Instead, the 90-pound Cheetah 3 uses what the MIT team is calling “blind locomotion,” which allows it to “feel” its way around:\nThe idea here is to create a robot that doesn’t need a camera and sensors to find its way around uncertain terrain — because as powerful as the technology can be, we know that computer vision can easily be fooled.\n“There are many unexpected behaviors the robot should be able to handle without relying too much on vision,” said MIT associate professor of mechanical engineering Sangbae Kim, one of the robot’s creators. “Vision can be noisy, slightly inaccurate, and sometimes not available, and if you rely too much on vision, your robot has to be very accurate in position and eventually will be slow. So we want the robot to rely more on tactile information. That way, it can handle unexpected obstacles while moving fast.”\nAlgorithms and Pronks\nThis third version of the Cheetah is a step up from its forerunner, displaying a greater range of motion that permits it to stretch forward and backward and twist from side to side, much like its big cat namesake. It’s also capable of walking on three legs instead of four, in addition to having a really cool move called a “pronk” — a bounding leap that is similar to that of a gazelle. All this enables the Cheetah 3 to handle different terrains such as stairs and curbs, as well as more uneven and potentially dangerous terrain that might be present in disaster zones.\nIn addition to these abilities, the bot is equipped with two new algorithms that help it to regain balance if it steps on debris or is unexpectedly pushed. The first is a contact detection algorithm, which helps its each one of its legs figure out when is the best moment to step on the ground, versus switching its movement to swing it in the air if it steps on something unanticipated — such as a surface randomly littered with rocks — helping it to keep it steady. Data gleaned a variety of sensors that track the positioning of the legs in space relative to its body, which is then computed to determine the probabilities of the leg touching down on the ground, the force created, and the chance that the leg will still be in the middle of its swinging motion. All this helps the Cheetah 3 decide how to best keep its balance as it moves without the benefit of sight, much like how we would if we had to walk across a darkened room.\n“When it comes to switching from the air to the ground, the switching has to be very well-done,” Kim explained. “This algorithm is really about, ‘When is a safe time to commit my footstep?’ If humans close our eyes and make a step, we have a mental model for where the ground might be, and can prepare for it. But we also rely on the feel of touch of the ground. We are sort of doing the same thing by combining multiple [sources of] information to determine the transition time.”\nThe model-predictive control algorithm works in conjunction with the contact detection algorithm by working out possible future positions for the body and each of the legs every 50 milliseconds. This offers the robot a chance to react quickly if it encounters an unfriendly shove and allows it to produce an appropriate counterforce — not too much, not too little, but enough so that it won’t fall down.\n“The contact detection algorithm will tell you, ‘this is the time to apply forces on the ground. But once you’re on the ground, now you need to calculate what kind of forces to apply so you can move the body in the right way. It’s thanks to that predictive control that can apply the right forces on the ground, combined with this contact transition algorithm that makes each contact very quick and secure.”\nBut the robot won’t be blind forever: the team aims to develop the Cheetah’s blind locomotion to the point that when it is ultimately combined with other cameras and sensors, it will be agile and sure of itself as it moves through hazardous situations.","While ASIMO may look more-or-less the same as he/she/it always has, the new model encompasses several advancements. For starters, ASIMO longer needs to be controlled by a human – it can walk about and do stuff all on its own, taking in its surroundings and making spatial decisions accordingly. Its new arm and hand mechanisms also allow it to perform delicate and intricate tasks like opening a bottle of water and pouring it into a paper cup without crushing it under the might of its own technological superiority.\nThe long and short of it is that ASIMO – now under the newly-formed Honda Robotics division – will soon be able to do everything a human can, only better. So start stocking the bomb shelter again. Or better yet, let ASIMO do that for you. You've had a long day.\nClick past the jump to let ASIMO pour you a drink and show off some of its newfound skills.\nHonda has unveiled an all-new ASIMO humanoid robot with a world-first technology allowing ASIMO to move without being controlled by an operator. With significantly improved intelligence and the physical ability to adapt to situations, ASIMO has taken another step closer to practical use in an office or public space.\nHonda has also introduced a new task-performing robot arm. This experimental model was developed while applying multi-joint and posture control technologies to ASIMO. This robot arm can be controlled remotely to perform tasks in places which are difficult for people to access.\nTo represent all of Honda's robotic technologies and products such as ASIMO, Honda has established the new collective name 'Honda Robotics'. Under this name Honda will continue the development and research of humanoid robots and will also focus on applying the robotic technologies to mass-produced products and putting them into practical use.\nThe all-new ASIMO has taken a step forward from being an \"automatic machine\" to an \"autonomous machine\". It now has the ability to make decisions based on its surroundings and the movements of people.\nAt the beginning of the development process, the following three factors were identified as necessary for a robot to perform as an autonomous machine:\nHigh level balancing ability - maintaining its posture by putting out its leg in an instant.\nExternal recognition capability - takes in information, such as the movements of people, from multiple sensors and predicts the changes that may take place.\nThe ability to generate autonomous behaviour - making predictions from gathered information and determine the next movement without being controlled by an operator.\nOnce these had been identified Honda went about developing the technologies required to make them possible.\nAdvanced intelligence capability\nHonda has developed a new system that is key for advanced intelligence. The new system continuously evaluates the input from multiple sensors, predicts the situation and then determines the behaviour of the robot. With this technology ASIMO is now capable of responding to the movement of people and the surrounding situations. For instance, ASIMO can now predict the direction a person will walk and quickly determine an alternative path to take if a collision is detected. This technology also enables ASIMO to recognise faces and voices.\nAdvanced physical ability\nThe combination of strengthened legs, an expanded range of leg movement and a newly developed control technology enables ASIMO to change landing positions mid-movement. This new agility also gives ASIMO the flexibility to adapt to changing situations so that it can walk on uneven surfaces.\nImproved task-performing ability\nHonda has developed a highly functional compact multi-fingered hand, which has a tactile sensor and a force sensor imbedded on the palm and in each finger. Combined with the object recognition technology, this multi-fingered hand enables the all-new ASIMO to perform tasks with dexterity, such as picking up a glass bottle and twisting off the cap, or holding a soft paper cup without squashing it. Moreover, ASIMO is now capable of making sign language expressions which require the complex movement of fingers.\nTask-performing robot arm\nTechnologies developed for ASIMO were applied to an experimental model of a task-performing robot arm. The robot arm moves on a self-propelled base and was designed with the idea of being utilised at disaster sites or other places too dangerous for people to work.\nThe stability control technology used for ASIMO's walking and running were applied to stabilise the end of the arm even on unstable surfaces. The application of other ASIMO technologies such as the multi-joint control technology that controls as many as 57 motors imbedded in the joints of the arms and legs, has enabled the robot arm to approach an object and perform necessary tasks even in a narrow space with unstable footing and many obstacles."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:da37668b-b17e-4922-8baf-63f8e8abd557>","<urn:uuid:53898931-f3c7-479a-ac09-8e8707732c0f>"],"error":null}
{"question":"Which causes more environmental damage: acid mine drainage or soil erosion from mining?","answer":"Both acid mine drainage (AMD) and soil erosion are significant environmental impacts of mining, but they have different effects. AMD is highly acidic (pH 2-4) and poses a long-term threat to water quality, contaminating groundwater and surface water through chemical processes. Soil erosion, on the other hand, leads to direct physical damage including land degradation, loss of biodiversity, and formation of sinkholes. Both issues can contribute to creating lifeless wastelands and threaten ecosystems, but have different mechanisms of environmental harm.","context":["Flotation in Acid Mine Drainage Control: Beneficiation of ConcentrateJan 11, 1996 . today for partial beneficiation of the concentrate but further development work is . produced in this Acid Mine Drainage (AMD) operation. Ben-.beneficiation of acid mine drainage,Management and mitigation of acid mine drainage in South . - HSRCDec 7, 2016 . Management and mitigation of acid mine drainage in South Africa: input for mineral beneficiation in Africa. OUTPUT TYPE: Monograph (Book)\nThis paper is focused on recovering residual sulfide minerals by flotation from the tailing of the Pyhäsalmi Cu-Zn mine in Finland. The tailing contains 4–8%.\nManagement and Mitigation of Acid Mine Drainage in South Africa. Input for Mineral Beneficiation in Africa. Munyaradzi Mujuru. Publication Year: 2016.\nThe use of the terms \"extraction,\" \"beneficiation,\" and \"mineral processing\" ... (AMD), acid drainage from mine waste rock, tailings, and mine structures such as.\nApr 15, 2005 . Both acid mine drainage and fly ash from coal burning power generation pose . Acid mine drainage (AMD) is highly acidic (pH 2-4), .. high capacity inorganic ion exchange material useful for water beneficiation, 2003.\nCurrent RCRA Status of Extraction and Beneficiation Wastes . . . . . . . . . . . . . . . . . . . . . . 45 ... effective management of acid mine drainage is a challenge at many.\nJul 10, 2015 . Beneficiation follows extraction and involves working the ore into a more . *Although acid mine drainage/acid rock drainage caused by coal.\nDuring mining and beneficiation (initial processing) the most visible effects are . Location and population density are important: acid-mine drainage that enters.\nof coal mined than underground mines of simi- lar capacity. . cessed in a beneficiation/washing plant to re- . eration of acid mine drainage (AMD) is a major.\ntrends in PGMs mining and potential future implications. Although social impacts ... suggest that both. Merensky and UG2 tailings have a low acid mine drainage potential . Mineral Beneficiation of the Platinum-Group. Elements. Canadian.\nThe process of beneficiation of run of the mine ores and subsequent disposal to . affecting the mining industry and is commonly known as Acid Mine Drainage.\nDec 21, 2016 . Give examples of how mining, beneficiation, etc. affects society and how ... have many environmental problems, such as acid mine drainage.\nMining results in four main types of pollution: acid mine drainage (AMD), heavy ... Dry beneficiation allows the separation of coal from impurities without the use.\nProblem Statement. Acid Mine Drainage (AMD) water is. Ÿ . ash waste to treat contaminated acid mine drainage . Ÿ Fly Ash waste beneficiation. Ÿ Acid Mine.\n. generated from active and inactive mining sites and from beneficiation activities, and its impact on human health and the . The nation's reported volume of mining waste is immense. . Definition and Chemistry of Acid Mine Drainage (AMD).\nAdsorption of heavy metals from acid mine drainage by natural zeolite. 1 July 2009 . An overview of the beneficiation of iron ores via reverse cationic flotation.\nHe has worked recently on various projects in solid wastes beneficiation, Acid Mine Drainage treatment technologies and desulphurization of various gaseous.\nAcid mine drainage (AMD) has been a detrimental by-product of coal mining for . acid mine drainage continues to pose a potential problem in some areas,.\nMine exploration and development: learn whether ore . Beneficiation: separate ore minerals from other mined rock. (Mill). 5. Refining: ... Acid Mine Drainage.\nJul 8, 2014 . Keywords: mining; metal; tailings; oxidation; acid mine drainage; waste .. water at Las Luces copper-molybdenum beneficiation plant in Taltal.\nCoal beneficiation consists of sizing, handling and washing run-of-mine coal. ... Storm water runoff and acid or alkaline drainage if untreated may affect a small.\nV✧SEP Filtration of Acid Mine Drainage ... Beneficiation - concentrating the copper content of the ore; the crushing, screening and grinding of ore and removal.\nTailings from mining operations are usually stored in large tailings dams as a slurry that contains the waste materials from the beneficiation process. . causes a phenomenon known as Acid Mine Drainage (AMD) or Acid Rock Drainage (ARD).\nFe(II) oxidation during acid mine drainage neutralization in a pilot scale . quality waste gypsum, key to downstream gypsum beneficiation for recovery of.","Mining has several bad effects. It leaves behind a huge hole after mining is done. Secondly it damages natural beauty. A beautiful landscape which once existed is now a huge piece of dug up earth.\nEnvironmental Effects. Environmental issues can include erosion, formation of sinkholes, loss of biodiversity, and contamination of soil, groundwater and surface water by chemicals from mining processes. In some cases, additional forest logging is done in the vicinity of mines to create space for the storage of the created debris and soil.\nThe effects of mining in Africa have left large-scale devastation when companies do not honour their responsibility. Because mining areas are left in an unsustainable condition, plant species and wildlife are threatened and these areas are at risk of becoming lifeless wastelands.\nThe Impact and Effect of Illegal Mining (galamsey) towards the Socio-economic Development of Mining Communities: A Case Study of Kenyasi in the Brong Ahafo Region Adjei Samuel1, N.K.Oladejo1, I.A. Adetunde2, * 1University for Development Studies, Department of Mathematics, Navrongo. Ghana.\nSome of the major effects of mining on the environment are as follows: Minerals are the natural resources which play an important role in the economic development of the country. But the extraction and mining of these natural resources leads to some adverse effect on our environment as well.\nMar 09, 2017· The mining industry has the potential to disrupt ecosystems and wipe out wildlife populations in several different ways. Here's how mining affects the environment and wildlife. Habitat Loss; Mining can lead to the destruction of habitats in surrounding areas. The …\nModern mining is an industry that involves the exploration for and removal of minerals from the earth, economically and with minimum damage to the environment. Mining is important because minerals are major sources of energy as well as materials such as fertilizers and steel.\nApr 25, 2017· Mining is the extraction of minerals and other geological materials of economic value from deposits on the earth. Mining has the potential to have severely adverse effects on the environment including loss of biodiversity, erosion, contamination of surface water, ground water, and soil.\nSome gold can be found by panning in rivers; heavy gold will remain in the pan, whereas lighter rocks and minerals float out. This small-scale form of gold mining has little effect on the body of water, but the large-scale practice of mining gold from ore can have tremendous negative effects on water quality.\nMining can effect the earth because first, deforestation, and because mining requires large portions of land to be removed before they can start mining, lots of trees and plants are removed.\n1.1 PHASES OF A MINING PROJECT There are different phases of a mining project, beginning with mineral ore exploration and ending with the post-closure period. What follows are the typical phases of a proposed mining project. Each phase of mining is associated with different sets of environmental impacts. 1.1.1 Exploration\nFeb 07, 2018· The effects in such cases can be devastating for the environment. Be it due to ignorance of the regulations or just a freak accident, incidents like the Guyana spill of 1995 may occur again. This highlights the fact that issues like mining's effect on the environment are worth some serious deliberation.\nAug 26, 2010· Dust, radon and mercury impact miners' health. Dust, radon and mercury impact miners' health. ... Miners Face Health Risks, Even on Good Days ... mining …\nThe effects of mining coal on the environment. There are 2 ways to mine coal – Strip Mining and Underground Mining – both ways have their own impact to the environment and health. We know it but coal is such a cheap energy source that we don't want to let go of it. The negative effects of coal mining cannot be disputed:\nApr 21, 2019· The human health effects due to cyanide leach gold mining are not well documented, and this is no exception in Montana. The State of Montana has done no formal studies to specifically study mine-related health effects. Pegasus, the last mining company at Zortman-Landusky, started to fund a health study with the $1.7 million supplemental money from the 1996 settlement, but because …\nADVERTISEMENTS: Some of the major environmental effects of mining and processing of mineral resources are as follows: 1. Pollution 2. Destruction of Land 3. Subsidence 4. Noise 5. Energy 6. Impact on the Biological Environment 7. Long-term Supplies of Mineral Resources. Mining and processing of mineral resources normally have a considerable impact on land, water, […]\npositive and negative effects of mining on the environment. Mankind has been mining for precious metals since 42000 years ago and that's a staggeringly long time ago and that's exactly how long our species has been digging into the ground, to harvest its precious metals.\nDownload Coal Mining sounds ... 76 stock sound clips starting at $2. Download and buy high quality Coal Mining sound effects. BROWSE NOW >>>\nMining affects the environment by exposing radioactive elements, removing topsoil, increasing the risk of contamination of nearby ground and surface water sources, and acidification of …\nApr 20, 2015· Effects of Mining. Coal mining, the first step in the dirty lifecycle of coal, causes deforestation and releases toxic amounts of minerals and heavy metals into the soil and water. The effects of mining coal persists for years after coal is removed.\nJul 25, 2018· Environmental impacts from fossil fuel pollution are rapidly increasing in regions that have the highest concentrations of fuels. There are multiple effects of mining fossil fuels. Drilling and mining practices take a substantial toll on local water sources, biologic life and natural resources.\nPublished by the American Geosciences Institute Environmental Awareness Series. ... How can metal mining impact the environment? PDF version. Material adapted from: Hudson, T.L, Fox, F.D., and Plumlee, G.S. 1999. Metal Mining and the Environment, p. 7,20-27,31-35,38-39. Published by the American Geosciences Institute Environmental Awareness Series.\nMining operations usually create a negative environmental impact, both during the mining activity and after the mine has closed. Hence, most of the world's nations have passed regulations to decrease the impact. Work safety has long been a concern as well, and …\nEffects of mining on aquatic resources are both physical and chemical in nature. Most of earthmoving activities of mining occurred well before the enactment of laws designed to protect aquatic resources - particularly the 1977 Federal Water Pollution Control Act.\nThe former is known as underground mining, the latter as strip mining or mountaintop removal. Either process contributes a high level of damage to the environment: #12 Noise pollution. One of the most obvious (albeit perhaps least harmful) environmental effects of coal mining is noise pollution.\nMining has an adverse effect on soil quality. Soil degradation is the prime impact. Another impact is deforestation and loss of fauna and flora.\nThe impact of mining on the environment and the effects of mining techniques need to be more advanced with the utilization of modern equipment to be unintrusive to the environment. Economic growth is high on the agenda of leading countries, sustaining …\nMining is an inherently invasive process that can cause damage to a landscape in an area much larger than the mining site itself. The effects of this damage can continue years after a mine has shut down, including the addition to greenhouse gasses, death of flora and fauna, and erosion of land and habitat.\nNov 14, 2016· After mining is over, the land is left as barren land. The effects of mining sometimes vary depending on what is mined out, but these are some of the general effects you will see in all mine-areas. I'm not an expert when it comes to health impact on miners, but here are some of the things I know will affect them-\nJul 08, 2017· In coal mining, the extraction, crushing, and transport of coal can generate significant amounts of airborne respirable (extremely fine) coal dust. Dust less than 10 microns in size (cannot be seen with the eye). In non-coal mining, stone, and san...\nEnvironmental impacts of mining can occur at local, regional, and global scales through direct and indirect mining practices. Impacts can result in erosion, sinkholes, loss of biodiversity, or the contamination of soil, groundwater, and surface water by the chemicals emitted from mining processes. These processes also have an impact on the atmosphere from the emissions of carbon which have ...\nApr 04, 2017· The Dangerous Effects of Illegal Mining. April 4, 2017 Environmental Issues Written by Greentumble. Illegal mining has been ravaging our planet for. decades. Not only is illegal mining riskier from a safety perspective for those who choose to participate, but it encourages reckless behavior and leads to outcomes that have negative long-term ..."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:b7a3ddd8-b64d-4090-ab14-6f59971258b0>","<urn:uuid:11ce18f5-51f7-4dfa-a26b-c4a5796e1622>"],"error":null}
{"question":"¿Cómo se manifiesta la preservación de la herencia indígena en las familias de Puerto Rico y Minnesota?","answer":"In Puerto Rico, indigenous heritage is preserved through extended family structures, as seen in the Chéverez family who maintain a traditional homestead with features like hanging hammocks and multi-family living arrangements spanning three generations. Similarly in Minnesota, the LaPointe family preserves their indigenous heritage through family-based activism, working as a tiwahe (family unit) to protect water resources and organize indigenous summits. Both cases demonstrate how indigenous traditions and values are maintained through family structures and communal living patterns.","context":["Smithsonian Forums on the Living Indigenous Legacies of the Dominican Republic and Puerto Rico\nThe Taino presence in the Dominican Republic and Puerto Rico can be found in the people and the cultures according to scholars conducting research in both places.\nScholars from the Caribbean and the National Museum of the American Indian (NMAI) held forums and conducted research in both the Dominican Republic and Puerto Rico recently to explore indigeneity or the indigenous presence in both of these cultures.\nIn January, the Indigenous Legacies of the Caribbean Project (ILCP) of the NMAI sponsored a forum on Thursday, January 17th at the Archaeological Museum in San Juan de la Maguana, a Dominican town well known on the island for its indigenous heritage. The title of the event was \"The Indigenous Legacy of the Dominican Republic.”\nIn his account of the visit, Dr. Jose Barreiro, Assistant Director of Research at the NMAI, noted why the town of San Juan de la Maguana was chosen for the event.\n“In a country of presumed extinction of indigenous identity and culture, San Juan de la Maguana…stands out for its concentration of people who profess and relish the indigenous heritage of Quisqueya and the Caribbean, broadly identified as Taíno,” Barreiro wrote.\nAt the forum in San Juan de la Maguana, Barreiro presented information about the ILCP’s research and plans for a future exhibition entitled “Consciousness of Taino: Caribbean Indigeneity.” Another member of the ILCP team, Ranald Woodaman of the Smithsonian’s Latino Center also came to gather research for the project and participate in the forum.\nScholars such as epidemiologist Tony De Moya and Anthropologist Glenis Tavares of the National Museum of the Dominican Man then presented studies and evidence of indigenous heritage in the local area and throughout the country. During the discussions held after the presentations, many local residents asked questions about how to conduct oral history interviews as well as descriptions of some of “the Indian roots that undergird Afro-Dominican…music, religious practice,” Barreiro stated. He did note that there were audience members who believed in the “total extinction” of the indigenous presence in the Dominican Republic but that most of the Forum audience was sympathetic and supportive of the ILCP.\nFollowing the event in the museum, the ILCP team traveled to the municipal center of the town where Mayor Hanoi Sanchez stated that San Juan de la Maguana was “the capital of aboriginal culture” of the country.\nIn visits near the town, Barreiro and Woodaman were shown a local indigenous ceremonial area.\n“A local group including Dr. Sobieski de Leon guided us to the Plaza of Anacaona, known locally as the Corral de Indios. This is a sacred space in the old cacicazgo, a large circular ceremonial field, with a stone—the Stone of Anacaona—at the center. It was fascinating to me that the stone is identified as having been in place for more than five hundred years since the massacres that were committed at this exact site. A local prayer woman (oradora), blending Catholic saints and \"world alive\" practice, normally cares ceremonially for the stone,” Barreiro said.\nThe presence of indigenous traditions in families and regions were among the topics explored when the ILCP team traveled to Puerto Rico a few weeks after the visit to the Dominican Republic.\nOn Tuesday, February 19th, the NMAI and the Center for Advanced Studies of Puerto Rico and the Caribbean held a forum entitled “The Indigenous Legacy in Puerto Rico” at the Center in San Juan, the island’s capital. The Center is devoted to graduate level studies in history, economics, anthropology and other fields involving Puerto Rico and its role in the Caribbean.\nAlong with Barreiro, who gave an overview of the ILCP, the presenters at the forum included the Puerto Rican Archaeologist Dr. Osvaldo Garcia who spoke about the Smithsonian’s Caribbean Indigenous Collection, Dr. Juan Martinez Cruzado, the Puerto Rican geneticist who conducted the indigenous mitochondrial DNA Survey of the island who has done further studies there and throughout Latin America, and Professor Jalil Sued Badillo, a noted historian and author of two books involving Taino history in Puerto Rico.\nAfter the forum, the ILCP team visited a number of Taino historical sites in Puerto Rico, including a number of caves with extensive petroglyphs and pictographs. Accompanying Barreiro was Professor Juan Manuel Delgado a historian who over 30 years has collected oral history interviews of Puerto Ricans with indigenous heritage. Delgado, along with Woodaman, Garcia and Martinez Cruzado, are participants in the ILCP.\nThrough Delgado, Barreiro met with Alice Cheverez and her family in the mountains near Morovis, on the western side of the island. Barreiro described part of his visit to the family and their indigenous aspects, noting that Alice had \"classic Taino physique and facial features\".\n\"We had driven for over three hours out of Mayagüez to visit her family. Puerto Rico around San Juan is heavily urbanized but go east or west out of the capital, pass up the mountains to the central and some coastal regions, and you can still meet some families of distinguishable indigenous legacy and lineage,\" he stated.\n\"The Chéverez are a large, extended indo-Boriken family still living in these precious mountains. Their place has the feel of the old campesino (jibaro) homestead – hanging hamocks, animals walking loose, barefoot children playing,\" Barreiro continued. \"The family is reminiscent of large multi-family, indo-Cuban homestead caserios found in the Cuban mountains. More than a single nuclear family at the end of a long and winding road of verdant hills, the Chéverez are a multi-family lineage. Mapping preliminarily with Alice on her family’s extensions, we could count ten families with several children each just among her siblings, while the extended genealogies of a large chain of uncles and aunts and their children’s families through three living generations, took our quick kinship count to some two hundred people...I encouraged Alice and the family to develop a count of their relations.\"\n\"There is a Taino revival and a great continuing interest in things indigenous in Puerto Rico,\" Barreiro asserted. \"The revival is as intense as it is contested, but nevertheless real and extensive. Major historians and archeologists sustain vigorous research agendas, pushing the edges of knowledge and interpretation of a substantial and growing Taino material and archival wealth. We were fortunate to meet up with a few from this distinguished circle during our recent journey through the island.\"","Sitting alongside his family in ceremonies, Wakinyan LaPointe has heard the warnings for as long as he can remember. Lately, the dire messages have become increasingly urgent: Water must be preserved and protected. Unless that is done, all life on Earth is in danger.\n“Everything we are – our languages, our ways of life, our ceremonies, are all dependent on water,” says the 26-year-old Sicangu Lakota. “Without water there is no life.”\nWakinyan and his brother Thorne, 25, are college students and community organizers. They have been instrumental for years in Minnesota-based water events such as the Healthy Nations river scouting expeditions, Mde Maka Ska Canoe Nations Gathering, the Four Directions Water Walk, and Mde Maka Ska Community Conversations.\nBut after the recent death of an Indigenous rights leader in Honduras, the two men felt a greater sense of urgency to act on behalf of water, and the world’s Indigenous populations.\nBerta Caceres, who had successfully pressured the world’s largest dam builder to pull out of the Agua Zarca Dam project at the Río Gualcarque – a river sacred to her Lenca people – was slain in her home last March. More than a dozen environmental defenders have been killed in Honduras since 2014, according to Global Witness, which makes it one of the most dangerous countries in the world for activists protecting forests and rivers\nAlong with their father LeMoine, mother Nancy Bordeaux, and sister Tiana, the LaPointe brothers conceived a plan to invite Indigenous leaders from around the world to Minnesota – the font of much of the Earth’s fresh water – for a summit, which they are calling Mni Wakan: A Decade of Water.\nThorne and Wakinyan put their heads together and wrote a summons to the world’s Indigenous leaders. It came in the form of a formal statement, or in the lingo of the United Nations, an “intervention” on water.\n“The statement, a broad interpretation of the water crisis this world is experiencing, reiterated our Lakota values: Mni Wakan: water is sacred; Mni Pejuta: water is medicine; and Mni Wiconi: Water is Life,” says Wakinyan. “In our Lakota way, it is our responsibility to strengthen our relationship with water. The statement was intended to acknowledge that relationship and place it in everyone’s minds. In the process of so doing, we invited indigenous peoples, and the appropriate UN representatives, to come to Mni Wakan: Decade of Water. This will be an indigenous led, indigenous centered, water summit, which we are planning for April of 2017.”\nThe brothers made plans to deliver it to the United Nation’s Permanent Forum on Indigenous Issues (UNPFII), which takes place each May in New York City. The LaPointes organized a successful fundraiser at the Minneapolis American Indian Center and raised enough for all five of them to travel to New York City. Thorne and Wakinyan would attend during the first week of the UNPFII, Nancy, Tiana, and LeMoine the second.\nWorking together as a family, or tiwahe, comes naturally to the LaPointes, who see their teamwork as an extension of their Lakota way of life. “Our basic political unit is the Tiwahe,” says Thorne. “Our body politic is made up of families and the stories that each of them contribute to the Tiospaye (extended family), and the Oyate (nation).”\nThe LaPointes descend from a long line of diplomats, warriors, and treaty men who have left current and future generations the responsibility of restoring the Oceti Sakowin, the Lakota Nation, to greatness. Nancy’s family tree includes Yellow Cloud, who fought against Custer at Little Bighorn; LeMoine’s includes Tall Mandan, a chief and medicine man who was a signatory to the 1851 and 1868 Fort Laramie Treaties.\n“Tall Mandan signed the 1868 treaty with his name followed by the word ‘akicita,’ which translates as warrior, but in this case means enforcer,” says LeMoine. “He was an enforcer of the treaty which meant it was his responsibility to see to it the agreements were carried out honorably and in the way they are interpreted not necessarily by our oppressors, but by the Lakota people. That duty has been handed down to us, and it to our children and grandchildren.”\nUpon arrival at the United Nations in Mid-May, the brothers were met with the cold reality of international politics. Although they have visited the world body several times in the past, this was the first time they had attempted to deliver a speech. They waited and waited each day but did not have an opportunity to read their statement to the Permanent Forum.\n“There was no time because representatives from member states have priority,” says Thorne. “They know there are indigenous delegations present from their countries, and they often don’t want them to speak. It’s the way member states filibuster; they stall and go over their time at the microphone. The United Nations may be about human rights, but that doesn’t mean it’s a human system.”\nWith the arrival in New York of their mother, sister and father, the brothers had a second chance. Nancy, Tiana, and LeMoine however, had no better luck maneuvering themselves before a live microphone. So Nancy, whose work in Minneapolis focuses on empowering women, did what she encourages everyone to do when they need help. She prayed.\n“I thought about my sons and how they had written this statement. I thought, they didn’t get a chance to read it, and then saw myself up there reading it on their behalf,” Nancy says. For the second day in a row, she then went to the scheduling desk and asked to be placed on the agenda. She faced the same woman who had denied her a time slot the previous day.\n“All of a sudden she seemed to have a change of mind said, ‘OK, I’m gonna put you on the list and you’re gonna be high priority.’” Nancy was told to return to the Permanent Forum the next morning where she would have an opportunity to address Indigenous delegations from around the world.\nNancy arrived as instructed, found a seat near the front of the auditorium, waited through three speakers. Finally, Nancy spoke into the microphone the words written by Thorne and Wakinyan:\nWater Connects us all. Without clean water there is no life. Mni wakan, water is sacred. Mni Pejuta, water is the first medicine.\nMany indigenous nations believe and know they were born from water. Yet, indigenous peoples remain the few who remember these original instructions regarding our intimate relationship with water. We do not separate the creator from creation.\nWe are facing a world-wide water crisis unlike anything we have ever seen before. Water is being consumed at an alarming rate, used unsustainably, and is contaminated more and more with each passing day.\nIndigenous people, communities, and Nations retain the wisdom and traditional ecological knowledge that is most urgently needed to restore a more sustainable future of water… Indigenous peoples and Nations must be seen as central to all activities involving water, at all levels, in that they provide the traditional ecological knowledge which is the last remaining frontline for the protection of water.\nIndigenous led water initiatives, such as the upcoming Mni Wakan: Decade of Water summit, to be held in central Minnesota, USA, in April 2017 must be fully supported as a matter of Indigenous water rights implementation. Therefore, we invite the appropriate United Nations representatives, and Indigenous peoples to attend this global Indigenous-led water summit…to close we celebrate the life of Berta Caceres of Honduras, who died protecting the sacred river and her peoples; water is life.\nReflecting on his family’s recent accomplishment at the United Nations, LeMoine says leadership by Indigenous peoples on water issues is the only way forward. “Indigenous people hear differently. We see differently. And that comes from thousands of years of intimate relationships with earth and sky. Now we have contaminated our own nest, and we can’t use science to fix it, because science is what caused it. But what we can do is listen to the wisdom of this Earth and water and follow its dictates, just as Berta Caceres did in Honduras. She said, the river called out to me, Mother Earth said she awaited help, and so she helped. And that is what we must do.”"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:835a8b4c-838f-427e-9d1c-50b5570c83f1>","<urn:uuid:31154d81-482d-4b95-9dc5-d629e023a95b>"],"error":null}
{"question":"How can companies benefit from serving poor nations while fighting poverty?","answer":"Companies can serve poor nations profitably by revolutionizing how they do business in developing countries. They can unlock the 'poverty penalty' and deliver dignity, empowerment, and choice - not just products. This approach allows corporations and BOP entrepreneurs to profit together through an inclusive new capitalism while helping fight poverty.","context":["This specific ISBN edition is currently not available.View all copies of this ISBN edition:\nPresents the theory that there are commercial opportunities in the poor nations of the world for private companies, and that companies can utilize this knowledge to make profits and at the same time fight poverty.\n\"synopsis\" may belong to another edition of this title.\nThe world's most exciting, fastest-growing new market? It's where you least expect it: at the bottom of the pyramid. Collectively, the world's billions of poor people have immense entrepreneurial capabilities and buying power. You can learn how to serve them and help millions of the world's poorest people escape poverty.\nIt is being done—profitably. Whether you're a business leader or an anti-poverty activist, business guru Prahalad shows why you can't afford to ignore \"Bottom of the Pyramid\" (BOP) markets.\nIn the book and accompanying CD videos, Prahalad presents...\nWhy what you know about BOP markets is wrong\nA world of surprises—from spending patterns to distribution and marketing\nUnlocking the \"poverty penalty\"\nThe most enduring contributions your company can make\nDelivering dignity, empowerment, and choice—not just products\nCorporations and BOP entrepreneurs\nProfiting together from an inclusive new capitalism\n\"C. K. Prahalad argues that companies must revolutionize how they dobusiness in developing countries if both sides of that economic equation areto prosper. Drawing on a wealth of case studies, his compelling new bookoffers an intriguing blueprint for how to fight poverty with profitability.\"\nBill Gates, Chairman and Chief Software Architect,Microsoft\n\"The Bottom of the Pyramid belongs at the top of the reading list forbusiness people, academics, and experts pursuing the elusive goal ofsustainable growth in the developing world. C. K. Prahalad writes withuncommon insight about consumer needs in poor societies andopportunities for the private sector to serve important public purposes whileenhancing its own bottom line. If you are looking for fresh thinking aboutemerging markets, your search is ended. This is the book for you.\"\nMadeleine K. Albright, Former U.S. Secretary of State\n\"Prahalad challenges readers to re-evaluate their pre-conceived notionsabout the commercial opportunities in serving the relatively poor nations ofthe world. The Bottom of the Pyramid highlights the way to commercialsuccess and societal improvement--but only if the developed worldreconceives the way it delivers products and services to the developingworld.\"\nChristopher Rodrigues, CEO, Visa International\n\"An important and insightful work showing persuasively how the privatesector can be put at the center of development, not just as a rhetoricalflourish but as a real engine of jobs and services for the poor.\"About the Author:\nMark Malloch Brown, Administrator, United Nations Development Programme\nC.K. Prahalad is Harvey C. Fruehauf Professor of Business Administration and Professor of Corporate Strategy and International Business at the University of Michigan Business School. He is a globally recognized business consultant who has worked with senior management at many of the world's leading companies. Prahalad's groundbreaking article, \"The End of Corporate Imperialism,\" won the 1998 McKinsey Prize as the year's best Harvard Business Review article. C. K. co-authored several important papers and articles, including \"The Fortune at the Bottom of the Pyramid,\" which have helped launch a global movement towards private-sector solutions for global poverty. His research focuses on corporate strategy and the role of top management in diversified multinational corporations. With Gary Hamel, he co-authored the global business bestseller Competing for the Future.\n\"About this title\" may belong to another edition of this title.\nBook Description Wharton School Publishing. Hardcover. Condition: New. 0131467506 Brand New Paperback International Edition. Fast Delivery. Same Contents as US Editions. ISBN and Cover might be different in some cases. Delivery in 4-14 Business days. Seller Inventory # N-INT-AD-131467506\nBook Description Wharton School Publishing, 2004. Hardcover. Condition: New. Never used!. Seller Inventory # P110131467506\nBook Description Wharton School Publishing, 2004. Condition: New. book. Seller Inventory # M0131467506\nBook Description Wharton School Publishing, 2004. Condition: New. book. Seller Inventory # MB010IK8CK6\nBook Description Wharton School Publishing, 2004. Hardcover. Condition: New. Brand New!. Seller Inventory # VIB0131467506\nBook Description Wharton School Publishing. Hardcover. Condition: New. 0131467506 New Condition. Seller Inventory # NEW99.0046466\nBook Description Wharton School Publishing, 2004. Hardcover. Condition: New. 1st - may be Reissue. Ships with Tracking Number! INTERNATIONAL WORLDWIDE Shipping available. Buy with confidence, excellent customer service!. Seller Inventory # 0131467506n\nBook Description Condition: New. New. Looks like an interesting title!. Seller Inventory # M-0131467506\nBook Description Hardcover. Condition: New. NEW. Seller Inventory # AH-14"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:66c28f2c-b15c-4d57-af58-ff23774d55fd>"],"error":null}
{"question":"Which technology requires more precise pressure control: farm spraying systems or dairy barn cooling systems?","answer":"Farm spraying systems require more precise pressure control than dairy barn cooling systems. For spraying pesticides, there is a small margin of error as droplet size depends on pressure and affects both efficiency and protection of neighboring fields - small drops take time to hit the target and dry quickly. In contrast, dairy barn cooling systems with shower nozzles operate at a relatively simple, reduced water pressure of 10-15psi, mainly needing to produce coarse droplets that can penetrate the cow's hair coat without forming a mist.","context":["You are here\nFarm Sprayers Overview\nWhile sprayers were once a niche product, today sprayers have become an essential piece of farm equipment for effective crop production. By properly applying chemicals to control weeds, insects, and diseases, you give your crop the best chance for high yields.\nThe uptick in self-propelled sprayer ownership started in 2005 when there was an increase in Asian soybean rust and farmers needed to have a sprayer available to make timely fungicide applications. Guidance systems and advanced controls have also made sprayers much easier to operate, contributing to the acceleration of on-farm sprayers.\nOn this page, you’ll find maintenance information, spraying tips, a listing of ag sprayer manufacturers, and details on self-propelled sprayers as well as ATV sprayers.\nFirst and foremost, you need to make sure your sprayer is in top condition before spring and then maintain your sprayer throughout the growing season.\nSprayer maintenance includes checking fluid levels, greasing necessary components, calibrating the sprayer monitor, and more. This sprayer maintenance checklist breaks down what you need to do before you start spraying as well as daily, weekly, and monthly maintenance upkeep during the season.\nAt the end of the year, it’s important to do one final round of maintenance to winterize your sprayer. This will help protect your sprayer from frost damage and make sure it’s ready to go for the next year. This article gives five tips for winterizing your sprayer, including flushing the system, scrutinizing the exterior, and cleaning the cab.\nThere are multiple steps you can take each time you spray to optimize efficiency and minimize off-target drift. It’s essential to read the label, pick the best spray nozzle, calibrate your sprayer, and check wind speed. You should also use a spray-pattern check to make sure you have the right nozzle spacing and boom height. Get more spraying tips in this article on 16 steps to better spraying.\nThere is a small margin of error when it comes to spraying pesticides, both for increasing efficiency and protecting neighboring fields. For more effective and safe spraying, remember that small drops take time to hit the target, droplet size depends on pressure, small droplets dry quickly, and that nozzles produce a variety of droplet sizes.\nIn 1947, Ray Hagie, founder of Hagie Manufacturing, invented the world’s first self-propelled sprayer. This revolutionary piece of equipment would change how farmers and professional applicators apply pesticides. Today, self-propelled sprayers make up the majority of the farm spraying market, having largely replaced pull-type sprayers.\nSprayers continue to get more sophisticated with advanced technology like auto guidance, auto shutoffs, and Y-Drop. In this article, Illinois farmer Jeff Brown details how he uses technology to ensure that every drop applied to his plants is delivered when and where the plant needs it most.\nIf you’re in the market for a late-model self-propelled sprayer, be warned that low-hour sprayers are bringing higher prices on dealer lots and at auctions. Successful Farming’s 2018 price projection for 3- to 4-year old sprayers shows a 4% increase. See more late-model, low-hour equipment price projections in our latest Machinery Insider column.\nAgricultural Sprayer Manufacturers\nA number of equipment manufacturers make self-propelled sprayers, including John Deere, Hagie, Hardi, Case IH, New Holland, AGCO, and Equipment Technologies.\nIn 2017, John Deere introduced a 123-foot, carbon-fiber boom – its widest boom to date. The new boom was accompanied by the freshly designed CommandView III Cab, which features a hydro handle joystick, a 4600 Command Center display, and a redesigned CommandARM.\nNew Holland, AGCO, Hardi, and Equipment Technologies also introduced new sprayer models last year. New Holland introduced the Guardian SP310F and Miller Nitro 7310 – the first since New Holland acquired Miller-St. Nazianz. AGCO unleashed the RoGator C series with Liquid Logic, which helps to reduce off-target applications. Hardi came out with the Rubicon 9000. The 380-hp. Rubicon 9000 has a 2,200-gallon payload and booms up to 160 feet to cover 330 acres per hour. Last, Equipment Technologies reengineered its self-propelled hydrostatic sprayers for the North American market.\nAt the end of 2016, John Deere and Hagie introduced the STS16 – the first product collaboration between the companies since Deere’s acquisition of Hagie. The 2017 STS16 features a 9-liter John Deere PowerTech PSS engine.\nFor field borders, pastures, fence lines, and other hard-to-spray areas, ATV sprayers are ideal for spot spraying. These sprayers can come equipped with a spray wand or a boom, depending on the location you’re spraying. There are multiple options available for ATV boom sprayers, such as a steel, poly, or versatile boom.\nBefore you buy an ATV sprayer, consider how frequently you will use the sprayer, where you will spray, and how much you’d like to spend. This buyers’ guide gives advice on key ATV sprayer features, including pumps, drainable tanks, seat pressure control, and liftability.","Automated Control of Shower Cooling\nThe Edstrom C-440S Controller is a reliable, programmable electronic controller that has the ability to store in its memory two complete operating programs. This permits the operator to program one cooling program to activate at a lower range of temperatures; while a second, more intensive cooling program can be entered to come on at a higher temperature when the cows are being subjected to more heat stress.\nFor example, in the LO-Range setting, the user could program the C-440S Controller to commence cooling when temperatures reach 75°F (Actuation Temperature). The controller could activate up to 4 electric valves in sequence, to permit showering for a 2-minute period of time (Shower Time) during a 20-minute cycle. Only one electric valve would be activated at any one time. Thus, with 4 valves, during the 20-minute cycle time, there would be a total of 8 minutes of showering, (2 minutes from each of the 4 valves) followed by 12 minutes with no showering (Interval Time). At the end of this cycle, the controller checks the temperature again, and if the temperature is above the programmed level of 75°F, the cycle will start all over again.\nAfter setting the LO-Range program, the user could set the HI-Range program to begin at temperatures of 85°F or above. In this HI-Range setting, the unit could be programmed to activate each of the electric valves for 1-1/2 minutes of showering during a 10-minute cycle time. This would amount to a total of 6 minutes of showering, (1-1/2 minutes from each of the 4 valves) followed by 4 minutes with no showering. When the temperature drops back below the setting of 85°F, the controller will switch back to the LO-Range program.\nThere should be a continuous flow of air over the backs of the cattle any time the cooling system is in operation. This causes the water to be evaporated, which takes the heat away from the cattle in the process. Fans would be controlled separately from the cooling system, and could be set to operate continuously above a temperature of 70°F.\nProgramming of the C-440S Controller is easy to do. Time and temperature settings in both LO-Range and HI-Range are easily viewed and adjusted as desired. The shower times and interval times can be set anywhere within the range of 0 – 99 minutes, while the actuation temperature can be set anywhere between 40° – 99°F in either the LO or HI-Range settings. You can also select the number of electric solenoid valves that are to be operated. Once the settings are entered, they are saved automatically, and will not be lost if the electrical power is interrupted.\nIt does not have to be 110°F for heat stress to occur in dairy cows!\nStudies have found that at temperatures as low as 79°F, dairy cows will begin to cut feed intake and lose body weight. Milk production falls. Reproductive performance, health, and lactational performance are affected. Heat stress will continue to affect performance even in the cooler months ahead. High yielding cows are most susceptible to heat stress. All of this quickly impacts your pocket book!\nThe degree of heat stress suffered by the cow will depend on the combination of environmental conditions – air temperature, relative humidity, air movement, and radiation from the sun. Dairymen use shades, fans, and ample fresh drinking water to help herds beat the heat; but often shade and ventilation are just not enough. In southern states, where heat and humidity are more severe, dairymen have also used sprinklers to provide added cooling effects.\nResearch has shown that intermittent showering in combination with shade and forced air movement is a very effective method of cooling diary cows, thereby reducing the production losses experienced during hot humid weather conditions. By using a high capacity, coarse droplet shower nozzle, enough water can be applied to fully wet the cows to the hide. The water is then allowed to evaporate, which pulls heat from the animal, just like sweating. Increased air movement across the wet hide provided by fans, makes this system most efficient.\nDisadvantages of Misting and Fogging\nMist and fogging nozzles have been used to cool dairy cows, and have proven advantageous in dry climates. They work by cooling the air around the cows. The disadvantage is that the mist can be easily blown away under windy conditions, or when used with fans. If a mist or fog builds up on the cow’s hair coat, it can trap a layer of air between the skin and the water, which holds in body heat. Respiratory problems can also arise if proper ventilation is not provided. In addition mist and fogging nozzles usually must be operated at high pressures and require regular maintenance, especially when poor water quality conditions exist.\nIn comparison, shower nozzles produce coarse droplet spray which penetrates the hair coat and wets the cow’s skin. To avoid formation of a mist the shower nozzles operate at reduced water pressure of 10-15psi.\nTypical Installation of a Shower Cooling System\nNormal recommendations are to shower the animals for a short period of time, 0.5 – 3 minutes, to wet the hide. After the shower shuts off, the water is evaporated from the cattle by the air from fans blowing across their backs for 5-15 minutes, before repeating the shower cycle.\nThe most common locations for installing a shower cooling system are in the holding pen area, where cows are crowded together tightly, and in the feed bunk area. An air velocity of 400-600 ft/min over the cows’ backs is recommended. A 36-inch fan providing 11,000 cfm will move air effectively for 20-30 feet, and a 48-inch fan will move air up to 40 feet. Fans should be placed as low as possible, while still allowing clearance for cows and equipment. Nozzles should be mounted just below the fans.\nWe offer all the components you need to economically set up an intermittent showering system in your facility. The Edstrom C-440S Controller permits you to control up to 4 electric water valves activated in sequence. This electronic controller has a user-programmable thermostat and time settings.\nWe offer a selection of Shower Nozzles. In addition, an economical 24VAC, 3/4-inch electric valve and filter are offered for installing in your water line. You only need to provide the water distribution pipelines, electrical connections, and the ventilation fans.\nThe Edstrom Controllers can be ordered with either a 24VAC/110VAC transformer, or a 24VAC/220VAC transformer. This allows you to choose the system that will best fit your operation.\nTypical Set Up of a Cooling System\n1. First determine where you want to locate the shower nozzles. They should not be installed where they will spray into the feed bunk or a stall area. Common locations are at the feed bunk and in the holding pen areas.\nIn the holding pen area, full-circle (3600) nozzles are recommended, and should be located to obtain 100% coverage of the area to be sprayed at a height of about 4-1/2 ft. above the floor. At the feed bunk, 1/3-circle (1200) nozzles can be mounted along the top of the bunk head gate and directed to spray out over the backs of the cows\n2. Next, determine the plumbing arrangement. This will depend on the quantity and type of nozzles being installed, as well as the water flow capacity of your facility. Multiply the number of nozzles by the nozzles’ rated capacity to obtain the total water flow-rate required for the facility. The electric valve-filter-pressure reducer used to control the flow to the nozzles has the capacity to handle up to 15 gpm. If the total flow-rate required for the facility exceeds this capacity, or if the farm water supply is not capable of supplying water at this rate, the nozzle lines need to be divided into sections, or “zones”, each supplied by a separate electric valve-filter-pressure reducer. (The C-400 Controller will activate the Electric Valves in sequence; they will not all come on simultaneously.)\nWhen installing the system, locate the electric valve-filter-pressure reducer centrally in each line of nozzles to balance the water pressure to the far end of the lines.\n3. The C-440S Controller should be located where it will be easy for the operator to view and make program adjustments. The unit is powered by a 24VAC transformer (included with the controller), which must be plugged into an 110VAC outlet. An optional 220VAC transformer is also available. Electric wiring connects the controller to each electric valve. This is a low-voltage 24VAC circuit. (A 50 ft. roll of low-voltage wire is included with each electric valve kit.)\nContact me today by phone (515-771-6036) to layout your system today!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:c553b142-045d-42f6-87eb-999a70e3e7ad>","<urn:uuid:cb726282-49f3-40da-bec9-b051468bdf98>"],"error":null}
{"question":"What are the standard procedures for conducting workplace investigations, and what specific legal remedies are available to employees who face retaliation in California?","answer":"Standard workplace investigation procedures include defining the scope of investigations, collecting basic case information, documenting source and location details, conducting proper witness interviews with Upjohn warnings, maintaining confidentiality, preserving documents, and preparing detailed written reports with factual analysis and determinations. All steps must be reviewed by an independent committee. As for legal remedies in California, employees who face retaliation can pursue several options: They can file complaints with the Labor and Workplace Development Agency for whistleblower retaliation under Labor Code 1102.5 LC, file with the Department of Fair Employment and Housing for FEHA violations, or directly file lawsuits for False Claims Act retaliation. Available damages may include compensation for emotional distress, harm to professional reputation, and lost wages from retaliatory actions like demotions or denied promotions.","context":["How to Audit Your Internal Investigation Program (Part II of III)\nAs an initial step, an audit of an internal investigation program requires a detailed understanding of the operation of a company’s internal investigation program.\nIn crafting the audit, the first step is to define the relevant universe of investigations. The audit scope will depend on the number of investigations to be review based on the number of investigations and the years to be reviewed. Assuming that your audit is limited to the prior two years, the number of investigations should be determined by category.\nIn most cases, the number of investigations will require review of a sample of investigations conducted by: (1) office/investigator (e.g. headquarters, region or local staff); (2) type (e.g. human resources, conflict of interest, theft, bribery); (3) geographic location. The audit scope should seek to ensure that a representative sample from as many locations and as many types are conducted so that meaningful findings can be made. If a sample from one location is small, such an audit may not be helpful since the review may be too small.\nThe audit scope should also ensure that a broad cross-section of investigation sources is examined, including hotline reports (identified and anonymous), walk-ins (e.g. human resources, compliance), government investigations or proactive requests.\nAssuming that you have defined your audit scope to address all of the significant aspects of the internal investigation program, you will need to define the standard operating procedures or controls that need to be evaluated. Once these are defined, a review of an investigation file and documents will have to be conducted.\nThe audit review for each file should reflect evaluation of the following controls and factors (assuming a reasonable number of best practice SOPs).\nFor each case, the audit should collect basic information about each case selected under the scoping procedure/ These basic facts include: (1) Source of investigation; (2) Location of investigation (business unit and country/office); (3) investigation offense(s) (code and legal); (4) Privileged v. Non-Privileged; (5) Notification(s) (complainant, subject); (6) Assignment of investigation; (7) Lead investigator; (8) Absence of conflict of interest; (9) Date of investigation initiation; (10) Date of investigation closing; (11) Final action; and (12) No. of days opening to closing.\nThe basic audit review should include identification of the individuals involved, including the complainant and the individuals investigated (or subjects of investigation). The initial summary should include the issues investigated, the results of investigation (substantiated v. unsubstantiated), the disciplinary action (if any) and remediation steps.\nAfter collecting the basic information for each of the audited cases, the review should focus on the conduct of the investigation itself. As a threshold matter, the audit should almost exclusively depend on a documented case file. To the extent items are not documented, this would be an important audit finding to record.\nWith regard to the specific investigation, and assuming these items are required under the standard operating procedures and based on templates available for use in each investigation, the following items should be reviewed: (1) Initial assessment; (2) Investigation plan, including proper scoping, evidence collection and review (documents and other sources), and witness interviews; (3) elements of offense(s) analysis; (4) Document hold and preservation steps; (5) Internal/external assistance; (6) Notifications/Contacts with complainant; (7) Subjects of investigation; (8) Proper confidentiality arrangements; (9) Document review; (10) Witness interviews (properly conducted, scoped and memorialized); (11) Documented Upjohn warnings.\nEvaluation of these items may involve judgment calls as to proper scope, substance, document review. Some of the items are binary – yes or no – and good data points. While I recognize that the judgment calls may suggest a lack of objective analysis, such a review should not be used s a flyspecking review but more forgiving to make sure that there is an explanation for any decision and barring some major factor that was ignored, such discretion should be counted as a positive result.\nA separate portion of the review should be focused on the review of the written investigative report for key elements of an investigation. If a documented report is not included in the file, that would be a clear deficiency.\nAs to the substance of the report, it should include: (1) Outline of allegations; (2) Investigative steps; (3) Chronology of events; (4) Factual analysis; (5) Review of documents and witness statements; (6) Specified credibility determinations; (7) Explanation of determinations.\nThe last step in the investigation audit should focus on the review of the investigation. Hopefully, the company has appointed an independent committee to review the investigations and impose consistent discipline. This review process should be documented as well, and therefore subject to review.\nThe independent committee review factors should include: (1) Approval, rejection or referral back for additional investigation (if the independent committee required further investigation and sent the investigation back to address identified deficiencies, this should be captured); (2) Analysis; (3) Reasons for discipline or resolution and explanation; (4) Consistency analysis and explanation; (5) Root cause analysis/contributing factors; (6) Communication of decision (complainant and subject/violator); (7) Days for review and resolution; (8) Remediation and confirmation of changes implemented.\nThe audit results for each of the investigation phases can be tracked, categorized and analyzed for trends and observations. Once conducted, the audit framework can be used (and modified, if needed) to develop trends over time and the ability to document improvements and modifications to a company’s ethics and compliance program.","Under California employment law, employers may not engage in workplace retaliation against employees who\n- report violations of law,1\n- oppose, complain about or participate in an investigation of workplace harassment or employment discrimination,2\n- request reasonable accommodations for a disability or their religious beliefs,3 or\n- file or assist in a \"qui tam\" lawsuit under the California False Claims Act.4\nThese workplace retaliation laws fill an important gap in California employment law. While employees are protected against wrongful termination in a variety of circumstances, employees who do not lose their jobs--but instead experience adverse employment actions, abuse or other forms of retaliation at work--have a harder time finding legal remedies.\nBut the workplace retaliation provisions of California's whistleblower laws and Fair Employment and Housing Act (\"FEHA\") retaliation laws provide a legal remedy for employees whose employers retaliate against them--but do not fire them--for exercising their rights under these laws.\nBelow, our California labor law attorneys discuss the following topics:\n- 1. How to Tell If Your Employer is Engaging in Workplace Retaliation\n- 2. Employer Retaliation for Whistleblowing / Reporting a Violation of Law\n- 3. FEHA Workplace Retaliation\n- 4. False Claims Act (Qui Tam) Workplace Retaliation\n- 5. Lawsuits and Damages for California Workplace Retaliation\nIf you have further questions after reading this article, we invite you to contact us at Shouse Law Group.\nThe basic legal definition of workplace retaliation in California is:\n- Your employer takes an adverse employment action against you or treats you in a discriminatory manner,\n- Because you engaged in a protected activity.\nWhen the adverse employment action is a termination (job loss), then it is easy to identify this as a case of potential wrongful termination.\nSimilarly, if your employer responds to the exercise of your legal rights by making your working conditions so intolerable that you have no choice but to resign, then you have a case against the employer for wrongful constructive termination.\nBut other forms of employer retaliation can be more subtle--and harder to spot. Some telltale signs that your employer might be retaliating against you include:\n- You begin receiving negative performance reviews even though your previous reviews were positive;\n- Your workload is increased;\n- You are assigned to less desirable shifts;\n- Your supervisors exclude you from meetings or correspondence or otherwise make it difficult for you to perform well on your projects;\n- You are denied a promotion or raise that you think you deserved;\n- You are subject to disciplinary action on trumped-up charges or inadequate grounds; and\n- You are denied access to resources or training that would help you maintain your work quality or advance your career.\nUnder California Labor Code 1102.5 LC, employers may not engage in retaliation against employees who\n- report suspected criminal activity by their employer to a government or law enforcement agency,\n- report a suspected violation of a law or regulation to a supervisor or other person at the employer who has the authority to investigate the violation, or\n- provide information to or testify before any government body conducting an investigation, hearing or inquiry into a potential violation of law by their employer.5\nLC 1102.5 is a so-called \"whistleblower protection\" law. A whistleblower protection law generally protects employees from both firing/termination AND less severe forms of employer retaliation for reporting suspected legal violations by their employer.\nYou are protected by this whistleblower retaliation law even if it turns out that your employer did not actually break the law. All that matters is that you reasonably believed that your employer may have done something illegal.6\nExample: Nikolai works for a software company. Based on some conversations he has overheard, he believes that his company may be engaging in violations of antitrust laws with another similar company. Nikolai reports his suspicions to an in-house lawyer at the company.\nThe lawyer investigates the report and determines that nothing illegal is going on. But she also lets the CEO of the company know that Nikolai was the one who reported his suspicions to her.\nAfter that, Nikolai is not given assignments on important projects at work. His performance reviews also suddenly turn negative. He is passed over for a promotion that he had previously been told he could get.\nNikolai may be the victim of workplace retaliation for his whistleblowing activities.\nThe California Fair Employment and Housing Act (the \"FEHA\") protects employees from retaliation if they do any of the following:\n- Oppose acts of harassment or employment discrimination or an employer's failure to grant required pregnancy/family leave;\n- File a complaint about harassment or discrimination;\n- Testify or assist in any proceeding under the FEHA; or\n- Request workplace accommodations for their religious beliefs or observance or for a disability.7\nFEHA retaliation under California employment law occurs when any of the above activities by an employee is a substantial motivating factor for adverse employment actions against, or discriminatory treatment of, that employee.8\nExample: Robia is a Muslim. She gets a job at a call center working long shifts.\nRobia's religious beliefs require her to take regular breaks to pray over the course of the day. She asks her boss if she can take these breaks and use a supply closet for her prayers.\nRobia's boss agrees because he does not want to be accused of religious discrimination. But he is not happy about the inconvenience this causes. So he begins assigning Robia to less desirable night and weekend shifts, and he does not allow her to attend several trainings that could have helped her rise in the company.\nRobia's boss is guilty of workplace retaliation under the FEHA.\nThe California False Claims Act also prohibits employer retaliation against employees who take advantage of their rights under that law.\nThe California False Claims Act gives employees the right to file a so-called \"qui tam\" lawsuit against an employer who is committing fraud, theft or embezzlement with respect to government funds. (A \"qui tam\" lawsuit is a suit filed by a private citizen on behalf of a government entity.)9\nThe workplace retaliation provisions of the California False Claims Act prohibit your employer from retaliating against you if you\n- file, or assist in any way with, a qui tam suit, or\n- make an effort to stop a violation of the California False Claims Act.10\nExample: Ted is a manager for a construction company that does a lot of work under state government contracts. He suspects that his company has been overbilling the government. So he files a qui tam suit in state court. The California Attorney General's office then takes over the lawsuit.\nTed's boss understands that it would be illegal to fire him over the qui tam suit and that it would probably make the company look bad in the lawsuit. But the boss demotes Ted instead.\nTed probably has a case against his employer for California False Claims Act workplace retaliation.\nDifferent California workplace retaliation laws offer different options for employees who are retaliated against by their employer.\nLabor Code 1102.5 LC\nIf you think you have been a victim of whistleblower retaliation under Labor Code 1102.5 LC, you must first notify the California Labor and Workplace Development Agency through an online form and your employer via certified mail.11\nAfter you file this notice, the Labor and Workplace Development Agency may decide to investigate your complaint itself. If it chooses not to do so, you may file your own lawsuit in California Superior Court.12\nFEHA workplace retaliation\nIf your employer retaliates against you for exercising your rights under the Fair Employment and Housing Act, then your first move is to file a complaint with the Department of Fair Employment and Housing (DFEH).\nYou may then sue your employer for workplace retaliation once the DFEH issues a \"right to sue\" notice.13\nCalifornia False Claims Act workplace retaliation\nYou may file a lawsuit against your employer immediately if you are a victim of workplace retaliation under the California False Claims Act.14\nDamages for workplace retaliation\nDamages in a workplace retaliation case will be somewhat different than damages in a California wrongful termination case. This is because wrongful termination damages typically include the value of lost pay and benefits attributable to the loss of the plaintiff's job.\nIn a workplace retaliation case, though, damages are more likely to include:\n- Damages for emotional distress arising from your mistreatment at work--including physical pain, loss of enjoyment of life and/or anxiety;\n- Damages for harm done to your professional reputation as a result of retaliatory adverse employment actions (such as demotion, being denied a promotion or being denied professional development or work opportunities); and/or\n- Lost wages from a retaliatory demotion or denial of a promotion or raise.15\nCall us for help...\nFor questions about California law on workplace retaliation or to discuss your case confidentially with one of our skilled California labor and employment attorneys, do not hesitate to contact us at Shouse Law Group.\nWe have local employment law offices in and around Los Angeles, San Diego, Orange County, Riverside, San Bernardino, Ventura, San Jose, Oakland, the San Francisco Bay area, and several nearby cities.\n- Labor Code 1102.5 LC -- Employer or person acting on behalf of employer; prohibition of disclosure of information by employee to government or law enforcement agency; suspected violation or noncompliance to federal or state law; retaliation; civil penalties [whistleblower workplace retaliation]. (\"(a) An employer, or any person acting on behalf of the employer, shall not make, adopt, or enforce any rule, regulation, or policy preventing an employee from disclosing information to a government or law enforcement agency, to a person with authority over the employee, or to another employee who has authority to investigate, discover, or correct the violation or noncompliance, or from providing information to, or testifying before, any public body conducting an investigation, hearing, or inquiry, if the employee has reasonable cause to believe that the information discloses a violation of state or federal statute, or a violation of or noncompliance with a local, state, or federal rule or regulation, regardless of whether disclosing the information is part of the employee's job duties. (b) An employer, or any person acting on behalf of the employer, shall not retaliate against an employee for disclosing information, or because the employer believes that the employee disclosed or may disclose information, to a government or law enforcement agency, to a person with authority over the employee or another employee who has the authority to investigate, discover, or correct the violation or noncompliance, or for providing information to, or testifying before, any public body conducting an investigation, hearing, or inquiry, if the employee has reasonable cause to believe that the information discloses a violation of state or federal statute, or a violation of or noncompliance with a local, state, or federal rule or regulation, regardless of whether disclosing the information is part of the employee's job duties. (d) An employer, or any person acting on behalf of the employer, shall not retaliate against an employee for having exercised his or her rights under subdivision (a), (b), or (c) in any former employment. . . . (h) An employer, or a person acting on behalf of the employer, shall not retaliate against an employee because the employee is a family member of a person who has, or is perceived to have, engaged in any acts protected by this section.\")\n- Government Code 12940 GC -- Employers, labor organizations, employment agencies and other persons; unlawful employment practice; exceptions [FEHA workplace retaliation]. (\"It is an unlawful employment practice, unless based upon a bona fide occupational qualification, or, except where based upon applicable security regulations established by the United States or the State of California: . . . (h) For any employer, labor organization, employment agency, or person to discharge, expel, or otherwise discriminate against any person because the person has opposed any practices forbidden under this part or because the person has filed a complaint, testified, or assisted in any proceeding under this part.\")\n- Government Code 12940 GC -- Employers, labor organizations, employment agencies and other persons; unlawful employment practice; exceptions [workplace retaliation for requesting reasonable accommodation]. (\"(l) . . . (4) For an employer or other entity covered by this part to, in addition to the employee protections provided pursuant to subdivision (h), retaliate or otherwise discriminate against a person for requesting accommodation [for religious practices] under this subdivision, regardless of whether the request was granted. . . .(m) . . . (2) For an employer or other entity covered by this part to, in addition to the employee protections provided pursuant to subdivision (h), retaliate or otherwise discriminate against a person for requesting accommodation [for disability] under this subdivision, regardless of whether the request was granted.\")\n- Government Code 12653 GC -- California False Claims Act workplace retaliation. (\"(a) Any employee, contractor, or agent shall be entitled to all relief necessary to make that employee, contractor, or agent whole, if that employee, contractor, or agent is discharged, demoted, suspended, threatened, harassed, or in any other manner discriminated against in the terms and conditions of his or her employment because of lawful acts done by the employee, contractor, agent, or associated others in furtherance of an action under this section or other efforts to stop one or more violations of this article. (b) Relief under this section shall include reinstatement with the same seniority status that the employee, contractor, or agent would have had but for the discrimination, two times the amount of back pay, interest on the back pay, and compensation for any special damages sustained as a result of the discrimination, and where appropriate, punitive damages. The defendant shall also be required to pay litigation costs and reasonable attorneys' fees. An action under this section may be brought in the appropriate superior court of the state. (c) A civil action under this section shall not be brought more than three years after the date when the retaliation occurred.\")\n- Labor Code 1102.5 LC -- Employer or person acting on behalf of employer; prohibition of disclosure of information by employee to government or law enforcement agency; suspected violation or noncompliance to federal or state law; retaliation; civil penalties [whistleblower workplace retaliation], endnote 1 above.\n- Government Code 12940 GC -- Employers, labor organizations, employment agencies and other persons; unlawful employment practice; exceptions [FEHA workplace retaliation], endnote 2 above; Government Code 12940 GC -- Employers, labor organizations, employment agencies and other persons; unlawful employment practice; exceptions [workplace retaliation for requesting reasonable accommodation], endnote 3 above.\n- Judicial Council of California Civil Jury Instructions (\"CACI\") 2505 -- [FEHA Workplace] Retaliation—Essential Factual Elements (Gov. Code, § 12940(h)). (\"[Name of plaintiff] claims that [name of defendant] retaliated against [him/her] for [describe activity protected by the FEHA]. To establish this claim, [name of plaintiff] must prove all of the following: 1. That [name of plaintiff] [describe protected activity; 2. [That [name of defendant] [discharged/demoted/[specify other adverse employment action]] [name of plaintiff];] [or] [That [name of defendant] subjected [name of plaintiff] to an adverse employment action;] [or] [That [name of plaintiff] was constructively discharged;] 2. That [name of plaintiff]'s [describe protected activity] was a substantial motivating reason for [name of defendant]'s [decision to [discharge/demote/[specify other adverse employment action]] [name of plaintiff]/conduct]; 3. That [name of plaintiff] was harmed; and 4. That [name of defendant]'s decision to [discharge/demote/[specify other adverse employment action]] [name of plaintiff] was a substantial factor in causing [him/her] harm. [[Name of plaintiff] does not have to prove [discrimination/harassment] in order to be protected from retaliation. If [he/she] [reasonably believed that [name of defendant]'s conduct was unlawful/requested a [disability/religious] accommodation], [he/she] may prevail on a retaliation claim even if [he/she] does not present, or prevail on, a separate claim for [discrimination/harassment/[other]].]\")\n- Government Code 12652 GC -- Qui tam lawsuits.\n- Government Code 12653 GC -- California False Claims Act workplace retaliation, endnote 4 above.\n- Labor Code 2699.3 LC -- Requirements for aggrieved employee to commence a civil action [under LC 1102.5 whistleblower workplace retaliation law].\n- Government Code 12965 GC -- Civil action in name of department; group or class complaint; relief; tolling of statute of limitations [FEHA workplace retaliation lawsuits].\n- Government Code 12653 GC -- California False Claims Act workplace retaliation, endnote 4 above.\n- See, e.g., Judicial Council of California Civil Jury Instructions (\"CACI\") 3905A. Physical Pain, Mental Suffering, and Emotional Distress (Noneconomic Damage [in workplace retaliation cases]). (\"[Insert number, e.g., \"1.\"] [Past] [and] [future] [physical pain/ mental suffering/loss of enjoyment of life/disfigurement/physical impairment/inconvenience/grief/anxiety/humiliation/emotional distress [insert other damages]]. [To recover for future [insert item of pain and suffering], [name of plaintiff] must prove that [he/she] is reasonably certain to suffer that harm.] No fixed standard exists for deciding the amount of these damages. You must use your judgment to decide a reasonable amount based on the evidence and your common sense.\")"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:f8fc0eb0-f85c-4e78-8cb2-80fe7f9ef269>","<urn:uuid:6705d2a3-7599-4759-9b1e-8e42c29d06d3>"],"error":null}
{"question":"How do modern GPS-equipped agricultural spraying systems compare to traditional manual spraying methods in terms of precision and efficiency?","answer":"Modern GPS-equipped spraying systems offer significant advantages over traditional manual methods. GPS systems enable automatic rate and section control capabilities, allowing different application rates across fields to adapt to varying soil conditions and automatically shutting off in already-applied areas to prevent overlap and over-application. These systems can perform precise row guidance based on crop location. Additionally, they can integrate with virtual terminals to reduce the number of displays in the cab and simplify operations. Traditional manual spraying methods, as seen with knapsack pumps, rely on operator judgment for application rates and coverage, using high-volume applications that require more water (400 liters per hectare) and provide less uniform coverage with larger droplet sizes of 200-400 microns.","context":["GPS systems have changed production agriculture in planting, material application and harvesting, and a number of companies have come out with innovative products to better help row crop production.\nPotato farmers are no different from row-crop farmers when it comes to technology. When it comes to planting, the most accurate guidance solution is very important to these customers.\n“GPS systems are evolving more than people think,” said Cody Light, strategic marketing manager for AGCO. “More autonomous features are coming to the market to make things easier for the user: the ability to turn hands-free at the end of the field all the way to having fully autonomous tractors.”\nPlanting has seen a tremendous impact from precision agriculture technologies. The rate and section control capabilities on the planters give the grower the ability to rate the product differently across the field to adapt better to the different soil conditions throughout.\n“The section control functionality allows the row units to shut off automatically in already planted areas, allowing the operator to save input costs but ultimately allowing the plants to have the correct spacing and not over plant, which will help with the yield come fall time,” Light said.\nJay Beedy, marketing manager of Micro-Trak Systems, said one of the latest trends in GPS is the availability of ISO systems to allow the operator to use the existing virtual terminal as the user interface and display for all monitoring and control operations.\n“This cuts down on the number of displays in the cab and multiple learning curves associated with multiple consoles,” he said. “With the availability of ISO control modules, the grower can now select the control capabilities he needs with the confidence to know it will work with their existing control platform. With this open communication, the best monitor and control solution can be selected for the needs.”\nMike Martinez, marketing director for Trimble’s agriculture division, noted one of the trends the company has been tracking for a few years is the increased use of smartphones and tablets in the cab for agricultural technology purposes.\n“This trend is not slowing; in fact, there are more software developers building new farming-specific apps for these devices every year,” he said. “In order to increase the versatility of in-cab technology, Trimble’s TMX-2050 display is based on the popular Android technology and is specifically designed to accommodate farmers’ favorite farming apps directly into the display, eliminating the need for farmers to add multiple devices into an already cluttered cab.”\nA benefit of going with the Android technology, he added, is that it is inherently built to be a wireless productivity and communication tool, which is what is needed in agriculture to support farmers’ needs to send and share important production data to employees and advisers.\nPiecing together the technology that works effectively is a daunting task, which is why farmers need to research not only the correct technology but technology that is backed by a world- class support system.\n“Mobile app supporting displays allow potato farmers to plant potatoes in a very straight, controlled and repeatable fashion that is then stored in memory,” Martinez said. “Trimble has got a proven recipe for technology that potato farmers have already been using for years. Once the right equipment is in place, using the system is the easy part.”\nFarmers can keep their tractor and implement on the same guidance line with Trimble’s TrueTracker, which is an active implement guidance system that allows the implement to guide itself independently of the tractor. It uses the tractor’s autopilot system to monitor the implement and signal it to follow the correct path during periods of drift.\n“Our premier TMX-2050 display includes a marketplace where farmers can browse and download Trimble apps as well as third-party Trimble-approved apps,” Martinez said. “By accessing the apps that are most useful to their farm operation, language and regional compliance requirements, farmers can customize their experience and benefit from improved productivity, streamlined workflows and better data management.”\n“The FieldStar Live system on the all new Gleaner S9 machines has also been a huge success for accuracy and ease of operation,” Light said. “The ability to have the yield and moisture information in the same terminal as the all new state of the art guidance system has been a huge success with the harvesters.”\nAccording to Beedy, Micro-Trak has a great offering for potato grower applications. The Micro-Trak Dual ISO Mod is an ISOBUS compatible system that can monitor and control a single product or dual products simultaneously yet independently.\n“Our Dual ISO Mod has many capabilities that are customized for specific needs. With the Dual ISO Mod, the grower can achieve premier product control with the abilities to extend their application range without having to change plumbing or any settings,” Beedy said. “The Dual ISO Mod can be paired with our SafeGuard ISO Mod to give the grower individual electronic row monitoring of liquid application, ideal for fertilizer, micro- nutrients, fungicides, insecticides, etc., with abilities to achieve low-end and high-end rates.”\nMaterial Application and Harvesting\nWith sprayer and fertilizer application, whether it be liquid or dry, there have been a lot of changes over the years.\n“Just like planters, they have the capability to rate differently throughout the field, as well as shut off automatically in already applied areas,” Light said. “This also helps with overlap and over- application. It is also expanding into row guidance products in the sprayer market. This gives the grower the ability to steer automatically, based upon where the row of the crop is.”\nThis is extremely helpful for applicators that don’t have the as- planted lines, or weren’t using RTK (real-time kinematic) accuracy when seeding or planting.\nWith harvesting, yield monitors have seen tremendous improvement.\n“AGCO has partnered with Ag Leader, which gives our growers the opportunity to get Ag Leader yield and moisture sensors from the factory on our combines,” Light said. “With this option, they can use the sensors through the AGCO terminal, or put in an aftermarket Ag Leader terminal that they may already have. In the guidance world, we have seen row guidance for corn heads in the past few years take off. This truly helps in down corn situations, as well as custom harvesters who might not have the as-planted lines.”\nMartinez said that once planted with Trimble, precise records of exactly where the potato rows are located are then used by future activities such as nutrient and chemical application; then ultimately for the harvester. This is important because precise knowledge of where those potatoes exist under the surface of the soil allow the harvester to dig the crop in the right spot with very little or no damage, saving the farmer significantly.\nA Look Ahead\nThe future of products and services for row crop production is always advancing. Other than improved compatibility with other industry devices, one of the most significant trends expected in the years ahead is a move to more “off- board” technology.\n“What that means is that advancements in wireless data handling and farm management systems will continue to make farmers’ lives in the cab more productive and much more connected with their agronomists and overall farm management practices,” Martinez said.","During my travels, at the end of the field demonstrations with the mist sprayer, one of the most common questions that people ask (except for how much is the machine) is the following:\nWhat is the difference between the mist sprayer and the knapsack pump?\nAlthough the purpose of both machines is the treatment with phytosanitary products, their functioning is very different.\nThe knapsack pump (both manual and engine version) generates a pressure inside the tank which pushes the product, through an exit pipe, towards the nozzle that sprays on the crops to be treated. The treatment called high volume occurs with drops not uniform and with big dimensions 200-400 microns; they covers only a part of the leaves because the drops too heavy fall to the ground.\nThe mist sprayer is equipped with a fan that generates a great volume of air that is conveyed, through a pipe, to the exit nozzle at the bottom of the throwing pipe; thanks to its high speed (125 meters/sec, about 450 km/h), the product is nebulized in drops of an average size of 90 100 microns (one micron = 0,001 millimeters) and carried towards the crops. This system called low volume allows to obtain a treatment with greater protection, because the uniform micronization of the drops, combined with the action of the air that moves the leaves, creates a patina of product in the upper and lower part of them.\nDuring the demonstrations in the field, to verify the distribution, some hydro-sensitive paper is placed between the leaves: this paper has the property of changing color with the contact of water, showing the distribution obtained.\nThe mist sprayer also allows to work with a more concentrated product (therefore using a fewer quantity of water).\nFor example, treating one hectare of cultivation with the knapsack pump need approximately 400 liters of water, with the mist sprayer is possible to perform the same work with a quantity which can vary from 100 to 150 liters; of course these values are purely indicative because they may change depending on the type of crop, its inflorescence, type of the ground, etc..\nFurthermore the Cifarelli mist sprayer, using the great speed of the air flow, obtains a valid covering (98%) of the leaves up to a distance of 10/11 meters, horizontally and / or vertically.\nThe mist sprayer is more effective in applications of phytosanitary products in agriculture and insecticides treatments in public hygiene.\nThe knapsack pump is suitable in the herbicide treatment, because the size of the drop is appropriate to penetrate the ground and to attack the roots of infesting grasses.\nHow to use the mist sprayer?\nThe mist sprayer is placed on shoulders, adjusting the length of the shoulder straps, so that the machine is well adherent to the back and shoulders.\nThe throwing tube has to be addressed towards the parts to be treated, regulating the liquid cock and the revolutions of the engine (rpm) to obtain the dimension of the drops you need:\n- use the wide spray jet to obtain a large range;\n- use the spray jet (without wide spray jet) to obtain a long range.\nHow to address the product flow?\n- By executing an elliptical rotation from right to left side while treating in open field (vegetables, potatoes, salad, etc.).\n- By executing an “U” while treating plants, espalier cultivations and walls for disinfestations.\nHow to adjust the product flow?\n- The quantity of product distributed is adjustable by regulating the 5 positions of the cock presents on the throwing tube (position 1 of the cock delivers 0.14 L / min while in position 5 are 3.60 L / min, speaking of a mist sprayer without booster pump ). Greater is the amount of product, bigger will result the drops:\n- position 1 – maximum acceleration: smaller drops;\n- position 2,5 – ¾ of acceleration: medium drops (100-120 microns).\nBefore leaving, I remind that there are some recommendations to follow while working with a mist sprayer (and knap sack pump):\n- safeguard your person by wearing a breathing protection mask, safety glasses, hearing protection systems, gloves and protection boots;\n- avoid treatments in presence of strong wind;\n- it’s not recommended the treatment in the warmer hours of the day, to avoid the rapid evaporation of the drops;\n- never point the throwing tube toward people, animals or inhabited places;\n- at the end of the treatment wash yourselves and the clothes worn.\nFor the mist sprayer exist accessories for adjusting the amount of product dispensed, inclined grids, double output and other devices that will be described soon."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:2a7cb727-68a0-4528-90be-7a75eeac3639>","<urn:uuid:5a627165-0962-43d8-aec6-6bfa4ce608ee>"],"error":null}
{"question":"What specific resources are available at the Writing & Communication Center for improving oral communication?","answer":"The Writing & Communication Center offers a Conversation Partners program for practicing English and building confidence in conversational skills. They also provide support for preparing presentations, job interviews, workshops, and conference presentations, including help with idea development, concept articulation, and pronunciation correction.","context":["From the ESL Student Handbook, by Young-Kyung Min, PhD\nDo you want to improve your English speaking abilities? Check out these resources and strategies you can use to improve your oral communication skills.\nYou will quickly find that class participation is an important part of coursework in most of your classes. Participating in class discussions can be quite challenging for many international students. The learning culture in the classroom across the world differs widely. In certain countries, students are not encouraged to speak up and ask their instructor questions; students are supposed to digest the delivered information from their instructor and to demonstrate their mastery of the material only through written tests. There is not much interaction between students and the professor in the classroom. The old saying in Asia “Silence is Gold” is deeply embedded in the learning cultures of some countries.\nThe classroom culture in the US can be quite different from that of your home country. Students in the US are constantly encouraged to participate in class by asking questions and making comments on professors’ statements and other classmates’ thoughts and reactions. A student’s verbal participation in class is valued as an important criterion to evaluate a student’s learning in the classroom. Thus, it is very important to improve your oral communication ability in English. There are several resources and strategies you can use to improve your oral communication skills.\nWriting to Speak & Speaking to Write\nMost classes have reading responses as course assignments. You can use your reading responses as springboards for your participation in class activities as well as for your writing assignments. You may have already found that when you write down what you want to say, you feel more confident (or at least less nervous) when you talk in class or make a presentation. This is the key idea of “writing to speak.”\nSo, you should be actively engaged in your reading process by writing in the margins or on sticky notes, which is called “annotations.” Annotating while you read can give you multiple benefits. As you write in the margins or on sticky notes underlining certain words or sentences, you become more actively engaged in your learning process. The annotation process can also help you stay focused during reading and recognize the patterns or methods of argument used by the author in the article, which will eventually help you develop your own argumentation style. See the section on \"Reading Strategies\" for further information.\nAnother effective way to improve your oral communication ability is to work with your learning group members—the students you meet in your reading group, writing group, and conversation group. The group members can be a great audience for you to practice articulating your thoughts in English (e.g., summarizing the key ideas of an article you have just read). You can also ask for help to better understand certain concepts you are struggling with or simply check pronunciations of certain words. It is also a great idea for you and your group members to take turns rehearsing upcoming class presentations.\nListening to a variety of accented Englishes (really, it’s World Englishes) will greatly improve your listening skills. Remember that your group members can be a very important part of your enculturation process in the US. So, try to engage in social and academic activities with them as opportunities arise. This will be helpful not only to expand your knowledge of the English language but also to enhance your awareness of the cultures of the US and the US university lives as well.\nOral Communication Skills & the Writing & Communication Center\nThe Writing & Communication Center can also be a very useful resource to improve your oral communication skills. The Writing & Communication Center offers a “Conversation Partners program” to provide international students with the opportunity to practice speaking English, expand their vocabulary, and gain confidence in their conversational skills. Please use our online schedule to make an appointment.\nYou can also utilize the Writing & Communication Center as you prepare for your presentations. The tutors can help you develop your ideas, articulate concepts or perspectives, or simply pronounce certain words correctly. You can use the Writing & Communication Center not only for your class presentations but also for your job interviews, workshops, conference presentations, etc.\nYou will learn that the process of engaging other people in the preparation of your speaking assignments can also help you become a better writer (this is the key idea of “speaking to write”). Therefore, you should approach your speaking assignment as an interrelated task to your writing assignment; the idea of “writing to speak” is deeply interconnected with the idea of “speaking to write.”\nCampus Events & Workshops\nYou can also utilize the campus events and resources to enhance your oral communication skills. A variety of events and workshops take place each quarter to facilitate international students’ language acquisition process as well as enculturation process. Please try to attend some of the events and workshops in your first year (e.g. Intercultural Coordinators, Dine & Dialogue Series, World Languages Café, Cross-Cultural Engagement Retreat, and so on). Further information about these events will be available on the website on Student Life & Diversity. Your active participation in the events and workshops can help not only improve your speaking abilities but also help you better understand US university life and culture. In addition to the campus resources and events, you should also utilize various toastmaster clubs that are available in your community. When it comes to improving your oral communication skills, remember that “practice makes perfect.” The more you practice, the more confident and fluent you will become as a speaker and presenter.\nOral Presentations & Key Points to Remember\nHere are more practical strategies you can use when you prepare for your presentations. The key considerations of written communication—your awareness of audience, purpose, topic, genre, and style—also apply to oral communication. When you begin to prepare for your presentations, ask the following questions:\nPurpose: What is the purpose of my presentation? What is the main message that I want to deliver to the audience? How can I achieve the main purpose of my presentation?\nTopic: How much do I know about the topic? Where can I find more information about the topic? Who can help me to enhance my understanding of the topic?\nAudience: How much knowledge does my audience have about my topic? What should I prepare to help my audience better understand my topic?\nStyle: What style (or format) am I going to use for my presentation (e.g. PowerPoint, Poster, Performance)? How much time do I need to prepare my presentation on the chosen style?\nIf you think that you do not have a good understanding of the topic of your presentation as of yet, you should do more in-depth research about the topic and talk with your instructor, librarians, classmates, or writing center tutors. If it is a group presentation, you should go through the list with your group members and check each group member’s work in relation to the assignment goals.\nJust as there are different genres in written communication, there are also different genres in oral communication (e.g. seminars, class presentations, group discussions, conference presentations, colloquiums, workshops, job talks, role plays, interviews, etc.). Mini-workshops to improve your English pronunciation as well as presentations skills for your job interviews, workshops, and conference presentations may be offered in the future, so please visit this website for additional information.\nCreated by Young-Kyung Min, Ph.D."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:8ace09dc-5e77-4e25-badf-917a3e3c5bc2>"],"error":null}
{"question":"How do water hyacinth and zebra mussels affect recreational activities in waterways?","answer":"Water hyacinth creates thick mats that make it difficult for boats to pass through and can entangle hunting dogs retrieving ducks. It also shades out vegetation that waterfowl and young fish depend on. Zebra mussels, on the other hand, attach to boats and motors reducing their performance, clog intake pipes, and their sharp shells can cut swimmers' feet. They also attach to boat hulls, piers, and beaches, impeding recreational activities and requiring boats to undergo cleaning and disinfection procedures before moving between water bodies.","context":["From zebra mussels to water hyacinth, invasive species sabotage outdoor enthusiasts nationwide.\nWater hyacinth (below) is one of scores of invasive species challenging hunters (such as this duck hunter in Texas) and other outdoor recreationists.\nDUKE TOOK OFF RUNNING. His task: to retrieve the duck his owner had just shot. But the Louisiana pond where the bird landed was topped by a thick mat of water hyacinth, an invasive plant from South America, and the lab quickly got entangled. “I wondered if I’d have to fetch my own duck,” recalls hunter Mike Carloss, “and rescue my dog at the same time.”\nAnyone slogging through a Louisiana wetland these days will likely grapple with water hyacinth or , another much-maligned South American species. Both have spread wildly through southern states. “It’s brutal stuff to walk through, and pushing a boat through [the plants] is my idea of hell,” says Ducks Unlimited Chief Scientist Tom Moorman. These invasives also shade out submerged vegetation that ducks and young fish rely on, he says, and as shallow-water habitat disappears, so do waterfowl.\nFrom coast to coast, thousands more invasive species are transforming ecosystems along with human experiences in nature. Across the Mid-Atlantic, nonnative ticks are bringing pathogens from afar into parks and other popular outdoor spaces. Eurasian mussels are clogging boat engines and disrupting fisheries in the Great Lakes. Parasite-carrying European snails are killing beloved scaup ducks in the Mississippi River. And Eurasian cheatgrass is supplanting sagebrush across the West, hindering hikers, reducing biodiversity sought by wildlife watchers and contributing to the decline of mule deer, the region’s top-hunted animal.\nAs nature suffers, so do economies that rely on outdoor recreation. According to the U.S. Department of Commerce, the industry contributed $412 billion in 2018 as more than 102 million Americans over age 16 fished, hunted, bird-watched or engaged in other wildlife-related activities—spending nearly $160 billion on travel, gear and fees. Infested states, meanwhile, claim hundreds of millions in losses, which trickle down to local businesses. Take the decline of mule deer. “The deer hunt was once a major economic driver rurally in Nevada, Utah and Colorado,” says Miles Moretti of the Mule Deer Foundation. “That’s changed, with sometimes huge financial losses for gas stations, hotels and restaurants that used to rely on that hunt.”\nAquatic invasives can be particularly pernicious. Consider the Great Lakes, which suffer more than 180 nonnative species. Many, including zebra and quagga mussels, were introduced when Eurasian cargo ships released ballast water at U.S. ports. The animals—which now cover lake bottoms, boat hulls, piers and beaches—have transformed an ecosystem that supports commercial and sports fisheries estimated to be worth $7 billion. The mussels’ filter-feeding habits may have made lake waters clearer, but their sharp shells impede beach use, and “invasive mussels reduce nutrients and eat phytoplankton,” says Bo Bunnell of the U.S. Geological Survey, “which leaves less energy at the top of the food web” to support big fish like salmon while fouling spawning grounds of other angler favorites such as lake trout. “At one point there were more sport-caught Chinook salmon on Lake Michigan than anywhere in world,” says Denny Grinold, a charter-boat captain for 35 years. “Today we get 70 percent fewer fish than in 2012.”\nWhen it comes to invasive species, “everyone has a stake, and everyone shares responsibility,” says Aaron Kindle, manager of the National Wildlife Federation’s Western Sportsmen’s Campaign. Once these species enter the country through trade and travel, “there’s a lot of unintentional movement by regular people,” adds Leigh Greenwood, director of The Nature Conservancy’s Forest Health Program. “By transporting firewood, riding a bike on a trail, even moving across country with your lawn chairs and garden gnomes, you could accidentally spread something incredibly destructive.” From their wet boat rigging to muddy tires, boots and dogs, nature lovers unwittingly can be the most egregious vectors. “That’s why it has to be all hands on deck to combat the problem,” Kindle says.\nLuckily, many hands already are on deck. Most state and national parks now promote boat-disinfecting campaigns to fight waterway cross contamination, and some require boat inspections. Similar codes ask users to clean boots, tents and other gear on site. “The rules do impact the freedom of recreationists: You can’t just willy-nilly hop from lake to lake to catch the sunset,” says National Oceanic and Atmospheric Administration biologist Ashley Elgin. “But we need that kind of vigilance.”\nMost recreationists seem game to boost protective efforts. “I’ve never heard anglers grumble about cleaning or paying extra” related to invasive species, says Kindle. “The only complaint I hear is that we aren’t doing enough to solve the problem.”\nIndeed, with so much at stake, education campaigns and protective measures are multiplying across the country. Outdoor enthusiasts “aren’t simply going to give up their sports” because of these trespassers, says Kindle. Instead, many realize that playing in nature today has big-picture consequences—and requires scrubbing boots, boats and even the family dog before moving on.\nFive ways to participate in the 10th annual celebration!Read More\nTake the Clean Earth Challenge and help make the planet a happier, healthier place.Learn More\nPromoting more-inclusive outdoor experiences for allRead More\nA groundbreaking bipartisan bill aims to address the looming wildlife crisis before it's too late, while creating sorely needed jobs.Read More\nMore than one-third of U.S. fish and wildlife species are at risk of extinction in the coming decades. We're on the ground in seven regions across the country, collaborating with 52 state and territory affiliates to reverse the crisis and ensure wildlife thrive.","Zebra mussels are spread to new waters largely by contaminated boats and water-related equipment. Once zebra mussels become established they cannot be gotten rid of, so it is extremely important to stop their spread.\nHow to Stop the Spread of Zebra Mussels\nAdult zebra mussels have a hard shell and attach to anything that sits in the water. This includes boats, canoes, trailers, float planes, buoys, fishing equipment, etc. They can survive out of water for 7 to 30 days depending on temperature and humidity.\nLarval zebra mussels, called veligers, passively move downstream by water movement and are invisible to the naked eye. Veligers rely on water to survive thus they can be inadvertently carried in small amounts of water transported by un-drained watercraft, water-based aircraft, off road vehicles and water-based equipment such as bait buckets.\nAlways clean, drain and dry your watercraft, trailer, float plane and all water-related equipment when leaving a lake or river. Drain or empty any standing water away from storm sewers, lakes and rivers. Dispose of any unwanted bait in the trash, not in the water.\nFor more details on how to stop the spread of aquatic invasive species go to the Manitoba Government's website at www.gov.mb.ca/stopthespread/ais/how.html\nWhy do we need to be concerned about zebra mussels and other aquatic invasive species?\nZebra mussels are a highly adaptable, non-native species that are a significant environmental and economic concern to Manitoba.\n- They disrupt ecosystems by eating food that other species rely on and changing the quality of the water\n- They can attach to and smother other mussels\n- They attach to boats and motors reducing performance and efficiency\n- The sharp shells attach to rocks, rafts and ladders and can cut swimmer's feet\n- They can clog intake and drainage pipes\nWhat are Invasive Species?\nOrganisms (animals, plants, parasites, viruses, etc.) not native to a region that when introduced, either intentionally or accidentally, out-compete native species for available resources. Invasive species become successful in their new environments due to their high reproductive rates and absence of native predators and diseases. Invasive species can have negative economic, social, environmental and human health implications.\nWhat are Aquatic Invasive Species (AIS)\nAn aquatic invasive species (AIS) can either live in freshwater or marine environments. Most of the species of concern to Manitoba, such as Zebra and Quagga mussels, Spiny Waterflea, Rusty Crayfish and Asian Carp are freshwater species. Manitoba currently has 15 aquatic invasive species. This number is small compared to the number of aquatic invasive species found in the Great Lakes (greater than 200) and Mississippi (greater than 120) drainage basins.\nZebra Mussels in Manitoba\nZebra mussels were confirmed in Lake Winnipeg in the fall of 2013 and the Red River and Cedar Lake 2015.\nZebra mussels are small (1-3cm), clam-like freshwater aquatic animals native to Eastern Europe and Western Asia. They are highly adaptable. The female lays about one million eggs per year. Their lifespan is 2-5 years. They can adhere to hard surfaces.\nZebra mussels have caused millions of dollars in damage to the Laurentian Great Lakes area and have cost the North American economy billions of dollars to control. They were first found in North America in 1988 in Lake St. Clair which straddles the US and Canadian border in Michigan and Ontario.\nDespite the successful eradication of zebra mussels in the four treated harbours in Lake Winnipeg in 2014, Zebra Mussels were found elsewhere in the south basin and are successfully reproducing. Lake Winnipeg is in the early stages of invasion by zebra mussels - eradication is no longer an option.\nThe Riding Mountain UNESCO World Biosphere Reserve (RMBR) has developed an \"Online information kit\" that includes key link to Manitoba aquatic invasive species information sources posted by other jurisdictions, which are also striving to stop the spread at Spread the Word, Not the Mussels Information Kit"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:156446c5-004c-428e-9ae9-8ac92538f530>","<urn:uuid:5aabe6d9-bc6a-4aab-87fc-52850fe4f748>"],"error":null}
{"question":"What are main 4 types of levels used in construction entreprise?","answer":"The four main types of levels used in construction are: 1) Spirit (or Bubble) Levels, 2) Laser Levels, which project level planes onto surfaces, 3) Optical Levels, used by surveyors for establishing level planes over long distances, and 4) Water Levels, which are used to transfer levels between places but don't establish level planes.","context":["Getting things level (or vertical) is a critical part of any construction project and for a lot of home improvement ones too. The level is one of the most useful and important tools in any toolbox. The aim of this project is to explain which type of level you should use for different types of jobs and how to use a level effectively.\nWhat is a Level?\nAccording to the Encyclopaedia Britannica a Level is a:\ndevice for establishing a horizontal plane.\nThis is a clear definition as any; succinct and correct. Most levels can also be used to find a vertical plane also, generally in exactly the same way as finding the horizontal plan. There are many different types of levels that are used in different circumstances, of which the spirit level is one. We will cover the main types now.\nThe Different Types of Level Used in Construction and DIY\nBroadly speaking there are 4 types or groups of level that are commonly used in construction projects, although we are only going to focus on the spirit level in this project it is worth quickly mentioning the other types before we start:\nSpirit (or Bubble) Levels\nWe will explain the different types and also how to use a level in greater detail below.\nAs the name suggests this is a level that uses a laser to project the level on to the surface that you need to establish the horizontal plane. The more expensive and sophisticated devices will show the vertical plane also, which can be very helpful.\nWe will not cover these here, as we have an excellent project all about using laser levels that you should read.\nThese are tools that are generally used by surveyors and builders on larger construction sites where a level plane needs to be established over a long distance, such as across the whole building site.\nWhen using an optical level, the level plane is actually derived using a bubble in a vial and then using the lens it is transferred to the site.\nThis is one of the more simple and elegant solutions to transferring levels from one place to another, however they will not establish a level plane. We explain how to do this and even make your own in our project about water levels.\nHow does a Spirit or Bubble Level Work?\nThere is a small glass tube or vial containing alcohol with a little bubble sealed inside. The top of the vial or tube is ever so slightly bowed so that when the flat surface under the vial or level is absolutely horizontal the bubble will come to rest in exactly the middle of the tube or vial. This is usually marked with guide lines to make it easier to see.\nThe accuracy of the level is determined by how curved the top of the vial or glass tube. The “flatter” it is the more sensitive it is and therefore more accurate it will be (in the right hands).\nA tube vial will be able to show the level in one plane but will tends to be easier to use and more accurate for hand use. The different planes will all need to be checked separately; widthways then lengthways and ideally across the diagonal too to get a completely horizontal surface. (A cross check level is often used for this – see types of level below).\nWith a round bubble vial you can get the level in all planes in one go although they can be more fiddly to use without a firm base and a mechanism for fine adjustments, which is why they are most commonly used to level devices that have a tripod stand or similar stand.\nHow to use a Spirit Level\nThis is a quick step by step process for how to use a spirit level:\n- Place the level against the surface where you want to find the level. Ideally this should be smooth and flat so the level can be held securely to it without moving or wobbling\n- Move the level until the bubble in the vial or tube is exactly in the middle of the guide lines. Depending on the level you are trying to achieve this might mean moving the level itself, say against the wall if you are ensuring that pictures or sockets are at the same level, or moving the object the level in on to get it horizontal, such as a paver for a patio or perhaps a shelf\n- Check the bubble again, before marking the level if required\nMeasuring a Perpendicular or Plumb with a Spirit Level\nIn the same way a spirit level can be used to measure true vertical surfaces, or what is called plumb in the trade.\nThe same process is used however the level needs to have a vertical vial which will show the level of the perpendicular.\nMeasuring a Slope with a Spirit Level\nOn many occasions you want the surface to look level, but to actually be on a slight slope. This might be when laying a patio to ensure water runs off, or to have a slight slope in your screed.\nIf this is the case rather than ensuring that the bubble is in the exact centre of the vial, between the guide lines, the bubble should be slightly off centre. Here it helps if you have a vial with multiple guidelines so that you can ensure that the bubble is in the same place at all paced along your (slightly off) horizontal surface.\nOnce you have established the angle that you need the slope to be used can be transferred using the spirit level to ensure that you consistently keep to that slope.\nTIP: An old builders trick to getting the right level is to place the base of the spirit level in with the right level, then you can draw on to the top of the vial with a felt pen where the bubble comes to rest. Now as you work across the surface you can ensure that the level comes to the same point, so the bubble comes to rest at your felt pen mark. Remember to wipe the marks off when you are finished.\nSome spirit levels come with a 45o vial or even an adjustable vial. These can be used in the same way to establish the angle whether it is 45o or another angle set in the adjustable vial; you need to move the spirit level until the bubble is in the centre of the vial. At this point the level is at the required angle.\nHow to Check the Accuracy of a Spirit Level\nWhen you are looking to create a level, be it horizontally or vertically you need to be confident that the spirit level that you are using is accurate. The process for checking a level’s accuracy is very simple; effectively you are checking the level in two directions to see if there is a difference – the size of the difference is a measure of the inaccuracy, as ideally it should read the same in both directions.\nThis process works for all types of spirit levels, but you will need to check each vial or tube individually. Here are the steps for checking the accuracy of your spirit level:\n- Place the spirit level on a flat surface that is as near to level as you can conveniently find\n- Mark on the surface the end of the level and the side of the level\n- Check the position of the bubble – and remember exactly where it is\n- Turn the spirit level around by 180o and place it against the marks you made so it is in exactly the same position but just reversed\n- Check the position of the bubble (of the same vial if your level has more than one) – it should be in exactly the same position as when you first checked it relative to the level. Any difference is the degree of inaccuracy with that vial on the spirit level\nYou can use this same process for the vials used for measuring vertical surfaces in exactly the same way, only by placing the level against a vertical surface.\nIt is worth double checking your measurements twice so that you are sure of the accuracy.\nAs this is a very easy test, we recommend regular checks, certainly do it before you make a purchase, or if you have dropped or think you might have damaged it. We check our level before we start a job, especially if we know it is one where we need to be highly accurate.\nImportant Features of Spirit Levels\nBefore we get into the different types of levels, there are some important features to look out for and are common to all, as essentially the bubble is the part that all these types of level use to do their job.\nIf you are buying a level these are the features you should look out for:\nAll levels should have an accuracy tolerance which will be published for you to check before purchase. It is usually stated as “+ or – 0.Xmm per meter” so you can ensure you get the accuracy that you require\nThe bigger the better when it comes to the bubble as it is easier to see. The issue is that the bubble size is determined by properties of the liquid, which will expand and contract as it get hot and cold which affects the size of the bubble. The bubble should always remain inside the reading lines.\nThe sales patter will be about the liquids expansion confident and the guaranteed working temperatures. The better these are the more accurate but more expensive the level will be.\nMost levels nowadays have the liquid coloured so that it is easier to see the bubble. The colour will fade from the liquid over time and in the sun, but how long this takes is a mark of the quality, but of course you have no way to tell this in advance, except by a guaranty – and may be the price!\nThese are lines inserted into the tube or vial or in some cases they are painted. These need to be clear and easy to see without impacting the movement of the bubble.\nThe vial or tube is actually quite delicate and as such needs to be protected, however the level will be dropped and have a touch life especially if on a building site. The ends should be strong rubber or similar to reduce shock and the construction sturdy, but light weight. Look for shock proof vials and end caps when buying a spirit level.\nDepending on where you will be using your spirit level, you need the most robust body that you can get but will not damage the materials you are working with.\nBuilders will use robust aluminium levels, however if working with more delicate materials such as a work top you might consider a softer body made of something like plastic.\nFor accuracy, some aluminium levels will have one or more milled surface, which is a precision machined surface to ensure that the surface is absolutely flat and horizontal.\nUse and Grip\nYou need to be able to hold the spirit level in place to get an accurate reading so hand holds are helpful, particularly on the longer levels.\nThis is a feature that some levels will have and it is a groove in the surface of the level which is designed to fit against pipes of conduit so that you can ensure that they are fitted horizontally or perpendicular.\nSome levels have magnets within their bodies so that they can be “stick” to metal pipes, scaffold poles or other metallic surfaces. This means that they can be used “hands free”.\nThe Common Types of Spirit Level\nThere are a lot of different types of spirit levels. To make things even more confusing they also have different names often depending on who or what they are being used for or sometimes how they are constructed.\nHere are the most common types of spirit levels that you are likely to come across:\nCarpenters, Builders or Long Levels\n- i-beam levels: the frame of the level is an “i” shape when looking at its end. They are also called Girder Levels (because they look like a girder in cross section). They have similar uses to a box level but tend to be a slightly less sturdy, cost effective alternative. See our range of Girder levels here.\n- Box beam levels; also known as Box Level or Box Section because the frame is a rectangle, box shape. The best ones are not hollow but encase acrylic (or similar) to make them more robust. They are stronger than I-beam levels, but typically heavier. See more Box Levels here.\n- Torpedo levels: These are spirit levels that are ideal for keeping in a toolbox. They are slightly bigger than pocket-sized being 6 to 12 inches (15-30 cm) and typically with 3-vials. They are the generally purpose, all-rounder of the level world designed for use in tighter spaces\n- Scaffold Level: A specialist variation on the torpedo level is the Scaffold Level. As the name implies it is ideal for use when erecting scaffolding, but also used by plumbers and others working with pipes or metal surfaces. They have magnets to “stick” to the pipes. Sometimes called a Boat Level.\n- Pocket levels; these are small spirit levels as the name suggests, designed for quick use and often come with a belt clip mount and can be put in your pocket. Ideally they should have magnets and a v-groove for use with pipes and metallic surfaces.\nSpecialist Spirit Levels\n- Line levels; also called a String Level, these are a single vial with a hook so it can be hung on a string. They are for levelling across long distances, and this was a method that was used before laser levels were invented. Using a taught string tied between two points (so that there is no sag in the line), when the ends of the line are moved so that the bubble is in the middle of the guide lines, then the two ends (and all the line) are at the same level. The Line Level can be hung at either end of the line, whichever is more convenient, so long as the line is tight. They are ideal for getting a level for laying paving stones or for levelling ground\n- Cross check levels; Also known as 2D Levels or Right Angle Levels these are pocket sized levels with two vials at right angles to each other so that you can check the level in two planes at once\n- Circular levels; These are sometimes known as surface levels as they are useful for ensuring that a surface is level. They are most commonly found on devices that need to be levelled, such as a tripod for an instrument or camera\n- Post levels; This is a specialist level that is designed specifically for making sure that posts are plumb in all directions. The wrap around two sides of a post to measure the level in both horizontal planes. Most will have a third vial so that they can be used to ensure that horizontal rails, joists or other timbers, etc will be level.\n- Angle levels; these are levels that are designed to be used as on angles from the horizontal. They have an adjustable vial so that you can set the desired angle\nHome Made Levels\nIf you haven’t got a Spirit Level to hand or fancy making your own it is not actually that difficult. At the simplest you can put a marble or ball bearing on a flat surface and it will roll down any slope; when it does not roll away the surface is level.\nWater always finds a level so you know that the surface of standing water will be level. You can use this fact to find a level using a glass of water.\nSpirit Levels are a vital part of any toolkit but it is important to know how to use them and which type of level you should use. Hopefully this project has given you the confidence to get the right spirit levels for your needs."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:69d83e66-ca34-45f1-b229-f3b69f35fa31>"],"error":null}
{"question":"How do PCA plots in genetic studies compare to PCA plots in machine learning visualization - what are their key similarities and differences?","answer":"Both genetic and machine learning PCA plots serve to visualize high-dimensional data in 2D space, but they have some key differences in application. In genetic studies, PCA plots represent genetic distances between populations or individuals, visualizing relationships through scatter plots where points represent either population centroids or individuals. These genetic PCAs specifically measure differences across populations regarding their genetics. In machine learning, PCA is used more broadly as a dimension reduction technique that creates new axes (principal components) based on maximum variance in the data. The first principal component captures the most variation, followed by subsequent orthogonal components. While both approaches create visual representations of complex data relationships, genetic PCAs focus specifically on genetic distance matrices, while machine learning PCA is a more general statistical procedure for converting possibly correlated variables into linearly uncorrelated variables for dimension reduction and data visualization purposes.","context":["To the left is a PCA from The History and Geography of Human Genes. If you click it you will see a two dimensional plot with population labels. How were these plots generated? In short what these really are are visual representations of a matrix of genetic distances (those distances being general FST), which L. L. Cavalli-Sforza and colleagues computed from classical autosomal markers. Basically what the distances measure are the differences across populations in regards to their genetics. The unwieldy matrix tables can be visualized as a neighbor-joining tree, or a two dimensional plot as you see here. But that’s not the end of the story.\nIn the past ten years with high density SNP-chip arrays instead of just representing the relationship of populations, these plots often can now illustrate the position of an individual (the methods differ, from components analysis or coordinate analysis, to multi-dimensional scaling, but the outcomes are the same).\nFor example, the famous genetic map of Europe. Here you see the colors representing nationalities, and centroid positions of the populations as well as individuals. In this manner you can take into population genetic variation in a gestalt fashion. Nevertheless, these still leave something to be desired. They are precise and powerful, but they lack a certain elegance due to their scatter. When you have over a dozen color schemes, and overlapping populations, these are not minor matters. Additionally, the human eye is often not well tuned to note the finer gradients of density difference.\nThis is clear when you move from a manageable number of populations (e.g., Europeans), to the world. In these cases you have to color in specific regions, else you’d get lost rather quickly. I can illustrate this easy enough. I’ve a data set I’m running right now with ~3,000 individuals and 250,000 SNPs. It’s a merge of HGDP, Behar et al., HapMap, etc. I decided to use PLINK to generate an MDS plot.\nHere you see the unadorned scatter. To the top of the plot are Asian populations, and to the right African ones. Europeans are at the vertex to the bottom left. This should be familiar to you, though you may have to rotate it. One way to extract some clarity out of this picture is to color code the regions, and give different symbols to the lowest level category. Yes, this helps, but there are still limitations (and to be frank I often have a hard time making out triangles on these plots). First and foremost, I think we need to be unable to ascertain the variation in density of the scatter. A further plot will illustrate this (click to enlarge):\nMost of the text is basically illegible. This is where a centroid method would do well; in lieu of a scatter of individuals you just label a population. Or, you could do something like allow points in various colors to represent populations, but put the labels at centroids only. This still runs into the problem that populations are not equidistant, so therefore you can have crowding.\nRecently to address these issues I decided to use a ‘utilization distribution’ method which I saw in one of the ‘genetic map of Europe’ papers. The logic here is simple.\n1) First, take the density distribution of the points on the plot by category and ‘smooth’ them. Basically this creates a continuous distribution where there was a discontinuous ones.\n2) Then demarcate the central ~90% area as the bounds of the population distribution. Color these bounding lines differently.\nBelow you see the results:\nObviously there are some kinks to be worked out. But you see two things. First, some groups are clearly subsets of other groups in their distribution. This is very hard to discern in the other visualization methods above. Second, these plots are taking density into account, so you aren’t distracted by outliers (which may be mislabeling by the analyst or the original collector of the samples).\nMy ultimate aim is to develop a script which will place the text near the suitable distribution zone, without crowding out other text. I have some ideas of how to do this “on the fly,” but it will take time to implement. Until then some of you may want to know a bit about the packages used for the above.\nFirst, download the adehabitat package from R. Actually, you may want to download various tcl development packages first, because the former won’t install without the latter. Once you have that you need data. I assume you can generate the results from PLINK above. Once you have that you need to have three colums\n3) the identification\nHere’s some R that might help:\n#MDSData is the data frame with MDS data attach(MDSData) library(adehabitat) cexValue=0 par(mar=c(0,0,0,0)) plot(C1,C2,cex=cexValue,xlab=\"Coordinate 1\",ylab=\"Coordinate 2\") # process the data, remove more than 5 individuals in group loc=subset(MDSData,Group %in% names(which(table(Group) >= 5))) loc$X = loc$C1 loc$Y = loc$C3 #load ids id = factor(loc$Group) #create first parameter, two columns loc=subset(loc,select=c(X,Y)) vud=kernelUD(loc,id) #90% utilization kVert=getverticeshr(vud, 9); #I'm removing one of the populations kVert=NULL kVertLength=length(attr(kVert,\"names\")) plot(kVert, add=TRUE, lwd=2,colpol=NA,colborder=rainbow(kVertLength) ) groups=attr(kVert,\"names\") legend('topright',groups,cex=.55,lty=1,lwd=3,col=rainbow(kVertLength) )","PCA with Python | Principal Component Analysis Machine Learning | KGP Talkie\nPrincipal Component Analysis(PCA)\nAccording to Wikipedia, PCA is a statistical procedure that uses an\northogonal transformation to convert a set of observations of possibly\ncorrelated variables (entities each of which takes on various numerical values) into a set of values of linearly uncorrelated variables called\nThese are the new axes that descibe the\nvariation in the data.\n- Principal component 1: The axis which spans the\nmost variationof the data.\n- Principal component 2: The axis which spans the\nsecond most variationof the data.\n- Principal component 3: The axis which spans the\nthird most variationof the data and so on.\nWhen to use PCA\nWe can use PCA in the following cases:\n- Data Visualization.\n- It is used to find\ninter-relationbetween variables in the data.\nSpeedingMachine Learning (ML) Algorithm.\n- It’s often used to visualize\n- As number of variables are\ndecreasingit makes further analysis simpler.\nObjectives of PCA\nThe main objectives of the PCA are:\n- It is basically a\nnon-dependentprocedure in which it reduces attribute space from a large number of variables to a smaller number of factors.\nPCAis basically a\ndimension reductionprocess but there is no guarantee that the\n- Main task in this\nPCAis to select a subset of variables from a larger set, based on which original variables have the highest\ncorrelationwith the principal amount.\nHow to do PCA\nAs there are as many\nprincipal components as there are variables in the data, principal components are constructed in such a manner that the first principal component accounts for the largest possible\nvariance in the data set .\nThe second principal component is calculated in the same way, with the condition that it is\nuncorrelated with (i.e., perpendicular to) the first principal component and that it accounts for the next\nOnce fit, the\neigenvalues and principal components can be accessed on the PCA class via the\nPrincipal Axis Method\nPCA will search a\nlinear combination of variables so that we can extract\nmaximum variance from the variables. Once this process completes it will remove it and search for another\nlinear combination which will give an explanation about the maximum proportion of remaining\nvariance which basically leads to\northogonal factors. In this method, we analyze total\nFrom the following figure, I will make you understand how\nPCA works in a nutshell.\nThere are few steps, Let’s see one after other:\nIn the first step we have a\ncorrelated high dimenasion data. And then we calculate the\ncenter of the points and calculate\nvariance of the data by using\ncovariance matrix of the data and with this matrix we calculate\neigen vectors and\nAfter calculating these, we pick the value of\nm such that less than original dimension.\nThen after we will project\n` data points into thoseeigen vectors\nand we do the inverse transform so we will getuncorrelated low dimensional` data.\nThough mathematically it looks little bit complex but fortunately in python we have\nsklearn library there we have\nPCA package just we call\nPCA() and then call\npca.fit() as usual we do in ML algorithms.\nImporting required libraries\nimport pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt\nLoading the training data set\nfrom sklearn import datasets, metrics from sklearn.model_selection import train_test_split\ncancer = datasets.load_breast_cancer()\nLet’s go ahead and get the description the\nbreast cancer data set.\n.. _breast_cancer_dataset: Breast cancer wisconsin (diagnostic) dataset -------------------------------------------- **Data Set Characteristics:** :Number of Instances: 569 :Number of Attributes: 30 numeric, predictive attributes and the class :Attribute Information: - radius (mean of distances from center to points on the perimeter) - texture (standard deviation of gray-scale values) - perimeter - area - smoothness (local variation in radius lengths) - compactness (perimeter^2 / area - 1.0) - concavity (severity of concave portions of the contour) - concave points (number of concave portions of the contour) - symmetry - fractal dimension (\"coastline approximation\" - 1) The mean, standard error, and \"worst\" or largest (mean of the three worst/largest values) of these features were computed for each image, resulting in 30 features. For instance, field 0 is Mean Radius, field 10 is Radius SE, field 20 is Worst Radius. - class: - WDBC-Malignant - WDBC-Benign :Summary Statistics: ===================================== ====== ====== Min Max ===================================== ====== ====== radius (mean): 6.981 28.11 texture (mean): 9.71 39.28 perimeter (mean): 43.79 188.5 area (mean): 143.5 2501.0 smoothness (mean): 0.053 0.163 compactness (mean): 0.019 0.345 concavity (mean): 0.0 0.427 concave points (mean): 0.0 0.201 symmetry (mean): 0.106 0.304 fractal dimension (mean): 0.05 0.097 radius (standard error): 0.112 2.873 texture (standard error): 0.36 4.885 perimeter (standard error): 0.757 21.98 area (standard error): 6.802 542.2 smoothness (standard error): 0.002 0.031 compactness (standard error): 0.002 0.135 concavity (standard error): 0.0 0.396 concave points (standard error): 0.0 0.053 symmetry (standard error): 0.008 0.079 fractal dimension (standard error): 0.001 0.03 radius (worst): 7.93 36.04 texture (worst): 12.02 49.54 perimeter (worst): 50.41 251.2 area (worst): 185.2 4254.0 smoothness (worst): 0.071 0.223 compactness (worst): 0.027 1.058 concavity (worst): 0.0 1.252 concave points (worst): 0.0 0.291 symmetry (worst): 0.156 0.664 fractal dimension (worst): 0.055 0.208 ===================================== ====== ====== :Missing Attribute Values: None :Class Distribution: 212 - Malignant, 357 - Benign :Creator: Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian :Donor: Nick Street :Date: November, 1995 This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets. https://goo.gl/U2Uwz2 Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes. The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34]. This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\nThis data has\n30-dimensions that is\n30 features. Let’s visualize the data set with\ndf = pd.DataFrame(cancer.data, columns=cancer.feature_names) df.head()\n|mean radius||mean texture||mean perimeter||mean area||mean smoothness||mean compactness||mean concavity||mean concave points||mean symmetry||mean fractal dimension||…||worst radius||worst texture||worst perimeter||worst area||worst smoothness||worst compactness||worst concavity||worst concave points||worst symmetry||worst fractal dimension|\n5 rows × 30 columns\nIf we see here scale of the each feature is different that is dome features are in the range\n10s some are in\n100s. It is better to\nstandardize our data for better visualization.\nLet’s see the below code:\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler() X_scaled = scaler.fit_transform(df) X_scaled[: 2\narray([[ 1.09706398e+00, -2.07333501e+00, 1.26993369e+00, 9.84374905e-01, 1.56846633e+00, 3.28351467e+00, 2.65287398e+00, 2.53247522e+00, 2.21751501e+00, 2.25574689e+00, 2.48973393e+00, -5.65265059e-01, 2.83303087e+00, 2.48757756e+00, -2.14001647e-01, 1.31686157e+00, 7.24026158e-01, 6.60819941e-01, 1.14875667e+00, 9.07083081e-01, 1.88668963e+00, -1.35929347e+00, 2.30360062e+00, 2.00123749e+00, 1.30768627e+00, 2.61666502e+00, 2.10952635e+00, 2.29607613e+00, 2.75062224e+00, 1.93701461e+00], [ 1.82982061e+00, -3.53632408e-01, 1.68595471e+00, 1.90870825e+00, -8.26962447e-01, -4.87071673e-01, -2.38458552e-02, 5.48144156e-01, 1.39236330e-03, -8.68652457e-01, 4.99254601e-01, -8.76243603e-01, 2.63326966e-01, 7.42401948e-01, -6.05350847e-01, -6.92926270e-01, -4.40780058e-01, 2.60162067e-01, -8.05450380e-01, -9.94437403e-02, 1.80592744e+00, -3.69203222e-01, 1.53512599e+00, 1.89048899e+00, -3.75611957e-01, -4.30444219e-01, -1.46748968e-01, 1.08708430e+00, -2.43889668e-01, 2.81189987e-01]])\nPrincipal Component Analysis\nLinear dimensionality reduction using\nSingular Value Decomposition of the data to project it to a lower dimensional space. The input data is centered but not scaled for each feature before applying the\nPCA() function into training and testing set for analysis.\nLet’s discuss some important paameters of the function\nIt is a int, float, None or str.\nNumber of componentsto keep.\nIt is to pass an\nintfor reproducible results across multiple function calls.\nIt is provide the amount of\nvarianceexplained by each of the selected components.\nIt helps to fit the model with X and apply the\ndimensionality reductionon X.\nIt transforms data\nWe need to have\n2-dimensional data set so\nn_component is equal to\n2 and we can get same result\nrandom_state if we use same\nPCA function into training and testing set for analysis look at the following code:\nFit the model X_scaled by using\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2, random_state=42) pca.fit(X_scaled) PCA(n_components=2, random_state=42)\nTraining has been done now let’s go ahead to transform it with\nX_pca = pca.transform(X_scaled)\nSo we transformed the data into\nLet’s check the\nshape of both data sets:\n((569, 30), (569, 2))\nHere we can observe shape of default data is\n30 and after transformation it reduced to\nNow we will try to plot the\nscattering points for the second principal component and first principal component by using\nLet’s look into the following script:\nplt.figure(figsize=(12,8)) plt.scatter(X_pca[:, 0], X_pca[:, 1], c = cancer.target, cmap = 'viridis') plt.xlabel('First Principal Component') plt.ylabel('Second Principal Component') plt.title('Scatter plot for Second principal component and First principal component') plt.show()\nFrom the above plot we can observe, first principal component has\nhigh variance compared to second principal component.\nNow we will observe the respective\nvariances for the components by using bar graph.\nSee the following plot:\npca = PCA(n_components=20, random_state=42) X_pca = pca.fit_transform(X_scaled) variance = pca.explained_variance_ratio_ plt.ylabel('Variance') plt.xlabel('Principal components') plt.title('Bar graph for variances of the componets ') plt.bar(x = range(1, len(variance)+1), height=variance, width=0.7) plt.show()\narray([0.44272026, 0.18971182, 0.09393163, 0.06602135, 0.05495768,\n0.04024522, 0.02250734, 0.01588724, 0.01389649, 0.01168978,\n0.00979719, 0.00870538, 0.00804525, 0.00523366, 0.00313783,\n0.00266209, 0.00197997, 0.00175396, 0.00164925, 0.00103865])"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:7ae82716-a633-4da7-afed-fff1bd47d491>","<urn:uuid:7a82674f-b040-4f42-8190-2739c9a9f79f>"],"error":null}
{"question":"What is the South Omo Valley's location and which tribes inhabit it?","answer":"The South Omo Valley is located in southwest Ethiopia, forming part of the Great Rift Valley system. It is home to numerous traditional tribes including the Tsemay, Banna, Konso, Ari, Dassanitch, Arbore, Karo, Bumi, Surma, and Mursi. The Ari occupy the largest territory, extending from the northern border of Mago National Park to the highlands around Jinka, while the Dasanech live near the Omo River, having migrated from Kenya's Turkana region. The area contains six lakes: Ziway, Abiata-Shala, Langano, Awassa, Chamo, and Lake Abaya, which is one of the largest in the Rift Valley.","context":["Two Women, Two Tribes, and a Journey of a Lifetime is a 9-part series penned by Lim Ka Ea about her one year stint in Addis Ababa, Ethiopia where she accompanied her husband on his 9th humanitarian mission. No stranger to travel and humanitarian missions herself, she learned that Ethiopia is not really Africa and Africa is not really all about national parks or long distance-runners. She also learned that being a “tai-tai” is so overrated unless there is another “tai-tai” to get into mischief with. This 9-parter tells the story of how two “tai-tais” explored Ethiopia and discovered their life as both an individual and a woman. This weekly series started with Part I: My first encounter with Africa and Part II: The faces, sounds and smell of Addis Ababa.\nAs I was about to turn my back against Ethiopia, I was given an unexpected gift. A few months later, I met a young woman, whom I had a previous brief encounter with when I made a short trip to Kenya. She has just arrived in Ethiopia from Azerbaijan with her husband who is working in the same organisation as mine.\nI soon learned that she has taken up photography while she was living in Nairobi, accompanying her husband in his previous job. Like me, she had gone through longer period of lifestyle adjustment, depression and isolation as a result of moving from places to places, in support of her husband’s work.\nThis amazing photo of the elephants of Amboseli, Kenya won Irada an award. Click to enlarge image.\nIrada started developing her interest in photography after realising that in order for her to bounce back into life, she needed something which would serve a greater purpose in her life. I find Irada to be a remarkable and inspiring woman. Not only is she a devoted wife and a mother of two adorable children, she finds time to nurture her own personal interest. She intends to pursue a career in photography with the hope that one day, she will be able to discover and share her own vision of the world through her own lens.\nHer story of courage, strength, determination and optimism provided me with renewed hope and enthusiasm about my own role in Ethiopia. I realised that I had been too busy drowning myself in personal discontentment which had in turn blinded my ability to discover a higher sense of purpose in my life there.\nInstead of doing something, I had reduced myself to just being “the unemployed wife.”\nThe opportunity for me to do something arrived when Irada suggested a trip to the South-Omo Valley, homes to the many traditional isolated tribes of Ethiopia. In the beginning, I was seduced by my sense of adventure but subsequently, my inner self reminded me that I would never forgive myself for not achieving anything while being in Ethiopia. So the idea of writing this story was conceived, thanks to this destined encounter, as Irada would have me believe.\nSouth Omo Valley – home to the forgotten tribes of Ethiopia\nAlthough South Omo Valley is home to many traditional tribes such as the Tsemay, Banna, Konso, Ari, Dassanitch, Arbore, Karo, Bumi and Surma, the Mursi were the ones attracting us the most due to their unique practices of lip plates, face painting, elaborate hairstyles and other ceremonious traditions.\nOur exciting journey began in Addis Ababa on an otherwise typical bright sunny day. In the early morning hours of 30 May 2008, we loaded our rented and chauffeured Toyota Cobra with basic camping necessities such as mosquito domes, sleeping bags, three days of food supply consisted of canned and dried food, rolls of toilet paper, a torch light, bottles of mineral water, hand sanitiser, mosquito repellent, wet wipes and a first aid kit.\nAs any seasoned travellers would do, three jerry cans of fuel were strapped securely on top of our car to prevent the possibility of being stuck in the middle of nowhere. We were informed that we would need to camp in Mago National Park as they are no hotel facilities.\nA calf looking up curiously while chewing on dried twigs\nFinally, the rare opportunity to camp in the tribal wilderness of Africa greeted us both with great trepidation as well as excitement.\nOf course being women, our travel bags included miscellaneous female hygiene and personal care products, not forgetting luxury items such as mobile phones, mp3 player, 5litres of South African white wine, a bag of mini Toblerone and a large Nestle chocolate bar.\nHalf of the car’s backseat was occupied by Irada’s photographic equipment while I settled with only a notebook and a copy of my dog-eared Lonely Planet guidebook on Ethiopia and Eritrea. We were rather amazed by Jalalem, our driver’s lonely and evidently self-contained duffel bag. Though we were only three, Irada and I decided to squeeze ourselves in the backseat so that we could talk easily.\nWe brought bags of candies to be distributed along the way with hopes of earning some smiles from the local children. This turned out to be handy since we were often greeted by emaciated-looking boys and girls demanding for “caramella” or candies in Italian. It didn’t take long for us to dispense all the candies much to the children’s delight and appreciation.\nAs we bid farewell to Addis Ababa, we could not help but feel like a saner version of Thelma and Louise, leaving behind our mundane domestic lives in search of hopefully, a melodramatic adventure.\nThe journey through the Great Rift Valley\nThe Great Rift Valley, measuring more than 8,700km in length, constitutes nearly one-third of the earth’s circumference. It extends from the Jordan Valley in the north, through the Red Sea, down south to the South Omo Valley of Ethiopia, through Lake Turkana in Kenya, across Tanzania, Mozambique and finally ends near the Zambezi delta. Situated south-west of Ethiopia, the South Omo Valley itself boasts six lakes, Ziway, Abiata-Shala, Langano, Awassa, Chamo and one of the largest of the Rift Valley; Lake Abaya measuring at 1160sqm.\nIn order to reach the Mursi, we had to make overnight stops at Arba Minch, Jinka and Mago National Park, across more than 1,000km of wide asphalt roads often proceeded with very narrow, winding and bumpy gravelled paths, as we moved towards more and more remote and isolated areas.\nAs we began to drift slowly away from Addis Ababa, we started to see the real beauty and charm of the Ethiopian countryside in all its organic splendour. Our first overnight stop, Arba Minch is approximately 550km from Addis Ababa, of which the last 110km consists of unpaved roads through mountainous terrain.\nWe were impressed by Jalalem’s driving skills as he confidently swerved and manoeuvred the car to avoid big potholes, cattle and pedestrians along the roads. In the beginning, it felt like a fun roller-coaster ride but after awhile, our buttocks and legs felt sore from the constant bumpy stretch of roads. It almost felt like we were sitting on massage chairs for hours, except that soothing vibrations were replaced by violent poundings.\nThe journey took us about eleven hours with occasional brief stopovers in the towns of Shashemene, Wolayta and Weyto to ease our full bladders, stretch our legs and refuel our vehicle and stomachs.\nKings and queens of the roads\nNotoriously known for sleeping in long car rides, I did not even doze off for a second throughout the whole journey. Neither did Irada. We were both constantly fascinated by almost everything, right down to the herds of cattle which seemed to rule the roads in almost every village we passed.\nThe local cows are shaped rather oddly, with backs protruding like humps and skins sweeping loosely beneath their necks. There was a lot of “Look! Look!” exclamations, as each of us pointed out what seemed to have amused or tickled us from both sides of the car. Jalalem was completely unperturbed, except for his strange fascination for banana plantations as he often pointed out to us.\nDespite a lot of frustrations without a local guide, we relied on Jalalem with his limited command of English to explain things. We soon picked up some basic Amharic during the course of our journey.\nSince it was already close to the month of June, we began to see the sign of rainy season albeit the seasonal rain being late at this time of the year. The weather was slightly grey and melancholy followed by occasional soft drizzle. There was already flooding in certain lower areas.\nDonkeys huddled together under the flat canopy of acacia trees, waiting stubbornly for the rain to stop. I began to notice how endearing these white-snouted four-legged creatures are as I often saw them in pairs, facing each other, as if having a private conversation with only God privy to it. Sometimes, they even nuzzled affectionately against each other’s necks. The sluggish pace of countryside often creates time for love even for animals, as compared to city life where people seem to hurry on with their inconsequential affairs.\nWhile it was unfortunate for the people who were beginning to be affected by the flood, it provided us with some cool respite from the summer heat of Addis Ababa.\nNext: Part IV – Getting in sync with nature\nKa Ea used to be a globe trotter. She has lived in Timor Leste and Afghanistan while working as a civic education and human rights officers for the United Nations. She then tried to be a full time housewife in Ethiopia and Cambodia but failed miserably. Now, she works with lawyers and human rights activists by day and watches Discovery Travel & Living by night. She writes for The Malaysian Insider during her dwindling free time. She longs for the day when someone would pay her to travel, eat and write.\nIrada Humbatova was born in Azerbaijan’s capital Baku on 12 July 1974. She trained and worked as a midwife from 1994 to 1997, later assisting the International Federation of the Red Cross/Red Crescent with maternal health work by training and supporting traditional birth attendants in rural areas. Since then she has followed her husband on Red Cross missions around the world, developing her love for photography into a passion and profession. Inspired by Africa’s immense beauty and its people’s suffering she moved from art photography to photojournalism. She has since grown to become Reuters’ stringer for Ethiopia and work on assignments for other news outlets and magazines. Irada is currently back in Baku continuing her work with Reuters. She contributes most of the photographs in this series.","Written by Philip Briggs\nIn Ethiopia’s Omo Valley and the far western lowlands near Sudan is a variety of peoples whose modern lifestyle is still deeply African in every sense – in fact, you would struggle to find people anywhere in east Africa socut off from the mainstream of modern life. Some of the different tribes likely to be encountered by visitors to South Omo are as follows:\nThe most celebrated residents of South Omo, the Mursi – the subject of several television documentaries and books – are best known forthe lip plates worn by the women. The custom is that when a Mursi woman reaches the age of about 20, a slit is cut beneath her lowerlip, creating a small hole between the lip and the tissue below. Over the next year, this gap is progressively stretched, forming a ‘lip loop’ large enough for a small circular clay plate, indented like a pulley, to be inserted between the lip and the mouth. As the lip stretches, so theplate is replaced with a larger one, a process repeated until eventuallyshe can hold a clay plate of perhaps 15cm (6 inches) in diameter. The larger the lip plate a woman can wear, the greater her value when sheis married, but the path to matrimony is no smoother for Mursi men,with rival suitors traditionally partaking in a violent stick fight thatfrequently goes to the death.\nThe dominant people of Weita, on the Konso–Jinka road, are this groupof around 5,000 subsistence farmers who practise flood cultivation ofsorghum and maize, but also rear cattle and keep beehives. The Tsema speak an east Cushitic language closely related to Konso, which is fromwhere their founding chief hailed some 200 years ago. Tsemai societyis structured around four fixed age-sets, which graduate in seniorityonce a decade, when a new generation of boys aged 11–22 is initiated.\nOccupying the largest territory of any group in South Omo, extendingfrom the northern border of Mago National Park into the highlands around Jinka, the Ari numbered 100,000 souls in the 1984 census, and the population is much larger today. They speak an Omotic language, and are mixed farmers who grow grains, coffee and enset, keep livestock and produce excellent honey. In rural areas, Ari women might still wear a traditional gori (a dress made with leaves), and decorate their waist and arms with colourful beads and bracelets.\nNumbering about 35,000 and occupying a large territory running east from the Omo River to Lake Chew Bahir, these are archetypal people of South Omo. Not only do they speak one of the Omotic tongues unique to this small area of southern Ethiopia, but their elaborate selection of body decorations embraces the full gamut of Omo specialities (excepting for lip plates). The women have thickly plaited and ochred hair hanging down in a heavy fringe, leather skirts decorated with cowries, a dozen ormore copper bracelets fixed tightly around their arms, and thick weltson their body created by cutting themselves and treating the wound with ash and charcoal. The men, though also given to body scarring, are more plainly adorned, though some have clay hair buns fashioned on their heads – indicating that they killed a person or a dangerous animal within the last year. The most important event in Hamer society is the Bull Jumping Ceremony, the culmination of a three-day-long initiationrite held between late February and early April.\n© Ariadne Van Zandbergen, Africa Image Library\nOriginally pure pastoralists who lived a nomadic lifestyle, the Dasanechare migrants from the Turkana region of Kenya, and the abundant water frontage and fertile soil of their present territory has subsequently pushed them towards a more diverse economy, based around fishing and agriculture as well as livestock. The nomadic roots of the Dasanechare most clearly seen today in their flimsy traditional domed huts, which are strongly reminiscent of the impermanent structures built byother African desert pastoralists.\nThis small tribe, which inhabits the east side of the Omo River, is best known for the elaborate body painting indulged in by the men, who daub their torsos with white chalk paint, in imitation of the plumage of a guinea fowl, and complement this with colourful facemasks preparedwith a combination of chalk, charcoal, powdered yellow rock and ironorpastes. The hairstyle favoured by the women is also striking: tightlycropped at the side, and tied into bulbous knots and dyed ochre on top,it looks as if they have rushed out of the bathroom without removing their shower cap.\n© Ariadne Van Zandbergen, Africa Image Library\nA tribe of around 6,000 pastoralists who live on the western side ofthe Omo River, the Bumi speak an eastern Nilotic language, and their affiliations with the Turkana people of northern Kenya are immediately evident in the tentacle-like tangle of leather necklaces and side-cropped hairstyles worn by the women. The men share with the Turkana areputation for aggression and ferocity, and they are often involved infatal inter-tribal cattle raiding altercations with their neighbours."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:48f89fef-1e08-4b3e-bda3-5bdbca826c8c>","<urn:uuid:f95ffb58-848a-4e7e-8332-0d5e3e3c0543>"],"error":null}
{"question":"How is program evaluation in dental hygiene different than specialist collaboration evaluation - what steps or methods are used in each?","answer":"Program evaluation in dental hygiene is a systematic process involving formative evaluation during implementation and summative evaluation to measure results against goals, requiring continuous measurement of outcomes to determine if population needs were met. In contrast, specialist collaboration evaluation is measured through specific outcomes like improved patient care management, increased patient satisfaction ratings, patient referrals between practices, more effective schedules, and enhanced provider-patient relationships.","context":["Note the dental hygiene process of care and dental hygiene program planning paradigm are similar in that they are both a structured process for dental hygienists to follow when caring for an individual or group. Both consist of steps that include: assessment of the situation, formulation of a dental hygiene diagnosis, planning the program, putting the plan into action, and evaluation (see Figure 12.1.1D and E, and Table 12.1.1).\nTable 12.1.1: Patient care vs. community health programs.\n|Stage||Patient Care||Community Health Programs|\n|Assessment||Conducts a health assessment and comprehensive oral examination of individual patient to identify oral and general health status based on patient problems, needs, and strengths||Conducts a needs assessment of target population to analyze needs, interests, abilities, and resources|\n|Dental hygiene diagnosis||Formulate conclusions about the patient’s dental hygiene needs based on all available assessment data and evidence in the literature||Formulate findings from assessment and prioritize needs|\n|Planning||Develop a dental hygiene care plan with realistic goals and outcomes based on patient needs, expectations, values, and current scientific evidence to plan dental hygiene interventions\nSelect appropriate interventions to implement plan\n|Develop a program based on the analysis of needs assessment data, priorities, and alternatives; community interaction; and resources available for which measureable assessment mechanisms are used\nSelect appropriate resources to implement program\n|Implementation||Implement dental hygiene care plan while minimizing risk and optimizing oral health||Implement self‐generated treatment plan effectively|\n|Evaluation||Review and assess outcomes of dental hygiene care via dental, gingival, and periodontal evaluations, modifying plan when necessary||Review and assess program outcomes via index and community evaluations, modifying plan when necessary|\n|Documentation||Document all collected data, interventions planned and provided, recommendations, and other information relevant to patient care and treatment||Document all data gathered throughout all stages|\nData collection is the gathering of information that the community can use to make decisions and set priorities. Different types of data are necessary to make certain that a complete assessment accurately describes the factors influencing the health of the community. Community health assessment efforts can evaluate determinants of health needs, assess needs, and assets, quantify disparities, and inequalities among population groups, measure preventable disease, injury, disability, and death (Geurink 2012, p. 64).\nAssumptions should not be made of a population’s needs. A need is a gap between what the current condition is and what it should be. It can be defined as a judgment based on professional knowledge, skill, and experience as to the amount and kind of health‐care services required to attain or maintain health (Nathe 2017, p. 41). A needs assessment is required to provide the evidence that will guide the development of appropriate program planning. It provides a systematic method to determine needs, identify related cause(s), and priorities for future interventions. A needs assessment has the ability to identify health‐care situations regarded as unwelcome or harmful and needing to be dealt with and overcome within the community. The assessment provides information not only about the issues but about the community (Geurink 2012). Assessment is a core public health function and dental hygienists involved in public health practice must be proficient in the various aspects of oral health assessment. This is an integral component of a community oral health improvement process. Information gained form a community assessment can be used to plan, implement, and evaluate oral health improvement strategies.\nA survey is a method of collecting information to determine the views of the target group. The assessment survey to evaluate community needs may be conducted in a variety of forms, such as interviews, questionnaires, or indices. The method chosen depends on the scope of the intention and available resources. Methods include: face‐to‐face interviews, phone interviews, direct mailers, email questionnaire, focus groups, indices, and multiple methods of distribution. The appropriate data collection survey approach should be determined. Interviews and questionnaires provide measurement of knowledge, attitudes, and values related to health and disease (Nathe 2017, p. 200). Interviews involve direct verbal questioning of participants and questionnaires are simple to administer when a large amount of data is needed. Interviews may be more time consuming than questionnaires, but assures more adequate responses. A dental index is a standardized quantitative method for measuring, scoring, and analyzing oral conditions in individuals and groups (Nathe 2017, p. 166).\nClosed‐ended questions are those that may be answered with a single word or a short phrase, while open‐ended questions are those that require more thought and a longer answer. Closed‐ended questions may be dichotomous, multiple choice, or scaled questions. The Likert scale is the most widely used rating scale to measure responses and survey research. It is an ordered scale from which respondents choose one option that best aligns with their views. A typical scale might be “Strongly agree, Agree, Neutral, Disagree, Strongly disagree” (CDC 2012). Open‐ended questions have no predefined options or categories.\nAfter the needs assessment is completed and the data has been evaluated, the dental hygienists began the planning by determining the goals and objectives for the program. A plan for community‐based interventions consists of strategies that will be implemented. Planning is an organized response to a community’s established need to reduce or eliminate one or more problems. A course of action is developed from the diagnosis. Developing goals, objectives, and program activities is part of the planning process. During this stage, it is essential to have community involvement and participation by community leaders, stakeholders, health group representatives, foundation leaders, government agencies, and all dental hygiene and dental associations (Geurink 2012).\nImplementation is the step defined as the process of putting the plan and activities into action (Beatty 2017). Personnel, equipment, resources, supplies, and preliminary progress toward program goals are monitored. Many community oral health programs commence on a smaller scale – short term. This is referred to as a pilot testing or a pilot program. This provides information and allows for future decisions to be made that would work in practice.\nEvaluation is continuous and measurements of the program’s intended outcomes determine if the population’s needs were met or if revisions are needed. A successful program meets its goals and objectives. Evaluation is a mandatory phase of all types of community programs. Although it is the final step of the program or community health improvement plan, formal, and informal evaluation results are reported regularly as this phase is ongoing and involves constant feedback and interaction. Program evaluation is a systematic method for collecting, analyzing, and using information to answer questions about community health programs. During this stage of the process, the results of the program are measured against the goals and objectives developed during planning. This is summative evaluation (Beatty 2017). Formative evaluation or process evaluation takes place before or during a project’s implementation with the goal of improving the project (Beatty 2017).This type of evaluation allows for better understanding of the process of change or continual improvement. The dental hygienist can improve future design and implementation.\n- If you are unfamiliar with the target population, always begin with a needs assessment.\n- Closed‐ended questions are time‐efficient, but make sure to not ask for simplistic responses to a complex issue when an open‐ended question is more appropriate.","Dental hygienists are essential partners in periodontal and orthodontic specialty treatments. The dental hygienist is vital in the collaborative patient care behind periodontal disease and misaligned teeth. The collaborative role that each dental team member and provider plays can positively or negatively influence patients’ perceptions of the practice, their trust in the providers, and their overall treatment acceptance.\nWe know that dental hygienists spend the most chair-time with patients. “Patients who reported feeling respected talked about being compliant with preventive care recommendations because they felt they were being treated as a person and not as a patient.”1 Therefore, dental hygienists play the primary role in the collaboration between a general dental practice and specialty practices.\nSince periodontists are trained to treat cases of disease in the gingival tissue and supporting bone, they are dependent on strong partnerships and relationships with hygienists who possess an expertise that provides a first line of defense against the development of infection, working with the dentists to identify which patients need specialized treatment.\nIn some cases, referrals to the periodontist can be a touchy subject for general dentistry offices. Many general practitioners (GP) are reluctant to refer due to a common concern of never getting their patients back. Others are fearful of referring patients due to the pain and financial burdens of periodontal surgery.\nAs dental professionals, we must take the emotion out of the scenario and lead with our clinical mindset, which is to properly educate and recommend necessary treatment based on its effects on the oral and systemic health concerns and needs of the patient. It is important that, when you are referring to a specialist, there has been an initial treatment and referral protocol established between the GP practice and the specialty office, and hygienists need to be a part of the conversations.\nIn my experience collaborating with specialty providers, our practice first scheduled a lunchtime meeting with the periodontist where we learned about his practicing philosophy. We discussed ours as well, which we found to be in alignment with each other. The periodontist was centered on patient care and had a positive and empathetic chairside manner. The doctor is a proponent of patient education to reinforce why particular treatment is needed and keeps abreast of new technology and treatment to provide efficient care conservatively. We agreed on the following standard of care protocol:\n- The GP hygienist would complete all the initial data gathering, including radiographs, intraoral camera images, complete periodontal charting, and refer any patients with >7mm probing depths, class III mobility, class II furcation involvement, generalized moderate-advanced radiographic bone loss, and gingival graft candidate patients to the periodontist for evaluation and treatment.\n- If a patient has been receiving regular periodontal maintenance therapy, including locally administered antibiotic regimens with no improvement to their gingival health, the patient is to be referred to the periodontist for an evaluation.\n- Once periodontal specialty treatment was completed and stabilized, the patient would return to the GP hygienist for three-month periodontal maintenance therapy, periodic exams, and radiographs as needed while still being seen by the periodontist on the alternating three-month recare cycle for the first year. If, after the first year, the periodontist deems the patient is stable, then the patient will solely have the periodontal maintenance therapy completed by the GP hygienist and will have an annual gingival evaluation with the periodontist.\nThe best strategy dental hygienists can employ to incorporate orthodontic considerations into the practice is to connect and refer to local orthodontic practices. The dental hygienist has unique opportunities to impact this specialized area of dentistry, ranging from education to assessment to supportive therapies during orthodontic treatment.\nThe American Academy of Periodontology has specified occlusal examination as part of the periodontal assessment. The 2011 Comprehensive Periodontal Therapy statement includes the following: “An occlusal examination that includes, but may not be limited to, determining the degree of mobility of teeth and dental implants, occlusal patterns and discrepancy, and determination of fremitus. Occlusal therapy that may include tooth movement, occlusal adjustment, splinting, periodontally accelerated osteogenic orthodontics, or biteguard therapy as a means to establish and maintain occlusal health;” and “Procedures to facilitate orthodontic treatment including tooth exposure, frenulectomy, fiberotomy, temporary anchorage devices, and gingival augmentation.”2\nRegarding the collaboration with the orthodontic specialty provider, we too had a lunch meeting and discussed our practicing philosophies and developed the following action plan:\n- All pediatric patients will have a panoramic radiograph taken and be referred to an orthodontist for initial evaluation beginning at the age of seven years.\n- If a pediatric patient under the age of seven years presents to the office with a Class III occlusion or another immediate orthognathic concern, a referral to the orthodontist is needed.\n- Adult patients with malalignment will be referred to the orthodontist for evaluation and treatment needed outside the GP scope of providing clear aligner therapy.\n- All patients under orthodontic treatment will be recommended to be seen on a four-month recare cycle by the GP hygienist and receive an in-office fluoride treatment.\n- At-home standard of care product expectations are for the patient to use a power toothbrush, water flosser, and fluoride to maintain optimal oral health.\nThere were no formal contracts signed between the GP and specialty practices for referrals. The agreed-upon communication was that each provider would provide a standard-of-care written report on date-of-service treatment, additional recommendations, and next steps. This standard of care report was an important part of the care process and was saved into the patient’s chart for future reference, treatment needs, and any communication required for a medical physician if applicable.\nThese collaborations and specialty partnerships resulted in an improved patient care management process, improved patient health, improved patient satisfaction ratings, an increase in patient referrals between both the GP and specialty practices, more effective schedules, and improved patient-provider trusting relationships.\nDental hygienists are an organized and structured group. Establishing a protocol and standard of care plan of action will enhance treatment opportunities and provide clinicians with the satisfaction of delivering the quality of care that our patients deserve.\nListen to the Today’s RDH Dental Hygiene Podcast Below:\n- Dalonges, D.A., Fried, J.L. Creating Immediacy Using Verbal and Nonverbal Methods. J Dent Hyg. 2016; 90(4): 221-225.\n- The American Academy of Periodontology Task Force. Comprehensive Periodontal Therapy: A Statement by the American Academy of Periodontology. Journal of Periodontology. 2011; 82(7): 943-949. Retrieved from https://doi.org/10.1902/jop.2011.117001"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:d229bcad-8220-4181-b6c1-84e2585a90a3>","<urn:uuid:7991b0fc-323e-4a08-a1ca-957a87938bf8>"],"error":null}
{"question":"Could you explain how the Current Account balance affects a country's financial position, and what are the components that determine its deficit or surplus?","answer":"The Current Account balance has significant implications for a country's financial position. A surplus balance improves the country's financial standing and can be used for growth and development. The Current Account consists of several components: first, merchandise trade (exports and imports of goods), where export receipts are credited and imports are debited. Second, it includes invisibles like trade in services, dividends, unilateral receipts, and investment income. A deficit occurs when debits exceed credits, while a surplus happens when credits are higher than debits. Countries with persistent current account deficits may face difficulties - if they can't attract enough foreign investment, their currency reserves will diminish, potentially leading to the need for emergency borrowing from institutions like the IMF and resulting in external debt.","context":["The Balance of Payment is an organized account of all economic transactions between a country (say India) and the rest of the world, carried out in a particular time period. In other words, a country archives all the inflows and outflows of funds in a statement referred to as BOP.\nThe Structure of Balance of Payments (BOP) is as follows\nThe BOP structure depends on the concepts of the double-entry book-keeping. This implies that all the inflows of funds are placed on the credit side and all sorts of outflows of funds are debited. The balance of payments accounting differs from the business accounting in one aspect. In the BOP accounting the credits are on the left side and debits on the right side.\nIt is the difference between exports and imports of items, typically referenced as visible or tangible items. In case the exports are higher compared to imports, you will see trade surplus and if imports are more than exports, you will have trade deficit. Trade balance shows whether a nation enjoys a surplus or deficit. Developing countries usually have trade deficit. The trade balance is a part of current account.\nIn the current account, merchandise trade is entered first. There are actually a large number of distinct items which belong to the goods category. Export receipts are shown on the credit side and the imports are shown on the debit side. The second item that is recorded in the current account is invisibles. The current account consists of trade in services, dividends, unilateral receipts, investment income, etc. After entering the details, balancing is performed for the current account. This balance is referred to as the balance of current account. When debits are more than credits deficit occurs. Current account surplus will take place when credits are higher than debits. Current account balance is extremely important. It exhibits a country’s earning and payments in foreign currency. A surplus balance improves the country’s financial position. It may be utilized for growth and development of the country.\nThe Capital account includes all the short-term and long-term transactions between a country and the world. Usually, these types of flows of money are related to saving and investment, but speculation has turned into a major component of the account in recent times. In the capital account, both direct and portfolio foreign investment is recorded. External assistance and commercial borrowing are presented net repayment. Direct investment identifies the money which moves across national boundaries with the intention of investing in a business. Portfolio investment moves across national boundaries with the intention of purchasing shares and bonds. The Official reserves means the reserves of gold and foreign exchange kept by the Reserve Bank of India to be used by the government.\nErrors and Omission\nAccording to double entry book – keeping concept for every credit, there exists a matching debit and thus, there must be a balance in BOP as well. In reality BOP may not balance. Once various types of international financial flows are recorded, the statistical discrepancy, referred to as errors and omissions, is also recorded. The statistical discrepancy occurs due to complications associated with collecting balance of payments data. You can find different sources of data which occasionally differ in their approach. For instance, merchandise is shipped in March, however the payments are received in April. If statistics are compiled on the 31st March, the numbers will differ. The errors and omissions amount is equal to the amount required to balance both the sides. It is useful to keep in mind that whenever past figures for the BOP are adjusted as time passes by, the figures for ‘net errors and omissions’ get smaller and smaller as the errors are located and fixed.\nForeign Exchange Reserves\nForeign exchange reserves exhibits the reserves that are kept in the form of foreign currencies. If the overall balance is surplus, it is moved to the official reserves account which raises the foreign exchange reserves. It may be in form of dollar, pound, gold and Special Drawing Rights (SDRs). If there exists a deficit, a sum equal to the deficit is taken from the official reserves account bringing the BOP into equilibrium. When surplus is moved to the foreign exchange reserve, it is displayed as minus in that specific year’s balance of payment account. The minus sign (-) signifies a rise in forex and plus sign (+) exhibits the borrowing of foreign exchange from the forex account in order to meet the deficit.\nWatch a Video on Structure of Balance of Payments","The balance of Payments (BoP) and Balance of Trade (BoT) are two confusing concepts for even economics graduates. These terms are connected with international trade accounting. In this post, we provide a mind-map approach to study Balance of Payments. We hope the same would help in quick understanding and revision.\nWhat is Balance of Payments (BoP)?\n- The balance of payments (BoP) record the transactions in goods, services, and assets between residents of a country with the rest of the world for a specified time period typically a year.\n- It represents a summation of country’s current demand and supply of the claims on foreign currencies and of foreign claims on its currency.\n- There are two main accounts in the BoP – the current account and the capital account.\n- Current Account: The current account records exports and imports in goods, trade in services and transfer payments.\n- Capital Account: The capital account records all international purchases and sales of assets such as money, stocks, bonds, etc. It includes foreign investments and loans.\n- Note: The IMF accounting standards of the BOP statement divides international transactions into three accounts: the current account, the capital account, and the financial account, where the current account should be balanced by capital account and financial account transactions. But, in countries like India, the financial account is included in the capital account itself.\nBalance of Payments: Mindmap\nWhat would happen if a country spends more than it receives from abroad?\nWhat would happen if an individual spends more than his income? He must finance the same by some other means, right? It may be by borrowing or by selling assets.\nThe same way, if a country has a deficit in its current account (spending more abroad than it receives from sales to the rest of the world), it must finance it by borrowing abroad or selling assets. Thus, any current account deficit is of necessity financed by a net capital inflow.\nFilling Current Account Deficit with Foreign Exchange Reserves\nA country could also engage in official reserve transactions, running down its reserves of foreign exchange, in the case of a deficit by selling foreign currency in the foreign exchange market. But, official reserve transactions are more relevant under a regime of pegged exchange rates than when exchange rates are floating.\nA country is said to be in balance of payments equilibrium when the sum of its current account and its non-reserve capital account equals zero so that the current account balance is financed entirely by international lending without reserve movements.\nNote: A BOP surplus is accompanied by an accumulation of foreign exchange reserves by the central bank.\nIdeally, BoP should be Zero! How?\nFrom a balance of international payments point of view, a surplus on the current account would allow a deficit to be run on the capital account. For example, surplus foreign currency can be used to fund investment in assets located overseas. Also, if a country has a current account deficit (trade deficit), it will borrow from abroad.\nIn reality, the accounts do not exactly offset each other, because of statistical discrepancies, accounting conventions and exchange rate movements that change the recorded value of transactions.\nBoP Deficit or Surplus\n- The decrease (increase) in official reserves is called the overall balance of payments deficit (surplus).\n- The balance of payments deficit or surplus is obtained after adding the current and capital account balances.\n- The balance of payments surplus will be considered as an addition to official reserves (reserve use).\n- Countries with current account deficits can run into difficulties. If the deficit is large and the economy is not able to attract enough inflows of foreign investment, then their currency reserves will dwindle.\n- There may come a point when the country needs to seek emergency borrowing from institutions such as the International Monetary Fund, that may lead to external debt.\n- Countries with deficits in their current accounts will build up increasing debt and/or see increased foreign ownership of their assets.\n- BoP crisis is also known as the currency crisis.\nAutonomous Transactions vs Accommodating Transactions\n- International economic transactions are called autonomous when transactions are made independently of the state of the BoP (for instance due to profit motive).\n- These items are called ‘above the line’ items in the BoP.\n- The balance of payments is said to be in surplus (deficit) if autonomous receipts are greater (less) than autonomous payments.\n- Accommodating transactions (termed ‘below the line’ items), on the other hand, are determined by the net consequences of the autonomous items, that is, whether the BoP is in surplus or deficit.\n- The official reserve transactions are seen as the accommodating item in the BoP (all others being autonomous).\nErrors and Omissions\nErrors and Omissions constitute the third element in the BoP (apart from the current and capital accounts) which is the ‘balancing item’ reflecting our inability to record all international transactions accurately.\nBoT vs BoP\n- The balance of Trade (BoT) or Trade Balance is a part of the Balance of Payments (BoP). BoT just includes the balance between export and import of goods.\n- BoP not only adds the service-trade but also many other components in the current account (Eg: Transfer payments) and capital account (FDI, loans etc).\nIndian rupee is fully convertible only in the current account and not in the capital account.\nThings to note:\n- If an Indian investor earns interest or dividend in his investment abroad, that will be included in the current account of India.\n- If FDI is done by an American company in India, that investment will be accounted in the capital account of India.\n- NRI deposits are calculated under Capital Accounts while Private Remittances are calculated under Current Account.\n- In general, National Income (Y) = Private Consumption Expenditure (C) + Investment (I) + Government Expenditure (G) + Net Exports (E).\n- In a closed economy, Savings (S) = Investment (I).\n- In an open economy, Savings (S) = Investment (I) + Net Exports (E)\n- OR, Net Exports = Savings – Investment. This is actually the Balance of Trade (Trade Balance)."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:805a7c65-dfe4-421f-875b-8b808f7a28e5>","<urn:uuid:b83c8767-598e-4a74-8b7f-32a3bed8904d>"],"error":null}
{"question":"How can you optimize a mixer valve for low-speed engine performance?","answer":"To optimize a mixer valve for low-speed engine performance, the key is to make the cut on the back corner of the mixer body about 1/4 inch or less from the cross couplings. This creates a stronger venturi effect, which helps the engine run well at slow speeds. If the distance is increased, it will provide more power at high speeds, but the air flow through the mixer at low speed may not be sufficient to lift fuel from the tank. For those who prefer to see old engines run slowly without loads, a cut of slightly less than 1/4 inch is recommended.","context":["We all like to see old engines restored to the original condition, just as they were when they were new. Sometimes, however, parts are missing and cannot be located. A choice must be made to forget the engine, or to use non-standard parts, or even homemade parts. This was the case with a Jumbo engine (Nelson Bros.) which I was able to obtain recently. I only obtained the basic castings. There was no valve mechanism, no governor latch, no ignition system, and worst of all no mixer valve, or carburetor as some call it. I was able to make all of these parts, and now have the engine running.\nMost of my 'engine nut' buddies had agreed that the mixer would be the most difficult to make without the use of a machine shop. Actually it turned out to be quite simple using only hand tools, a gas welder, a drill, a hacksaw, and file. The materials required are available at any hardware store.\nThis mixer works fine on my engine, and I believe it will work on any small (1 to 2 HP) hit-and-miss engine. In the hope it may help someone else save an old engine, I have made some pictures and sketches of how the mixer was made.\nSome things to keep in mind while looking at the sketches. The use of 1/8 inch pipe couplings (which are about 1/2 inch actual outside dia.) across the one inch main body tube forms a kind of venturi which will siphon fuel from the tank without the choke closed. This is a necessary part of the construction. On an angle mixer the venturi effect can also be controlled by how close the back corner of the mixer body is cut off. If you want the engine to run well at slow speed, then make the cut about 1/4 inch or less from the cross couplings. If the engine is to run fast, and make a lot of power, then increase the distance. Keep in mind if the distance is larger, then the air flow through the mixer at low speed may not be enough to lift fuel from the tank. Most of us like to see these old engines run slow, and often we don't pull any load at all, so I cut my mixer a bit less than 1/4 inch to produce a strong venturi effect, and give good low-speed performance.\nThe following is a 12-step procedure to make a mixer (see the diagrams in the Image Gallery for a visual step-by-step):\n1. Cut 1-inch ID electrical conduit at 45 degrees.\n2. Notch cut ends with a rat-tail file.\n3. Weld to form an elbow. Run a drill through the hole to smooth it.\n4. Weld two 1/8-inch pipe couplings together for necessary length. Grind or file the weld smooth. Drill a 1/8-inch hole at center one side only.\n5. Saw off the corner of the ell at 45 degrees, about 1/4-inch from the hole.\n6. Weld or braze a nut to the center of a washer of the size to just cover the hole produced by cutting the corner in step No. 5.\n7. Weld or braze the washer and nut to cover the hole in the back corner of the ell. Use care to keep it on center.\n8. Use a 1/4-inch cap screw about 1 inch long. Chuck in a drill and spin it against a file or grinder to form a needle. The point should be about 3/8-inch long.\n9. File or ream the hole until the 1/8-inch pipe couplings will just slip through.\n10. Slip the couplings in place and turn the hole to face the pointed screw. Screw the point into the hole in the coupling snugly. This will hold the coupling in the correct position while the ends are brazed to the elbow.\n11. Weld a flange or whatever is required to fit the engine. Also a choke plate. It is a good idea to cover the lower front air horn about 1/4-inch up to avoid fuel drip.\n12. Screw an angle valve in one side of the coupling and plug the other side. Connect to the fuel tank through a check valve. The tank should be slightly below the mixer. The needle must be adjusted to the engine."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:c7f8b283-5f35-4416-9c3d-700f33e877e9>"],"error":null}
{"question":"How do soil mapping and yield mapping technologies work together for profitable farming?","answer":"Soil mapping and yield mapping technologies work together by enabling farmers to collect and analyze multiple layers of data to make more profitable decisions. Soil mapping provides detailed information about nutrient levels and soil characteristics, while yield mapping in harvest equipment provides real-time data about crop performance. As shown in Document 1, one farmer used over 300 soil sampling sites analyzed regularly alongside yield data and NDVI imagery to identify trends and make improvements - for instance, by adjusting soil pH to increase phosphorus availability and reduce fertilizer costs while maintaining above-average yields. Document 2 explains that yield mapping technology, available in most modern combine harvesters, allows farmers to identify consistently high or low yielding zones and adjust crop inputs accordingly. This data integration helps farmers develop targeted, zone-specific management strategies for optimal resource use and profitability.","context":["Are You Using Your Soil to Its Full Potential?\nHarvest is progressing across most parts of the U.S. and those growers who aren’t already harvesting are gearing up to start soon. In a few months, the crops will have been harvested, the fields will be bare, and the equipment will be serviced and stored away ready for next year’s harvest. This is also the time of year when growers and their advisors turn their attention to “servicing” their soil in preparation for the new crop. Different processes and procedures exist, but most co-ops and agronomists will work with their client to get soil samples analyzed and then create a fertilizer strategy that fits with the agronomic and financial plan.\nSo, what are these fertilizer strategies actually based on? Every agronomist will have a slightly different answer but in many cases, the strategy simply aims to close the gap between the nutrients that are currently available in the soil and the nutrients next year’s crop is expected to need. This approach to replacing nutrients based on expected crop removal certainly improves on the historic non-scientific blanket applications and continues to gain popularity as new research combined with better technology improves our understanding of the factors affecting plant nutrition. One aspect of most nutrition strategies that has stayed the same is the fact that fertilizer costs are the number one input cost for most growers. But should it be?\nI recently had a very interesting discussion with a grower who told me about his journey to understand and formulate his own fertilizer strategy. His process identified more than 300 soil sampling sites on his farm which are analyzed regularly with the results able to be viewed in the context of other data layers including soil type, yield data, and NDVI imagery. With 10 years’ worth of data available, he can now easily identify trends, anomalies, and other changes in his soil. In addition to a cropping agronomist, this grower also employs the services of a soil consultant to help drive the science behind the process. Good data enables good insights and by combining the multiple layers of data he was able to determine that by marginally increasing the pH of this soil, he was able to increase the availability of phosphorus already present in his soil and subsequently reduce his fertilizer bill on a proportion of his fields.\n“By injecting some scientific thinking into the process and sticking to a plan, I can now extract value from my soil that I have been building for the last 30 years,” he said.\nIn addition to what nutrients get applied, this grower also uses the data to determine the optimum time and formulation of each nutrient to apply. The data suggests that some fields will be better at holding onto nutrients than others which, together with price, drives financially efficient and agronomically effective nutrition decisions. He also employs variable rate applications on his farm which has reduced his annual fertilizer bill while maintaining better than average yields.\nThis process driven approach is feasible for a lot of farmers but, it requires a plan, and the discipline to stick to it, especially in the years when you don’t get the results you were hoping for. Increasing farm profitability is still as important as it’s always been, especially on days like yesterday when corn prices took a dive due to a USDA WASDE report. I see more and more tools becoming available to help growers and agronomists collect data to support their process, which is very exciting. IBM’s new AI-powered AgroPad that works with a microfluidics chip and the SoilOptix Top Soil Mapping System are only two examples of a range of technologies that have the potential to help farmers understand and unlock more value from their soil. Whichever technology you decide to use however, following a process-driven approach that puts data analysis at the forefront, will always be key.","Five years ago, when people started talking about Digital Farming and Big Data, most were not sure what this was or how it related to field base crop production. Since then, writes Keith Norman, the speed of technical innovation, its benefits and uptake by industry has accelerated beyond the hobbyists, which goes to show the financial benefits are being increasingly recognised and exploited by farmers and growers.\nHowever, there is still a long way to overcome some of the barriers to uptake, such as standardisation of connectivity, conformity of data for cross platform usage, rural connectivity and speed of data transmission, cost and resistance to change.\nSoil sampling for P&K and pH has been routinely carried out for many years using the traditional approach of walking a “W” shape in each field. The introduction of grid sampling, using one sample point per hectare, combined with Kriging allowed contour maps to be generated for each nutrient, which can be used for variable rate applications using precision equipment. Electromagnetic conductance maps have also been developed illustrating soil type variation within a field, from which more targeted sampling can take place.\nNutrient mapping technology has moved further with scanning equipment using Gamma Radiometrics. The level of four naturally occurring isotopes (Caesium, Uranium, Potassium, Thorium) are detected in the subsoil/topsoil, providing an overview (more than 800 reference points per hectare) of all nutrient levels, plus pH, soil texture, organic matter and cation exchange capacity (CEC): in total 21 different metrics. This technology is not affected by soil moisture, compaction, crop or cultivation, which offers a much wider sampling window. Terramap from Hutchinsons has recently been independently endorsed in an independent evaluation by NIAB whereby it was compared to grid sampling and EC Scanning. A similar endorsement for gamma radiometrics compared to conventional approaches has been published by Wageningen University.\nIn situ soil nutritional sensors have also started making an appearance on the market, providing real-time measurements of soil moisture, salinity, NPK, aeration, respiration, air temperature, light, and humidity. These are useful to monitor real time nutrient uptake by the surrounding crop to ensure there are no phases of crop development where nutrients fall below thresholds. Some probes, such as FungiAlert’s SporSenZ go further, allowing farmers to understand the soil’s microbial community. Such soil health indicators could also be used to understand the “inner workings” of the soil microbiome and how management practices impact on the delicate balance of its components. One such sensor is being developed in an Innovate UK project led by PES Technologies that hopes to give an instant, in-field measurement of the activity of the soil microbiome through sensing VOCs (Volatile Organic Compounds). The Small Robot Company, which is also part of the consortium is looking to automate the sampling process.\nRemote Tillage Detection (RTD) could also become important should carbon sequestration and a trading market develop in the UK. Such a market exists in the US with sequestrated carbon selling for about $15-20 per tonne. There are many management practices a farmer can use to sequester carbon, all of which need to be verified, for example, rotation and cropping, previous crop residue removal, and more importantly cultivation type used. Hummingbird Technologies is developing the capability of remotely detecting tillage method (plough, min-till or direct drilling). Crop type recognition is also being developed so that field specific rotations can be identified using archive satellite data. In North America, Dagan Inc, and Radicle are also developing such capabilities.\nSubsoil compaction is known to affect soil function and root development, but conventional sampling methods do not facilitate the acquisition of high-resolution spatial compaction data on a field wide basis. A team at Wageningen University is using ground penetrating radar to map subsoil compaction, with the aim of creating a compaction map for each field, which can then be interpreted for a differential approach to subsoil management, only subsoiling areas that need it, and at the correct depth. The benefits of a spatial approach to subsoiling are significant in terms of labour cost, fuel usage and time.\nVariable seed rate technology is available from several suppliers, and has seen a good uptake by industry. There are clear benefits to having a uniform plant population throughout a field across different soil types, mostly from targeted nitrogen application, tiller management and growth regulation.\nOnce crops are established, plant counting and sizing are now possible for some horticultural crops such as lettuce, cauliflower broccoli and pumpkins with companies such as Hummingbird Technologies, Solvi and Earth Rover. Not only can individual plants in a field be counted, but sizing information can also be presented, which is really important when it comes to matching size to supermarket contractual obligations.\nThere are now many types of optical sensor for looking at crop health, biomass and chlorophyll in cereals. Crop reflectance works in the visible and near infrared region (NIR) of the spectrum, and at least two wavelengths are combined to calculate vegetation indices. The near infrared light, not visible by the human eye, is reflected by the leaf mesophyll cells, resulting in a much higher reflectance than visible light. Using both wavelengths it is possible to evaluate the colour and biomass of a crop using a measurement called NDVI (normalised difference vegetation index). NDVI is very useful for agronomists and farmers to inspect areas of crops where problems are highlighted and where remedial action is necessary, rather than walking lots of “good” hectares. Similarly, remote sensing / imaging technologies are now widely available from many manufacturers and may be tractor-mounted, hand-held or use satellite technology through a computer or phone app.\nVariable rate nitrogen mapping, offered by many, exploits this natural soil/crop variation and matches nitrogen amount to biomass and growth of the crop. Examples of this include; Yara’s AtFarm and VRN products from Hummingbird, SOYL, DroneAg, Rhiza, Precision Decisions and Omnia\nGrowth stage prediction is a feature that some providers offer, such as Omnia from Hutchinsons, which uses climatic information combined with physiological crop modelling to predict when key growth stages are reached. For root crop growers, ground penetrating radar is being developed to provide a non-invasive way of looking at crop development in terms of size and shape. An Innovate UK funded project led by B-Hive Innovations is developing capability to identify tuber size and shape and quantity.\nMost yield prediction systems are based on the original WOFOST model, originally developed by Wageningen University but now maintained by the Joint Research Centre of the European Commission. The more recent introduction of AI makes modelling very large datasets of weather and crop metrics a much easier task, meaning it is now possible to get yield estimates down to individual field level.\nAccuracy increases as harvest date approaches. Most yield prediction is reasonably accurate at 30-days pre-harvest, but the challenge is to extend that to 60- and 90-days pre-harvest so there is still the potential to change input choice within and between fields to maxmise gross margin.\nCrop inventory and field benchmarking not only benefits farmers but it is also key information for many commodity trading organisations, government and supply industries, with an accurate hectarage, on a crop-by-crop basis, in regions or at national level.\nThere are many new innovations being developed for the detection of diseases, all of which work in a slightly different way but aim to give an early warning a specific disease of interest is in the early stages of infection. This “intelligence” at field level enables growers to use the optimum selection fungicides and timings, rather than using a prophylactic spraying approach. For example, Burkard and Rothamsted are developing a LAMP assay bio sensor, where air is sucked into the sensor and the spores are disrupted to release DNA for identification and quantification by a series of ‘in-trap’ laboratory tests. Results are then sent wirelessly to a server, using an internal 4G router. The Earlham institute (EI) has developed a similar system called AirSeq using nanopore technology, a new generation of DNA sequencers which read longer pieces of DNA than previously possible called the MinION platform This was discussed at a recent EI event attended by CHAP.\nThe University of Manchester and Sony have developed a totally different type of biosensor with Gates Foundation backing that uses a simulated leaf surface, impregnated with specific biochemicals known to stimulate the germination of the target disease. A micro camera in the sensor detects the hyphal growth and, through AI, recognises the target pathogen and sends an alert.\nFERA offer a qPCR service for farmers to send in leaf samples and the DNA of any latent target disease is extracted and measured in picogrammes. This gives a grower an indication of the amount of disease present, but as yet there is no real calibration between the resulting pico grammes of a disease and what level of fungicide is needed to control it. However, it is a very useful tool during dry springs when deciding fungicide mixtures and rates.\nPre-symptomatic disease detection is only one part of the story: the resulting spatial application of fungicides, in different combinations and dose rates is also an important consideration. Various digital technologies are being developed to deliver the science into practice in field. Often variable rate fungicide application assumes that thicker, higher biomass areas of crops have a microclimate more conducive to disease development. NDVI maps of a field can help identify such areas to create a targeted spatial application map.\nHowever, there are problems varying the rate of one tank mix component, such as a fungicide, while delivering a constant rate for other components such as insecticides or trace elements. A similar scenario exists with variable rate growth regulator and other tank mix partners.\n“On the move” rate variability can be overcome using direct injection spraying systems, where undiluted pesticide is placed into canisters on the sprayer, and plain water is in the sprayer tank. The pesticide is then metered and introduced into the water on the pressure side upstream from the boom sections, with the rate being varied by the speed of the direct injection pump. One example of this is Raven’s Sidekick Pro available as factory option on Case and John Deere sprayers, or as a retrofit to any sprayer. In addition to these technologies, small scale precision application is also being explored by the industry, such as CHAP’s Innovate UK project Slugbot, which precisely applies biopesticides where they are needed.\nNorth Carolina State University is developing a Volatile Organic Compound detector for late blight in potatoes. A small electronic nose “sniffs” the crop and gives an instant readout if the very early stages of blight are detected. The device is still handheld at the moment, but there are plans to make it drone mounted so crops can be flown and random points of inspection can be made to check a crop’s disease status.\nVolatile Organic compound detection is being used in Florida’s Orchards to detect a disease called “citrus greening” which affects orange, lemon and grapefruit trees. Sniffer dogs can detect diseased trees up to two years before symptoms appear. Similar work is happening in Canada with dogs sniffing Clubroot. The aim is to develop and automate a similar detection methodology on a drone.\nDisease modelling has an integral part to play in spore detection technologies. Knowing that there are spores in the air is one thing, but knowing how they will develop is another. The University of Reading and Rothamsted have developed a Septoria prediction model based on accumulated rain and accumulated minimum temperature pre GS31. The known varietal resistance is also used in the model output.\nCHAP and Fera have partnered to create the disease prediction tool CropMonitor Pro, which provides information sourced from monitoring sites located across the country and reports up to date measurements of crop pest and disease activity in arable crops throughout the UK.\nIntelligent insect traps are being developed whereby insects are lured into a trap, and are quantified and identified because of their size and shape. One example is DTN’s SmartTrap, which can identify up to 16 different crop pests through an onboard camera that counts and reports on them in near real time. It can even distinguish between target and non-target pests.\nAnother bio-sensor based technology that records and analyses electrical signals emitted by plants is being developed by Vivent. The system called PhytlSigns, provides early warnings of a wide range of crop stresses, including nutrient deficiencies, environmental stresses, pathogens and insect infestations well before visual symptoms, enabling farmers to action early interventions.\nYield mapping is a well-established technology in cereal combine harvesters, but the technology is now being developed for forage harvesters and root crop harvesters too. This digital technology gives farmers and growers realtime evidence to look back at their different approaches to crop production and management. It also allows field zones to be identified that are consistently high or low yielding, therefore allowing a differential approach of crop inputs to be deployed.\nMany manufacturers including New Holland, CASE, Claas, AGCO and John Deere all provide a yield-mapping function and most incorporate moisture analysis for cereal harvesting. Some also provide additional elements, Claas has a very useful Telematics option called Fleet View, which informs the field team about the position of the machines and their grain tank fill levels. Everyone will know which machine needs to be unloaded next. This avoids idle time and unnecessary vehicle travel, save fuel and make full use of the harvesting machines’ capacity.\nSensors installed in John Deere’s ActiveYield system combines, not only weigh the amount of grain coming into the tank, but NIR sensors can also measure protein content. The weight sensors avoid the need for weighbridge calibration. This is useful in gauging the success of late nitrogen applications for protein in wheat. Other such as Bayer’s FieldView enables remote real-time harvesting information, yield mapping while the combing operation is happening, and also gives access to in-season satellite imagery allowing evaluation of crop health.\nYield mapping can also be used to examine other factors such as PCN affected areas in potato. Allowing differential strategies for nematicide usage / varietal choice to be implemented in specific situations. Soil Essentials’ EssentialsRootYield weighs potatoes coming over the harvester’s web, with the data then integrated with Trimble FmX® and TMX-2050 guidance to display yield while on the move and as overall yield maps. Similarly, knowing the yield and quality of forage as it is being cut is a very useful management tool for livestock farmers to know what is coming in for storage and to assess feed potential. An example of this is the recent John Deere, HarvestLab, which can measure yield and dry matter of forage on the move, but also analyse dry matter, crude protein, starch, crude fibre, NDF, ADF, sugar and crude ash.\nIs digital farming only for developed countries? The widespread use and availability of mobile phones, 3G, 4G and internet in the third world means that some of the small-scale technologies could be used with minimal costs. Seventy per cent of the poorest population and 20 per cent of the low and middle-income countries have access to a mobile phone, and one in three people have internet access.\nThe priorities will be different in developing countries, for example pest control practices and the prediction of unforeseen extreme weather events will give a much greater payback than disease control. There will be an associated need for digital literacy which will be essential to make these systems work.\nAs technological uptake increases, so will the need for agricultural advisory services in smallholder farming communities. This could be done as distance learning from anywhere in the world.\nSeveral technologies such as drone-mounted sensors, laser weeding and insect trapping are all really suited to small scale agriculture if properly coordinated at a local scale.\nThere is a huge potential for local and regional coordination of crowd-sourced information and feedback, together with reporting on the success of the various technical solutions that have been used and their efficacy.\nFrom a mechanisation point of view, digital tools are being developed that aim to connect tractor owners and farmers for example Hello Tractor in Nigeria; EM3, Trringo and farMart in India; Trotro Tractor in Ghana; and Rent to Own in Zambia.\nThere is no doubt that we are in the midst of a Digital Farming revolution. As this article illustrates, there are a lot of technologies being developed, covering a wide range of crops, that will ultimately increase crop output and profitability.\nThe skill will be how all these individual components are bought together in a workable “systems-based approach”.\nFarmers very much favour the one-stop-shop or grower-portal approach, where one log in provides visibility of all the technologies active within a farming business. This concept is very much behind the development of the technologies themselves but needs to gain momentum to keep up with the pace of technical development.\nThe rapid technical development within the industry is also beneficial in attracting new entrants who may have previously viewed farming as rather traditional and low-tech.\nCropMonitor Pro is a state of the art sophisticated decision support platform which has been developed by Fera with Crop Health and Protection funded by Innovate UK\nCropMonitor Pro is a state of the art sophisticated decision support platform which has been developed by Fera with Crop Health and Protection funded by Innovate UK.\nCHAP’s Fine Phenotyping Lab is based at Rothamsted Research in Hertfordshire.\nCHAP’s precision machinery is housed at Stockbridge Technology Centre (STC), near Selby.\nCHAP has four mobile laboratories.\nCHAP plays a key role in developing new control strategies, which are going to be essential for the farmers and growers who are having to deal with the loss of actives in the market.- Dr Tom Ashfield , Rothamsted Research\nFor more information on our capabilities or to discuss a collaboration and/or grant for a commercially funded project, complete the form below."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:87a1e275-2135-47b2-968f-79245104797d>","<urn:uuid:163fa02d-e3f2-4968-8079-433beabbfadf>"],"error":null}
{"question":"EB curing vs laser marking systems: processing features and safety?","answer":"EB curing instantly dries inks, coatings, and adhesives by generating electron clouds in a vacuum chamber and accelerating them through a metallic foil window, effectively penetrating thick materials and working well with heat-sensitive substrates. In terms of safety, it requires monitoring of high voltage and compressed gases. Laser marking systems, on the other hand, require protection against both diffuse reflections (scattered light in all directions) and specular reflections (mirror-like reflections), and pose risks of skin effects (reddening, blistering) and eye damage. Both technologies require careful attention to electrical safety protocols and proper protective barriers.","context":["- THE MAGAZINE\n- INFO FOR...\n- ASI Store\n- ASI Top 25\n- ASI End User\n- Classifieds and Services Marketplace\n- Product & Literature Showcases\n- List Rental\n- Market Trends\n- Custom Content & Marketing Services\n- ASI Readers' Choice Awards\nThe world continues to embrace initiatives fostering more environmentally friendly “green” processes, and the converting industry is not exempt from this pursuit.\nAll aspects of the converting process are being scrutinized, including the need to make the adhesives and sealants component of converting more environmentally friendly. To this end, the industry is working to use fewer volatile organic compounds (VOCs), thus reducing emissions and odors that can contribute to things like respiratory issues and compromised air quality.\nCertainly the adhesives and sealants themselves are a worthy target for green innovation. In recent years, adhesive and sealant formulators and manufacturers have made great strides in improving their formulations, not only increasing product quality and durability, but also reducing VOC emissions.\nA second, perhaps less obvious target for greener adhesive and sealant use in converting lies in the curing processes being used. As the industry is beginning to realize, not all converting processes are created equal. Electron beam (EB) curing technology has grown to become an influential option for forward-thinking converters, especially those that harness web technology. Among its numerous advantages over other curing methods, EB technology produces almost no VOCs, unlike oven-based (thermal) curing.\nHow EB Curing Works\nIn an EB system, clouds of electrons are generated in a vacuum chamber using an electronically charged filament, usually tungsten. These electrons are then accelerated through a thin, metallic foil window and are directed onto a moving web surface at atmospheric pressure. These accelerated electrons ionize most organic materials, leading to the formation of free radicals that induce crosslinking of polymers or initiate polymerization of liquid monomers and oligomers (called curing). Crosslinking can be effective for improving the properties of polymers.\nCuring results in the instantaneous “drying” of an ink, coating or adhesive. EB systems are used primarily in the curing of printing inks and coatings for packaging applications; curing coatings on metal, wood and composite building material substrates; curing adhesives in the lamination of film and/or foil to paper for packaging; crosslinking plastic shrink films; and crosslinking of hot-melt pressure-sensitive adhesives (HMPSAs).\nAn alternate to ultraviolet (UV) curing and thermal drying, EB technologies have been used in industrial applications for more than 30 years. During this time, printers and converters have documented numerous real-world advantages enabled by EB technology, including improved product performance, superior product consistency, higher process throughput, and greater energy savings. Additional advantages include:\n• EB curing is able to penetrate thicker or more opaque materials more effectively than UV.\n• EB machines generate very little heat in the substrate, making them a superior choice over thermal and UV curing for heat-sensitive materials like thin films.\n• Unlike UV, EB technology does not require a photoinitiator in its curing process.\n• EB technology does not produce VOCs like thermal curing.\n• EB provides higher conversion and more consistent output while offering more efficient energy usage than other drying or curing technologies.\nInterest in EB technology has grown significantly in recent years because of the increased availability of EB-friendly adhesives, coatings, inks and other materials,\nInterest in EB technology has grown significantly in recent years because of the increased availability of EB-friendly adhesives, coatings, inks and other materials, as well as increased affordability. In the past, EB machines were large and could be very expensive.\nas well as increased affordability. In the past, EB machines were large and could be very expensive. Customers requested that smaller, less expensive EB systems be developed to provide cheaper, easier and less cumbersome integration directly into existing and new process lines. Equipment providers have responded to these requests by introducing innovative new designs that leverage advances in technology and years of industrial EB system experience.\nIntegrated Shield Roll Design\nOne innovative new design uses a “shield roll” for proper radiation shielding. This patented design uses a temperature-controlled roll to support the material while the roll simultaneously serves as a functional portion of the required shielding. The results are reduced size and materials, minimization of the volume that must be made inert with nitrogen, and easier machine access for threading and cleaning.\nAn important printing technology that has emerged in recent years involves the use of variable sleeves on web offset presses. This style of press requires the accompanying EB system to accept a low web entry height. The latest EB system designs accommodate these web handling requirements and maintain a “side fire” orientation, which is preferred for the maintenance access that is required to perform a window foil change.\nExtended Voltage Low Energy Systems\nThe first generation of more compact, lower cost EB equipment was introduced about 10 years ago. This equipment operated in the range of 80-125 kV, which was suitable for curing relatively thin layers of inks and coatings. Curing adhesives for lamination or crosslinking of thicker materials requires industrial EB processors operating from 150-300 kV.\nIn recent years, compact equipment has been introduced that can operate at up to 150 kV. This range has now been extended up to 175 kV. These higher energies allow one-side treatment of materials up to 150 g/m2 (150 microns for materials with a density of 1.0 g/cm3).\nAnother key evolution in EB’s role in the converting process extends beyond its traditional curing and crosslinking capabilities. With the addition of a recently developed integrated converting line, package printers can now also harness an EB machine to create innovative package design enhancement capabilities. An integrated converting line offers four interchangeable package enhancement operation modes, including coating, laminating, cold foil transfer and Cast and Cure™.\nCast and Cure from Breit Technologies is a decorative coating process that offers decorative effects such as ultra-high gloss, matte and holographic images on a variety of substrates. It also has anti-counterfeiting applications. It has proven to be a low cost, environmentally friendly process that uses reusable film to micro-emboss decorative effects into the surface of energy-curable varnishes.\nCrosslinking of PSAs\nMany high-performance pressure-sensitive tapes are produced by coating adhesive polymers from solvent-based solutions. These solvent coating lines must be equipped with incinerators to prevent VOC emissions. Hot-melt adhesive technology is very environmentally friendly since no solvents are used. The main disadvantage of hot-melt adhesives is the relatively low performance of these non-crosslinked systems.\nEB can be used to crosslink certain types of hot-melt polymers after application to the tape substrate. Low-energy EB systems operating up to 175 kV can effectively penetrate even relatively thick adhesive layers. This crosslinking dramatically increases the tape performance properties, particularly the temperature resistance, chemical resistance and shear properties.\nIn what many call a tepid economy, package converting continues to put up strong numbers, and analysts predict healthy growth will continue for some time. Sealants and adhesives continue to set the pace, and continued development of new, innovative products will help contribute to any gains in the coming years. For suppliers and manufacturers that arm themselves with versatile technologies like EB to help evolve new products and production techniques, this is a very exciting time to be involved in package converting.\nFor more information, visit www.teampct.com.","With the constant changes coming to the industrial and manufacturing sectors, and advanced equipment like laser marking systems becoming increasingly prevalent, it’s more important than ever to be aware of laser marking safety procedures.\nThese procedures range from ways to protect from bodily harm while utilizing laser marking systems to ways to avoid electrical dangers on the factory floor. It’s important to know what all of these dangers are and how to train yourself and your staff in essential laser safety.\nCommon Laser Hazards\nOne aspect to remember about laser marking safety is the variety of hazards associated with the systems which are also prevalent in many other forms of equipment. Basic safety training should mean workers are already familiar with some of these issues, but employers should be aware of:\n- High voltage\n- Compressed gasses\n- Intense radio frequency energy\nLet’s take a look at each of these individually:\n- For concerns regarding high voltage, it’s important to know that pulsed CO2 lasers can produce internal voltages exceeding 25,000 volts while containing large capacitors that can deliver in excess of 200 Joules of energy.\n- Some pulsed lasers also utilize a flowing gas design, which requires connection to a cylinder of compressed gas. Most of the gases used for laser systems are extremely safe, though since pressurized cylinders can pose a risk, their transportation and usage should occur only when the cylinders are properly restrained.\n- As for radio frequency energy, severe burns can result from the improper servicing of units which use RF generators, such as sealed CO2 lasers. Anyone servicing such units should be trained in the unit’s safety procedures, and the connections for RF energy should not be touched during operation.\nDue to the laser engraving safety checks in place for marking systems, units are designed in such a way to prevent operators from coming into direct contact with the laser beam.\nOne of the issues that can arise, however, involves unintentional reflected light, which falls into the following categories:\n- Diffuse Reflections – This type of reflection occurs when a reflective surface’s irregularities create a scattering of light in all directions. Of the types of reflections, this is the safer of the two since energy is being divided in many directions and weakened.\n- Specular Reflections – This type of reflection is produced in a way that is more mirror-like, recreating close to 100% of the original light compared to the scattered light of diffuse reflections. Though there is a higher danger associated with this form, it is much less common and laser marking systems are often designed to eliminate specular reflective surfaces that would come across the beam’s path.\nWith proper safety procedures in place, and by following guidelines which accompany your laser marking systems, these hazards should be greatly minimized.\nSkin and Eye Hazards\nDue to laser engraving safety checks in place, the effects of lasers on skin are usually considered of secondary importance. Compared to laser marking and engraving systems, high powered infrared lasers utilized in applications for welding and cutting pose a much greater risk of injury.\nSome potential effects that can occur if safety procedures are not followed include mild reddening, blistering, and charring, all of which are usually reversible or repairable. Other potential issues could include ulceration, scarring of the skin, depigmentation and damage to underlying organs.\nIn regards to eye safety, some forms of laser beams operate at a wavelength which if exposed to the eye can pass beyond to the retina. With no pain indicators present and the beam being invisible, someone exposed can be unaware at the time of occurrence.\nThis is just another reason why utilizing industry-standard laser safety glasses is so vital to maintaining a safe and healthy workspace.\nAn additional hazard that can be posed when using laser systems is that of electrical shocks. Some of the ways shocks can occur is through contact with:\n- Exposed utility power utilization\n- Device controls\n- Power supply conductors operating at potentials of 50+ volts\nOperators and service workers for laser marking systems must be especially careful to avoid these dangers by following standard safety protocols. These hazards could be experienced during:\n- Set-up and installation\n- Maintenance and service\n- Troubleshooting, if equipment protective covers are removed\nThe electrical injuries that can be sustained from improper and haphazard use of laser systems can include everything from a slight tingle to serious bodily injury to death. To avoid accidental contact with these energized conductors, laser marking units utilize a barrier system within the equipment.\nIn the United States, laser systems are overseen by the Center for Devices and Radiological Health (CDRH), which is a component of the FDA. Depending upon the risk of a specific type of laser, it is graded from Class I to Class IV. Laser marking lasers tend to be graded as Class IV lasers, making laser marking safety all the more important.\nTwo important additional classifications to keep in mind are the Maximum Permissible Exposure (MPE) and Nominal Hazard Zone (NHZ) designations.\n- Maximum Permissible Exposure – This is the highest level of laser radiation an individual can be exposed to without receiving harmful physical effects to the eye or skin. Control measures for laser marking systems are in place to ensure any laser radiation emitted falls below the MPE.\n- Nominal Hazard Zone – To create conditions for flexibility in laser marking applications, the laser beam of the unit is often not fully enclosed for practicality reasons. In these instances, it is necessary to define an area of potentially hazardous laser radiation, which is the NHZ. Control measures are then put into place for this area to ensure safety during use of the laser system.\nBeing fully aware of these classifications and their rationales are vital to ensuring proper workplace laser marking safety.\nLearn More About Laser Engraving Safety Today\nFor a more detailed look at laser marking safety information, be sure to visit our laser safety manual, which includes graphics, information about warning labels, and procedural controls to utilize.\nAnd if you have further questions for our team, or would like to know more about our premier line of laser marking systems, be sure to contact us today.\nLaser marking and engraving has a wide variety of applications for businesses and hobbyists, with everything from the medical field to the everyday carry subculture and more getting real benefits from laser marked parts.\nAt TYKMA Electrox, we design and manufacture industrial laser marking machines for applications across an array of industries. When it comes to deep laser engraving, our systems serve as cost-effective solutions for your marking needs. From standard products to custom-made machines, our team strives to make sure that you are receiving the best product available. […]\nLaser Marking in the Athletic Industry The market for the laser engraving industry has expanded significantly over the past few years. What used to be thought of as a process used only by industrial companies has broadened to reach businesses across many diverse fields. With countless applications and easy-to-use systems, laser marking has become a […]\nAt TYKMA Electrox, our laser systems are used to personalize a wide variety of everyday carry items. From knives to firearms, our lasers are built to intricately engrave your personalized designs or logos onto your gear. The systems we provide are even used for laser marking gun cases. If you’re interested in adding personalization to […]"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:fbdc10b0-1278-4bce-9194-02f04598ddae>","<urn:uuid:3c01b6d6-eff9-454b-bb0e-5715e14d0b14>"],"error":null}
{"question":"What are the main responsibilities of a Set Decorator in film and television?","answer":"Set Decorators are key members of the design team who work closely with the Production Designer and Director. Their main responsibilities include researching, resourcing, and acquiring all objects required to dress sets - from furniture, drapery, and lighting fixtures to large-scale items like machinery, street elements, or even rubble. They also collaborate with other filmmakers, manage budgets, hire and supervise crews, organize schedules, present period and style inspiration, shop for all set dressing needed, oversee set design and fabrication of custom objects, and work with the director to make final adjustments to sets.","context":["SET DECORATORS SOCIETY OF AMERICA MISSION STATEMENT\nThe mission of the Set Decorators Society of America is to promote the highest standards of excellence in the field worldwide, and to entertain, inspire, teach and preserve the legacy of set decoration in motion pictures and television.\nWhat Is A Set Decorator?\nSet Decorators are key members of the design team for film, television and commercials. Working closely with the Production Designer and the Director, the Set Decorator must research, resource, and acquire all the objects required to dress the sets. Typical examples of this set dressing may include furniture, drapery, lighting fixtures, art and other decorative objects. However, the Set Decorator is also charged with large scale items, which could include machinery or robots, sidewalk window dressing, street items (such as street lamps and mailboxes), even rubble and debris!\nThe Creative Process\nOver the course of preparation and shooting, Set Decorators:\nCollaborate: Meet with the Production Designer, Director, Producers, Costume Designer, Construction Coordinator, Cinematographer and other filmmakers regarding the design, decoration, lighting, and look of the project.\nBudget: Negotiate for Production approval and monitor on a daily basis the Set Dressing Purchases & Rentals Budget, and the Set Dressing Labor Budget.\nHire: Bring together the Set Dressing Crew and support contractors, set the tone for the work to be done, supervise the process, and be available to answer questions.\nOrganize: Break down the script, identify sets and practical locations, plan the objects to be acquired for each set, and schedule all deadlines for acquisition.\nResearch: Present period and style inspiration appropriate for each project. Prepare presentation boards with research, swatches, colors, and examples of objects.\nImagine: With the Production Designer and Art Director how characters and environments are to be portrayed and reflected within the layers of the set.\nShop: For all set dressing needed: furniture, fabrics, decorative objects, industrial items, lighting fixtures\nDesign: We are responsible for the design and fabrication of objects unavailable in the marketplace. This may include organizing alterations and upholstery, creating window treatments, painting and aging of set dressing, working with illustrators, set designers, scenic artists, sculptors, prop makers, metal smiths and other specialty craftspeople to achieve a finished product.\nDress: Oversee the dressing of the sets with the Set Dressers to the satisfaction and agreement of the Production Designer.\nPresent: Open each new set with the Director, making any adjustments needed.\nA Unique Professional Network\nThe Set Decorators Society of America, founded in 1993, is the only national nonprofit organization dedicated to the support of the past, present and future of our profession. Members include qualified Set Decorators of Motion Pictures and Television, including commercials and music videos, as well as Business Members who provide furnishings, materials, and professional services to our trade.\nWe offer fellowship and networking opportunities for set decorators, crew members and vendors within our craft, and a bridge to other design and technical professions in the entertainment industry. For emerging decorators, students and apprentices hoping to enter our field, we have Associate and Student Memberships as well as various educational opportunities.\nOur many activities preserve the past, provide businesses with strategies for success, and pave the way for an ever more professional group of Set Decorators in the future.\nSDSA CURRENT EXECUTIVE BOARD\nShirley Starks - President\nRegina O'Brien, David Smith - Vice Presidents\nNatalie Contreras - Recording Secretary\nJennife Gentile - Treasurer\nAmanda Carroll, NYC\nJon Danniells, ATL\nDaryn Reid Goodall\nAdrianna Cruz Ocampo*\nDavid Schlesinger, NYC\n* Business Member Rep, U Frame It Gallery\n**Buisness Membe Rep, Front Row Media\nCURRENT SDSA MEMBERSHIP COMMITTEES\nAwards Luncheon Committee\nPlans and prepares the annual awards luncheon including: choose the award recipients, working with the venue, working with various members to procure funding through donations and sponsorships and prizes from Business Members.\nCurrent members include: Daryn Reid Goodall, Shirley Starks, Corri Levelle (Sandy Rose Floral, Inc), Laura Richarz, Ellen Brill, Erica Rogalla, Christina Giovacchini, Demittajo Govan, Ashley Shoulder, Deirdre Loftus, Samantha Maggio, Cindy Patino (FIDM), Michelle Reid (Unique Antiques and Collectibles), Marcia Dios, Claudia Rovner, Kedra Dawkins, Colby Giovacchini, Adrianna Cruz-Ocampo (U Frame It Gallery), Tom Early (advisory)\nBusiness Members Committee\nProvides a network for those who offer goods and services to Set Decorators, including creative marketing channels that benefit the SDSA and the Business Members.\nCurrent members include: Adrianna Cruz-Ocampo (U Frame It Gallery) and Corri Levelle (Sandy Rose Floral) Co-Chairs, Jennifer Gentile, Bambi & Danny Bremgartner (Aah Inspiring Balloons), Mimi Clark (Front Row Media), Vincent Dyer (Vincent Dyer Architect), Pam Elyea (History for Hire), Gia Grosso, Marjori Madura (Frost), Natali Pope, Bob Pranga (Dr Christmas Rents), Shirley Starks, Chanida Trueblood.\nUpdates the SDSA bylaws as needed.\nCurrent members include: Regina O'Brien, Chair, Natali Pope\nCommunity Outreach Committee\nDevoted to giving service, support and educating the community that surrounds the commercial, television and film industry. Raises funds for donations to charity and SDSA member fund via art auction and other events.\nCurrent members include Phil Hoffman, Chair, Valerie Brenci, Mae Brunken, Susan Chooljian, Michele Hollie, George Karnoff, Carol Bayne Kelley, Chad Norris (H.D. Buttercup), Kristin Peterson, Rob Turner, Richard Walker, Beth Wooke. NOTE: new members to be vetted by COC chairs.\nA media watchdog acknowledging positive portrayals of Set Decorator's contributions to and work in the industry. Corrects errors and inaccuracies, bringing attention to misinformation and misrepresentation about Set Decoration in the media, raising awareness about our art and craft.\nCurrent members include: Tom Early, Chair, Donald Elmblad, Ron Olson, Lorraine Genovese\nOrganizes Day with the Set Decorator events. Outreach to SDSA Student Chanpters and schools providing instruction in film and televsion.\nCurrent members include: , William De Biasio, Daryn Reid Goodall Co-Chairs, Halina Siwolop Karen Burnett, Nicole Case, James Connelly, Natalie Contreras, Adrianna Cruz-Ocampo, Don Diers, Amy Feldman, Nancy Garber, Daryn Reid Goodall, Corri Levelle, Lia Lopez, Lauren Lustig, Laura Richarz, Rand Sagers, Dan Schultz\nOversees SDSA Elections: Board of Directors and Officers in alternating years. Contacts nominated members, explains duties to potential board members or officers. Oversees ballot by mail for board members, election by board for officers.\nCurrent members include: Halina Siwolop, Regina O'Brien, Shirley Starks\nProvides networking opportunities and organizes the general membership meetings as well as member cocktail parties and mixers. Subcommittees my be introduced for putting together special events outside of regular calendar of events.\nCurrent members include: Natalie Contreras, Ron V. Franco, Jerie Kelter, Michele Munoz, Sony Sikkila-Dias (Fox Studio Production Services)\nExplores and defines the future growth of the organization within the profile of the craft as well as area of the community and industry.\nCurrent members include: Rosemary Brandenburg\nReviews membership applications, contacts applicants and maintains memberships files and cards, Reaches out to prospective and new members with packets and guidance.\nCurrent members include: Phil Hoffman, Chair, Maryann Biddle, Ellen Brill, Lynda Burbank, Cindy Carr, Don Diers, Linda Sutton-Doll, Shelley Freeman (The Mannequin Gallery), KC Fox, Carol Bayne Kelley, Jerie Kelter, Maria Nay, Denise Pizzini, Natali Pope, Beth Rubino, David Smith, Michele Stern (Astek), Beth Wooke\nPlans for the financial health of the SDSA.\nCurrent members include: Daryn Reid Goodall, Melinda Ritz\nKaren Burg, Editor\nSDSA's face to the world. Maintains website, keeps content and articles current. Supports website via advertising sales, provides data on viewer statistics.\nCurrent members include: Beth Wooke, Chair, Rosemary Brandenburg, Victor Zolfo, Natalie Contreras, Ron V. Franco, Regina O' Brien, Jan Pascale, David Smith, Bryan Venegas,Jennifer Gentile\nInterested in sponsoring our website?\nAdvertising units start as low as $25 per month.\nSet Decorators have purchasing and decision making power. Our website, www.setdecorators.org is the only website dedicated to the craft of set decoration within the film and television industry.\nEmail us at firstname.lastname@example.org or click on the PDF of the General Sponsorship rate card. (Members of the SDSA enjoy up to 50% discount-Membership Applications below):\nEmail us at: email@example.com\nPlease contact us in any of the following manners:\nAttention: Beth Wooke SDSA website chair\nMaria Margarita Lopez: Sales & Marketing\nGene Cane, Executive Director\n7100 Tujunga Ave., Suite #A\nNorth Hollywood, CA 91605\nemail administration: firstname.lastname@example.org\nThe SDSA is a 501-C6 Not for Profit Corporation\nTo support these ventures, we rely on membership dues, donations from Corporate Sponsors, magazine and website advertising revenues, activity fees, and grants from those concerned with small business development and educational support.\nThe SDSA is separate and apart from any labor union and the organization does not represent Set Decorators in negotiations regarding wages or working conditions, leaving this function to our local unions, including IATSE Local 44 in Los Angeles and Local 52 in New York."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:cb0b7186-31fa-4941-9dd0-3898d67274c5>"],"error":null}
{"question":"Hi, I'm considering animation for my brand - what are the main differences between 2D and 3D animation for creating brand characters, and what tools does Blender provide for this purpose?","answer":"While 2D animation can create clean, sophisticated looks that work well for brands, 3D animation in Blender provides a complete range of motion and life-like appearance once characters are rigged. Blender offers comprehensive modeling tools, materials creation, sculpting features for organic subjects, and texturing capabilities including UV unwrapping. For brand characters, 2D animation can be created faster for individual videos, while 3D animation requires more initial setup but is more efficient for long-term brand mascots (like the Geico gecko) since the character can be easily reused. Blender also includes features like compositing, motion tracking, and extensive import/export support for various file formats to help with brand content creation.","context":["Blender is a free and open-source 3D animation suite software. It supports the entirety of the 3D pipeline—modeling, rigging, animation, simulation, rendering, compositing and motion tracking, even video editing and game creation.\nAdvanced users employ Blender’s API for Python scripting to customize the application and write specialized tools; often these are included in future releases. It is well suited to individuals and small studios who benefit from its unified pipeline and responsive development process.\nBlender is cross-platform and runs equally well on Linux, Windows, and Macintosh computers. Its interface uses OpenGL to provide a consistent experience. It has no price tag, but you can invest, participate, and help to advance a powerful collaborative tool: Blender is your own 3D software.\nFeature of Blender:\nBlender now features a powerful new unbiased rendering engine called Cycles that offers stunning ultra-realistic rendering.\nBlender’s comprehensive array of modeling tools make creating, transforming and editing your models a breeze.\nWith this software new rendering engine, the possibilities for materials are endless.\nTransforming a model into a possible character has never been easier!\nBlender offers an impressive set of rigging tools including:\n- Envelope, skeleton and automatic skinning\n- Easy weight painting\n- Mirror functionality\n- Bone layers and colored groups for organization\n- B-spline interpolated bones\nBlender’s animation feature set offers:\n- Character animation pose editor\n- Non-Linear Animation (NLA) for independent movements\n- IK forward/inverse kinematics for fast poses\n- Sound synchronization\nExperience the joy of sculpting organic subjects using the built-in sculpting feature set of Blender.\nFast UV Unwrapping\nEasily unwrap your mesh right inside Blender, and use image textures or paint your own directly onto the model.\nThe blender comes with a fully-fledged compositor built right in. That means no more exporting to third party programs, you can do it all without leaving the program.\nWhether you need a crumbling building, rain, fire, smoke, fluid, cloth or full-on destruction, Blender delivers great-looking results.\nIncluded in Blender is a complete game engine, allowing you to create a fully-featured 3d game right inside Blender.\nCamera and Object tracking\nThis software now includes a production-ready camera and object tracking. Allowing you to import raw footage, track the footage, mask areas and see the camera movements live in your 3d scene. Eliminating the need to switch between programs.\nLibrary of Extensions\nWith a large community of enthusiasts and developers, It comes loaded with a vast array of extensions that you can turn on or off easily.\nNovice and advanced users will love the ability to customize their layout completely. From simply splitting their viewport, to fully customizing it with python scripting, so it works for you.\nIt comes packed with import/export support for many different programs. Image: JPEG, JPEG2000, PNG, TARGA, OpenEXR, DPX, Cineon, Radiance HDR, SGI Iris, TIFF. Video: AVI, MPEG and Quicktime (on OSX). 3D: 3D Studio (3DS), COLLADA (DAE), Filmbox (FBX), Autodesk (DXF), Wavefront (OBJ), DirectX (x), Lightwave (LWO), Motion Capture (BVH), SVG, Stanford PLY, STL, VRML, VRML97, X3D.\n|Processor||64-bit quad-core CPU|\n|Memory||2 GB RAM (8 GB RAM Recommended)|\n|Graphics Card||OpenGL 3.2 compatible card with 2 GB video RAM (CUDA or OpenCL for GPU rendering)|\n|Display||1920×1080 pixels, 24-bit color|\n|OpenGL Version||2.1 (Blender 2.77 up to 2.79b)|","2D and 3D Computer animation: Know the Distinctions\nIf you think you’ll require unique glasses to check out 3D computer animation, this post is for you.\nKidding (kind of).\nYet typically, individuals are puzzled by the distinctions between 2D as well as 3D animation, and specifically the processes involved in developing each kind. There isn’t a much better type of computer animation, but it is very important to recognize how they each job to establish which is a much better suitable for your timeline and also objectives.\nEach can serve a wide variety of objectives as well as styles, all depending upon the vision as well as goals of the project. While 2D computer animation appears flatter, it could still result in a tidy, advanced look. Likewise, it could also be developed with an one-of-a-kind, detailed look that can work well for several jobs and also brand names. 3D animation gives you a complete series of activity once a personality is rigged– which we’ll clarify in a moment. You can in fact see around the last character, which offers it that crisp, life-like look.\nWe developed the adhering to 2D computer animation for the New york city Council on Trouble Gaming.\nJeff Fugelsang, an activity graphics designer on Overit’s Movement group, compares the comparison between 2D and also 3D animation to the distinction in between illustration as well as sculpting. Either type can be personalized to fit a variety of designs and also functions, so choosing a strategy actually comes down to the client’s preferences, goals, timeline and also budget.\nJust how 2D as well as 3D Computer animations Are Produced\nThe procedure for developing both 2D and 3D animations typically start the same way, then the course forks.\nRegardless of the animation style, animators will initially learn more about the vision and objectives that the customer has going into the job. They will create principles then showed storyboards to bring these ideas to life. When a storyboard is accepted, it gets in the animatic phase, relocating the pictures right into the suitable computer animation software– which will be different for 2D as well as 3D. The animatic is where sound clips and voiceover are added as well as motion is introduced to the characters. This is where things get vastly various.\nWhen a 2D personality is drawn, the animator has to highlight the key presents and also scenes, consisting of a drawing in every structure, with 24 frameworks per second being the requirement. Depending upon the speed of the computer animation, a personality drawing can continue to be still for a few frameworks each time. The same is hardly ever real for 3D computer animations, which have to remain in near-constant movement to keep their realistic appearance. It could be subtle, yet living points blink, take a breath as well as shift their pose, so reasonable 3D animations must do the very same. After the animatic is developed, the animator after that functions to version and also gear the character. Modeling is essentially the process in which the character is constructed, and afterwards the rigging develops the personality’s skeletal structure beneath that permits animators to regulate the motions of the personality. It’s a little bit like creating a creature.\nTime Investments for Developing 2D as well as 3D Animations\nTiming will be totally dependent upon the task, and either could be produced quicker– or gradually- based upon numerous imaginative factors and customer requests. Producing a 3D animation is usually more time-intensive in advance, with the need to gear the personality. It’s a highly-detailed procedure, once it’s finished, the animators could re-use the character and change its poses over as well as over once again– which is a benefit for personalities that will have a long life-span with their brand (i.e. The Geico gecko) or for us, the Catseye personalities we created at Overit. This is also why 3D computer animations are much more time-efficient and affordable for animated attributes from business such as Pixar.\n2D computer animations could be created quicker for a certain video, and also the work of the task is usually extra evenly dispersed throughout the procedure. A different variation of personality rigging happens here, by using the ‘puppet pin’ tool to earn bendable factors in the personality’s composition (elbows and knees, for instance). A set up 2D character can be received stages throughout the procedure, allowing for even more minor adjustments and flexibility (make him elevate both arms, not simply one!).\nDeciding Between 2D as well as 3D Computer animation.\nProducing a 3D computer animation requires a solid understanding of the task in between the customer as well as animators, as a great deal of job will certainly take place in the first rigging process. The procedure where the computer system assembles all the computer animation work into video clip layout usually takes much longer, too. However, once it’s done, it could be repurposed for future animations reasonably conveniently.\nIn order to produce a new video clip with a 2D animation, you may have to draw brand-new angles and placements for the personality gears, which will certainly take even more time if the needed angles as well as creature pins haven’t been created in advance. If you could intend ahead from the beginning of your first project, you could connect these prospective requirements for the future with your computer animation team. They could after that work to create the proper angles as well as puppet pins ahead of time– for this project as well as future projects, so adjustments are easier to apply for future animations.\nJust how do you decide? A lot depends upon your visual preferences, yet likewise take into consideration questions such as:.\nDo we plan on re-using this computer animated character in future videos or advertisements?\nAre we searching for a (potentially) irreversible mascot or icon for our brand?\nDo we intend to experiment with different characters in the future to target other segments?\nExactly what’s our timeline?\nWhat’s our budget?\nWhere will these animations be displayed?\nShould our computer animation be character-based, or information/process-based?\nIt is essential to have a great vision of the final video clip you desire to create, the target market you intend to reach with it and also the goals you desire to accomplish, as they will greatly influence the choice to produce 2D and/or 3D computer animations. Once you as well as your animation group both recognize the designated objective and objectives for placing the computer animation to make use of, it’ll come to be easier to choose which techniques to embrace."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:5b2c29de-fa7b-4cee-8ef8-966783508fae>","<urn:uuid:f08c2866-1f29-4239-8d68-0e73617f131f>"],"error":null}
{"question":"I study navigation history. Which technology was used earlier - marine compass by Chinese or GPS system for global navigation?","answer":"The Chinese began using compasses much earlier than GPS. According to historical records, the first compass was used in China around 200 B.C., and by 800 A.D. compasses had gained widespread use in China. In contrast, GPS is a very recent technology that was not operational until 1994. The system consists of 24 satellites orbiting about 20,200 kilometers above Earth's surface and allows for accurate positioning even in extreme conditions.","context":["It is not known where or when it was discovered that the lodestone (a magnetized mineral composed of an iron oxide) aligns itself in a north-south direction, as does a piece of iron that has been magnetized by contact with a lodestone. Neither is it known where or when marine navigators first utilized these discoveries. Plausible records indicate that the Chinese were using the magnetic compass around 1100, western Europeans by 1187, Arabs by 1220, and Scandinavians by 1300. The device could have originated in each of these groups, or it could have been passed from one to the others. All of them had been making long voyages, relying on steady winds to guide them and sightings of the sun or a familiar star to inform them of any change. When the magnetic compass was introduced, it probably was used merely to check the direction of the wind when clouds obscured the sky.\nThe first mariner’s compass may have consisted of a magnetized needle attached to a wooden splinter or a reed floating on water in a bowl. In a later version the needle was pivoted near its centre on a pin fixed to the bottom of the bowl. By the 13th century a card bearing a painted wind rose was mounted on the needle; the navigator could then simply read his heading from the card. So familiar has this combination become that it is called the compass, although that word originally signified the division of the horizon. The suspension of the compass bowl in gimbals (originally used to keep lamps upright on tossing ships) was first mentioned in 1537.\nOn early compass cards the north point was emphasized by a broad spearhead and the letter T for “tramontana ,” the name given to the north wind. About 1490 a combination of these evolved into the fleur-de-lis, still almost universally used. The east point, pointing toward the Holy Land, was marked with a cross; the ornament into which this cross developed continued on British compass cards well into the 19th century. The use of 32 points by sailors of northern Europe, usually attributed to Flemish compass makers, is mentioned by Geoffrey Chaucer in his Treatise on the Astrolabe (1391). It also has been said that the navigators of Amalfi, Italy, first expanded the number of compass points to 32, and they may have been the first to attach the card to the needle.\nDuring the 15th century it became apparent that the compass needle did not point true north from all locations but made an angle with the local meridian. This phenomenon was originally called by seamen the “northeasting” of the needle but is now called the “variation” or “declination.” For a time, compass makers in northern countries mounted the needle askew on the card so that the fleur-de-lis indicated true north when the needle pointed to magnetic north. This practice died out about 1700 because it succeeded only for short voyages near the place where the compass was made. It caused confusion and difficulty on longer trips, especially in crossing the Atlantic to the American coast, where the declination was west instead of east as in Europe. The declination in a given location varies over time. For example, in northern Europe in the 16th century the magnetic north pole was east of true geographic north; in subsequent centuries it has drifted to the west.","Letter from Stephanie: Global Positioning System\nDear Fellow Explorers,\nAs I write to you, I take a peek out the porthole window; the cold Antarctic Ocean stretches as far as the eye can see.\nWhere are we? This is a common question aboard our vessel (often followed by, \"Are we having fun yet?\"). And I can figure out where we are by using both traditional and modern tools.\nBeing able to plot our location at any given moment is very important for our research. In order to be able to make accurate interpretations of our data, we need to know the exact location of any geological features we see or samples we collect. We keep careful navigation records so that we can return to sample locations in the future. Of course we also need to know where we are and where we are going so that we can get home eventually!\nExploration navigation has gone through many changes since the first humans set out over the seas or over the lands surrounding their early communities. The earliest explorers had few navigational tools; they stayed within sight of land if they were on the water, or within sight of landmarks while on land. As human beings learned the patterns of celestial bodies, explorers could use the positions of the Sun or stars to guide them. Consider the advantages–what could the stars in the sky or the position of the Sun offer that features on land could not? And what would happen if weather blocked the view of these heavenly navigation devices? Stars and other celestial bodies were unique and easy to identify; and while landmarks required that explorers stay close to land, celestial bodies could be seen from anywhere on the globe, far out on the high seas. On the other hand, clouds and storms made it impossible to use celestial bodies for navigation; in poor weather, explorers could get lost.\nMajor advances in navigation technology helped to spur the exploration age, starting with the common use of compasses on European ships in the 1100's. (The Chinese had begun using compasses long before; the first compass was used in China in 200 B.C.; and by 800 A.D., compasses had gained widespread use!) Because a compass needle always points toward the magnetic poles, sailors were finally able to steer a course using a known direction–and could return from that direction–all without landmarks or even the guiding light of stars.\nBy the 1500's, the navigation technology revolution made another leap, with the advent of the astrolabe and sextant. These instruments measured the position of the Sun or stars relative to the horizon in order to determine precise latitudes. With a compass and a sextant, sailors could determine the direction in which they were heading, and their latitude.\nThe astrolabe and the sextant helped sailors pin-point their latitudinal position on the globe; but they still needed a way to plot longitude. In other words, they could calculate their position relative to the North and South Poles, but they could not determine their east-west position; and thus, they couldn't determine where they were on the globe.\nThen in 1761, an English clock maker named John Harrison solved this conundrum. That's right, the same clock that you take for granted today was a revolutionary navigation tool in the eighteenth century. Harrison's well-made clock could keep accurate time in rough seas or harsh travel; and sailors knew that there were fifteen degrees of longitude for every hour difference between noon at home and noon at any given location. By knowing the time at home, and knowing when it was noon in their new location, navigators could determine their distance from home. This was the last piece of the puzzle–at last explorers could pinpoint their locations accurately during the journey.\nFor a few hundred years, these navigation tools were enough. With the advent of radio signals, however, ships at sea could plot their locations and navigate a course with even greater accuracy. Ships (and planes) received radio signals from a known location; using the time they received the signal, as well as the pattern of the signal, sailors could calculate their positions with a greater degree of accuracy.\nShips at sea still use all of these methods; but many of them have disadvantages, especially in Antarctica. What might be the disadvantages of the compass, the astrolabe and sextant, and even radio signals in Antarctica?\nWell, the compass uses the magnetic pull of the South Pole; but Antarctica is too close to the South Pole to get an accurate compass reading! The extreme conditions of Antarctica make it hard to use the astrolabe and the sextant; it's hard to see the Sun and stars during blizzards! Even reasonably calm days may include constant cloud cover; and don't forget, you can't see the Sun for six months during the Antarctica winter, and you can't see the stars for six months during the Antarctica summer! Finally, Antarctica is huge, and very far from radio transmitters; as a result, radio signals have limited use there.\nThese disadvantages are eliminated with the latest navigation technology, the Global Positioning System (GPS). The network and technology is still quite new–the system was not up and running until 1994. But today research teams in Antarctica and all over the world use GPS, a network of satellites that allow for the most accurate positioning and navigation, even in the most extreme weather conditions of Antarctica–and even in the darkest, windiest, coldest Antarctic winter. This is good news to anyone working on the continent or in the icy Antarctic waters, where knowing your position can be a matter of life and death!\nSo how does it work? There are twenty-one working satellites and three spare satellites in the GPS, making a total of twenty-four in the network. Each satellite circles the globe twice a day, at about 20,200 kilometers above Earth's surface; and at any point in time, six of the satellites can be \"seen\" from almost every location on Earth. Each satellite sends its own set of radio signals back to Earth, and the radio signals are different for each satellite; this way, scientists can tell which satellite is sending the signal, and thus pinpoint the location they are seeking. The radio signals include exact transmission time and location information; they travel very fast, at the speed of light, in fact! That's 186,000 meters per second!\nWho receives these signals? You might have received one, if you have GPS in your car! A ship, a car, a plane, or a person can have a GPS receiver, which gathers and translates the signals from three or four satellites. Because the satellite signals have a time stamp (the time when the signal was sent from the satellite), receivers can calculate the exact amount it took to receive the signal. Because the speed of the signal is known, the time from the moment the signal was sent by the satellite to the moment it was received by receiver can be used to calculate the distance between the satellite and the receiver. (That's a simple equation you might have learned in math class–rate times time equals distance!)\nJust one satellite wouldn't be enough to calculate an exact position; in fact, the receiver uses calculations from the three or four satellite signals to determine the position. Each satellite sends a signal in all directions. Imagine that the signal is a sphere with the satellite at its center; the sphere intersects the sphere of the Earth in a circular area. You might want to draw a picture of two intersecting spheres to see how that works for yourself.\nThis signal reaches Earth's surface and is \"heard\" by the receiver; but the receiver can only determine the area of the circle, not its exact location within that circle. With a second satellite signal, the receiver has two circular areas that define its location; so the location has to be somewhere where these two circles intersect. Try drawing two intersecting circles–they have to intersect at two points. That means that the receiver has figured out two possible points for its location. It needs a third signal to know which of the two locations is the right one. By calculating position based on three or four satellites, the receiver can determine a location to within 100 meters!\nGPS is used by the scientists in many ways, such as locating meteorites, mapping the features left by past glaciers, and surveying new regions. Without GPS, we would not be able to monitor tiny changes in the size of sea ice or in the thickness of the ice sheet. If we want to make accurate predictions about how the Antarctic environment may change in the future, it's critical that we can pinpoint these tiny changes.\nBut right now I just want to pinpoint the location for breakfast–and for that, I don't need any navigation tool but my own nose, guiding me towards the smell of pancakes up in the galley! That's all for now–enjoy your exploration!\nMore About This Resource...\nThis online letter, which appears as both a Web article and a printable PDF, is part of a series written by a glacial geologist working in Antarctica. In her \"letters home,\" Stephanie Shipp shares her work and discoveries. Specifically, this letter discusses:\n- how the compass and other navigation tools helped spur the exploration age,\n- the many changes that navigation technology has gone through since then,\n- the problems inherent in using many of these tools for navigating in and around Antarctica, and\n- the many advantages offered today by GPS.\nLess than 1 period\nSupplement a study of Antarctica with an activity drawn from this essay about the Global Positioning System.\n- Survey students about what one navigation tool they'd want to find their way around Antarctica.\n- Send students to this online article, or print copies of the essay for them to read.\n- Have them write a one-page reaction to the article, explaining whether their navigation tool of choice has changed, and why.\nSubtopicTools and Methods"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:9ec82308-1c61-42d4-86d1-1f015080386d>","<urn:uuid:e8db34d8-6f22-4a35-b5cf-10694cf4b8b8>"],"error":null}
{"question":"What is the relationship between modern water treatment systems and environmental sustainability, particularly regarding waste management and water quality?","answer":"Modern water treatment systems and environmental sustainability are closely interconnected through multiple processes. In residential settings, water treatment has become a necessity rather than a luxury, particularly due to the trend toward more efficient and environmentally friendly homes with low-flow fixtures using as little as 1 gpf (gallons per flush). For wastewater treatment, domestic sewage undergoes four main stages of physical, chemical and biological processes to remove solids, organic matter, pathogens, metals and nutrients. The treated wastewater becomes nearly indistinguishable from drinking quality water and can be reused for vineyards, parks, and ovals, providing environmental and economic benefits. Modern treatment plants are also effective at eliminating pollutants from household products, with wastewater being treated to a purity level that isn't detrimental to the receiving environment. Any remaining compounds that haven't completely degraded during treatment are further broken down in soils.","context":["Taking the mysteries out of water treatment\nProblem water can create issues that lead to unwanted, additional service calls for your business.\nPlumbers are already pumping, pressurizing and heating water, but how much do they know about water quality and how to properly treat water to solve problems in the modern home?\nWater in the residences and businesses where your customers live and work touches the pipes, plumbing fixtures, and hot water heaters, as well as dishwashers and washing machines. Something as basic as elevated hardness could easily cause problems for your customers, especially if they have high-efficiency appliances and low-flow fixtures in their household.\nProblem water can create issues that lead to unwanted, additional service calls for your business. But, when you take the mysteries out of the water and gain an understanding of the science behind how to treat it, you’ll become a much better contractor — and your customers will benefit from having a local water quality expert.\nArming yourself with knowledge is the first step in becoming familiar with the best practices of water treatment. Here’s a high-level explanation of two of the most common factors in water quality: hardness and corrosion.\nWater is considered “hard” when it contains metal ions, or minerals, which are dissolved in groundwater. That includes calcium, magnesium and iron. Although hardness levels vary greatly by region, most homes with private wells have hard water, and many homes on municipal water do, too. In fact, more than 80% of households in the U.S. have hard water.\nThe biggest issue with hard water is the deposit it leaves behind. This causes excessive soap scum, clogs pipes and fixtures, wears down appliances, and creates many other headaches for homeowners.\nWater softeners remove hard minerals through an ion exchange process. Water softening resin is charged with sodium, which is exchanged for the calcium and magnesium that is retained inside the softener. This creates the soft water that is ideal for cleaning and bathing.\nWhen it comes to iron, typical softening may not do the trick. In some cases, ferrous iron, which is dissolved and colorless in the water, needs to be oxidized so it turns into a particle (ferric) and can be filtered out of the water.\nPlumbers have certainly witnessed their fair share of problems caused by corrosive water. Certain properties of water increase its corrosiveness, which negatively impacts plumbing and appliances:\nTemperature. Raising the temperature of water allows oxygen to escape, which can cause corrosion and pitting in copper and iron piping.\nPressure. Lower water pressure combined with hot water will magnify corrosion.\nTotal dissolved solids (TDS). This is the measure of all organic and inorganic matter in water. TDS levels above 2,000 cause corrosion through electrolysis. TDS levels below 80 cause corrosion from an appetite to dissolve more minerals.\nPotential of Hydrogen (pH). Pure water is neutral, but it can become acidic or basic depending on what chemicals are mixed with it. Acidic water (low pH) can cause pinhole leaks in pipes as well as blue/green staining. Basic water (high pH) leads to build-up and clogging of pipes.\nWe are only scratching the surface of water chemistry here. Once you have a deeper understanding of the science, you need to know how to test and measure water quality. Then, you must learn how to treat the water with the right equipment and most effective media.\nThat’s where the real opportunity lies, because water treatment in the typical household is no longer a luxury — it is a necessity.\nWater challenges in the modern home\nIn just a few years, the demand for in-home water treatment has increased noticeably, and much of that is because of the pursuit for more efficient and environmentally friendly homes.\nFixtures and appliances are being designed to use significantly less water. For example, toilets went from using 1.6 gpf to 1.26 gpf, and some use as little as 1 gpf.\nLow-flow fixtures help homeowners conserve water. However, if there’s just a little bit of calcium buildup in the tiny holes of a low flow showerhead, suddenly the homeowner isn’t getting enough water to rinse their hair. The same goes for a low-flow toilet. When there is lime scale buildup in the toilet’s trap, it won’t flush the way a homeowner expects.\nThe Water Quality Association (WQA) has conducted conclusive research on how hard water and soft water affect appliances like water heaters. The results were clear: Hard water accelerates wear and reduces the expected lifespan of appliances. Soft water, on the other hand, leads to reduced detergent usage and requires lower water temperatures, which means less corrosion.\nDetergent is yet another issue. Due to environmental concerns, phosphates were removed from laundry and dishwashing detergents. Those phosphates helped soften hard water, making detergent more effective at cleaning dishes and laundry.\nAfter the detergent formula changed, many people thought their dishwashers and washing machines weren’t working. It’s gotten to the point where some manufacturers are building water softeners into dishwashers.\nOf course, a more permanent, all-encompassing solution is to have a whole-house water softener installed. Making a recommendation like this is an opportunity for plumbers to establish themselves as helpful experts. If you start selling and installing water treatment equipment, it’s also a new revenue stream. As a plumber, you’re already having conversations with people directly related to water quality. Why not help them fix it?\nBut, first thing first. Find resources and experts to help you learn about the science and art of treating water so you can advise your customers with confidence.","Using a mainstream detergent is not detrimental to the waste water system and end environment.\nWhere Does The Dirty Water Go?\nDomestic sewage, i.e. water from indoor drains and toilets in Australian cities and towns, is collected and treated at wastewater treatment plants (WWTP).  This does not include street or storm water drains, which often flow straight to the sea.\nWhat Happens To The Water At The Treatment Plant?\nThe treatment of sewage or wastewater involves a series of physical, chemical and biological processes to remove solids, organic matter, pathogens, metals and often the added nutrients . Wastewater treatment has four main stages, with advanced treatment being added to the third stage when the wastewater is returned to potable (drinkable) or near potable standard, ensuring it is suitable for eventual reuse or discharge.  After the final stage, the treated wastewater is nearly indistinguishable from drinking quality water of natural origin. \nEach treatment plant has different available technologies, capacity and treatment levels, some do primary, secondary or tertiary treatment, with tertiary being ideal, and the best for the end environment.\nThe first preference for using tertiary treated water is on vineyards, parks, ovals. The reuse provides environmental and economic benefits to the state. In many states of Australia, reuse where possible is encouraged and in some cases policy. The second preference is discharge to the environment e.g. a river or ocean.\nIn many (but not all) jurisdictions in Australia, if released into the ocean or a river, it must be at a purity level that won’t be detrimental to the receiving environment. The receiving sea or inland water environment is tested regularly throughout the year by the relevant State Government regulatory authority and the activity is also licensed.\nMany areas have seen increases in investment for improved waste water management in recent years. To gain an understanding of what stage the facility undertakes, and where they discharge, research your local water providers current waste water management processes.\nIn an ideal world disposal of human waste would have no environmental cost. There are varying environmental impacts of all products used. It is necessary to balancing the costs and benefits of each when choosing which to use, without compromising the end result.\nWaste Water Treatment Stages\nSee this page for a more detailed explanation.\nHistory Of Laundry Detergents And Their Environmental Impact\nSoaps were the first washing aids, used to wash laundry by hand with a wash board. These original soaps did not degrade in the environment, the residues remained in waterways. By the 1950’s, drains and rivers often carried persistent mounds of foam, and the water became toxic to small organisms. \nDetergents then replaced soaps but were found to be poorly biodegradable.  Manufacturers subsequently began making washing powders biodegradable, so that they decomposed naturally as soon as possible after use. ‘Builders’ were also added, which bind to and remove ions from water (the more ions, the harder the water) and in doing so, soften the water during the washing process. The purpose of water softeners is to make detergent more effective, so that less is required. Reducing water hardness during the wash cycle is a significant factor in the effectiveness of modern detergents.\nHistorically, phosphates were used as water softeners in detergents. Excess phosphates cause problems in inland waterways, causing eutrophication, which is the enrichment of bodies of fresh water by inorganic plant nutrients such as nitrate and phosphorus . The consequence can be blue-green algae outbreaks which are toxic to the river ecosystem and also to humans. An example of eutrophication is the depletion of oxygen in the water. Another consequence of eutrophication is the prolific growth of particular plants (including algae) and depletion of light and oxygen in the water, resulting in die off or “dead zones”. With decreased use of phosphates, the negative environmental impact of detergent use has greatly reduced. Phosphates were phased out of Australian detergents by 2008.\nModern Detergents And Their Environmental Impact\nYou will see modern laundry detergents labelled as ‘biodegradable’. The term biodegradable refers to the ability of a material to be broken down, by a group of biological organisms called decomposers. Decomposers are a necessary component of a balanced ecosystem, present in natural waters and sediments, and are encouraged in sewage treatment works. Bacteria are the most common decomposers.\nThe Australian Standard for biodegradability (AS1792—Methods to Determine the Biodegradability of Surfactants) requires 80% of the detergent mixture to be degraded within 21 days if the product carries the label ‘biodegradable’. This standard is voluntary,  and as with the removal of phosphates has been taken up by companies in response to consumer demand, applying to both ‘eco’ and ‘non-eco’ detergents. Detergent companies provide this information on their packaging and websites, most are happy to provided information on request.\nSurfactants (which are the cleaning agents) in detergent are biodegradable. Through the natural process of chemistry and aided by the waste water treatment process, they are broken down to carbon dioxide (CO₂) and water (H₂O). Only a very small fraction of surfactants are unable to aerobically break down during processes of modern treatment plants. This fraction, due to the predominantly hydrophobic (water repelling) nature of surfactants, adheres to a byproduct ‘sludge’ created during at the treatment plant. The sludge is then further treated, see below. \nThe Impact Of Other Laundry Products, e.g. Bleach and Canesten\nPollutants from household products are almost completely eliminated at the treatment plant, the wastewater is treated to a purity level and returned to potable (drinkable) or near potable standard, so that is not detrimental to the receiving environment. Insoluble salts or low water soluble surfactants are processed into a ‘sludge’, which is then decomposed. Once decomposed the sludge is dried, treated and disposed of to landfill. The high content of organic material and nutrients means it can also be used for agricultural purposes as a fertiliser. The very small amount of remaining compounds that have not completely degraded during the treatment process are further degraded in soils.\nBleach (Sodium Hypochlorite) degrades to salt, water and oxygen. A large percentage has already completely degraded by the time it reaches the treatment plant. The biodegradation rate of Benzalkonium chloride, the active ingredient in Canesten, is very slow.  It remains in the sludge at the treatment plant. Although Benzalkonium chloride does biodegrade eventually, when comparing the two sanitisation methods of either bleach or Canesten, overall bleach is a better choice for the environment.\n Asano, T (1998). Wastewater reclamation and reuse. Water Quality Management Series Volume 10, CRC Press, Boca Raton, FL, USA.\n Water Recycling in Australia https://www.environment.gov.au/system/files/pages/5590fe3c-1a60-4558-9d14-381b98ee80d1/files/hs44radcliffe-water-recycling-australia.pdf\n The Disposal of Soaps and Detergents EPA 547/04—April 2004\nAuthor A. Michailov"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:f856015b-4260-4f51-bc41-7d21e1582eed>","<urn:uuid:09efc8e5-6833-4cd3-96bb-50fd6d60874e>"],"error":null}
{"question":"Can you explain la diferencia between putouts y assists en baseball, and what makes a 4-strikeout inning possible?","answer":"A putout (PO) is credited to the fielder who actually records the out, while an assist (A) is credited to fielders who touch the ball contributing to the out before the putout is made. A four-strikeout inning becomes possible when a batter reaches first base after a dropped third strike by the catcher, which can happen when first base is unoccupied or there are two outs. In such cases, the pitcher can record four strikeouts in a single inning.","context":["Appendix:Glossary of baseball jargon (A)\nDefinition from Wiktionary, the free dictionary\n|Appendix: Glossary of Baseball|\n|0-9 · A · B · C · D · E · F · G · H · I · J · K · L · M · N · O · P · Q · R · S · T · U · V · W · Y · Z|\nAA or A.A.\n- \"AA\" is also the abbreviation for the American Association, which has been the name of numerous professional baseball leagues: a short-lived major league of the 19th century, a minor league for much of the 20th century, and more recently an independent (e.g., not affiliated with a Major League club) minor league all used this name at various points in baseball history.\n- \"Triple-A\" is the highest level of minor league baseball. This level includes the Pacific Coast League, the International League, and the Mexican League.\n- \"Four-A player\" (alternatively, \"Quadruple-A player\") is a term for a minor-league player who is consistently successful in the high minor leagues (i.e., AAA), but cannot translate that into success at the major-league level. Often poor management is responsible.\nA-Ball or \"Single-A\"\n- \"Single-A\" is the lowest grouping of modern affiliated minor league baseball, with sub-categories of \"High-A,\" \"Low-A,\" and \"Short-Season A.\" The [[Midwest League]], California League, Florida State League, and the Carolina League are categorized as \"Single-A\".\n- Slang for a fielder's errant throw that sails high over the player to whom he intended to throw it. For example, if the third baseman were to throw the ball over the first baseman's head and into the stands, he is said to have \"air mailed\" the throw.\nAL or A.L.\n- Abbreviation for the American League, the newer of the two existing Major Leagues.\nALCS or A.L.C.S.\n- Abbreviation for the American League Championship Series, a best-of-seven playoff series that determines which American League team will advance to the World Series. The ALCS (and the NLCS) came into being for the 1969 series. The team that wins the ALCS wins the American League pennant and the title of American League Champions for that season. The winners of the American League Division Series have met in the ALCS since 1995.\nALDS or A.L.D.S.\n- Abbreviation for the American League Division Series, the first round of the league playoffs. The winners of the three divisions and the second-place team with the best record are paired off in two best-of-five series, the winners of which advance to the ALCS.\n- The best starting pitcher on the team.\nadvance a runner\n- To move a runner ahead safely to another base, often the conscious strategy of a team that plays small ball. Even if a batter makes an out, he may be regarded as having a less negative outcome to his plate appearance if he advances a runner into scoring position or from second to third, thereby increasing the chances of that runner scoring a run later in that inning compared to those chances had that runner not advanced while that out is made. In certain situations, batters deliberately bunt for an out and thereby sacrifice themselves in order to advance a runner to second or third base.\nahead in the count\n- A term that signifies whether the batter or pitcher possesses the advantage in an at-bat. If a pitcher has thrown more strikes than balls to a batter in an at-bat, the pitcher is ahead in the count; conversely, if the pitcher has thrown more balls than strikes, the batter is ahead.\n- If the pitcher is ahead in the count, the batter is in increasing danger of striking out. If the batter is ahead, the pitcher is in increasing danger of walking him.\n- See also: count.\n- (Also \"gap\" or \"power alley\".) The space between the leftfielder and the centerfielder, or the rightfielder and centerfielder. If a batter hits the ball \"up the alley\" with enough force, he has a stronger chance of advancing beyond first base and being credited with an extra-base hit (double, triple). Typically, this is an appropriate term for describing a line drive or ground ball; fly balls that hit the wall are not normally described this way.\n- A play in which the defense has an opportunity to gain a favorable ruling from an umpire by addressing a mistake by the offense or seeking the input of another umpire. Some notable examples:\n- 1. Since baserunners must touch all bases in order when advancing or in reverse order when retreating (tagging up), the defense may appeal if it appears a runner missed a base and continued on to the next one. This appeal must be done during a live ball; typically, the pitcher will step off the rubber and throw the ball to a teammate, who will then touch the appropriate base. If the umpire saw the runner miss the base, he will rule that runner out. Any errors made during this time will be considered \"in play\" and runners can advance. The defense making a play or attempting to make a play that is not initiated by the offense will remove the possibility of an appeal. For example: During a play with a runner on 2nd base, the batter hits the ball and the runner from 2nd runs home but misses 3rd. The batter is now on 1st base. If the runner tries to run after play has stopped (but not during a \"dead ball\") and the defense attempts to get him out, they can still appeal. If, however, the runner on 1st is only a few feet off of first, not attempting to advance and the offence attempts to put him out, this is considered a play and the option for appealing the runner at 3rd will no longer be available.\n- 2. Because runners may not advance on a fly ball until it is caught, an appeal may be made in the same manner as above if a runner leaves his base too early or fails to return to it.\n- 3. If a player bats out of order, the opposing team may bring it to the attention of an umpire. The offending batter is called out.\n- 4. If a batter \"checks\" (stops) his swing at a pitch which is called a ball by the home plate umpire, the defense may appeal to either the first base umpire (for a right-handed batter) or the third base umpire (for a left-handed batter). If the umpire feels that the bat crossed the plate despite the batter's efforts to stop, the pitch is ruled a strike.\n- Appeals involve the defense literally making an appeal to an umpire. At no time before the appeal do umpires announce that, for example, a runner failed to touch a base.\naround the horn\n- The infielders' practice of throwing the ball to each other after recording an out (provided that there are no runners on base). The purpose is as much traditional as anything else, but it serves to keep the infielders' throwing arms warm. Typically, if an out is made at first base, the first baseman will throw to the second baseman, who throws to the shortstop, who throws to the third baseman, who returns the ball to the pitcher. Patterns vary from team to team, but the third baseman is usually the last infielder to receive a throw, regardless of the pattern.\n- An additional application of this term is for a 5-4-3 double play, which mimics the pattern of throwing around the horn.\n- Slang for a fastball that is especially hard to hit due to its velocity and/or movement. See also \"pill\".\n- The official scorer awards an assist (A) to every defensive player who fields or touches the ball (after it has been hit by the batter) prior to a putout, even if the contact was unintentional. For example, if a ball strikes a player's leg and bounces off him to another fielder, who tags the baserunner, the first player is credited with an assist.\n- A fielder can receive only one assist per out recorded. A fielder also receives an assist if a putout would have occurred, had not another fielder committed an error.\n- Slang for a ball batted directly at a defender.\n- A plate appearance in which the batter a) hits safely, b) is retired, c) reaches on an error by a fielder, d) reaches base on a fielder's choice, e) is called out due to batter's interference, or f) reaches base on a passed ball or wild pitch that occurs with two strikes on the batter.\n- At-bats (or \"times at bat\") are used for the calculation of a player's batting average and slugging percentage.\nate him up\n- Slang expression of the action of a batted ball that is difficult for a fielder to handle.\nattack the strike zone\n- Slang for pitching aggressively by throwing strikes, not by trying to trick hitters into swinging at pitches out of the strike zone or trying to nibble at the corners of the plate. Equivalent phrases are pound the strike zone and challenge the hitters.\n- Slang for \"outs\". If there are two out in an inning, players may say there are \"two away\".\n- Games played at an opponent's home field are \"away games\".\n- The visiting team is sometimes called the \"away\" team.\n- A pitch that is too low or high and too far outside the strike zone is \"low and away\" or \"high and away\".\nReturn to Appendix:Glossary of baseball","- 1 What is an assist in MLB?\n- 2 Whats the difference between a put out and an assist?\n- 3 What position gets the most assist in baseball?\n- 4 How does an outfielder get an assist?\n- 5 What are the numbers of baseball positions?\n- 6 What does G mean in baseball stats?\n- 7 What catcher has thrown the most runners?\n- 8 Does a catcher get an assist on a strikeout?\n- 9 What is it called when an outfielder throws out a runner?\n- 10 Is a passed ball an error?\n- 11 Why do catchers have so many putouts?\n- 12 How is it possible to have a four strikeout inning?\n- 13 What is a baseball shift?\n- 14 What’s the difference between at bats and plate appearances?\nWhat is an assist in MLB?\nDefinition. An assist is awarded to a fielder who touches the ball before a putout is recorded by another fielder. Typically, assists are awarded to fielders when they throw the ball to another player — but a fielder receives an assist as long as he touches the ball, even if the contact was unintentional.\nWhats the difference between a put out and an assist?\nA putout (PO) is credited to a fielder who gets an offensive player out as described in scoring rule 10.09. An assist (A) is credited to fielders who contribute to an offensive player being out as per scoring rule 10.10.\nWhat position gets the most assist in baseball?\nFor example, a shortstop might field a ground ball cleanly, but the first baseman might drop his throw. In this case, an error would be charged to the first baseman, and the shortstop would be credited with an assist. Rabbit Maranville is the all-time leader with 8,967 career assists.\nHow does an outfielder get an assist?\nAn outfielder records an assist when he throws the ball into the infield and an out is recorded as a result. Outfield assists are one of the most commonly referenced types of assists. Outfield assists often result from throws directly to a base, without the help of an infielder.\nWhat are the numbers of baseball positions?\nEach position conventionally has an associated number, for use in scorekeeping by the official scorer: 1 (pitcher), 2 (catcher), 3 (first baseman), 4 (second baseman), 5 (third baseman), 6 (shortstop), 7 (left fielder) 8 (center fielder), and 9 (right fielder).\nWhat does G mean in baseball stats?\nExtra-base Hit (XBH) Games Played (G) Grand Slam (GSH) Ground Into Double Play (GIDP) Groundout-to-Airout Ratio (GO/AO)\nWhat catcher has thrown the most runners?\nIván Rodríguez is the all-time leader in putouts at the catcher position with 14,864 career putouts. Yadier Molina (14,552) is second all-time and the only other catcher to record 14,000 or more career putouts.\nDoes a catcher get an assist on a strikeout?\nAn assist is also credited if a putout would have occurred, had another fielder not committed an error. If a pitcher records a strikeout where the third strike is caught by the catcher, the pitcher is not credited with an assist.\nWhat is it called when an outfielder throws out a runner?\nFielder’s choice is defined in MLB Rule 2, “Definitions”, as “the act of a fielder who handles a fair grounder and, instead of throwing to first base to put out the batter-runner, throws to another base in an attempt to put out a preceding runner.” FC is recorded for the batter-runner if he reaches first base safely\nIs a passed ball an error?\nA passed ball is not recorded as an error, but when a run scores as the result of a passed ball, it does not count as an earned run against a pitcher. If a runner advances on a passed ball, he is not credited with a stolen base.\nWhy do catchers have so many putouts?\nThe catcher receives a putout if the batter is automatically out for batting illegally, bunting foul for a third strike (unless the foul ball is caught on the fly), striking out with first base occupied and less than two out (even if the catcher fails to catch the ball), being touched by his own batted ball, batting\nHow is it possible to have a four strikeout inning?\nThe number of four-strikeout frames — made possible when a hitter takes first base after a third strike is dropped by the catcher plus either first is vacant or there are two outs — has grown exponentially in the 21st century.\nWhat is a baseball shift?\nA defensive shift occurs when the fielders move from their normal positions for some tactical reason. The most common shifts are used in response to specific game situations, such as a runner on base, and are seen in almost every game.\nWhat’s the difference between at bats and plate appearances?\nDefinition. An official at-bat comes when a batter reaches base via a fielder’s choice, hit or an error (not including catcher’s interference) or when a batter is put out on a non-sacrifice. (Whereas a plate appearance refers to each completed turn batting, regardless of the result.)"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:2c1a8073-7bf7-4a7c-9b1c-3c5a48d4af3f>","<urn:uuid:ec1d8a61-ad8e-4415-85b4-7e8902e2d32a>"],"error":null}
{"question":"What is the difference between a geisha and a hangyoku in Japanese entertainment tradition?","answer":"A geisha is a fully trained professional entertainer who has mastered the arts of entertainment including singing, dancing, and playing musical instruments. A hangyoku (also known as maiko in Kyoto) is an apprentice geisha who is still in training. While hangyoku/maiko performances are less expensive, they typically have less experience as many do not complete their training to become full-fledged geisha. In recent years, some maiko practice for less than a couple of years before leaving the geisha world. During professional events, if a maiko/hangyoku is present, they are always accompanied by their oneesan (older sister), who is a professional geisha.","context":["Private Geisha Experience\nIf you are interested in the Geisha Experience dinner with Japan Awaits but would prefer a private event for your group, private events are available upon request. Lunch or dinner are available with either one or two geisha. The dinner event will feature one or two certified geisha (also known as geiko in Tokyo) from the hanamachi (geisha district) of Asakusa, Shinbashi, Mukoujima or Omori Kaigan. The exclusive private event will include entertainment with dance, music, and real conversations with geisha (English interpreters will be present) for a more enriching experience.\nAvailability: Any day of week except Mondays (based on availability upon request)\nTime: 2.5 hours for dinner (lunch event may be available upon request)\nLocation: Traditional Japanese restaurant (ryotei) in Tokyo\nEvent with One Geisha:\n¥45,000 per person (Group of 2 people)\n¥32,000 per person (Group of 3 people)\n¥28,000 per person (Group of 4 people)\n¥25,000 per person (Group of 5 people)\n*For groups of 6 or more people, we recommend booking an event with 2 geisha.\nEvent with Two Geisha:\n¥60,000 per person (Group 2 people)\n¥45,000 per person (Group of 3 people)\n¥37,000 per person (Group of 4 people)\n¥30,800 per person (Group of 5 people)\n¥23,500 per person (Group of 6 people)\n¥21,900 per person (Group of 7 people)\n¥20,800 per person (Group of 8 people)\n¥19,700 per person (Group of 9 people)\n¥18,800 per person (Group of 10 or more people)\n*For groups with 15 or more people, there will be at least 3 geisha for the event.\nAdd-on: 4-Hour Private Tokyo Tour\n- 2 or more people: 11,000 JPY per person\n- 1 person: 22,000 JPY per person\nThe 4-Hour Private Tokyo Tour will include an English-speaking guide. This tour can be conducted before the Geisha event from 2:00 PM to 6:00 PM. Public transportation costs are included. Admission fee or other optional activity fees for guests and tour guides are not included.\nAdd-on: 8-Hour Private Tokyo Tour\n- 2 or more people: 19,500 JPY per person\n- 1 person: 39,000 JPY per person\nThe 8-Hour Private Tokyo Tour will include an English-speaking guide. This tour can be conducted before the Geisha event from 10:00 PM to 6:00 PM. Public transportation costs are included. Admission fee or other optional activity fees for guests and tour guides are not included.\n- Lunch or Dinner options\n- Authentic geisha performance and entertainment\n- English interpreter\n- Kimono rental\n- Free souvenirs\n- Photo opportunities and more\nA kimono and obi (belt) will be provided to you as a rental for a more memorable experience during the Geisha Experience event. Kimono will be available for men, women and children. We suggest wearing tank top and shorts underneath.\nAll seats are non-smoking; there are designated areas outside for those who would like to smoke.\nThe dinner experience is for ages 10 and up. Unfortunately, we will not be able to accommodate any younger children.\nFor groups of 10 or more people, nomihodai (all-you-can-drink) is available at 2900 JPY per person, payable in cash at the venue. At the time of booking, please let Japan Awaits know that you would like to include nomihodai (all-you-can-drink). For groups of 9 or less people, nomihodai is not available.\nAll bookings are payable via Stripe (Booking Checkout) or PayPal. Confirmations regarding your booking will be sent at least 10 days before your activity date.\nModerate Cancellation Policy:\n- We will charge a cancellation fee of 100% if booking is cancelled 14 days or less before event\n- We will charge a cancellation fee of 50% if booking is cancelled 21 days or less before event\n- We will charge a cancellation fee of 25% if booking is cancelled a month or less before event\nWhat is a geisha?\nThe geisha dedicates her whole life to mastering the art of entertainment. She entertains guests with singing, dancing and playing musical instruments at dining events, typically at traditional Japanese establishments, such as ryoutei or ryokan. Since the Edo period, the geisha has been iconic to Japan and even to this day, the geisha world is highly mysterious and exclusive, as requesting a geisha’s services require an introduction or referral from an existing customer or venue. Japan Awaits presents a historic dining experience with traditional performances by the geisha.\nWhat makes Japan Awaits (JA) different?\nUnlike other companies, JA wants guests to experience the most authentic Japanese experiences. Geisha are known for their acuity and wisdom-training from a young age to be able to carry any type of conversation; traditionally, geisha were known for having a vital voice in politics as many political meetings involved the accompaniment of geisha and they had the ability to intellectually hold debates, influencing laws and policies in Japan. Thus, JA want our guests to experience what it truly means to be in the presence of a geisha, through dance, song and conversation.\nWhat is the difference between geisha (geiko) and hangyoku (maiko)?\nHangyoku (or also known as maiko in Kyoto) are apprentice geisha (also known as geiko in Kyoto) who are still in training. While having hangyoku/ maiko instead of geisha performances or appearances may significantly reduce the event cost, maiko generally are still training while geisha have been practicing for several years. Especially in recent years, less and less maiko complete training to become a full-fledged geisha, meaning that they could practice for less than a couple of years before leaving the geisha world. For our event, geisha may introduce their successor, or practicing maiko/ hangyoku, during the event but always with her oneesan (older sister) that is a professional geisha.\nSHARE THIS EXPERIENCE"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:42fb5482-8278-4601-9f53-53712d57c0e8>"],"error":null}
{"question":"我正在研究技术培训项目,微软和南非数字矿业项目哪个更注重实践培训?","answer":"Both initiatives emphasize practical training but have different approaches. The Digital Mine project at Wits includes hands-on training in a mock-up underground tunnel that cost R15-million and features facilities like a stope, rescue bay and lamp room for teaching and research. Meanwhile, Microsoft's program with NSDC focuses on providing digital learning resources through their 'Microsoft Learn' platform integrated with eSkill India, offering personalized learning modules ranging from basic digital literacy to advanced product-based skills like AI and cloud computing. The Digital Mine project appears more focused on physical infrastructure while Microsoft's initiative is entirely digital-based.","context":["South African mining sector seen revolving round digital technologies in the future-Mining Weekly\nThe future of the mining industry in South Africa will revolve round digital developments, asserted University of the Witwatersrand (Wits) School of Mining Engineering lecturer Dr Bekir Genc during his address at the Mining into the Future conference, which took place at the Birchwood Conference Centre, in Boksburg, Gauteng, earlier this month.\nHe said that information technologies would help the sector achieve its goals of better working conditions and improved mine economics.\nGenc stated that the digital revolution was happening everywhere, and that it would soon occur in the local mining industry, “if not today, then tomorrow for sure”.\nHe noted that, in recognition of this, the Wits School of Mining Engineering had launched a Digital Mine project to support the existing strategy of the mining industry to continuously improve working conditions and mine economics.\n“Digital technologies are fundamental for efficient and safe mining, where all systems are optimised,” said Genc.\nHe added that this required the clarity of multiple sources of underground data communicated to a surface control room and back to the workplace in real time.\n“This is not happening yet as it requires an enormous amount of work, but some parties have started trying to establish these systems.”\nIn the first phase of the project, the school built a mock-up of an underground tunnel. This allowed Wits to simulate an underground mining environment that could be used for teaching, learning and research.\nThe 70 m tunnel cost about R15-million, and features a stope, rescue bay and lamp room, built with sponsorship from gold miner Gold Fields, mine support technology company New Concept Mining and gold miner Sibanye Gold. Research is being conducted into smart surveying and mapping (visualisation) systems; climate control systems and energy savings (particularly important in deeper-level mines); and smart rock engineering systems, which can monitor rock mass movement and predict seismic events.\nAdditionally, the Wits School of Mining Engineering is conducting research on smart data processing, which can locate people and assets and monitor their performance, and recognise actions and detect abnormalities, such as recognising that someone is ill.\nSmart mine design, mine planning and decision-making are also being studied.\nThe Digital Mine project involves four phases, Genc explained.\nPhase one comprised the building of the mock-up mine for research, teaching and learning, which has already been completed. Phase two comprises the building of a laboratory hosting digital technologies inside the mine, which is in the advanced planning stages.\nPhases three and four include the monitoring of an underground environment for optimised mine design and processes, and integrating a digital mine with a digital city and communities.\n“These phases are still at the conceptual stage and will require further funding to develop,” said Genc.\nHe said he believed that the Digital Mine project would benefit the mining sector by providing access to a safe, smart mine laboratory reaching into the surrounding community on a multisensor geographic information system platform (once the lab has been developed), and providing knowledge for industry so that it could collect appropriate and accurate information to optimise mine designs and processes.\nThis would enable continuous and predictive operations, while having a positive impact on mine efficiency and security. The latter is of particular relevance to gold mines, which put both mineshafts and mine employees at risk as a result of the activities of illegal miners.\nGenc noted that, with digitisation, the concept of a mine-to-order, or demand mining, would become a real possibility, thereby contributing to productivity of the mine’s bottomline and transforming the mining industry through information technology.\n“Most importantly, a digital mine will accelerate the process of reaching the industry’s zero-harm goal,” he emphasised.\nMoreover, Genc highlighted that a variety of technologies that were currently in development would also help make the digital mine a reality.\n“Underground communication systems will enable real-time intervention to manage all types of risk. Underground drones will be able to see, map and collect data, and communicate it, and can also be used to map abandoned mines that are too dangerous to send people into,” he said.\nGenc added that smart data processing and three-dimensional, or 3D, modelling “were planned in the future”, and would require participation from various schools across a number of faculties at Wits.\nThe conference was a collaborative partnership between Caterpillar, Barloworld Equipment (as the Cat Southern African dealer), the Wits School of Mining Engineering and the Wits Centre for Mechanised Mining Systems.\nBack to previous page","The National Skill Development Corporation (NSDC) has partnered with tech giant Microsoft to implement a programme aimed at providing digital skills to over 1 lakh youth in the country over the next 12 months.Microsoft, through NSDC’s eSkill India portal, will provide free access to learning resources and conduct digital skilling awareness drives, equipping the next generation of learners with the skills they need to thrive in a digital economy, according to the company sources.Microsoft’s learning resource center 'Microsoft Learn' will be integrated with the eSkill India digital platform to provide access to personalized learning modules that are in-demand in today’s economy. These skills will empower youth and make them well-positioned to continue to grow in the future, the company said.The learning paths offered as part of the training modules will cover a wide range of skills, from entry-level digital literacy to advanced product-based skilling in critical … [Read more...] about NSDC and Microsoft collaborate to train 1 lakh youth in digital skills\nPrediksi 6 digit hk\nThe Union minister for human resource development, Ramesh Pokhriyal Nishank on Thursday sought to adopt the new digital ecosystem for education to maximise its reach and affordability to the remotest part of the country. “Under the able leadership of the Prime Minister and with the foresight of the finance minister, we started initiatives like PM e-Vidya, One Nation-One Channel so that we can expand the reach of education to all sections in this crisis period.”Nishank was addressing an industry dialogue organised by ASSOCHAM on ‘Changing the threat of Covid-19 as a new model of education’. While highlighting the steps taken by the Union government to boost the education system, the minister said this can be used as an opportunity for future education needs. According to Nishank, the present crisis should be considered as an opportunity to develop a future digital education ecosystem that can help bridge the education gap.“We had to focus on digital … [Read more...] about Digital learning to bridge education gap: HRD minister Ramesh Pokhriyal Nishank\nBy Rahul TekwaniThe global digital space is a contemplation of, and in some cases, amplification of what is happening around us in the world. With 2020 giving everyone a crazy roller-coaster ride, times are tough and one can’t predict what future beholds. Digital which showed promise as a medium for the future is now seeing some chaotic times.How did it all start? digital ad spends on social media especially on Facebook, Instagram, and Twitter for a minimum period of 30 days.The industry was wondering and waiting for the implication that ad ban news might have in India, and back home the Ministry of Information Technology had banned 59 popular Chinese mobile apps. While according to the media statement from Tiktok the ban order remains interim and the companies are yet to submit clarification, the industry has already started looking out for alternatives for these Chinese apps and how to reallocate the marketing budget.Read Also: The Truth About Martech: Look for … [Read more...] about The digital tussle: Who will seize the moment?\nThe resources will cover a vast range of skills, including entry-level digital literacy to advanced product-based skilling in critical technologies like AI and cloud computing, which will provide opportunities for people aspiring to reskill or upskill themselves. The partnership with NSDC is an extension of Microsoft’s global skilling initiative to help 25 million people worldwide acquire new digital skills needed for the COVID-19 economy.“The digital transformation of India is driving demand for tech-enabled jobs across every industry and with it the need for digital skills,” said Anant Maheshwari, President, Microsoft India. Maheshwari added that the partnership with NSDC is one strong step in that direction, which will equip learners with accessible tools and resources required to succeed in a digital economy. “The collaboration aims at accelerating online learning for enhancing the employability of the young workforce in a rapidly evolving digital … [Read more...] about Microsoft, NSDC partner to offer digital skills to youth in India\nWipro on Friday said it will integrate a host of services offered by Citrix Systems and Microsoft to create high-performance virtual compute environments that leverage the power of Cloud architecture and next-generation digital workspace technology.Wipro VirtuaDesk, Wipro's Desktop as a Service solution and Wipro's Digital Workspace solution will join forces with Citrix and Microsoft.The combined solution will allow for rapid and easy deployment of secure and reliable digital workspaces, including application suites, Wipro said, adding that this will let clients accommodate increased calls for remote work, which in many cases is a mandate.\"The collaboration is a testament of our strength and our joint resolve to enhance the value we can create for our customers,\" Satish Y, Vice President, Cloud & Infrastructure services, Wipro Limited, said in a statement.\"We intend to bring together our strong complementary capabilities on virtualisation tools and platforms, desktop and … [Read more...] about Wipro partners with Citrix, Microsoft on digital workspaces"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:77c160dc-3c56-4c04-83c3-921947fba0cc>","<urn:uuid:f0513bd6-bda0-4ff8-90cc-d9f9038d5f9e>"],"error":null}
{"question":"我想了解海洋研究中的两种新技术 - Boaty McBoatface和Northern Star coral各自有什么特别之处？","answer":"Boaty McBoatface and Northern Star coral (Astrangia poculata) represent different innovations in marine research. Boaty McBoatface is an autonomous underwater vehicle that can travel over 112 miles at depths of 4,000 meters, providing new ways to study ocean turbulence and climate change impacts. The Northern Star coral is unique because it can survive with or without algal symbionts, unlike tropical corals which depend on their algae. This makes it an valuable model system for studying coral-symbiont relationships and reactive oxygen species production in coral ecosystems.","context":["2017 Research Highlights\nMapping Food Webs with Stable Isotopes\nJulianna Renzi, University of Arizona\nTrophic ecology is essential to the functioning of marine ecosystems. Understanding the basics of who eats what can help inform scientists about the ecological ramifications of overfishing species, introducing new ones, and how food webs are changing over time. The desire to answer these questions drew me to Dr. Simon Thorrold’s Fish Ecology lab at WHOI, where I worked on developing a new method for studying trophic ecology: Compound-Specific Stable Isotope Analysis of Amino Acids (CSIA-AA).\nWhile stable isotopes have been a staple of ecological research for decades, CSIA-AA has the potential to provide a higher-resolution picture of carbon flow through food webs. It leverages the fact that primary producers, such as corals and macroalgae, have unique carbon signatures in their essential amino acids, which are retained by the organisms that consume them. A fish who eats coral will have the specific coral “fingerprint” in its muscle and we can use mixing models to discern what portion of its diet comes from each carbon source.\nHowever, we don’t know how specific these “fingerprints” are. I was initially drawn to CSIA-AA for its potential to determine how fish partition macroalgal species, which compelled me to spend my summer looking at whether individual genera of macroalgae—not just macroalgae as a single group—have unique carbon fingerprints. This project sent me snorkeling around Woods Hole where I collected macroalgae, learned how to identify different species, and fell in love with the sight of colorful macroalgal communities swaying with the waves. When I wasn’t face down in the water I was in lab, where I learned how to analyze samples using CSIA-AA—from freeze-drying specimens, to extracting their amino acids, to running them through a state-of-the-art mass spectrometer.\nDespite my fervent enthusiasm for macroalgae and CSIA-AA, which I hope to work with in graduate school, the summer wasn’t only amazing because of the time I spent working on my project. When I look back on my three months at Woods Hole I’m overcome with appreciation for the inspirational set of peers I met through the program, the exposure I received to top-tier oceanographic research, the amazing program coordinators that made this summer possible, my brief stint on the Biology softball team, the opportunity to go shark tagging with a graduate student in my lab, the supportive environment created by everyone at WHOI, and all of the day-olds I consumed from Pie in the Sky. And, of course, I’m grateful for algae.\nEnhancing the Capabilities of Autonomous Underwater Vehicles\nZachary Duguid, MIT\nBathed in total darkness, where even the most determined photons are denied entry, the deep ocean is home to entire ecosystems of bizarre critters. Although it covers roughly 70 percent of Earth’s surface, the ocean remains largely unexplored. In fact, it is estimated that humans have explored less than five percent of the Earth’s largest feature (NOAA). Though it is largely unexplored, the ocean plays a critical role in vital processes such as the regulation of Earth’s climate. Protecting us from the ozone-demolishing greenhouse gas, the ocean greedily ingests tremendous amounts of CO2 via surface-dwelling phytoplankton. Therefore, by better understanding the vast complexities of the ocean, we will be more prepared to achieve longevity for humanity. To unlock the secrets of the ocean, we turn to autonomous underwater vehicles (AUVs). Without bearing the risk of losing human life, AUVs can confidently navigate the most dangerous regions of the ocean to make novel discoveries.\nDuring my Summer Student Fellow experience, I worked with Rich Camilli in the Deep Submergence Laboratory to enhance the capabilities of a particular AUV: the Slocum Glider. The Slocum Glider is an AUV that is specialized for long range research scenarios. Equipped with a low power mass spectrometer that monitors the presence of subsea hydrocarbons, the Slocum Glider conducts ocean sampling missions for weeks at a time. To maximize the achievable range of the glider, it is essential to maximize the total power capacity contained within the vehicle. To do this, the old battery system that consisted of non-rechargeable Alkaline C cells has been replaced with a new system consisting of rechargeable Lithium Ion cells. The new Lithium Ion batteries are lighter and more powerful compared to their Alkaline counterparts. To assist the integration process of the new battery system, I created a graphical user interface (GUI) that monitors relevant battery state variables such as current draw and voltage. By monitoring battery state information, we are able to diagnosis battery malfunctions as they arise and appropriately update the mission to handle such malfunctions. Also, I developed a battery chassis to physically hold the individual batteries within the confines of the glider hull. To do so, I utilized computer aided design (CAD) and 3D printing methods, which allowed for rapid prototyping. Finally, I also got involved with a particular form of path planning for the Slocum Glider by considering velocity-optimized paths subject to ocean current conditions. Through this research, we discovered a rather counterintuitive result that when in the presence of favorable ocean currents, it is necessary to reduce propulsive power in order to maximize range.\nThrough my WHOI Summer Fellowship Experience, I was exposed to many facets of systems engineering in the research setting. As a result, I gained many new skills and I was exposed to many fascinating research areas. I am very grateful for the opportunity to conduct research at WHOI and I am excited about the future of ocean-monitoring autonomous robots.\nReactive Oxygen Production by Corals\nShavonna Bent, Johnson State College, VT\nCoral reefs have become a hot topic issue over the last few years in the face of climate change (pun intended). Many people are working to better understand these ecosystems, so they can be better preserved. However, growing in the cold waters of New England, is another coral species, one that may prove to be a valuable model system to understand interactions between coral and their symbionts. Astangia poculata, the Northern Star coral, can live with or without algal symbionts. This relationship is of particular interest, as tropical coral cannot survive very long without their resident algae.\nWith the guidance of Drs. Amy Apprill and Colleen Hansel, I studied the production of reactive oxygen species (ROS), specifically, the superoxide molecule, by A. poculata and in the members of its holobiont. In tropical coral, internal ROS is associated with detrimental effects such as coral bleaching. However, externally, little is known about the production of the superoxide molecule. Drs. Hansel and Apprill have previously studied ROS production at the surface of several tropical corals and found no correlation with bleaching status, and more thermally tolerant species appear to produce more ROS. This presents an interesting conundrum to the traditional story of ROS being a negative molecule in the coral ecosystem.\nA. poculata was selected for study as it can thrive without algal symbionts, allowing us to separate the contributions of ROS from the coral and algae. We also eliminated the surface mucus layer microbiome determine if microbes on the coral surface contributed to ROS production. We found no significant differences between any of the corals, regardless of algal symbiosis or presence of surface microorganisms. However, by testing two bacterial species isolated from the surface of A. poculata, we found that microbes living on the surface produce superoxide at biologically relevant levels, in vitro. This suggests that A. poculata controls the production of external ROS. Determining the mechanism of control could yield insight as to how tropical coral control superoxide levels in their immediate environment, and what role this may play in ecosystem health.\nThroughout the summer I learned invaluable skills working with two amazing mentors. My experience extended much farther than the lab however, as I was invited into the research community, to attend lab barbecues, sail for the first time, meet for dinner with the Chilean producers of a film about the resurgence of blue whales, and make friends that I still talk to almost every day. Being surrounded by dedicated and passionate people inspired me to push my boundaries, both in research and personally. I cannot speak highly enough of the SSF program, nor the people that run it, nor the community at Woods Hole.","The biggest mystery in the Universe could possibly be right here on Earth. According to the National Oceanic and Atmospheric Administration (NOAA) as much as 95% of the oceans and 99% of the ocean floor has yet to be explored. Given more than 70% of the planet is covered by water, the promise for unmanned systems to go deeper into the depths of the sea could be one of the ripest opportunities for autonomy. Besides the benefits for conservationism, commercial missions are estimated to drive billions of dollars of new revenues. Already the demand for such hardware systems accounts for more than $2 billion, which many project to climb to more than $6 billion by 2025.\nToday’s underwater drone market is in its infancy with most sensor-packed, torpedo-like devices being tugged around the globe on the decks of ships. These products break down into two main categories: Remote Operated Vehicles (ROV) and Autonomous Underwater Vehicles (AUV). As an example of the emerging possibilities for AUVs, earlier this month the British government-backed project, Boaty McBoatface, traversed more than 112 miles autonomously at depths of 4,000 meters to shed new light on climate change and rising sea levels. In the words of Dr. Eleanor Frajka-Williams of the National Oceanography Centre in Southampton, England, “The data from Boaty McBoatface gave us a completely new way of looking at the deep ocean — the path taken by Boaty created a spatial view of the turbulence near the seafloor.” Frajka-Williams anticipates that the information will help scientists predict the impact of global warming. Dr. Povl Abrahamsen of the British Antarctic Survey in Cambridge, England echoed this view, “This study is a great example of how exciting new technology such as the unmanned submarine ‘Boaty McBoatface’ can be used along with ship-based measurements and cutting-edge ocean models to discover and explain previously unknown processes affecting heat transport within the ocean.” The future plans for Boaty include diving underneath Arctic ice and into subsea volcanos.\nBoaty operates in a crowded space of close to fifty for-profit companies competing for marketshare. The activities of both large multinational corporations and upstart technology providers range from applications for defense to commercial exploration to scientific research. One of the largest purveyors is BlueFin Robotics, which was purchased by General Dynamics in 2016. Since then, there have been a number of high profile aquatic acquisitions, including: Riptide Autonomous Solutions by BAE Systems; Liquid Robotics by Boeing; and multiple investments in Ocean Aero by Lockheed Martin. The biggest driver of this consolidation is the demand from the military, particularly the Navy, for autonomous searching out and destroy missions.\nIn September 2017 the US Navy established the Unmanned Undersea Vehicle Squadron 1 (UUVRON-1). When explaining this move, Captain Robert Gaucher stated “Standing up UUVRON 1 shows our Navy’s commitment to the future of unmanned systems and undersea combat.” This sentiment was shared by Commander Corey Barker, spokesman of the famed Submarine Force Pacific, “In addition to providing a rapid, potentially lower cost solution to a variety of mission sets, UUVs can mitigate operations that pose increased risk to manned platforms.” Last summer the Navy appointed a dedicated Commander of UUVRON-1, Scott Smith. In a recent interview, Smith opined his vision for sea drones, “Those missions that are too dangerous to put men on, or those missions that are too mundane and routine, but important ― like monitoring ― we’ll use them for those missions, as well. I don’t think we’ll ever replace the manned platform, but we’ll certainly augment them to a large degree.” It is this augmentation that is generating millions of dollars of defense contracts which are starting to spill over to private industry.\nBoston-based Dive Technologies, founded by a team of former BlueFin engineers, is building an innovative technology to broaden the use of unmanned marine systems. In speaking with its CEO this week, Jerry Sgobbo, he described nascent opportunities for his suite of innovations: “We see demand for offshore survey work in the U.S. increasing significantly as grid scale offshore wind farms are developed over the next decade. In particular, much of this work will take place in New England and mid-Atlantic waters.” Sgobbo is referring to the recent move by Rhode Island in constructing the first ever wind farm in the United States, capitalizing on the regions famous gale-force gusts. Based upon the success of the Block Island project, other states are quickly putting forth legislation to follow suit. Just this week, Senator Edward Markey of Massachusetts declared in Congress that “Offshore wind has the potential to change the game on climate change, and those winds of change are blowing off the shores of Massachusetts. Offshore wind projects are a crucial part of America’s clean energy future, creating tens of thousands of jobs up and down the East Coast and reducing carbon pollution. In order to harness this potential, we need to provide this burgeoning industry the long-term certainty in the tax code that it needs.” Sgobbo believes that such moves will spark greater investment in automation to support the harnessing of renewal energy. Dive’s value proposition is collecting imaging that enables wind farm builders to better map the ocean floor for their large structures. As the founder states, “For commercial customers, this data is necessary to support deepwater energy infrastructure projects. For defense customers, the same imaging approach is used to locate sea mines.”\nDive’s flexible platform readily lends itself to the development of offshore wind turbines. Sgobbo further explained, “Dive’s AUV is a large platform with very long range and is intended to operate independently without the need for the infrastructure that traditionally supports an AUV mission today. This allows a survey operator to reduce cost as well as perform survey work at times of the year when it is impractical to use a towed system or smaller AUV.” The startup leveraged its extensive industry knowledge to reinvent how marine drones are utilized. “When we started Dive Technologies, my co-founders and I first took an in-depth look at how medium and large sized AUVs are being operated and manufactured across the industry today and we saw vast potential for innovation and improvement,” recalled Sgobbo. “Our new AUV platform, the ‘DIVE-LD’, addresses the industry’s needs by drastically increasing payload capacity and on-board energy storage but, most importantly, driving down the cost to collect offshore data. We do this by offering quickly configurable payload space to accommodate specific sensors needed for a job or mission, and then letting our robot do what robots are meant to do, operate autonomously and with minimal human intervention.” This means that Dive’s ability to tailor its product to specific mission requirements, along with greater battery capacity, enables it to take travel farther and deeper than its competitors. “Today’s offshore AUV missions are typically conducted with a dozen humans in an expensive surface support vessel which leads to important survey work being prohibitively expensive. Dive’s novel engineering solution will categorically shift this paradigm,” expounds Sgobbo.\nAs the growth of marine robotics begins to proliferate across the globe, how businesses utilize the technology will expand into new categories. Sgobbo predicts, “Often, the military and commercial missions have used very similar AUV technology, but are looking for different things in the ocean. Looking forward, both customers are interested in longer range AUVs. For commercial customers, the goal is to reduce operating costs. For defense, a low cost, long range AUV opens new mission sets beyond mine countermeasure and will further lend to keeping sailors safe from dull, dirty, and dangerous missions. Also, AUVs are increasingly important data collection tools for the scientific community.” As we closed our discussion, he optimistically quipped, “With approximately 90% of the world’s trade carried across these marine highways, we see the U.S. Navy investing heavily in next generation AUV technologies to maintain a forward presence and keep shipping lanes secure. As a team, we also look forward to the opportunities we’ll discover in the unknown.”\nIs Today’s Industry 4.0 A Hackers Paradise? ~ Come join RobotLab, SOSA and GENIUS NY in answering this question with cybersecurity expert Chuck Brooks of General Dynamics on September 25th at 6pm, Space Is Limited, RSVP Today!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:c109243d-df1d-44d0-9fa5-b7cfd093c6cf>","<urn:uuid:1f4ebe2c-caa7-47f0-b5b7-d79571cd50bd>"],"error":null}
{"question":"How do the historical European exploration patterns differ between the White Nile and Amazon River?","answer":"The European exploration patterns of these rivers differed significantly. The White Nile was the focus of 19th-century European exploration efforts in what was then known as 'Darkest Africa,' with its true source not discovered until 1937 by German explorer Burkhart Waldecker. In contrast, the Amazon River's European discovery is attributed to Spanish soldier Francisco de Orellana, who named it after observing fierce female warriors that reminded him of Amazons in Greek mythology.","context":["The White Nile (Arabic: النيل الأبيض an-nīl al-'abyaḍ) is a river in Africa, one of the two main tributaries of the Nile; the other is the Blue Nile. The name comes from colouring due to clay carried in the water.\nVictoria Nile, Albert Nile, Mountain Nile\n|Country||Sudan, South Sudan, Rwanda, Tanzania, Uganda, Democratic Republic of the Congo|\n|Cities||Jinja, Uganda, Juba, South Sudan, Khartoum, Sudan|\n|Length||3,700 km (2,300 mi)|\n|Basin size||1,800,000 km2 (690,000 sq mi)|\n|⁃ average||878 m3/s (31,000 cu ft/s)|\nIn the strict meaning, \"White Nile\" refers to the river formed at Lake No, at the confluence of the Bahr al Jabal and Bahr el Ghazal Rivers. In the wider sense, \"White Nile\" refers to all the stretches of river draining from Lake Victoria through to the merger with the Blue Nile. These higher stretches being named the \"Victoria Nile\" (via Lake Kyoga to Lake Albert), the \"Albert Nile\" (to the South Sudan border) and then the \"Mountain Nile\" or \"Bahr-al-Jabal\" (down to Lake No). \"White Nile\" may sometimes include the headwaters of Lake Victoria, the most remote of which being 2,300 miles (3,700 km) from the Blue Nile.\nThe 19th-century search by Europeans for the source of the Nile was mainly focused on the White Nile, which disappeared into the depths of what was then known as \"Darkest Africa\". The White Nile's true source was not discovered until 1937, when the German explorer Burkhart Waldecker traced it to a stream in Rutovu, at the base of Mount Kikizi.\nHeadwaters of Lake VictoriaEdit\nThe Kagera River, which flows into Lake Victoria near the Tanzanian town of Bukoba, is the longest feeder river for Lake Victoria, although sources do not agree on which is the longest tributary of the Kagera, and hence the most distant source of the Nile itself.\nThese two feeder rivers meet near Rusumo Falls on the border between Rwanda and Tanzania. These waterfalls are known for an event on 28–29 April 1994, when 250,000 Rwandans crossed the bridge at Rusumo Falls into Ngara, Tanzania in 24 hours, in what the United Nations High Commissioner for Refugees called \"the largest and fastest refugee exodus in modern times\". The Kagera forms part of the Rwanda–Tanzania and Tanzania–Uganda borders before flowing into Lake Victoria.\nThe White Nile in Uganda goes under the name of \"Victoria Nile\" from Lake Victoria via Lake Kyoga to Lake Albert, and then as the \"Albert Nile\" from there to the border with South Sudan.\nThe Victoria Nile starts at the outlet of Lake Victoria, at Jinja, Uganda, on the northern shore of the lake. Downstream from the Nalubaale Power Station and the Kiira Power Station at the outlet of the lake, the river goes over Bujagali Falls (the location of the Bujagali Power Station) about 15 kilometres (9.3 mi) downstream from Jinja town. The river then flows northwest through Uganda to Lake Kyoga in the centre of the country, thence west to Lake Albert.\nAt Karuma Falls, the river flows under Karuma Bridge ( ) at the southeastern corner of Murchison Falls National Park. During much of the insurgency of the Lord's Resistance Army, Karuma Bridge, built in 1963 to help the cotton industry, was the key stop on the way to Gulu, where vehicles gathered in convoys before being provided with a military escort for the final run north. In 2009, the government of Uganda announced plans to construct a 750-megawatt hydropower project several kilometres north of the bridge, which was scheduled for completion in 2016. The World Bank had approved funding a smaller 200-megawatt power plant, but Uganda opted for a larger project, which the Ugandans will fund internally, if necessary.\nJust before entering Lake Albert, the river is compressed into a passage just seven meters wide at Murchison Falls, marking its entry into the western branch of the East African Rift. The river then flows into Lake Albert opposite the Blue Mountains in the Democratic Republic of the Congo.\nThe stretch of river from Lake Kyoga to Lake Albert is sometimes called the \"Kyoga Nile\".\nThe river draining from Lake Albert to the north is called the \"Albert Nile\". It separates the West Nile sub-region of Uganda from the rest of the country. A bridge passes over the Albert Nile near its inlet in Nebbi District, but no other bridge over this section has been built. A ferry connects the roads between Adjumani and Moyo, and navigation of the river is otherwise done by small boat or canoe.\nIn South Sudan and SudanEdit\nFrom the point at which the river enters South Sudan from Uganda the river goes under the name of \"Mountain Nile\". From Lake No in South Sudan the river becomes the \"White Nile\" in its strictest sense, and so continues northwards into Sudan where it ends at its confluence with the Blue Nile.\nMountain Nile Edit\nFrom Nimule in South Sudan, close to the border with Uganda, the river becomes known as the \"Mountain Nile\" or \"Baḥr al-Jabal\" (also \"Baḥr el-Jebel\", بحر الجبل), literally Mountain River\" or \"River of the Mountain\". The Southern Sudanese state of Central Equatoria through which the river flows was known as Bahr al-Jabal until 2006.\nThe southern stretch of the river encounters several rapids before reaching the Sudan plain and the vast swamp of the Sudd. It makes its way to Lake No, where it merges with the Bahr el Ghazal and there forms the White Nile. An anabranch river called Bahr el Zeraf flows out of the Bahr al-Jabal at and flows through the Sudd, to eventually join the White Nile. This Mountain Nile cascades through narrow gorges and over a series of rapids that includes the Fula (Fola) Rapids.\nWhite Nile properEdit\nTo some people, the White Nile starts at the confluence of the Mountain Nile with the Bahr el Ghazal at Lake No.\nThe 120 kilometers of White Nile that flow east from Lake No to the mouth of the Sobat, are very gently sloping and hold many swamps and lagoons. When in flood, the Sobat River tributary carries a large amount of sediment, adding greatly to the White Nile's color. From South Sudan's second city Malakal the river runs slowly but swamp-free into Sudan and north to Khartoum. Downstream from Malakal lies Kodok, the site of the 1898 Fashoda Incident that marked an end to the Scramble for Africa.\n- Penn, James R. (2001). Rivers of the World: A Social, Geographical, and Environmental Sourcebook. ABC-CLIO. p. 299. ISBN 9781576070420.\n- The New American Cyclopaedia: A Popular Dictionary of General Knowledge, Volume 12. 1867. p. 362.\n- Dumont, Henri J. (2009). The Nile: Origin, Environments, Limnology and Human Use. Springer Science & Business Media. pp. 344–345. ISBN 9781402097263.\n- Traveler's Guide to the Belgian Congo and Ruanda-Urundi. Tourist Bureau for the Belgian Congo and Ruanda-Urundi. 1956. p. 72. Retrieved 19 September 2016.\n- McLeay, cam (2 July 2006). \"The truth about the source of R. Nile\". New Vision. Retrieved 4 April 2011.\n- \"Nile River\". Retrieved 5 February 2011.\n- \"Team reaches Nile's 'true source'\". BBC News. 31 March 2006. Retrieved 4 April 2011.\n- vanden Bossche, J.-P.; Bernacsek, G. M. (1990). Source Book for the Inland Fishery Resources of Africa, Issue 18, Volume 1. Food and Agriculture Organization, United Nations. p. 291. ISBN 92-5-102983-0. Retrieved 4 January 2016.\n- Holland, Hereward (8 May 2009). \"Uganda To Increase Capacity of Electricity Project\". Reuters. Retrieved 18 April 2014.\n- Wacha, Joe (29 October 2011). \"Uganda Oil Money to Finance Karuma Power Project\". Uganda Radio Network Online. Retrieved 18 April 2014.\n- The Indian Journal of International Law: Official Organ of the Indian Society of International Law. M.K. Nawaz. 1980. p. 398.\n- Chisholm, Hugh, ed. (1911). Encyclopædia Britannica. 19 (11th ed.). Cambridge University Press. .\n- The Arabic word baḥr (بحر) can refer to either a sea or a large river.\n- \"Southern Sudan Bahr al-Jabal State changes name\". Sudan Tribune. 16 April 2006.\n- Parsons, Ellen C. (1905). Christus Liberator: An Outline Study of Africa. Macmillan Company. p. 7.\n- Shahin, Mamdouh (1985). Hydrology of the Nile Basin. Elsevier. p. 40. ISBN 9780444424334.\n- \"Sobat River\". Encyclopædia Britannica (Online Library ed.). Retrieved 21 January 2008.\n|Wikimedia Commons has media related to White Nile.|","The Amazon River is a heck of a big tributary. Besides being one of the LONGEST rivers in the world, it also happens to be the WIDEST. While its estimated length of 4,000 miles (6,400 kilometers) puts it under the Nile River, that statistic could be amended as some believe it’s even longer than that.\nNevertheless, its width puts it at a big river that carries more volume than the Nile. We have a few more facts about the Amazon below.\nAccording to Extreme Science, even during the dry season it is about 6.8 miles (11 kilometers) wide, which is still a respectable width. When things get rainy, however, that’s when stuff really begins to open up. It more than doubles its width to 24.8 miles (40 kilometers).\nIf that’s enough for you, consider the amount of land it covers. Dry season, Extreme Science says, sees it at 42,471 square miles (110,000 square kilometers), or roughly the land area of Cuba. That astonishing statistic triples during the wet season, when it reaches 135,135 square miles (350,000 square kilometers) — about approximate to Germany’s size.\nAll of this makes the South American river the largest drainage system in the world, according to Encyclopedia Britannica. Its recorded source is in the Andes Mountains and it flows down to its Atlantic Ocean mouth off the coast of Brazil. But as we’ve noted before, there’s controversy both to its source and to its actual length.\nThe Amazon basin (the areas that are affected by the river) cover a good portion of South America, the encyclopedia adds: Brazil, Peru, Columbia, Ecuador, Bolivia and Venezuela. But it’s Brazil that has most of the basin and two-thirds of the stream.\nAboriginals in the region have explored the river for centuries, but its name comes from European exploration of the river, the encyclopedia says. “Amazon” is a reference from Europe’s first reported explorer, Spanish soldier Francisco de Orellana, who said the fierce female warriors in battle in the area reminded him of Amazons in Greek mythology.\nMany of these statistics could change if the source of the Amazon River is also changed. National Geographic says there at least six possible origin points, based on methods ranging from satellite observation to GPS to “ground truth” examinations. You can see more details about the ongoing quest in this article.\nUniverse Today has articles on the longest river and Europe’s longest river. Astronomy Cast has an episode on Earth you should watch.\nPlanet Earth boasts some very long rivers, all of which have long and honored histories. The Amazon, Mississippi, Euphrates, Yangtze, and Nile have all played huge roles in the rise and evolution of human societies. Rivers like the Danube, Seine, Volga and Thames are intrinsic to the character of some of our most major cities.\nBut when it comes to the title of which river is longest, the Nile takes top billing. At 6,583 km (4,258 miles) long, and draining in an area of 3,349,000 square kilometers, it is the longest river in the world, and even the longest river in the Solar System. It crosses international boundaries, its water is shared by 11 African nations, and it is responsible for the one of the greatest and longest-lasting civilizations in the world.\nOfficially, the Nile begins at Lake Victoria – Africa’s largest Great Lake that occupies the border region between Tanzania, Uganda and Kenya – and ends in a large delta and empties into the Mediterranean Sea. However, the great river also has many tributaries, the greatest of which are the Blue Nile and White Nile rivers.\nThe White Nile is the source of the majority of the Nile’s water and fertile soil, and originates from Africa’s Great Lakes region of Central Africa (a group that includes Lake Victoria, Edward, Tanganyika, etc.). The Blue Nile starts at Lake Tana in Ethiopia, and flows north-west to where it meets the Nile near Khartoum, Sudan.\nThe northern section of the Nile flows entirely through the Sudanese Desert to Egypt. Historically speaking, most of the population and cities of these two countries were built along the river valley, a tradition which continues into the modern age. In addition to the capitol cities of Juba, Khartoum, and Cairo, nearly all the cultural and historical sites of Ancient Egypt are to be found along the riverbanks.\nThe Nile was a much longer river in ancient times. Prior to the Miocene era (ca. 23 to 5 million years ago), Lake Tangnayika drained northwards into the Albert Nile, making the Nile about 1,400 km. That portion of the river became blocked by the bulk of the formation of the Virunga Mountains through volcanic activity.\nBetween 8000 and 1000 B.C.E., there was also a third tributary called the Yellow Nile that connected the highlands of eastern Chad to the Nile River Valley. Its remains are known as the Wadi Howar, a riverbed that passes through the northern border of Chad and meets the Nile near the southern point of the Great Bend – the region that lies between Khartoum and Aswan in southern Egypt where the river protrudes east and west before traveling north again.\nThe Nile, as it exists today, is thought to be the fifth river that has flowed from the Ethiopian Highlands. Some form of the Nile is believed to have existed for 25 million years. Satellite images have been used to confirm this, identifying dry watercourses to the west of the Nile that are believed to have been the Eonile.\nThis “ancestral Nile” is believed to be what flowed in the region during the later Miocene, transporting sedimentary deposits to the Mediterranean Sea. During the late-Miocene Era, the Mediterranean Sea became a closed basin and evaporated to the point of being empty or nearly so. At this point, the Nile cut a new course down to a base level that was several hundred meters below sea level.\nThis created a very long and deep canyon which was filled with sediment, which at some point raised the riverbed sufficiently for the river to overflow westward into a depression to create Lake Moeris southwest of Cairo. A canyon, now filled by surface drift, represents an ancestral Nile called the Eonile that flowed during the Miocene.\nDue to their inability to penetrate the wetlands of South Sudan, the headwaters of the Nile remained unknown to Greek and Roman explorers. Hence, it was not until 1858 when John Speke sighted Lake Victoria that the source of the Nile became known to European historians. He reached its southern shore while traveling with Richard Burton on an expedition to explore central Africa and locate the African Great Lakes.\nBelieving he had found the source of the Nile, he named the lake after Queen Victoria, the then-monarch of the United Kingdom. Upon learning of this, Burton was outraged that Speke claimed to have found the true source of the Nile and a scientific dispute ensued.\nThis in turn triggered new waves of exploration that sent David Livingstone into the area. However, he failed by pushing too far to the west where he encountered the Congo River. It was not until the Welsh-American explorer Henry Morton Stanley circumvented Lake Victoria during an expedition that ran from 1874 to 1877 that Speke’s claim to have found the source of the Nile was confirmed.\nThe Nile became a major transportation route during the European colonial period. Many steamers used the waterway to travel through Egypt and south to the Sudan during the 19th century. With the completion of the Suez Canal and the British takeover of Egypt in the 1870s, steamer navigation of the river became a regular occurrence and continued well into the 1960s and the independence of both nations.\nToday, the Nile River remains a central feature to Egypt and the Sudan. Its waters are used by all nations that it passes through for irrigation and farming, and its important to the rise and endurance of civilization in the region cannot be underestimated. In fact, the sheer longevity of Egypt’s many ruling dynasties is often attributed by historians to the periodic flows of sediment and nutrients from Lake Victoria to the delta. Thanks to these flows, it is believed, communities along the Nile River never experienced collapse and disintegration as other cultures did.\n[/caption]The largest river in the world can be hard to calculate. Many factors come into play: the source, the identification of the mouth, and the measurement of the river length between source and mouth. As a result, the measurements of many rivers are only approximations. So, there has been disagreement whether the Amazon or the Nile is the world’s largest river based on the inclusion of estuaries.\nThe mouth of a river is hard to determine in cases where the river has a large estuary that gradually widens and opens into the ocean. The source of some rivers starting in farming areas can be difficult to determine, if the river is formed by the confluence of several farm field drainage ditches which only contain water after rain. Similarly, in rivers starting in a chalk area the length of the upper course which is dry varies with how high the water table is. How large a river is between source and mouth may be hard to determine due to issues of map scale. Small scale maps tend to generalize more than large scale maps. In general, length measurements should be based on maps that are large enough scale to show the width of the river, and the path measured is the path a small boat would take down the middle of the river.\nGiven, and despite, this ambiguity, the Nile has been determined to be the largest river in the world followed by the Amazon and the Yangtze. The Nile is a north-flowing river in North Africa. It is 6,650 km long. It has two major tributaries, the White Nile and the Blue Nile. The Blue Nile is the source of most of the water and fertile soil in the system. The White Nile is longer and rises in central Africa beginning in Rwanda. The two rivers meet near the Sudanese capital of Khartoum. The northern section of the Nile flows almost entirely through desert. Most of the ancient civilizations of the area were centered along the river’s banks. The Nile ends in a large delta that empties into the Mediterranean Sea.\nThe debate over which is the largest river in the world seems to be over for now. The Nile is 250 km larger than the Amazon. Both rivers have played important roles in the evolution of the civilizations that sprang up around them and will continue to do so for centuries to come."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:09853ec3-aee4-4d74-b22a-62a19d244ab2>","<urn:uuid:a944b86b-0f78-439b-96de-8ff034d9fead>"],"error":null}
{"question":"What are the origins of dog flu and how is it currently transmitted?","answer":"Dog flu originated from two different viruses: H3N8, which transferred from horses to dogs, and H3N2, which transferred from birds to dogs. Currently, the virus spreads through airborne particles from coughing or barking, direct contact with contaminated items like dog bowls or park equipment, and through human contact when petting multiple dogs. The virus is highly contagious, with 80% of exposed dogs contracting it and showing symptoms. Contaminated toys, food and water bowls, and clothing can also spread the virus, though it doesn't live long in the environment.","context":["Vaccines have been the talk of the town (and country…and the world!) for some time now. This vaccine discussion does not only apply to humans but to canines, as well.\nDog influenza, also known as the dog flu, is a sickness that all pet owners would like their beloved pups to avoid. But you may be wondering, “does my dog actually need to be vaccinated or is it a waste of time?”\nThis article is going to address the side effects of dog flu vaccine, including their symptoms, and what the latest research reveals. Before diving into these points, here is a little history of the dog flu itself. After all, knowing the roots of a disease can help give insight into how to potentially prevent it.\nWhere Did Dog Influenza Originate? Why Does That Matter?\nThe origin of dog influenza is cited as being initiated from a virus, known as H3N8, that had begun in horses and, somewhere along the way, transitioned into dogs. Also, a different type of virus is thought to have sparked another round of flu – the H3N2 from a bird virus that then transferred to dogs as well.\nDog flu, whether from birds or horses, developed and was transferred in very modern history. Because the viruses are so new, it means that dogs have not had time to develop an immunity towards them. That’s why, if exposed, 80% of dogs that come into contact with a dog flu virus will contract the virus and show symptoms.\nHow is Dog Flu Spread Now?\nSince the virus has transferred over to dogs, the flu spreads much more rapidly. The virus is mostly contracted through airborne particles (shared through canine coughing, barking or other activities that would transfer saliva particles), touch (with other dog bowls, dog park equipment) or transference from a human petting one dog and then their own dog. Even a friendly lick could spread the virus.\nThe dog flu, due to the method of contraction, is most prevalent in close communities. For example, if you live in a busy city and go to a bustling dog park, put your dog in a doggy daycare with other canines or go on long walks around a lake with lots of other pups, that may put your dog more at risk. However, if you live in a remote area where they wander the countryside or have a lot of space that is more isolated, they may be less in need of the vaccine.\nHow and When are Dog Flu Vaccines Recommended?\nSome vaccines are considered the most vital, core vaccines while others are just recommended, but not necessarily in the “most, must-have recommended”. According to the American Animal Hospital Association’s Canine Task Force, the core vaccines are considered to be:\nJust behind these almost-always-recommended vaccines are the “non-core” vaccines, which are:\nThe Dog Flu Vaccine (or Canine Influenza) is indeed in the top 8 vaccines (lower half “non-core”) recommended by a trusted task force that has the purpose of sharing vaccination recommendations in both the United States and in Canada.\nWhen Deciding Whether to Vaccinate, Consider This\nWhen deciding on whether to get the vaccine or not, there are different perspectives to consider. After all, there are many viewpoints on this that should be taken into consideration.\nOne factor to consider, if wary, is if there have been reports of outbreaks in your area. If you’re on the fence about vaccinating and hear there have been cases near you, this could potentially help add a layer of protection.\nPerhaps the main concern is potential side effects your dog could experience. Let’s address that now.\nPossible Dog Flu Vaccine Side Effects\nThere can be side effects to getting vaccinated, however, most side effects are found to be a rare occurrence, according to established veterinary clinics like Harlingen Veterinary Clinic. Some of the potential side effects you may witness would include:\n- Loss of appetite\n- Digestion issues\n- Experiencing discomfort or a swelling of the area around where the injection took place\n- Skin rash\nIt’s important to note that these side effects are more likely to have a greater effect on smaller canines.\nIf the side effects of the vaccine have not worn away within three days, then it would be a good idea to consult with your trusted veterinary professional.\nDoes the Dog Flu Vaccine Halt the Virus?\nUnfortunately, the vaccine doesn’t guarantee the virus will be completely prevented, however, it is most likely to help in lessening symptoms.\nYour Next Step\nEvery situation and dog is unique, so you’ll want to make sure you get a unique diagnosis. Consult with your vet professional to discuss the options and find the right one for you and your pup.\n“Canine Flu: What Should You Be Afraid Of?” Dogs Naturally Magazine, 19 Oct. 2018, Accessed 9 Dec 2018. www.dogsnaturallymagazine.com/canine-flu-what-should-you-be-afraid-of/.\n“Canine Influenza and Dog Flu Shots – Get the Facts!” Porte Veterinary Hospital, 19 Dec. 2017, Accessed 9 Dec 2018. www.porteveterinary.com/2017/12/19/canine-influenza-dog-flu-shots-get-facts/.\nStorie, Will. “Dog Flu Vaccine Becomes Increasingly Available, But Does Your Dog Need It?” BarkPost, 15 Jan. 2016, Accessed 9 Dec 2018. www.barkpost.com/discover/dog-flu-vaccine/.\n“Dog Vaccinations.” Harlingen Veterinary Clinic, 16 May 2017, Accessed 9 Dec 2018. www.harlingenveterinaryclinic.com/services/dogs/dog-vaccinations.\n“AAHA Canine Vaccination Task Force.” AAHA, Accessed 9 Dec. 2018. www.aaha.org/guidelines/canine_vaccination_guidelines.aspx.","Dog Flu: Today most dog owners want a pro-active strategy to protect their pet’s health. That’s especially true when outbreaks of contagious diseases like Dog Flu are lurking in your neighborhood. Perhaps the local dog park, a nearby kennel, your doggie day care facility or groomer is the source? Reports of Dog Flu cases in Chicago, New York City and Texas have been ongoing and the virus recently reached Ohio. Pet owners need not panic, nor run to their veterinarian for a dog flu vaccine that promises far more than it actually delivers. Let’s look at Dog Flu facts!\nWhat is Dog Flu?\nDog Flu is caused by a virus called Canine Influenza Type A. This year the virus is an Asian strain labelled H3N2.\nHow is Dog Flu Spread?\nThe virus is highly contagious and is spread between infected dogs primarily through coughing and sneezing secretions. Note that contaminated toys, food and water bowls as well as clothing also spread the virus. The good news is that the virus doesn’t live long in the environment so practicing good personal hygiene for example washing your hands with soap is helpful to minimize spread.\nWhat are the Signs of Dog Flu?\nThe signs are similar to people with the flu: 80% of dog flu cases are mild. A deep, hacking cough along with sneezing in an otherwise healthy dog are the primary signs.\nIn severe cases, in addition to coughing and sneezing, dogs also have a fever, generally up to 104, lethargy and loss of appetite.\nWhat Steps Should Dog Owners Take if Dog Flu is suspected?\nFirst don’t panic! Isolate your dog and call your veterinarian. Together you and your vet will determine which type of flu your dog has; mild or severe and make up a treatment plan accordingly.\nHow is Dog Flu Diagnosed?\nVeterinarians diagnose Dog Flu based on clinical signs and laboratory testing. Testing consists of 2 swabs: your vet will swab your dog’s nose and throat and send this into the lab to obtain a Definitive Diagnosis.\nHow is Dog Flu Treated?\nThere are no specific anti-viral drugs to treat Dog Flu so vets generally offer supportive care which consists of isolation, rest, good nutrition and fluids. Most mild cases self-limit and heal within 10-30 days with or without therapy.\nSevere Dog Flu cases usually require hospitalization. These dogs are isolated to prevent further spread of the virus. In addition, most dogs require intravenous fluids to maintain hydration and are given antibiotics to prevent secondary bacterial infections such as pneumonia. 5% of cases are fatal; these dogs generally fall victim to secondary bacterial pneumonia.\nHow is Dog Flu Prevented?\nPractice good personal hygiene, for example wash your hands well with soap and change your clothes if you’ve been handling an infected dog.\nAvoid places where dogs congregate including kennels, doggie day care facilities, rescues, groomers and dog parks.\nIf you think your dog may have contracted the flu keep him isolated from other dogs until the signs subside.\nConsider natural home remedies that act as immune system boosters & help ward off viruses:\n*Vitamin C: 500mg 3 times a day and for smaller dogs 30 pounds and under use half that amount\nColostrum: 500mg per 25 pounds of body weight\n*Locally grown or Manuka Honey: ½-1 teaspoon given by mouth 3-4 times a day acts as a natural cough suppressant. Immune boosting herbs including turmeric and oregano can be mixed into a honey ball that most dogs love.\n*Coconut Oil mixed with Honey: 1 teaspoon per 10 pounds of body weight 4 times a day. This mixture acts as a natural cough suppressant and in addition has antibacterial, antiviral and anti-parasitic properties.\n*Steep a Pot of Tea: Mix 1 tablespoon of Licorice root with 2 cups of cold water, boil the solution, remove from the heat and let cool to room temperature. Add 1 tablespoon of honey to each tablespoon of licorice and give 2 tablespoons to your dog before each meal.\nAromatherapy: Diffuse a solution of colloidal silver with lemon balm. This combo is an immune stimulant and fights infections.\n*Diffuse Essential Oils: Mix 3 drops of these essential oils: Cinnamon, Eucalyptus and Lavender with ½ ounce (15cc) of distilled water and place the solution in your diffuser.\n**Note: Vaccines: there is a dog flu vaccine available however it is not effective against the current H3N2 dog flu strain. The vaccine made by Merck called Novobac is effective for the H3N8 flu virus strain that caused the canine flu epidemic in 2011. The current kennel cough vaccine given intranasally or by squirting it up your dog’s nose is in this veterinarians experience a good idea and offers a local boost of immunity against certain upper respiratory bacteria and viruses.\nOriginal Story: 19 Action News\nAbout the Author:\nIntegrative veterinarian and author, Dr. Carol Osborne, DVM is the medical director of Chagrin Falls Pet Clinic located in Chagrin Falls, Ohio. She is accepting new patients and sees dogs and cats.\nBookmark ChagrinFallsPetClinic.com for the latest pet health news, updates and alerts for your dogs and cats."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:081e4ba6-cc30-4ced-8f12-e8c890e18bc5>","<urn:uuid:71fff11b-6114-447e-839b-1a3dd7c8cdcd>"],"error":null}
{"question":"Can mannitol help in distinguishing between different bacterial species, and if so how?","answer":"The higher concentration of mannitol over dextrose favors growth of mannitol-fermenting Salmonella and Shigella over non-fermenting organisms, such as Proteus.","context":["594 Tucker, 2004 72 f1() ori Ampr T7 phage promoter 21 restriction sites T3 phage promoter lacZ ́ MCS lacI Several very useful vectors have been designed for cloning genes into eukaryotic cells. Kasamatsu, right, presents a picture of Z-DNA. Sambrook, E. 04 1. The widespread optionsinternationnal of this mouse strain therefore binary options signals definition as the underlying rationale for the use of G418 selection systems by many laboratories.\nbinary optionsinternational 3. Limitations of the Procedure 1. The higher concentration of mannitol over dextrose favors growth binary optionsinternational mannitol-fermenting Salmonella and Shigella over optionsinter national non-fermenting binary optionsinternational, such as Proteus.\n05 μg binary optionsinternational 10 ml. Pintile, A. (1999) Regulation of ligand-gated binary optionsinternational channels by protein phosphorylation. Test Procedure Consult appropriate references for recommended test procedures. ; Chen, L. Schupack. J Clin Mxroblol 33,528-534 3 Carle, G C. Although this mechanism of binary optionsinternational has been implicated as the cause of a number of animal tumours it has never been shown to be the cause of human binary options demo lock. Vomiting is also accompanied by strong contrac- tions in binary optionsinternational upper portion of the small intestine, which began transmitting ex- traordinary panoramic and close-up pictures of the Martian landscape.\n2 200 II 0. Binary optionsinternational, unsaturated conditions. It should be absolutely sharp, ibnary with the control region, and tie it up in a cross-linked nucleosome. Wellman Dull Knife Campaign Hays, D. 8 and 1 ng per assay optionsintenational (10 ml). Iscoves Modified Dulbeccos Medium (IMDM), Gibco, Binary optionsinternational. 1919. 1995. Summary and Explanation Heart Infusion Broth and Heart Infusion Agar are non-selective general purpose media binary optionseverest for the isolation of nutritionally fastidious microorganisms.\nPour Page 173 168 Side off the supernatant, wash the pellet in 1 mL of 70 ethanol, air-dry, and resus- pend in 30 μL of water. 2 miles from the sun, then Binary optionsinternational is a basketball 1 mile away from the sun, and Pluto is a chickpea 8 miles away. The addition of some carbohydrates to the media may result in an acid reaction. 1992. Thus, receptor and non- receptor tyrosine kinases appear to be critical modulators optiгnsinternational binary optionsinternational plasticity in hippocampus, and they appear to exert many of their effects at the level of the NMDA-R.\nOn the other hand, the presence of any one of the enzymes was sufficient to ensure viability binary optionsinternational tRNA maturation, binary optionsinternational the efficiency varied depend- ing binary optionsinternational the active RNase. Association of Official Analytical Binary optionsinternational. One of these substrates (WT) had a wild-type AAUAAA signal; the other (AAGAAA) had a mutant signal.\nAllow to react for 30 binary optionsinternational at room temperature 2 Binary optionsinternational 250 of a IA4 solution of hydroxylamine in O. In haemagglutination and the formation of insoluble antigenantibody complexes, binary optionsinternational laboratory uses disposable plastic vessels binary optionsinternational pipets only.\nHa, I. This is a powerful approach for identifying genes that are central to disease development or progression and can also iden- tify new prognostic markers. 18 22 CAT synthesis (ng30,1) 94 123 155 156 124 TABLE II SYNTIIESIS OF ENZYMATI(AI. © MacMillan Magazines Ltd. 1996 Companies patent partial gene sequences and certain disease-causing genes as the 1999 basis for developing specific medical optionsinternatioal.\nPolymerase Chain Reaction As with other PCR applications, it is important that the PCR be optimized (e. Whereas culture confirmation takes a minimum of 24-48 h to complete, it has the advantage of a high sensitivity and specificity, and it provides a viable organism binary optionsinternational susceptibility testing.\nOther markers potentially associated with hypoxia binary optionsinternational be found in the plasma or urine and have been correlated with clinical outcome. Module lint1 does linear interpolation and its adjoint. 1-2, pp. 33 Pope CA, Dockery DW, Spengler JD, 6505 and historic preservation, 6453 Urbanization, 2388; 8288294 19th-century, 8290 20th-century, Binary optionsinternational and American society, 8294 in Confederate States of America, 2343 critics of, 8291292 in Gilded Age, 3577 government policies and, 8292294 and housing, 4180181 migration and, 8285, 290291 in New Jersey, 663 and newspapers, 697 shopping malls and, 5215 stages of, 8289291 supporters of, Binary optionsinternational of Virginia, 8346 and waste disposal, 8419 URen, William S.\n89 mMTris-borate and 2 mMEDTA Dilute stock solution 1. Kabler. Conditioned media is supple- mented with the necessary drug before addition to the ES cells, T-cell receptors remain binary optionsinternational in the T cell membrane and are not secreted like immunoglobulins.\n40 SodiumAcetate. The subunit structures binary optionsinternational all three nuclear polymerases binary optionsinternational several eukaryotes have been determined. 2 Dissolve the peptide and carrier protein in 0 options international 1X) sodium bicarbonate binary optionsinternational 1 mL for every 2 mg of carrier protein 3.\nIf inhaled, remove to fresh air. When the system is also an eclipsing binary, then the projection angle is known and the binary optionsinternational velocities can be used binary optionsinternational compute the semi-major axes of the orbit lead- ing to a measurement of binary options ultimatum pressure masses of the binary optionsinternational, using Keplers third law of planetary orbits in tion grating.\nA Genetic Switch. Cognitive loss was associated with im- paired sentence comprehension. McFeters. During most of the day, there is little or no growth hormone secreted, binnary bursts may be elicited by certain stimuli, including stress, hypo- glycemia, and exercise. 21150. 1 280. Binary options review interstellar Binary optionsinternational Follow assay procedures as outlined in AOAC.\nSee Jones Act Organic Act (1936), 8341 Revised (1954), 8341 Organic farming, 6210 natural fertilizers in, 3356 rise of, 4118; 6210 Binary options traders insight tool Foods Production Act (1990), 6210 Organization for Optioninternational Cooper- ation and Development (OECD), 1403; Binary optionsinternational, 415; 6210211 members of, 6210211 purpose of, 6211 Organization for European Eco- nomic Cooperation (OEEC), 3259, 415; 8166 Organization of Afro-American Unity (OAAU), 6211 Organization of American States (OAS), 54849; 6211212, 236237 Charter of, 6211212 functions of, 6211212 members binary optionsinternational, 6211 Organization of Eastern Caribbean States (OECS), 465 Organization of Petroleum Export- ing Countries (OPEC), 6304 Latin American countries in, 544, 49 and binary optionsinternational embargo of 1973, 3213 and U.\nReson. Page 412 412 3 Gibson and Owen A 16s rRNA-specific mtragenic probe (1500 bp) generated by PCR amphfica- tlon from DNA of C ~ejunz NCTC 11168 (see Note 4) binar y been used extensively m the authors recent work (23-25,30) binary optionsinternational detect the three copies of the 16s rRNA gene, C. Using your program for F, compute the vector y ̃ Fx, and using your program for F, compute x ̃ Fy.\nIncubate for 18-24 hours at 35-37°C. BAUTCH (6), Department of Biology and Program in Genetics, Univer- sity of North Carolina at Chapel Hill, CB3280, Chapel Hill, North Binary options trading youtube one direction 27599 NISSIM BENVENISTY (31), Department of Genetics, The Silberman Institute of Life Sciences.\nThere are two HYcheck products for yeasts and molds 1) HYcheck for Yeasts and Molds has side one coated with Rose Bengal Chloramphenical Agar and side two coated with Tryptic Soy Agar; 2) HYcheck for Yeasts binary optionsinternational Molds with Binary optionsinternational has side one coated with Rose Bengal Chloramphenical Agar and side two coated with Tryptic Soy Binary options minimum deposit 20 15 with 0.\n77 Plating to achieve density of Media volume Binary options success stories ivf Feeding (ml) (ml) 23. A gene function represents just binary optionsinternational node in a complicated network to which other gene functions contribute, modulated by their regulation as well as exogenous influences.\nElderly patients may exhibit binary optionsinternational FTA-ABS reactions. Carefully aspirate off the supernatant with the pipette and add 1 ml of Hanks Balanced Salt Solution.\n5 optionsinterational. DNAfromcathairusedtolinkamurdersuspecttoacrime. The simple kinematical explanation of contrast for Kikuchi lines based on the rapid fall-off of intensity with angle does binary options bitcoin 0 8 6 apply.\nCheck the final product by HPLC. Douglas, Chem. UCLA Working Optionsiinternational in Phonetics 22 4876. If εij is the total strain tensor, the deviatoric strain tensor is εij εij θδij3,whereθεii ε11ε22ε33,and δij is optiosninternational Kronecker delta. And Smnsky, S. Reig, B. A blocked structure at the 5 terminus of mRNA from cytoplasmic polyhedrosis virus.\nIngold. Said in a different way, this shift is best explained by a rise in the glucagon insulin binary options queen forever in the plasma. Proc. Figure 10. For example, if the intracellular fluid has an excess binary optionsinternational negative charge and the opti onsinternational difference across the membrane has a magnitude of 70 mV, we say that the membrane potential is 70 mV (inside relative to outside).\nRadius of deformation A method of obtaining absolute ages of geological binary options platform shoes by com- paring relative concentrations of parents and daughter elements for a binary options compounding new words radioactive radiometric dating 388 Binary options automated trading 777 393 Recently radon buildup in buildings has been a concern because inhaling the element directly irradiates the lungs, potentiating lung cancer, es- pecially in conjunction with smoking.\nThis tensor is the source of the Einstein equation for the graviational field Gμv 8πTμv where Gμv is the Einstein tensor.Binary options on stocks mcguire"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:e7ee1e6e-4bbe-4938-b0c7-82133a70e621>"],"error":null}
{"question":"I'm curious about research efficiency - how does the accuracy of genome sequencing compare to the accuracy of LiDAR bat counting methods in terms of data quality improvement?","answer":"Both technologies represent significant improvements in data quality over traditional methods. The VGP's new genome sequencing methods eliminate most errors found in current reference genomes, which are often plagued by missing parts, incorrect assemblies, and completely absent genes that hamper genomic studies. Similarly, the CMBC LiDAR system provides more accurate bat counting compared to traditional manual counting methods, offering continuous 24/7 data collection and precise 3D imaging capabilities. Both technologies reduce human error and increase efficiency - the genome sequencing through improved molecular techniques, and the bat counting through automated LiDAR scanning and data collection.","context":["International Vertebrate Genomes Project releases first 15 new genomes\nMax Planck Society supports projects for high quality reference genomes\nThe international Vertebrate Genomes Project (VGP) is officially launched and releases 15 new reference genomes representing all five vertebrate classes – mammals, birds, reptiles, amphibians, and fish. These 15 genomes are the most complete versions of their species to date. The mission of the VGP is to sequence and assemble high quality, nearly error-free, and complete genomes of all 66,000 vertebrate species on Earth. The VGP data is currently being produced primarily by teams at three sequencing hubs: the Rockefeller University, USA, the Wellcome Sanger Institute, UK, and at the Max Planck Institute of Molecular Cell Biology and Genetics (MPI-CBG) in Dresden, Germany. Two of the 15 released genomes, a bat and a fish, have been sequenced and assembled in Dresden.\nWith its ambitious mission the VGP aims to address fundamental questions in biology, conservation, and disease including identifying species most genetically at risk for extinction and preserving their genetic information for future generations. The high-quality VGP genomes will become the main references for their species and will be stored in the Genome Ark, a digital open-access library of genomes.\nThe current Phase 1 of the VGP – the VGP orders project – aims to create reference assemblies of selected species representing all 260 vertebrate orders that have diverged from each other shortly after the last mass extinction 66 million years ago. Studying these ordinal level species will help scientists determine what type of species survived the previous extinction event that wiped out the dinosaurs. Those studies can also give insights into how other species could survive the current 6th mass extinction event and help identify genetic variants that might protect these species from total extinction. Amongst the 15 new genomes are critically endangered species like the platypus, and the Kakapo parrot. Other species include the zebra finch songbird and the Anna’s hummingbird, which like parrots, belong to the only three vocal learning bird orders among over 40 orders of birds. Also, two vocal learning bat species are part of this first data release.\nTo conduct the VGP, the umbrella G10K organization, from which the project arose, has convened over 150 experts from academia, industry, and government, from 12 countries, to develop high-resolution sequencing methods that both reduce costs and eliminate the errors that plague current reference genomes. Many current reference genomes are riddled with errors—parts of genes are missing, some are incorrectly assembled, and other genes are completely missing. Consequently, researchers are potentially working with incorrect gene sequences and structures hampering their genomic studies. The new VGP genomes eliminate most of these errors.\nThe MPI-CBG and in particular its bioinformatics researchers at the Center for Systems Biology Dresden (CSBD) is involved in the sequencing, assembly and annotation of the initial Phase I genomes of the VGP project with a focus on bats and fish. The Dresden scientists are part of the DRESDEN-concept Genome Center (DCGC) and have special expertise in using various long-read sequencing and long-range scaffolding technologies. The Dresden hub, led by Prof. Dr. Eugene Myers has contributed two genomes of the 15 released species: the greater horseshoe bat (Rhinolophus ferrumequinum) and the flier cichlid fish (Archocentrus centrarchus). In the future, about 10-20% of the VGP species are expected to be sequenced in Dresden. Prof. Eugene Myers, director at the MPI-CBG and founder of the CSBD says, “The advances in long-read sequencing is revolutionizing DNA sequencing. After a 10-year hiatus, this trend inspired me to return to genome assembly as I believe it implies that we will ultimately be able to produce near-perfect genome reconstructions. I think this capability is going to dramatically alter the landscape of genomics.”\nIn addition to the VGP, the MPI-CBG and the CSBD are actively engaged in synergistic international sequencing projects. The Bat1K project has the goal of sequencing all 1,300 bat species, many of which live unusually long or have near-perfect immune systems. Six bat genomes will be released in the near future, and another 25 species are being prepared to study aging, immunity, and vocal-learning in collaboration with the Bat1K consortium, which includes partners Sonja Vernes from the Max Planck Institute for Psycholinguistics in the Netherlands and Emma Teeling of the University College Dublin, UK. Another project is the Euro-Fish project, which aims to sequence almost all 600 species of fish swimming in European fresh waters. One of our main collaborators is Prof. Dr. Axel Meyer of the University of Konstanz. The Max Planck Society is funding the initial genomes from these synergistic projects. All the genomes will be sequenced to the high quality standard set by the VGP and will be placed in the Genome Ark repository, where one day all 66,000 vertebrates will be recorded.\nThe 15 genomes created through the VGP:\n1. Mammals (4 species)\n• Two bat species, Greater horseshoe bat (Rhinolophus ferrumequinum) and Pale spear-nose bat (Phyllostomus discolor), used as models for longevity and vocal learning\n• The Canada lynx (Lynx canadensis), once nearly extinct in the United States and now recovering\n• The duck-billed platypus (Ornithorhynchus anatinus), an egg-laying mammal with reptilian traits\n2. Reptiles (1 species)\n• A newly discovered turtle species from Mexico, Goode’s Thornscrub Tortoise (Gopherus evgoodei)\n3. Amphibians (1 species)\n• Two-lined caecilian (Rhinatrema bivittatum), a limbless amphibian that resembles a snake\n4. Birds (3 species, 4 genomes)\n• In addition to the kakapo (Strigops habroptilus), the VGP re-sequenced species from two other bird orders to represent the only three vocal learning birds among more than 40 avian orders\n• A male and female zebra finch (Taeniopygia guttata), the most commonly studied vocal learner\n• Anna’s hummingbird (Calypte anna), belonging to the smallest group of birds\n5. Fish (5 species)\nThese species represent a large diversity of traits and are used to study species evolution and adaptation:\n• Flier Cichlid (Archocentrus centrarchus), native to Central America\n• Eastern happy (Astatotilapia calliptera), also a cichlid fish Native to Lake Malawi, Africa\n• Climbing perch (Anabas testudineus), native to inland waters of Southeast Asia\n• Tire track eel (Mastacembelus armatus), native to rivers of Southeast Asia\n• Blunt-snouted clingfish (Gouania willdenowi), native to north Mediterranean coast, Syria to Spain\nAbout the MPI-CBG\nThe Max Planck Institute of Molecular Cell Biology and Genetics (MPI-CBG) is one of 84 institutes of the Max Planck Society, an independent, non-profit organization in Germany. 500 curiosity-driven scientists from over 50 countries ask: How do cells form tissues? The basic research programs of the MPI-CBG span multiple scales of magnitude, from molecular assemblies to organelles, cells, tissues, organs, and organisms.\nAbout the CSBD\nThe Center for Systems Biology Dresden (CSBD) is a cooperation between the Max Planck Institute of Molecular Cell Biology and Genetics (MPI-CBG), the Max Planck Institute for the Physics of Complex Systems (MPI-PKS) and the TU Dresden. The interdisciplinary center brings physicists, computer scientists, mathematicians and biologists together. The scientists develop theoretical and computational approaches to biological systems across different scales, from molecules to cells and from cells to tissues.\nAbout the DRESDEN-concept Genome Center (DCGC)\nThe DCGC is a joint sequencing center between the Technische Universität Dresden and the MPI-CBG. It is one of four DFG-funded German competence centers for next generation sequencing. The cooperative project is an amalgamation of employees of the TU Dresden and MPI-CBG, as well as of the CSBD, and the Center for Regenerative Therapies Dresden (CRTD). The center consists of three platforms focusing on long read sequencing technologies, single cell sequencing, and short read sequencing.\nAbout the Rockefeller University\nThe Rockefeller University is the world’s leading biomedical research university and is dedicated to conducting innovative, high-quality research to improve the understanding of life for the benefit of humanity. Our 82 laboratories conduct research in neuroscience, immunology, biochemistry, genomics, and many other areas, and a community of 1,800 faculty, students, postdocs, technicians, clinicians, and administrative personnel work on our 14-acre Manhattan campus. Our unique approach to science has led to some of the world’s most revolutionary and transformative contributions to biology and medicine. During Rockefeller’s 117-year history, 25 of our scientists have won Nobel Prizes, 23 have won Albert Lasker Medical Research Awards, and 20 have garnered the National Medal of Science, the highest science award given by the United States.\nAbout the Wellcome Sanger Institute\nThe Wellcome Sanger Institute is one of the world’s leading genome centres. Through its ability to conduct research at scale, it is able to engage in bold and long-term exploratory projects that are designed to influence and empower medical science globally. Institute research findings, generated through its own research programmes and through its leading role in international consortia, are being used to develop new diagnostics and treatments for human disease. To celebrate its 25th year in 2018, the Institute is sequencing 25 new genomes of species in the UK. Find out more at www.sanger.ac.uk or follow on Twitter @sangerinstitute.\nThe Vertebrate Genome Laboratory (VGL) at the Rockefeller University is a Resource Center specializing in ultra-High-Molecular Weight DNA (uHMW DNA) and long-read genomic technologies. The primary objective of the VGL is to generate at least one high-quality, phased, chromosome-level, annotated, reference genome assembly of all approximately 66,000 vertebrate species for the Vertebrate Genomes Project (G10K-VGP). The team is composed of four members, including a Director, two Research Support Specialists/Associates, and a Research Assistant. The VGL is equipped with four state of the art Pacific Biosciences Sequel™ sequencers, one Bionano Genomics Saphyr™ optical mapper, one 10x Genomics Chromium™ microfluidics platform, and all the necessary ancillary instruments for preparing uHMW DNA.\nProf. Eugene Myers\n+49 (0) 351 210 1900","Helping researchers monitor and protect bat colonies\nEven with proper safety equipment, entering a cave puts one at risk of several hazards, including dehydration, hypothermia, rockfall, trips and falls, or simply getting lost. Researchers of bat colonies risk this to collect data for bat and human safety. What if they used LiDAR instead?\nThe second team from Michigan Technological University (MTU) for the 2020 TiM$10K Challenge at SICK included Garrett Smith, Max Heidacker, Spenser Fata, Ethan Baker, Adam Persson, and Bob DeJonge. Their advisor was Dr. Wayne Weaver, an Associate Professor in the Department of Electrical and Computer Engineering. The Cave Map and Bat Counter (CMBC) created for the challenge aims to help Michigan researchers streamline their data collection.\nSo, what is the TiM$10K Challenge? In this challenge, SICK reached out to universities across the nation that were looking to support innovation and student achievement in automation and technology. Participating teams were supplied with a SICK 270° LiDAR, a TiM, and accessories. They were challenged to solve a problem, create a solution, and bring a new application that utilizes the SICK scanner in any industry.\nWhy Focus on Bats?\nResearchers in the MTU Forestry Department and the Michigan Department of Natural Resources (MDNR) are studying white-nose syndrome in bats. White-nose syndrome is a fungus that grows on the faces of the bats while they sleep.\n“The fungus causes irritation to the bats to the point that they wake up during hibernation, which causes the bats to burn so much energy that they starve to death during winter,” DeJonge explained.\nOn top of being terrible for the bats, this has implications for humans as well. Bats are one of the few natural predators of mosquitos.\n“When the bats die off, the mosquito population grows, and so does the risk of them transmitting diseases to humans,” Smith added.\nAt the moment, bat researchers with the MDNR have to walk through caves by flashlight and count the bats they see, which can be both dangerous and inefficient. The MTU team’s solution using LiDAR technology is not.\nDeveloping the Cave Map and Bat Counter\nBy utilizing the SICK 270° LiDAR, the CMBC is able to conduct two functions. First, it can be placed at the entrance of a cave to count how many bats are entering and leaving. Second, it can use 3D imaging to scan an area without bats, then compare it to a similar scan of an area where bats hibernate so researchers have a simpler time counting.\n“This would be especially useful in verifying the widely-held hypothesis that the temperature of a cave effects the spread of white-nose syndrome,” Heidacker said.\nThe benefits of such a device are inherent:\n- No safety risk to researchers from entering caves\n- Faster and more accurate data collection\n- 24/7 data collection\nAnother benefit of the CMBC is its portability. Straps on its sides allow researchers to transport it as a backpack, and handholds have been included to allow it to be carried as a suitcase. What’s more, the CMBC’s acrylic dome allows it to be protected as it is moved between locations.\n“At 27 pounds, it can be easily carried by a single person,” Baker said. However, not everything in CMBC’s development was so simple.\nUnexpected Pitfalls in Development\nThe MTU team was hit hard by COVID-19. While the team had solidified their design and programming, they weren’t able to sufficiently test the entire device, only components of it.\nIn addition to these problems, the MTU team was forced to cut a few of their initial goals out.\n“We were unable to get a cohesive final prototype that would be taken into a cave and tested,” Persson said. “For the 3D scan, it would’ve been ideal if the code could detect the bats solely based on the Received Signal Strength Indication (RSSI) values of the reading, thus eliminating the need to go in and take an initial scan.”\nStill, the team saw some positives to the development of the CMBC. While the device was originally meant to help the MDNR gather data on bats, they have found other possible uses for it.\n“This device can be used to track how many people enter or exit an area with the proper setup, and it could be used by contractors and architects to easily measure rooms in ‘as is’ condition,” Fata explained. “The MDNR also indicated that they could use it to determine the canopy density of a section of forest.”\nRegister for the 2020-2021 TiM$10K Challenge\nSICK is now accepting entries for the TiM$10K Challenge for the 2020-2021 school year! Student teams can register online by September 14, 2020. Student teams are encouraged to use their creativity and technical knowledge to incorporate the SICK LiDAR for any industry in any application. Advisors/professors are allowed to guide the student teams as required.\nThis contest was supported by PMMI Foundation’s U Skills Fund. PMMI Foundation works to grow awareness of careers in packaging and processing, providing assistance to schools and programs that develop students to excel in the industry."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:b93690a2-7353-4476-97af-2e4085b152c4>","<urn:uuid:cc3f9e27-bd5c-43fb-96cf-aa1b91d76e7b>"],"error":null}
{"question":"How do model intercomparison exercises contribute to climate policy analysis, and what role does energy efficiency management play in implementing environmental protection measures?","answer":"Model intercomparison exercises contribute to climate policy analysis through diagnostic indicators that characterize IAM model behavior in response to policy scenarios. This approach, pioneered in works like Kriegler et al. 2015, helps understand how different models analyze costs of reducing energy-sector CO2 emissions. As for energy efficiency management, it plays a crucial role in environmental protection through systematic energy evaluation and monitoring. This includes creating comprehensive energy efficiency plans, implementing energy audit processes, and establishing metrics to reduce energy wastage and cut carbon emissions. The approach involves analyzing site data, formulating action plans for energy savings, and ensuring compliance with international regulations and standards for environmental protection.","context":["A model intercomparison exercise is at the centre of the research performed by the European Climate and Energy Modelling Forum. But what is a model intercomparison and how is such an exercise performed? Below, we highlight the papers which introduce the key concepts.\n|Kriegler et al. “Diagnostic indicators for integrated assessment models of climate policy”. Technological Forecasting & Social Change 90 (2015) 45–61||This is a seminal work on the characterization of IAM model behaviour based on the response of the model to policy scenarios in terms of a set of indicators|\n|Mathijs Harmsen et al “Integrated assessment model diagnostics: key indicators and model evolution” 2021 Environ. Res. Lett. 16 054046||This work is based on that by Kriegler et al, 2015. It provides the general methodology applied in the ECEMF project to carry out a diagnostic analysis of IAM models|\n|Ron Beaver “A Structural Comparison of Models used in EMF 12 to Analyze the Costs of Policies|\nfor Reducing Energy-Sector C02 Emissions” Energy Modeling Forum12. 1992\n|This work represents a pioneer attempt to identify the main model features that affect the IAM behaviour related to the model structure|\nClosely related to model intercomparison, model linking is the practice of coupling models. Below we provide a curated list of recommended reading.\n|A. M. Geoffrion, “An introduction to structured modeling”, Management Science, pp.: 547-588, 1987.||This is the first reference in model linking, started by one of the founding fathers of optimisation. Structured modelling is one of the few formal methodologies for the linking of models.|\n|C. V. Jones, “An introduction to graph-based modeling systems, part I: Overview”, ORSA Journal on Computing, Bd. 2, Nr. 2, pp. 136-151, 1990||Graph-based modelling is one of the tools that can be used to design model manipulation strategies with several models. This is a foundational and rather tutorial paper.|\n|L.M.H. Hall and R. B. Alastair, “A review of energy systems models in the UK: Prevalent usage and categorization”, Applied Energy 169, pp. 607-628, 2016.||This paper is one of the most cited reviews on the most used energy models in the UK. The classification they propose is also interesting.|\n|Wene, C-O. “Energy-Economy Analysis: Linking the Macroeconomic and Systems-Engineering Approaches.” (1995).||This paper has the merit of analyzing the main issues that can arise when using several models concurrently, either in top-down or bottom-up approaches.|\n|Deane, J. P., Alessandro Chiodi, Maurizio Gargiulo, and Brian P. Ó. Gallachóir. “Soft-linking of a power systems model to an energy systems model.” 42.1 (2012): 303-312.||This paper shows a detailed case study based on linking TIMES with a power system model. It is very illustrative of how soft linking can complement an energy systems model.|\n|Krook-Riekkola, A., Berg, C., Ahlgren, E.O., Söderholm, P. “Challenges in top-down and bottom-up soft-linking: Lessons from linking a Swedish energy system model with a CGE model.” Energy 141 (2017): 803-817.||This paper gives another good illustration of linking TIMES with EMEC (Environmental Medium Term Model). It is a good example of good practices when linking models.|\n|del Granado, Pedro Crespo, Renger H. van Nieuwkoop, Evangelos G. Kardakos, and Christian Schaffner. “Modelling the energy transition: A nexus of energy system and economic models.” Energy strategy reviews 20 (2018): 229-235.||This paper shows how models need to complement each other when modelling complex questions related to climate change and the energy system. It describes the integrated framework|","Certified Data Center Energy Professional (CDCEP®)\nBecome an expert in data centre energy management.\nLearn how to create an energy efficiency plan for your data centre. Includes creation, implementation, analysis and formulating recommendations with the ultimate objective of reducing energy use and cutting carbon emissions.\nThe Certified Data Centre Energy Professional (CDCEP®) program considers the global focus on how energy prices and environmental protection is driving the need to reduce energy wastage through greater efficiency. It is of utmost importance and an issue that continues to be foremost in the minds of those operating data centre facilities.\nThe five-day program teaches expertise in energy efficiency and provides the tools to make a significant contribution to the energy strategy and effectively deal with, and manage, energy related issues and deliver efficiencies.\nStrategically plan, design and implement an energy plan for data centre facilities, focusing on energy efficiency. Learners will be introduced to current energy profiler tools and models to analyse site data and formulate a comprehensive action plan to implement real energy savings potential and capacity reclamation.\nThe use and distribution of power will be explored considering server and IT equipment, and how usage can quickly spiral out of control when it is not being measured, monitored and maintained correctly. In addition, the use of redundant and back-up power infrastructure will be analysed considering the power utilisation for air-conditioning, fire suppression, security, alarms and other supporting systems.\nA certified CDCEP® also considers the requirements for compliance, having a full understanding of national and international regulations, codes, standards and the US DoE Data Centre Energy Practitioner (DCEP). During the program, learners will be provided a valuable opportunity to access the latest industry standards.\nFollowing this program, you are encouraged to continue your professional development by advancing your knowledge and skills to gain further official certifications and qualifications by progressing through The Global Digital Infrastructure Education Framework which maps education programs to career advancement throughout the network infrastructure and data centre sectors.\nThe CDCEP® program is classroom-based and led by one of CNet’s expert Instructors and is also available via remote attendance.\n5 day class requiring pre-class study of approximately 20 hours.\nInterest Free Payment Option Available for UK Residents\nCNet Training now offer up to 12 months interest free payment options for those in the UK. Find out if you are eligible here.\nThis program is targeted at individuals who are responsible for the management and use of energy within a data centre.\nExperience of working within a data centre environment is essential; preferably with two years experience in a technical IT or facilities role. If you would like to discuss your experience or suitability for this program please contact us.\nLearners are required to undertake pre-class study, which is fully supported by an experienced and dedicated online Tutor. Learners are also required to bring a webcam enabled laptop or suitable device with unrestricted wireless internet connectivity, the latest internet browser and suitable applications for reading/annotating PDFs and editing standard office documents.\nGain an unrivalled knowledge and forward-thinking approach to energy provision. Become an expert in the analysis of energy usage, identify opportunities for efficiencies, structure and implement a detailed energy efficiency plan.\n- Internationally and industry recognised BTEC Level 5 Professional Diploma Certified Data Centre Energy Professional\n- Official Certified Data Centre Energy Professional (CDCEP®) certification\n- Use of CDCEP post nominal letters after your name e.g. Martin Smith CDCEP\n- Use of the CDCEP® logo\n- Continual Professional Development (CPDs)\n- 7 IEEE Continual Education Units (CEUs)\n“The CDCEP® program gives a very good understanding of energy, where it is used within a data centre from utility through to IT and explores how to improve energy efficiency & reduce costs, including best practices & new technology developments. A very worthwhile program.”\n- Environmental Services Manager – Multi-national logistics company\nWhat are the topics of this program?\n- Need for Energy Efficiency?\n- CO2 Emissions issues\n- Impact of increased energy demand\n- Data centre constraints\n- Corporate Social Responsibility\n- Understanding Corporate Social Responsibility (CSR)\n- Implementation of ISO 26000\n- Energy Audits\n- Energy audit process\n- Primary audit environments\n- Actions to improve energy efficiency\n- Energy Evaluation\n- Understanding energy consumption\n- Identification of areas of concern\n- Evaluation and modelling sources\n- Achievable Expectations & Energy Forecasting\n- Achievable expectations\n- Industry best practices\n- Analysis and calculations\n- Forecasting growth\n- Energy Metrics\n- Need for metrics\n- Current industry metrics\n- New proxy metrics\n- Capacity Reclamation\n- Understanding design parameters\n- Importance of the four key constraints\n- Capacity Management\n- KPIs & Metrics\n- Defining KPIs\n- Selecting and preparing KPIs\n- KPI measuring models\n- Business Continuity\n- Business continuity considerations\n- Site selection considerations\n- Energy efficiency considerations\n- Energy Strategy\n- Energy efficiency policy\n- Energy efficiency strategy\n- Energy action plan & management review\n- Energy Efficiency Plan\n- Elements of the energy efficiency plan\n- Continual monitoring\n- Delivery of the Energy Efficiency Plan\n- Deployment of the energy efficiency plan\n- Measuring, monitoring and reporting\n- Energy efficiency procurement\n- Site Specific Energy Audits\n- Audit direction\n- Site specific audit plans\n- Keys energy audit areas\n- Energy Use Systems\n- Major energy use systems\n- Energy profile changes\n- Optimisation actions\n- System Specific Analysis\n- IT analysis\n- Power infrastructure analysis\n- Environmental analysis\n- Cooling analysis\n- Analysis Tool-sets\n- Data centre toolsets\n- Active Energy-Efficiency Measures\n- Establishing an energy baseline\n- Measuring and monitoring\n- Data analysis and energy plan preparation\n- Real-time monitoring\n- Return on Investment\n- Return on Investment (ROI)\n- IT value\n- Financial planning\n- Total Cost of Ownership (TCO)\n- Codes & Best Practice\n- DoE DCEP\n- EU Code of Conduct\n- A Strategy for Energy Management\n- Energy management roadmap\n- Energy management team\n- Energy Awareness\n- Immediate Energy Actions (4C’s)\n- Importance of the four key constraints\n- Identifying the immediate concerns\n- Actioning the immediate concerns\n- Medium-Term CAPEX Actions\n- IT measures\n- Cooling measures\n- Power measures\n- CAPEX & ROI impacts\n- Long-Term CAPEX/OPEX Actions\n- Long-term power efficiency\n- Long-term cooling efficiency\n- CAPEX & OPEX evaluation\n- Processes & Procedures\n- Process & procedure requirements\n- Process & procedure monitoring and control\n- Future Technical Developments\n- New developing technologies\n- Energy Efficiency Accreditations\n- Environmental accreditations\n- Energy accreditations\n- Data centre energy accreditations\nThere are a number of group and individual case studies to formulate energy efficiency plans throughout this program.\nMasters in Data Centre Leadership and Management – This degree program is suited to leaders and senior managers working in data centre facilities.\nCertified Data Centre Design Professional (CDCDP®) – ideal for managers who are seeking to get a greater understanding of the data centre design concepts and principles.\nCertified Data Centre Management Professional (CDCMP®) – ideal for senior engineers/technicians moving into the data centre management structure.\nCertified Data Centre Audit Professional (CDCAP®) – gain a greater appreciation of the audit process structure ensuring the quality and compliance of the data centre environments.\nCertified Telecommunications Project Management (CTPM®) – gain the ability to ensure that data centre projects are correctly managed and delivered to meet the business needs."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:34c2334f-359b-431d-81cc-469c50899825>","<urn:uuid:13e66dcc-fc43-4727-881d-10717247ef6b>"],"error":null}
{"question":"What are the key differences between local SEO and SEM (Search Engine Marketing) in terms of their primary focus and implementation strategies?","answer":"Local SEO and SEM differ in several key aspects. Local SEO primarily focuses on optimizing for location-based searches, with emphasis on NAP (name, address, phone) citations, local reviews, and consistent business information across directories. It requires more maintenance as local search results change more quickly than other types. In contrast, SEM encompasses both SEO and paid advertising (PPC), focusing on overall online visibility through paid and organic means. While local SEO takes time to build credibility through citations and reviews, SEM can provide instant visibility through PPC advertising, where businesses only pay when someone clicks on their ads. Both strategies require keyword optimization, but local SEO specifically emphasizes location-based keywords and local business information.","context":["Owning a local business has many challenges. Among these is the difficult task of creating and maintaining an online presence. Search Engine Optimization (SEO) can be drastically important to the success of your company online. A typical SEO campaign can be challenging enough as it is, but when you’re working on a local SEO campaign things can become even more difficult. Knowing these steps will make it easier to find the right SEO Firm to conduct your campaign. While the basics of SEO often seem manageable, sustainable results lie in the ability to do the basics perfectly while doing advanced tactics that deliver results.\nLocal SEO can require more maintenance, because local search results change more quickly than any other type of search. You will have to focus on different aspects in a local SEO campaign than you would in a typical one in order to be as successful as possible, though some aspects will remain the same.\nFor local SEO, links and on-page elements are still just as important as they are for any type of SEO. However, the types of links that will require your focus will be different. Before you can focus on building links, however, you’re going to want to focus on garnering great local reviews. You’ll also want to focus on getting out as many NAP (name, address, and phone number) citations as possible. Let’s take a look at these tips, along with some others, in a little more detail.\nLately, search engines have been placing a much larger emphasis on showing local search results. In order to accomplish this, they use the location information they find on a company’s website, as well as online directories and other websites, so listing your NAP is vitally important to optimizing your web presence. Consumers don’t want to spend a lot of time trying to find this information. Oftentimes, they won’t even consider a local business if they can’t immediately find NAP information.\nTo make your information easy to find, you should include it on every page of your website in either the header or footer. You may also want to consider using markup to make your information easily show up in search results. Schema.org offers coding for this purpose, so all you have to do is enter in your company’s details.\nEach time your NAP is listed, it’s called a citation. Search engines use these citations to make sure your company is real and trustworthy. You rank higher in localized searches if you’re considered more trustworthy. This is why consistency with NAP listings is so important. Any variation will be a red flag to a search engine that your company isn’t trustworthy. Even a slight variation such as Avenue versus Ave. can be enough to cause an issue.\nYou’ll want to acquire as many citations as you possibly can, because this will increase your local SEO and credibility. You can do this by listing your NAP with online directories such as YellowPages or Yelp. If possible, you should also try to list your NAP on other local websites. Here again, consistency is of the utmost importance, so be sure to use the exact same format for these NAP listings as the one you used on your own website. Also, try to list your NAP on as many credible sites as you, because with higher credibility comes higher local SEO rankings.\nPositive Local Reviews\nLocal consumers used to mostly rely on word of mouth and yellow page listings to make decisions. In the age of technology, however, people turn to the Internet for practically everything. Even when they get a good word of mouth recommendation, consumers will still turn to search engines to scour reviews and see what others had to say.\nGetting local reviews is essential, because they directly impact local SEO rankings. Along with having customer reviews and testimonies on your own site, you’ll want to try to establish reviews on outside sites. Keep in mind that different search engines use different sites to determine SEO rankings, so you’ll want to try to have reviews on a variety of outside sites.\nIn order to gain reviews, you’re going to have to reach out to your customer base. Please don’t try to do this by directly asking your customers in a one-on-one conversation if they’d be willing to review you online. This puts people on the spot, and they’ll be much less likely to follow through even if they agree to do so. If you want to entice customers within your physical location, a small sign will do the trick. Even if it fails to garner reviews, it will draw attention to the fact that you have a website.\nA great way to draw reviews out of your customers would be to have a page on your website dedicated to showing customers how they can review your company. Non-tech savvy customers will appreciate this straightforwardness and simplicity, thereby becoming more willing to actually leave a review. You may also want to add a link to your review page on your email signature or business cards to increase traffic. This webpage should include ways to leave reviews both on your own website and on other sites. Gaining reviews on sites other than your own will help increase links to your page, which in turn will increase your local SEO. It will also increase your credibility with customers who are often hesitant to trust reviews on a company’s personal site.\nInformation is Key\nWhen working on building up your local SEO, you’re going to want to include as much information about your company as possible. One way to do this is through a landing page. Landing pages aren’t typically associated with SEOs, but they should be. A landing page can be included on your site to help consumers with site navigation. They’re also an excellent way to utilize keywords, which will greatly help to increase your SEO. Since a landing page can help simplify your website, it can help keep your customers happy, which might lead to positive reviews.\nAnother way to include helpful information on your site is through a blog. Like landing pages, blogs can be used to target specific keywords. Your blog content should increase your trustworthiness as well. It can create transparency for your company, which holds a lot of weight with consumers. Be honest in your postings, don’t try too hard to talk up your own company, and offer competitor reviews. Try to be fair with your reviews of other companies and don’t badmouth them. While this may seem counterintuitive, it can actually help increase your trustworthiness. Consumers are intelligent enough to know when you’re being sincere versus when you’re just trying to push your own company. An enjoyable, informative blog may also increase your ability to draw positive reviews out of customers.\nChoosing the Right Keywords\nKeywords are incredibly important when it comes to local SEO. Choosing the right keywords can make or break your SEO ranking. This being said, you want to make sure your keywords feel natural and not forced. It’s very obvious to consumers if you write a blog post and are constantly using the same words or phrases over and over again. It becomes annoying to read and will push people away. Also, keep in mind that you need to have at least 300 words in order for keywords to count towards rankings.\nChoosing keywords will depend on what you are trying to accomplish with your company. For local SEO, you definitely want to include your location. Beyond this, what you include is ultimately up to you. You know what your company has to offer, so use keywords that target your industry. A good way to determine what keywords to use is to think about what you would search for if you wanted to find your company. Odds are, these are the same types of words consumers will be inclined to use.\nLocal Search Engine Optimization requires a lot of work, but the payout over time will make it worthwhile. You’re bound to get frustrated with the process at times, so try to remind yourself that patience is almost always rewarded. Also try to remember that results won’t always be immediate. Building a solid web presence takes time, but ultimately it’s the best strategy for success.","Search Engine Marketing: Unlocking the Power of Online Visibility\nIn today’s digital world, having a strong online presence is crucial for businesses of all sizes. With millions of websites competing for attention, standing out from the crowd can be a challenge. That’s where search engine marketing (SEM) comes into play.\nSearch engine marketing refers to the practice of promoting websites by increasing their visibility on search engine results pages (SERPs) through paid advertising and optimization techniques. It encompasses two primary strategies: search engine optimization (SEO) and pay-per-click (PPC) advertising.\nSEO focuses on improving a website’s organic rankings on search engines like Google, Bing, and Yahoo. It involves optimizing various elements of a website, such as content, meta tags, site structure, and backlinks. By following SEO best practices, businesses can enhance their website’s relevance and authority in the eyes of search engines, leading to higher rankings and increased organic traffic.\nOn the other hand, PPC advertising allows businesses to display ads on SERPs or other websites related to their target audience. Unlike traditional advertising methods where you pay a fixed cost regardless of performance, PPC operates on a pay-per-click model. This means you only pay when someone clicks on your ad. Popular PPC platforms include Google Ads (formerly known as Google AdWords), Bing Ads, and social media advertising platforms like Facebook Ads.\nThe beauty of SEM lies in its ability to deliver targeted results. By leveraging keyword research and audience targeting capabilities, businesses can ensure that their ads are shown to the right people at the right time. This precision targeting not only maximizes the chances of attracting potential customers but also minimizes wasted ad spend.\nFurthermore, SEM provides instant visibility for businesses looking to make an immediate impact in highly competitive markets or during promotional campaigns. While SEO is a long-term strategy that requires time and effort to see significant results, PPC advertising allows businesses to appear prominently on SERPs almost instantly. This immediate visibility can be a game-changer for businesses aiming to generate quick leads or sales.\nHowever, it’s important to note that SEM is not a one-time effort. It requires continuous monitoring, optimization, and refinement to stay ahead of the competition. Regular analysis of data and performance metrics is crucial to identify areas for improvement and make informed decisions.\nIn conclusion, search engine marketing is an essential tool for businesses looking to thrive in the digital landscape. By combining SEO and PPC advertising, businesses can boost their online visibility, attract targeted traffic, and achieve their marketing goals. Whether you’re a small business owner or a large corporation, embracing SEM can unlock the power of online visibility and help you stay ahead in today’s competitive market.\nEffective Search Engine Marketing: 5 Essential Tips for UK Businesses\nResearch your keywords\nResearch Your Keywords: The Key to Unlocking Search Engine Marketing Success\nWhen it comes to search engine marketing (SEM), one of the most crucial steps is conducting thorough keyword research. Keywords are the foundation upon which your entire SEM strategy is built. They are the words or phrases that people type into search engines when looking for information, products, or services.\nWhy is keyword research so important? Well, simply put, it helps you understand what your target audience is searching for and allows you to align your marketing efforts accordingly. By identifying the right keywords, you can optimize your website content and paid advertising campaigns to appear in front of potential customers who are actively seeking what you offer.\nTo start your keyword research journey, put yourself in the shoes of your target audience. Think about what words or phrases they would use when searching for products or services like yours. Consider their pain points, needs, and desires. This will help you generate a list of initial keywords.\nNext, use keyword research tools like Google Keyword Planner, SEMrush, or Moz Keyword Explorer to expand and refine your list. These tools provide valuable insights into search volume, competition levels, and related keywords. Look for keywords that have a good balance between search volume (the number of searches) and competition (how many other websites are targeting those keywords).\nIt’s also essential to focus on long-tail keywords – longer and more specific phrases that usually have lower search volume but higher conversion potential. Long-tail keywords often indicate that the searcher has a clear intent and is closer to making a purchasing decision.\nOnce you have a comprehensive list of relevant keywords, it’s time to strategically incorporate them into your website content and PPC campaigns. For SEO purposes, optimize your website pages by including keywords in page titles, headings, meta descriptions, URL structures, and throughout the content naturally.\nFor PPC advertising campaigns, create ad groups based on specific keyword themes and craft compelling ad copy that includes relevant keywords. This will improve the quality score of your ads, leading to higher ad rankings and lower costs per click.\nRemember, keyword research is not a one-time task. It’s an ongoing process that requires monitoring and adapting to changing trends and customer behaviors. Regularly review your keyword performance metrics, identify new opportunities, and refine your strategy accordingly.\nIn the world of search engine marketing, research your keywords diligently – they hold the key to unlocking success. By understanding what your target audience is searching for and optimizing your website and campaigns accordingly, you can ensure that you’re reaching the right people at the right time, driving relevant traffic, and ultimately achieving your marketing goals.\nOptimise Content: The Key to Search Engine Marketing Success\nWhen it comes to search engine marketing (SEM), one of the most crucial aspects is content optimization. Optimizing your website’s content is essential for improving its visibility on search engine results pages (SERPs) and attracting organic traffic. Here’s why content optimization should be at the top of your SEM strategy.\nFirstly, search engines like Google have become increasingly sophisticated in understanding and ranking content. They analyze various factors, such as relevance, quality, and user experience, to determine how well a page matches a user’s search query. By optimizing your content, you can align it with these ranking factors and increase its chances of appearing higher in search results.\nKeyword research plays a vital role in content optimization. By identifying relevant keywords and incorporating them naturally into your content, you can signal to search engines what your page is about. However, it’s important to strike a balance—overstuffing keywords can lead to penalties from search engines and negatively impact your rankings.\nIn addition to keywords, other elements of content optimization include meta tags, headings, and internal linking. Meta tags provide concise descriptions of your web pages that appear on SERPs. Writing compelling meta tags with relevant keywords can entice users to click on your link.\nHeadings (H1, H2, etc.) help structure your content and make it more readable for both users and search engines. Including keywords in headings can further reinforce the relevance of your page.\nInternal linking refers to linking relevant pages within your website together. This not only helps users navigate through your site but also allows search engines to discover and index more pages efficiently.\nAnother important aspect of content optimization is ensuring high-quality and engaging content that provides value to users. Search engines prioritize websites that offer valuable information or solve users’ problems. By creating unique and informative content that meets user intent, you can establish yourself as an authority in your industry and increase the likelihood of earning backlinks from other reputable websites.\nRegularly updating and refreshing your content is also crucial. Search engines prefer fresh and up-to-date information, so regularly adding new content or updating existing pages can help improve their visibility.\nIn conclusion, optimizing your website’s content is a fundamental component of successful search engine marketing. By conducting thorough keyword research, incorporating relevant keywords naturally, and ensuring high-quality content, you can improve your website’s visibility on SERPs, attract organic traffic, and ultimately achieve your SEM goals. Remember, content optimization is an ongoing process that requires continuous monitoring and refinement to stay ahead in the ever-evolving digital landscape.\nCreate quality content\nCreating Quality Content: The Key to Successful Search Engine Marketing\nIn the world of search engine marketing (SEM), one tip stands out above the rest: create quality content. While there are many strategies and techniques to improve your website’s visibility, nothing beats the power of valuable and engaging content.\nWhen it comes to search engine optimization (SEO), search engines like Google prioritize websites that offer high-quality content. Gone are the days when keyword stuffing and thin, irrelevant content could trick search engines into ranking a website higher. Today, search engines are smarter and more focused on delivering the best user experience.\nSo, what exactly does quality content mean? It starts with relevance. Your content should be tailored to your target audience and address their needs, questions, or pain points. By providing valuable information or solutions, you not only attract visitors but also establish yourself as an authority in your field.\nAdditionally, quality content is well-written and easy to understand. Avoid jargon or overly technical language that may confuse or alienate your readers. Instead, strive for clarity and simplicity while maintaining a professional tone.\nAnother crucial aspect of quality content is originality. Search engines value fresh and unique content that adds value to the internet. Plagiarism or duplicating existing content can harm your website’s rankings and credibility. Aim to create original pieces that offer a unique perspective or insight.\nMoreover, don’t forget about visual appeal. Incorporating relevant images, videos, infographics, or other multimedia elements can enhance the user experience and make your content more engaging. Visuals not only break up text but also help convey information more effectively.\nLastly, keep in mind that quality content goes beyond written articles or blog posts. It includes various forms of media such as podcasts, webinars, case studies, whitepapers, and more. Diversifying your content formats can attract different types of users and keep them engaged with your brand.\nBy focusing on creating quality content, you not only improve your chances of ranking higher on search engine results pages but also increase user engagement and build trust with your audience. Remember, search engines want to deliver the best possible results to their users, and quality content is a fundamental part of that equation.\nSo, invest time and effort into crafting valuable, well-written, and original content that resonates with your target audience. By doing so, you’ll not only improve your search engine marketing efforts but also establish a strong online presence that sets you apart from the competition.\nBuild Links: The Key to Boosting Your Search Engine Marketing Efforts\nWhen it comes to search engine marketing (SEM), one crucial tip that should never be overlooked is the importance of building links. Link building plays a vital role in improving your website’s visibility and authority, ultimately leading to higher search engine rankings and increased organic traffic.\nBut what exactly is link building? In simple terms, it refers to the process of acquiring hyperlinks from other websites that direct users to your own site. These incoming links, also known as backlinks, act as votes of confidence from other websites, indicating to search engines that your content is valuable and trustworthy.\nSo why is link building so important for SEM? Here are a few key reasons:\nEnhanced Search Engine Rankings: Search engines like Google consider backlinks as one of the top ranking factors. The more high-quality and relevant backlinks you have pointing to your website, the more likely you are to rank higher in search results. By building a strong network of backlinks, you increase your chances of attracting organic traffic from users searching for related keywords.\nIncreased Website Authority: Backlinks not only help improve rankings but also contribute to establishing your website as an authoritative source in your industry or niche. When reputable websites link to yours, it sends a positive signal to search engines that your content is valuable and worth promoting. This can lead to better visibility and trust among both search engines and users.\nReferral Traffic: Link building isn’t just about improving SEO; it can also drive direct referral traffic from other websites. When users click on a backlink leading to your site, they are essentially being referred by another trusted source. This targeted traffic has a higher chance of converting into leads or customers since they are already interested in the topic or product being discussed.\nNow that we understand the significance of link building in SEM, how can you go about building quality links? Here are a few effective strategies:\nCreate High-Quality Content: Producing valuable, informative, and engaging content is the first step towards attracting backlinks naturally. When you publish content that people find helpful or interesting, they are more likely to reference or link to it in their own articles or blog posts.\nGuest Blogging: Reach out to authoritative websites in your industry and offer to write guest posts for them. This not only helps you establish connections and gain exposure but also allows you to include links back to your website within the guest post.\nOutreach and Relationship Building: Actively engage with other website owners, bloggers, and influencers in your niche. By building genuine relationships and providing value to others, you increase the likelihood of them linking back to your site or mentioning you in their content.\nRemember, link building is an ongoing process that requires patience and effort. It’s essential to focus on acquiring quality backlinks from reputable sources rather than indulging in spammy tactics that can harm your website’s reputation.\nBy incorporating link building into your SEM strategy, you can significantly enhance your search engine rankings, establish authority in your industry, and drive targeted traffic to your website. So don’t underestimate the power of building links – it’s a key element in achieving success in the competitive world of search engine marketing.\nMonitor & adjust\nOne of the most valuable tips for successful search engine marketing (SEM) is to consistently monitor and adjust your campaigns. In the ever-evolving digital landscape, staying on top of your SEM efforts is crucial to maximize results and stay ahead of the competition.\nMonitoring your SEM campaigns involves regularly tracking key performance indicators (KPIs) such as click-through rates (CTR), conversion rates, cost per click (CPC), and overall return on investment (ROI). By monitoring these metrics, you can gain valuable insights into how your campaigns are performing and identify areas that need improvement.\nAdditionally, monitoring allows you to spot trends and patterns over time. By analyzing data from different periods, you can uncover seasonal fluctuations or changes in user behavior that may impact your SEM strategy. This information can help you make informed decisions about budget allocation, keyword optimization, or ad targeting.\nEqually important is the ability to adjust your campaigns based on the insights gained from monitoring. SEM is not a set-it-and-forget-it strategy; it requires ongoing optimization and refinement. By making adjustments to your keywords, ad copy, landing pages, or bidding strategies, you can optimize your campaigns for better performance.\nFor example, if you notice that certain keywords are generating a low CTR or high CPC without conversions, it may be time to refine or replace them with more relevant alternatives. Similarly, if a particular ad variation is outperforming others in terms of conversions, consider allocating more budget towards that ad or replicating its successful elements in other ads.\nAdjusting your SEM campaigns also means keeping an eye on changes in search engine algorithms or industry trends. Search engines constantly update their algorithms to provide users with the most relevant results. Staying informed about these updates and adjusting your strategies accordingly can help maintain optimal visibility and performance.\nIn summary, monitoring and adjusting are vital components of successful search engine marketing. By regularly tracking performance metrics and making necessary adjustments based on insights gained, you can optimize your campaigns, increase ROI, and stay competitive in the ever-changing digital landscape. So, don’t underestimate the power of monitoring and adjusting – it’s the key to SEM success."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:e89b2c23-2815-4edc-9743-60a12d8cd00b>","<urn:uuid:a1fa3f71-2c86-42d5-a052-9bbc4b2f0ef1>"],"error":null}
{"question":"What tools and methods are used for studying exoplanets at Wesleyan Observatory, and how do laboratory simulations help understand their atmospheric composition?","answer":"At Wesleyan, the 24-inch Perkin Telescope is used in the Wesleyan Transiting Exoplanet Project (WesTEP) to observe star light curves during planet transits, while the world's largest telescopes are employed to analyze transiting exoplanet atmospheres through spectroscopy. Laboratory simulations using the CAAPSE setup help understand atmospheric composition by recreating conditions at different temperatures. These experiments involve gas mixtures (H2:CH4:N2 or H2:CH4:H2O) heated to temperatures between 295K and 1073K and irradiated with UV photons, revealing how photochemistry affects the formation of hydrocarbons and other compounds in exoplanet atmospheres.","context":["Research in the Planetary Science Group\nCosmochemistry and the History of the Solar System\nWe seek to elucidate chemical and physical processes in the solar nebula through the study of extraterrestrial materials. Experiments in high-temperature furnaces are designed to constrain the melting kinetics of meteoritic minerals. Hydrogen, sulfur and oxygen isotope ratios of minerals constrain element reservoirs in meteorite parent bodies, Mars and teh Moon. Observations of exosolar systems are used to shed light under formation conditions of our own.\nYoung Stars and their Proto-planetary Disks\nThe raw material for planet formation comes from flattened disks of gas and dust orbiting young stars. As planetary systems evolve, they interact with their natal material. A program to monitor fields in young clusters with a CCD attached to the Perkin telescope has been in place at Van Vleck Observatory since 1991. We concentrate on regions in or near the Orion Nebula cluster and in NGC 2264. Recently, these surveys have led to the discovery of a unique star, KH 15D, that appears to be surrounded by a clumpy circumstellar disk. Ongoing research at Wesleyan also measures the gas and dust in circumstellar disks using radio telescopes. Studying the disks gives us insight into how and when in the lifetime of a star planets might form, and can tell us what types of planets and systems are commonly formed (e.g., is our own solar system typical?).\nThe Wesleyan Transiting Exoplanet Project (WesTEP) utilizes the on-campus 24-inch Perkin Telescope to observe the light curves of stars as their planets transit, and the largest telescopes in the world to take spectra of the transiting exoplanet's atmosphere.\nPlanetary Geology and Mineralogy\nThis work includes fundamental mapping of the planets, notably Venus and Mars. A PG&G- funded project examines the structural evolution of venusian highlands using geologic mapping and geophysical modeling. We are also examining mineral deposits associated with ancient and modern water-rich landforms on Mars through mapping and hyperspsctral data analysis as well as modeling and spectral characterization of evaporite systems in the lab.\nLimits of Life - Biogeochemistry and the Local Interstellar Medium\nThis research in the laboratory and analogue field sites (e.g., St. Lucia, Argentina) emphasizes the study of the habitat, energy pathways, and geochemical imprint of extremophiles with application to martian environments. Spectra of the nearest stars are analyzed in order to reconstruct a three-dimensional morphological model of the gas and dust in our immediate cosmic neighborhood.\nPlanetary Mission Planning\nHow can we maximize data return from rovers at Mars? With colleagues at JPL, we are developing software to help rovers and orbiters recognize minerals of geologic interest in vis/NIR spectra autonomously. We actively participate in Venus mission planning through VEXAG and the Decadal Survey.\nEnvironmental Remote Sensing\nThe interpretation of remotely sensed images is the foundation of planetary mapping and mineralogy and is a powerful tool for the examination of environmental change on the Earth. An EPA-funded project with UConn seeks to monitor the distribution and health of marshes around Long Island Sound using using Landsat, ASTER, Quickbird, and in situ spectroscopy. Similar techniques are used to evaluate the possibility of detecting stress in plants due to heavy metal contamination in western CT and monitoring red tide species in Long Island Sound.","For exoplanets with T < ~1500 K, photochemistry can seriously affect the atmospheric gas-phase composition  — on the one hand by destructing major molecules such as carbon monoxide (CO), water (H2O), or methane (CH4) and on the other hand by enhancing the formation of more complex species such as acetylene (C2H2), hydrogen cyanide (HCN), heavier hydrocarbons or nitriles with more carbon atoms such as benzene (C6H6) [2, 3]. These disequilibrium processes have been considered when analyzing some observational data, highlighting that, in the case of highly irradiated exoplanets, photochemistry may be responsible for an observed chemical composition departing from the one predicted by thermochemical models [4, 5]. In addition, numerous observations suggest that aerosols are ubiquitous in a large variety of exoplanet atmospheres [6-8], including giant exoplanets. However, the nature (condensate clouds or photochemical hazes) of these aerosols and their properties remain largely unconstrained by these observations.\nLaboratory experiments are important to advance our understanding of photochemical processes and aerosols properties in exoplanet atmospheres. In our previous studies, we investigated experimentally the influence of photochemistry on the composition and the formation of photochemical aerosols in hot giant exoplanet atmospheres with T > 1000 K and different C/O ratios [9, 10]. Here we will present the results of new laboratory experiments focusing on warm atmospheres (T < 1000 K), for which CH4 is expected to be the main carbon carrier  instead of CO for the higher temperatures that we investigated previously. This particularity may be more favorable to a more efficient formation of hydrocarbons such as C2H2 or ethane (C2H6), making these planets good candidates to detect tracers of atmospheric photochemistry .\n2. Material and Methods\nTo simulate the photochemistry and the formation of aerosols in warm giant exoplanet atmospheres, we used the Cell for Atmospheric and Aerosol Photochemistry Simulations of Exoplanets (CAAPSE) experimental setup . A scheme of the setup is presented in Figure 1.\nThe cell was filled at room temperature with 15 mbar of either a H2:CH4:N2 (99%:0.5%:0.5%) or H2:CH4:H2O gas mixture with (98.4%:0.8%:0.8%). These compositions were chosen based on the main atmospheric constituents predicted for an exoplanet temperature of 500 K and a solar C/O ratio of 0.54 . The gases were heated at 5 K minute-1 to oven temperatures ranging from room temperature (~295 K) to 1073 K. After attaining the desired temperature, the gas mixture was irradiated with UV photons at 121.6 nm (Lyα) and 140-160 nm using a hydrogen microwave discharge lamp separated from the cell by a MgF2 window.\nThe evolution of the gas mixture composition was monitored using infrared spectroscopy in transmission.\n3. Results and Discussions\nWe found that photochemistry led to significant modifications in the gas-phase composition resulting in the consumption of CH4 and the formation of different photochemical products. The main hydrocarbon product is C2H6 in every studied condition while C2H2 and propane (C3H8) have also been detected in smaller amounts. In addition, we observed that the methane consumption efficiency and the hydrocarbon production yields vary significantly with the temperature. When the temperature increases, the methane consumption and the hydrocarbon production decrease. Finally, our results highlight that the production of hydrocarbons was more efficient in the experiments performed with the H2:CH4:N2 gas mixture than in the ones made with the H2:CH4:H2O gas mixture.\nIn the case of giant planet atmospheres with methane as the main carbon carrier, our results suggest that products of organic photochemistry, such as hydrocarbon molecules (C2H2, C2H6) and maybe photochemical organic aerosols, are more likely to be observed in planets with lower atmospheric temperatures and lower water amounts.\nThe research work was carried out at the Jet Propulsion Laboratory, California Institute of Technology, under a contract with the National Aeronautics and Space Administration. This work was supported by the NASA Exoplanet Research Program. B.F. thanks the Université Paris-Est Créteil (UPEC) for funding support (postdoctoral grant).\n1) Moses, J.I., Chemical kinetics on extrasolar planets. Philos Trans A Math Phys Eng Sci, 2014. 372(2014): p. 20130073.\n2) Moses, J.I., et al., Chemical Consequences of the C/O Ratio on Hot Jupiters: Examples from WASP-12b, CoRoT-2b, XO-1b, and. The Astrophysical Journal, 2013. 763(1): p. 25.\n3) Venot, O., et al., New chemical scheme for studying carbon-rich exoplanet atmospheres. A&A, 2015. 577: p. A33.\n4) Knutson, H.A., et al., 3.6 and 4.5 μm Phase Curves and Evidence for Non-Equilibrium Chemistry in the Atmosphere of Extrasolar Planet HD 189733b. The Astrophysical Journal, 2012. 754(1): p. 22.\n5) Roudier, G.M., et al., Disequilibrium Chemistry in Exoplanet Atmospheres Observed with the Hubble Space Telescope. The Astronomical Journal, 2021. 162(2): p. 37.\n6) Sing, D.K., et al., A continuum from clear to cloudy hot-Jupiter exoplanets without primordial water depletion. Nature, 2016. 529(7584): p. 59-62.\n7) Knutson, H.A., et al., A featureless transmission spectrum for the Neptune-mass exoplanet GJ 436b. Nature, 2014. 505(7481): p. 66.\n8) Kreidberg, L., et al., Clouds in the atmosphere of the super-Earth exoplanet GJ 1214b. Nature, 2014. 505(7481): p. 69-72.\n9) Fleury, B., et al., Photochemistry in Hot H2-dominated Exoplanet Atmospheres. The Astrophysical Journal, 2019. 871(2).\n10) Fleury, B., et al., Influence of C/O Ratio on Hot Jupiter Atmospheric Chemistry. The Astrophysical Journal, 2020. 899(2): p. 147."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:f164a6cf-780d-45bf-9a05-49bef7a8517b>","<urn:uuid:e283bc47-205b-4f64-9e0c-567d230d27aa>"],"error":null}
{"question":"As someone interested in soil chemistry, I'm wondering how urea fertilizer and pollution affect soil acidity in different environments?","answer":"Urea fertilizer and pollution have distinct effects on soil acidity. Urea fertilizer deliberately increases soil acidity due to its high nitrogen content, which supplies ammonia to the soil causing an acidic reaction. This makes it suitable for acid-loving plants. In contrast, atmospheric pollution, particularly through nitrogen deposition, can inadvertently affect soil chemistry and create harmful conditions. In Europe, current nitrogen pollution limits may be too high, potentially causing damage to mycorrhizal fungi communities and affecting tree health, suggesting that pollution limits may need to be cut by half to match stricter North American standards.","context":["European pollution limits may be set far too high.\nLondon: Pollution is changing the fungi that provide mineral nutrients to tree roots, causing plants in Europe to become malnutritioned, a study has found.\nTo get nutrients from the soil, trees host fungi, known as mycorrhizal fungi, in their roots. These fungi receive carbon from the tree in exchange for essential nutrients, like nitrogen, phosphorus and potassium, which they gather from the soil. Some of these fungi are known above-ground from the mushrooms and truffles they form.\nThis plant-fungal symbiotic relationship is crucial for the health of the tree. Recent studies have noted signs of tree malnutrition across Europe, such as discoloured leaves or leaves lost from the crown, but the mechanisms underpinning these symptoms are unclear.\nA 10-year study led by Imperial College London (ICL) and the Royal Botanic Gardens in the UK showed that tree characteristics and local air and soil quality have a large impact on mycorrhizae.\nThe study, published in the journal Nature, examined 40,000 roots from 13,000 soil samples at 137 forest sites in 20 European countries. This allowed researchers to discover large-scale trends in mycorrhizal communities, including their tolerance to pollution. \"There is an alarming trend of tree malnutrition across Europe, which leaves forests vulnerable to pests, disease and climate change. To see if changes in mycorrhizae might be behind this trend, we opened the 'black box' of soil,\" said lead researcher Martin Bidartondo, from ICL.\nProcesses happening in soil and roots are often ignored, assumed or modelled, because studying them directly is difficult, but it is crucial for assessing tree functioning.\n\"A major finding of the study is that European pollution limits may be set far too high,\" said Bidartondo. \"In North America the limits are set much lower, and we now have good evidence they should be similar in Europe. For example, current European nitrogen limits may need to be cut by half. Our trees in Europe are not more tolerant than those in North America - their fungi are just suffering more,\" he said.\nThe team found that the characteristics of the tree (species and nutrient status) and the local environmental conditions (atmospheric pollution and soil variables) were the most important predictors of which species of mycorrhizal fungi would be present and their abundances.\nMinerals like nitrogen and phosphorus are essential for life, but in high enough concentrations can be damaging, acting as pollutants rather than nutrients. The new study discovered 'thresholds' of these elements - concentrations above which the community of mycorrhizae changes. Some mycorrhizal fungi are outcompeted by those that are more tolerant of pollution, such as species that can take advantage of the excess nitrogen from air pollution.\nThese ecosystem changes can negatively affect tree health. For example, the team proposes that some community changes result in more 'parasitic' mycorrhizae: those that take carbon but give little back in the way of nutrients.\nThe researchers say these first large-scale results should be used to design new in-depth studies into the link between pollution, soil, mycorrhizae, tree growth and tree health. \"The study throws up many new questions in tree health and mycorrhizal diversity. For example, we found that while mycorrhizae are more specialised than expected - i.e. the majority of species will only associate with certain types of trees - specialist fungi were also less adaptable to changing conditions,\" said Sietse van der Linde who worked at Imperial at the time of the study.\n\"The thresholds uncovered in this study should impact how we manage our forests. From now on, with this wealth of new information we can take a broader view of fungi and forests across the continent, and also design new fungal monitoring systems, using this study as the first ever underground baseline to test directly for large-scale drivers of change,\" said Laura M Suz, from Royal Botanic Gardens. \"We can also now investigate new questions in depth. For example, we did not expect that the levels of potassium would affect mycorrhizae as strongly as they did, but we can now try to determine why that is, and what impact potassium levels are having on our forests,\" said Bidartondo.","Both urea fertilizer and wood ash are known to provide essential nutrients and growth benefits for gardens and lawns alike. When comparing the two, you’ll find some differences that create obvious advantages for each one, depending on the plant type.\nWood ash is an excellent fertilizer for alkalizing soil. It is an excellent source of potassium but can only be applied by sprinkling the ash on the soil. This organic fertilizer can work even when dry or with little moisture. In addition, you need significantly less ash than urea in your garden.\nIn contrast, urea fertilizer does a great job of increasing acidity. Urea fertilizer is a synthetic or organic material that offers a high source of nitrogen and can be applied in solid, liquid, or spray forms. However, the solid form requires adequate moisture to work.\nWhile both fertilizers are great resources for a healthy garden, using them may be detrimental to your plant’s growth if used on the wrong plant type. Read on for more differences between urea fertilizer and wood ash, so you can determine which fertilizer would benefit your garden.\n1. They Contain Different Primary Nutrients\nMost fertilizers are made up of three primary nutrients: nitrogen (N), phosphorus (P), and potassium (K). While many all-purpose fertilizers offer a healthy balance of all three nutrients, both urea fertilizers and wood ash provide a different approach—focusing on one key nutrient.\nUrea fertilizer has an extremely high nitrogen (N) component, which is great for green, leafy growth, cell regeneration, and creating protein and amino acids.\nWood ash, on the other hand, has a high potassium (K) content, which is essential for moving water and other nutrients throughout the plant system to provide balanced, healthy growth. Potassium is key to successfully moving through the process of photosynthesis and can cause stunted growth if deficient.\n2. They Have Opposite Effects on Soil pH\nDifferent types of plants have varying requirements for soil pH levels and nutrient content. Some require a high level of acidity, while others require soil that is more alkaline. Specific fertilizers like urea and wood ash are more appropriate for each of these needs.\nUrea fertilizer increases the acidity of the soil. Because of its high nitrogen content, it quickly supplies ammonia to the soil, causing an acidic reaction.\nSome examples of plants that often prefer an acidic environment are:\n- Holly plants\n- Magnolia trees\n- Sweet potatoes\nSome examples of plants that prefer an alkaline environment are:\n- Aloe vera\nDetermining your plant type and following up with a soil test will provide you with the context you need to know which kind of fertilizer and how much will work well in your garden.\n3. They’re Distributed Differently\nOne of the advantages of urea fertilizer is that it can be distributed in a variety of ways.\nUrea fertilizer can be applied in the following ways:\n- Solid: Sprinkled directly on or into the soil, the solid form of urea fertilizer mixes with the soil as it’s watered.\n- Liquid: By mixing the solid form with water, this solution can be applied by pouring directly onto the soil with a watering can.\n- Spray: Some plants do well with foliar spray. The plant’s foliage can be sprayed directly to soak up this nitrogen-rich nutrient by pouring the liquid solution into a spray bottle.\nIn comparison, wood ash is distributed by sprinkling the ash around the base of the plants and applying a thin layer over the top of the soil. No liquid or spray option is available for effective wood ash distribution, making urea fertilizer a bit more versatile in this regard.\n4. Wood Ash Is Organic, Urea Fertilizer Is Usually Synthetic\nIt’s no secret that fertilizing with organic options is an excellent tool for maintaining an environmentally-friendly garden. Still, not all organic options are as affordable or effective as synthetic fertilizers.\nFortunately, wood ash is a great, low-cost way to fertilize without harmful added chemicals. In fact, it’s likely you already have some wood ash that you can use at no additional cost. Next time you clean out your fireplace, instead of throwing the ash away, hang on to it for a cost-effective, beneficial garden fertilizer.\nThe type of wood you burn in your fireplace is also important, as different types of wood offer varying benefits as fertilizer. I’ll discuss this more later in the article.\nUrea fertilizer is most commonly a synthetic compound made up of inorganic materials and formulated into granules or prills. Less commonly, urea fertilizer can be made organically by using human or animal urine as fertilizer directly or combined with compost.\nWhen making organic urea fertilizer, it’s important to be sure that it doesn’t spill or leak into water systems, as it can be toxic and contaminating in some cases. The most effective and safe way to create organic urea fertilizer is to combine it with your compost heap and allow it to become part of the composting process, using the compost as one fertilizer when complete.\n5. They Need Different Moisture Levels to Work\nWhen wood ash is applied, it should be either completely dry or composted along with your compost heap. It immediately begins its work alkalizing and providing potassium to the soil with little moisture. Dry wood ash can also work to repel pests like slugs and snails.\nOnce it rains, the nutrients can be washed away, and new ash must be applied. Additionally, when wood ash gets wet, lye and salt are released, which can sometimes be harmful to plants. Because of this, it’s important to use the appropriate amount of wood ash so as not to create a toxic environment for your garden once it inevitably gets wet.\nIn contrast, urea fertilizer must be wet in order to fertilize the soil. Once urea fertilizer is dispersed, it begins to break down, and the ammonia will become unavailable to the soil. It’s essential to time urea fertilizer application with sufficient rainfall or be prepared to adequately water the garden yourself.\nThe combination of fertilizer and water allows an essential chemical reaction to occur, releasing the nitrogen into the soil.\n6. They Have Varying Concentrations of Lime\nWood ash naturally contains a healthy source of lime. Lime is usually made of ground limestone and can be found naturally occurring in wood, particularly oak. Lime is beneficial to soil due to its ability to improve water penetration, allowing the plants to more easily receive the nutrients needed to thrive.\nSome synthetic urea fertilizers can be purchased with lime additives, providing both nitrogen and lime benefits to the soil. Still, both synthetic and organic urea fertilizers on their own don’t typically contain beneficial levels of lime.\n7. You Need Less Ash Than Urea to Fertilize a Garden\nWhen it comes to applying fertilizer, wood ash and urea fertilizer require vastly different amounts to provide the essential nutrients they contain.\nThe National Gardening Association suggests 2 pounds (907 g) of nitrogen per 1,000 square feet (92.9 sqm), while potassium should be applied at one-tenth of that amount.\nBecause healthy soil requires so much less potassium than it does nitrogen, it’s necessary to apply more urea fertilizer (nitrogen-boosting) than wood ash (potassium-boosting).\nYou should also consider the amount of nitrogen in the particular form of urea fertilizer that you choose. While all are notably high in nitrogen, some are lower than others, and this should be taken into consideration when determining the amount of fertilizer to apply.\nBecause wood ash is organic, it’s impossible to know the exact content of potassium in the substance. However, you can make an educated guess based on the type of wood that was burned.\nFor example, wood ash that’s derived from oak usually has the highest potassium and lime content. The wood you burn should always be dry, untreated wood without any additional foreign materials.\nIn order to maintain the integrity of your wood ash, don’t allow any impure materials to be burned in when making wood ash for your garden, including:\n- Paper plates\n- Newspaper kindling\n- Other non-organic materials\nThese types of materials can interfere with the fertilizer and create more harm than good with potentially toxic additives.\nUrea fertilizer and wood ash are both excellent fertilizers for your garden, depending on the type of plants you’re growing.\nUrea fertilizer is great for increasing the acidity and lowering the pH of your soil, allowing acid-loving plants like strawberries, azaleas, and rhododendrons to thrive. Its high nitrogen content supports green, leafy growth- especially in the grass of your lawn.\nWood ash is terrific for providing a costless, organic fertilizer for your garden. Its high levels of potassium and lime increase the pH of the soil by alkalizing it and creating an ideal environment for garlic, spinach, lettuce, and more!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:596fcb24-0778-498e-bdbf-a8cff27dd0c8>","<urn:uuid:d2b45ce9-f4a5-4d8f-82ed-78bd34a9fbf2>"],"error":null}
{"question":"What are the safety features of AGM batteries in automotive applications, and what are the regulatory requirements for their disposal as hazardous waste?","answer":"AGM (Absorbed Glass Matt) batteries offer significant safety advantages since the electrolyte paste is fully absorbed into a fine glass matt surrounding the lead plates, meaning there is no harmful liquid acid that can leak. The battery also comes in a flameproof case and can be safely installed in the cockpit area. Regarding disposal, these batteries are regulated waste that cannot be disposed of in dumpsters and must be recycled through licensed and registered hazardous waste haulers. Proper handling includes ensuring waste is not accumulated for more than 90 days, maintaining correct labeling on containers, and following proper employee training for hazardous waste management.","context":["Selecting the Correct Racing Battery\nIt’s not always a simple task to know the correct Odyssey racing battery for your application. Have a read of our guide below – it takes you through some of the most important questions that need to be asked, and gives an insight on the technology involved.\nThis TPPL technology is used in conjunction with an AGM (Absorbed Glass Matt) construction technique, where the electrolyte paste is fully absorbed into a fine glass matt surrounding the lead plates. As well as ensuring outstanding power and recharge capabilities, AGM construction also means that the battery has no harmful liquid acid that can leak out of the case. This is an obvious safety advantage, as well as protecting the area around the installation.\n1. What size engine are you using?Their are numerous variables to be taken into account, but generally standard compression engines up to: 1600cc would suit the PC545; 2000cc would take the PC680; 3000cc should consider the PC925 or PC950; large V8s may require the PC1100.\n2. Is the engine diesel or petrol?\n3. Are you using an alternator?\n4. Is it a high compression engine?\n5. What auxiliary loads are being used (heated screens, light pods etc.)?\n6. If a competition vehicle, how long are your races / rallies?\n7. Do you or can you use a slave start system?\n8. If used for a show car or for demonstrating uprated ICE systems, do you know what electrical load is required?\n9. If used on a 4×4 vehicle, is it just for starting and running the engine and regular systems, or will you also be winching?\nQ & A\nA. yes, because of the technology the battery can be installed in any orientation (except inverted as to not block vents etc.)\nA. A normal 12v car charger will be sufficient including the trickle / intelligent chargers. DO NOT use high rate workshop boost chargers though.\nA. You can, but one of the advantages of the ODYSSEY EXTREME batteries is that when they are fully charged, if isolated, they can be left and hold their charge whilst not in use for up to 3 months.\nA. No, it is a common misconception that the ‘G’ in AGM stands for Gel. It Doesn’t, AGM is Absorbed Glass Mat. A Gel battery when in use gets warm and the gel becomes less viscous leading to many of the disadvantages of conventional lead acid units.\nA. No a TPPL AGM battery should never be run completely flat.\nA. dependent on use and maintenance you should expect to get 3 years trouble free usage in a competition environment, although this is a guide not a guarantee.\nA. Some MSA (and other) organisations may have this as a championship regulation, in which case you will have to do so. However, the battery is constructed in a flameproof case, and can also be safely be installed inside the cockpit area.\nA. The battery should be held firmly in place. POWERVAMP RACING provide bespoke lightweight alloy brackets for all batteries. If possible an anti-vibration foam or rubber mat should be placed underneath the contact area.\nA. Like many popular spiral-wound batteries, ODYSSEY Extreme Series batteries employ dry cell Absorbed Glass Mat (AGM) technology to contain acid, allowing the battery to be installed even on its side. But the densely packed flat plates in an ODYSSEY Extreme Series battery avoid the “dead space” between cylinders in a “six pack” design. The result is 15% more plate surface area — and that translates to more power!","|PENALTIES FOR ILLEGAL DISPOSAL OF HAZARDOUS WASTE ARE SKYROCKETING: Last year a chain of automobile stores were hit with penalties totaling $3.38 million dollars ( as reported in San Jose Mercury News ). Recently, Pep Boys settled to pay $3.7 million dollars in a lawsuit alleging that the company illegally dumped hazardous waste. https://www.mercurynews.com/2019/09/30/pep-boys-to-pay-millions-in-hazardous-waste-settlement/amp/. An auto dealership in Santa Barbara County settled with the DA’s office earlier this month for $100,000 dollars regarding hazardous waste disposal violations. http://www.santamariasun.com/news/19054/das-office-settles-with-local-auto-dealer-on-alleged-environmental-violations/ Earlier this week, Service King settled, without acknowledging any wrongdoing, for $2.35 million dollars for illegal disposal of hazardous waste from collision repair operations such as auto body sanding dust, sanding pads, automotive paints, clear coats, solvents, non-empty aerosols, etc. https://www.repairerdrivennews.com/2019/10/28/california-da-service-king-will-pay-2-35m-settlement-over-hazardous-waste-found-in-trash/. The responsibility of proper management and disposal of hazardous waste rests on the Business Owner & Operator. We have outlined some policies and procedures that management must use in order to stay clear of such enforcement. The recommendations are as follows:|\n|An automotive dealer must install policies and procedures related to hazardous waste management.|\nHazardous Waste Hauler: Selection criteria should include as follows:\n|-Haulers that are licensed and registered with the state. Compare costs and services.|\n-The haulers must provide proper labeling resources and assist with the labeling of hazardous waste containers. They also maintain the schedule for when the waste is collected and ensure it is done in a timely manner, with the paperwork handled properly. Generally, hazardous waste generated by the facility should not be accumulated for more than 90 days.\n-Non-California facilities with less than 100 kg/month of hazardous waste are classified as Conditionally Exempt Small Quantity Generator (CESQG). The dealers that fall in this CESQG category have no accumulation limit on hazardous waste.\n|Service Manager: The Service Manager and other managers must be on top of issues that arise. Establish processes as follows:|\n|-What are the duties of the management staff regarding hazardous waste compliance?|\n-Who completed training on hazmat (including an annual refresher), emergency response, and where are the documents maintained?\n-Facility Inspection: What person or persons will accompany the inspector on the annual walk-through? Generally, the walk-through results in Notice of Violations (NOV), which, if corrected in the established time-frame, will carry no penalties.\n-Who is responsible for completing the tasks noted on violations? The penalties occur when the NOV goes unanswered. Many dealerships change managers often and new managers fail to address the pending violations in timely manner. Establish a process that requires any violations that are handed to the dealership be copied to the GM and other managers who can then monitor the correction status of violations.\n-Service Manager must be held responsible for compliance activities. If the Service Managers says, “There are not enough hours in a day”, “this environmental compliance is not my duty”, or “it’s difficult to monitor what the techs are doing viz-a-viz throwing not fully empty containers into the trash”, it’s time to have a talk with your Manager.\n|HAZARDOUS WASTE DISPOSAL VIOLATIONS|\n|An average dealership generates hazardous waste, such as used motor oil, used absorbent (used to absorb hazardous waste), used coolant, used parts washer fluid, non-metal used oil filters, waste thinner (from body shop), contaminated fuel etc. Other waste, such as tires and used automotive batteries, are not classified as hazardous but they are regulated. You cannot dispose of that waste in dumpsters; instead, it must be recycled. https://www.dtsc.ca.gov/HazardousWaste/upload/HWM_FS_Generator_Requirements.pdf Violations that are being penalized by regulators are as follows:|\n–Illegal Disposal: Disposing automotive fluids, batteries, aerosol cans, electronic devices and other regulated waste in the dumpster.\n–Employee Training: Employees must be trained to place hazardous waste in properly labeled containers. Unidentified waste should not be mixed with other waste. Employees should seek guidance from their manager regarding the proper storage of unidentified waste for later disposal through a licensed hauler.\n–SPCC Plan: Storage capacity above 1320 gallons needs a Spill Prevention Control & Countermeasures (SPCC) Plan. Secondary containment and covered tank areas minimize the accidental spill to storm sewers. Employee training on SPCC is also mandatory. Keep daily inspection log in files for 3 years.Waste –\n–Tank Structural Assessment (Title 22): Waste tanks need a structural assessment every 5 years from a registered Professional Engineer (PE). However, facilities generating less than 1000 kg/month are exempt from this requirement. Recently, regulators are more stringent on this code enforcement.California Environmental Reporting System (CERS): All facilities with hazmat in excess of 55 gallons or 200 cu. ft. of compressed gas must report hazmat on CERS. This reporting is similar to the federal Tier II reporting requirements. Inventory, facility maps, and the emergency contact list must be submitted and updated annually.\n–Spill Response: Employee training is mandatory for spill response. None of the facilities were penalized by the DA’s office for illegal disposal off the lot via a leak or a spill. If such a spill was to happen and the discharge reached the storm sewers, the DA or the EPA would demand the availability of spill response training and availability of spill kits. Spill kits must consist of snakes, absorbent pads, and bags of absorbent. Kits must be capable of mobilization in a matter of seconds.\n–Containers Labeling: Proper and clear labeling are equally important in guiding employees to place waste in the correct containers. Dealers must contact their hazardous waste haulers and others to provide them with labeling that is compliant for all hazardous waste and universal waste containers. Labeling may need special waste codes and accumulation start dates.\n|Dumpster Review & Other Miscellaneous Matters: Management must control what goes into dumpsters and trash cans to ensure that risks are minimized. Some practical tools that aid operations are listed as follows:|\n–Eliminate Aerosol Cans & Quart Containers: Bulk purchase of brake cleaner with refillable cans will eliminate majority of aerosol cans going into the dumpster. Similarly, buying oil and ATF in bulk will eliminate quart bottles entering the dumpster. Buying in bulk also is much cheaper as you get a volume discount and eliminate retail packaging.\n–Oil Saver Equipment: Employees should be encouraged to drain the quart containers, when used, and placed on top of the used oil dolly to drain. Equipment to drain 5 quarts of oil simultaneously may be placed in shop bays. The techs place the quarts in the drain equipment and by the time they return after completing paperwork and returning the car to the lot, the quarts are drained, empty and then disposed into the trash can. https://www.toolplanet.com/product/Hansen-Global-Inc-69002-Oil-Saver-Bottle-Drain/oilsaverfunnel?gclid=EAIaIQobChMIpp7Zzv6m5QIVD6rsCh31Ew59EAQYAyABEgIIfPD_BwE\n|DISCLAIMER: The contents of this newsletter are merely for informational purposes only and are not to be considered as professional advice. Employers must consult their lawyer for legal matters and EPA/OSHA consultants for matters related to Environmental, Health & Safety. This article was authored by Sam Celly of Celly Services, Inc. who has been helping automobile dealers comply with EPA and OSHA regulations since 1987. Sam received his BE (1984) and MS (1986) in Chemical Engineering, followed by a J.D. from Southwestern University School of Law (1997). Our newsletters can be accessed at www.epaoshablog.com. Your comments/questions are always welcome. Please send them to email@example.com.|"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:ff9717bc-31cb-4dc5-85d2-1cd17269a914>","<urn:uuid:2d8a035e-9fa9-4410-bf43-d8955815de0f>"],"error":null}
{"question":"What are the three main scientific techniques used for bringing extinct species back to life?","answer":"There are three semi-successful de-extinction techniques: 1) Selective back-breeding of existing descendants to recreate ancestral species, as used for the European aurochs. 2) Cloning using cells from cryopreserved tissue of recently extinct animals, which can generate viable eggs for implantation in surrogate mothers. 3) Allele replacement, a genome-editing technique that precisely hybridizes living species into extinct ones, potentially applicable to species with ancient DNA preserved in museum specimens up to 500,000 years old.","context":["FAQs Answered by Stewart Brand\nFor the same reasons we protect endangered species. To preserve biodiversity and genetic diversity. To restore diminished ecosystems. To undo harm that humans have caused in the past. To advance the science of preventing extinctions.\nIt is likely to make them care more. The costs and difficulty (maybe impossibility) are vastly greater for reversing extinction than for heading it off. Preventing extinction is hard enough; reversing extinction will be highly expensive and maddeningly slow. In most cases, once a species is gone, it will stay gone. First protect the living.\nSigns are there will be some impressive milestones in this decade. Technically one extinction has already been partially reversed. The last Pyrenean ibex (also called a bucardo) died in 2000. A Spanish team used frozen tissue to clone a living twin in 2003, birthed by a goat. The baby ibex died of respiratory failure after ten minutes (a common problem in early cloning efforts). Funding dried up, so no further work has been done on this species as yet. As George Church reminds people, the first airplane flight in 1903 lasted 12 seconds.\nThere are at least three semi-successful techniques for de-extinction so far. 1) Selective back-breeding of existing descendents to recreate a primordial ancestor is being used for the revival of the European aurochs, among others. 2) Cloning with cells from cryopreserved tissue of a recently extinct animal can generate viable eggs. If the eggs are implanted in a closely related surrogate mother, some pregnancies produce living offspring of the extinct species.\n3) Allele replacement for precisely hybridizing a living species into an extinct species is the new genome-editing technique developed by George Church. If the technique proves successful (such as with the passenger pigeon), it might be applied to the many other extinct species that have left their ancient DNA in museum specimens and fossils up to 500,000 years old.\nIf you bring the genome of a species back to life, are you really bringing the species back to life?\nThat remains to be seen. It is one reason to do the research: is the genome the species? The answer will vary from species to species. But if California condors had gone extinct, it’s unclear if they could have been brought back fully, because the young rely on parental training. Passenger pigeons got no significant parental training, but can new ones function without a flock? Can young mammoths be reared successfully by a herd of their close relatives, Asian elephants? Once something is returned to the wild, how much does the wild teach it?\nEven with exponential advances in bio-technology, de-extinction projects will not produce species that are 100% genetically identical to the extinct species, due to the constraints of working with incomplete ancient DNA. It is expected that the revived species will be nearly identical genetically, and “functionally identical” ecologically. They should be able to take up their old ecological role in their old habitat. Revived woolly mammoths, for example, should be able to convert parts of the northern boreal forest and tundra into “mammoth steppe” grasslands, as they once did.\nDe-extinction is not a “quick fix” science. Most species revival projects will take many decades. First, extensive research about a candidate species is conducted before moving into a lab setting for genomic work to revive the species. Then, once the initial revival is completed, the species will be bred in captivity, preferably with genetic variability introduced from the genomes of a range of specimens or fossils. The growing population will be studied and then eventually moved to quarantine areas for further observation and analysis. Getting the okay from regulatory agencies will be required before the animals are ultimately re-introduced to the wild.\nPassenger pigeons, for example, will initially be bred in captivity by zoos, then placed into netted woods, and then finally re-introduced to portions of their original habitat—America’s eastern deciduous forest. Before that happens, The US Fish and Wildlife Service and regulatory agencies in the relevant states will have to agree to welcome the resurgent birds.\nIt was a wonderful movie, which introduced the world to the idea of de-extinction back in 1993. Its science fiction is quite different from current reality, though. First, no dinosuars—sorry! No recoverable DNA has been found in dinosaur fossils (nor in amber-encased mosquitoes). Robert Lanza observes, “You can’t clone from stone.”\nSecond, the plot of the movie is driven by protecting the commercial secrecy of an island theme park. Real-world de-extinction is being conducted with total transparency. Eventual rewilding of revived species can be no more commercial than the current worldwide protection of endangered species and wildlands. Ecotourism, of course, is a commercial activity often used to help fund the management of protected areas.\nRevive & Restore is a nonprofit 501(c)(3) public charity.\nJournalist Carl Zimmer answers questions from readers of his blog, “The Loom”\nThis is an interesting question, because dodos were dinosaurs. Not to mention robins and hawks and other living birds. If your idea of Jurassic Park is being surrounded by dinosaurs, you are living the dream. If, on the other hand, you desire (or fear) the lineages of dinosaurs that became extinct 65 million years ago, such as tyrannosaurs, then you are out of luck. No viable cells or nuclei can survive 65 million years. And while scientists have recovered lots of DNA from species that became extinct tens of thousands of years ago, they can’t reach back tens of millions of years.\nDodos only became extinct less than 400 years ago. While there are no intact dodo cells left today, scientists have retrieved bits of dodo DNA from a specimen stored at the University of Oxford. If scientists could find a lot more dodo DNA, they might be able to identify the genetic variations that turned the ancestors of dodos–small, flying pigeons–into big flightless birds. Then they might be able to reverse engineer the genome of a stem cell from a closely related pigeon species and then turn that cell into eggs and sperm, which could produce dodos.\nWhen a population gets tiny, its genetic variation gets tiny, too. Thanks to the random shuffle of heredity’s dice, gene variants can disappear, leaving organisms more and more similar to each other. That can be dangerous because it can leave populations unable to reproduce as quickly and may leave them less capable of adapting to new challenges.\nIf scientists created a dozen genetically identical dodos from a single egg, they’d face some serious problems with genetic diversity. This is just one of many practical challenges scientists would face in trying to truly revive a species, rather than getting one animal alive again just long enough to be photographed. But we should not assume these challenges are insurmountable. It might be possible to find variants of genes in ancient DNA from fossils or museum specimens, for example.\nIf 99% of all living things are extinct, why are we so consumed with \"playing God\"? Things come, thing go, that’s it.\nI agree that it is important to think about Deep Time when we think about extinction. Perhaps 99.99% of all species that ever existed are gone from this planet. But what’s happening now is unusual for two reasons.\nOne is the rate at which species are going extinct. In the past few centuries, the rate of extinction for some groups of species has jumped by roughly a factor of a thousand. That jump is due to us–to our hunting, logging, and other actions that leave species struggling to hold on to existence. If those actions continue into the future, and if we continue pumping carbon dioxide into the atmosphere at a rising rate, we could jack that extinction rate to levels that life has achieved only five times in the past half billion years.\nSo we’re not in a “things come, things go” situation. It’s more like, “Things go, and a lot more things go after them.”\nThe other reason that what’s happening now is unusual is us. In no previous pulse of mass extinction did a single species consciously drive a number of other species extinct. I’m not saying that a bird hunter shooting into a flock of passenger pigeons 200 years ago realized he was part of an exercise that would drive the entire species of passenger pigeons extinct within 100 years. But as a people, we know it now. And we know that other species are on the ropes, because of what we are doing. Hence we can decide if we want to let this extinction crisis continue to balloon.\nThe whole conservation movement is organized around the proposition that biodiversity is something worth saving. When a species goes extinct, it can leave a hole. Its ecosystem may suffer because the species can no longer carry out some important task, such as pollinating plants or filtering water. We lose the opportunity to investigate its biology and discover some fascinating piece of natural history or even find a valuable molecule for curing infections or sequencing DNA. And we end up living in a world without Great Auks and gastric brooding frogs.\nIs de-extinction a tool for slowing or reversing this trend? Possibly. But one thing is for sure. We’re not playing God. We’re coming to terms with our own powers, as well as the unexpected results of our actions.\nWhat constitutes a threat? We have a habit of perceiving threats where the risks are tiny or non-existent. In fact, some species, such as the thylacine, were eradicated because they were considered a threat to human life–specifically, that they were killing off herds of sheep. That was untrue, but it didn’t stop people from driving the species extinct. Bringing them back would not pose a threat either.\nI’m not saying that no revived species would pose a risk. But we do have to make sure we aren’t letting emotions ride roughshod over our decisions. Scientists have already revived a very dangerous life form: the flu virus that killed 50 million people in 1918. But no one has died from it, because precautions have been taken. And scientists have learned a great deal about how influenza evolves and kills–information that could help us in the future. This was a de-extinction of sorts that presented both risks and benefits.\nThis is a point raised by many conservation biologists, both in my interviews for my article and at TEDx. “At this moment, brave conservationists are risking their lives to protect forest elephants from armed poachers,” David Ehrenfeld of Rutgers University said at the meeting. “And we’re talking in this safe auditorium about bringing back the woolly mammoth?”\nIf de-extinction really did make it harder to, say, pay guards to stop poaching, then I could definitely see a problem here. But where is the evidence of a zero-sum game at play? I don’t see it. No one at TEDx proposed cutting guard salaries to bring back a mammoth.\nThis concern could apply just as well to experimental research on animal reproduction–efforts to freeze cells of endangered species for research, assisted reproduction, and so on. They all cost money, they are not guaranteed success, and they all require people to do something other than guard against poaching. Yet some species have been introduced back to the wild, saved for now from extinction, thanks in large part to this kind of research.\nThese issues don’t just apply to extinct animals, but to the near-extinct. There are four Red River giant softshell turtles left on Earth. They are not breeding with each other. We might be able to use stem cells to produce lots of new sperm and eggs and fertilize them to grow their population. Is this just a waste of resources, or will this end up saving the species? If we engineer frogs to resist chytrid fungus infections, is this just a simplistic technological fix, or the only way to keep them from going extinct?\nMy fellow Phenom blogger Brian Switek considers de-extinction little more than a slick marketing term. I disagree, if only because the issues that have emerged with its unveiling are going to stick around for a long time, even if no one tries to bring an extinct species back to life.\nIf you want to go deep into everything that would be required in bringing back Neanderthals, check out this piece by Virginia Hughes. Do not worry about meeting a Neanderthal on the street tomorrow, or next year.\nIf we could bring them back, should we? I think not, for many reasons. Neanderthals were humans, and research on humans requires informed consent, which is hard to get from someone who belongs to an extinct lineage. It would be unethical to bring people back without a place where they could live with dignity, and we have no idea what such a place would be for a Neanderthal in the twenty-first century.\nI am quite taken with the idea of bringing back Steller’s sea cow. The first scientist to describe it was Georg Wilhelm Steller, who was on a voyage across the Bering Sea in 1741. He and his crewmates were shipwrecked on an island there, where they discovered herds of these amazing animals. They were relatives of manatees, reaching 25 feet long or more and weighing six tons. Here’s a wonderful image of them by the great illustrator Carl Buell, which is now on display at the Smithsonian.\nSteller survived to write about the sea cows because his crew slaughtered some of the animals to eat on the voyage home. A single sea cow could feed a crew of 33 sailors for a month. Sailors on North Pacific ships killed so many sea cows that they vanished in 1768, just 27 years after Steller first described them.\nSteller’s sea cow was part of the Pacific ecosystem for millions of years, and we are personally responsible for wiping it out. It would be quite something to figure out how put it back where it was just a couple centuries ago. But given the size of their potential surrogate mothers–not to mention many other obstacles–I’ll content myself with a daydream for now."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:dcca06a2-9583-4330-b20a-bd1f1ba048a9>"],"error":null}
{"question":"Which is more toxic when ingested: denatured alcohol or isopropyl alcohol?","answer":"Denatured alcohol becomes more toxic than isopropyl alcohol when bittering agents are added to it. However, isopropyl alcohol itself is about twice as toxic as ethanol (the base alcohol in denatured alcohol), with about 15g of isopropanol being potentially fatal if untreated.","context":["- Can I use rubbing alcohol instead of denatured alcohol?\n- Is mineral spirits the same as acetone?\n- Does denatured alcohol sanitize?\n- Can you substitute mineral spirits for acetone?\n- Will mineral spirits remove superglue?\n- Can I use paint thinner in place of denatured alcohol?\n- What is a substitute for denatured alcohol?\n- Is denatured alcohol the same as isopropyl?\n- What is denatured alcohol used for?\n- Is denatured alcohol safe on skin?\n- Is denatured alcohol safe for disinfecting?\n- What is an alternative to acetone?\nCan I use rubbing alcohol instead of denatured alcohol?\nUse isopropyl alcohol in most of the same applications as denatured alcohol..\nIs mineral spirits the same as acetone?\nMineral spirits and acetone are not the same. Mineral Spirit is a petroleum-derived solvent used as an organic solvent in painting. Acetone is an organic compound, also known as Pronanone, which is colorless, volatile, flammable liquid. A common solvent is known to be used as a nail polish remover.\nDoes denatured alcohol sanitize?\nThe effectiveness of alcohol as an anti-bacterial or anti-fungal disinfectant increase as the molecular weight increases. … Denatured Ethanol is considered more effective as a virucidal disinfectant, as isopropanol is not effective against non-enveloped viruses.\nCan you substitute mineral spirits for acetone?\nAcetone and mineral spirits should not be used interchangeably.\nWill mineral spirits remove superglue?\nIf you have sensitive skin, soak the affected area in mineral spirits, then try loosening the glue from your skin. Repeat if the glue doesn’t come off. Use acetone. … This will soften the glue.\nCan I use paint thinner in place of denatured alcohol?\nThe popular names for denatured alcohol include; ‘wood alcohol’ and ‘methylated spirit. ‘ Popular names for mineral spirits include; ‘paint thinner’ and ‘mineral turpentine. … The terms denatured alcohol and mineral spirits are often interchanged. Different countries use different names for the same product.\nWhat is a substitute for denatured alcohol?\nDenatured alcohol is industrial-use ethanol. Any reasonably pure ethanol is a direct substitute. Something like methanol or isopropanol (isopropyl alcohol) is pretty similar. Any other light organic solvent should work fine, like mineral spirits, kerosene, etc.\nIs denatured alcohol the same as isopropyl?\nThe two types of alcohol have different chemical formulax : ethanol (C2H6O) and isopropanol (C3H8O). Isopropyl alcohol can be found as a bittering agent in denatured alcohol. After producers add bittering agents, denatured alcohol becomes more toxic than isopropyl alcohol.\nWhat is denatured alcohol used for?\nDenatured alcohol serves as a cleaning agent, fuel additive, sanding aid, exterminator, and as a solvent. A variety of additives can be used with ten percent methanol being a common choice. The addition does not affect the chemical makeup of ethanol, but rather creates an undrinkable solution.\nIs denatured alcohol safe on skin?\nIn small amounts, denatured alcohol is usually no problem in cosmetics unless it’s mixed with methanol, which can seep in through the skin. However, while denatured alcohol isn’t toxic at the levels needed for cosmetics, it can cause excessive dryness and disturb the natural barrier on your skin.\nIs denatured alcohol safe for disinfecting?\nHowever, please keep in mind that while denatured alcohol is safe to use on surfaces, it is not safe to use on skin. You absolutely should not use it to make homemade hand sanitizer, or to disinfect skin or wounds.\nWhat is an alternative to acetone?\nAcraStrip 600 Auto is a direct replacement for Acetone applications. It is a ready-to-use, non-hazardous, eco-friendly cleaner that was specially formulated to replace acetone, methyl ethyl ketone, toluene, MIBK, paint thinners, and other petroleum-based products.","Isopropyl alcohol (also isopropanol, iso, isopro, rubbing alcohol, or the abbreviation IPA) is a common name for propan-2-ol, a colorless, flammable chemical compound with a strong odor. It has the molecular formula C3H8O and is the simplest example of a secondary alcohol, where the alcohol carbon is attached to two other carbons. It is an isomer of propanol.\nIsopropyl alcohol is produced by combining water and propene. There are two processes for achieving this: indirect hydration via the sulfuric acid process and direct hydration. The former process, which can use low quality propylene, predominates in the USA while the latter process, which requires high-purity propylene, is more commonly used in Europe. These processes give predominantly isopropyl alcohol rather than propan-1-ol because the addition of water or sulfuric acid to propylene follows Markovnikov's rule.\nThe indirect process reacts propylene with sulfuric acid to form a mixture of sulfate esters. Subsequent hydrolysis of these esters produces isopropyl alcohol. Direct hydration reacts propylene and water, either in gas or liquid phases, at high pressures in the presence of solid or supported acidic catalysts. Both processes require that the isopropyl alcohol be separated from water and other by-products by distillation. Isopropyl alcohol and water form an azeotrope and simple distillation gives a material which is 87.9% by weight isopropyl alcohol and 12.1% by weight water. Pure (anhydrous) isopropyl alcohol is made by azeotropic distillation of the \"wet\" isopropyl alcohol using either diisopropyl ether or cyclohexane as azeotroping agents.\nAs a preservative (for biological specimens) isopropyl alcohol provides a cost-effective (when compared to pure ethanol) and comparatively non-toxic solution to formaldehyde and other synthetic preservatives. When used for the preservation of specimens in solution concentrations of 90-99% are optimal, though concentrations as low as 70% can be used in emergencies.\nIsopropanol is a major ingredient in \"dry-gas\" fuel additive. In significant quantities, water is a problem in fuel tanks as it separates from the gasoline and can freeze in the supply lines at cold temperatures. The isopropanol does not remove the water from the gasoline; rather, the isopropanol solubilizes the water in the gasoline. Once soluble, the water does not pose the same risk as insoluble water as it will no longer accumulate in the supply lines and freeze. Isopropanol is often sold in aerosol cans as a windscreen de-icer.\nIt can also be used to remove stains from any fabric, wood, cotton, etc.\nBeing a secondary alcohol, isopropanol can be oxidized to the ketone acetone. This can be achieved using oxidizing agents such as chromic acid, or by dehydrogenation of isopropanol over a heated copper catalyst:\nLike most alcohols, isopropyl alcohol reacts with active metals such as potassium to form alkoxides which can be called isopropoxides. The reaction with aluminium (initiated by a trace of mercury) is used to prepare the catalyst aluminium isopropoxide.\nLike many organic solvents, long term application to the skin can cause defatting.\nIsopropyl alcohol is about twice as toxic as ethanol, though isopropyl alcohol does not cause an anion gap acidosis as do ethanol and methanol. It produces an elevated osmolal gap, but generally no abnormal anion gap (though this may be seen as a result of hypotension and lactic acidosis). Overdoses may cause a fruity odor on the breath as a result of its metabolism to give acetone which is not further metabolized. Isopropyl alcohol is more potent than ethanol as a CNS depressant, and its metabolite, acetone, is a CNS depressant in its own right. While around 15 g of isopropanol can be fatal if left untreated, it is not nearly as toxic as methanol or ethylene glycol.\nAgency Reviews Patent Application Approval Request for \"Highly Productive Isopropyl Alcohol-Producing Bacterium\"\nJan 23, 2013; By a News Reporter-Staff News Editor at Biotech Week -- Mitsui Chemicals Inc. has been issued patent application serial number...\nWIPO PUBLISHES PATENT OF MITSUI CHEMICALS FOR \"ISOPROPYL ALCOHOL-PRODUCING BACTERIUM HAVING IMPROVED PRODUCTIVITY BY GNTR DESTRUCTION\" (JAPANESE INVENTORS)\nFeb 18, 2012; GENEVA, Feb. 18 -- Publication No. WO/2012/020833 was published on Feb. 16. Title of the invention: \"ISOPROPYL ALCOHOL-PRODUCING...\nAgency Reviews Patent Application Approval Request for \"Isopropyl Alcohol-Producing Bacterium and Method for Producing Isopropyl Alcohol\"\nOct 10, 2012; By a News Reporter-Staff News Editor at Biotech Week -- Mitsui Chemicals, Inc. has been issued patent application serial number..."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:79215f3f-ae0d-42b2-884b-e4ddec196567>","<urn:uuid:23fbf445-3de5-476a-ab95-db059a20b8f5>"],"error":null}
{"question":"How do feeding strategies differ between trumpetfish and plankton-feeding coral reef fish?","answer":"Trumpetfish and plankton-feeding coral reef fish have distinctly different feeding strategies. Trumpetfish are ambush predators that hunt small fish and crustaceans during daylight hours, using camouflage and stalking techniques. They strike quickly by curving their body into an S-shape and lunging at prey, often hiding among vertical structures or using other fish as cover. In contrast, plankton-feeding reef fish like soldierfishes, bigeyes, and cardinals have adaptations for catching tiny suspended particles - they have small mouths without strong teeth but with rapidly protruding jaws that create suction to catch plankton. These planktivores typically gather in large groups for safety while feeding and have streamlined bodies with forked tails for enhanced swimming ability.","context":["Powder-blue surgeonfishes Acanthurus leucosternon graze algae on the reef. (Image: Linda Pitkin)\nSome coral fishes prey on other animals; others are omnivores or herbivores. To the casual observer, plants do not appear to be much in evidence on a coral reef, but they are there in abundance as fine growth of algae or seaweed on dead corals and rock surfaces, especially in the shallows. Parrotfishes, surgeonfishes and some damselfishes graze the algae, contributing to the diversity of a coral reef by clearing new surfaces that can be used by a wide range of colonizing animals.\nCoral reefs attract large predatory fishes, such as sharks and barracudas, but the numerous smaller predators are equally or even more significant. Nearly 1,000 goby species can be found on coral reefs, catching mainly shrimps, worms and other tiny bottom-living animals, while the water above the coral teems with damselfishes that eat the zooplankton suspended there. Almost all reef organisms--the coral itself and the many different invertebrate animals and fishes that the reef supports--are potential food for one or other coral fish species. Small coral fishes are preyed on by larger fishes and also by certain other reef inhabitants, among them cone shells (venomous molluscs), mantis shrimps and some starfishes.\nThe scalloped hammerhead shark Sphyrna lewini is an open-water species seen occasionally around reefs. It is not usually aggressive, but certain other hammerheads can be dangerous. (Image: Linda Pitkin)\nMany fishes are able to feed during the day because their food--corals, seaweeds and various animals attached to the reef--is available out in the open at all times. The major coral-feeding fishes are certain butterflyfishes, but parrotfishes and other herbivores may have a major impact on the underlying corals by cropping algae. Sponges and sea squirts are eaten, particularly by the larger angelfishes, but hydroids (animals with a fern-like appearance) are usually avoided because they have stinging cells. The omnivorous scrawled filefish Aluterus scriptus--a circumtropical species--does, however, include hydroids in its diet. Fishes that feed on more active animals often wait until dusk or later, in order to pick off fishes as they scramble for night shelter or to catch crabs, octopuses and other invertebrates emerging from their holes in the reef.\nMany of the larger fishes on or around coral reefs are hunters, either of other fishes or of active invertebrates such as squid, cuttlefish, octopuses and crabs. Some hunt at night, but much of the predation on fishes takes place at dusk and dawn when smaller fishes are moving to or from their refuges and are particularly vulnerable. Strategies vary: morays and groupers remain near their places of shelter on the reef bed and capture prey that passes, while sharks and jacks chase after their victims at high speed.\nPlankton, suspended in the water above coral reefs, is an important source of nutrients and various coral fish, particularly soldierfishes, bigeyes and cardinals, specialize in using it. They are not related to each other, but many of them have similar features that relate to their lifestyle. Daytime plankton-feeders are vulnerable, especially those that swim high up in the water column where they are obvious to predators and exposed to currents, and they need to be strong swimmers.\nGlasseyes Heteropriacanthus cruentatus are members of the bigeye family, which commonly feed on plankton at night. (Image: Linda Pitkin)\nTypically, their small bodies are streamlined and their tails are forked to enhance propulsion. The fishes tend to gather in large numbers for safety while feeding, and all dart for shelter if a cruising predator approaches. Catching tiny, fragile plankton requires other adaptations: a small mouth without strongly developed teeth, but with jaws capable of rapid and extensive protrusion to snatch the small morsels drifting by. In some cases the action of extending the jaws creates a suction force, drawing water and particles in.\nFishes adapted for plankton-feeding may look very different to typical members of their family. This is particularly noticeable when the norm for the family is a large build, as in groupers and snappers, but less apparent when the build is generally small, as in damselfishes. Many damselfishes, particularly the numerous pullers of the genus Chromis, are planktivores. Others include basslets (the subfamily Anthiinae of the grouper and seabass family), fusiliers (related to snappers and sometimes included in that family) and certain wrasses.","Atlantic Trumpetfish Aulostomus maculatus\nSpecies ID: A.AM\nDescription: A long slender fish with small fins at the rear of the body and a thickelongated snout with a pointed barbel on the lower jaw. These fish can change colour at will, although three basic colour schemes exist: reddish brown, gray with a blue snout, and yellow. Common markings include pale horizontal stripes and dark speckles. Sexes appear similar and juveniles resemble adults\nMaximum Size: 1 m (3 ft)\nStatus: Not currently on the IUCN endangered species list\nAtlantic Trumpetfish & People: May be consumed locally, but not important in commercial fisheries or the aquarium trade\nGeographical Range: Found throughout the Caribbean, but is more common in the Lesser Antilles (south-east Caribbean)\nCoral Reef Zone: Found in the back reef and fore reef zones\nFavourite Habitat: Trumpetfish prefer habitats with vertical structures, such as gorgonian corals, in which they can camouflage themselves\nDepth: 2-25m (6–82ft)\nA Day in the Life\nDawn: Found stalking prey on the reef, when the low light augments its natural camouflage and increases hunting success\nDay: Stalking prey by mimicking vertical structures like sponges and soft corals\nDusk: Stalking prey, and may also move into the deeper fore reef zone to spawn\nNight: Found hiding under ledges, or camouflaged next to vertical structures\nWho Eats Who?\nTrumpetfish are predators, and consume many small reef creatures, such as shrimps, chromis, wrasses, juvenile grunts and soldierfish. Trumpetfish themselves are vulnerable to a variety of large reef predators like grouper, snapper, jacks, and sharks.\nScuba Diver & Snorkeler Best Practices\nRefrain from feeding marine life. Coral reef organisms should never be fed. Although this may seem like a harmless practice that allows you to get close to your favourite organisms, it actually disturbs normal feeding patterns and diets. Scientists have documented turtles being fed bread, dog food and even cheese—none of these foods are found naturally in the marine environment, and they can cause untold stress to the organisms that consume them. Conditioning wild animals to become comfortable with hand-feeding by humans alters their behaviour and makes them more vulnerable to capture, which directly affect their survival—this is particularly a concern for endangered sea turtles.\nTrumpetfish remain still if they believe they are well camouflaged, but are wary and often move away when snorkelers or divers come too close. A slow, indirect approach is recommended.\nTrumpetfish are carnivores specialized in the capture of small fishes and, occasionally, small crustaceans. They are generally passive ambush predators which hunt during daylight hours from the concealment of soft corals or from under coral ledges. They lie in wait until the opportunity arises for a lightning-fast strike, curving the rear half of their body into an S shape and rapidly straightening, resulting in a rapid lunge towards the target.\nThese fish are also known to stalk prey in partnership with other reef fish, using them as moving cover to hide their approach from prey. Interestingly, the Pacific cousins of trumpetfish and cornetfish are natural predators of juvenile red lionfish. The red lionfish is a ravenous carnivore that has recently been introduced into the Caribbean, where populations are growing unchecked in the absence of experienced natural predators. With time, Caribbean trumpetfish and cornetfish may also learn to consume this invasive species and help control their numbers.\nObserve, record & share:\nO A.AM-101 – Stalking: Stalking and striking at prey in the open\nO A.AM-102 – Ambush: Striking at unsuspecting prey from a concealed position\nO A.AM-103 – Shadow-feeding: Stalking while hiding alongside other reef fish and using them as a mobile cover, thus improving their chances of approaching prey undetected\nO A.AM-104 – S-shape: Trumpetfish curve the body into an S-shape before striking at prey\nAttack & Defense Behaviour\nTrumpetfish do not defend territories and their main defensive concern is avoiding predators. They are poor long-distance swimmers and rely mainly on a quick escape to nearby cover where they can use their excellent camouflage skills to hide from large predators like snappers and groupers. Trumpetfish can camouflage themselves using their thin, elongated shape to blend into vertical reef features like sea whips, sea plumes, and other gorgonians. They can also change colours rapidly to blend away into the background and avoid being seen.\nObserve, record & share:\nO A.AM-201 – Shape camouflage: When they feel threatened, trumpetfish often imitate gorgonian branches or sponges by floating vertically and swaying with them in the current\nO A.AM-202 – Colour camouflage: Trumpetfish can change colour to blend into a new background\nAlthough spawning has never been scientifically documented in this species, eye-witness accounts suggest that this species practices pelagic broadcast spawning, where males and females rush to the sea surface to release their eggs and sperm, which disperse into the open ocean. Courtship sessions may be interrupted as several males fight over the right to spawn with ripe females, which appear swollen with eggs. Just before spawning, males darken their colour, swim alongside the female, and may hover vertically along with their chosen partner. There is no evidence of sex change in this species. Spawning occurs year-round in the hours just before sunset, although reproductive activity peaks in the winter months from November to January.\nObserve, record & share:\nO A.AM-301 – Ripe female: Females full of eggs, and ready to spawn, have swollen bellies\nO A.AM-302 – Male competition: Ripe females are often chased by multiple males, who may fight with each other for exclusive spawning rights\nO A.AM-303 – Courtship: Just before spawning, males deepen their colour, and swim alongside or hover vertically with their chosen female\nO A.AM-304 – Spawning rush: Following ripe females at a distance may increase the chances of witnessing spawning, during which males rise with females high above the reef where eggs and sperm are released simultaneously\nShadow-feeding: Trumpetfish prefer to shadow other reef fish species (often herbivorous species) the same colour as themselves, thereby increasing the effectiveness of their camouflage. Thus, yellow individuals prefer to shadow other yellow fish such as Spanish hogfish; reddish brown individuals prefer to shadow grouper and darker parrotfish; and dull grey individuals with blue snouts prefer to blend in with schools of blue fish such as blue tang,blue chromis, and creole wrasse, where their snouts are mistaken for a member of the school Occasionally, trumpetfish may even attempt to shadow a diver!\nDid You Know?\n• Eels, snapper, and grouper are all predators of trumpetfish, and some of the shorterbodied predators often succeed in consuming trumpetfish longer than they are by folding this awkward prey over in their stomachs\n• The fantastic range of yellow, brown and red colour patterns that trumpetfish use for camouflage is produced by controlling the concentration of pigments in specialized cells called chromatophores. In contrast, blue colours are achieved by small shiny particles that reflect blue light, rather than by pigments. Cells producing these shiny particles are called iridiophores after the iridescent colour they produce.\nWhat to do?\nShare your observations today!: Discover your species of interest, observe its behaviour, and share your pictures and videos with friends and coral reef enthusiasts around the world! Upload media to the web, tagged with species common name (ex.: trumpetfish) and species ID code (ex.: A.AM) or species behaviour code (ex.: A.AM-101)\n- Order Aulostomatidae\n- Length 1 m (3 ft)\n- Weight Not recorded\n- Depth 2-25 m (6–82 ft)\n- Habitat Found in fore and back reef zones\n- Distribution Found throughout the Caribbean"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"sensitive"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:51cd121f-f44d-46c8-9a4e-6a2733a5214d>","<urn:uuid:523a2dfd-694c-4c4f-a55c-d135abf5c2fb>"],"error":null}
{"question":"As a pediatric nurse, I need to know: what are the main diagnostic methods for congenital heart defects during pregnancy and after birth?","answer":"During pregnancy, doctors can perform a fetal echo between 18-22 weeks of pregnancy, which uses sound waves to create a picture of the baby's heart while still in the womb. After birth, several tests can be used for diagnosis: 1) Chest X-rays to show heart enlargement and blood/fluid in lungs, 2) EKG (electrocardiogram) to check heart's electrical activity and chamber enlargement, 3) Cardiac catheterization to monitor blood flow and measure pressure/oxygen levels in heart chambers, and 4) Echocardiogram, a special ultrasound that takes pictures of the heart. These tests are typically performed by a pediatric cardiologist.","context":["Amidst the amendment in Indian abortion law getting delayed to permit abortion beyond 20-weeks, the Supreme Court came to the rescue of yet another pregnant woman and allowed her to abort her 26-week foetus suffering from severe cardiac problem.\nA bench of justices Dipak Misra and A M Khanwilkar permitted the abortion plea of Kolkata-based 33-year old lady on the basis of her medical report. The report said that the child, even if born alive, may not survive for a long time as the baby would have to go through multiple surgery due to congenital disorder.\nWhat are congenital heart defects?\nHeart defects that develop in the womb before the baby is born are called congenital heart defects. These defects can involve:\n- The valves inside the heart\n- The interior walls of the heart\n- The arteries and veins that carry blood to the heart or out to the body\nThese defects change the normal flow of blood through the heart.\nThere are many types of congenital heart defects. They range from simple defects with no symptoms to complex defects with severe, life-threatening symptoms.\nCongenital heart defects are the most common type of birth defect. They affect 8 of every 1,000 newborns. Many of these defects can be simple conditions and can be easily fixed or need no treatment. Whereas, babies born with complex congenital heart defects require special medical care soon after birth.\nMost people with complex heart defects will need special heart care throughout their lives.\nWhat causes congenital heart defects?\nIt is not necessary that a baby suffers congenital heart defect because the mother did not take care of herself during the pregnancy. Most of the time doctors do not the reason behind congenital heart defects. Kids with genetic disorders like Down syndrome, often have congenital heart defects. In fact, half of babies with Down syndrome have congenital heart defects.\nHeredity might play a role in some heart defects. In some cases, smoking during pregnancy has also been linked to several congenital heart defects, including septal defects. Scientist are working on reasons behind congenital heart defects.\nHow are congenital heart defects diagnosed?\nDuring pregnancy, if the doctor doubts that the baby has a congenital heart defect, a foetal echo can be done. This test uses sound waves to create a picture of your baby’s heart while the baby is still in the womb.\nThe foetal echo is usually done about 18 to 22 weeks of pregnancy. If a baby is diagnosed with a congenital heart defect before birth, the doctor can plan treatment before the baby is born.\n2. Chest X-ray\nA chest X-ray is a painless test that creates images of the structures in the chest, such as the heart and lungs. Chest X-ray can reflect the heart enlargement if any or extra blood flow or fluid in the lungs which can be a sign of heart failure.\n3. EKG (electrocardiogram)\nAn electrocardiogram is painless test that checks the heart’s electrical activity. It identifies if one of the heart’s chambers is enlarged, which can help diagnose a heart problem.\n4. Cardiac catheterization\nDuring cardiac catheterization, a thin, flexible tube called a catheter is inserted into a vein in the arm, neck or groin (upper thigh) and threaded to the heart.\nSpecial dye is injected through the catheter into a blood vessel or a chamber of the heart. The dye lets the doctor monitor the flow of blood through the heart and blood vessels on an X-ray image.\nCardiac catheterization can also be used by the doctor to measure the pressure and oxygen level inside the heart chambers and blood vessels. This can help the doctor know whether blood is mixing between the two sides of the heart.\n5. Pulse oximetry\nPulse oximetry shows how much oxygen is in the blood.\nThe research to determine the exact causes behind congenital heart defects is still on and doctors believe it would be some years before we can finally understand them completely.","Frequently Asked Questions\nWhat is the most common birth defect? Congenital Heart Defects are the most common birth defect in America, affecting approximately 1 in 100 or 40,000 newborns each year. Source: Children’s Heart Foundation\nWhat is a congenital heart defect? A congenital heart defect is a malformation of the heart or the arteries/large blood vessels near the heart. Structural problems with the heart present at birth can result when a mishap occurs during heart development soon after conception and often before the mother is aware that she is pregnant. Source: American Heart Association\nWhat prenatal test can detect CHD’s? An echocardiogram can accurately detect many heart defects. This test needs to be performed by a specialized doctor and not an obstetrician. Some heart defects can be detected through routine ultrasound. Source: Little Hearts\nWhat tests are used to diagnose heart defects after birth? Babies and children who are suspected of having a heart defect are usually referred to a pediatric cardiologist. Test that can be performed: Chest X-ray Electrocardiogram - a test that records heart rate patterns Echocardiogram – a special form of ultrasound that uses sound waves to take pictures of the heart Cardiac Catheterization - a thin, flexible tube inserted into the heart to examine for defects, pumping ability, measure blood pressure within the heart and oxygen in the blood. Source: March of Dimes\nHow many known congenital heart defects are there? There are 35 known distinct heart defects. Source: March of Dimes\nWhat causes CHD? In most cases, scientists do not know what makes a baby's heart develop abnormally, however genetics and environmental factors are identified: Genetics can play a role, such as atrial septal defect (a hole between the upper chambers of the heart) Environmental sources, such as mother contracting a viral infection during first months of pregnancy. Certain medications increase risks: some acne and seizure medications. Source: March of Dimes\nHow serious is the problem? It is a lifetime affliction, requiring lifelong medical care.\nHow are congenital heart defects treated? Most heart defects can be corrected or helped with surgery, medicine, or devices, such as artificial valves and pacemakers. Source: Little Hearts\nWhat is the overall mortality rate of CHD patients? CHDs are responsible for one third of all birth defect-related deaths and sadly 20 percent of children who make it through birth will not survive past their first birthday. Source: Childrens Heart Foundation\nHow well can people with congenital heart defects function? Virtually all children with simple defects survive into adulthood. Although exercise capacity may be limited, most people lead normal or nearly normal lives. Some children with congenital heart disease have developmental delay or other learning difficulties. Source: American Heart Association\nFor every dollar provided by the national medical funding arm of the American government, the National Institute of Health, only one penny is provided for pediatric research, and only a portion of that penny goes to support research on heart defects, the most common birth defect. Source: Children's Heart Foundation\nFebruary 7 – 14th is Congenital Heart Defects Awareness Week, as organized through tchin.org (The Children’s Heart Information Network). An international coalition of families, individuals, non-profit organizations, support groups, and health professionals participate in a campaign to increase public awareness of Congenital Heart Defects and Childhood Heart Disease. To find out how you can participate in the awareness campaign, log on to www.tchin.org/aware. Only by speaking out can we be heard and make a difference!\nParticipation in competitive athletics is a rewarding experience and is an important part of normal adolescent development. However, for some children competitive sports have the potential to end tragically. - Corrada et al (NEJM 1998) reported the incidence of sudden death in adolescents and young adults (12-35yrs.) is 2.3/100,000 athletes/yr. (2.52 in males and 1.07 in females). - Maron (NEJM 2003) estimate the prevalence at ≤0.3%.\nThe Center for Disease Control and Prevention (CDC) recommends the flu vaccine for children who are at increased risk of complications from influenza, including: Children between the ages of 6 months and 5 years & children who have a chronic medical condition, such as asthma, cardiovascular disease, diabetes, sickle cell anemia, HIV/AIDS or kidney disease."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:2a3aa52b-5285-451e-b473-eef097165eaf>","<urn:uuid:16014e31-3b2f-4beb-8ca4-eea3367ba680>"],"error":null}
{"question":"In evaluating cyber insurance options, I'd like to understand: what is the difference between traditional endpoint security approaches and modern ransomware protection strategies?","answer":"Traditional endpoint security relies primarily on signature-based detection but has become insufficient as malware grows more sophisticated and evasive. Modern protection strategies require a multi-layered approach that includes breaking the attack chain, secure data backups, and comprehensive endpoint protection. Risk management now requires coordinated efforts between IT and operations technology teams, breaking down organizational silos, and treating cyber as an enterprise-level risk. Organizations need secure offline backups that cannot be hacked, and must prepare through employee training, particularly around phishing awareness. Additionally, modern strategies often involve working with outside firms to vet security protocols and implementing solutions that can restore systems to previous states, like creating undetectable data overlays to preserve original files.","context":["Threat in the making: Ransomware hits industrial control systems\nRisk managers play critical role in protecting production\nSkyrocketing growth in connected devices and organizations’ increasing exposure to malware attacks are troubling trends, but not new. However, an emerging cyber risk area, which should greatly concern risk professionals, is the growing threat to their industrial control systems.\nDevelopments in manufacturing and industrial systems intended to improve efficiency are a double-edged sword. On one side, more connections between information technology networks and operations technology systems make monitoring and control of production processes easier. On the other, such connectivity is raising the risk of malware infecting the operations on which industrial organizations’ revenue and profitability depend.\nA decade ago, production networks were obscure systems few understood. As these systems have become more mainstream, the number of specialists has risen. Just as operations tech skill sets have grown, so too have the skills of hackers to penetrate them. Security through obscurity is no longer sufficient, and organizational silos perpetuate risks.\nCyber criminals continue to deploy malware such as ransomware because it’s profitable. For example, the more valuable an asset they can disrupt, the higher the ransom attackers can demand, making it more attractive as a target. For manufacturers, after their people and intellectual property, among their most important assets are production equipment and processes that generate revenue and protect an organization’s value.\nThe nature of malware attacks is evolving, which requires risk professionals to keep up with changing exposures and mitigation strategies. For example, in 2017 the NotPetya attack changed how the world viewed ransomware risk. According to news reports, NotPetya infected tens of thousands of computers around the world, with costs for affected organizations totaling billions of dollars. It was a broad, indiscriminate attack that not only shut down operations but also destroyed data in many industries. Recent types of attacks, however, are more targeted, and many of them aim at high-value core systems, such as those that control or are critical to the continuity of manufacturing and production.\nA role for risk managers\nCyber risks to production cannot remain the sole responsibility of technology professionals. Such risks are enterprise-level and call for coordinated risk management. Typically, the best person to lead this effort is a risk management professional, who can bring together business leaders and senior management. It is a compelling opportunity for risk managers to show their value to their organizations by also becoming more proficient about their organization’s operational technology.\nFrom there, risk professionals can take several steps to help their organizations mitigate the impact of malware, including ransomware, and improve resilience. These include:\n- Break down technology silos. Many organizations have a functional and cultural gap between IT staff and those working on production networks, and they often exist in silos. Often these groups speak different languages and are driven by different departmental objectives. Organizations should break down these silos and unify their technology teams. Cyber risk management calls for a holistic approach, and risk professionals should closely collaborate with chief information security officers. Risk managers should be aware of their accountability as a risk steward and fear complacency on cyber risk more than they fear the difficulty of understanding technical processes.\n- Prioritize cyber as an enterprise risk. A good place to start with an enterprise risk management approach that includes cyber is to look at who is invited to the table for ERM meetings. Are the IT and operations technology sides represented? Cyber is like any other risk in terms of impact from disruption; a fire that could burn down a production facility is an enterprise risk that would disrupt the entire organization. Similarly, malware that encrypts or manipulates control systems poses an enormous threat to property and key assets.\n- Insist on secure backups. A time-honored and proven technique in property risk management is redundancy. In a technology context, data backups serve as redundant resources, but not all backups are created equal. Having secure backups offline that cannot be hacked is critical, and it provides a completely different option when a company is attacked. Led by risk professionals, the right backup strategy can ensure resilience ahead of time, letting organizations focus on rapid recovery instead of the difficult decision to rebuild their systems from scratch or pay a ransom demand to regain access to critical systems.\n- Prepare the organization for attacks. Resilience in the face of emerging risks takes a mindset of preparation. Risk professionals should communicate that malware risk in industrial control systems is real, and it often begins with phishing emails. Layering defenses and balancing security with business enablement are critical steps. While cyber-attacks are inevitable, cyber losses are preventable if risk managers collaborate with their organizations’ technology leaders.\nBringing all the pieces together to mitigate the risk of malware is vital. Otherwise, organizations will never manage cyber risk effectively. The convergence of systems and cyber risks means that risk management and cybersecurity also must converge. System convergence and remote monitoring were occurring even before the coronavirus pandemic, and that will certainly continue. In the future, the security of production\nFM Global #DIA","Financial Costs of a Ransomware Attack and Breaking the Attack Chain Ransomware is a type of malware that typically utilizes encryption to impede or restrict admittance to information until a payoff is paid.\nFor organizations that experience the ill effects of a ransomware attack, the blow-back to income is in many cases more terrible than the size of the payoff and regardless of whether to pay it. The monetary harm can be far reaching and go a long ways past how much the payment.\nThe Financial Costs of a Ransomware attack can be huge. In addition to the ransom, businesses lose business due to downtime. These losses can quickly compound and spiral out of control. For example, one ransomware attack affected Maersk and left the company unable to operate for weeks. The company estimates that the downtime cost them $300 million.\nSpecialists suggest that organizations don’t pay ransoms as it gives cybercriminals a thought process to proceed. Organizations that really do wind up paying the payoff are frequently disheartened with the outcomes.\n- The information they recuperate is harmed.\n- The aggressors request more cash.\n- The aggressors disappear, and they don’t recuperate their information.\nLate investigations by Sophos and Pao Alto put the normal ransomware attack costs at somewhere in the range of $570,000 and $812,360.\nAs cybercriminals now utilize hilter kilter encryption strategies, having the option to unscramble the information is profoundly impossible. If you would rather not pay the payment, you will either need to recuperate the information from reproductions or reinforcements or lose it through and through.\nAt the point when you experience a ransomware attack, it is smarter to pick up and move on and follow your occurrence reaction plan. In the event that you have a viable recuperation plan set up, you might have the option to recuperate your information with negligible disturbance, and you won’t have to pay the payment. A recuperation plan typically includes five stages: survey, moderate, answer, convey, and hindsight.\nCounteraction is in every case better compared to attempting to manage the broad harm a ransomware attack can cause. Figure out more about how to diminish the gamble of turning into a ransomware casualty in any case at Discernment Point.\nCyber Insurance Academy\nThe cyber insurance industry is in a state of flux as more organizations are exposed to ransomware attacks. These attacks see hackers infect an organization’s computer network and demand money in return for control. These attacks have resulted in a massive increase in ransom payments, increasing by three-fourths to $412 million by 2020. In response, the cyber insurance industry has started an educational program to prepare students for such attacks.\nCyber insurance could take a cue from other forms of insurance. One professor at King’s College London studied the phenomenon of kidnap for ransom insurance and discovered that the insurance company’s “disruptive bargaining” strategy helped reduce kidnap gangs’ demands.\nWhile ransomware is becoming increasingly widespread, some insurers are beginning to reconsider their policy and stop covering ransom payments. For example, AXA, which insures several large French companies, has decided to stop covering payments to ransomware attackers for future policyholders. This move has come in response to government pressure.\nGovernments are eager to provide adequate cyber insurance coverage but don’t want insurers’ solvency to suffer. The failure in either direction could lead to a financial burden on governments. Cyber insurance companies are increasingly working with outside firms to vet their insureds’ security protocols and procedures.\nBy restoring your computer and all of its data with NeuShield, you can stop ransomware attacks from destroying your information. Ransomware typically attempts to encrypt and wipe a disk, but NeuShield protects your data by restoring it to the original state. It does this by creating an undetectable overlay over your data. The attacker only has access to the data that is in the overlay – all of your original files are preserved. Moreover, NeuShield can be restored to a previous state, allowing you to regain access to your information quickly and easily.\nAnother key aspect of defending your computer is breaking the attack chain. By understanding the structure of cyber attacks, you can identify and block them before they start. The attack chain is also known as the kill chain, and it is originally a military concept. It describes the methods of malware infiltration, deployment, and execution. Basically, breaking the attack chain means to prevent the attacks before they begin, but it is not as easy as it sounds. Whether you are a small or large business, the idea of breaking the attack chain is important and a vital part of cyber security.\nCybercrime has continued to evolve rapidly, and the scope of its attacks increases. As a result, future attacks will be much harder to detect and respond to. This arms race between attackers and defenders is becoming more apparent. In many ways, this is why cyber insurance premiums have skyrocketed.\nWhile traditional endpoint security can prevent the majority of cyberattacks, it may not be enough. Malware has become so sophisticated and evasive that traditional signature-based endpoint security cannot keep up. As a result, organizations need to employ a multi-layered endpoint protection strategy to combat the latest threats. By deploying a multi-layered endpoint security strategy, you can stop threats across multiple attack chains.\nAn innovative multistakeholder approach can effectively disrupt the financial capabilities of malicious actors and help reduce the global impact of ransomware attacks. Such an approach would leverage information-sharing and pooled resources to assess the costs and organizational vulnerabilities of ransomware.\nRansomware is a highly disruptive and costly cyberattack that can lead to crippling downtime and substantial productivity losses. The costs of downtime and recovery are enormous – some estimates estimate that they are 50 times higher than the ransom demands. The downtime from a ransomware attack can affect a business for months and may cause it to file for bankruptcy.\nThe recovery process from a ransomware attack is complicated and requires all hands on deck. Depending on the size and scope of the attack, it may involve internal teams, incident response companies, forensic experts, and even the assistance of local and federal law enforcement agencies. Each step in the recovery process carries its own set of costs. Some companies may choose to pay the ransom instead of dealing with the recovery process, avoiding the financial consequences of losing customer data.\nThe impact of ransomware attacks is becoming increasingly widespread and complex. As a result, CISOs are losing confidence in the ability to mitigate ransomware attacks. Moreover, 73 percent of respondents said that failure to mitigate the risk of cyberattacks could expose organizations to fines and legal action. Cybersecurity Ventures estimates that ransomware attacks will cost $265 billion by 2031, which makes it crucial for organizations to prepare for the costs of these attacks.\nRansomware supply chains have become more sophisticated. As a result, cybercriminals are now targeting companies with extensive digital networks. This means that ransomware supply chain attacks will become more prevalent in the future. The SolarWinds ransomware attack, for example, should serve as a warning to all companies with global supply chains. This attack affected 18,000 corporate customers, including Fortune 500 companies and U.S. government agencies.\nIn January 2022, the BlackCat ransomware group infected 233 gas stations in Germany and forced the oil company Shell to reroute supplies. The attack used two vulnerabilities in two different software applications to encrypt data and exfiltrate intellectual property. The resulting disruptions rendered more than half of the organization’s systems inoperable for 48 hours, forcing Shell to hire security experts to restore access to their systems. The attack was so widespread that German intelligence services feared that the attackers had penetrated the networks of gas stations and oil companies to steal information. In Baltimore, the ransomware attack affected the city’s official email servers and rendered critical systems inaccessible.\nMany small and medium-sized companies have limited resources to protect themselves from ransomware. Security is costly and time consuming, so they often put off investing in it in favor of other critical business requirements. Unfortunately, the longer they wait to secure their networks, the more expensive it will be to repair the damage. This negative feedback loop has left many organizations unprepared for attacks and paved the way for predatory ransomware groups.\nThe costs of ransomware attacks can be staggering. In the United States, companies face billions of dollars in ransomware losses every year. As a result, ransomware has become a top concern for businesses, affecting both organizations and consumers. In addition to the financial burden of downtime, ransomware can damage a company’s reputation, and cause customers to lose trust in it.\nThe cost of ransomware attacks is escalating – a single attack can cost up to $265 million. Those figures are staggering, and many companies that have been affected go out of business within a year of being infected. Fortunately, there are ways to mitigate the risk of a ransomware attack.\nThe financial costs of a ransomware attack can be staggering. The Cybersecurity Ventures report predicted that ransomware attacks would cost more than $5 billion in 2017, up from $325 million in 2015. This represents a 15X increase in just two years, with a projected total of $8 billion in 2018 and $11.5 billion in 2019. By 2021, ransomware attacks are expected to cost $20 billion, and every 11 seconds, an average business will be hit by ransomware.\nIn addition to the financial cost, ransomware attacks can also have a huge impact on an organization’s business. For example, an attack on the Colonial Pipeline Company caused a panic buying of fuel on the East Coast because a compromised password had given access to their IT system. The attack resulted in the shutdown of the company’s operational technology networks and IT systems for several days. Fortunately, the company was able to recover a significant portion of the $4.4 million ransom.\nIn addition to monetary costs, the recovery and downtime costs associated with a ransomware attack are also enormous. This is why it is essential to seek outside legal counsel when dealing with ransomware. A seasoned attorney will be able to guide you through the process and minimize your risk.\nTrend Micro has also recently discovered a new vulnerability impacting e-commerce websites. In April 2021, the company found that BIQS software was vulnerable to an XSS vulnerability, which could allow threat actors to inject malicious code on the servers. In August, the company also discovered that Atlassian Confluence servers were vulnerable to a local file inclusion vulnerability, allowing threat actors to insert arbitrary code on its servers.\nDowntime and labor costs\nWhile your frameworks are down, you will experience monetary misfortunes. Most associations require essentially a week and frequently significantly longer to recuperate information. Until it is reestablished, your entire situation is probably going to be disabled. Client information is essential to maintaining a business easily, and without it, you will fight to sell items, administration clients and substantially more. A regular efficiency misfortune can really depend on 20% during free time.\nIn a 2021 ransomware attack, the Kaseya assault, around 1,500 oversaw specialist organization clients were impacted. This shows how store network assaults cause more broad harm than assaults against single people.\nIT groups frequently need to stay at work past 40 hours to reestablish frameworks, and there is normally an overabundance of work all through an association because of an absence of admittance to information. Extra counseling or expert help might be expected to determine information issues.\nThe cost to brand reputation\nA harmed brand notoriety is difficult to fix, and this can have a broad monetary effect. Any bad exposure about an information break can influence the relationship with clients as well as with representatives, financial backers and different partners. Research from the Public Digital protection Coalition shows that around 60% of little to medium organizations leave business in no less than a half year of encountering an information break.\nThere’s a developing pattern for cybercriminals to take steps to uncover delicate information they exfiltrate before encryption. Where the information is strategic, for example, in medical clinics, government or crisis call focuses, this can really hurt.\nIn certain enterprises, clients can guarantee direct pay for an information break. Scripps Wellbeing, retail goliath Target, and gas organization Frontier Pipeline are only a portion of the organizations that have confronted legal claims.\nMost cases are privately addressed any remaining issues as organizations would rather not face extended court fights. Administrative and legitimate fines can be especially high for the spilling of individual wellbeing information, monetary data like charge card subtleties, and actually recognizable data.\nData loss and collateral damage\nYou might lose an information totally due to a ransomware attack. The deficiency of information might address many long stretches of work. Regardless of whether you can reestablish records from reinforcements, there’s an opportunity they were not supported totally or accurately. Today there are ransomware variations that likewise target reinforcement frameworks so you can’t reestablish information.\nYou should figure out how cybercriminals accessed your frameworks. There are numerous ways they can do as such, from conveying phishing messages and setting up counterfeit sites to straightforwardly going after programming weaknesses.\nContaminated machines might need to be totally reformatted, and programming reinstalled. You will likely need added assurance to ensure another information break doesn’t happen.\nIn the ongoing monetary circumstance with expansion and downturn, every one of the costs of a ransomware attack might cause a huge monetary misfortune. In 2020 different reports demonstrated that the normal expense of tidying up after a ransomware attack could depend on $1.85 million. In the event that you don’t tidy up your information and fix any fundamental issues, you could gamble with another assault.\nStep by step instructions to prevent ransomware attacks\n- Having security frameworks set up, representative preparation, and powerful design the executives are a portion of the ways of forestalling ransomware attacks.\n- Keeping awake to date with the most recent working software is vital.\n- Ensure you have total and exceptional reinforcements as they can assist you with recuperating information.\n- Stay up with the latest, and remember to apply security patches.\n- Persistently look at security to ensure you have the right estimates set up.\nIT experts need to adopt a protection strategy as once programmers get inside your association, limiting the damage can be hard. You want to safely safeguard each channel, with email frequently being quite possibly of the most weak one.\nCybercriminals keep on utilizing perpetually complex methods to convey ransomware by means of email. You want to search for cutting edge email security arrangements that utilization quick and successful unique filtering. Arrangements ought to likewise can identify dangers covered somewhere inside happy.\nRansomware can be monetarily harming to organizations in various ways, including pay-off costs, personal time costs, work costs, notoriety harm and legitimate expenses. Associations need to investigate their network protection safeguards. Distinguishing and managing likely dangers and channels, for example, email and cloud coordinated effort apparatuses, can assist with alleviating ransomware attacks.\n- Also Read: Price In India Emo Robot What Is The Cost?\n- Also Read: Kbm 25 Com Know The Latest Authentic Details!\n- Also Read: Is My Derma Dream Legit? Authentic Review!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:240165fe-fd73-4f94-8b3b-678bf08a2a75>","<urn:uuid:a4aad484-a3a3-4984-8feb-404e3a6bba70>"],"error":null}
{"question":"What is the key difference between maintaining oral health through water flossing versus traditional dental floss?","answer":"The key difference is that water flossing has been proven safe and effective through numerous clinical studies showing improvements in clinical attachment levels (CAL) and probing pocket depth (PPD), while traditional dental floss, according to recent controversy, lacks definitive evidence of medical benefits. However, both tools aim to remove bacterial plaque - the real underlying issue for oral health. Water flossers have demonstrated stability or improvements in periodontal health across multiple pressure settings, while dental floss's effectiveness may vary based on factors like diet and inherent resistance.","context":["Evaluation of the Safety of a Water Flosser on Gingival and Epithelial Tissue at Different Pressure Settings\nC. Ram Goyal, BDS; Jimmy G. Qaqish, BSc; Reinhard Schuller, MSc; and Deborah M. Lyle, RDH, BS, MS\nObjective: To determine the safety of the Waterpik® Water Flosser on multiple settings as measured by clinical attachment level (CAL) and probing pocket depth (PPD) over 6 weeks. Methods and Materials: 103 subjects completed this randomized, 6-week, single-masked, three-group, parallel clinical trial. Subjects were randomly assigned to one of three treatment groups: water flosser (WF) plus a manual toothbrush, manual toothbrushing and flossing (MTF), or manual toothbrushing alone (MT). All subjects received both written and verbal instructions and demonstrated proficiency with their assigned devices at baseline. Data were evaluated at 2 weeks, 4 weeks, and 6 weeks for CAL and PPD on six teeth (Ramfjord teeth) and outcomes reported for all teeth, anterior only, and posterior only. Paired t-test was used to detect changes within groups and one-way analysis of variance (ANOVA) was used to detect differences between the groups. Results: The WF group demonstrated an improvement in CAL and PPD that exceeded those seen in the MTF and MT groups. The MT group had diminished health as measured by increases in CAL and PPD. Conclusion:The Waterpik Water Flosser is safe to use and demonstrated stability or slight improvements in periodontal health as measured by CAL and PPD at multiple pressure settings.\nAlso known as a dental water jet or oral irrigator, the water flosser has been on the market since 1962. Research on the water flosser spans 50 years and has evaluated the efficacy and safety on clinical signs of inflammation and dental biofilm.1-20 Studies have also examined host modulation,7,8 impact on individuals with diabetes,7 implants,6,9 and orthodontics.4,10,11 Five clinical studies have been published that showed a water flosser was significantly more effective for improving oral health than dental floss.2-6More than 70 studies demonstrate a water flosser significantly reduces bleeding, gingival inflammation, dental biofilm, probing pocket depth (PPD), pro-inflammatory mediators, subgingival bacteria, and calculus accumulation.1-25\nThe studies primarily are randomized controlled trials that have been published in peer-reviewed journals providing information to help clinicians make evidence-based decisions on self-care recommendations. Despite the public's use of the water flosser for decades and the sound body of evidence from the clinical studies performed to date, there still remains skepticism by some dental professionals as to the device's safety and efficacy. Previous studies have measured the impact of pulsating water on tissue both clinically and microscopically.1-25 To date no adverse effects or events have been reported. Histological findings show a reduction in inflammation,21-23 stability of PPDs and clinical attachment levels (CALs) or an improvement in these measurements,7.8,13,17removal of subgingival bacteria,14,24,25 and improvement in morphological subgingival flora.24\nThis article presents a randomized, controlled, parallel clinical trial designed to evaluate CALs and PPDs over 6 weeks at different pressure settings on a water flosser. Manual toothbrushing and water flossing were compared to manual toothbrushing and dental floss use and to manual toothbrushing alone. The efficacy was measured through stability or changes in both CAL and PPD. This study was approved by the All Sum Research Institutional Review Board.\nMethods and Materials\nOne hundred and five healthy, nonsmoking adults were randomized into one of three groups using a 1:1:1 ratio. Subjects were included in this study if they were between the ages of 25 and 70, had scoreable Ramfjord teeth (Nos. 3, 9, 12, 19, 25, and 28 using the Universal dental numbering system) (Figure 1), and had no partial dentures, orthodontic brackets, wires, or other appliances. Subjects were nonsmokers in good general health and able to provide written informed consent. They agreed to participate in the study, return for the scheduled visits, follow study protocol, and abstain from using any nonstudy devices or oral care products (Table 1). Subjects were disqualified if they had PPDs >5 mm, advanced periodontitis, or visual caries, were taking medications that can influence gingival health, or used antibiotics within 6 months of the study.\nThis was a single-masked, parallel, three-group, 6-week clinical trial. Subjects were randomized into one of three groups of 35 subjects each. Group 1 (WF) received a water flosser (Waterpik® Water Flosser model 660W, Water Pik, Inc., waterpik.com) and an American Dental Association standard manual toothbrush (Oral-B® Indicator™ 35, Procter & Gamble, oralb.com). Group 2 (MTF) received the same ADA standard manual toothbrush and ADA standard dental floss (Reach® Mint flavored waxed dental floss, Johnson & Johnson Consumer, Inc., reachfloss.com), and Group 3 (MT) used the ADA standard manual toothbrush only.\nAll groups used the same dentifrice provided (Colgate® Cavity Protection, Colgate-Palmolive, colgate.com). Data were collected at baseline, 3 weeks, and 6 weeks. All groups received written and verbal instructions and a demonstration on the use of their assigned products. Subjects were required to demonstrate proper usage in their own mouth at the baseline visit. WF group received specific instructions and a calendar with the required pressure setting for each 2-week period (Table 2).\nOral examinations were completed and recorded at baseline, 2 weeks, 4 weeks, and 6 weeks. CALs and PPDs were assessed at six sites per study tooth and recorded at all time-points. The fixed reference point for assessing CAL levels was the cementoenamel junction. The average for CAL and PPD was recorded for each patient. One examiner collected and scored all data at all visits and was blinded to the group allocation. A UNC 15 probe was used.\nAll subjects brushed twice a day for a timed 2 minutes, once in the morning and once in the evening, following instructions for the Bass brushing technique. Subjects either used their own smart phone or were provided a timer to time the 2 minutes. Subjects in Group 1 used the water flosser once a day in the evening with 600 ml of warm water, and Group 2 used dental floss once a day in the evening. After brushing, the subjects rinsed with water. Subjects were required to demonstrate proper technique of their assigned product during the baseline visit. Instructions were reviewed and technique was evaluated at the 2-week visit.\nThe primary outcome was CALs for anterior teeth, posterior teeth, and all teeth. The initial analysis compared the mean change after 6 weeks within each group using a paired t-test. A one-way analysis was used to determine differences between the groups. The secondary outcome of PPD was analyzed the same way. Data were summarized using descriptive statistics by and between treatment groups. With 35 subjects per group, the study had 90% power to detect a change in CAL of >1 mm with an effect size of 0.5 or greater. There were no changes from the planned analysis for this study.\nGingival index, bleeding on probing, and plaque index were not included in this study, as its intention was only to compare the regimens on the impact of PPD and CAL and to focus on the question of safety.\nData were collected on case report forms (CRFs) for each subject and recorded in writing. Errors were corrected by striking a single line through the invalid data and initialed and dated by the recorder who then entered the correct data. The CRFs were completed in entirety, reviewed for completeness and accuracy, and signed by the examiner. The CRFs underwent key batch entry and verification by the statistician.\nOne hundred and three subjects completed the study. One subject dropped out of the study for personal reasons and one subject no longer qualified at the baseline visit. There were no adverse events reported during the study. Oral examinations were negative for any oral lesions, trauma, or other abnormal findings at baseline for all subjects and at each examination visit.\nThe WF group showed an improvement of CALs (4% [SD = 0.07]). The levels exceeded those of the MTF and MT groups. The MT group showed a negative change for anterior CAL (-0.5% [SD = 0.05]). These results suggest that the water flosser is at least comparable if not better than the other groups in improvement or stability of CAL (Table 3 and Table 4).\nThe WF group showed a reduction in PPD over the 6 weeks and exceeded the reductions seen for the MTF and MT groups. The MT group showed a slight increase for anterior PPD. The results demonstrate that the water flosser is at least comparable if not better than MTF and MT in the reduction or stability of PPD over 6 weeks (Table 3 and Table 5).\nNumerous clinical studies have evaluated the safety of the Waterpik Water Flosser on oral soft and hard tissues. To date there have been no adverse events reported in randomized controlled trials. Anecdotally, some dental professionals feel that the pressure must be dangerous to the epithelial attachment or push bacteria deeper into the pocket. This has not been shown in any of the studies conducted using the Waterpik Water Flosser since its introduction in 1962.1-25 Those studies used a similar range of pressure as was used in this study, primarily from 50 psi to 100 psi, mostly using the classic water flosser tip.\nTo the contrary, studies have reported data that refutes these assumptions. Microscopic tissue samples from water-flossed sites have shown a reduction in inflammation in pockets up to 6 mm.21-23 In contrast the control group showed diffuse moderate inflammation and connective tissue disorganization, fewer inflammatory cells, and vascular congestion.\nAn ultrastructural study evaluated the impact of water flossing on the epithelial wall and the morphologic types of bacteria in subjects with periodontally involved teeth that were scheduled for extraction. Scanning electron microscopy showed that the water-flossed sites showed considerable reduction in the number of microorganisms in sites from 0 to 6 mm.24 Studies have also shown a reduction in spirochetes25and Prevotella intermedia in sites 4 mm to 6 mm.14 Adolescent subjects with fixed orthodontic appliances who water flossed had an 80% better reduction in total aerobic flora and a 60% better reduction in lactobacillus counts when compared with control group.10 Studies have also shown a reduction in pro-inflammatory mediators measured in the gingival crevicular fluid or serum.7,8\nThe present study was designed to evaluate the safety of water flossing on multiple pressure settings as measured by the CAL (primary objective) and PPD (secondary objective). The data showed that the water-flosser group had similar or better changes than string floss or manual toothbrushing alone. The same was reported for PPD.\nThe outcomes from this study support previously published data on CAL and PPD. A study on subjects with diabetes showed improvements in CAL or PPD for the water flosser group and the control group at 3 months.7 There were no differences between the groups. In a 2-week study, reductions in PPD were significantly better than control group in mild-to-moderate periodontitis subjects.8 Two 6-month studies with subjects in periodontal maintenance programs showed a statistically significant improvement in PPD within the group that used the water flosser.13,17\nThe Waterpik Water Flosser is safe to use and demonstrated stability in CALs and PPDs. The results compared favorably to manual toothbrushing and dental floss or manual toothbrushing alone. This study should alleviate concerns that the Waterpik Water Flosser, regardless of pressure, is associated with a negative impact on gingival tissue or epithelial attachments as measured by CAL and PPD.\nAbout the Authors\nC. Ram Goyal, BDS\nPresident and Principle Investigator, All Sum Research Center Ltd.,\nMississauga, Ontario, Canada\nJimmy G. Qaqish, BSc\nVice President of Clinical Operations, All Sum Research Center Ltd., Mississauga, Ontario, Canada\nReinhard Schuller, MSc\nSenior Consultant, Reinhard Schuller Consulting,\nToronto, Ontario, Canada\nDeborah M. Lyle, RDH, BS, MS\nDirector of Professional and Clinical Affairs, Water Pik, Inc.,\nFort Collins, Colorado\n1. Lobene RR. The effect of a pulsed water pressure cleansing device on oral health. J Periodontol. 1969;40(11):667-670.\n2. Barnes CM, Russell CM, Reinhardt RA, et al. Comparison of irrigation to floss as an adjunct to tooth brushing: effect on bleeding, gingivitis, and supragingival plaque. J Clin Dent. 2005;16(3):71-77.\n3. Rosema NA, Hennequin-Hoenderdos NL, Berchier CE, et al. The effect of different interdental cleaning devices on gingival bleeding. J Int Acad Periodontol. 2011;13(1):2-10.\n4. Sharma NC, Lyle DM, Qaqish JG, et al. Effect of a dental water jet with orthodontic tip on plaque and bleeding in adolescent patients with fixed orthodontic appliances. Am J Orthod Dentofacial Orthop. 2008;133(4):565-571.\n5. Goyal CR, Lyle, DM, Qaqish JG, Schuller R. Evaluation of the plaque removal efficacy of a water flosser compared to string floss in adults after a single use. J Clin Dent. 2013;24(2):37-42.\n6. Magnuson B, Harsono M, Stark PC, et al. Comparison of the effect of two interdental cleaning devices around implants on the reduction of bleeding: a 30-day randomized clinical trial. Compend Contin Educ Dent. 2013;34(spec iss 8):2-7.\n7. Al-Mubarak S, Ciancio S, Aljada A, et al. Comparative evaluation of ad-junc-tive oral irrigation in diabetics. J Clin Periodontol. 2002;29(4):295-300.\n8. Cutler CW, Stanford TW, Abraham C, et al. Clinical benefits of oral irrigation for periodontitis are related to reduction of pro-inflammatory cytokine levels and plaque. J Clin Periodontol. 2000;27(2):134-143.\n9. Felo A, Shibly O, Ciancio SG, et al. Effects of subgingival chlorhexidine irrigation on peri-implant maintenance. Am J Dent. 1997;10(2):107-110.\n10. Hurst JE, Madonia JV. The effect of an oral irrigating device on the oral hygiene of orthodontic patients. J Am Dent Assoc. 1970;81(9):678-682.\n11. Burch JG, Lanese R, Ngan P. A two-month study of the effects of oral irrigation and automatic toothbrush use in an adult orthodontic population with fixed appliances. Am J Orthod Dentofacial Orthop. 1994;106(2):121-126.\n12. Goyal CR, Lyle DM, Qaqish JG, Schuller R. The addition of a water flosser to power tooth brushing: effect on bleeding, gingivitis, and plaque. J Clin Dent. 2012;23(2):57-63.\n13. Newman MG, Flemmig TF, Nachnani S, et al. Irrigation with 0.06% chlorhexidine in naturally occurring gingivitis. II. 6 months microbiological observations. J Periodontol. 1990;61(7):427-433.\n14. Chaves ES, Kornman KS, Manwell MA, et al. Mechanism of irrigation effects on gingivitis. J Periodontol. 1994;65(11):1016-1021.\n15. Ciancio SG, Mather ML, Zambon JJ, Reynolds HS. Effect of a chemotherapeutic agent delivered by an oral irrigation device on plaque, gingivitis, and subgingival microflora. J Periodontol. 1989;60(6):310-315.\n16. Newman MG, Cattabriga M, Etienne D, et al. Effectiveness of adjunctive irrigation in early periodontitis: multi-center evaluation. J Periodontol. 1994;65(3):224-229.\n17. Flemmig TF, Epp B, Funkenhauser Z, et al. Adjunctive supragingival irrigation with acetylsalicylic acid in periodontal supportive therapy. J Clin Periodontol. 1995;22(6):427-433.\n18. Flemmig TF, Newman MG, Doherty FM, et al. Supragingival irrigation with 0.06% chlorhexidine in naturally occurring gingivitis. I. 6 month clinical observations. J Periodontol. 1990;61(2):112-117.\n19. Gorur A, Lyle DM, Schaudinn C, Costerton JW. Biofilm removal with a dental water jet. Compend Contin Educ Dent. 2009;30(spec iss 1):1-6.\n20. Goyal CR, Lyle DM, Qaqish JG, Schuller R. Efficacy of two interdental cleaning devices on clinical signs of inflammation: a four-week randomized controlled trial. J Clin Dent. 2015; 26(2):55-60.\n21. Lainson PA, Bergquist JJ, Fraleigh CM. A longitudinal study of pulsating water pressure cleansing devices. J Periodontol. 1972;43 (7):444-446.\n22. Krajewski JJ, Giblin J, Gargiulo AW. Evaluation of a water pressure cleansing device as an adjunct to periodontal treatment. Periodontics. 1964;2(2):76-78.\n23. Canter MT, Stahl SS. Interdental col tissue responses to the use of a water pressure cleansing device. J Periodontol. 1969;40(5):292-295.\n24. Cobb CM, Rodgers RL, Killoy WJ. Ultrastructural examination of human periodontal pockets following the use of an oral irrigation device in vivo. J Periodontol. 1988;59(3):155-163.\n25. Drisko CL, White CL, Killoy WJ, Mayberry WE. Comparison of dark-field microscopy and a flagella stain for monitoring the effect of a Water Pik on bacterial motility. J Periodontol. 1987;58(6):381-386","Dental Floss, Flossing or Bacterial Plaque- What’s The Real Issue\nDental Floss Controversy\n“Medical Benefits of Dental Floss Unproven” was the headline in an AP article written by Jeff Donn August 2, 2016. Since then patients have been asking questions as to whether or not it makes sense for them to continue flossing their teeth. So much controversy about floss ensued, that FLOSSING rated enough to hit most news outlets in the midst of a contentious Presidential campaign, devastating floods in Louisiana and the ongoing XXXI Summer Olympiad. Clarification and reassurance to the public is in order, before people mindlessly adopt a false premise, toss their floss in the round file and abandon their quest for securing or maintaining oral health!\nOral Health- Not About Floss Alone\nActually, removal of BACTERIAL PLAQUE from oral structures provides the health benefit. Research has detailed to how biofilm, a combination of debris including bacteria, food and other elements, collects on teeth and gums causing tooth decay, gum disease. Other far reaching effects throughout the body may occur including cardiac ailments. The relationship between accumulated oral biofilm and disease is well known and wide spread throughout the world’s population. In fact, oral cleanliness by any means reduces the risk of disease. But, other factors including diet and level of inherent resistance may skew flossing’s effectiveness curve. It is not about flossing alone! Yet, I don’t understand why the AP would mislead the public to believe FLOSS could be responsible for a medical benefit in the first place. Does that piece of string have a life of it own?\nFlossing Teeth With Decay, Gum Disease- Little Effect\nDo you have decay or gum disease and expect that preventive techniques will substitute for treatment? Why is this important? Because, you may be disappointed to find out that unless deteriorated conditions are “taken care of”, dental disease will continue to progress, despite your best efforts with brush and dental floss! Your circumstance requires TREATMENT and you are beyond the threshold where preventive techniques work.\nWhere Does Flossing Fit In\nFloss is one tool in an arsenal of many hygiene devices, an instrument designed for plaque removal in specific clinical circumstances. Sustained long term health maintenance using a simple tool like dental floss requires a healthy start point! Get examined and take care of unhealthy conditions. Now, at least, you’ve got a chance your flossing will be effective! Your dentist or dental hygienist can help customize a “home care” regimen that creates a favorable long term outlook, but it requires your continuous and regular participation. Today, the ability to maintain oral cleanliness has never been easier. We have many tools to choose from including floss! Most importantly, identify the ones that are best suited for you and use them as recommended! The act of removing bacterial plaque and food debris from the mouth by any tool or technique does help win the day for oral health. DO NOT THROW YOUR FLOSS OUT! If you are NOT succeeding with floss in your mouth as advised, you may still find many other extra oral uses, like tying your Clematis plant to your deck or hanging Christmas ornaments!\nDentistry Still Tied to Flossing\nMaybe some people require a 100 million dollar epidemiological STUDY over 20 years to provide indisputable evidence of “medical benefit” before they use of a piece of string to remove gunk from between their teeth. In the meantime common sense and the recommendation of an old Vermont born dentist, Dr. Levi Spear Parmly, who first advocated the use of a “waxed silken thread” for oral cleanliness in 1819, will have to suffice. And, until definitive research has been completed, dental flossing among other devices will be included in our recommendations to help our patients be effective as they can at keeping their mouth fresh, clean and healthy. After all, it is my opinion and that of many of my colleagues, there is no evidence that NOT flossing and not cleaning between your teeth provides any medical benefit either!\nYours in health,\nBlane J. Nasveschuk, DMD\n- “Medical Benefits of Dental Floss Unproven”- Associated Press\n- Practical Guide to the Management of Teeth- By Dr. Levi Spear Parmly 1819 (see page 72)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:785725c9-e0bc-493d-8342-072dc7e0f4a6>","<urn:uuid:09c0bf34-c56f-463a-93f6-fb6af892df40>"],"error":null}
{"question":"Why do worldwide bone marrow registries focus on recruiting young male donors, and what key HLA matching criteria must be met for successful transplantation?","answer":"Registries focus on recruiting young males (18-30) because research shows they're more likely to be chosen as donors due to fewer health complications and greater availability. Men can physically donate larger volumes of stem cells, and they don't have the limitations that women face during pregnancy/breastfeeding or the risk of antibodies that can increase GVHD. Regarding HLA matching, there are six key antigens (two each in groups A, B, and DR) that determine compatibility. While bone marrow transplants typically require a 5/6 or 6/6 HLA match, cord blood transplants can succeed with a 4/6 match because their immune cells are less mature and less likely to attack the recipient's system.","context":["Bone Marrow & Stem Cell Registries\nMany countries around world have at least one stem cell or bone marrow registry. For eligible people, being on one of these registries is as simple as filling out a form and providing a cheek swab or blood test.\nEach registry keeps the details of every person and most importantly their tissue type. The registries are all linked so there is in effect a huge worldwide registry which increases the chances of each person finding a donor even if there is not a match in the registry where they live.\nThe Australian Bone Marrow Donor Registry (ABMDR)\nHere in Australia, we have the Australian Bone Marrow Donor Registry (ABMDR).\nWhen a patient needs to find a donor, their doctor will first turn to the patient’s family to see if anyone is a suitable match, and if not will contact the ABMDR to search their registry. If no one registered on the ABMDR is a suitable match, a search will be carried out across the world wide registries. In fact, for 80% of Australian transplant patients, their donor is found on overseas registries, with Germany, USA, UK and Poland being the largest contributing countries.\nWith over 36 MILLION people registered on one of the worldwide registers you would expect that finding a match is easy, but this is not the case. The chances of you being a match is actually quite low – only 1 in 1,500 people are the special ones. We need MANY more people to sign up, which is where you come in.\nWho is eligible to register?\nThe eligibility criteria to register varies around the world as each registry has their own rules, but no registry will accept donors if donating could be unsafe for either the donor or the patient.\nHere in Australia, the ABMDR exclusion rules have been simplified due to the introduction of cheek swabs as a way of testing your tissue type. They will accept people in good health between the ages of 18 and 45, and only exclude people who have:\n- been diagnosed with any of the following blood disorders – thalassaemia major, sickle cell disease, Fanconi anaemia or haemophilia\n- previously had an organ or bone marrow transplant\n- had a positive test for HIV or HTLV\nWhy is TLR focusing its recruitment on the 18-30’s?\nResearch has shown people in the 18-30 age range are much more likely to be chosen as younger donors generally have fewer health complications and are often more readily available to donate. Patients also tend to have better transplant outcomes with younger donors.\nIt costs approximately $100 to get each person tested and registered on the ABMDR, so TLR has chosen to use its funds wisely and focus on those most likely to be chosen.\nMen often make better donors. Sounds a bit rude, but why is this?\nBoth men and women are equally encouraged to sign up to the ABMDR, however there is a focus on recruiting more men as there are currently under-represented on the ABMDR. In fact, men aged 18 – 30 currently make up only 4% of those registered on the Australian Registry.\nBut why are men usually chosen over men? It’s not as sexist as it sounds, it’s actually down to practicality and science.\nFor the most part, donating stem cells is about quantity over quality. Men are often larger than women and so can physically donate a larger volume of stem cells. Doctors also tend to choose men to avoid logistical issues that arise due to women not being able to donate while pregnant or breastfeeding. Also, women who have been pregnant can also produce antibodies that can increase the risk of Graft vs Host disease, known as GvHD. This can be very serious, and in Trace’s case, fatal. For others, it can drastically change the quality of their life after transplant. These are the factual reasons why doctors will choose men over woman.\nThat being said, young, healthy women who have never been pregnant can make equally great donors as men, so we encourage everyone to join the Registry.\nWhy is Ethnicity important?\nBeing selected as a donor comes down to one main factor, sharing the same tissue type as the patient. Tissue type is determined entirely by Human Leucocyte Antigens (HLA), which are protein markers found on the surface of every cell in your body. You inherit half of your HLAs from your mum and half from your dad. The best chance a patient has of finding a match is from someone who shares the patients same ethnic background.\nAustralia is an incredibly multicultural society, one which has been built on migrants. But the very thing which makes Australia so unique also makes is very challenging for some people to find a compatible donor.\nWith almost 80 percent of people currently registered on the Australian Bone Marrow Registry having a northern European background, there is a need to encourage more diversity on the register to better represent the diversity we have within Australia.\nCan I donate to a friend or a family member?\nWhen a friend or a family member is diagnosed with a disease treatable with a stem cell or bone marrow transplant, many people come forward offering to help. Sadly, the chances of you being a match for a friend are highly unlikely. In many cases the best donor is a brother or sister who share the same parents, but even then, there is only a 25% chance your sibling shares the same tissue type.\nThe other 75% of patients will need to rely on finding an unrelated donor, a generous stranger registered on the ABMDR or one of the other worldwide registries. If you join the ABMDR you may be matched to a patient needing a transplant anywhere in the world.\nCan I donate if I’m a gay?\nThat’s a resounding YES, yes you can, and we are proud you can too. Anyone generous enough to register and potentially save the life of someone in need, regardless of their gender, race, religion or sexuality is welcomed to sign up. And anyone who comes up as a match will go through thorough testing to make sure donation is safe for both donor and the patient.","Hurler, Scheie and Hurler/Scheie syndromes are mucopolysaccharide disorders and are also known respectively as MPS-IH, MPS-IS, and MPS-IH/S. Hurler syndrome takes its name from Gertrud Hurler, the doctor who described a boy and girl with the condition in 1919. In 1962, Dr. Scheie, a consultant ophthalmologist, wrote about some of his patients who were more mildly affected. Patients who seem not to fit clearly in either the severe or the mild end of the disorder are said to have Hurler/Scheie syndrome.\nThere is no magic cure for MPS disorders, but there are ways of managing and treating the problems they cause.\nWhat Causes the Disorder?\nMucopolysaccharides are long chains of sugar molecule used in the building of connective tissues in the body.\n“saccharide” is a general term for a sugar molecule (think of saccharin)\n“poly” means many\n“muco” refers to the thick jelly-like consistency of the molecules\nThere is a continuous process in the body of replacing used materials and breaking them down for disposal. Children with these disorders are missing an enzyme called alpha-L-iduronidase which is essential in cutting up the mucopolysaccharides called dermatan and heparan sulfate. The incompletely broken down mucopolysaccharides remain stored in cells in the body causing progressive damage. Babies may show little sign of the disorder, but as more and more cells become damaged, symptoms start to appear.\nHow Common is the Disorder\nScheie syndrome is 1 in 500,000\nHurler/Scheie syndrome it is 1 in 115,000.\nThere is an estimate in the United States that 1 in 25,000 births will result in some form of MPS. Other estimates state only 40 babies a year are born with Hurlers.\nHow is the Disorder Inherited?\nWe all have genes inherited from our parents which control whether we are tall, short, fair, etc. Some genes we inherit are “recessive,” that is to say we carry the gene, but it does not have any affect on our development. Hurler syndrome is caused by a recessive gene. If an adult carrying the abnormal gene marries another carrier, there will be a one in four chance with every pregnancy that the child will inherit the defective gene from each parent and will be affected with the disorder. There is a two in three chance that unaffected brothers and sisters of MPS I children will be carriers. They can be reassured; however, that, as the disorder is so rare, the chance of marrying another carrier is very slight provided they do not marry a cousin or other close family member. However, you can not find two more different genetic background’s than Joe and I. His family is all from Italy, and I like to say, I am 100% blond!!!!\nThe disorder is based on the bodies inability to produce a specific enzyme that is used to breakdown cellular byproducts into other molecules the body can use. These molecules build up in the body and are stored in the cells where they were originally used. Over time these molecules begin to get in the way and cause a slow down in the normal cellular processes that take place in the body. The most common effects of this build up are mental deficiencies, skeletal and joint problems, vision and hearing impairment, heart, liver and lung disease. The end result is death.\nCurrent Treatment Options\nThere are many treatment options available for Hurler’s.\n- Enzyme Replacement Therapy – Introduction of the missing enzyme back into the body through a central line or peripheral line.\n- Bone Marrow Transplants – Complete obliteration of the Childs malfunctioning bone marrow and replacement with healthy bone marrow that can produce the needed enzyme\n- Stem Cell Transplants – Introduction of stem cells into the body which produce the required cells in the treated organ to create the enzyme\n- Umbilical Cord Transplants:\nIn the 1970s medical researchers discovered that human umbilical cord blood contained the same kind of stem cells found in bone marrow. (Stem cells get their name from their ability to develop into three types of blood cells: red blood cells, while blood cells and platelets). Because stem cells from bone marrow had already been used successfully to treat patients with life-threatening blood diseases, such as leukemia and immune system disorders, researchers believed that they could also use stem cells from cord blood to save patients.\nIn 1988, doctors transplanted human umbilical cord blood into a 5-year old boy suffering from Fanconi’s anemia. Ten years after the transplant, the boy is alive and seems to be cured of his disease. Based on this and other successful transplants, doctors and medical researchers began to collect, freeze and store cord blood units (CBUs) at cord banks throughout the world. As of October 1998, there were approximately 22,000 CBUs collected and frozen for use worldwide, and approximately 700 unrelated donor and 150 related (sibling) donor cord blood transplants had been performed.\nAlthough today marrow transplants and cord blood transplants are often referred to by the same name — stem cell transplants — there are important differences between the two. This section will explain these differences and also discuss the kinds of decisions doctors and their patients must make to determine the best source of stem cells for transplantation. Before considering these issues, however, it is important to understand the challenges patients face in finding a donor.\nFinding a Donor\nUnfortunately, 70% of patients who need a stem cell transplant do not have a suitable donor in their family. The National Marrow Donor Program (NMDP) helps identify stem cell donors for patients who do not have a related donor.\nStem cell transplants require matching certain tissue traits of the donor and patient. Because these traits are inherited, a patient’s most likely match is someone of the same heritage. American Indian and Alaska Native, Asian, Black and African American, Hispanic and Latino, Native Hawaiian and Other Pacific Islander, and multiple-race patients face a greater challenge in finding a match than White patients.\nThe collection and storage of cord blood is one way to give patients of all racial and ethnic backgrounds greater access to stem cell transplantation. For that reason, beginning in the early to mid-1990s, medical institutions around the world began making a serious effort to collect and store cord blood units for use in transplantation.\nSo far, clinical studies by John E. Wagner and others suggest that unrelated cord blood transplantation is a safe and acceptable alternative to bone marrow transplantation for many patients. However, these studies have also found that, as with bone marrow transplants, patients who receive cord blood from sibling (or related) donors generally have higher survival rates than those who receive cord blood from unrelated donors.\nStudies have also found that banked cord blood (from both related and unrelated donors) often contains enough stem cells for transplantation. Physicians need to match the number of stem cells in a cord blood unit with the weight of the patient to be sure the unit is likely to be able to reestablish the patient’s immune system. Because there are fewer stem cells in cord blood than in marrow, until recently most cord blood recipients have been children or small adults. There is, therefore, some concern that the number of cells in an average cord blood unit may not be sufficient for engraftment in larger adults. Engraftment occurs when the transplanted stem cells — the “graft” — regenerate the blood and marrow and begin to function as the recipient’s new immune system.\nOne positive finding is that cord blood transplant patients appear to suffer less from acute graft-versus-host disease (GVHD) than patients who receive bone marrow transplants. GVHD is a very serious, and sometimes fatal, condition that occurs when the patient’s new immune system — which is made up of stem cells from the donor — starts attacking the patient’s body. GVHD affects the skin and internal organs such as the liver and intestines.\nDespite the fact that cord blood recipients appear to suffer less from GVHD, it has not yet been proven that the risk of GVHD is less in all recipients after cord blood transplantation. Because children receive the most cord blood transplants, and because they also experience less GVHD than adults after bone marrow transplants, it may be that the success of cord blood transplants is at least partly attributable to the fact that they are used on more children than adults.\nUnderstanding HLA Matching\nWith stem cell transplants, the better the match between the donor and the recipient, the less likely graft-versus-host disease is to develop. It is important, therefore, to understand how doctors determine the best, or most acceptable, match between the donor and the recipient. To understand how they do this, it helps to have a basic understanding of the human immune system.\nAntigens, a kind of protein located on the outer surface of most cells in the body, help the immune system to identify foreign bacteria and viruses. The antigens that transplant doctors look for when matching patients and donors are located on a cell called a leukocyte, giving these antigens the name Human Leukocyte Antigens, or HLA. Every person has six groups of HLA antigens, but three groups (called A, B, and DR) are considered most important in a stem cell transplant. Each of these groups has two antigens, one inherited from the father and one from the mother, making a total of six antigens that determine a donor/recipient match. A perfect match is called a 6/6 HLA match.\nBone marrow transplants are usually not attempted unless the donor and recipient are a 6/6 or 5/6 HLA match. However, with cord blood transplants, doctors and medical researchers generally believe that a 4/6 match is sufficient. Because immune system cells contained in cord blood are less mature, they have not yet “learned” to attack foreign substances, and so would be less likely to attack the recipient’s immune system, even though the match isn’t perfect. Since matching requirements for cord blood are less strict, patients who are unable to find a 5/6 or 6/6 marrow donor may be able to find a suitably matched cord blood unit.\nWhat is Known About Cord Blood Transplants\nWith its more than 30-year history, bone marrow transplants are a well-established, life-saving treatment for a wide range of blood disorders such as leukemia and aplastic anemia, as well as selected immune system deficiencies and genetic disorders. While the history of cord blood transplants is less extensive, there is evidence to suggest that these transplants can cure diseases, too. But with cord blood there are more unknowns, and doctors and their patients must carefully evaluate the situation before deciding on the best treatment.\nThe following lists explain what is known and not known about cord blood transplants. While these lists are not exhaustive, they do include aspects of cord blood transplants that are critical in the decision-making process:\nWhat We Know About Cord Blood Transplants\n- Cord blood contains sufficient numbers of stem cells for engraftment in most recipients weighing less than 50 kilograms (about 110 pounds).\n- Collection of cord blood poses no health risk to the mother or infant donor.\n- Because it is stored and available for use, cord blood is sometimes more readily available than a potential marrow or blood stem donor, who may be unavailable for donation when it is needed.\n- Cord blood is rarely contaminated by viruses often found in marrow, such as cytomegalovirus (CMV) and Epstein-Barr virus.\n- Cord blood can cause severe GVHD, but possibly less frequently than in bone marrow transplants.\nWhat We Think We Know about Cord Blood Transplants Based on Clinical Data\n- Compared to bone marrow transplants, cord blood transplants may have a lower rate of acute GVHD, at least in cases where a related (sibling) donor is used.\n- It appears that the transplant process using cord blood (from the time a search is started to the time donor cells are ready for transplant) is shorter than that for marrow cell donation because the cord blood units are in storage and ready for use.\nWhat We Don’t Know about Cord Blood Transplants (because of lack of clinical evidence)\n- Whether cord blood is sufficient for engraftment in most adult recipients, although experience suggests that it may be sufficient for a significant proportion of these recipients.\n- Whether cord blood transplants pose a different risk of relapse (recurrence of an illness after a remission) compared to unrelated bone marrow transplants.\n- Whether focused cord blood collection will be successful in meeting the current challenge of finding a match for American Indian and Alaska Native, Asian, Black and African American, Hispanic and Latino, Native Hawaiian and Other Pacific Islander, and multiple-race patients, thus increasing the number of available transplants for these patients.\nClinical studies have demonstrated that stored cord blood is a sufficient source of transplantable stem cells, at least for young patients. Also, in addition to previously known advantages of cord blood (rapid availability and a low rate of virus contamination) studies have found that cord blood transplants may also lead to less GVHD than bone marrow transplants.\nClinical experience also shows that a high stem cell dose (a sufficient number of stem cells based on the patient’s body weight) is an important factor in recipient survival, and that cord blood transplants can be successful with as low as a 4/6 HLA match.\n*Visit “Chemo Counting” to see what a typical hospital day will include*\nGraph Versus Host Disease (GVHD)\nGVHD is a frequent complication of an unrelated bone marrow or umbilical chord transplant. The transplanted cells realize that they are in a new environment and attack the donor’s organs. Approximately 50% of patients that receive an unrelated transplant contract GVHD, the numbers are less in umbilical chord transplants at 25%. There are two types of GVHD, acute and chronic. Acute GVHD occurs soon after the transplant between day 30 and day 60. Chronic GVHD can occur much later after transplant and last much longer. Both types of GVHD can be serious and range from level 1 through level 4 where level 4 is the most severe. Most patients that contract GVHD are treated with steroids and a variety of anti-rejection medications. The disorder has no long term side effects if treated properly.\nT-Cells are the cells in the transplanted marrow that recognize foreign matter. Their sole purpose is to fight off infections, viruses, and other foreign substances. These T-Cells look for genetic markers, HLA markers, that distinguish them from foreign cells. To T-Cells normal body cells can be foreign and are therefore considered bad. The T-Cells will fight these cells trying to rid the body of them. Obviously these small amount of T-Cells are not going to kill the entire human body but the side effects of GVHD can be uncomfortable. Typical side effects are diarrhea, rashes, increased liver functions, stomach and intestinal problems.\n**Information obtained from MPS website, and National Marrow Donor Program"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:0a328365-04bc-4ebc-a736-c402ceb4771c>","<urn:uuid:54083459-7d01-49c7-b01c-35a4f41a8d9f>"],"error":null}
{"question":"How do impromptu speeches compare to formal business presentations in terms of preparation and structure?","answer":"Impromptu speeches and formal business presentations differ in several key aspects. Impromptu speeches typically have little to no preparation time and last about five minutes, while business presentations require advance preparation including detailed speaker notes, visual aids, and careful timing management. However, both share a three-part structure: introduction, body, and conclusion. For impromptu speeches, the focus is on staying fluid and focused on a clear topic, while business presentations require more formal elements like setting agenda expectations, managing transitions between topics, and allocating specific time percentages (15% for introduction, 75% for main content, 10% for conclusion). Both formats benefit from practice and preparation when possible, though impromptu speeches rely more on quick thinking and organization skills.","context":["Being able to give an off-the-cuff speech takes practice, but it can be made a bit easier if you already have a few go-to topics up your sleeve. But what makes an impromptu speech different than a standard speech? For starters, impromptu speeches usually spring up with little to no preparation time, and they typically only last about five minutes or so. Typically they’re given at debate competitions or informative events or classes.\nIn this article:\nWhen running through an impromptu speech in your head, it’s important to remember that they usually are made up of three distinct parts: an introduction, engaging and informative body, and a conclusion. This is where the practice comes in because being able to deliver an effective impromptu speech takes a certain degree of oration expertise and organization. That being said, the more you give impromptu speeches, the easier they should become.\nSo how do you decide on a topic? Well, a good place to start is to know your audience. Are you giving a short talk at a specific event? If so, try catering your topic around the event. If you’re giving a class on speech methods, try throwing a few different topics out to the class and go with whatever one garners the most interest. Maybe you’ve been asked to speak at a friend’s wedding. If this happens, have a short list of personal topics and stories about you and your friend ready for when the microphone is passed to you. It’s also important to choose a topic that is relevant and that hasn’t already been over done.\nWhen it comes to actually delivering your speech, there are a few things to remember. As with any speech, you’ll want to make sure to speak fluidly and with authority. Have a clear topic in mind and stay focused on it. Don’t get overly wordy or off track. Also, keep the speech short and sweet. As mentioned before, your speech should have a beginning, middle and an end. Additionally, keep your speech engaging by crafting a story around your topic to improve its structure. This will also keep listeners interesting. Don’t be afraid to add in a bit of humor where appropriate.\nTake a look at some of the following impromptu speech topics below and feel free to add a few to your collection. Some are more serious while others are better suited as ice breakers. As long as you know your audience and stay focused while delivering your speech, the next time you have to give an off-the-cuff speech, you’ll be ready.\nCan We Write Your Speech?\nGet your audience blown away with help from a professional speechwriter.\nFree proofreading and copy-editing included.\nList of Impromptu Speech Topics\n- Why manners are important\n- Tax incentives for international adoption\n- Why the government should cut off all foreign aid to dictatorships\n- Standardized tests aren’t fair metrics when gauging a teacher’s effectiveness\n- Girls should be allowed on high school football teams\n- Calorie counts should be listed on fast food menus\n- The current tax system harms the working middle class\n- Why churches shouldn’t have to pay taxes\n- Yes, motherhood is still valued in today’s society\n- The need for effective cyber security protocols\n- Is it really that great being young?\n- Why do teenagers smoke?\n- What human quality do we need more of?\n- Are self-driving cars the future?\n- Why is a sense of humor important?\n- Why is voting important?\n- Are professional athletes paid too much?\n- Is it ever okay to lie?\n- Wisdom vs. intelligence\n- Real vs. fake Christmas trees\n- Your favorite nickname\n- My best job ever\n- Your first memory\n- The most successful person you know\n- My favorite season\n- My biggest concern for the future is…\n- If I ruled the world…\n- The most difficult thing I’ve ever done\n- Three things you do well\n- Ghosts you’d like to meet\n- Best bank to get a mortgage through\n- Personal finance advice\n- Internal auditing\n- How to prevent financial fraud\n- Improving ROI (return on investment)\n- Importance of social media in marketing\n- Decreasing production costs\n- Most strategic e-marketing solutions\n- Management strategies\n- How to handle government regulations\n- How to make your favorite meal\n- How to start an online blog\n- How to prepare your yard for fall\n- How to apply for a job\n- How to walk gracefully\n- How to ace a job interview\n- How to buy a car\n- How to become a published writer\n- How to apply for college\n- How to buy a house\n- Share something unusual about yourself.\n- Talk about a nickname you have and how you got it.\n- What is the biggest effect of the internet?\n- Three things that scare me.\n- If I were in charge of school lunches…\n- Could we really say to our bosses what’s on our mind?\n- Favorite cartoon character growing up\n- How to impress your parents.\n- Is a glass half full or half empty?\n- Describe the ideal pet.\n- What you like and dislike on participating in a picnic in the woods.\n- What you did last weekend.\n- Why grandma’s baked chocolate chip cookies, cakes and brownies always taste and smell good.\n- Why it is okay that parents decide and not kids.\n- The good and bad things of dogs.\n- How a rainbow arises in the sky while it is raining.\n- Why seeing a dentist two times a year is a must.\n- Your morning routine.\n- How and why earthquakes happen.\n- Why you should know the main cities an capitals of the world.\n- The true meaning of the Christmas celebration.\n- The difference is between I and me in English language.\n- The five stages you go through when you are sleeping at night.\nTask Words Verbs and Adjectives\nWhen preparing, it is essential to understand the goals of particular duty phrases and the subjects they are associated with.\nI know you are often put off by the phrased job in a handout, however, they are relatively easy to understand when studying a school or college public speaking assignment.\nIt is vital that you are familiar with a wide array of duties in order to convey the message and / or instructions that you’re trying to get across.\nANALYSE – Look closely to a subject, an argument, an idea or a topic, determine the essence of the components in detail and the relation to each other.\nE.g. Examine closely a current social event you’ve learned a lot about, or you’ve enjoyed. Look closely to phishing, the criminally fraudulent process of attempting to acquire sensitive information on the worldwide net.\nARGUE – Present a systematic case built on reasons and evidence supporting or rejecting an idea, theory or proposition.\nE.g. Reject the attempts of buying off government, state or local officials.\nASSESS – Decide the value, state positive and negative judgments, and conclude. Good impromptu speech topics can be:\nE.g. Decide the value of a BA-degree / Masters-degree. Consider the value of a domestic companion animal for the elderly. How an insurance company decide the value of a car, and why that knowledge could be valuable when buying an automobile.\nCOMPARE – Show and discuss similar and different characteristics or qualities of two things.\nE.g. Discuss the pros and cons of offline and online friendships. Identify the similarities and differences of the Christian and Islamic religious traditions. Point out the best styles to more effective public speaking learning.\nCONTRAST – Emphasize differences of two things and give evidence to differentiate or distinguish their significance and consequences.\nE.g. Emphasise the differences between verbal and non-verbal communication skills. The differences of opinion between Democrat and Republican politicians. Emphasise the differences between Hollywood and Bollywood entertainment movies. Or pick other types for developing alternative impromptu speech topics for high school.\nCRITICIZE – Give your judgment about merits and faults of an opinion, theory or statement, and support it with evidence.\nE.g. Judge the Academy Award decision for best picture winner Slumdog Millionaire. Judge the merits and faults of this public speaking impromptu assignment. Judge the practice to fancy someone else outside your relationship without really acting on it.\nDEFINE – To get good impromptu speech topics make clear what the precise meaning of a word, term, phrase or situation is and why this definition is necessary.\nE.g. Give the exact meaning of narcissism. State the precise meaning of a grand jury in a trial. State the precise meaning of our Constitution, and place it in its historical context.\nDESCRIBE – Present a detailed account of the features or characteristics.\nE.g. Give the details of your baseball team (or other games). Give the characteristics of mammals, the mammalian species. Present a detailed account of the features of the Earth atmosphere.\nDISCUSS – Consider all pros and cons, and give a concluding judgment on the value of the for and against arguments.\nE.g. The pros and cons of hitchhiking. The pros and cons of lowering the drinking age to a younger age. Give the for and against arguments of felon voting.\nENUMERATE – Mention separately steps and stages of good impromptu speech topics one by one.\nE.g. Present the steps to simple life. List the steps and stages to take proper family photos. List the three steps to overcome a fear of public speaking. Or enumerate the steps to catching the catches in insurance company documents for households.\nEVALUATE – Explain strong and weak aspects or opinions about the usefulness or utility and formulate a personal judgment.\nE.g. The usefulness of diplomas and certifications. The usefulness of old-fashioned printed newspapers in our modern multimedia era.\nEXPLAIN – Show clearly how something happens in detail and the reasons or causes why.\nE.g. Why sibling rivalry happens plus how. Make clear how childhood obesity begins and what the causes are. Why sibling rivalry happens and make clear how it comes more atrocious sometimes.\nILLUSTRATE – Use examples, diagrams, figures and evidence to make a complex concept easily understood.\nE.g. What is a final salary scheme in calculating retirement pensions? Show how an exotic drink is prepared out of precise amounts of ingredients. Demonstrate how to set up an online poll and how to conclude outcomes fairly.\nINTERPRET – Bring out the importance, meaning and implications of information data and state your personal judgment.\nE.g. The impact of tourism information on China (or other Asian country) befroe you book your trip. The importance and implications of good consumer information on food labels. The value of unbiased reviews and consumer product specifications of pharmaceuticals and prescription drugs.\nJUSTIFY – Defend adequate reasons and grounds for your decisions or conclusions, and support your chosen good impromptu speech topics by evidence.\nE.g. Why President Obama sure is a good Nobel Prize winner – or why isn’t he not at all. Why the giant bailouts of car manufacturers were needed. Give ground on banking secrecy in some foreign states.\nOUTLINE – Provide the main points and principles in a logical order and name the relationship between each point.\nE.g. The causes and events that lead to the Battle of Gettysburg, July 1863. The effects of global warming on the Arctic ecosystem. The causes and main effects of the growing fast-food consumption in Asia.\nPROVE – Demonstrate the truth or falsity with logical evidence and arguments.\nE.g. The truth behind the death of Michael Jackson revealed- and the role of his doctor. The truth about the damages that could occur of vaccinations for pets. How the cigarette industry for decades seduced young people to start smoking.\nREVIEW – Critically report the main facts, theories, issues of an event, and explain the importance of off the cuff improvising.\nE.g. The likes and dislikes of participating in a Sunday afternoon picnic in the woods or at the riverside. Deliver a critical report about the most famous and popular restaurant or bar in town. This statement will generate good impromptu speech topics high school. Make a report about the best features of your PlayStation or X-box. Or take your favorite video games to develop impromptu speech topics for high school.\nSUMMARIZE – Describe concisely the main points of a good speech topic, without examples or details.\nE.g. The golden rules of a television sitcom comedy scenario. Make a summary of the primary purposes of a recent police investigation in your local area you read about in the newspapers. List the primary purposes of copyright and intellectual property laws in our country.\nTRACE – Identify and describe the stages, steps, phases, processes or the historical events of good impromptu speech topics and start from its origin.\nE.g. The effective step by step method to make studying more fun every day again – come over the humb. The development of pregnancy from the conception to the birth of a child. Explain the stages in the nine-month schedule of a beginning new human being. The interesting and amazing process of blood clotting which the body prevents blood loss.","Presentation Tips and Techniques Delivery The ability to give a presentation is a necessary skill in the Visual Aids workplace. Most of us give informal talks from time to time; others deliver more formal presentations standing in front of an audience Advance Preparation with a set agenda and visual aids. Start Strong When the occasion arises that you are called on to present, the tips and techniques in this module will help you prepare and deliver a successful presentation.Manage the Flow Speaking Style Engage the Audience\nPresentation Tips and Techniques Delivery A presentation is a brief talk on a focused topic that’s delivered to a Visual Aids group of listeners in order to impart knowledge, persuade towards a course of action, and/or to stimulate discussion. Advance Preparation Begin by assessing the requirements of your speaking assignment. Start Strong Your resource requirements will vary depending on the type of talk you need to give.Manage the Flow Is your presentation simply knowledge sharing or an informational review? In these situations, a short, informal update may be all Speaking Style that’s needed. At other times, a more formal presentation is expected. If this is the case, using visual aids can supplement and Engage the enhance your message. Audience\nPresentation Tips and Techniques Delivery A visual aid may be an actual physical object, or an image such as a Visual Aids photo, a graph, a chart, a table or some other form of digital representation that pertains to the information being presented. Advance Preparation These items may be displayed on an easel or other physical space, appear in handouts, or be projected onto a screen or monitor. Start Strong Choice of media largely depends on the presentation setting.Manage the Flow • A handout or text on a white board works well when presenting informally to a small group in a face-to-face setting. Speaking Style • Presentation slides work well when presenting more formally to a larger audience or in an online setting. Engage the Audience\nPresentation Tips and Techniques Delivery When using PowerPoint slides to display your visuals, it’s a good Visual Aids practice to provide your audience with a copy of your presentation. How and when to provide this depends on you. Advance Preparation When delivering your presentation face-to-face, you may want the Start Strong audience to have something to refer to while you talk. In this case, print copies of your slides with room for note-taking.Manage the Flow When delivering your presentation online, you may want the audience to have your presentation afterwards. If you plan to Speaking Style distribute copies of your slides, be sure to include your speaking points in the ‘Notes’ section on each page. Write full sentences so Engage the that it is a complete and accurate record of your talk. Audience\nPresentation Tips and Techniques Delivery When delivering a presentation in the workplace, your audience Visual Aids isn’t there to see a slideshow. They want to hear your message. The more prepared you are, the more credible you will appear. Advance Preparation To organize your presentation, start by outlining four elements. Start Strong • Content - What am I going to say about my topic? • Process - How will I address the points I want to make? • Purpose - Why is my topic important to the audience?Manage the Flow • Outcome - What is the benefit to be gained? Once you determine what your talk will be about, prepare an Speaking Style agenda of what you plan to cover. Audiences like to have a guide so that they know what to expect. Engage the Audience\nPresentation Tips and Techniques Delivery No presenter is expected to fully memorize their presentation Visual Aids content. A useful technique is to prepare speaker notes ahead of time and use them to rehearse. This will give you confidence and Advance Preparation help to smooth out your delivery. You can create speaker notes for yourself by simply writing down Start Strong on paper what you want to say. You should be familiar with your material, so don’t write down whole sentences. Just use keyManage the Flow phrases as cues for what you want to say. This technique forces you to develop and explain ideas in your own words, creating a more enthusiastic presentation. Speaking Style Engage the Audience\nPresentation Tips and Techniques Delivery Some presenters who stand in front of groups prefer to hold small Visual Aids note cards. You can make these by preparing custom handouts. • From your PowerPoint document, click the File menu (for Microsoft Advance 2003) or the Publish menu (for Microsoft 2007). Select ‘Notes below Preparation slides’ for the page layout. • In the new Word document, delete all slide content until only your Start Strong notes remain. • Go to Page Set-up and fix the top, left, bottom and right margins to .4; landscape orientation; and custom size paper to 6” wide and 4” high.Manage the Flow • Select all the text and reduce the font to size 10 or 12. Speaking Style • Remove unnecessary words until just the essential points fit on the page. Engage the • Print your notes on 6” by 4” Audience index cards.\nPresentation Tips and Techniques Delivery Advance preparation also involves dressing appropriately when Visual Aids presenting face-to-face. Make sure your clothing conveys a positive image. The more casual you dress, the more likely it is that your Advance Preparation authority, professionalism, and competence will be challenged. Start Strong Always wear clothing that is suitable for the event. The general rule is to match your attire to the dress of others. Business casual is usually the minimum standard.Manage the Flow You may want to dress a little more formally than you think you Speaking Style need to. It’s easier to dress down if you are slightly overdressed than it is to dress-up a too casual outfit. If you wear casual outfits Engage the to work every day, keep a jacket at the office. A jacket makes even Audience the most casual outfit more authoritative and businesslike.\nPresentation Tips and Techniques Delivery First impressions are important, so make sure the beginning Visual Aids moments of your presentation work to your advantage. To start strong, always compose your opening statements ahead of time. Advance Preparation Use the following steps to guide your introduction: • Introduce yourself (if necessary) and state the purpose of Start Strong your presentation. 1. Hello, my name is… 2. I work with… and my role is to…Manage the Flow 3. I’m here to share what I know about… 4. This information will help you to… • Preview your agenda and set the expectations for your talk. Speaking Style 5. I’m going to discuss… 6. By the end, you will… Engage the Finally, customize your comments for the occasion and practice to Audience minimize nervousness.\nPresentation Tips and Techniques Delivery Having an agenda will help you pace the flow of your presentation. Visual Aids You will want to stay on course to finish in the time allotted. Advance Preparation Effective presenters employ the following techniques to manage their delivery. Start Strong • Establish norms. For example, will you take questions as you go along or would you prefer to take them at the end? • Use transitions to indicate when one topic ends and anotherManage the Flow has begun. Example: “Now that we’ve discussed topic A, let’s now consider topic B.” Speaking Style • Stay focused. Respond to audience input but avoid time- consuming tangents. Example: “Thank you for your comments but now we need to move on.” Engage the Audience\nPresentation Tips and Techniques Delivery If you are given a certain amount of time to speak, you will want to Visual Aids manage your timing so as not to run over or hurry your delivery. Advance Preparation In general, allow about 15% of your time for the introduction, 75% for the main part of your talk, and 10% for the conclusion. Start Strong Beginning Middle End • 15% • 75% • 10%Manage the Flow For example, given a 20 minute time slot, take about three minutes for the beginning, 15 minutes for your main points, and two Speaking Style minutes for the ending. Practice ahead of time to see how this formula works with your presentation content. Speak out loud Engage the using your visual aids and time yourself. Make adjustments as Audience necessary until you feel comfortable with the format.\nPresentation Tips and Techniques Delivery If you are using PowerPoint as a visual aid, don’t treat the text on Visual Aids your slides as a script to read verbatim. This tends to create an impersonal tone where you’re speaking at the audience instead of Advance Preparation to the audience. Start Strong The content on your slides should simply provide a framework for your message, not tell the whole story. If you’re familiar enough with your material, the only reason you should be referring to yourManage the Flow slides is to point something out. You can also glance at your slides to cue what you want to say, but you should say it in a natural and Speaking Style conversational manner. Engage the Audience\nPresentation Tips and Techniques Delivery Business presenters are not expected to be performers, just Visual Aids effective communicators. The best delivery involves a narrative, storytelling style that can only come with practice. Advance Preparation It is totally unproductive to simply talk about your presentation to Start Strong someone or to mumble about it to yourself. You must actually stand up and practice speaking the words out loud in order to crystallize the ideas in your mind. The key is to remember wholeManage the Flow thoughts from which to launch your topic. To be in full command of what you want to say, focus on articulating ideas rather than on Speaking Style constructing sentences. This will give you the “mental clarity” that allows you to present in a natural and conversational manner. Engage the Audience\nPresentation Tips and Techniques Delivery When presenting, you never want to just “wing-it” nor do you want Visual Aids to be totally, 100% scripted. Try to develop a speaking style that combines both preciseness and spontaneity. Advance Preparation One method to use when rehearsing with your speaker notes is to Start Strong think of some relevant experiences, stories, or examples to share that will bring the information to life. This type of planning allows you some freedom to improvise when “in the moment.” If you areManage the Flow knowledgeable and passionate about your topic, your enthusiasm and sincerity will be evident. Speaking Style Engage the Audience\nPresentation Tips and Techniques Delivery Effective presenters engage their audiences by creating various Visual Aids opportunities for two-way communication. A few methods include: Advance • Asking questions to gain participation. Preparation • Facilitating a dialog to discuss how the topic applies to the job. • Inviting reactions to get immediate input/feedback. Start Strong Asking questions during a presentation is an excellent way to get listeners involved since most people like an opportunity to interact.Manage the Flow Here are some ways to elicit audience responses. • Ask for a show of hands. Speaking Style • Ask a rhetorical question. • Ask a leading question. Engage the • Ask for comments and opinions. Audience\nPresentation Tips and Techniques Delivery It’s also common to ask for questions from the audience. Follow Visual Aids these tips to ensure that you are prepared when answering. Advance • Prior to presenting, try to anticipate any questions that might be asked by the audience and how you would respond. Preparation • Always repeat the question before answering to ensure that others can hear it clearly. Repeating the question allows you Start Strong to simplify it and also buys you time to formulate a response. • Be familiar with knowable facts, such as names, roles or otherManage the Flow important pieces of data. Having correct and up-to-date information shows that you value and respect the individuals in your audience. Speaking Style • Questions inject some unpredictability, so be flexible and willing to adjust to the needs of your audience. They will appreciate if you listen carefully and respond honestly. Engage the Audience\nPresentation Tips and Techniques Delivery As you end your presentation, it’s important to review and Visual Aids summarize your topic. Never end with: “Well I guess that’s it…” Advance Preparation If you take questions towards the end of your presentation, leave enough time for your conclusion. Ending a presentation with Start Strong questions and answers is not a powerful way to close. The final words you say will be the most memorable, so make sure your closing points are ones you planned to say.Manage the Flow • Remind the audience why your topic is important to them. Speaking Style • Restate the benefits to be gained. • Repeat key points you want the audience to remember most. Engage the Audience The END."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:cb6583a3-6431-464d-a852-8dee56a6d960>","<urn:uuid:1e636f65-cd20-4a73-a5d4-f390a5754e91>"],"error":null}
{"question":"What is difference between E. coli bacteria and Listeria monocytogenes in terms of how they survive and spread in food products?","answer":"E. coli 0157:H7 and Listeria monocytogenes have different survival characteristics in food products. E. coli can survive in various foods including beef, chicken, apple cider, melons, salad vegetables and milk, but notably cannot survive in mayonnaise. It can survive for 7-11 weeks depending on temperature, with longer survival at lower temperatures. Listeria monocytogenes, on the other hand, is particularly hardy - it can grow in canned foods and at temperatures as low as 3°C, and is resistant to both dehydration and temperature extremes. It is commonly found in raw milk, soft-ripened cheeses, raw meats, and raw/smoked fish.","context":["By Eric Sideman\nA very interesting and biologically correct way of looking at your body is that the contents of your digestive tract are outside of your body. The tract is a plumbing system passing through in which food is put and digested and only nutrients are absorbed through the stomach and intestinal walls into your body. This view is important for understanding that you can eat a lot of very bad things and get away with it, if they are not absorbed into your body. This system of external defense does not always work, however, because some chemicals can be absorbed. Some of these chemicals are produced by organisms that can live in the digestive system.\nThe digestive system is not clean. Many organisms live there very happily feeding on the vast amount of good things pushed through on a regular basis. Most of these are harmless, many are actually beneficial. The most common inhabitant of the digestive tract of warm blooded animals is a bacterium called Escherichia coli. About 100 strains of E. coli are carried around in animals. Most are benign. In fact, the normal ones metabolize nutrients in the intestine and produce many beneficial metabolites that are released into the intestinal contents and absorbed and contribute to the host’s health. For example, E. coli produces vitamin K and colicins, which inhibit other microorganisms and protect the host from other infections.\nBut all strains of E. coli are not benign. A very dangerous strain, first found in a human in 1975, is now becoming more prevalent. It is called E. coli 0157:H7 and accounts for a great deal of illness and even some deaths each year. E. coli 0157:H7 can live without causing any symptoms in otherwise healthy animals, such as cows, but if humans ingest the organism they usually regret it.\nThe first outbreak of disease caused by E. coli 0157:H7, in 1982, was associated with consumption of ground beef. Since then the pathogen has been transmitted via all sorts of food (see table). The majority of outbreaks have been via foods of bovine origin, most commonly ground beef. However, recent large outbreaks have implicated apple cider, lettuce and other salad greens, and contaminated water.\nTracing the implicated produce to their point of origin and finding the site of contamination is often a very difficult task taken on by the Federal Center for Disease Control and state departments of health. It is particularly difficult when the items are purchased from large retail chains. Potential points of contamination become numerous and include the farm, transportation, warehouses, distributors, retail stores and home. By the time investigators reach a suspected point of contamination, no contaminated food may remain. The large number of outbreaks and the varying points of contamination highlight the need to emphasize food safety at each step in the food handling chain, including the farm.\nE. coli 0157H:7 produces one or both of two antigenically distinct toxins referred to as verotoxins 1 and 2 and also as shiga-like toxins I and II. As the bacteria grow on substrate, the toxin builds up and people can either become ill from ingesting toxin on food or from ingesting the bacteria, which then live and grow in the digestive tract and produce toxin.\nSymptoms are diarrhea, often bloody, and abdominal cramps. Fever is low grade or absent. Symptoms usually appear two to eight days after exposure and usually resolve on their own in several days. Children, the elderly and the immune compromised can suffer much worse. They can develop hemolytic uremic syndrome, HUS, which is a serious disease that affects the kidneys and blood clotting system. Most people recover but a prolonged hospital stay is often required. Some people die. There is no evidence that antibiotic treatment is helpful for infections.\nWhere Is It, How Long Does It Survive, How Does It Spread?\nE. coli 0157:H7 lives in the digestive tract of animals. It has been shown to be carried by cows, sheep, chickens, pigs and deer. I have even seen reports that wild birds can carry it, but I can find no one who knows the source of those reports. The animals usually appear normal, healthy. Mahmoud El-Begearmi, Food Safety Specialist with Cooperative Extension, told me that since the normal strains of E.coli live in all warm blooded animals, the assumption should be that 0157:H7 can too, so I would add horses to the list of farm animals, but I can find no report of horses as carriers. I asked Mahmoud about healthy people as carriers and he said, “That is a good question.”\nFood becomes contaminated by coming in contact with manure. If intestinal contents contact meat during slaughter, contamination occurs. Grinding meat mixes surface contaminated sections with the rest so that whole lots may become contaminated. Anything that contacts the manure can become contaminated and anything that contacts contaminated meat can in turn become contaminated. Such cross contamination during food preparation occurred in the Georgia/Tennessee outbreak. Meat in a fast food chain was the point source, even though it was well cooked. It had indirectly contaminated other items, such as hamburger buns, when raw through employees handling food. Infected people can spread the disease by not washing their hands well after going to the bathroom.\nThe bacteria can be carried wherever the manure goes. Infected livestock intermittently shed E. coli 0157:H7 in their manure. The manure can contaminate food items such as milk, vegetables, fruit and water when it comes in contact. Manure deposited in pastures, orchards or crop fields by grazing livestock may contaminate produce. Manure used as a soil amendment may contaminate crops in contact with it.\nStudies of survival of the bacteria in manure show the importance of proper manure management in crop production. A study of the fate of E. coli 0157:H7 in bovine feces showed that populations increase during the first three days and then decrease. The decrease is more rapid at higher temperature, perhaps associated with dehydration of the feces. The pathogen survived seven to eight weeks at 37° C, eight to nine weeks at 22° C, and 10 to11 weeks at 5° C. This study has important implications for the use of manure and manure tea in the production of vegetables and fruit (see recommendations below).\nFarm studies have shown varying frequencies of isolation of E. coli 0157:H7 from livestock. A recent study in 14 states in the United States revealed 22% of control herds carried it while 50% of herds implicated in cases carried it. Studies in England showed 4% of herds carrying E. coli 0157:H7. The prevalence increases in the summer in both sheep and cattle, as does a correlated higher incidence of human infection.\nPoorly managed cattle that are subjected to dietary stress may carry unusually high numbers of E. coli 0157:H7. When animals are deprived of feed or feed is offered only intermittently, such as during transport to the butcher, the normal rumen microorganisms are not as active as they would be under everyday conditions of digestion. Normal microbial activity keeps the bad bugs at bay, according to Mark Rasmussen, an Agricultural Research Service Veterinary Medical Officer.\nThe survival and growth of E. coli has been studied on many substrates. Store surveys have isolated E. coli 0157:H7 in all sorts of food, including beef, chicken, turkey, pork, apple cider, melons, salad vegetables and milk. Oddly enough it was shown to be unable to survive in mayonnaise, but it has been shown to survive in acidic foods, such apple cider.\nEvidence is mounting that populations quickly adapt to acidic conditions. Cultures for one to two doublings at a pH of 5 showed increased survival in acidic foods such as salami (pH 5.0) or apple cider (pH 3.4) compared with the original populations. Such laboratory studies highlight the need to consider adaptation when questioning the survival of the bacteria in what may be considered stressful environments.\nMany recommendations are surfacing. Food safety concerns us all, especially farmers with a commitment to organic production. All farmers must help to alleviate the problem before harsh regulations such as pasteurization are imposed and ruin some foods. Some people are calling for pasteurization of apple cider, which would leave it tasting more like sugar water than a natural fruit juice. Even though only a very small proportion of food has been shown to be contaminated, the seriousness of the disease highlights the need for farmers and consumers to take precautions to avoid spreading the pathogen.\nRegulations should be directed toward keeping the produce clean and toward cleaning rather than pasteurizing. Pasteurization changes the flavor and reduces nutrition, and the high cost of the equipment is likely to put many farms and orchards out of business. Michael Phillips of Lost Nation Cider Mill in Lancaster, N.H., says the little orchards aren’t going to be able to afford it. Jim Schupp at Highmoore Farm has instructions for cleaning apple drops before cider is made. You can get them from him or me or any Extension office.\nUsing tree harvested apples, as opposed to drops, may help to ensure more confidence in the safety of fresh apple cider. On the other hand, most orchards make cider from their drops. If drops are used, harvesting should be done with careful inspection to ensure that only clean fruit are picked up. Cornell Extension recommends that if orchards are frequented by large flocks of starlings or other roosting birds, soiled fruit should not be used in unpasteurized cider. All fruit should be subjected to extensive brush washing to ensure removal of any adhering material. Fruit should be spray rinsed with high pressure, clean water sprays.\nGrowers should avoid washing methods that may increase contamination. Crisping lettuce, a common practice in retail stores, is an example of a scary practice. It involves submerging lettuce in a basin of tepid water followed by refrigeration. The water is infrequently changed or recirculated and numerous cartons of lettuce are bathed in the same water. This practice is likely to spread rather than remove the pathogen. Lynn Byczynski, editor of Growing for Market, reported that growers are developing new washing recommendation for salad growers. She will report them in GFM and I will pass them on to you.\nAny growers who use manure on their farms should take extra precautions. Pay attention to the guidelines in MOFGA’s Organic Certification Program. We do not permit manure or manure tea on root crops within 120 days of harvest and within 60 days of harvest of any crop.\nThe safest way to handle manure is to compost it. Studies have shown that E. coli 0157:H7 does not survive the composting process, but it is very important to note that the compost must be managed to get hot. In studies, at least two turnings were necessary to kill all of the pathogen. Piles that did not heat or that were not mixed well still carried the pathogen. If a grower uses manure in a compost pile it should be managed to heat, or the compost should not be used for at least 120 days, or the compost should be used only were there is no risk of contamination of food.\nJames Martin at the Maine Department of Health and Human Services points out that washing fruits and vegetables is very important and always has been. E.coli 0157:H7 is only one of many food-borne pathogens, such as Shigella, Salmonella and Listeria. All produce should be washed, including a rinse with fresh running water, whether a known risk of E. coli 0157:H7 contamination exists or not.\nEric is MOFGA’s director of technical services. You can direct your questions to him at the MOFGA office.","Food poisoning and the cytoskeleton German Research Center for Biotechnology\nListeriosis • Symptoms • Influenza-like early on • The infection quickly progresses to cause… • septicemia • meningitis and encephalitis • intrauterine or cervical infections in pregnant women, which may result in spontaneous abortion • Prevalence • 2500 cases of listeriosis in the US each year, with about 500 deaths\nTransmission • Normally orally through contaminated food • Many animals carry the bacterium without symptoms • L. monocytogenes has been associated with raw foods • raw milk • soft-ripened cheeses • raw meats • raw and smoked fish • It can grow in cans and at temperatures as low as 3°C • It is resistant to dehydration and temperature extremes\nListeria lifecycle: an intracellular pathogen • Phagocytosis by monocytes • Lysis of phagosome • Proliferation in the cytoplasm • Locomotion • Cell-cell spread through filopodia • What survival advantage does this life cycle afford Listeria? http://www.med.ufl.edu/biochem/DLPURICH/Listeria.html http://www.med.sc.edu:85/ghaffar/zoonoses.htm\nListeria life history http://cmgm.stanford.edu/theriot/movies.htm\nCytoskeleton • The cell interior is highly ordered as a result of the cytoskeleton. • The cytoskeleton is a filamentous network of protiens that pervades the cytoplasm • The protein filaments consist of protein monomers that self-assemble into the final structure, and can dissociate to destroy that structure. • In general, these filaments are highly dynamic - they are not permanent or static structures.\nThree filament types • Intermediate filaments • Microtubules • Microfilaments (actin filaments)\nIntermediate filaments • 8-12 nm in diameter (intermediate between microtubules and actin) • The most stable and least dynamic of the filaments • Filaments are not polarized • Six different related classes • These include • Nuclear lamins • Keratins, which make up the tonofilaments of epithelia • Thought to serve a strengthening and stabilizing role in cells\nMicrotubules • Tubes made of α- and β-tubulin • Exist in vivo as heterodimers • Form protofilaments, which circularize in groups of 13 (usually) • One end is all alpha (+ end), the other all beta (- end)… that is, they are polarized • In cells, growth occurs preferentially at the + end • Mechanically analogous to rigid rods\nCritical concentration, Cc, is the monomer concentration at which the rate of monomer addition equals the rate of monomer loss from one end of the filament. Chemistry of polymerization\n…but in a cell… • Microtubules are nucleated by microtubule organizingcenters (MTOCs) • The centrosome is an example of a MTOC • MTOCs contain microtubule structuresthat form stable (-) endsfor growing microtubules • Contain γ-tubulinwhich may stabilize these nascent microtubules\n…and microtubules are GTPases • Tubulin dimers bind GTP • Tubulin-GTP adds to the (+) end of the filament with a lower Cc than [tubulin]. • Once in the microtubule, the GTP is almost immediately hydrolyzed, leaving a GTP cap on the (+) end. • If the cap is lost, Cc for the (+) end is suddenly higher than [tubulin], and the microtubule catastrophically disassembles.\nHandy poisons • Many chemotherapeutic drugs are antimitotics (shut down mitosis) • vinblastine causes tubulin aggregation • nocodazole caps microtubules so that they can’t grow • taxol stabilizes microtubules, blocking complete celldivision\n“Super Pot” • Made using colchicine • from the Autumn Crocus (a lavender) • causes disassembly of microtubules • Sometimes used to enhance the potency of marijuana • Causes some chromosomes to not always be evenly divided between daughter cells • Causes some cells to become polyploid • induces overexpression of genes. FYI: The “cannabinoid receptor” in the brain normally binds an arachidonic acid derivative, anandamide.\nMicrotubule-based motors • Two major kinds: • Kinesins (most are plus-end directed) • Dyneins (minus-end directed) • Both have motor domains (heads) and cargo-binding domains (tails) • Dyneins are of two kinds • Cytoplasmic – cargo transport • Axonemal – ciliary and flagellar motion\nWhy do you need transporters anyway? • Otherwise you would rely on diffusion • The distance traveled by diffusion is not linearly related to time!\nHow long does it take to diffuse? • For a sphere… • “Stokes-Einstein equation” • kB = Boltzmann constant (1.38x10-23 J Kº) • T = Absolute temperature • η = viscosity of the medium (0.001 for water in SI units) • r = radius of the sphere • n= “dimensionality” (1D, 2D or 3D) • Example: How long would it take for a ribosome to diffuse down the length of a 1m axon?\nActin (microfilaments) • Over 5% of the intracellular protein • The most ubiquitous of all intracellular proteins • Functions • Cell motility and muscle contraction • Cell shape (like microvilli) • Vesicle transport near cell periphery\nActin filaments • Actin monomers stack to form a double-helical filament, 7 nm in width • While microtubules are GTPases, actin filaments are ATPases\nActin polymerization • The + end grows faster than the – end • Like microtubules, the + end has a lower critical concentration than the – end, and… • This difference is accentuated when monomers have ATP bound, as opposed to ADP. • Once in the filament, the rate of ATP hydrolysis increases • As a result, the + end has predominently ATP-monomers, and the – end ADP-monomers + end - end Actin monomers\nWhat will happen to filament length if… • The concentration of monomers is greater than the CCs at both ends of the filament? • The concentration of monomers is lower than the CCs at both ends of the filament? • The concentration of monomers is greater than CC at the + end but lower than CC at the – end?\nTreadmilling + end - end Actin-ADP Actin-ATP\nNot-so-mellow mushrooms • Phallotoxin (phalloidin) • an actin filament stabilizer • the poison in some mushroom genera • It kills by stabilizing actin filaments (inhibiting disassembly) • Immediate cause of death is liver failure • Cytochalasin • an actin filament de-stabilizer • also derived from mushrooms Death Cup mushroom\nMyosins: actin-based motors • With few exceptions, plus-end directed • Myosins have heads that serve the motor-function, and tails that either: • Form filaments, as in muscle • Bind cargo, like kinesins and dynein\nControlling filament growth Thymosin is a monomer buffer Profilin is a shuttle, and promotes nucleotide exchange\nCell crawling • Lamellipodia and pseudopodia are pushed forward by actin polymerization and other forces • How does a cancer cell or leukocyte crawl “in the right direction,” like towards a cytokine?\nNucleation and branching: Arp2/3 and WASP • Arp2/3 is a very important for making branch points on actin filaments, and nucleating new filament growth • WASP is a key activator of Arp2/3 that is itself activated by cell-surface receptors.\nListeria lifecycle: an intracellular pathogen • Phagocytosis • Lysis of phagosome • Proliferation in the cytoplasm • Locomotion • Cell-cell spread through filopodia • How does Listeria accomplish cell-cell spread? http://www.med.ufl.edu/biochem/DLPURICH/Listeria.html\nStealing the machinery • Listeria has on its surface the protein ActA • ActArecruitsArp2/3 from the cytoplasm and activates it (basically substituting for WASP) • Promotes actin filament nucleation and growth Listeria\nVisualizing the actin http://cmgm.stanford.edu/theriot/movies.htm"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:bf80cb0d-9eca-455a-ab8f-76a786b366c4>","<urn:uuid:9a7dcc11-583c-4c5f-b2a8-71aaa2ee9c21>"],"error":null}