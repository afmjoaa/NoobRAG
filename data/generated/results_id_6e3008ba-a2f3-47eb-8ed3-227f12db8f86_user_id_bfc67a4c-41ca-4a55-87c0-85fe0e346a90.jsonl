{"question":"Between Rassuen and Dijon, which city has more historical connections to industry and manufacturing?","answer":"Rassuen has stronger historical industrial ties through its soda and chemical plant built in 1808. The plant was integral to the district's development, employing 500 workers and producing sodium carbonate and sulfate for the entire region until its closure in 1988. In contrast, while Dijon is described as a culturally rich city with medieval and Renaissance heritage, there is no significant mention of industrial or manufacturing history in its description.","context":["HBM (low-rental housing)\nHBM (low-rental housing on Bouvlevard Frédéric Mistral): classified “Patrimoine du XXème siècle” (20th century heritage). “Habitations Bon Marché” (low-rental housing), built under the Loucheur Act, was constructed in 1930 and is the model for today’s HLM (low-income housing).\nIn 1932, the Loucheur Act was passed allowing the construction of 200,000 apartments and offering affordable loans to private individuals. It is within this context that F. Clermont and A. Bossu were in charge of building all HBM (low-rental housing) in Istres.\nMade up of 84 double-oriented flats spread over 4 floors, this building is famous for its layout, which runs Boulevard Frédéric Mistral, following the curve of the historic centre’s ancient fortification. The façade consists of a single block, as if 8 main buildings had been pushed together and connected by hidden stairwells. No ornament or design interrupts the rhythm of the facade: the only creativity allowed was a darker coating on the ground floor, differentiating it from the other brighter floors. An archway was constructed at the very centre, leading to a beautiful courtyard decorated with a fountain and creating a pleasant area that is necessary for group housing.\nIt is a unique neighbourhood with original housing, representing our beautiful town.\nOld Istres was built on a bank of limestone abundant in fossilised oysters. It consisted of a large hill with an oval 250m x 188m base that stretched from the north to the south, dominated by a large central eminence measuring 30 metres above sea level. It was a city perched on a rocky hilltop with rural Mediterranean-style houses.\nHouses were built starting from the central castle and followed a concentric zone model. The city seemed to have reached its final size rather early since the outer wall was completed in 1379.\nIn the 16th century, Upper Istres was already in “ruins”. Having experienced a local economic growth during the 16th and 17th centuries, Istres started to expand and rebuild its entire area: most of the houses were constructed between the 16th and 18th centuries.\nThe outer wall, although partly falling into ruins and opened up for new passages into different neighbourhoods, apparently survived until the 18th century. Old Istres features several beautiful bourgeois homes; however, it is mainly a town of country dwellers. The angled walls and street corners remind us of this old farm town where carts had to be able to turn easily. Niches mark the Catholic fervour of Provence that was present up until the 19th century. In addition to farmers, many craftsmen and shopkeepers contributed to the life of Old Istres. Certain street names reflected specific trades (“Fabre”, blacksmith in Provençal, which comes from the Latin word “faber” meaning “craftsman”, is the origin of the famous street called “Rue des Fabre”) as well as lawyers, solicitors, schoolmasters, clergymen, children, the elderly, etc. An entire colourful world animated the streets of Istres during the Old Regime.\nToday, the old centre is brought to life by the homes of Old Istres that have created an active and dynamic partnership, organizing many events.\nIn addition, tours of the old centre, a witness of our town’s historical past and development, are organised by the Tourist Office. You can visit it in a fun and entertaining way, with new unusual tours of the old centre during summer, by yourself with our “Istres, à travers son histoire” (Istres Throughout Its History) brochure, or with a tour guide by request.\nEntressen is an area of Istres included in the Canton d'Istres Nord region. It was Initially an independent town; however, that is no longer the case today. Nevertheless, this area of Istres still has its own postal code and local festivities.\nOccupied during the Protohistoric period until the Late Antiquity, the town at the time was considered an oasis in the Crau: the pond and green areas were used as a place to rest. Around 200 years B.C., the Greeks built a large number of villas. Then, it was the Romans’ turn to enjoy this beautiful green area and spring. An ancient path crossing Entressen on the route from Arles to Martiques proves the presence of the Romans. Later, Entressen also became a key point over which Arles and Istres often argued.\nFrom the 19th century, Entressen began to evolve, starting with the Avignon-Marseille railway, which is no longer in use today. Construction in the early 20th century and expansion of the air force base dramatically increased the city’s population. Entressen was once known for its typical Provençal farmhouses. These large houses were originally owned by people from Marseille and often used as hunting estates. With all of the changes that have been mentioned, Entressen has increased its population by 10. Today, there are nearly 5,000 inhabitants.\nMany festive events take place every year such as the traditional “Fête du Foin” (Hay Festival) and “Fêtes d'Entressen” (Festivals of Entressen).\nRANQUET AND HEURES CLAIRES\nThe areas of Heures Claires and Ranquet, built at the edge of the Étang de Berre, are made up of “cabanon” (small Provençal cabins) constructed to create a pleasant atmosphere and enjoy nature (fishing, swimming, lazing about, etc.). They were popular holiday spots where the “cabannoniers” lived according the theory: “Fai pas bon travaia quand la cigalo canto”* (*It’s not good to work when the cicada chirps)\nFamous for its harbour, water sports centre and Saint Martin spring, the area of Heures Claires is perfect for talking pleasant strolls and swimming.\nOrganised by the city and the CIQ of Heures Claires, the “Fête du port” (Harbour Festival) and “Fête de l’eau” (Water Festival) occurring in late June are great examples of the dynamism of this typical area of Istres.\nNestled in a small green cove, 3km from Istres in the direction of Martigues, Ranquet has a small beach and the typical charm of a village with quaint cottages.\nA supervised beach enables visitors to safely relish in the joys of swimming and includes a free car park, shower, WC, water fountain, floating pontoon and access to a bar restaurant that leads directly to the beach.\nDuring summer, you can also enjoy the “Fêtes du Ranquet” (Festival of Ranquet) in mid-August and the city’s jazz festival in late July.\nThe “district” of Rassuen was created at the same time as its soda and chemical plant, built in 1808 on the saline of Rassuen, and fed by the Étang de Lavalduc. The directors of the factory then created the town around this plant and financially took care of all of the equipment and facilities necessary for the life of a half thousand people. It was also around this factory that the district and city would eventually grow and develop.\nThus in 1850, a chapel and primary school were financed and built by the manager of the plant at the time, Jean Jacques Prat, who eventually became mayor of the town in 1854 until 1860.\nRassuen’s railway station was founded in 1875 and is still used today. It is used to send the production of by-products manufactured by the plant such as sodium carbonate, sulphate, etc. to the entire region and especially to northern France.\nIn 1986, as a result of relocation, manufacturing was gradually brought to a halt. The 500 employees, of which over half were foreigners, were steadily laid off. In the absence of activity, the plant closed in 1988 and wascleaned up by the Produits Chimiques du Midi Company in 1999.\nAlongside the history of this plant that marked the creation and development of the district of Rassuen, other infrastructures were gradually set up near this old 190 year-old industrial wasteland. The covered bowling pitch was opened in 1986 where regional tournaments occurred ten years later. In 1998, the local council set up a cultural area with a Concert Café known as “L'Usine”, designed by the architect Frédérik Rill, where several regional activities take place.\nToday, the “Fêtes de Rassuen” (Festivals of Rassuen) and a variety of competitions and events that take place near the bowling pitch animate this neighbourhood, which marked the growth of the town.\nLocated 5km from Istres on Route de Miramas, the Domaine de Sulauze is a private estate situated in a beautiful green setting between vineyards and scrubland. This unique estate stretches to the Étang de l’Olivier over 650ha.\nPart of the estate is used to raise Spanish fighting bulls and grow “foin de crau” (special AOC hay) while the other part is dedicated to winegrowing and the production of AOC Côteaux d’Aix wine. A brasserie was also recently set up on the estate.\nThe annual “Fête des Bergers” (Shepherds’ Festival) partly takes place at the Domaine de Sulauze in early December for the mass celebrated in the Provençal language, the blessing of the horses and the hot wine offered by the owner of the wine cellar. Ferrades (bull branding) and young cow races are organised for groups in the estate’s arenas.\nToday, tours of the wine cellar and the estate’s bamboo garden are also organized by the Tourist Office as part of the “Un Eté à Istres” (A Summer in Istres) operation.","Dijon is one of France’s most appealing cities. Filled with culture and heritage, it is a city that holds character and charm. From medieval to Renaissance buildings, it is a centre for historic stories. As a well connected city, there is so much to explore and see. Home to the traditional mustard, Dijon is a culturally rich visit. As the capital city of the Burgundy region, there are lots of attractions to see.\nBefore visiting any town or city make sure you know the basics. General details and important information.\n- Emergency Services: 112\n- Language: French\n- Currency: Euro\n- Country Code: FR\n- Travel Visa: None required\n- Population: 155,114\nResearching various official sources, we perceive the risk to holiday makers and travellers are as follows;\nTop travel advice and interesting tip bits of information from experienced travellers.\nFor the Emergency services just dial 112 from any phone.\nHospitals in Dijon\nAs a city, Dijon has well connecting transportation. Despite not being in the area of a major airport, the city is still accessible. Train is a perfect way to travel around the city, with high-speed trains (TGV) connecting lines to neighbouring cities. Car is another transport option, being easily accessible from Paris and Lyon.\nHow do I keep up with the local news?\nWhat are some safety tips I should know?\nKeep your bag across your shoulders to prevent a thief snatching it and where possible avoid flashing expensive items and cash.\nTravel insurance is a good thing to have, just in case of any incidents.\nWhat are the common crimes?\nAs with most popular European cities, tourists should be careful of pickpockets and petty thieves especially around major tourist sites and travel hubs.\nAre there any areas to avoid?\nCentral Dijon is very safe but riding the new tram to outlying suburbs is less advisable.\nImprove Your Personal Safety\nKnowledge – the more you have the better equipped you are.\nAwareness – the more you see the safer you become.\nResponse – the right reaction can change a situation.\nEvery culture has its customs and traditions, they have been handed down the generations and are always held in high regards by the local residents.\nAn international show devoted to Horticulture and Landscaping. The show takes place every five years since 1980 and gathers many thousands of visitors. The exhibitor categories are Ornamental horticulture, flowers, bonsai, cut flowers and orchid and these are displayed in the Parc des Expositions, which is transformed into a tropical paradise.\nFestive days in Fountain Ouche\nThis is a month of festivities in Dijon open for everyone to enjoy. The festivals aim is to promote social cohesion through culture and celebrate a festive time of sharing and meeting with people. For 3 weeks in summer the area enjoys events, shows, theatre, circuses and concerts which culminate in the Parade Metis, where over size animals visit Fountain Ouche and the evening ends with a dance.\nAnnual events allow a city come together for some amazing experiences. If visiting at this time, make sure you have your accommodation booked and are always aware of your surroundings when travelling around.\nDijon International Gastronomic Fair\nHeld each year for the first 2 weeks of November, the fair includes more than 500 exhibitors and receives more than 200,000 visitors. With hundreds of booths by both amateur and professional cooks, new products in the field of food and wine and lots of delicious things to try, this fair is a popular event. There are also cooking demonstrations for those interested in learning new cooking tips, while sampling the professionally prepared food. Each year, the organisers of the fair invite one foreign country to add a touch of exotic to the festivities and add interest to this food event in Dijon.\nGolden Age Grand Prix\nThe Grand Prix de l’Age d’Or is one of the longest surviving races in France. Currently it is held at the historic Dijon Prenois where you can watch the historic racing taking place. In 1964 Serge Pozzoli and Jacques Potherat, with a handful of enthusiasts started the Cups Golden cup, the first competition gathering of old cars. Renamed the Golden Age Grand Prix this historic event continues and is one of the most well known in France and Europe.\nCoupes Moto Légende\nHeld annually at the Prenois Race Circuit 20km north of Dijon in late May or early June, is one of the largest classic motorcycling events of its type in Europe. Attracting up to 30,000 spectators and participants from all over Europe the event allows over 1000 members of the general public to take their old motorcycles out on track for up to three 15 minute sessions over the weekend of the event. These old bikes are categorised into different classes from pre 1930 through to the “superbikes” of the early 1980s and range from the simplest road going machines to famous ex- works racers.\nWhat are the main attractions?\nPlace François Rude\nAlso known as Bareuzai Square, it is the central point in the medieval centre of Dijon. The surrounding streets are pedestrian areas and it is a very pleasant place to take a historic stroll, or enjoy a drink. Its architecture is a mixture of medieval and Renaissance and in the centre is a fountain. A bronze statue of the child Bareuzai can be found in the square, squeezing grapes to make wine, as Dijon is the second most important town in this wine region.\nThe park features carved stone balustraded terraces, sequences of waterfalls, ornamental planting and children’s play areas. There is also a large stone bear who greets you at the entrance, which is a copy of a sculpture by Henri Martinet. It is a haven of rest very popular with Dijon locals and many tourists.\nThe Owl of Dijon\nIn the Rue de la Chouette, a pedestrian path along the north side of the Notre Dam, at the corner of a buttress of a chapel is carved a bird that Dijonnais call the owl . Its original meaning is not known. The owl is very worn due to the superstition it raises, where Dijon locals and tourists lift their left hand and stroke the owl asking for a wish to be fulfilled. Adopted by the town as an emblem, little gold owls are embedded in the pavement showing tourist routes.\nAre there any historic attractions?\nThe Well of Moses\nA masterpiece monumental sculpture of the Dutch artist Claus Sluter in 1395. The style has Gothic grandeur combined with a European realism, but on a monumental scale rarely seen. It consists of a large crucifixion scene of a tall cross surmounting a hexagonal base, which was surrounded by the figures of the six prophets who had foreseen the death of Christ (Moses, David, Jeremiah, Zachariah, Daniel and Isaiah). The work was damaged in 1791, during the French Revolution and only fragments of the Crucifixion scene survive, which are now housed in the Musée Archéologique in Dijon.\nThe Palace of the Dukes of Burgundy is a well preserved historic palace in Dijon. The oldest part is from the 14th and 15th century Gothic Ducal Palace and seat of the Dukes of Burgundy. Today, the palace is still part of Dijon politics with the Mayor of Dijon’s office within. It’s also a museum with the ground floor dedicated to the palace’s and Dijon’s history and the east wing containing the Musee des Beaux-Arts, one of the Frances premier art museums.\nCathedral of Saint Benignus of Dijon\nTo the west of the Ducal palace the twin-towered Cathédrale St. Bénigne stands in Gothic majesty. This large church is the seat of the Archbishopric of Dijon, and is a French national monument. Originally a Benedictine abbey, the cathedral is the product of a many reconstructions over its 1,500 year history. Today, in addition to being a national monument, the church is as a museum with primarily Roman and medieval artifacts.\nMusée de la Vie Bourguignonne\nThis is situated in the cloister of a former Bernardine convent building and houses a collection to display every day life of rural and urban people in Dijon, from the 18C to the 20C. The Museum is over three floors. The ground floor has exhibits covering rural life of Burgundy in the late 1800s, the 1st floor shows daily life in Dijon from the late 1700s until the 2nd World War and the 2nd floor has a reading room and library as well as audio visual displays.\nWhere else is good to visit?\nThe lake covers 37 hectares with a beach of 3000 m2 and more than 30 hectares of grass, shrubs and trees. Built in 1964, safer dreams of Canon Félix Kir who was a mayor of Dijon from 1945 to 1968. Today the lake is a much loved leisure site and area of natural beauty inhabited by swans and duck who joined in the winter by seagulls and coots. There are leisure activities here with a swimming area, sailing area, canoe and windsurfing centre, volley-ball, table tennis, mini-golf, tennis, and extensive playgrounds. A railway line runs alongside the lake and there is a statue of the Grenadier, from Dijon sculptor Georges Diebolt.\nThe municipality of Dijon decided to build this iron lattice covered market in 1873. The plans were prepared by Gustave Eiffel, a native son of Dijon and architect of the city and the building was completed by engineer Clement Weinberger. The structure is a series of ironwork arches and columns, with capitals decorated with tendrils of vine. The cross pieces of the great arches are decorated with heads of deer, sheep, wild boar and game. The roof is much inspired by that of the halls of Paris. The central market open until 1 pm on Tuesdays, Fridays and Saturdays and Thursdays for food stalls."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:94d594b5-57cb-4b28-8645-b07a3a0a2d99>","<urn:uuid:cff818c2-955f-4270-9119-cae103aaa98d>"],"error":null}
{"question":"What are the traditional offerings to Lord Ganesha, and how does modern family time differ from past practices?","answer":"Traditionally, Modaks are the main sweet offering to Lord Ganesha - these sweets are particularly dear to him and are offered by thousands of worshippers. The word Modakam in Sanskrit means that which gives joy and pleasure. In contrast, modern family time has changed significantly - observations show that when families gather, such as in restaurants, everyone typically pulls out mobile devices instead of communicating with each other. While experts note that family time can contribute to less depression, better academic performance, and happier children, this quality time is being compromised by increased screen time and media use.","context":["I meditate upon the supreme Ganapati who is worshipped by Vasishta, the Vamadevas, etc. He is the son of Lord Shiva, is praised by Guruguha. He shines bright like millions of cupids. He is tranquil. He loves great poetry, drama, etc. He loves the sweet Modaka. His mount is a mouse.\nHappy Vinayaka Chaturthi to all ! Today is the most important day for the worshippers of Vinayaka, also known as Ganapathi, Ganesha, Vigneshwara etc. The beloved elephant headed God is worshipped all-over India but is especially beloved to the people of Maharashtra and South India. An ancient God, there are indications that He was worshipped as early as in 1200 BC.\nवक्रकुण्ड महाकाय कोटि सूर्य समप्रभ |\nनिर्विघ्नं कुरु म देव शुभ कार्येषु सर्वदा ||\nThus I pray every morning :\n“You of the twisted trunk and massive body with the dazzle of millions of suns, Lead me Lord on a path that has no obstacles or hindrances in all my good endeavours”.\nGanapathi is worshipped in 32 different forms such as Bala Ganapathi (child God), Veera Ganapathi (Warrior God), Siddhi Ganapathi (God of Achievement) etc. My personal favourite, given my love of music and dance, is Nritya Ganapathi (the Dancing God), whose picture adorns today’s post. Much as the rotund form of Ganesha is beloved to us, today we should look beyond the obvious into the symbolism of this form.\nHis large and rounded body denotes the entire universe. He is the embodiment of all.\nThe Elephant, which is a vegetarian and doesn’t kill to eat, signifies gentle strength. An elephant also responds to love and affection as God will respond to our love.\nThe large head symbolises wisdom. The large ears sift truths from untruths.\nThe curved trunk denotes the primal sound, the mystic OM. This symbol in Sanskrit ॐ resembles an elephant and his trunk; the Tamil ஓ resembles the head and trunk.\nThe trunk also is a symbol of discrimination – the same trunk has the strength to pull up a tree or pick delicately at the smallest of things.\nThe great stomach symbolises that Ganesha swallows the sorrows of the universe and protects the world.\nThe mouse which is underfoot symbolises the petty desires and ego of man which needs to be vanquished.\nGanesha is shown to hold different items in his hands, about 40 different ones being common. Each represents an attribute. In the picture above, one hand in the Abhaya pose says ‘Don’t fear, I am here’.\nA hand holds the double headed axe to symbolise his destruction of impediments and evil.\nA hand holds the lotus flower, which indicates purity as the flower grows unsullied even in the dirtiest of ponds.\nThe fourth hand holds Modaks, the sweet dear to Him. Today thousands of worshippers will offer these sweets to their dear deity. Modakam in Sanskrit means that which gives joy and pleasure (Moda); just as this sweet gives us joy, Ganesh too blesses us with joy.\nIn honour of Ganapathi, I present the short invocation Maha Ganapathim Manasa Smarami (I meditate on the great Ganapathi) written by Muthuswami Dikshithar (1775-1835) and set to raga Natta (to know more about this raga, click here). This familiar and well-loved song is very often sung at the start of Carnatic Music concerts, as all good tasks should be started by invoking His name.\nTo present this song, let us start with the gentle voice of Yesudas singing in the film Sindhu Bhairavi.\nFor an instrumental version, listen to U.Srinivas on the Mandolin here .\nLastly, listen to this vocal version by the Maestro Maharajapuram Santhanam :\nWhich one do you like best?\nFootnote (Lyrics) :\nLanguage : Sanskrit\nमहा गणपतिं मनसा स्मरामि\nवसिष्ट वामदेवादि वन्दित ||\nमार कोटि प्रकाशं शान्तं\nमहाकाव्य नाटकादि प्रियं\nमूषिक वाहन मोदक प्रियं\nA notation is available in this site.\nmahA gaNapatim manasA smarAmi\nvasishTa vAmadEvAdi vandita\nmahA dEva sutam guruguha nutam\nmAra kOTi prakAsham shAntam\nmahA kAvya nATakAdi priyam\nmUshika vAhana mOdaka priyam\nI meditate (smarAmi) on the supreme (mahA) Ganapati who is worshipped (vandita) by Vasishta, the Vamadevas, etc (Adi). He, the son (sutam) of Lord Shiva (mahAdEvA), is praised (nutam) by Guruguha. He shines bright (prakAsham) like millions (kOti) of cupids (mAra). He is tranquil (shAntam). He loves (priyam) great poetry (mahA kAvya), drama (nAtaka), etc (Adi). He loves (priyam) the sweet Modaka. His mount (vAhanam) is a mouse (mUshika).","Hansa Bhargava MD FAAP\nStaff Physician, Children's Healthcare of Atlanta\nMedical Editor, WebMD\nPediatricians are seeing more and more teens suffering from stress. Whether they are complaining of it or having somatic symptoms such as headaches and stomach aches, it seems that stress and anxiety are on the rise. We know that over scheduling, homework, and the pressures of getting into college can contribute to this. But can media also affect it? Is screen time and media a stressor or a remedy for stress?\nIn a recent WebMD survey published in their Teens and Stress report, 54% of teens were stressed according to parents. Interestingly, 40% of parents turned to the screen for family stress relief while 58% of teens did. Social media and texting was used as stress relief by almost half the teens. This is on the heels of the Common Sense Media survey reporting that US teens were using media for 9 hours a day. Other recent reports have shown that 94% of teens with mobile devices are online daily with many online constantly.\nSo it seems that stress is on the rise and media use is on the rise. Although there may not be a direct relationship, some real issues impact stress and anxiety. Consider this: 23 % of teens report cyberbullying, especially girls. There have been reports of “Facebook depression” and loneliness, as kids who aren’t in social media conversations may feel left out. Other negative consequences can also have an impact: many teens are in front of a screen late at night or ‘sleep text’, both of which can contribute to lack of sleep, which in turn can decrease focus and potentially cause irritability and depression. And last but certainly not least, what about the time media consumes?\nTime spent on media is time often not spent communicating with family. Lately, when I’ve gone into a restaurant, I’ve observed that as soon as a family sits down, everyone pulls out a mobile device. No one is really talking. So even the short amount of time not doing homework, playing soccer, or at school is being compromised. Psychologists, community leaders and experts have long reported that family time can contribute to less depression, less anxiety, better academic performance and generally happier kids. But what if that family time is on media??\nAs the AAP reviews our screen time recommendations, I feel that we, as pediatricians should continue to advise parents about basic principles.\nParents need to lay down some parameters about when and how media is used. Media is a centerpiece of teens’ lives and is not going away, but just as we don’t give our kids a set of keys to our car and say “just drive”, we need to enforce appropriate media use. And good modeling is also critical: parents need to put down their mobile devices and simply communicate with their kids. Old fashioned parenting and just talking to your kids can build the foundation to a less stressful childhood and hopefully a happier life."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:45d27ccb-0128-4392-b1fc-9fdd01828ab1>","<urn:uuid:9ee5a44c-ac0e-4471-bc2a-f3b31e423c46>"],"error":null}
{"question":"What is the relationship between traditional folklore storytelling and modern vertical farming techniques, in terms of how they evolve and adapt over time?","answer":"Traditional folklore and modern vertical farming both demonstrate evolution and adaptation over time, though in different ways. Folklore involves stories being passed down orally from generation to generation, with each storyteller adding something new to make the tales more interesting and fascinating. Similarly, vertical farming represents an evolution in agricultural practices, adapting to modern challenges by moving from traditional horizontal farming to vertical systems that use less space and water. While folktales preserve cultural heritage through variations and retellings, vertical farming adapts to environmental and socioeconomic changes through technological innovation, though it still faces challenges in scaling up beyond community levels.","context":["2 edition of Folk tales and fables found in the catalog.\nFolk tales and fables\n|Statement||collected by Phebean Itayemi and P. Gurrey.|\n|Series||Penguin West African series, WA 3|\n|Contributions||Gurrey, Percival, joint comp.|\n|LC Classifications||GR350 .I8|\n|The Physical Object|\n|Number of Pages||122|\n|LC Control Number||55016450|\nLand of a Thousand Fables, also known as the Fablesphere, is a realm created by master illusionist Artorius Vigo for Anna Henrietta and Sylvia Anna when they were children that brings many fairy tales and legends to life. However, the spell was only stable until , at which time, without maintenance, magical entropy began to set in and the illusion began to take on a more twisted tone. As. Folklore spins traditional tales of fantasy and history. Our unique sampling of second grade reading fables worksheets are an excellent way to encourage your child to read. Learn about \"The Boy Who Cried Wolf,\" \"The Ant and the Grasshopper,\" and many other classics.\nFairy tales, fables, tall tales, and folktales – they are all similar in some ways. All of these types of stories fall under or are a sub-genre to what we know as folklore. Basically, folklore is a type of story passed down orally from person to person. They share many common themes. Fables and Fairy Tales is a whimsical bookstore for the child in all of us. A magical place where imagination and adventure come to life. Our family owned and operated bookshop is located on the historic downtown square in Martinsville, IN. Our mission is to provide excellence in our products and services to our customers and local community.\nFables have animals, plants, mythical creatures, or other similar characters that are given human qualities. Variations. Folktales may have different variations. Fables are usually uniform, especially the ones that are written down. Image Courtesy: “Folk-tales_of_Bengal_” by w:Warwick Goble – (Public Domain) via Commons Wikimedia. Fairy Tales and Fables: Hispanic Heritage Revisit these classic fairy tales and fables — retold with a Latino twist! From a Caribbean Rapunzel to numerous variations on \"The House That Jack Built,\" young readers are sure to enjoy a fresh take on these favorites.\nNAEP 1996 science state report for Department of Defense domestic dependent elementary and secondary schools, grade 4\nThe farmers assistant\nA mirrour of monsters\nThe 2000-2005 Outlook for Luggage and Personal Leather Goods in Latin America\nWhere did your family come from?\nPartial revision of the genus Sthenelais Kinberg (Polychaeta: Sigalionidae)\nTask Force report on affirmative action\ncaptains death bed\nThe consumer finances and socio economic survey report, 2003/04.\nJust had sex?\nNatural rubber-producing plants for the United States\nThe Pioneer and Semi-Official Air Mails of Canada, 1918-1934\nBooks shelved as fables-folktales-and-myths: Le Morte D'Arthur - Volume I by Thomas Malory, The Thief and the Beanstalk by P.W. Catanese, The Dark Prophe. Fairy Tales and Fables (The Junior Classics; The Young Folks' Shelf of Books, Volume 1) Hardcover – January 1, by marcia williams, mabel & dalphin (Author) out of 5 stars 6 ratings See all formats and editions/5(6).\nRead Fables, Folktales, Myths 3rd Grade books on Epic plus o of the best books & videos for kids. Stories, Tales, and Fables - Junior Great Books Series Two - Volumes 1 - 4 (Junior Great Books Series 1, Volumes 1 through 4 Includes \"Household Tales, Tales Told Again, Just So Stories, Tales & Fables, Yugoslav Folk-Tales, The Jack Tales, The Way of the Storyteller, The Story of Doctor Dolittle, Celtic Fairy Tales, Russian Wonder Tales & The Cow-Tail Switch and other West African Stories\").\n52 stories, myths, fables and folk tales from around the world Introduction. All children love stories. Parents and teachers love them too because they connect us to the wisdom and beauty found in all cultures and peoples of the earth.\nBrowse and buy a vast selection of Fables, Fairy, Folk Tales & Legends Books and Collectibles on The folktale is a story passed down verbally from generation to generation. Each storyteller added something new to the stories, making them more interesting and fascinating as the ages passed.\nDifferent folktales bear the characteristics of the culture, folklore and customs of the people from which they Folk tales and fables book.\nRead more on Wikipedia. is the world's biggest collection of fairy tales and folklore. Browse our full list of tales and stories. Fairy Tales, Myths & Fables - Kids: Books.\n1 - 20 of results. Grid View Grid. List View List. BESTSELLER. Pre-Order Now Add to Wishlist. Quickview. The Tower of Nero (B&N by Rick Riordan. BN Exclusive $ See All Formats. BESTSELLER. Add to Wishlist. Find folk tales and legends from all over the world in this book list for grades PreK Teachers.\nFables By. Arnold Lobel. Grade. Read i ng level. Paperback Book Find new titles and get fresh teaching ideas by exploring book lists organized by author, holiday, topic, and genre. Grade s. INpreparing this illustrated edition of the Fables and Folk Stories the aim has been to make the book more attractive, and so simple that it will appeal to a younger class of readers.\nChildren in their second year of school can read understandingly and enjoy these short stories that File Size: KB. World’s largest collection of fairy tales, fables and folk tales.\nDiscover more than 4, classic tales plus new stories by fairy tale fans. We have an expansive inventory of fairy tales and fables for toddlers and kids. Browse our extensive children's folk tales books on sale at The Scholastic Parent Store. Fairy Tale Story #1: Cinderella From rags to riches, and the goose that laid the golden eggs, to escaping a witch’s oven, these fairy tales for kids Author: Ariel Zeitlin.\nMy Uncle gave me a book for christmas when I was probably about 10 (mid-late 90's) All I can remember about it was that it had at least a hundred fables/fairy tales/ nursery rhymes, and poems.\nIt was a a big square, hard backed, blue covered book at least inches thick and the edges of the pages were gold on all sides.\nLIST: Fairy Tales, Fables and Other Stories for Children & the Adult Child. Fairy Tales. Little Red riding Hood - You can be misled if you don’t use your eyes, ears and brains. The Ugly Duckling - Beauty is hidden until it is ’t assume a person’s worth by their outside appearance.\nThese traditional stories may be fairy tales and fables. Folktales may be more culturally specific but contain concepts and truths that transcend cultures.\nThis list of books of fairy tales, folktales, and fables are great for foundational literacy and are a good starting point to introduce these traditional stories to your preschoolers. Fairy tales are stories that range from those originating in folklore to more modern stories defined as literary fairy tales.\nDespite subtle differences in the categorizing of fairy tales, folklore, fables, myths, and legends, a modern definition of the fairy tale, as provided by Jens Tismar's monologue in German, is a story that differs \"from an oral folk tale\", written by \"a single.\nThe most popular fairy tales throughout the ages. Cinderella, Little Red Riding Hood, Beauty and the Beast and more. Snow White and the Seven Dwarfs The story of beautiful Snow White, the seven dwarfs and the evil Queen.\nYour students will work through IEW Units 1–7 as they learn to take notes, retell narrative stories, summarize references, write from pictures, and compose their own fables, myths, and fairy tales.\nThis Student Book includes assignments, blank outlines, source texts, checklists, vocabulary cards, and grammar helps for two levels of students—basic and advanced/5(8). The \"Myths, Folktales, and Fairy Tales\" project is designed so that you may choose any one or all of the three sections to explore depending on available class time and desired teaching focus.\nSince each of the sections is aimed at a different grade level, modifications of the activities are advised. Quick links to unit plan resources: 4 Items.Folklore, Fairy Tales & Fables 5 More Best Picture Books of \"Twisted\" Fairy Tales When children are familiar with the characters and stories in traditional fairy tales, which carry with them timeless messages and lessons, sometimes it’s fun to shake it up a little bit and have some fun.\nFolktales: Folktales refer to stories that have been passed down from ancestors of a particular group of people to the younger generations. Fable: A fable is a story with a moral or based on a myth. Passing Down: Folktales: In most cases, folktales are passed on from one generation to another.\nFable: Fables too are passed on from one generation.","Agricultural systems around the world need to adapt to the rapidly changing environmental, demographic, and socioeconomic landscapes, and new alternative practices, such as vertical agriculture, may offer new opportunities to accelerate such adaptation.\nNext Gen Farming Without Soil and 90% Less Water | GRATEFUL\nWhat is vertical farming and why is it important\nModern agricultural systems encompass an estimated 1.5 billion hectares of the world’s surface area. With a growing population and resource needs, the availability of arable land is shrinking rapidly.\nSince the agricultural revolution, conventional agriculture has focused on practices requiring considerable quantities of space, water, fertilizer, and pesticides. The past 50 years have seen an accelerating rate of increase in these requirements as modern food production aims to increase productivity in the hopes of addressing growing food insecurity.\nLooking into the future, yield production is forecasted to decrease due to widespread environmental and socioeconomic changes that will generate unpredictable consequences on food systems.\nIn response, many strategies have been developed as alternatives to conventional agricultural practices. These strategies have focused on key principles and their combination to be effective: require less space, less water, and increase yield per unit of area. Moreover, due to the negative effects of agrichemicals, modern practices have also aimed to use significantly less to avoid potentially adverse effects for humans and animals.\nOne such alternative is the development of vertical agriculture, also referred to as vertical farming. As the name implies, vertical agriculture relies on expanding production vertically and not horizontally. Vertical agriculture is a multilayer indoor plant production system that allows for precise control of growth factors, such as light, temperature, humidity, carbon dioxide concentration, water, and nutrients.\nThis allows for the growing and production of crops year-round, completely independent of solar light and other external conditions. Indeed, vertical agriculture makes use of key concepts within ecology and physiology to optimize growing and fertilization within controlled conditions. For instance, elements of photobiology, thermomorphogenesis, hydroponics, and genetic breeding, are all used commonly across systems of vertical agriculture.\nBenefits, challenges, and disadvantages moving from horizontal to vertical farming\nAs a result of tight control over crop breeding, growing, and harvesting, vertical farming provides several benefits relative to conventional methods of ‘horizontal’ food production. This was the topic of a literature review by Kalantari et al. published in 2016 in the Journal of Landscape Ecology.\nFrom a systems perspective, the enclosed design prevents pests and diseases from entering by the adoption of a high level of hygiene, continuous monitoring, and non-chemical disinfection, providing security from crops. Moreover, recent technology has also allowed for automated control over environmental conditions by using sensors and imaging techniques in combination with crop simulation models and artificial intelligence, limiting the need for physical labor.\nVertical farming also allows for flexible organization, with designs ranging from large vertical walls covered with crops to large hangars or re-used shipping containers that can be transported. Consequently, vertical agricultural systems, can comprise many varying sizes and be located within many different areas from the middle of highly urbanized cities to more suburban or rural areas.\nMoreover, the verticality element of this system also provides nutrient and water flow, helping to reuse costly resources. The reduction in space also means there is a significant increase in yield per area, holding extensive potential for a future world of urbanization.\nFrom an economic perspective, vertical farming also provides for more jobs in localized areas and is community-focused by addressing the needs of immediate areas, which in turn can provide food at a lower price. Finally, the optionality of location for vertical systems also allows producers to reduce transport costs, as consumers may access them within urban areas, or transport can be minimized to nearby areas.\nHowever, despite the design, environmental, and economic advantages, vertical farming also incorporates several issues that remain a challenge to its broader implementation as a system.\nVertical farming has a high energy requirement and needs extensive investment costs to implement and develop successfully. Moreover, indoor issues relating to excessive UV, heat, and ozone-induced plant damage may have unpredictable repercussions for plant growth.\nAdditionally, vertical systems are difficult to adapt to a larger scale. They are costly to build and maintain and have yet to demonstrate the ability to provide food for larger areas than community-scale populations. This would make it difficult to implement in areas at higher risk of food insecurity, such as developing agricultural nations.\nThe lack of empirical research on a broader scale has meant that vertical farming has yet to develop past the concept stage on community levels, as persistent issues make it difficult to break through to a larger scale.\nImage Credit: YEINISM/Shutterstock.com\nGrowing skywards - the implications of vertical farming in a rapidly populating and changing world\nAmong the development of alternative agricultural practices, vertical agriculture provides a promising solution for many of the challenges facing current agricultural policies. However, for vertical systems to be integrated on a larger scale requires further technological progress and economic investment.\nNevertheless, gradually implementing more verticality, or combining it with other practices aiming for more sustainable practices may be promising. For instance, the combination of verticality with other practices such as intercropping may be particularly beneficial for developing more sustainable food systems.\nIncorporating technological progress into vertical systems also holds promise, with automated sensors and machinery able to operate near-independently. Progress in gene editing and plant genome modifications will also allow for faster, bigger, and healthier crops, allowing vertical agriculture to produce more over time.\nThroughout agricultural history, farming systems have typically spread over large spans of land, yet the reduction in arable land, as well as the increase in demand to house growing populations, means that such strategies need to be reconsidered, and vertical agriculture may play a role looking into the future.\nContinue Reading: Benefits of Vertical Agriculture and Hydroponics\n- Beacham, A. M., Vickers, L. H., & Monaghan, J. M. (2019). Vertical farming: a summary of approaches to growing skywards. The Journal of Horticultural Science and Biotechnology, 94(3), 277–283. doi: 10.1080/14620316.2019.1574214\n- Chaudhry A. R. and Mishra V. P.,(2019) A Comparative Analysis of Vertical Agriculture Systems in Residential Apartments, Advances in Science and Engineering Technology International Conferences (ASET), 2019, pp. 1-5, doi: 10.1109/ICASET.2019.8714358\n- Sarkar, A., & Majumder, M. (2015). Opportunities and Challenges in Sustainability of Vertical Eco-Farming: A Review. Journal of Advanced Agricultural Technologies, 2(2). doi: 10.12720/joaat.2.2.98-105\n- SharathKumar, M., Heuvelink, E., & Marcelis, L. F. (2020). Vertical Farming: Moving from Genetic to Environmental Modification. Trends in Plant Science, 25(8), 724–727. doi: 10.1016/j.tplants.2020.05.012"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:8d781596-5d32-4312-aad5-9b9b8aad5284>","<urn:uuid:3566e03d-b8ac-4d36-b13c-9d56f4d7ba0e>"],"error":null}
{"question":"How do sound waves physically behave in concert halls, and what acoustic considerations were historically important in their design?","answer":"Sound waves in concert halls exhibit complex physical behaviors including reflection, diffusion, and diffraction. When sound hits surfaces, it can either reflect like a mirror, scatter in different directions (diffusion), or bend around obstacles (diffraction). These behaviors are critically important for acoustics since they affect how sound travels through the space. Historically, concert hall design didn't formally consider acoustics until 1900 with Boston's Symphony Hall - before that, architects simply copied shapes of halls with known good acoustic properties. The basic acoustic requirement was reverberation time (the time it takes for sound to decay), which should be between 1.9 and 2.3 seconds for symphonic music. Modern halls must balance direct sound with early and late reflections while accounting for factors like audience size and distance from the orchestra. The standard calculation is 10 cubic meters per audience member and 10 audience members per musician.","context":["Any sound engineer can tell you the exact size of every loudspeaker in their system. The answers are much less precise when it comes to the size of the sound waves coming out of the speakers. It is much easier for sound waves to wrap themselves around our heads than it is to wrap our heads around sound waves.\nTheir humongous variation in size, their invisibility, and solitary audibility (we can only experience sound exactly where we are) combine to create a tremendous challenge for our brains. But size matters, especially in sound. Size affects how sound transmits through the air, reflects off objects, is absorbed by surfaces, and wraps around balcony fronts for starters. It affects decisions on speaker placement, spacing and when to make a fuss about the beautiful set piece blocking the high horn. Nobody can see sound waves with their eyes, but as professional sound engineers we must have the ability to visualize them, a form of extra sensory perception that comes from understanding the nature of acoustic transmission. Our clients are counting on our ability to see sound. Otherwise it is the blind leading the blind.\nSIZE AND SCALE\nAn audio frequency has physical size once it exists within a transmission medium. The wavelength (l) is the transmission speed/frequency or transmission speed x period (T). Wavelength is inversely proportional to frequency (becomes smaller as frequency rises). The first thing we all learned in audio was that our hearing ranges from 20Hz to 20kHz. Audible wavelengths in air range from around 56ft. down to about half an inch; the size of the largest intermodal-shipping container to the width of a child’s finger, a 1000:1 range. The mid-point audio reference of 1kHz approximately matches your elbow to your fist (Fig. 1).\nWhy should we care about wavelength? After all, no acoustical analyzers show this, and no knobs on our console can adjust it. In practice, we can be blissfully ignorant of wavelength, as long as we use only a single loudspeaker in a reflection-free environment. Good luck getting that gig. Wavelength is a decisive parameter in the acoustic summation of speaker arrays and rooms. Once we can visualize wavelength, we can see the spacing between speakers and surfaces, and visualize what will happen with the sound.\nLet’s first address a fairly common misconception that large wavelengths (low frequencies) propagate more slowly than highs. Low frequencies are by definition a slower rate of change than highs, but the transmission speed through the medium (whether air, a wire or a magnet) is frequency independent.\nFigure 2: Humidity air loss over distance\nThe transmission loss rate over distance, however, has a size-related aspect. High frequencies show a greater loss rate than lows in all cases and the effects vary with humidity (dry air is generally lossier than wet air) and slightly with temperature. The precise mechanism is complex but suffice to say that the loss rate rises as the transmitted wavelength gets closer to the molecular spacing of the medium. Air is low density so the losses are substantial at the high end of our hearing range. This means that all sound paths, both direct and reflected are increasingly filtered at the high end over distance. The steady darkening of reverberant decay is in large part due to the accumulated HF air loss over distance (Fig. 2).\nIt is well known that the speed of sound is temperature dependent. So is the size of sound, since it is proportional to transmission speed. The wavelength of sound is rescaling with temperature. It’s hard to visualize, since wavelengths of sound are … invisible. Instead we can do a reality polarity reversal and visualize temperature as rescaling our drawings of the sound system and the room, with wavelengths staying the same. In that parallel universe the room shrinks as it warms up. Either way, the reality is that a hot room fits fewer wavelengths of a given frequency than a cool one.\nHow much does the sound speed (and size) change over temperature? Not much. If we did a concert that went from a sauna to ice cold, the sound speed would fall by 10 percent. Not enough to fix a bad sound design or break a good one. At worst, we may need to adjust some delay settings.\nREFLECTION, DIFFUSION AND DIFFRACTION\nSound propagation paths are typically modeled by the ray-tracing method. Sound propagates from the source in straight lines, like rays of sunlight. In free field, the sound continues outward and steadily loses level. The relative level values for each ray are adjusted to mimic the coverage pattern shape of the particular speaker.\nWhen the ray strikes a surface it is reflected like light on a mirror (angle of incidence equals angle of reflection). Rays and reflections from additional speakers intersect and pass through those of the original source. This is the approximation of sound transmission and summation properties used in most modeling programs.\nNow let’s look at the effects of size. The ray-tracing model holds up well for smooth surfaces large enough for the longest wavelengths to reflect like a mirror. The flat expanse of an arena floor is an equal opportunity reflection generator and can be modeled by ray tracing over the full audio range. By contrast, complex irregular surfaces scatter the sound in different directions over frequency, a process known as diffusion, a uniform field of non-uniformity. Surfaces with raised and lowered areas of various sizes and angles present a variable face to the variably sized sound waves. Therefore the uniform field of the sound wave that hits a diffuse surface reacts differently over frequency, scattering a less uniform copy of itself into the room.\nIn some cases, sound waves will bend around the surface, rather than bouncing off, a process termed diffraction. Tall walls line the sides of the freeway but somehow we still manage to hear the cars: diffraction bends it over the wall. Thanks to the miracle of diffraction, I hear firetrucks as if they are right outside my open ninth floor window! Diffraction over walls and through openings creates a secondary virtual transmission source. I have to stick my head outside the window (the other side of the diffractor) to localize the firetruck on the ground.\nSmall barriers (relative to l) are passed by with minimal effect. Large barriers (relative to l) reflect a substantial portion and leave a shadow area of low-level sound behind the barrier. Any actual barrier has frequency dependent diffractive properties due to fixed opening size and variable l. Small pillars block only high frequencies while others bend around. A 50ft. diameter pillar will block nearly everything.\nDiffraction creates huge problems for audio installations. Diffraction is what makes people think it’s OK to put an I-beam in front of our speaker. They can still hear it, so what’s the problem? It’s thanks to diffraction that management thinks we should mix the show through a window opening under the balcony. Curse you, diffraction!\nFigure 3 Acoustic transmission paths: Ray tracing, diffusion, resonance, and diffraction\nRoom dimensions can create a sympathetic spacing relationship with a particular set of wavelengths, resulting in resonance. Room and internal cavity resonances can affect the decay characteristic of a room by prolonging certain frequency ranges. A room with repeated spacing relationships between surfaces is likely to be sympathetic to wavelengths sized to fit between them. This can result in a room having a particular range that hangs on long after the others have decayed away. “Helmholtz resonators” are external room-coupled chambers that provide effective absorption of low-and mid-range frequencies. This acoustic effect can be easily demonstrated by blowing air over the opening of a beer bottle. The resonant frequency corresponds to the size of the sound waves that fit in the chamber. A sound engineer will be happy to demonstrate how the resonance frequency falls along with sobriety as the bottle is emptied.\nDRIVERS AND HORNS\nThe size of a cone driver correlates to the size of the wavelengths it can efficiently reproduce and the direction pattern created. A front-loaded driver is flush-mounted to the enclosure with a flat front surface. The enclosure provides no directional steering beyond the flat baffle reflection. Internal volume and reflex port tuning affect the LF range lower limit (larger cabinet size corresponds to the ability to extend to larger wavelengths. The beamwidth of a front-loaded cone driver is predictable and varies with driver diameter. It’s widest in the LF range and narrows with frequency, a phenomenon termed “proportional directivity.” The pattern will be 90° when speaker diaphragm and transmitted wavelength are equal size. At lower (larger) frequencies the coverage will be wider than 90 degrees and vice versa. The upper limits of a speaker’s range are also size-related. Wavelengths significantly smaller than the driver size will scatter into sidelobes, which will render them inapplicable for our sound system application (though not for guitar amps).\nSize also plays a critical role in the performance of horns. Well-engineered horns are sound reflectors that guide the sound to create a wavefront with a directional pattern stamped on it that will continue after it has left the mouth. The horn flare (in both planes) is the driving force in creation of the directional control. This is scalable. In other words, a big horn and a small horn made from the same equation will have the same pattern. The size of sound however does not scale—1kHz has fixed size (neglecting temperature, atmospheric pressure changes, etc.) and therefore it fits very differently into a small horn than a big one.\nFigure 4: Comb filter reference\nThis is a Goldilocks aspect for any real physical horn: it is too big, too small, and just right, depending on the wavelength. Too big means there are reflection paths that create cancellations, thereby reducing efficiency and disturbing the efforts to consistently guide the sound into a given shape. Too small means the guidance tool (the horn flare) is too small to effectively steer the wavelengths and does not “couple” with the direct sound, resulting in reduced efficiency. Just right means we realize the efficiency gains and have consistent steering without cancellation lobes. Therefore any given horn has a limited working range that must be respected.\nThe cutoff frequency is the lowest range where the horn increases efficiency and maintains directivity. The driving forces are a combination of horn length, mouth size, and flare rate. It is generally agreed that the horn length should be a minimum of ½ l and the mouth circumference should be at least 1l. If you want big deep low end, get a big deep horn.\nLet’s see how size matters when we put cones and horns together. A standard two-way configuration commonly uses a front-loaded LF cone and HF compression driver or dome tweeter. The two-way family generally scales the two drivers together; i.e. smaller LF drivers pair with smaller HF drivers. LF drivers usually range from 5in. to 15in. while the accompanying HF drivers would be around 0.75in. to 4in., respectively. Crossover frequency falls as the size scales up, generally ranging between 4kHz and 800Hz over the scaling. LF operating range also falls as the size scales up, generally ranging from 100Hz to 40Hz.\nThere are innumerable variations by make and model. The driver loading (horn-or frontloaded) will affect the scale ratios between components and crossover frequency. The front-loaded woofer and medium-size horn are the standard pairing, e.g. a 12in. and 3in. driver set with a 1200Hz crossover. We can expect a larger HF driver and lower crossover if the LF driver is horn-loaded. As HF horn size rises, the cutoff frequency falls, allowing for a lower crossover (and a larger HF driver). If the HF driver has a small horn or a dome tweeter, the LF driver will be scaled down and crossover rises. These are basic trends and there are exceptions (both good and bad). My all-time favorite two-way configuration was the old Cerwin-Vega box with an 18in. and a piezo-electric tweeter, passive. Not!\nFigure 5 Spectral and spatial summation are linked by wavelength offset\nThe spacing between multiple speakers and surfaces is size-linked to the acoustic behavior. At stake here is whether the speakers will couple (to themselves and/or the surfaces) or uncouple and potentially scatter the sound. Let’s start with speaker-to-speaker. Coupling is best maintained by minimizing the spacing, which keeps phase offset (the enemy of coupling) to a minimum. Spacings of 1/2 l or less will fairly guarantee highly efficient coupling because the area forward of the speakers is essentially “in phase” and the side areas less so. When the spacing reaches 1l or more, we can fairly guarantee poor coupling because the side areas are also essentially “in phase” (although a cycle or more behind), which creates side lobes.\nEvery speaker-to-speaker spacing has these milestones. The size-related question is at what frequency we migrate to the dark side (lobe). The counterforce to side lobe generation is directional control. If we can keep our speakers close enough to reach the range where the elements don’t have a lot of energy on the sides, then we are safe to uncouple the array. A typical main array stays close enough to maintain coupling in the lows where the individual elements lack directivity. As frequency rises the elements are engineered to increase their directional control and minimize the sidelobes associated with the small sound size relative to the spacing.\nThe relationship of speakers to surfaces is much the same. We instinctively know the benefits of placing subwoofers on the floor because this spacing provides ideal coupling at those wavelengths. We quickly learn why we avoid placing high horns right next to surfaces (when we can) because even a small spacing is too large for our tiny HF wavelengths.\nComb filtering is another spacing-related effect. Sources that arrive at different times (multiple speakers or reflections) will modify the frequency response with a series of peaks and dips; i.e. comb filtering. The response is completely predictable if we are fluent in the size of sound. Two sources that are 1l apart will show an octave-wide peak at that frequency, and narrower peaks and dips above. When sources arrive 2l apart, the peak will be 1/2 octave, 3l create a 1/3 octave peak, and so on. If the travel distance between two speakers is the length of your elbow to your fist, then we can expect to see a peak a 1kHz will appear along the line of separation (Figs. 4 and 5).\nWe can’t see the size of sound directly, but there is great benefit to being able to visualize it in our minds. Modern audio analyzers are very helpful in this regard since they show us phase, from which we can find the wavelength. These modern analyzers are the best learning tool to help us to acquire the ability to see sound in the room.","The architecture of sound\n- It wasn’t until 1900 that the first concert hall – Symphony Hall in Boston – was designed with acoustics in mind.\n- How the musicians and audience feel has become increasingly important over the past 10 years. This phenomenon is called psychoacoustics.\nTheir spectacular design did not make the acousticians’ work any easier: more than 2,000 people can be seated in each of the halls, which was the first challenge. In addition, they are intended to attract all types of music – not only classical symphony orchestras, but also jazz combos and pop, world music and rock concerts.\nNeither of the two resembles a traditional concert hall. Instead, they are a hybrid of two forms that acousticians know well: the shoebox style and the vineyard style, which are designed specifically for symphonic music (others might be designed for opera, for example). The shoebox style is the oldest and most common. Boston’s Symphony Hall, Vienna’s Musikverein and Amsterdam’s Concertgebouw are all excellent examples. The Berlin Philharmonic, inaugurated in 1963, is built in the vineyard style, which was revolutionary for its time. The audience surrounds the stage on different levels, like terraced vineyards, breaking with the cold formality of the shoebox.\nHybrid concert hall\nThe Elbphilharmonie in Hamburg combines two architecural forms: the shoebox and the vineyard style.\nAntoine Pecqueur, a French musician and journalist, prefers the acoustical experience in Paris. “It’s more generous and transparent. The sound is very precise for both listeners and musicians.” But he also appreciates the dynamic shades of the concert hall in Hamburg. “It gives the musicians a lot of liberty. Visually the Elbphilharmonie is appealing, too – inside and outside, offering a splendid view over the city.”\nEnsuring sound balance\nCollaboration between architects and musicians is now essential. Before the 20th century “acousticians weren’t called upon for their expertise”, explains Gerhard Müller, professor at the Technical University of Munich. “Architects took an empirical approach, copying the shape of a hall where they already knew the acoustic capabilities.” Previously, music was composed for and adapted to the acoustics of a building.\nIt wasn’t until 1900 that the first concert hall – Symphony Hall in Boston – was designed with acoustics in mind. Ever since, acoustic architectural demands have become increasingly complex: halls must be able to draw larger audiences and bigger orchestras. Musical instruments also have more powerful sounds now.\nAny concert venue has a few basic requirements. The first is reverberation time, which is the time it takes for sound to decay until it stops. This is a function of sound richness and of a hall’s effects. “Reverberation was actually the only acoustic requirement until the mid-20th century”, explains Kahle. Ideal reverberation time is between 1.9 and 2.3 seconds for symphonic music, depending on the volume of the hall, the size of the audience and the type of music.\nFavouring the overall experience\nThe challenge for acousticians is to strike the right balance. First, they must control the reverberations in the hall so that the music comes across to the audience as clear and powerful. When a sound is produced, it goes directly to the listener (direct sound) but also bounces to various places such as walls, the ceiling, balconies, decorations, reliefs and even the chairs. A concert hall needs these sound reflections: early ones followed by late ones, and the much-valued lateral reflections.\nAcousticians also consider the level of sound that the audience will hear, the distance between the audience and the orchestra, and the volume ratios in the concert hall. “For optimal sound, we calculate 10 audience members per musician and 10 cubic metres per audience member, so 100 cubic metres per musician”, says Kahle. “The more musicians and audience members there are, the bigger the hall must be. And when more than 2,000 people are in the audience, there are even more challenges. The bigger and taller the hall, the further the walls are from the orchestra and the audience. You need to get creative and find ways to bring the walls closer, by using reflectors or playing with the front of the balconies.”\nBeyond the scientific criteria, “how the musicians and audience feel has become increasingly important over the last 10 years”, says Constant Hak, assistant professor of building acoustics at the Eindhoven University of Technology. “This is a phenomenon called psychoacoustics: when musicians are playing, they must feel good and be able to hear their own play and that of their co-musicians correctly. As a result, they will play better.\nThe same goes for the audience: when people enter the hall, their experience will be more special if they feel enveloped by the music and the space, almost as if they were in a cocoon. Appreciating acoustics is very subjective. We don’t hear good acoustics – we feel them. The history of a certain concert hall will also have an effect on some audience members, causing them to evaluate their concert experience in different ways.”\nThe next generation of concert halls will have to integrate new technologies, says Hak. There is increasing interest in musical centres, either with several halls that can host various types of music or one large hall with variable acoustics. Indeed, not all types of music have the same acoustic requirements. “With electroacoustic solutions, like artificial reverberation and reflections using integrated microphones and loudspeakers, or with mechanical solutions, like curtains or rotatable panels, a single hall can be suitable for a variety of events.”"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:9ecc07c0-8655-40d1-9f71-185bf5ba09c0>","<urn:uuid:b2f9a70b-fa06-4b53-bad0-167bff81e566>"],"error":null}
{"question":"Hey! I've been wondering - what's the key difference between ancient Egyptian and Venetian Murano glass-making techniques? 🤔","answer":"The key difference lies in their production methods and materials. Ancient Egyptian glass-makers mixed sand and natron (a naturally occurring sodium carbonate harvested from Egyptian lakes) to produce large blocks of glass weighing up to twenty tons, which were then broken into pieces and traded. In contrast, Murano glass-making, which became prominent after 1291 when Venice moved all glass furnaces to the island, was known for its advanced glass blowing techniques, particularly exemplified by Angelo Barovier's innovations in the 15th century, leading to masterpieces like the enameled blown 'Barovier Cup'.","context":["Glass-makers and the Silk Road\nIncreased trade on the Silk Road in the 200s BC forced traders to try to come up with new things to trade that other people would want. West Asia was already way ahead of China, India, Europe, and Africa in glass-making. So West Asian glass-makers looked for some way to make their glass even more exciting to traders.\nWho invented blown glass?\nAround 75 BC, the Phoenicians figured it out: a new, much better way to make glass, much faster and cheaper than before. They learned how to blow glass. It’s also possible that it was Egyptians who figured out how to blow glass.\nSo how do you blow glass?\nYou stick a gob of hot glass onto the end of a long clay pipe, and you blow through the pipe as if you were blowing up a balloon. The air makes the gob of glass blow up, just like a balloon. (Later on, people used iron pipes to blow glass instead of clay.) People who made glass already had these long clay pipes sitting around, because they blew into them to make the fire hotter so they could melt glass. Probably glass manufacturers were looking for a way to produce a lot of glass cheaply, so they could sell a lot more of it. It wasn’t a big step to think of blowing a gob of glass through the clay pipe.\nThen as you blow you can shape the glass with an iron stick. This isn’t easy, but it is a lot easier and much faster than making core-formed glass!\nBlowing glass at the Corning Museum in New York State\nWhat is mold-blown glass?\nSoon after this, the Phoenicians also figured out how to just blow the glass right into a mold (we call this mold-blown glass). Then you don’t even have to shape it yourself, and you can get all sorts of fancy shapes.\nThe Glass Road\nGlass became one of West Asia’s main products for the Silk Road (so much that Chinese traders often called it the Glass Road) and international trade. By around 50 AD, glass-blowers were using iron pipes to blow the glass, instead of clay ones.\nWhere did people make glass?\nGlass-makers in the Eastern Mediterranean and Egypt made almost all of the glass in the ancient and early medieval world. They had the right kind of sand. And in Egypt, they had a good supply of natron to mix with the sand.\nA new ingredient: natron\nEarlier glass-makers had mixed plant ash with sand and lime to make glass. The plant ash lowers the melting temperature so it is easier to melt. But in Roman Egypt, glass-makers figured out how to use natron instead.\nNatron is a kind of salt – sodium carbonate. It evaporates naturally from some lakes in Egypt. As the summer goes on and the lake dries up, the salt around the edges of the lake dries into thick cakes. Pliny the Elder tells us that Egyptian people harvested these natron cakes and store them to use in making glass. That was more efficient and cheaper than burning plants for ash.\nEgyptian glass-makers mixed sand and lime with this natron to make glass. They made huge blocks of glass – as much as twenty tons at one time. Then they broke the big blocks into chunks with hammers and sold the pieces of glass to traders. Later on, when Egypt had used up a lot of their natron, they also bought natron from other African places like Sudan and Chad.\n(In the Parthian Empire, though, they didn’t have these natron lakes, so they kept on using plant ash.)\nLater people in Europe, Africa, and West Asia used little pieces of this opaque glass to make colored mosaic floors.\nBut then they wanted to make transparent glass\nAbout 60 to 70 AD, people realized they could get much cheaper blown glass, transparent vessels. They all wanted colorless glass. Raw glass is usually bluish or greenish. To make it colorless, they added a little antimony (which was better) or manganese (cheaper but not quite as high quality). You could even carve this transparent glass to look like rock crystal.\nWho made the glass into bowls and cups?\nTraders sold the big blocks of glass from Syria and Egypt to glass-workers who made it into useful things. There were big centers of glass production not only in Phoenicia but also further west in modern Köln (northern Germany) and other places around the Roman Empire.\nSome of these glass-makers may have been travelers. They came to a city, set up a temporary glass kiln, turned out a few batches of glass bowls and cups and sold them, and then moved on to another town.\nDid the Romans use glass in their windows?\nYes, they did. Once people could blow glass and it got cheaper to make, they started to use glass in their windows. You could blow a big cylinder of glass, and then slice it when it was still hot and open it up into a flat rectangle.\nMany Roman basilicas and markets had glass in the windows – sometimes clear, and sometimes colored like medieval stained glass windows. One example is the Basilica of Constantine in Trier, in southern Germany.\nDid the Romans and the Parthians recycle broken glass?\nYes, glass recycling was a big thing in the ancient world. The Roman poet Martial mentions people who collected and sold broken window glass and bowls to glass-makers. Roman glass-makers sorted this recycled glass into different colors, melted it down, and recycled it. Often glass was recycled, melted down, and blown into a new shape several times.\nRoman glass reached Japan\nGlass-makers in India\nLearn by doing: go see someone blowing glass\nMore about glass – medieval and modern glass\nHow Glass Is Made, by Alan J. Paterson (1985). Easy reading, but it’s really about modern glass technology.\nStudies in Ancient Technology: Leather in Antiquity – Sugar and Its Substitutes in Antiquity – Glass, by R. J. Forbes (2nd revised edition 1997). Only part of the book is about glass, but it will tell you everything you need to know about glass in ancient Greece and Rome. By a specialist, for adults.\nEarly Glass of the Ancient World: 1600 B.C.-A. D. 50, by E. M. Stern (1995). Marianne Stern is the leading world expert on ancient glass.\nRoman, Byzantine and Early Medieval Glass: Ernesto Wolf Collection, by E. M. Stern and others (2002). Same expert author as above.","The glass making has long-standing roots which can be traced back over three thousand years ago. It’s quite difficult to determine with certainty which people can boast the discovery of glass making, which probably was the consequence of an accidental invention.\nAccording to an ancient Phoenician legend, handed down by Pliny the Elder (AD 23 –AD 79), some merchants, returning from Egypt with a large shipment of sodium carbonate, stopped one evening along the banks of a river to rest. They used few blocks of saltpeter to light a fire and cook some food. The fire kept on burning all night long, and in the morning they found with amazement a new bright and transparent material: glass!\nThe oldest archaeological finds of glass pastes date back to around the fourth millennium BC and were found in the area stretching from the Mesopotamian basin to Egypt: mostly rings, beads, seals, inlays and plates, and this goes to show that the most ancient techniques only allow the production of objects of small dimensions, intended to ritual uses or created for ornamental purposes.\nApparently, in the early days of the process, the rarity due to the difficulty of production, was to consider the glass as a precious material like semiprecious gems and stones, with which were realized the jewelry.\nFrom the Hellenistic period there was an increase in long-haul trades, and industries began to produce large-scale, and commonly used luxury items. This is when the glass manufacturing experienced a period of prosperity, spreading throughout the Mediterranean.\nAt the time of emperor Augustus the manufacture of glass, along with the other arts, experienced profound changes. Glass artifacts of that period have been found throughout Europe (France, Switzerland, Austria, Germany and Spain), and in those days the glass industry experienced a productivity growth.\nImportant production centers were created everywhere, thanks to itinerant craftsmen ready to bring their skills wherever there was demand for glass.\nThe art of glass spread throughout Europe especially during the Roman Empire, and certainly, the phenomenon that favored this expansion is to be found in the orientation to daily use of glass production.\nThe center of glassmaking in Italy was the island of Murano. Murano’s reputation as a center for glassmaking began when the Venetian government, in order to prevent fires in the city centre, ordered to move all glass furnaces to the island of Murano in 1291. From then on all the necessary measures to prevent possible industrial espionage were taken.\nMurano glass production became such a thriving industry that, until the end of the 18th C, the island was Europe’s leading centre for glass making.\nThe art of glass blowing in Murano achieved soon great results, due to the technological innovations introduced by Angelo Barovier, the greatest glassmaker of the 15th C, who in 1460 created the most precious masterpiece of glass art: the famous “Barovier Cup”, made of enameled blown glass, now preserved in the Glass Museum in Murano.\nA visit to Murano glass making factories today offers the opportunity to see how glass is still made, with the same techniques used in the past. You can also enrich the experience with the visit of the Glass Museum to admire the precious old glass works of art which are still today inspiring the glass masters of Murano."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:a940c937-9688-463f-8271-469444d26981>","<urn:uuid:e294203e-c509-457a-a9a0-c93750adacb6>"],"error":null}
{"question":"How do the concepts of adjacent color restrictions in the ring painting problem compare to the color mixing principles in the basic color theory?","answer":"In the ring painting problem, adjacent sections cannot share the same color, creating a strict mathematical constraint that yields 360 possible combinations. Meanwhile, in basic color theory, adjacent colors on the color wheel can actually be mixed together to create secondary colors (like yellow and red making orange), showing how adjacent colors interact differently in these two contexts. The ring problem deals with discrete color choices, while color mixing theory involves blending colors in various ratios to create new hues.","context":["2016 AIME II Problems/Problem 12\nThe figure below shows a ring made of six small sections which you are to paint on a wall. You have four paint colors available and you will paint each of the six sections a solid color. Find the number of ways you can choose to paint the sections if no two adjacent sections can be painted with the same color.\nChoose a section to start coloring. Assume, WLOG, that this section is color . We proceed coloring clockwise around the ring. Let be the number of ways to color the first sections (proceeding clockwise) such that the last section has color . In general (except for when we complete the coloring), we see that i.e., is equal to the number of colorings of sections that end in any color other than . Using this, we can compute the values of in the following table.\nNote that because then adjacent sections are both color . We multiply this by to account for the fact that the initial section can be any color. Thus the desired answer is .\nSolution by Shaddoll\nWe use complementary counting. There are total colorings of the ring without restriction. To count the complement, we wish to count the number of colorings in which at least one set of adjacent sections are the same color. There are six possible sets of adjacent sections that could be the same color (think of these as borders). Call these . Let be the sets of colorings of the ring where the sections on both sides of are the same color. We wish to determine . Note that all of these cases are symmetric, and in general, . There are such sets . Also, , because we can only change colors at borders, so if we have two borders along which we cannot change colors, then there are four borders along which we have a choice of color. There are such pairs . Similarly, , with such triples, and we see that the pattern will continue for 4-tuples and 5-tuples. For 6-tuples, however, these cases occur when there are no changes of color along the borders, i.e., each section has the same color. Clearly, there are four such possibilities.\nTherefore, by PIE, We wish to find the complement of this, or By the Binomial Theorem, this is .\nWe use generating functions. Suppose that the colors are . Then as we proceed around a valid coloring of the ring in the clockwise direction, we know that between two adjacent sections with colors and , there exists a number such that . Therefore, we can represent each border between sections by the generating function , where correspond to increasing the color number by , respectively. Thus the generating function that represents going through all six borders is , where the coefficient of represents the total number of colorings where the color numbers are increased by a total of as we proceed around the ring. But if we go through all six borders, we must return to the original section, which is already colored. Therefore, we wish to find the sum of the coefficients of in with .\nNow we note that if , then Therefore, the sum of the coefficients of with powers congruent to is We multiply this by to account for the initial choice of color, so the answer is .\nLet be the number of valid ways to color a ring with sections (which we call an -ring), so the answer is given by . For , we compute . For , we can count the number of valid colorings as follows: choose one of the sections arbitrarily, which we may color in ways. Moving clockwise around the ring, there are ways to color each of the other sections. Therefore, we have colorings of an -ring.\nHowever, note that the first and last sections could be the same color under this method. To count these invalid colorings, we see that by \"merging\" the first and last sections into one, we get a valid coloring of an -ring. That is, there are colorings of an -ring in which the first and last sections have the same color. Thus, for all .\nTo compute the requested value , we repeatedly apply this formula: (Solution by MSTang.)\nLabel the sections 1, 2, 3, 4, 5, 6 clockwise. We do casework on the colours of sections 1, 3, 5.\nCase 1: the colours of the three sections are the same. In this case, each of sections 2, 4, 6 can be one of 3 colours, so this case yields ways.\nCase 2: two of sections 1, 3, 5 are the same colour. Note that there are 3 ways for which two of the three sections have the same colour, and ways to determine their colours. After this, the section between the two with the same colour can be one of 3 colours and the other two can be one of 2 colours. This case yields ways.\nCase 3: all three sections of 1, 3, 5 are of different colours. Clearly there are choices for which three colours to use, and there are 2 ways to choose the colours of each of sections 2, 4, 6. Thus, this case gives ways.\nIn total, there are valid colourings.\nSolution by ADMathNoob\nWe will take a recursive approach to this problem. We can start by writing out the number of colorings for a circle with and compartments, which are and Now we will try to find a recursive formula, , for a circle with an arbitrary number of compartments We will do this by focusing on the section in the circle. This section can either be the same color as the first compartment, or it can be a different color as the first compartment. We will focus on each case separately.\nIf they are the same color, we can say there are to fill the first compartments. The compartment must be different from the first and second to last compartments, which are the same color. Hence this case adds to our recursive formula.\nIf they are different colors, we can say that there are to fill the first compartments, and for the the compartment, there are ways to color it because the and compartments are different colors. Hence this case adds\nSo our recursive formula, , is Using the initial values we calculated, we can evaluate this recursive formula up to When we get valid colorings.\nSolution by NeeNeeMath\nWLOG, color the top left section and the top right section . Then the left section can be colored , , or , and the right section can be colored , , or . There are ways to color the left and right sections. We split this up into two cases.\nCase 1: The left and right sections are of the same color. There are ways this can happen: either they both are or they both are . We have colors to choose for the bottom left, and remaining colors to choose for the bottom right, for a total of cases.\nCase 2: The left and right sections are of different colors. There are ways this can happen. Assume the left is and the right is . Then the bottom left can be , , or , and the bottom right can be , , or . However the bottom sections cannot both be or both be , so there are ways to color the bottom sections, for a total for colorings.\nSince there were ways to color the top sections, the answer is .\nThis is equivalent to a node coloring of a cycle with 6 nodes. After repeatedly using deletion-contraction, the solution comes out to be\nLabel the four colors and , respectively. Now let's imagine a circle with the four numbers and written clockwise. We'll say that a bug is standing on number . It is easy to see that for the bug to move to a different number, he (oops I just assumed the bug's gender) must walk or steps clockwise. (This is since adjacent numbers can't be the same, as stated in the problem). Note that the sixth number in the bug's walking sequence must not equal the first number. Thus, our total number of ways, , given the bug's starting number , is simply the number of ordered quintuplets of positive integers that satisfy for all and since the bug cannot land on again on his fifth and last step. We know that the number of ordered quintuplets of positive integers that satisfy without the other restriction is just , so we aim to find the number of quintuplets such thatNote that the number of ordered quintuplets satisfying is the same as the number of them satisfying due to symmetry. By stars and bars, there are ways to distribute the three \"extra\" units to the five variables (since ), but ways of distribution such that one variable is equal to are illegal, so the actual number of ways is . Since there are four possible values of (or the starting position for the bug), we obtain -fidgetboss_4000\nSolution 10 (Mini-Bash)\nLet's number the regions . Suppose we color regions . Then, how many ways are there to color ?\nNote: the numbers are numbered as shown:\nThe colors of are , in that order.\nThen the colors of can be , , , , or in that order, where is any color not equal to its surroundings. Then there are choices for , choices for (it cannot be ), choices for , and for , the last color. So, summing up, we have colorings.\nThe colors of are , in that order.\nAgain, we list out the possible arrangements of : , , , , , , , , or . (Easily simplified; listed here for clarity.) Then there are choices for as usual, choices for , and so on. Hence we have colorings in this case.\nAdding up, we have as our answer.\nThis solution was brought to you by LEONARD_MY_DUDE\nVideo Solution: https://www.youtube.com/watch?v=Yndl8HqVkJk\n|2016 AIME II (Problems • Answer Key • Resources)|\n|1 • 2 • 3 • 4 • 5 • 6 • 7 • 8 • 9 • 10 • 11 • 12 • 13 • 14 • 15|\n|All AIME Problems and Solutions|","How to Mix Color: Basic Theory\nAny color can be made using the following nine colors: Blue, Red, Yellow (the primary colors), Green, Orange, Purple (the secondary colors), White, Black, and Ocher.\nUnderstanding the basics is key when starting to paint. If you plan to paint repaired ceramic or sculpture and have painting experience, you can skip this paragraph. Reading the information below is helpful, but in practice actually mixing colors is essential.\nHaving a basic knowledge of the color wheel is really important.\nThree primary colors, Blue, Red and Yellow: These are the colors that are impossible to mix from a combination of other colors.\nThe 3 secondary colors, Orange, Violet, and Green: These are a mix of two primary colors. For example, mix primary yellow and primary red to make secondary color orange.\nThese 3 primary colors and 3 secondary colors make up the basics of the color wheel.\nThis is where theory and reality depart - the color wheel should be used only as a tool to understand colors behavior rather than a guide for choosing paints while implementing. The variations are too many for the color wheel to show them all.\nFor example: Cadmium Red is an orange-red and will have a bias towards yellow. Alizarin Crimson is a blue-red and will have a bias towards purple. So it is not just as easy as buying a \"pure red\" and a \"pure yellow\" -- they don't exist.\nDeveloping your Artist's Eye\nThe process of developing your Artists's eye can take a while. A few people have it intuitively and most have practice. So be patient. At the beginning, you'll be certain you mixed a color perfectly but as you apply it next to other colors or the color you are trying to duplicate, it will look wrong. Trying again and again is the only way for you eyes and brains to start understanding the slight differences and what color is missing a bit more.\nWhat is Hue?\nHue is the easiest to understand: at its most basic, it's art speak for the actual color of a pigment or object.\nWhat is Value?\nValue or tone is a measure of how light or dark a color is, without any consideration for its hue. The problem with a color's value or tone is that how light or dark is seems is also influenced by what's going on around it. What appears light in one circumstance, can appear darker in another circumstance, for instance when it's surrounded by even lighter tones. (See picture on right).\nWhat is Chroma?\nThe chroma or saturation of a color is a measure of how intense it is. Think of it as \"pure, bright color\", compared to a color diluted with white, darkened by black or grey, or thinned by being a glaze. Variations in chroma can be achieved by adding different amounts of a neutral gray of the same value as the color you're wanting to alter.\nAren't Value and Chroma the Same Thing?\nColor mixing would be easier if they were, but they're not. With chroma you're considering how pure or intense the hue is, whereas with value you're not considering what the hue is at all, just how light or dark it is.\nDo I Need to Consider Hue, Value, and Chroma Every Time I Mix a Color? As a beginner painter, yes you do. But the good news is that with experience of color mixing, it becomes easier and less of a systematic process. Initially it's well worth taking the time to consider the hue, value, and chroma in a color you're want to match, making a judgment or decision on each before you attempt to mix the color. You'll waste less paint and not have as much frustration by mixing the \"wrong\" colors.\nHow to Match a Color?\nWhen you first start its advisable to take your time to understand each step.\nStep 1: Analyze the hue - what color is it closest to on the color wheel?\nStep 2: Analyze the value - How light or dark is it?\nStep 3: Analyze the saturation - How bright or dull is it?\nSome Color Recipe Examples\nBlue Green -1 part yellow, 3 parts blue\nBlue Violet - 2 parts blue, 1 part red\nBrown - 1 part yellow, 1 part red, 1 part blue\nCharcoal - 2 parts blue, 1 part red, 1 part yellow\nCitron 1 - part orange, 1 part green\nFlesh - start with white and add yellow, red, brown and sometimes blue.\nNote: Flesh is the hardest color to describe (as you might imagine) so you will have to experiment with the ratios.\nGreen - 1 part yellow, 1 part blue\nOlive 1 - part green, 1 part violet\nOrange -1 part red, 1 part yellow\nPink -1 part red, 1 part white\nRed Orange - 2 parts red, 1 part yellow\nRed Violet - 2 parts red, 1 part blue\nRusset -1 part orange, 1 part violet\nViolet - 2 parts blue, 1 part red\nYellow Green - 2 parts yellow, 1 part blue\nYellow Orange - 2 parts yellow, 1 part red\nWhite makes any shade lighter, while the opposite color on the color wheel will darken it.\n**Artificial light always leads to inaccuracy in color matching, so use natural light **\nGlazing Over The Painted Area?\nDetailed lesson will be added at a later date (sorry!). See link for Sylmasta cold glaze. To properly apply cold glaze, air brushing is a must."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:8fe0fa17-4d43-492d-95f6-068a0c679275>","<urn:uuid:4e230104-508b-4118-851e-37268cbd99ea>"],"error":null}
{"question":"What are the recent findings about tillage practices' impact on soil enzyme activities when applying manure?","answer":"The research showed that tillage practices (comparing no-tillage versus conventional tillage) did not affect the enzyme activities within the first 3 years of the study. This finding was consistent across different research plots and manure application scenarios.","context":["Title: Multi-Location Study of Soil Enzyme Activities as affected by Different Manure Types, Rates, and Tillage Application Practices Authors\n|Stahlman, F -|\n|Erickson, Richie -|\nSubmitted to: Trade Journal Publication\nPublication Type: Peer Reviewed Journal\nPublication Acceptance Date: December 2, 2011\nPublication Date: December 9, 2011\nCitation: Acosta Martinez, V., Mikha, M.M., Sistani, K.R., Stahlman, F., Benjamin, J.G., Vigil, M.F., Erickson, R. 2011. Multi-location study of soil enzyme activities as affected by different manure types, rates, and tillage application practices. Agriculture. 1(1): 4-21. Interpretive Summary: Significant amounts of manure are produced in the U.S and disposed into agricultural land as a less expensive fertilizer to increase soil nutrients. Thus, it is important to determine continuously the soil enzyme activities in agricultural land under manure as they are sensitive indicators of nutrient cycling and soil organic matter changes. This study evaluated enzyme activities of C (ß-glucosidase, a-galactosidase), C and N (ß-glucosaminidase) and P cycling (phosphomonoesterases) as affected by manure types, rates and tillage application practices for different soils in plots established in 3 states (Colorado, Kentucky and Kansas). Results showed that tillage practices for manure application did not affect the enzyme activities within the first 3 years of this study. The response of the enzyme activities in the 3 different states depended on the manure and soil type. The enzyme activities responded faster in the sandier soil evaluated in Colorado (fine sandy loam) than the soil in Kansas (silt loam) after the 1st year of beef manure applications. Since the 1st year in Kentucky plots, C cycling enzyme activities were almost doubled in dairy and poultry treated soil compared to the none treated soil. However, acid phosphatase activity was higher under the poultry treated soil than in the dairy treated soil while C cycling enzyme activities were similar in soil treated with poultry manure or dairy manure. The three states (studies) showed significant responses in C and P cycling enzyme activities to manure applications within 1-2 years, representing potential benefits in soil nutrient cycling for agro-ecosystems supported with organic fertilizers.\nTechnical Abstract: A multi-location research effort evaluated enzyme activities key to nutrient cycling such as ß-glucosidase (C cycling), a-galactosidase (C cycling), ß-glucosaminidase (C and N cycling) and phosphomonoesterases (P cycling) in research plots established as follow: (1) two years of beef manure applications to a fine sandy loam at different rates (control: 0, low: 34 kg N ha-1 and high: 96 kg N ha-1) and different tillage practices in Colorado (CO); (2) three years of beef manure applications to a silt loam at different rates (0, low: 67 kg N ha-1 and high: 134 kg N ha-1) in Kansas (KS) and; (3) three years of poultry and dairy manure applications to a silt loam with different tillage practices at the same rate (403 kg N ha-1) in Kentucky (KY). Tillage practices (no-tillage vs. conventional tillage) had no effect on the enzyme activities. Principal Component Analyses (PCA) showed all enzyme activities associated with the high beef manure application rate after the 1st year in CO study at 0-5 cm. By the 2nd year, the low and high beef manure rates differed in the enzyme activities for KS study, but there was no differentiation between the low rate and control in the CO study. At the KY study, PCA plots indicated all enzyme activities were associated to poultry and dairy manure than in the control during the entire study. Acid phosphatase activity was greater in the poultry treated soil compared to dairy or the control; whereas C cycling enzyme activities (ß-glucosaminidase, ß-glucosidase and a-galactosidase) were similar in soil treated with dairy or poultry manure. Soil samples from 5-10 cm did not reveal treatment separation until year 2 for all studies (i.e., only high application rate differed from the other treatments). Our findings with different soils revealed significant responses in C and P cycling enzyme activities to manure applications within 1-2 years, representing potential benefits in ecosystem services (i.e., soil biogeochemical cycling) essential for the future for agro-ecosystems supported with organic fertilizers."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:3bc00d35-7e96-48c6-942e-633a35910bb4>"],"error":null}
{"question":"请问Git Bash是什么？有什么好处呢？🤔","answer":"Git Bash is a terminal specifically for Windows that allows users to use Git and Linux commands. It is recommended over the regular command prompt because it provides better command capabilities than the standard Windows command prompt.","context":["By Moustafa Elsisy\nYou might have heard of Git before (or GitHub) – maybe you tried to work on a programming group project before, or you know how common it is in the software development industry. Whether you have been exposed to it before or not, Git, once you get to know it, is a major skill to have under your belt.\nGit is a VCS (Version Control System), and what it basically does, is that it allows you to keep track of changes to your codebase, as well as facilitating collaboration between team members. The way it traditionally works is by having a remote repository that holds the code on a server, and local repositories on each developer’s local machine, to hold their version of the code.\nThe remote repository does not know about the changes you made to your local repository unless you upload your changes to it – this process is known as pushing. The changes you make are organized into commits, with each commit being a record of the changes that you made to your codebase. You get to choose when to make a commit – it is helpful that you organize your commits in the right way though; we will discuss that later. To update your local repository with the changes that have been pushed by other developers to the remote repository, you need to download those changes – this is known as pulling.\nIf you are on Windows, I really recommend that you get Git Bash before you start. Git Bash is a terminal that allows you to use Git and a lot of linux commands (which are much better than those in command prompt). If you are on linux, you probably have git already (in the case you do not, you can use apt-get).\nNext, you will need a place to host your remote git repository (such as GitHub, BitBucket, GitLab etc…).\nChoose your favourite (you might want to go with GitHub because it has the highest popularity, but I would recommend BitBucket if you prioritize features), and make an account there, then create a repository.\nYou should find a link to clone the repository (copying the remote repository to your local machine).\nFor simplicity, choose HTTPS instead of SSH for cloning.\nGo to the folder where you want your repository files to sit, open up your terminal in that directory, and use\ngit clone [clone_link_here] ./ (clone into the current directory)\nCreate a new file in the directory, and add some text to it.\nAt this point, your changes are untracked (git is not keeping track of the changes in its history).\nTo record your changes, you first have to add your files to the staging area using\ngit add -A (add all untracked files to staging area).\nThen its time to make your first commit, using\ngit commit -m \"[your commit message here, describing your changes]\"\nNow, it is time to push the changes history to the remote repository.\ngit push and enter your account details to accomplish that, and then go to your remote repository – you should see your changes there.\nAnd there you go! You just have pushed your first commit. There are a lot more commands to git though. Later, we will see how git can be used to organise multiple versions of the codebase, and facilitate collaboration between developers."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:6aa3d7bd-49db-4743-8f81-d46542754bad>"],"error":null}
{"question":"What's the key difference between stories and games when it comes to emotional impact? 🤔","answer":"The key difference is how they handle uncertainty of outcome. In stories, the emotional power comes from pre-determined and organized techniques used by a storyteller which the audience witnesses. In contrast, games derive their emotional power from witnessing an unpredetermined contest.","context":["In this article the following definitions are assumed:\n- Game – a competition with direct conflict between participants.\n- Story – a fictional account of something that happened to someone.\n- Interactivity – choice which determines outcome.\nIn the interactive entertainment industry there is often a vague or common use of the terms ‘story’ and ‘game’ which erroneously implies – even though the speaker may know it to be untrue – that story and game are one and the same aspect of interactive design, and one and the same experience for the interactive user. This inaccuracy is understandably not important to the general public, or even to veteran users of interactive products, because it doesn’t affect their enjoyment of a product labeled with either descriptor.\nBut clear definitions of each concept should be critically important to designers, because without an understanding of what a story and a game are as both methods and techniques of entertainment, the possibility of achieving emotional involvement is greatly diminished and ultimately left to chance. Understanding story and game, and the relationship between the two, is a prerequisite to the construction of, as opposed to the categorization or marketing of, interactive entertainment which achieves sustained emotional involvement.\nIn the definitions for story and game offered at the beginning of this essay, I’ve defined them as elements of technique to be used in design. This not only aids in construction, but allows for theoretical discussion of those hybrid products which might have some aspects of story and some of game, without insisting that they be forced into either category. As will be seen, there are problems with mixing story and game, but that shouldn’t be our point of departure. The immediate goal is not to classify or limit designs at all, but simply to identify what each process brings to the interactive drawing board, so that it can be used to best effect.\nOn the surface it doesn’t look like there’s any real reason to confuse the two terms. Certainly there are common-language uses of both words that intrude on each other’s turf – a “Cinderella story” in sports, say, or “running a game” on someone, as used when accusing someone of making up a story for the purpose of deceit – but our definitions seem to steer us clear of these grammatical rocks. Still, this kind of fraternization between terms can be seen to reach all the way into the interactive designer’s workshop, as is evidenced by any number of interviews in which designers talk openly about new game ideas in the works, when in fact there is little or no actual game-driven interactivity in the design or final product. If we were sure that this was only a result of colloquial usage it might be all right to dismiss it. But how sure can we be that the designers themselves are not confusing the two, or that they have any real idea what defines each as a method of entertainment?\nThere are, of course, similarities in the methods of each which may lead to confusion. The most basic of these similarities is the fact that both games and stories derive their emotional power from uncertainty of outcome. When preparing to engage in a story or witness a game, almost all of our involvement centers around what will happen at the end – which we expect, or at least hope, will contain both the greatest moment of uncertainty of outcome, as well as the resolution of that uncertainty. Of course we’re interested in the sights along the way – great plays in sports and games, wonderful emotional moments in film and literature – but we’re interested in those sights as stepping stones to, and portents of, the ending. Who will win the game? What will happen to the hero in the final act?\nBut there is also a critical difference between story and game as it relates to uncertainty of outcome. Simply put, the emotional power of a story’s outcome is generated by a storyteller through pre-determined and organized techniques and methods, which the audience witnesses. This contrasts sharply with the emotional power of a game’s uncertainty of outcome, which is derived from witnessing a contest which is not predetermined.\nExamples of the clash between these two forces abound in both passive narrative forms and in real-world gaming. Movies about sporting events are often unfulfilling because of the preparatory effects which narratives must use to generate emotional involvement. Because of these preparations – particularly various forms of foreshadowing – the dramatic outcome of any story is often logically known, or at least suspected, before it is revealed. At first seemingly counterproductive even in stories of a non-sports nature, this “tipping of the hand” actually allows the storyteller to work with or against the audience’s beliefs or suspicions, prompting the audience to doubt, moving them to hope, all through an ageless methodology based on creating tension. But in sports-oriented stories all of this preparation for effect works directly against the unprepared effect necessary for suspense in games.\nAs the story aspects of a sports story generate tension through foreshadowing, this necessarily renders the last at bat, the final shot, the big race as more predictable than they would be if occurring in real life. Who doubts the hero in a baseball movie will hit the desperately needed two-run homer in the final at-bat? Contrast this with the emotions felt when the game is live and it’s your favorite player at the plate and you have no predictive clues as to what will happen. Sure, your favorite player’s hitting .400 lately, and the pitcher’s last start was shaky, but that’s nothing compared to the foreshadowing you’ll be prompted and goaded with in a well-crafted story. If instead of a live event you’re now watching a movie where the batter’s abandoned and now reclaimed son is waiting breathlessly in the stands, under the wing of his mother, who still loves this man who left her for his dreams, would you bet the batter getting a hit?\nNotice, too, what happens when moments in real life games become too story-like, as did crippled Kirk Gibson’s famous home run, which won a playoff game for the Dodgers in the bottom of the ninth inning in the 1988 World Series. These moments, veering uncomfortably close to manufactured drama, are almost always described as (and literally were in this case – repeatedly) “a moment a screenwriter would come up with”: meaning, a real event has happened by chance in exactly the same way it would be executed dramatically. This intrusion of perceived effect (narrative preparation) can make an audience perceptibly uncomfortable, even though they know that what happened was not prepared in advance.\nDrama must be wary of leaning too close to the unpredictability of gameplay as well. There is the case of a theatrical play in which the staging of a picnic scene called for two actors to be opposite each other, down stage (closest to the audience), tossing a ball back and forth. The director hoped to use a layering of actions on stage to increase the depth of dramatic meaning in the scene, but the audience’s attention was instead solely focused on the actors playing catch, riveted by the thought that at any time the actors might loose an errant throw and literally drop the ball. Playing catch is not a game by the present definition, yet the simple reality (interactivity) of the process completely destroyed suspension of disbelief in the drama. If, instead, one actor was pitching and the other trying to get a hit, the drama of such a blatant contest would surely demolish any interest in the stage play.\nThe above are instances in which gameplay and story seem to damage each other. To see why this happens – why it must happen – we need to look closely at how the emotional power of games and stories are destroyed for an audience.\nWe’ve said that in both game and story the ending holds the payoff. For an audience interested in hearing a story there’s more than just a simple social gaffe committed when one member reveals the ending, because the possibility of fully experiencing the story is destroyed. Revealing the ending damages a story’s power because all of the preparedness in the beginning and middle is revealed for what it is: manipulation. Because that manipulation is intended to support uncertainty of outcome, and now does not, the audience’s ability to enter into a state of suspended disbelief is crushed. In fact, although the compromising of uncertainty of outcome in a story is perhaps the greatest damage that can be done, anything which intrudes upon suspension of disbelief precludes audience involvement in a story.\nBut how can the ending of a game be revealed, when the events of a game aren’t prepared beforehand, or suspension of disbelief be shattered when there is no suspension of disbelief? Yes, a friend might let out the final score of a game you’d taped for later viewing, but that’s the same kind of destruction of uncertainty of outcome that cripples storytelling. The real distinction between stories and games as it relates to preclusion of audience involvement centers not on uncertainty of outcome itself, but on the relative state of mind of the audience.\nWhere stories require suspension of disbelief before emotional involvement can take hold, games conversely require active belief that each participant is trying as hard as they can to achieve victory. If a player were to intentionally try to lose, then this belief on the audience’s part would be misplaced, which is why scandals involving fixing or throwing sporting events are so damaging. When an audience does not believe that the outcome of future games is unprepared, the integrity of the sport as a whole comes into question, with the consequence that the audience cannot care about or become emotionally involved in those contests.\nSo not only are story and game achieving their emotional power through uncertainty of outcome in exactly opposite fashions, but the power derived from one method destroys the power of the other. The audience must on the one hand disbelieve in the preparedness of stories, and on the other believe in the unpreparedness of games. If we believe in the preparedness of a story, that is if we openly, consciously admit that it’s all rigged, then it holds no emotional weight. Similarly, if we disbelieve in the unpreparedness of a game (believe it has been prepared), it’s meaning is void. For stories and games to be joined, the audience would have to be able to enter both states of mind simultaneously.\nIf what’s desired in interactive entertainment is emotional effect on par with the best that stories and games can present to an audience, then story and game must not be made interdependent and allowed to cancel each other out. (Since I wrote these words twelve years ago, every possible permutation of merging story and game has been tried, and no solution has overcome this basic schism.)\nFor those products where gameplay is primarily important, pre-determined story elements must necessarily be segregated. One common way of combining the two in such titles is to treat gameplay as tactical (via discrete missions or levels), while the story plays out in a separate strategic narrative. For products where storytelling is the focus, gameplay (as defined above) must remain segregated, and interactivity must be carefully tailored to fit any narrative structure. Titles taking this approach are significantly fewer, however, precisely because computers are incapable of providing interactive stories. In most such cases, faux interactivity (e.g. puzzles or branching dialogues) are substituted for actual gameplay in order to preserve the emotional power of the narrative.\nCopyright © 1997 & 2009 by Mark Barrett"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:a4ca7362-092f-409f-a165-b9b2054f8ec2>"],"error":null}
{"question":"How can I stay updated about weather conditions while boating on the water?","answer":"While on the water, you should stay tuned to NOAA weather radio for the latest warnings and forecasts. Watch for signs of approaching storms like dark threatening clouds, steady increase in wind or sea, and lightning flashes. Heavy static on AM radio may indicate nearby thunderstorm activity. If you have a VHF transceiver with built-in NOAA weather radio channels, use them. For ventures beyond 20-40 miles range, consider getting an HF single sideband transceiver.","context":["- Special Sections\n- Public Notices\nRick Morgan, Owen County emergency management director, asks that you should know the weather which can be both friend and foe.\nCalm winds and water make for enjoyable power boating, waterskiing, and fishing.\nA fresh breeze and a light chop provide an invigorating sailing or wind-surfing experience. But the sudden emergence of dark clouds, shifting and gusty winds, torrential downpours and lightning can turn a day’s pleasure into a nightmare of distress.\nHere are some tips on how to keep your pleasure and safety to a maximum.\nIf you plan for a day of boating fun, look at the weather reports several days ahead of time. Start listening for the National Weather Service extended five-day outlooks on NOAA weather radio, radio and TV.\nThe outlooks give general information to help you decide whether or not to continue making plans.\nBefore you set out, pay close attention to the TV weathercast and listen to detailed weather forecasts on NOAA weather radio.\nTake note of small boat cautionary statements, small-craft advisories, or gale or storm warnings in the forecasts.\nThe advisories and warnings alert mariners to higher winds and waves either occurring now or forecast to occur up to 24 hours from now.\nAdvisories and warnings for conditions expected later give mariners time to take action to protect life and property.\nAfter you set out, don’t touch that dial. Stay tuned to NOAA weather radio.\nYou know the weather and it will change. The change often occurs out of your sight and may be headed your way.\nUpdated warnings and forecasts are aired immediately on NOAA weather radio, alerting you to changes that may require action on your part.\nWhile on the water, stay alert. Check NOAA weather radio for latest warnings and forecasts.\nWatch for signs of approaching storms: dark, threatening clouds that may foretell a squall or thunderstorm, a steady increase in wind or sea, lightning flashes.\nAn increase in wind opposite in direction to a strong tidal current may lead to steep waves capable of broaching a boat. Heavy static on your AM radio may be an indication of nearby thunderstorm activity.\nIf a thunderstorm is approaching, head for shore if possible. Get out of your boat and away from the water and find shelter immediately. If a thunderstorm catches you while afloat, remember that gusty winds and lightning pose a threat to safety.\nPut on your personal flotation device and prepare for rough water. Stay below deck if possible.\nKeep away from metal objects that are not grounded to the boat’s protection system. Don’t touch more than one grounded object at the same time (or you may become a shortcut for electrical surges passing through the protection system).\nIf you have a VHF transceiver with built-in NOAA weather radio channels, use them.\nIf your VHF radio is not equipped with weather channels, you may want to buy a VHF weather radio. Keep in mind, however, broadcast reception varies with the location of you and the transmitter, the quality of the radio, and any obstructions. A broad, average range is 20 to 40 miles.\nIf you venture beyond that range, you should consider buying a good quality HF single sideband transceiver to add to your VHF. It may be more expensive, but it is worth it to be able to get the information that may save your life and property.\nHave fun and be safe on Kentucky waterways."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:efff973a-f7ec-4679-b7ff-d56109973628>"],"error":null}
{"question":"What are the soil health benefits of cover crops, and what challenges do vegetable farmers face when trying to incorporate them into their rotation?","answer":"Cover crops provide multiple soil health benefits: they improve soil structure through their root systems, increase organic matter, attract beneficial insects, foster helpful microbes, and enhance nutrient levels - particularly nitrogen in the case of legumes. They also create tunnels that aid in soil aeration and improve moisture infiltration. However, vegetable farmers face significant challenges incorporating cover crops into their rotation. Late-harvested crops like sweet corn, pumpkins, and tomatoes often remain in the ground until October or November, when fields may be too wet to work and cover crops don't establish well. Additionally, succession planting of short-season crops across small blocks makes it awkward to manage cover crops and can delay access to parts of the field.","context":["Benefits Cover Crops Could Bring to Your Field\nMarch 12, 2018\nIn recent years, many farmers have turned to cover crops for a variety of reasons. While the specific plant used varies, cover crops are planted in fields after harvest with the goals of improving field health and managing erosion. The practice is becoming increasingly common with farmers looking for soil health benefits, reduced runoff, or even the recently announced insurance savings. Still, many are hesitant — are the benefits worth the work of planting an entirely different crop? If you're one of those still on the fence, we broke down the positives of cover cropping so you can make an informed decision.\nImproving Soil Health and Structure\nOne of the primary advantages to planting a cover crop is the increased soil health that additional organic material brings to the field. The plants improve the soil and add nutrients, and when slashed or allowed do die back, form a natural compost. The cover crop will also attract a variety of insects to the field, which can help prevent the populations of harmful pests from growing. Additionally, the increase in organic matter will foster the presence of microbes that help eliminate fungal and bacterial infections.\nCover crops with a long taproot or wide root system (such as radishes or Ryegrass) also improve the soil structure. The roots create tunnels that aid in the aeration of the soil, as well as transportation passages for insects and microorganisms. The improved soil structure also helps the field withstand the force of heavy farm equipment and reduces subsurface compaction.\nA benefit to both the field and surrounding bodies of water, the above- and below-surface presence of cover crops can be effective in preventing runoff. Without direct exposure to the wind and harsh rainfall, erosion is less likely. The cover crops also help stabilize the soil by binding it together and protecting fertile topsoil from eroding.\nPlanting cover crops can bring higher nutrient levels to the soil, as well as making better use of fertilizer treatments. Legumes in particular are known for their nitrogen-fixing quality, in which they become a habitat for bacteria that convert nitrogen into ammonia. These plants increase the nitrogen levels in the ground while growing, and release it back into the soil when they die, making the nutrients available for use by your cash crop. The cover crop can also store nutrients from manure and fertilizer that is applied to the field, allowing the next year's crops to use what may have otherwise been lost over time.\nReducing the Need for Irrigation\nAs mentioned before, the roots of cover crops create passages in the soil, which can greatly improve the moisture infiltration and percolation. Deep roots are also able to bring up moisture from lower down in the soil, and the additional organic matter increases the water holding capacity. This higher level of retention enhances traction and translates to fewer problems planting in the spring, as farmers with cover crops are able to plant in conditions (whether too wet or too dry) that would be a risk for machinery in other fields.\nStamping out Weeds\nSome cover crops are referred to as \"living mulches\" due to their ability to suppress weeds. The leaves of the plant prevent weeds from getting the sunlight needed to survive, and its roots deprive them of needed nutrients. Upon dying or being slashed back, the cover crop works as a more traditional mulch, covering weeds and inhibiting their growth.","- About Us\nInnovations Help Vegetable Growers Find that Cover Crop Niche\nPublish Date:Summer 2016\nVolNo:Vol. XI No. 3\nThe benefits of cover crops are widely touted, but in the real world of farming it is often challenging to work cover crops into your rotation. Crops like late sweet corn, pumpkins and winter squash, tomatoes and peppers, fall brassicas, etc. are usually in the ground until October or November. By then fields are often too wet to work, and even if you can prepare a seed bed (i.e. on a coarse textured soil), cover crops planted in late October or November don’t normally establish well or protect soil from erosion over the winter.\nShort season crops are usually planted in succession with small blocks going across a field. Often the same piece of ground will be double or triple cropped. In this situation it is possible to squeeze in small blocks of cover crops, but they can be awkward to manage, and delay your ability to get back into that part of the field.\nSuccessful cover cropping requires stepping back and taking a slightly longer term perspective on your crop rotation. The National Organic Standards emphasize cover cropping, and certified organic vegetable growers are generally required to include cover crops in their rotations, but cover crops usually have to pencil out for a non-organic farmer to incorporate them in rotations. Some benefits of cover crops are relatively easy to quantify. Legume covers can provide plant-available nitrogen (PAN) to subsequent crops. Work in Salinas, CA also indicates that high seeding rates can sometimes pay off in terms of improved weed control. Other cover crop benefits are less easily quantified. Cover crop leaves intercept raindrops during wet winter months and reduce their impact on the soil surface. Fibrous cover crop roots hold soil aggregates together and reduce the risk of erosion, while deep tap roots can improve water infiltration and potentially loosen hard pans. Roots and their exudates also support the growth of microorganisms when soil would otherwise be bare. For example, cover crops have been shown to significantly increase winter survival of mycorrhizal fungi and other beneficial organisms. Many of these organisms release glomalin and other compounds that hold sand, silt and clay particles together in strong soil aggregates. Increased aggregate stability and the channels created by plant roots help to increase water infiltration rates, which in turn can reduce runoff and erosion during storms. High biomass cover crops can also maintain or increase soil organic matter, which increases soil water holding capacity and nutrient mineralization, and can help reduce the risk of some soil-borne diseases.\nOne of the biggest trade offs in traditional cover cropping is that ground is not in a cash crop during the period of time that the cover crop is growing and for up to four weeks after the cover crop is incorporated while the residue is decomposing. There are also the direct costs of seed, ground preparation, potentially irrigation, and incorporation. Depending on your crop rotation, some cover crops can increase the risk of pest damage, for example, brassica cover crops could increase the risk of clubroot in a field. Pest relationships are complex and very site specific. The benefits of cover cropping have to be balanced against potential drawbacks related to your crop rotation.\nSome farmers assume the benefits of cover crops can easily be replaced by purchasing and applying compost and organic fertilizers. This may be true with regard to crop nutrient demand, but cover crops are less expensive than most other purchased soil amendments, and can provide superior soil protection during heavy rain.\nCover crops can help with infiltration of rain water and slow or prevent surface runoff. In areas dependent on groundwater, this can be especially helpful for recharge of aquifers. However, a maturing cover crop can also begin to transpire groundwater resources, resulting in a net groundwater loss in arid regions. The best management technique in such a situation may be to terminate the cover crop early.\nThe best way to plant most cover crops is with the use of a grain drill. Ideally, this results in cover crop seeds being planted to a uniform depth and at the same rate across a field. Under dry conditions seed can be placed deeper into moisture. Other manual and tractor-assisted options include broadcasting the seed with a tractor mounted PTO-driven spin spreader, or a crank-style manual belly broadcaster for smaller areas. Broadcast seed should then be lightly buried with a disk, roller or harrow to prevent desiccation and depredation by birds and other animals. Research in Salinas indicates that burying with an offset disk results in a more uniform planting than a tandem disk. On finer textured soils in western Oregon rollers have been successfully used to incorporate seed. For a manual option in small areas, seed can be buried with a rake. Most farmers use what they have available and choose to purchase a better option when consistently cover cropping larger areas and finances allow.\nInter-seeding cover crops\nResearchers at Pennsylvania State University developed a seed drill that applies fertilizer and herbicide, and inter-seeds cover crops in one pass. Interseeder Technologies in Lancaster Co., PA is now commercially producing this equipment. Ed Peachey (OSU Extension) started working with this drill in 2015. About eight farmer collaborators are working with Ed. They are interested in establishing cover crops in late harvested sweet corn, silage corn and winter squash. Some are on highly erodible soils that flood each winter near the Willamette Valley, and they are mainly trying to establish cover crops that will form a root ball that help keep soil in place even if the cover crop gets flooded out. Other farmers are interested in improving soil organic matter, competing with weeds, and the nitrogen contributions of legume covers.\nWith this drill, farmers can seed into soil moisture. This avoids the need for extra irrigation for inter-seeded cover crops broadcast onto the soil surface, and reduces seed predation. Ed has been working with several cover crops to investigate a wide variety of objectives with cooperating farmers. Covers include Cayuse oats, black oats, barley, triticale, cereal rye, winter wheat, Sudan grass, orchard grass, tall fescue crimson clover, red clover, hairy vetch and common vetch. He has been evaluating the best time to interseed cover crops (crop stage and time of year), cover crop species, seeding depth, and herbicide compatibility. In sweet corn the cover crop is typically seeded at V6 growth stages (6 visible collars). Establishment is less complicated in organic fields where herbicide compatibility isn’t an issue. All the cover crops did well there. Trials are expanding in 2016 from Junction City to Brooks. Subscribe to OSU Veg e-Notesto learn about summer field days and to read more about project results.\nEd’s work is very relevant to smaller farms who might not be able to justify the expense of a specialized seed drill, but could broadcast covers into late summer crops and rake them in with cultivation equipment. Nick and others have had some success broadcasting covers into sweet pepper, eggplant, tomato, winter squash and sweet corn in small demonstration plots. Important factors seem to be seeding covers early enough so they could establish well before the vegetable canopy closes, and more frequent irrigation for germinating cover crop seedlings left near the surface during hot, dry weather.\nHigh-density cereal-legume mixes for weed suppression\nSurveys of small-scale growers frequently rate weed management as one of the top production challenges, and poorly managed cover crops can increase weed problems. Many winter weeds (e.g., annual nettle and shepherd’s purse) can set seed in less than two months, whereas a full-term cover crop is typically growing for a period of three to seven months. Increased weeds can have a negative impact on an organic farm’s profitability through reductions in yield and/or high weeding costs. Fast-growing cover crops can effectively smother weed competition and reduce weed populations in subsequent cash crops. If weeds are a concern, it is important to make cover crop decisions that can help reduce weed pressure over time.\nCereal-legume mixes have been very popular as cover crops among organic and small-scale farmers, partly due to the addition of nitrogen through nitrogen-fixing legumes. However, the use of legumes may not always be the best for winter weed control due to low plant densities at typical seeding rates and slow emergence in cool temperatures. According to USDA-ARS research in Salinas led by Eric Brennan (Research Horticulturalist focused on organic vegetable production), when cereal-legume cover crops are planted at high-densities (2-3x typical commercial seeding rates) they can reduce weed populations compared to standard seeding rates. Extra seed equals extra seed costs; however, this may pay off in reduced subsequent weeding costs in a cash crop. Good weed suppression can be achieved with cereal-only cover crops, as well, without needing to increase the seeding rate. See Eric’s YouTube Are legume-cereal cover crop mixtures a good fit for organic vegetable production? for a discussion on cereal vs. cereal-legume cover crop mixtures in California.\nFurrow cover cropping in organic strawberries\nA furrow cover cropping system has been developed by Brennan and Richard Smith (Farm Advisor with the University of California Cooperative Extension) for organic strawberries grown with plastic mulch on the Central Coast of CA. The system involves planting ‘Ida Gold’ mustard in the strawberry furrows before the winter rains come. This mustard is allowed to grow through the winter and is then easily mow-killed with a weed-whacker when the cover crop reaches the height of the beds. While this system doesn’t offer all of the benefits of growing a cover crop on an entire field, it does minimize erosion and surface run-off, and promote rainwater infiltration. These are serious resource concerns, especially in drought affected regions like Monterey County, CA where strawberries are planted on over 10,000 acres of land each year.\nGrowers in the Willamette Valley who are interested in adapting this system should be careful not to allow mustards to flower especially if they are near fields used for specialty brassica seed production. Pollen transfer could destroy your neighbor’s seed crop. Also during the current blackleg epidemic in Oregon, ODA Rules require that all brassica seed planted in Oregon is tested and found free of blackleg.\nNitrogen release from legume cover crops\nDan Sullivan (OSU Extension) and Nick studied nitrogen (N) release from cover crops in the lab and the field from 2006-2011. They found that a N mineralization model published in 1998 (J.T. Gilmour) accurately predicted N release after ten weeks from a wide variety of cover crops in Western Oregon. They incorporated this model into the OSU Organic Fertilizer and Cover Crop Calculator. The calculator uses cover crop biomass, percent dry matter and total percent nitrogen to predict plant-available nitrogen (PAN) release after about ten weeks. To use the calculator, sample your cover crop just before incorporation, and send a sample to a lab for percent dry matter and total nitrogen analysis. You can also use the calculator to estimate PAN release from organic fertilizers and the cost of your cover cropping and fertilizer program. Estimating plant-available nitrogen release from cover crops is a PNW Extension publication that explains the research used to verify this model, and how to sample cover crops. The publication also describes a shortcut method for generating rough estimates of PAN release if you prefer not to send samples to a lab. Figure 1 shows that as the nitrogen content of a cover crop increases (i.e. from increasing percent legume in the stand), the proportion of total nitrogen released as PAN during decomposition also increases.\nFinding a cover crop niche can be difficult for small-scale vegetable growers, but it definitely is possible. There will always the tempting reasoning that cover cropping just doesn’t pencil out for the farm. However, many of the benefits of cover cropping are hard to quantify and/or require a longer term approach. With the right management, cover cropping can even save a grower money on fertilizer and weeding costs. Innovative techniques like planting high-density cereal-legume mixtures, furrow and relay cover cropping may make cover cropping more feasible and increase the benefits to a farm operation. Perhaps try out some of these techniques over a small area this season to gauge their suitability to your farm. There are financial and technical resources to help a grower integrate cover crops into rotations, including the USDA Natural Resource Conservation Service’s Environmental Quality Incentives Program (or ‘EQIP’)and Oregon State University Extension. Don’t be afraid to ask for assistance to get the most out of your cover crops!\nThis article is based upon work supported by the Natural Resources Conservation Service, U.S. Department of Agriculture, under NRCS Conservation Innovation Grant 69-3A75-16-003, USDA’s Western Sustainable Agriculture Research & Education program, the Oregon Processed Vegetable Commission, the OSU Agricultural Research Foundation and Meyer Memorial Trust."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:04504440-b4b0-48c8-bf16-7ec933fffb69>","<urn:uuid:525c96f0-e9a6-4968-8816-154a2af3c064>"],"error":null}
{"question":"What's the typical process for conducting a website security audit? How does it compare with standard vulnerability scanning? La seguridad del sitio web es muy importante.","answer":"A website security audit involves multiple steps: First, identifying vulnerable areas of the system that could be targeted by hackers. Then, scanning web pages, files, and directories containing sensitive information, followed by manual scanning of vulnerable areas. The process includes reviewing the website manual and concluding with a comprehensive report containing findings and recommendations. In contrast, vulnerability scanning is a more focused, automated test that specifically looks for and reports potential vulnerabilities, requiring quarterly scans by a PCI Approved Scanning Vendor for external IPs and domains. Both processes are important for security, but the audit is more comprehensive, covering the entire web application including foundation software, configuration, themes, database, and server configuration.","context":["A website security audit checks your web application and its database for potential or existing vulnerabilities that attackers can exploit. It basically covers your entire web application, from its foundation software to its configuration, themes, database, server configuration, security aspects, etc. It is very important to have a well-protected site since this is one of the main elements of your online business. Hackers attack and use various means to obtain access to your site and make it malicious by changing HTML/ scripting code, database entries, and so on. So a thorough website security audit makes your web application secure by detecting any vulnerability that can be exploited for gaining unauthorized access to your website. The audit procedure is usually performed by specialized professionals who are aware of the vulnerabilities that can be used for intrusions into your web application.\nThe initial website security audit checklist covers the basic areas of website development. This area of website development includes functionality evaluation where the functional requirements of the site are investigated to identify whether the application meets the site requirement in terms of accessibility, usability, accessibility features, user friendliness, search engine compatibility, website performance, and other factors. Any changes that need to be made to the website or any other modifications should be noted down. Also any cross-browser testing should be conducted to check the compatibility of the site with different browser versions.\nAnother major area of the website security audit involves the scanning of web applications to identify any security or compatibility issues. Common issues that are often detected during a scan include XSS (cross-site scripting) vulnerabilities, SQL injection vulnerabilities, Perl injection vulnerabilities, HTTP redirection vulnerabilities, cross-site scripting bug, cookie hijacking vulnerability, and others. In most cases, these issues can be resolved with a simple update or installation of the latest versions of the required software or web hosting services. However, in some cases you may also need to conduct additional or in depth penetration tests to detect vulnerabilities. Additional testing may be required if the issue is severe.\nThe next step in the process of conducting a web security audit involves the review of the website manual. A good manual contains all the necessary information as well as the relevant code. Therefore it is very important that the manual is reviewed by a professional auditor in order to find out any information that may prove to be useful. Most auditors carry out their own web security audits, while some may even hire external personnel to conduct the tests. It depends on your requirement whether you need the services of an external auditor or you want to conduct the test yourself. If you intend to hire the services of an external auditor, it is important to ensure that they have expertise in the area of website security so that the tests they carry out are detailed, accurate, and reliable.\nBefore concluding the audit, make sure that the final report includes all the critical findings along with the recommendations. A website security audit is a lengthy process and you will need to make sure that the final report includes all the required details and is comprehensive. The final report should include the summary, recommendations, analysis and conclusion. In addition to this, it is necessary to include all the steps that were taken during the audit in the form of a checklist.\nThe first step that you should take during the website security audit is to identify all the vulnerable areas of your system. These are the areas that can be targeted by hackers. It is important to scan all the web pages that contain sensitive information, or contain forms that can be exploited. It is also necessary to scan all files and directories that contain sensitive information. This can be done by running scanning tools that are designed to identify the vulnerabilities on your system.\nOnce you have identified all the vulnerable areas of your website security audit, the next step involves the scanning of these areas manually. It is possible that you can use software that can help you detect the vulnerabilities. However, manual scanning is the best way to find the vulnerabilities. If you do not know how to identify a vulnerability, then you can get help from metasploit. Metasploit is a program that provides assistance to users in identifying all the vulnerabilities of their systems and determining the steps that need to be performed to fix them.\nTo conduct website security audits, it is best to look for programs that can help you in scanning the systems. Most of the programs that are available online can help you in finding the loopholes in your system and the ones that can be exploited. One of the best practices that you should follow in performing such an audit is to check whether the scanning tool that is being used by the company is capable of scanning all the files and directories in your system. It is also important to check if the tool can update the version that is being used in the future. If you perform all these steps in a systematic manner, then it is very likely that you will end up with the right plan to fix the problems that can affect your business.","Learn why you should include scans and pen tests in your info security program.\nWhether you’re aware of it or not, your network likely has vulnerabilities hackers could exploit.\nDefects in web servers, web browsers, email clients, POS software, operating systems, and server interfaces can allow attackers to gain access to an environment. Installing security updates and patches for systems in the cardholder or sensitive data environments can help correct many of the newly found defects and vulnerabilities before attackers have the opportunity to leverage them.\nBut in order to patch these vulnerabilities, you need to find them first. For that you need to implement vulnerability scanning and penetration testing.\nThe basics of vulnerability scanningA vulnerability scan is an automated, high-level test that looks for and reports potential vulnerabilities. All external IPs and domains exposed in the CDE are required to be scanned by a PCI Approved Scanning Vendor (ASV) at least quarterly.\nPCI DSS requires two independent methods of PCI scanning: internal and external scanning. An external vulnerability scan is performed outside of your network, and it identifies known weaknesses in network structures. An internal vulnerability scan is performed within your network, behind the firewall and other perimeter security devices in place, to search for vulnerabilities on internal hosts that could be exploited in a pivot attack.\nTypically, these vulnerability scans generate an extensive report of vulnerabilities found and provides references for further research on the vulnerability. Some even offer directions to fix the problem.\nRemember, regular scanning is just the first step. Act quickly on any vulnerabilities discovered to ensure security holes are plugged and then re-scan to validate that the vulnerabilities have been successfully addressed. Often times organizations that have the best process have the best security.\nSEE ALSO: Vulnerability Scans 101: What, Why and How to Comply\nThe basics of penetration testingJust like a hacker, penetration testers analyze network environments, identify potential vulnerabilities, and try to exploit those vulnerabilities (or coding errors). In simple terms, analysts attempt to break into your company’s network to find security holes.\nPCI DSS Requirement 11.3 (applicable to SAQ C and SAQ D) requires internal and external penetration testing of both the network and application layers of the CDE. But penetration testing isn’t limited to the PCI DSS. Any company that would like an unbiased look at their information security posture, should consider having a penetration test performed.\nThe time it takes to conduct a penetration test varies based on network size, network complexity, and the number of penetration test staff members assigned. A small environment can be completed in a few days, but a large environment can take several weeks.\nTypically, penetration test reports contain a long, detailed description of attacks used, testing methodologies, and suggestions for remediation.\nSEE ALSO: How Much Does a Pentest Cost?\nDefining a significant changeIn addition to annual penetration tests and quarterly vulnerability scans, you’ll want to perform these vulnerability assessments whenever significant infrastructure or application changes occur to determine if the changes made introduced any new vulnerabilities in the environment.\nPCI DSS Requirement 11.3 requires that penetration testing be performed after any ‘significant change’ to the CDE. Due to the cost and time required to perform a penetration test, organizations often claim no significant changes have been made to their PCI environment.\nHow do you know when a change to the CDE is considered significant? What might be considered a major change to a smaller organization may only be a minor change in a large environment. While this should be an internal risk-based decision, here are some examples of changes that would be considered significant: OS upgrade for CDE system, replacing firewall or critical security device, adding a new payment acceptance process, moving portions or all of the environment to a cloud-hosted environment. The process your organization follows to determine if a change to the CDE is significant should be documented in internal policy and procedure documents\nPenetration testing can be performed internally, if an organization has staff who are qualified to perform penetration tests and who are also independent from the systems being tested. Someone who is actively involved in the management and configuration of systems in the CDE shouldn’t also perform the penetration test, as they would not be considered independent. If a company lacks either the skills necessary to perform a test or the organizational independence, tests should be performed by a third-party penetration tester.\nSEE ALSO: Different Types of Penetration Tests for Your Business Needs\nDifference between penetration tests and vulnerability scansAs a review, vulnerability scanning, whether internal or external, is not the same as penetration testing.\nHere are two big differences:\n- A vulnerability scan is automated, while a penetration test includes a live person actually digging into the complexities of your network.\n- A vulnerability scan only identifies potential vulnerabilities. During a penetration test the tester will verify the exploitability of the vulnerability and look to identify the root cause of the vulnerability that allows access to secure systems or stored sensitive data.\nVulnerability scans and penetration tests work together to encourage optimal network security. Vulnerability scans are great weekly, monthly, or quarterly insight into your network security, while penetration tests are a more thorough assessment of your overall information security posture.\nNeed help with finding vulnerabilities? Talk to us about vulnerability scanning and penetration testing!\nMichael Simpson (QSA, CISSP, CCNP) is a Principal Security Analyst at SecurityMetrics and has been in the IT Security industry for 15 years. He has a Bachelor of Science in Computer Science and a Masters in Business Administration."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:672eabd2-fe8e-415c-95c4-426b2334f477>","<urn:uuid:ee711539-4f0d-4a64-8fc7-efc4764a9f12>"],"error":null}
{"question":"Which of these two celebrities who passed away in 2008 appeared as a guest star on Rowan & Martin's Laugh-In: Michael Crichton or Dick Martin?","answer":"Dick Martin was one of the hosts of Rowan & Martin's Laugh-In and passed away in 2008 at age 86. While Michael Crichton also died in 2008, there is no record in the documents of him appearing as a guest on Laugh-In.","context":["TV Trivia: Rowan & Martin's Laugh-In\nQ1. Which recurring sketch segment star’s famous line on Rowan & Martin’s Laugh-In was “Sock it to me“?\nQ2. Name two of the regular female cast members who had their bodies painted and go-go danced in bikinis for the Mod, Mod World segments in the first (1968) season of Rowan & Martin’s Laugh-In?\nThe sketch comedy show was titled Rowan & Martin’s Laugh-In after the two comedian hosts, Dan Rowan and Dick Martin.\nLaugh-In became famous for the stars that got their show-biz start on the series, such as regulars Ruth Buzzi, Judy Carne, Alan Sues, Richard Dawson, Goldie Hawn, Chelsea Brown, Arte Johnson, Lily Tomlin, Henry Gibson, and Jo Anne Worley, to name a few.\n(Dan Rowan, Judy Carne & Dick Martin 1967 Rowan & Martin’s Laugh-In Photo: NBC Television)\nSeniors and baby boomers will recall that guest performers often included musical acts as well as recurring performer “Tiny Tim” who was often featured. Tiny Tim’s falsetto rendition of Tiptoe Through the Tulips became a top 40 hit thanks to airplay Rowan & Martin’s Laugh-In.\nAiring from January 22, 1968 – March 12, 1973 on NBC, Rowan & Martin’s Laugh-In celebrated the hippie culture of the time with psychedelically-painted backdrops, “mod” clothing, etc.\nA wildly diverse crop of guest-stars ranged from producer/actor/director Orson Welles, to mime Marcel Marceau, jockey Willie Shoemaker, and everything in between.\nAmong the many guest-stars who appeared multiple times on Rowan & Martin’s Laugh-In during the series 5-year run were :\nComedians & Talk Show Hosts – Flip Wilson, Jack Benny, Henny Youngman, Rich Little, Tim Conway, Buddy Hackett, Charles Nelson Reilly, Don Rickles, John Byner, Carl Reiner, Milton Berle, Bob Newhart, Phyllis Diller, Johnny Carson, Dinah Shore, Dick Cavett, and Steve Allen.\nActors – John Wayne, Peter Lawford, Jill St. John, Carol Channing, Barbara Feldon, James Garner, Vincent Price, Tony Curtis, Greer Garson, Sheldon Leonard, Martin Milner, Debbie Reynolds, Ricardo Montalban, Joey Bishop, Douglas Fairbanks Jr., Peter Falk, Richard Crenna, Michael Caine, Peter Sellers, Nanette Fabray, Janet Leigh, Sandy Duncan, Robert Culp, and Sally FIeld.\nNFL quarterback Joe Namath appeared 3 times on Laugh-In between 1971-1972, while he was with the New York Jets.\nUnfortunately both Laugh-In hosts have since passed away – Dan Rowan was a new senior citizen when he died in 1987 (age 65), and Dick Martin an 86-year-old octogenarian when he died in 2008.\nRegulars Ruth Buzzi, Lily Tomlin, Goldie Hawn, and Jo Anne Worley are still alive, while Judy Carne, Alan Sues, Henry Gibson, Richard Dawson, and Arte Johnson are no longer with us.\nA1. Judy Carne was “tricked” into saying “sock it to me” during Laugh-In sketches, after which water was dumped on her.\nA2. Goldie Hawn, Judy Carne, Chelsea Brown, Ruth Buzzi and Jo Anne Worley shared the dancing duties in the first season. In later seasons, the dancing was done by extras.\n*Images are public domain or Creative Commons licensed & sourced via Wikimedia Commons, Vimeo, YouTube, or Flickr, unless otherwise noted*","Biographies on This Day in History: October 23\nOctober 23, 1940 - December 29, 2022\nPelé, Brazilian football (soccer) player, in his time probably the most famous and possibly the best-paid athlete in the world. He was part of the Brazilian national teams that won three World Cup championships...\nOctober 23, 1925 - January 23, 2005\nJohnny Carson, American comedian who, as host of The Tonight Show (1962–92), established the standard format for television chat shows—including the guest couch and the studio band—and came to be considered...\nOctober 23, 1942 - November 4, 2008\nMichael Crichton, American writer known for his thoroughly researched popular thrillers, which often deal with the potential ramifications of advancing technology. Many of his novels were made into successful...\nTaiwan-born film director\nOctober 23, 1954 -\nAng Lee, Taiwan-born film director who transitioned from directing Chinese films to major English-language productions. After high school Lee enrolled in the Taiwan Academy of Art, where he became interested...\nAmerican legal commentator\nOctober 23, 1959 -\nNancy Grace, American legal current-affairs commentator and outspoken champion of victims’ rights, perhaps best known as the anchor of the television program Nancy Grace (2005–16). Grace grew up in Georgia....\nMay 26, 1886 - October 23, 1950\nAl Jolson, popular American singer and blackface comedian of the musical stage and motion pictures, from before World War I to 1940. His unique singing style and personal magnetism established an immediate...\nAmerican football player\nOctober 23, 1962 -\nDoug Flutie, American gridiron football quarterback who won the Heisman Trophy in 1984 as the best player in college football and who had a 21-year professional football career in the United States and...\nOctober 23, 1844 - November 16, 1885\nLouis Riel, Canadian leader of the Métis in western Canada. Riel grew up in the Red River Settlement in present-day Manitoba. He studied for the priesthood in Montreal (though he was never ordained) and...\nAugust 6, 1902 - October 23, 1935\nDutch Schultz, American gangster of the 1920s and ’30s who ran bootlegging and other rackets in New York City. Born in the Bronx, Schultz took his alias from an old-time Bronx gangster and advanced from...\nAmerican neurosurgeon and medical correspondent\nOctober 23, 1969 -\nSanjay Gupta, American neurosurgeon and chief medical correspondent for CNN (Cable News Network). Gupta is best known for his captivating reports on health and medical topics, as well as his appearances...\nOctober 23, 1869 - October 3, 1936\nJohn Heisman, American collegiate gridiron football coach for 36 years and one of the greatest innovators of the game. He was responsible for legalizing the forward pass in 1906, and he originated the...\nChinese political figure\nMarch 5, 1897 - October 23, 2003\nSoong Mei-ling, notable Chinese political figure and second wife of the Nationalist Chinese president Chiang Kai-shek. Her family was successful, prosperous, and well-connected: her sister Soong Ch’ing-ling...\nking of Siam\nSeptember 20, 1853 - October 23, 1910\nChulalongkorn, king of Siam who avoided colonial domination and embarked upon far-reaching reforms. Chulalongkorn was the ninth son of King Mongkut, but since he was the first to be born to a royal queen,...\nAmerican activist and author\nDecember 11, 1939 - October 23, 2016\nTom Hayden, American activist and author. One of the preeminent activists of the 1960s, Hayden helped found Students for a Democratic Society (SDS) and was arrested as one of the Chicago Seven indicted...\nemperor of Russia\nOctober 23, 1715 - January 29, 1730\nPeter II, emperor of Russia from 1727 to 1730. Grandson of Peter I the Great (ruled 1682–1725), Peter II was named heir to the Russian throne by Catherine I (ruled 1725–27) and was crowned at the age of...\nJanuary 31, 1872 - October 23, 1939\nZane Grey, prolific writer whose romantic novels of the American West largely created a new literary genre, the western. Trained as a dentist, Grey practiced in New York City from 1898 to 1904, when he...\nSheikh Khalifa ibn Hamad Al Thani\nemir of Qatar\n1932 - October 23, 2016\nSheikh Khalifa ibn Hamad Al Thani, emir of Qatar (1972–95), who came to power five months after Qatar became a sovereign independent state (September 1971). Sheikh Khalifa held numerous governmental posts,...\nGilbert N. Lewis\nOctober 23, 1875 - March 23, 1946\nGilbert N. Lewis, American physical chemist best known for his contributions to chemical thermodynamics, the electron-pair model of the covalent bond, the electronic theory of acids and bases, the separation...\nvice president of United States\nOctober 23, 1835 - June 14, 1914\nAdlai Stevenson, 23rd vice president of the United States (1893–97) in the Democratic administration of President Grover Cleveland. Stevenson was the son of John Turner Stevenson, a tobacco farmer, and...\nOctober 23, 1906 - November 30, 2003\nGertrude Ederle, American swimmer who was the first woman to swim (1926) the English Channel and one of the best-known American sports personages of the 1920s. Ederle early became an avid swimmer. She...\nAugust 31, 1811 - October 23, 1872\nThéophile Gautier, poet, novelist, critic, and journalist whose influence was strongly felt in the period of changing sensibilities in French literature—from the early Romantic period to the aestheticism...\nWilliam Gilbert Grace\nJuly 18, 1848 - October 23, 1915\nWilliam Gilbert Grace, greatest cricketer in Victorian England, whose dominating physical presence, gusto, and inexhaustible energy made him a national figure. He evolved the modern principles of batting...\nEdward Stanley, 14th earl of Derby\nprime minister of Great Britain\nMarch 29, 1799 - October 23, 1869\nEdward Stanley, 14th earl of Derby, English statesman, important as leader of the Conservative Party during the long period 1846–68, thrice prime minister, and one of England’s greatest parliamentary orators;...\nOctober 23, 1905 - September 10, 1983\nFelix Bloch, Swiss-born American physicist who shared (with E.M. Purcell) the Nobel Prize for Physics in 1952 for developing the nuclear magnetic resonance method of measuring the magnetic field of atomic...\nMay 10, 1909 - October 23, 1978\nMaybelle Carter, American guitarist whose distinctive playing style and long influential career mark her as a classic figure in country music. By the time she was 12 years old, Maybelle Addington was well...\nJohn Boyd Dunlop\nBritish veterinary surgeon\nFebruary 5, 1840 - October 23, 1921\nJohn Boyd Dunlop, inventor who developed the pneumatic rubber tire. In 1867 he settled in Belfast as a veterinary surgeon. In 1887 he constructed there a pneumatic tire for his son’s tricycle. Patented...\npremier of China\nOctober 23, 1928 -\nZhu Rongji, Chinese politician who was a leading economic reformer in the Chinese Communist Party (CCP). He was premier of China from 1998 to 2003. Zhu joined the CCP in 1949. Following his graduation...\nErnest Thompson Seton\nAugust 14, 1860 - October 23, 1946\nErnest Thompson Seton, naturalist and writer who was an early practitioner of the modern school of animal-fiction writing. Seton was raised in North America, his family having emigrated to Canada in 1866....\nOctober 23, 1927 - July 17, 2009\nLeszek Kolakowski, Polish philosopher and historian of philosophy who became one of Marxism’s greatest intellectual critics. Kolakowski was educated privately and in the underground school system during...\nNovember 8, 1883 - October 23, 1935\nCharles Demuth, painter who helped channel modern European movements into American art and who was also a leading exponent of Precisionism. Demuth’s early training was under Thomas Anshutz and William...\nOctober 23, 1918 - August 8, 1997\nPaul Rudolph, one of the most prominent Modernist architects in the United States after World War II. His buildings are notable for creative and unpredictable designs that appeal strongly to the senses....\nOctober 23, 1750 - November 2, 1828\nThomas Pinckney, American soldier, politician, and diplomat who negotiated Pinckney’s Treaty (Oct. 27, 1795) with Spain. After military service in the American Revolutionary War, Pinckney, a younger brother...\nOctober 23, 1844 - April 21, 1930\nRobert Bridges, English poet noted for his technical mastery of prosody and for his sponsorship of the poetry of his friend Gerard Manley Hopkins. Born of a prosperous landed family, Bridges went to Eton...\nOctober 23, 1927 - June 10, 1994\nEdward Kienholz, American self-taught sculptor known for his elaborate found-object assemblages, which convey a harsh scrutiny of American society. Kienholz grew up in a working-class family on a farm...\nSir Anthony Caro\nMarch 8, 1924 - October 23, 2013\nSir Anthony Caro, English sculptor of abstract, loosely geometrical metal constructions. Caro was apprenticed to the sculptor Charles Wheeler at age 13 during summer vacations, and later he studied engineering...\nMay 24, 1810 - October 23, 1874\nAbraham Geiger, German-Jewish theologian, author, and the outstanding leader in the early development of Reform Judaism. In 1832 Geiger went to Wiesbaden as a rabbi and in 1835 helped to found the Wissenschaftliche...\nIlya Mikhaylovich Frank\nOctober 23, 1908 - June 22, 1990\nIlya Mikhaylovich Frank, Soviet winner of the Nobel Prize for Physics in 1958 jointly with Pavel A. Cherenkov and Igor Y. Tamm, also of the Soviet Union. He received the award for explaining the phenomenon...\nFeisal Abdul Rauf\nEgyptian American author and religious leader\nOctober 23, 1948 -\nFeisal Abdul Rauf, Kuwaiti-born Egyptian American imam, author, and interfaith leader. He led an effort to build an Islamic community centre in Manhattan, New York, a few blocks from the World Trade Center...\nOctober 23, 1813 - April 4, 1848\nLudwig Leichhardt, explorer and naturalist who became one of Australia’s earliest heroes and whose mysterious disappearance aroused efforts to find him for nearly a century. While Leichhardt was a student...\nOctober 23, 1920 - November 19, 1998\nTetsuya Fujita, Japanese-born American meteorologist who created the Fujita Scale, or F-Scale, a system of classifying tornado intensity based on damage to structures and vegetation. He also discovered...\nOctober 23, 1805 - January 28, 1868\nAdalbert Stifter, Austrian narrative writer whose novels of almost classical purity exalt the humble virtues of a simple life. He was the son of a linen weaver and flax merchant, and his childhood experiences...\nZellig S. Harris\nOctober 23, 1909 - May 22, 1992\nZellig S. Harris, Russian-born American scholar known for his work in structural linguistics. He carried the structural linguistic ideas of Leonard Bloomfield to their furthest logical development: to...\nSeptember 14, 1791 - October 23, 1867\nFranz Bopp, German linguist who established the importance of Sanskrit in the comparative study of Indo-European languages and developed a valuable technique of language analysis. Bopp’s first important...\nFrancis Jeffrey, Lord Jeffrey\nScottish critic and judge\nOctober 23, 1773 - January 26, 1850\nFrancis Jeffrey, Lord Jeffrey, literary critic and Scottish judge, best known as the editor of The Edinburgh Review, a quarterly that was the preeminent organ of British political and literary criticism...\nMehmed Emin Pasha\nMarch 28, 1840 - October 23, 1892\nMehmed Emin Pasha, physician, explorer, and governor of the Equatorial province of Egyptian Sudan who contributed vastly to the knowledge of African geography, natural history, ethnology, and languages....\nCharles Glover Barkla\nJune 7, 1877 - October 23, 1944\nCharles Glover Barkla, British physicist who was awarded the Nobel Prize for Physics in 1917 for his work on X-ray scattering, which occurs when X-rays pass through a material and are deflected by the...\nJames Edward Hubert Gascoyne-Cecil, 4th marquess of Salisbury\nOctober 23, 1861 - April 4, 1947\nJames Edward Hubert Gascoyne-Cecil, 4th marquess of Salisbury, British statesman and Conservative politician whose recommendations on defense became the basis of the British military organization until...\nSt. John of Capistrano\n1386 - October 23, 1456\nSt. John of Capistrano, ; canonized 1690; feast day October 23), one of the greatest Franciscan preachers of the 15th century and leader of an army that liberated Belgrade from a Turkish invasion. In California,...\nemperor of Japan\nFebruary 6, 885 - October 23, 930\nDaigo, 60th emperor of Japan. He was unsuccessful in continuing his father’s policy of limiting the power of the important Fujiwara family, which dominated the Japanese government from 857 to 1160. The...\nAndoche Junot, duke d’Abrantès\nOctober 23, 1771 - July 29, 1813\nAndoche Junot, duke d’Abrantès, one of Napoleon Bonaparte’s generals and his first aide-de-camp. Junot, the son of a prosperous farmer, joined the volunteers of the Côte d’Or district in Burgundy during..."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:9cd6e5d4-4364-4690-882f-042b7cef2308>","<urn:uuid:d299619e-b8a5-4f7d-9353-a643f43997f0>"],"error":null}
{"question":"How did institutional controls evolve in managing nuclear weapons knowledge in the 1950s, and what similarities exist with the regulation of printing in Renaissance Venice?","answer":"The British Army Operational Research Group managed nuclear weapons knowledge through formal 'indoctrination' programs and systematic assessment via pre-bomb and post-bomb questionnaires, measuring officers' attitudes toward nuclear warfare. Similarly in Venice, institutional control over printing evolved significantly, particularly with the establishment of the printers' and booksellers' guild in 1549 - the last guild formed in Venice. While the military formalized nuclear training to shape officers' understanding of atomic weapons, Venetian authorities increasingly regulated printed materials, especially after the Reformation, with both the Church and state working to control content. Both systems show how institutions developed formal mechanisms to manage and control access to potentially dangerous or controversial information.","context":["[Cross posted from Cold Warriors]\nIn September 1956, 250 British and Commonwealth officers attended the first of the British BUFFALO nuclear weapon tests at Maralinga, Australia. The object of their ‘indoctrination’ was to give them a better idea of the nature and possibilities of nuclear warfare. In order to ascertain whether any measurable change had occurred in the attitude of the Indoctrinees towards nuclear weapons as a result of their experiences, the British Army Operational Research Group devised a pre-bomb and post-bomb questionnaire that was to be completed by the attending officers. The answers provide some fascinating insights into the minds of soldiers who had to ply their deadly trade under the looming shadow of the atom.\nAfter a short delay, during which time some of the more impatient officers were reported as being extremely ‘browned-off’, the Indoctrinees were finally treated to not one, but two nuclear explosions. The yield of the first bomb was measured at 12.5 KT, the second 10 KT. In general, the officers appeared to be impressed by the flash and heat-wave of the nuclear explosion, but were underwhelmed by the noise and the blast from their viewing platform 5 ½ miles away. I’m not sure what they were hoping for, perhaps a good old fashioned 20 kilo-tonner would have done it for them? Nonetheless, the Army Operational Research Group promptly distributed the questionnaires. The questions were designed to assess the Indoctrinees knowledge of, and attitudes towards, nuclear weapons. One of the questions asked was:\nLying down in the open on fairly flat ground, would you rather be:\na) 2 miles from a 20 KT bomb explosion\nb) 400 yards from a 2000-lb HE bomb explosion\nc) 50 yards from a 25-pr HE shell explosion\n*Also, put a cross (x) under the one you dislike the most *\nNone of the above? Unsurprisingly, the majority of the participants ‘disliked’ nuclear weapons much more after experiencing the explosions. Another questions asked:\nIf you were an Army Commander who required a blitz on an enemy concentration 4 miles behind their front lines, which would you prefer as the most likely to achieve your object:\na) An atomic missile\nb) A HE bomb air attack of equivalent explosive force\nc) Heavy artillery bombardment of equivalent explosive force\n94% of the Indoctrinees answered that an atomic missile would be the best tool for the rather difficult job of blitzing the enemy position. The pre-bomb answers had shown that 84% of the officers would have chosen the atomic missile, however. The atom was certainly becoming conventionalized in the minds of the officer corps. Considering the British Army of the Rhine’s nuclear posture in Central Europe during this period, the acceptance of all things nuclear would have certainly been pleasing news for the Army Council. Yet, curiously another set of answers indicated that the majority of officers who witnessed the explosions believed that nuclear weapons would make war as an ‘art’ much more difficult. This is not the place to argue whether war is more akin to an art or a science (not now, Carl), but it does highlight the complexities and uncertainties that surrounded the profession of arms during the nuclear era.\nBy Simon Moody, PhD Candidate, King’s College London","CHEAP PRINT IN RENAISSANCE VENICE\nSalzberg, Rosa. Ephemeral City: Cheap Print and Urban Culture in Renaissance Venice. Manchester (UK), Manchester University Press, 2014. ISBN: 9780719087035; 240pp.; $110.00.\nSalzberg’s study, building on much new research by Salzberg and other historians into the documentary evidence from the period, greatly expands the conventional picture of early printing and its cultural impact, to include the large and lively business of “cheap print,” and that business’s large and lively audience, which was apparent in Venice from the late 1400s. Salzberg describes the printers and performers, and their typical backgrounds, along with the social, physical, political, and professional setting of the business, and its role in the culture of the time.\nCheap print includes pamphlets, broadsides, and flyers (fogli volanti) of all sorts—popular songs, bawdy poetry, religious images and writings, poetic treatments of current events, plays, political tracts, folk medicine, popular instruction on common practical topics, almanacs, etc.—as well as cheap books, especially of vernacular Italian literature (such as Aretino and, perhaps especially, Ariosto, generally in the form of abridgments or extracts). Some of the pamphlets were a hodgepodge of material of very different kinds.\nThis merchandise was commonly sold in the streets, often in conjunction with street performance. The same peddlers were also likely to sell soaps, perfumes, personal ornaments, and remedies, along with the printed items.\nStreet performers would hire printers to produce their printed matter, printers would produce printed items on their own initiative for sale to peddlers, and at least one or two street performers did their own printing. Many of the printers who produced such items were inexperienced newcomers taking advantage of the fact that printing, unlike other trades, was not controlled by a guild until the late 1500s. But there were often many and close connections between the street trade and some, at least, of the more august printing houses.\nCheap print was the medium for the transferral of much popular culture from oral media to print in a time of increasingly widespread literacy. The increased availability of texts increased the opportunities to learn and improve reading skills and the incentive to do so.\nCheap print was also the medium of a great deal of popular religious literature. This included much reformist and religious humanist literature, including extracts from Luther and Erasmus. This literature, heretical in Italy, often, but not always, passed successfully under the radar of the various censors. There was also a large volume of orthodox or counter-reformist literature, often printed with official stamps of approval. As with religious writings in other eras, the printed religious texts were often treated as amulets, folded up and kept about the person.\nEphemeral print helped to establish the vernacular in print alongside the Latin of the educated classes. It also, partly by virtue of the mobility of many of the peddlers, helped to establish a standard vernacular Italian as the language of print and national popular culture alongside the many spoken dialects that were not fully intelligible outside their home regions.\nPopular print was popular at all levels of society. Much of it was debased information for an ignorant and undiscriminating audience; for some in this audience reading would improve their understandings, for others it would merely lend the authority of print to their ignorance. But other works became popular not because their content was debased, but because quality content was, for the first time, made available in an affordable and accessible format.\nIn the early Renaissance, content and perspectives of all kinds found their way into cheap print. This began to change in the 1500s, as authority exerted greater control. The impulse was increased with the Reformation, in which print was clearly important as a vector for the diffusion of heretical ideas in Italy (as elsewhere). This brought the interests of Venice in line with those of the Church of Rome. Venice tended to preserve its own independence and initiative, but the goals of the two powers were increasingly the same. One medium of control was the establishment of the printers’ and booksellers’ guild, the last guild to be formed in Venice, in 1549.\nCheap print often escaped efforts at control, but only insofar as it was too debased to matter, or because its producers and their products were too hard to pin down. Religiously-oriented authorities tended to increase their control beyond matters of political and doctrinal content, to cover general morality as well, and to enforce the doctrinal minutiae of Counter-Reformation orthodoxy. The role of the Church in Venetian censorship increased from the early 1560s, but it remained impossible to police the entire output. The brunt of the censorship was borne by well-established printers and books, and to a lesser extent by those who cried their works most prominently in the streets. Through the 1500s at least, manuscript remained an important vehicle for the circulation of sensitive political works (and also pornography, as moral censorship clamped down).\nThe newly-formed guild could be an instrument of resistance to authority as well as one of control. It depended on where the interests of the guild members lay. The guild was active in restricting its membership, to reduce competition and also to maintain standards of professional competence, notably through an apprenticeship system. The participants in the cheap print industry were too numerous for complete control, much less elimination. But by the end of the 1500s, they had become increasingly marginalized and hemmed in, and to some degree increasingly tamed.\nIn addition to political factors, there was also the establishment of commercially relevant product categories through trial and error in the marketplace.\nThe result of the first 130 years of the evolution of printing in Venice was that the interaction between different specialties and between different levels of learning decreased, and “a more circumscribed, distinct corpus of ‘popular’ literature intended for the masses emerged.” By the end of the 1500s (p. 163), “a clearer division was emerging between printed works”—mostly religious—“sanctioned for reading by the general public and those that could be handled only by the more educated.”\nAll content © 2016 by Ken Dezhnev. All Rights Reserved.\nThe Winged Hat logo is a trademark of Ken Dezhnev.\nType & Typefaces |\nThe Composing Room |\nGeneral Typography & Criticism |\nDigital Typography & Graphics\nMy Digital & Consulting Work\ntop of page"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:a08c715e-6b92-4b33-9727-1bd1688c7f14>","<urn:uuid:7ffba9bd-e72a-48b1-981e-c10adbb486c7>"],"error":null}
{"question":"How do the reference lines differ between latitude and longitude in terms of their length and parallelism?","answer":"Latitude and longitude lines differ significantly in their characteristics. Latitude lines (parallels) have different lengths but are parallel to each other, while longitude lines (meridians) all have the same length but are not parallel to each other. The longitude lines are widest at the equator (69.172 miles) and gradually merge to a point at the poles, while latitude lines remain roughly constant at around 69 miles apart (varying from 68.703 miles near the equator to 69.407 near the poles).","context":["Longitudes are geographical points of direction that identify how east or west a position is on the Earth. The points are measured in degrees and symbolized by the Greek letter λ (Spelt as lambda). Also, there are special lines that run through the North Pole to the South Pole connecting points on the same longitudes. These lines are called meridians. The most special meridian is referred to as the Prime Meridian. This particular longitude runs through Greenwich in England. It holds the position of zero degrees (0°) longitude. In order to establish the longitude of other places on Earth, the places are measured by the angle east or west in relation to the prime meridian. It starts from 0° on the east side to +180 and to the west, side the angle goes up to -180. A place's location north or south of the Prime Meridian is measured by latitude. This can be described as the angle between the local longitude and the equator.\nIt is important to note that the Earth is not a perfect sphere. If it were a perfect sphere then the longitude at a particular place would be equal to the angle between vertical north–south plane through that place and the plane of the Prime/Greenwich Meridian. It is a good thing that the Earth is not uniform, the presence of mountains and other irregularities on Earth’s surface make it possible to shift the vertical plane a distance from the axis. When an intersection between a north to south plane and the Greenwich/prime meridian happens, an angle is created and this angle forms the accurate astronomical longitude. The longitudes that are identified by maps are formed by the angle between the meridian that passes through Greenwich and a plane that passes perpendicularly through the curvature chosen as Earth’s sea level. This measurement is not very accurate since the Greenwich plane does not go through the actual sea level.\nOrigin and Discovery\nThe history of the longitude has been contributed upon by great minds in the fields of astronomy, map making, and navigation over many centuries. This information was and still is important. For example, in safe ocean plotting, a means of defining the longitude and latitude was very much needed. The process of finding precise measures took centuries and the contribution of very great scholars. The earliest works recorded on research on the longitude was in the 3rd century BCE by Erastosthenes. His work was later build up by one Hipparchus in the 2nd century BCE. The 11th century revealed a great mind by the name Al-Burini who discovered that the earth rotated on its axis, a discovery that forms the basis for the modern belief of how longitude and latitude are related.\nIn the pursuit of greatness, nations had to invest in overseas trade, settlements, and outposts. For this reason, the need for identifying the location of their ships in the sea using its longitude was of high importance. Nations like France, Spain, and the Netherlands offered great prizes towards the solution of the longitude issue.\nOne of the earliest solution to the longitude problem was based on time gaps. The method involved sailors determining the local time by using the sun as a reference point in comparison with their local time. This method solved the challenge of mechanical clocks not working at sea due to humidity and the motions at sea.\nBritain's Charles II started the Royal Observatory in 1675 so as to find out the longitude of places in order to aid navigators. A method called The Lunar Distance Method was discovered, where an accurate location of stars was recorded, then the moon’s motion in relation to the stars could be used to calculate the time at Greenwich. The challenge in this method was predicting the moon’s motions and lack of availability of accurate instruments for the observation.\nThe 1714 Longitude Act\nThe year of 1714 was a great year for the longitude research. The British government offered a prize of £20,000 for a solution to the longitude question by a closeness of half degree, which is an equivalent of 2 minutes. As a motivation, two solutions were created at the same time. A clock maker by the name John Harrison made the first relevant contribution through his creation of the Marine Timekeeper H4. This instrument was later renamed the Marine Chronometer. The other contributors include John Hadley, and the German astronomer Tobias Mayer, who perfected the earlier astronomical catalogues and instruments to be used in the Lunar Distance method. The Astronomer Royal Nevil Maskelyne made notable contributions through his efforts on the Nautica Almanac and the Board of Longitude. The Royal Observatory remains a testing point for marine scholars and astronomical observers. These efforts contributed highly to Greenwich becoming the referential Prime Meridian.\nLongitude is denoted by an angular measurement starting at 0° to +180° eastwards and -180° westwards. Lambda (λ) has been used to denote places location east or west of the Prime Meridian. Each degree of longitude apart is separated by 60 minutes and a minute is in turn divided into 60 seconds. For accuracy purposes, the seconds are captured by decimal points as such 23° 27.5′ E. This position can also be written as a decimal fraction as such 23.45833° E. The angular part can also be conveyed as radians to be used in calculations as a signed fraction of π (pi), or an unsigned fraction of 2π. During calculations, the west/east suffix is dropped to be replaced by the negative symbol (-) west of the Prime Meridian while the positive sign (+) is used to denote places east of the Prime Meridian. An intersection of a specific longitude and a specific latitude is then used to calculate the position of a place on Earth.\nTo determine the longitude of a place, the time difference between that place and the Universal Coordinated Time (UTC) is calculated. Speed of sun movement across the sky = the number of degrees in a circle/number of hours in a day = 360° ÷ 24 hours = 15° per hour. Therefore, for a person 4 hours ahead of UTC, that person is near 60° longitude (4 hours × 15° per hour = 60°). In order to be accurate on this calculation, one needs to have a chronometer fixed at UTC and also be able to determine a place’s local time using astronomical observation or solar means.\nSingularity and Discontinuity of Longitude\nIn mathematics singularity can be defined as a point at which a mathematical entity cannot be defined or it fails to behave in a particular normalized way of such entities, while discontinuity is defined as the lack of continuation of a function at a point in its field. While doing calculations it is important to know that the longitude is singular at the poles so calculations may not be very accurate at such points. The point ±180° Meridian represents a form of discontinuity that must be carefully handled. To predict and avoid errors in calculations, the longitude and latitude could be replaced by the horizontal position representation during calculations.\nInfluence of Tectonic Plates on Latitude\nThe tectonic plates are constantly moving at a speed of 50-100mm per year. This means that different places on Earth are always moving in relation to one another. This movements increase the longitudinal distances between two points at any particular place. For example, the difference between Uganda on the African Plate and Ecuador on the South American Plate is increasing by around 0.0014 arc seconds per year. To reduce the change in longitude or latitude between place on the same plate a reference frame can be used where the points/coordinates are fixed on a singular plate like NAD83 for North America.\nLength of a Degree of Longitude\nThe length in miles or any other measurement of a degree between longitudes is solely dependent on the radius of the latitude circle. Since the degrees of latitudes are parallel, you will find that the distance between each degree of latitudes will remain almost constant. On the other hand, since the degrees of longitudes are wider apart closer to the equator and closer at the poles, the distance between two longitudinal points vary greatly. The approximate degree of latitudes is 69 miles apart, but this figure varies on a range from 68.703 miles near the equator to around 69.407 near the poles. A degree of the longitude has been recorded to be the highest at the equator at 69.172 miles at the equator. This figure gradually reduces to 0 at the poles as the longitudes merge into one.","Latitude alludes to the horizontal lines that represent the distance of any point, north or south of the equator, its direction is east to west. On the other hand, longitude implies the vertical lines indicating the distance of any point, east or west of the prime meridian, its direction is north to south. Latitudes are also known as parallels while longitudes are termed as meridians.\nOn earth’s surface, locations are determined by the two reference lines known as latitude and longitude. In fact, these are the ‘geographical coordinates’ which are used by a pilot and the ship captain, to indicate the position on the map. So, take a read of this article that sheds light on the difference between latitude and longitude.\nContent: Latitude Vs Longitude\n|Basis for Comparison||Latitude||Longitude|\n|Meaning||Latitude implies the geographic coordinate which determines the distance of a point, north-south of the equator.||Longitude alludes to the geographic coordinate, which identifies the distance of a point, east-west of the Prime Meridian.|\n|Direction||East to west||North to south|\n|Symbol||Greek letter ɸ (phi)||Greek letter λ (lambda)|\n|Stretches from||0 to 90°||0 to 180°|\n|Lines of reference||Known as parallels||Known as meridians|\n|Number of lines||180||360|\n|Length of lines||Different||Same|\n|Parallel||Yes, the lines are parallel.||No, the lines are not parallel.|\n|Classifies||Heat Zones||Time Zones|\nDefinition of Latitude\nIn geography, latitude is defined as the angular distance of any point, north or south of the equator, i.e. it is a coordinate system, that is used as a reference point to locate places on earth.\nAn equator is an imaginary circular line drawn on the earth, which divides it into two equal parts, wherein the upper half is called Northern Hemisphere, and the lower half is known as Southern Hemisphere. The circular lines, parallel to the equator, up to the North and South poles are the parallels of latitude.\nLatitude ranges from 0 degrees to 90 degrees, wherein equator indicates 0° latitude and 90° is at the poles. The parallels lying in the northern hemisphere are considered as north latitudes, while those lying in the southern hemisphere are called south hemisphere. Some major parallels of latitude are:\n- Tropic of Cancer (23.5° N)\n- Tropic of Capricorn (23.5° S)\n- Arctic Circle (66.5° N)\n- Antarctic Circle (66.5° S)\nDefinition of Longitude\nThe angular distance of any point, east or west of the Prime Meridian or west of the Standard Meridian is called longitude. It ascertains how far a particular place is, from the reference line. The reference lines passing from north pole to the south pole is known as meridians of longitude. These are semi-circles, whose distance decreases firmly polewards, as they all meet at the poles.\nAll the meridians are of the same length, and so Greenwich Meridian is considered as the Prime Meridian to number meridians. The value of prime meridian is 0° longitude and separate the earth into two equal parts, i.e. Eastern Hemisphere and Western Hemisphere.\nKey Differences Between Latitude and Longitude\nThe points presented below are noteworthy, so far as the difference between latitude and longitude is concerned:\n- The geographic coordinates which ascertain the distance of a point, north-south of the equator, is called latitude. The geographic coordinate, which identifies the distance of a point, east-west of the Prime Meridian, is termed as longitude.\n- The direction of latitude is east to west, which is parallel to the equator. On the contrary, the direction of longitude is north to south, intersecting the two poles.\n- Greek letter phi (ɸ) is used to represent latitude. Conversely, Greek letter lambda (λ), is a symbol for longitude.\n- The range of latitudes is from 0 to 90 degrees, but the longitudes range from 0 to 180 degrees.\n- The parallel circles from the equator to the north and south poles are termed as parallels of latitude. As opposed, the lines of reference, running from the two poles is known as meridians of longitude.\n- The total number of latitude lines are 180. Unlike, there are a total number of 360 longitude lines.\n- The parallels of latitude are of unequal length, whereas the meridians of longitude are of equal length.\n- In latitude, the lines of references are parallel to each other. On the flip side, in longitude, the lines of references are not parallel to each other.\n- Latitudes are used to categorise heat zones, i.e. torrid zone, temperate zone and frigid zone. In contrast, longitudes are used to classify time zones.\nThe surface of the earth is vast enough that it was difficult to locate any point, without the utilisation of the mathematical method. For this purpose, fictional lines are drawn on the globe, known as latitude and longitude. Both the latitude and longitude are imaginary lines, which are used to locate points on the earth’s surface, measured in degrees."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:e0159a1a-fc2e-4609-b92a-239a61a8a178>","<urn:uuid:98875f6c-08ab-40fd-b693-c8b6fb4c27dd>"],"error":null}
{"question":"How do the viewing experiences compare between the Esfahak observatory in Iran and the Griffith Observatory in Los Angeles?","answer":"The observatories offer distinctly different viewing experiences. The Esfahak observatory provides a focused, intimate experience through its design of three concentrated circles, with the central space specifically designed for direct sky observation where visitors 'don't want to see anything other than the sky itself.' The Griffith Observatory, meanwhile, offers multiple ways to view celestial objects, including the famous 12-inch Zeiss refracting telescope (through which over seven million people have looked), solar telescopes providing live views of the sun, and planetarium shows in the Samuel Oschin Planetarium theater where visitors can recline while learning about stars and the universe from live docents.","context":["- Architects: Contemporary Architects Association\n- Location: Isfahan, Isfahan Province, Iran\n- Architect In Charge: Amirali Zinati, Behnaz Motarjem, Aidin Emdadian, Sonia Beygi, Bahar Mehdi Pour, Hamidreza Malek Khani, Ramtin Ramezani\n- Area: 69.0 m2\n- Project Year: 2017\n- Photographs: Anis Eshragi\n- Consultant: Pouya Khazaeli\n- Local Partners: Mohsen Mehdizadeh, Mostafa Yaghoubi, Hosein Bagheri, Mehdi Hoseini\n- Text: Behnaz Motarjem\n- Association: Contemporary Architects Association CAA\nFrom the architect. It is the last days of winter. The weather is going crazy again. The pressure to finish everything before new year has pushed everyone to the streets. It’s as if it were a small rehearsal for the end of the world. We see each other in this mayhem. When there’s no time to start anything and everything must finish in the fastest way possible. We start in a weather for which we’re not quite sure how to dress, minutes away for the alarm to ring, some steps behind the finish line. It is 10 o’clock, March 10th, 2017. Our meeting is on the first floor at The Contemporary Architects Association.\nWe introduce ourselves the way we think we are.We get to know each other. We’re a new group but the decision is the same as last year’s. To build out of soil, in Esfahak, Southern Khorasan, to go by train, 17 hours away. This time we’ll build what they want us to. “an observatory”. In a lot near the school. A circle for twenty people to gather around. One meter above ground level.\nTomorrow afternoon we’ll build the adobe moulds out of wood.The adobe bricks will be 2 cm x 2 cm and 0,5 cm thick. Now we’ve really got started. Various halfway done designs are built on the tables. We choose one and decide to keep working on it. Sometimes we work more, other times we talk. Soon We realize this can’t be done by talking. It can’t be done until it’s built. In the middle of our talks there’s always someone saying “let’s build!”\nThree concentrated circles. The one at the center is the highest one and will be where man meets the sky. And two other circles that encompass a single person passageway that leads to the center. The place where we don’t want to see anything other than the sky itself. The design changes whilst building it. It seems as if everyone wants to become smaller so that they can walk inside the model before it’s actually built. We decided that the aim of this design is to concentrate. We won’t leave this circle. The walls go up and a week later, the job is done. We clean the surroundings and stand back with our mortar covered hands to observe. The observatory dream is ready.\nTwo days later we leave for Esfahak. We arrive at midnight. We barely sleep. We meet again in the morning. The old and the new that have recently joined us, and most importantly – Esfahak itself. Now we are a group from Montréal, from London, from Tehran, Kerman and Mashhad. What loud noise has brought us all together? Our work with adobe and dirt starts. The working lot is next to an old cob wall. This is where we’ll spend the next days. Nobody waits. There’s enough to do for everyone and more. We collect stones for the foundation. Some people mix the mortar with their bare feet. We laugh loudly. Our inhibitions are soon gone. Clean and ironed clothes are soon covered with dirt. We get to know each other better. One day working under this sun, with our feet deep within this soil and dirt equals to months of painful getting to know each other in the city. When we leave for lunch, the mortar is ready, the foundations built and we all know each other just so much better. After lunch at “Haji Pedar’s”, which is where we’re staying, we rest for a bit. Our working schedule is like the sun’s. We work just like the sun. Whatever we do is during the day. We balance the surface with mortar and adobe. The building of the walls starts with the outermost one.\nWe don’t have a plan to divide work, but we ask each other. We can tell what our bodies can and cannot do. Now everyone has their own place. With each brick over the other, row over row, we get to know ourselves better. One by going back and forth between different tasks and another by constantly working on a single one. Practice makes perfect. Constant shoveling has left our backs hurting. But we get better at it. We finally get what’s the best consistency for the mortar. Meanwhile, “Abbas Agha” arrives every once in a while with a new fresh batch of adobe bricks. We line up and empty the bricks. Reza and Pooyan make tea. How good it is to drink a cup of tea when you’re so tired. Everything must be mentioned, remembered. The greens that we had, the lunches, the short afternoon naps, the tea, the laughter, the joy of discovering each other and ourselves. They all were needed just as much as the adobe bricks and mortar to build the observatory. Just as involved in the process. We wash our tools in what’s left of the sunlight at the end of the day and store them in a small room where there are also two graves.\nWe have already started worrying about how we’re going to go back, even though it’s still early. Here, each moment that we work we’re connected to it all. Free of paperwork, the threads of life, the promises we’ve made, the gloominess and the need of anything from outside. This is an entire world by itself. We work and we eat and we talk and we are happy. We gather at nights and try to stay awake as much as we can. Our bodies are worn out and that means that, for the first time, our bodies are there –present. How could we ever go back?\nThe next days, newly shaped clouds, the wall keeps going up, people talk with us through the wholes of the cob wall. We have as many visitors as the adobe bricks we have used so far. What is it that you’re building? An observatory. It is for Esfahak? Yes. So it stays here, for us? Yes, it stays here, for you. The children join us. Our work excites them. Sometimes they help us out by handing bricks to us, other times they bring “chaghale badoom” for us. Now the walls have gone so far up that we are the first to fall victims of our own design. We’re inside and our connection with the world outside is severed. The sky is overhead and now we must work at nights with whatever lighting we can get. We get to observe the starry sky before anyone else.\nWe put up the middle wall last. With a 45 degree rotation per each adobe brick. The texture it creates looks like the palm trees we see every day and perhaps sleep in their shadows. We build the biggest palm tree in Esfahak with our newly acquired and faster skills. The last days everyone comes to help. Mustafa, Mohsen, Reza, Adel and the rest. It’s the last rows of brick and the wall has gone far higher up than our height. We are already missing this all. You can’t see the entire work from a single place. It doesn’t fit in our eyesight. We climb up walls and even go up the rooftop of some ruins next to the lot we’re working on. You can always hear someone yelling “come see how it looks from up here!” A child grown so big that its mother can’t look out for it anymore. The last day we take out all of the barrels and wooden boards we used to climb up and down and work. The passageways are now empty. Each time we are passing through them we meet each other. We go up again to the central innermost circle, one meter above ground level. It’s as if we’re on top of a castle. Our work is done. We built a castle. We conquered it. The observatory doesn’t need us anymore. It can stand on its own.\nHow do we go back? In silence. Hurt and hopeful. We are discoverers.","Visited: December 2017\nIf you want to see some real stars when you visit the Hollywood area, forget Hollywood… this place is it! The Griffith Observatory is one of Southern California’s most famous landmarks, and millions of visitors have gotten spaced out here out since it opened in 1935. It’s a short drive from Hollywood, and is a fun, yet educational, spot to take in at day or night, especially when a celestial event is taking place.\nThe land where Griffith Observatory sits was once a part of a Spanish settlement known as Rancho Los Felis. The property remained in the Felis family for more than a century and was subdivided through generations until Griffith J. Griffith (his parents must have had a weird sense of humor), a wealthy mining speculator who was born in Wales, purchased what remained of the rancho in 1882.\nFrom the observatory website: “During a tour abroad, Griffith had discovered the great public parks of Europe and decided that his home, Los Angeles, would need a ‘Great Park’ for the public in order to become a great city.\n“On December 16, 1896, he donated 3,015 acres of Rancho Los Felis to the City of Los Angeles in order to create a public park in his name. “It must be made a place of rest and relaxation for the masses, a resort for the rank and file, for the plain people.” Griffith Park became the largest urban park in the U.S. with wilderness areas.”\nHe became interested in astronomy after numerous visits to the nearby Mount Wilson Observatory, and Griffith “offered the City of Los Angeles $100,000 for an observatory to be built on the top of Mount Hollywood to be fully owned and operated by the City of Los Angeles. Griffith’s plan for the observatory would include an astronomical telescope open to free viewing.” Griffith died in 1919. Understanding his vision would not be completed in his lifetime, he drafted a will “containing bequests for a public observatory and a Greek theatre,” where I’ve seen the Moody Blues on more than a few occasions.\nDigression: Griffith J. Griffith was involved in the first “Trial of the Century.” We heard this story on our tour of the Hollywood Forever Cemetery (the obelisk tomb is Griffith’s…with the observatory in the background).\nGriffith was vacationing in Santa Monica in September 1903. While staying in the presidential suite of the Arcadia Hotel, Griffith shot his wife in the face as she knelt on the floor. She lived, but was severely disfigured and lost her right eye. Griffith was charged with assault with a deadly weapon with intent to commit murder. Henry T. Gage, the former governor of California, led the prosecution team. Griffith’s attorney’s cross-examination of the veiled Mrs. Griffith revealed that her husband, who was believed to be a teetotaler, was actually a closet drunk and “subject to paranoid delusions.” Griffith was unbelievably convicted of a lesser charge…assault with a deadly weapon. The judge sentenced him to two years in San Quentin State Prison, instructing that he be given “medical aid for his condition of alcoholic insanity.” Not surprisingly, this story is absent from the Griffith Observatory website.\nThe preliminary plans for the observatory were drawn up by well known Caltech physicist Edward Kurth, who also guided the construction of the building. In May of 1931 the Griffith Trust and Los Angeles Park Commissioners selected architects John C. Austin (seen below…photo courtesy of Los Angeles Public Library) and Frederick M. Ashley to oversee the final plans for the new observatory building.\nRussell W. Porter (below), who was known as the “Patron Saint of the amateur telescope-making movement,” worked with Kurth on the project. Kurth also never saw the grand opening, as he was killed in an automobile accident in February 1934, one year before the dedication and opening ceremonies in May 1935.\nTracy and I first visited the Griffith Observatory together in 2012 when it re-opened after its second major renovation. Recently, I decided to pay a return visit to see what’s happening in 2017. I drove up the winding road leading to the observatory, and even though it was 30 minutes before opening, the parking lot was nearly full (there’s lots of hiking in this area, too). The views from here stretch out to the ocean in one direction…\nNumerous films have been shot at the observatory, including Rebel Without a Cause, the classic 1955 film about misunderstood youth, starring James Dean and Natalie Wood. There’s a bust of Dean outside the observatory.\nAdmittance to the Griffith Observatory is free, and I recommend if you go on the weekend, you arrive there well before it opens at 10, because it gets really crowded by about noon and parking is then relegated to the road where you have to take a hike to the observatory. (Opens at noon Tuesday – Friday. I also recommend you get here early on those days.)\nThere were lots of people milling around the observatory before it opened. Many of those people include the hikers who walk up here on a 3 1/2 mile loop from the Fern Dell Trail (we like to do that with the Corgis). It’s a beautiful hike.\nDigression 2: Frank Shearer was a famed “plantsman,” and in 1912 “he began planting native and imported ferns within a natural canyon nestled in the park’s southwestern quadrant that was once the Mococahuenga council grounds used by the Gabrielino Indians for tribal meetings. By the start of the 1920s the first of Fern Dell’s rustic bridges, footpaths and faux bois (French for “false wood”) features, designed by New Zealand landscape architects, the Montgomery Brothers, had been constructed.”\nI highly recommend hiking the Fern Dell trail, even if you don’t go up to the observatory. I can tell you that our corgis, even with their short legs are able to navigate the entire route (much better than their out-of-shape parents).\nThere are a few interesting sights to check out in front of the observatory before entering. First, I stopped by an obelisk (Astronomers Monument). The monument “pays homage to six of the world’s most famous astronomers Galileo, Copernicus, Kepler, Newton, Hipparchus and Herschel.”\nThis was a “New Deal” project. Local artist Archibald Garner conceived the design who, along with five other artists sculpted the monument, with each one sculpting one of the astronomers. It was dedicated in November of 1934 (about six months prior to the opening of the Observatory).\nIn front of the Astronomers Monument is the Equatorial Sundial, made with high-nickel bronze. I assume this is how people gauged time before the iPhone. On the front sidewalk, just before you climb the steps to enter the observatory, check out the Solar System Lawn Model, which is a scale model of our solar system.\nNow it was time to check out the observatory. If you arrive early, that’s the best time to purchase tickets for one of the Planetarium shows they present each hour. Ticket prices range from $3 to $7 for the shows in the Samuel Oschin Planetarium theater (comfy seats where you recline and listen to a live docent who tells story of stars and the universe), while the shows in the Leonard Nimoy Event Horizon presentation theater are free…a most logical choice.\nMy suggestion is to arrive here when the observatory opens. When you step inside you’ll be in the Central Rotunda and there’s some cool things to see in this room. The rotunda “celebrates the intersection of science and mythology, earth and sky.” Perhaps the most popular spot in the entire observatory is located in this room. As you can see, the first thing most people usually do when they enter is congregate around the Foucault Pendulum.\nA favorite of visitors since the observatory opened, the 240-pound bronze ball suspended by a 40-foot cable “swings in a constant direction while the Earth turns beneath it.” For the patient among us, keep watching for a while as it knocks over pegs set up in the pendulum pit. The pit and the pendulum make for an interesting experience, as well as a good read.\nAfter looking down at the pendulum, raise your eyes to the colorful Ballin Ceiling Mural. In the 1930s, painter Hugo Ballin illustrated ancient stories of the sky. This ceiling tells stories of Atlas, Zeus, Mercury and even a woman holding the Star of Bethlehem.\nAlso in this room are the Ballin Wall Murals, Ballin’s attempt to “celebrate the progress of science through his spectacular art.\nIf you arrive early, here is my suggestion for visiting: Instead of seeing the rooms on the entrance floor (like most of the rest of the crowd), head downstairs and you should have virtually this entire space (pun very much intended) all to yourself. After walking down the stairs I entered the Cosmic Collection, a long hallway explaining the history of the Universe starting with The Big Bang Theory (not the television show).\nI found myself in the Edge of Space area, and more specifically the Pieces of the Sky that feature some very large meteorites. The 183-pound Bruceville Meteorite was found by a farmer as he plowed a field near Sacramento. It traveled to earth thousands of years ago.\nNot seen on my recent visit here was this photo that adorned the wall in this area back in 2012. As you can see, this Alabama woman made dubious history when she became the “first person documented to have been struck by a meteorite.” That’s one way you can get a piece of the rock.\nThe Griffith Observatory boasts The Big Picture...“the largest astronomical image ever put on display.” On this floor, I took a look through one of the many observing telescopes, which “enables visitors on the Edge of Space mezzanine to use simple Observing Telescopes mounted 60 feet away to explore objects in greater detail.”\nThen it was off to The Moon, where I learned about our closest neighbor and also what my weight would be on the moon’s surface. I stood on a scale that showed me on the moon I would weigh a mere 35 pounds (no Jenny Craig needed there).\nNext, I was now inside the Gunther Depths of Space Exhibit. I ran into an old friend of ours who we met in 2012. Tracy thought it might be her cousin, and I quickly realized her theory of relativity was not quite up to Albert Einstein’s, although I heard when he presented it, someone yelled out, “It’s about time!” Interestingly, Einstein was initially going to be one of the people carved on the Astronomer’s Monument in front of the observatory, however the planners felt it would be inappropriate to feature someone who was still alive.\nIt was time to learn about The Planets. While reading about each planet, I weighed myself to see what I would weigh on each one.\nFor instance, on Mercury I weighed 85 pounds, on Venus I weighed 160 pounds, while on Jupiter I weighed nearly 500 pounds, which coincidentally was my actual weight after this past Thanksgiving dinner.\nIn a little room I saw the Zeiss Mark IV planetarium projector. It was used at Griffith Observatory from 1964 to 2002. The planetarium theater was actually used to help astronauts “practice their stellar navigation skills.”\nAfter checking out the gift shop (that might be a good present for Tracy) and the Cafe At The End of the Universe…\n…I headed back up to the level where I entered the Wilder Hall of the Eye.\nI took a quick look at the Camera Obscura that “enables visitors on the Edge of Space mezzanine to use simple Observing Telescopes mounted 60 feet away to explore objects in greater detail.”\nBesides being an instrumental part of Bohemian Rhapsody by Queen, Galileo, among other things, mapped the moon’s surface and discovered the moons of Jupiter. It was in this area where I encountered The First Astronomical Telescope of Los Angeles. It was made by the John Byrne Company of New York in 1888, and its first owner was a retired physician and former State Senator.\nI heard they were going to have a Tesla demonstration, and although I can’t afford one, I was excited to see it. Unfortunately, the demonstration wouldn’t take place for nearly another hour, and it was actually Nikola Tesla’s coil that we use to bring electricity to our homes which would be demonstrated. I never witnessed that current event.\nI walked back under the Ballin Ceiling and entered the final part of my inside journey in the Ahmanson Hall of The Sky Exhibits. Gazing at the Phases of the Moon display, I thought back to my childhood when, for a moment, I dreamed of becoming an astronomer. However, just like the moon, it was only phase I was going through.\nIt wasn’t the only colorful exhibit in the room.\nI wandered in this room where one can view “three solar telescopes in this room use light coming through the coelostat in the dome overhead to provide live views of the constantly changing Sun.” I stepped outside, climbed the stairs to the top, where I saw the Coelostat (solar telescope) Dome.\nMany times you can get some pretty great views from up here…\nMy last stop at the observatory was the Zeiss Telescope. According to the website, ”Since opening in 1935, more than seven million people have put an eye to Griffith Observatory’s original 12-inch Zeiss refracting telescope. More people have looked though it than any other telescope in the world.”\nBack in 2012, as we headed toward our parked our car, near the edge of the parking lot we saw a tree. But this was not just any tree. This was the George Harrison Tree…whether it “gently weeps,” I did not know, however it was Something to see. (photo below is from our 2012 trip).\nDigression: On February 22, 2004, the City of Los Angeles declared George Harrison Day. A plaque was unveiled at the base of the George Harrison Tree in Griffith Park. (Note…in June 2014, the George Harrison tree was declared dead. The irony…it had been destroyed by beetles…can’t make this stuff up). A Yew tree, less susceptible to insects, now stands in its place. Hopefully, they’ll never have to find another yew. (Photo from The Guardian of the new tree planting)\nWalk another mile or so to get a good view of the Hollywood sign…\nFor a free experience (except for parking and the show), there are not many better places to visit than the historic Griffith Observatory. You can take a hike and explore the planets all in one afternoon. It is the true star trek and a place you should scope out.\n2800 East Observatory Road\nLos Angeles, CA 90027\nHours: Tuesday – Friday 12 p.m. to 10 p.m.\nSaturday – Sunday 10 a.m. to 10 p.m. • Closed Monday\nCost: Free (except show tickets, which are $3 to $7)\nParking: $4 per hour during observatory hours\nPublic Transportation can be an easier way to get here."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:f640b7c2-4e2d-45ed-8d4d-7374b0b7bb63>","<urn:uuid:c4a64f09-cb3b-4ec0-b61b-e1f5cf5e5041>"],"error":null}
{"question":"What triggered the rapid expansion of Qatar's air force and what did it involve?","answer":"Qatar's air force underwent an unprecedented expansion from operating just 12 Dassault Mirage 2000-5s to ordering 84 new fighter aircraft. This expansion included orders for 24 Dassault Rafale fighters in May 2015 (plus 12 additional ones in December 2017), 24 F-15QAs in November 2016 (with an option for 12 more), and 24 Eurofighter Typhoons in September 2017. This massive growth from 12 to 84 aircraft required substantial investment in both training and infrastructure. The expansion was part of broader GCC efforts to modernize their air forces and reduce reliance on US military support.","context":["Published in the Middle East Feb/Mar 2021 Supplement – The expansion of GCC Air Power has been rapid and in no small measure driven by region rivalry with Iran.\nIn recent years, the air forces of the Gulf Co-operation Council (GCC) nations (the Kingdoms of Saudi Arabia and Bahrain, the States of Kuwait and Qatar, the United Arab Emirates and the Sultanate of Oman) have undergone major modernisation and expansion programmes. Though the scale and pace of this process has increased markedly in recent years, it is more deep-rooted than is sometimes supposed. The process dates back to before Operation Desert Storm (1990-91), though it accelerated significantly about ten years ago, following the so-called US “Pivot to Asia” pursued by the Obama administration, and with the associated publication of Hilary Clinton’s ‘America’s Pacific Century.’\nIt became increasingly clear that although the US would remain engaged in the region, its allies in the Middle East would be expected to shoulder a greater share of the burden of defending themselves, supporting and co-operating with deployed US, British and French forces rather than substantially relying on these foreign elements. This added impetus to the drive to achieve greater interoperability with US forces, ensuring that new military installations were built to US and NATO specifications, and that personnel were trained to operate alongside allied forces. GCC air forces increasingly began to train with air arms from outside the Gulf – sometimes hosting exercises such as the UAE’s Advanced Tactical Leadership Course (ATLC), and sometimes deploying to exercise overseas. The Royal Saudi Air Force (RSAF), for example, participated in the Red Flag exercise in the USA, and in exercises in the United Kingdom and France.\nAt much the same time, some of the larger GCC nations embraced a more outward-looking stance, and adopted a greater willingness to operate on the international stage. Sometimes this meant using national wealth to support humanitarian assistance to other nations (especially other Muslim nations) – and this drove Qatar’s acquisition of the Boeing C-17 Globemaster, for example. Sometimes this new more international outlook resulted in GCC members participating in combat operations as part of an international coalition. The UAE beginning a rotational deployment in Afghanistan from 2007, and just four years later, both the UAE and Qatar deployed fast jet aircraft to participate in the NATO-led intervention in Libya.\nGCC air forces demonstrated their readiness to operate under US command, as part of an international coalition from 22 September 2014, when Saudi, Emirati, Qatari, Jordanian and Bahraini fast jets joined US aircraft in air strikes against Daesh targets in Syria, and were themselves later augmented by Moroccan General Dynamics F-16s.\nRivalry With Iranian\nFor Saudi Arabia, growing rivalry with the Islamic Republic of Iran was a major concern, especially after a multi-sided civil war began in Yemen on its southern border in late 2014, with Iran supporting and arming the Houthi rebels.\nTensions between Saudi Arabia and Iran go back many years, based in part on the rivalry between the Sunni and Shia branches of Islam, and on competition between the two for leadership of the Islamic World, as well as the very different forms of government – one an absolute monarchy, the other a theocratic Republic. These tensions are exacerbated by their very different relationships with the US and their attitudes to its influence over, and presence in, the Gulf region. The two Islamic powers even differ in their approach to oil pricing, with Saudi Arabia taking a longer-term view of the global oil market with a willingness to moderate prices, while Iran, with much smaller reserves and a larger population, tends to focus on high prices in the shorter term.\nSaudi Arabia’s concerns about Iran grew as Iran attempted to spread its influence, funding and training insurgent groups in Lebanon, Syria and post-Saddam Iraq, and as Iran intensified its efforts to build up its own nuclear arsenal.\nIn June 2017, Saudi Arabia, the UAE, Bahrain and Egypt severed diplomatic relations with Qatar, citing Qatar’s supposed “embrace of various terrorist and sectarian groups aimed at destabilising the region”, but also motivated by rivalry between these major oil and natural gas producers and by Qatar’s relations with Iran (they share the world’s biggest natural gas field). Relations are now being restored.\nThe Yemeni civil war has dragged on, however, and Saudi Arabia and its allies (including Sudan and Egypt) have continued to mount airstrikes against Houthi targets, with inevitable collateral damage to Yemeni civilians and civilian infrastructure provoking widespread condemnation.\nState-owned Saudi Aramco oil processing facilities at Abqaiq and Khurais in eastern Saudi Arabia came under attack by unmanned aerial vehicles (UAVs) on 14 September 2019. The Houthi movement in Yemen claimed responsibility, but direct Iranian involvement was widely suspected.\nThe need to deter and counter the Iranian threat has been a significant factor behind ongoing efforts by GCC air arms to modernise and expand.\nAir Power Expansion\nEven 30 years ago, one GCC air force was operating at significant scale, and was beginning to reduce its reliance on expatriate personnel. According to the US Air Force’s official Gulf War Air Power Survey, the RSAF flew more sorties than any other non-US coalition air arm during Operation Desert Storm (5,829 of them), and was the only non-US partner air force to score an air-to-air ‘kill’ during the conflict.\nThe Douglas A-4 Skyhawks and Dassault Mirage F1s that fled in the face of Iraq’s invasion also allowed the ‘Free Kuwait Air Force’ to fly 780 interdiction sorties (more than the French Armée de l’Air, for example), but generally, the GCC air forces were too small to play a leading part in the Allied air campaign, and the GCC nations’ most important contribution was in providing bases for US, British and other allied aircraft.\nEven before Iraq invaded Kuwait, Arab air forces were embarking on modernisation programmes. Saudi Arabia had introduced McDonnell Douglas (now Boeing) F-15 Eagle interceptors and British-supplied Panavia Tornados, Kuwait had already ordered some 40 McDonnell Douglas (Boeing) Hornets (32 single-seat F/A-18Cs and eight two-seat F/A-18Ds), and Bahrain had started to receive the first of 22 General Dynamics (now Lockheed Martin) F-16C/Ds, while the UAE was looking at options for a new fighter to augment its Mirage 2000s. Oman replaced its ageing Hawker Hunters with new BAE Hawks in the mid-1990s, and ordered F-16s in 2005, while Qatar replaced 14 Dassault Mirage F1s with 12 Mirage 2000s from 1997.\nArguably more significant than the delivery of ‘teen series’ fighters to GCC air forces was the US decision to supply more advanced weapons, including Raytheon GBU-10/12 laser guided bombs, AGM-65D/G Maverick air-to-ground missiles and above all, the AIM-120 AMRAAM air-to-air missile, which gave the new generation of warplanes a real long-range punch that had previously been lacking. The US was initially resistant to the idea of introducing this capability into the region, in part to limit proliferation of this advanced technology but also to try to allow Israel to maintain a (Congressionally mandated) ‘Qualitative Military Edge’ (QME) over its neighbours.\nThe US rationale for maintaining this QME is to support what it regards as a reliable and democratic ally, compensating for Israel’s smaller size and population than its potential adversaries. It also allows the US to use Israel to advance its geostrategic goals without the need to deploy additional US military forces. Israel has been used as a cost-effective, trustworthy, battle-hardened, force-multiplier and as a useful laboratory for US defence equipment, technology and tactics.\nEventually, in November 1999 Bahrain was given permission to procure AIM-120B Advanced Medium-Range Air-to-Air Missiles for its F-16 fighters, becoming the first Gulf Arab country to acquire these advanced missiles. The then-defense secretary William Cohen also promised to sell the AIM-120 to Saudi Arabia.\nBy the turn of the Millennium, it was clear that the ‘teen’-series fighters equipping GCC fighter arms would soon be rendered obsolescent – increasingly unable to guarantee success against developed versions of the Sukhoi Su-27 ‘Flanker’ (then viewed as the baseline threat), and by the new generation of fighters exemplified by the Eurofighter Typhoon, Dassault Rafale and Saab Gripen.\nAfter evaluating the Rafale, the UAE opted instead to acquire a new, bespoke derivative of the F-16, equipped with a new Northrop Grumman AN/APG-80 AESA radar, an internal FLIR and a state of the art electronic warfare suite. The Block 60 F-16E/F Desert Falcon was the most advanced F-16 variant ever produced, and was more capable than any USAF version. It also represented the most advanced fighter aircraft in the GCC. The F-16s augmented the UAE’s Mirage 2000s, rather than replacing these, and effectively doubled the UAE’s fighter force at a stroke. The UAE announced the purchase of 55 single-seat F-16Es and 25 two-seat F-16Fs in May 1998, and deliveries began in 2004. Subsequent efforts to acquire further advanced fighters saw the announcement of deals for the Dassault Rafale, Eurofighter Typhoon and Block 61 F-16s, but none were concluded. Most recently, the UAE appeared to have acquired the Lockheed Martin F-35A Lightning Joint Strike Fighter – if ITAR and Israeli QME concerns can be overcome, as well as a pause of sale initiated by President Biden’s administration.\nIn Saudi Arabia, the RSAF announced its intention to purchase the Eurofighter Typhoon from BAE Systems in December 2005, subsequently signing a Memorandum of Understanding (MoU) for 72 aircraft in 2006. In December 2011, Saudi Arabia signed a $29.4 billion deal for 84 Boeing F-15SA (Saudi Advanced) aircraft, with 70 existing F-15S fighter bombers to be converted to the same standard. Though there have been persistent rumours of a further Typhoon order, and though an MoI for 48 further aircraft has reportedly been signed, a contract remains stubbornly just out of BAE’s reach!\nIn Oman, by contrast, the original batch of 12 F-16C/Ds were augmented by 12 further aircraft after a second contract was signed in December 2011, and one year later, a contract was signed for 12 Eurofighter Typhoons. But whereas the Saudi Typhoon armament package included the Diehl BGT Defence IRIS-T IR-homing AAM, the Omani aircraft was armed with the BAE ASRAAM – arguably the most capable close-range missile exported to the region. This was because when Saudi Arabia signed up for Typhoon the only option was the ASRAAM Block 4 (which used a seeker that was subject to ITAR restrictions) whereas Oman (and now Qatar) have bought the ASRAAM Block 6, which uses an MBDA-made (non ITAR) seeker.\nKuwait ordered 28 Typhoons (six of them two-seaters) in April 2016, and will arm its aircraft with the IRIS-T missile. These aircraft will be the first Typhoons equipped with a production AESA radar, and the first fighters in the region with a new generation AESA with a repositioner. The 28 Typhoons will be augmented by 22 F/A-18Es and six twin-seat F/A-18Fs, all being delivered to a standard close to the US Navy’s new Block III version, with an Elbit Systems wide-area cockpit display. The 56 Typhoons and Super Hornets will replace the survivors of 40 ‘Heritage’ Hornets, marking a small but significant expansion.\nQatar’s air power expansion was, by contrast, anything but modest. The Qatar Emiri Air Force had operated a single fighter squadron equipped with 12 Dassault Mirage 2000-5s, but ordered 24 Dassault Rafale fighters in May 2015, 24 F-15QAs (plus an option for 12 more), in November 2016 and 24 Eurofighter Typhoons in September 2017. The QEAF ordered 12 additional Rafales in December 2017, with an option for 36 more! The expansion of the QEAF fighter element from 12 to 84 aircraft was an unparalleled step, and necessitated a huge investment in both training and infrastructure.\nBahrain, whose acquisition of the AIM-120 AMRAAM triggered the latest round of air power modernisation sought a new fighter for many years, but was limited by budgetary constraints. The sale of 19 new Block 70 F-16s was first approved by the US State Department in 2016 but was delayed as a result of the Obama administration’s human rights concerns. Incoming President Donald Trump dropped the human rights conditions that Obama had imposed and in June 2018 a contract was signed for the sale of 16 new-build Block 70 F-16Vs, accompanied by the upgrade of Bahrain’s existing fleet of 20 F-16C/Ds to the F-16V Viper configuration.\nThough we have highlighted the expansion and modernisation of GCC fighter forces, there has been similar progress in the fielding of new and more capable intelligence, surveillance and reconnaissance (ISR), airborne early warning (AEW), tanker and airlift capabilities, and with the introduction of larger numbers of more sophisticated and more modern helicopters. Moreover, the modernisation and expansion of GCC air power continues at pace, and the region is becoming increasingly self sufficient and independent of the US. The biggest ‘gap’ is now in the ‘infrastructure’ of air power – especially on a supranational level, with no real co-ordinated and integrated air defence and command and control network at above national level.\nby Jon Lake"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:fb677ee2-83bd-4d83-8da5-6d1e529a93c6>"],"error":null}
{"question":"Could someone tell me what happens when white light goes through two prisms versus two close-up lens filters if we combine them? Want to understand difference in light behavior.","answer":"When white light passes through two prisms in sequence, as in Newton's famous experiment, the first prism splits white light into a rainbow spectrum, and the second prism recombines these colors back into white light. In contrast, with close-up lens filters, combining two of them adds their refractive powers together to increase magnification, allowing the camera to focus even closer to the subject. However, it's recommended not to combine more than two close-up lenses because this can cause mechanical vignetting (unwanted darkening of image edges). The key difference is that prisms split and recombine light colors, while stacked close-up filters simply increase magnification power.","context":["Prisms are common objects in our daily lives. Used for decorative, scientific and practical purposes, prisms are just about everywhere. Prisms also have a lot to offer as tools for science experiments. With a few inexpensive prisms and other materials, you can perform several of these experiments to show a range of optical phenomena.\nPrisms work by bending, or refracting, the light that hits them. There are several simple experiments you can do to show examples of this refraction. With a small, triangular prism, you can most easily show this effect. Get a piece of paper on which there is clear, fairly large writing. Hold the prism a short distance over the paper. You will need to experiment to determine the best distance for this, but it should not be more than a few inches. Looking through the prism, you should be able to read the words on the paper, but their location will appear different than when you are looking at the paper directly. Measure the angle by which the words have been refracted with a protractor. If you have several different prisms, you can check to see if different angles of refraction are produced.\nThe most famous effect of prisms is the rainbow. The refraction of light that occurs in a prism also has the result of splitting white light into its component colors. This splitting is because different wavelengths of light travel at different speeds when crossing into a new medium (such as the glass of a prism). A simple experiment involving rainbows is to show how rainbows always exhibit the same colors in the same order. Shine a bright white light directly onto a prism. Place a white piece of paper opposite the light to catch the rainbow. Using several different prisms, record the rainbow colors that you see. Make sure to note the order of the colors.\nYou can also recreate Isaac Newton’s famous prism experiment. When you shine the white light onto one prism, a rainbow is produced. Instead of projecting that rainbow onto a white surface, aim the rainbow so that it directly hits a second prism. Place the white surface behind the second prism so that light will hit it. You may need to adjust the prisms to line them up carefully. You will find that the second prism refracts the light again. This should produce the effect of combining the colors of the rainbow back into white light.\nYou can analyze the spectrum of a chemical using a special type of prism known as a diffraction grating. Place a light source that is burning a particular chemical or element (possible examples include sodium lamps or fluorescent lighting). Aim the light so that it passes through a diffraction grating and onto a flat screen. You will see a rainbow spectrum on the screen as a result. If white light is observed in this way, you should see a typical rainbow. If you look at a single-chemical light source, you will also see bright lines in the rainbow. These are called emission lines and are specific to the chemicals that produce them. Compare the observed lines with known lines for specific chemicals to determine the composition of your light source.\n- Dick Luria/Valueline/Getty Images","Quick and Dirty Guide to Camera Filters and their Uses\nclick on links to check our current stock of that type of filter ( ie - HAZE).\nWelcome to the wonderful world of camera filters. There are much more than we have listed here. But here are some basics for quick reference:\nUV - A UV filter absorbs Ultraviolet rays without changing the exposure. With most images, most people will not see a difference when a UV filter is used. Many prefer to use as lens protection.\nSKY Skylight filters absorb some ultra-violet, blue and green. Eliminates shadows turning out bluish or cold under skylight. Typical subjects are buildings, shades, snow scenes, portraitures, etc.\nHAZE - Haze is caused by dust particles in the air. These particles reflect shorter wavelengths more than the longer ones. Haze 1 reduces excess blue and transmits 29% at 400mm wavelength.\n- Sky 1A - Skylight filters can absorb UV light as well as providing a warm effect.\nSky 1B - Reduces the excessive bluishness that frequently occurs in outdoor color photography, especially in open shade under a clear, blue sky. The absorption peak is in the range which corresponds to the film's green spectrum. Also keeps skin tones free of colored reflections from nearby objects such as the shade of trees.\nPolarizers - A polarizing filter, used both in color and black and white photography, can be used to darken overly light skies. Because the clouds are relatively unchanged, the contrast between the clouds and the sky is increased.\nAtmospheric haze and reflected sunlight are also reduced, and in color photographs overall color saturation is increased. Polarizers are often used to deal with situations involving reflections, such as those involving water or glass, including pictures\ntaken through glass windows\nThere are two types of polarizing filters.\nThe metering and auto-focus sensors in certain cameras, including virtually all SLRs, will not work properly with linear polarizers, both because of the mirror and because of the beam-splitters used to split off the light for focusing and metering. Circular polarizers will work with all types of cameras.\n- A linear polarizer filter transmits one of two states of linearly polarized light.\n- A circular polarizer (sometimes called a CPL filter) similarly selects a linear state but then converts it to circularly polarized light, by adding a birefringent layer (typically a quarter-wave plate) to the filter after the linear polarizer.\nThe PL filter comprises a thin, neutral grey liner polarizing sheet sandwiched between two pieces of optical glass in a rotating frame. Eliminates undesirable reflections from glass or water surfaces and also increases contrast in distant scenes with both color and black and white films. Infrared effects can also be produced by using PL together with a red filter with B&W films.\nTo eliminate reflections, place the camera at about 30-40 degrees from surface. To darken the color of the sky, direct sunlight should always be at the back.\nWith SLR cameras the effect can be checked by looking through the viewfinder while rotating the filter. With other cameras, first determine the effect without the filter by looking through it and then attach the filter at the same angle to take the picture.\nThe filter factor is about 3-4 with either color or b&w film but may vary with the type of subject. With certain movie cameras the viewfinder may become excessively dark and cause the TTL meter to make a large error. In such cases use a Circular Polarizing filter instead.\nThe Circular Polarizing filter is made by sandwiching a linear polarizing sheet and a quarter wave retardation plate between two pieces of optical glass.\nThe effect is the same as with the PL filter but is for use for the cameras which cannot meter exposures properly due to a refracting prism, half-mirror or divider.\nSpecial Effects Filters\nStar or Cross Screen Filters\nThese filters are made out of high quality optical glass in which the surface is etched with a fine grid pattern. Depending on the pattern and size of grid, point light sources and reflections create multi-beam stars. The twinkle of an eye, of a diamond necklace, rhinestone, street light, ocean's wave are all examples of common uses. Interesting variations are possible when combined with other special effects attachments. The orientation of the star patterns can be creatively chosen by rotating the filter mount while observing the image.\nClose up lenses or Magnifying filtersClose up lenses are high quality optical magnifying lenses which shorten the close-focusing distance of the lens. It allows the lens to go closer to the subject than before and to achieve a larger image scale. An increase in the exposure time is NOT necessary. These lenses can be combined by adding their refractive powers. Do no combine more than two close up lenses because of the danger of mechanical vignetting. Often comes in sets of 3-4 filters.\nDiffuser - Diffusion filters are used to create soften images. The keywords are enchanting, romantic and dreamy. Basically, a diffusion filter diffuses strong light without affecting the sharpness and contrast of the image. Thus, it is different from the effect of out of focus. Diffusion filters are mainly used in portrait work. In general, small skin defects can be eliminated almost completely, and facial contrast and wrinkles are soften. To create a better result, aperture should be opened\nup so that the subject can stand out well against the background.\nNeutral Density - The purpose of standard photographic neutral density filters is to allow the photographer greater flexibility to change the aperture or exposure time, allowing for more control, particularly in extreme circumstances.\nND filters appear grey and reduce the amount of light reaching the film, they have no affect on color balance.\nThey have four main uses:\n- To enable slow shutter speeds to be used, especially with fast films, to record movement in subjects such as waterfalls, clouds, cars, seas etc.\n- To decrease depth of field by allowing wider apertures to be used, which helps separate subjects from their background.\n- To decrease the effective ISO of high speed film (ie:above ISO400) and allow it to be used outdoors in blight situations.\n- To allow cine and video cameras (which have fixed shutter speeds) to film subjects such as snow, sand or other bright scenes which would normally cause over-exposure.\nFOR Black and White photography and other creative uses.\nYou can dramatically alter the tones of a black & white photograph by placing colored filters over the camera lens. For example:\nRED - Especially effective for increasing contrast in B & W photography. Often referred to as Ansel Adams filter. Ideal for dramatic cloud effects in landscapes. Can also be applied creatively in color and infrared photography.\nGREEN - Reduces blue and red. Affects blue skies in almost the same way as the yellow filter but differentiates better between delicate hues of grass and foliage. Great for correcting skin tones, bringing out facial expressions in close-ups and emphasizing the feeling of liveliness. 11 is highly effective for indoor portraits under tungsten lighting.\nYELLOW - Reduces background blue, accentuates the other colors.\nEspecially useful for clear contrast between blue sky with clouds and foreground. Provides a natural tonal rendition. For portraits, this filter reduces freckles and red spots on skin and darkens blue eyes. Often used for subjects at intermediate distances.\nORANGE - Increases contrast between reds and yellows. Particularly useful for distant outdoor shots taken with a telephoto lens. Also useful in color photography for spectacular sunsets, seascapes.\nBLUE - makes\nreds and oranges become a touch darker and blues and greens slightly lighter. Blue is little used for black & white work and would mostly be considered as a contrast reducer which you can often do satisfactorily using a different paper grade.\nColor Correction - Color Conversion - Light Balancing Filters\nCool Series Filters (80A,80B,80C,82A,82C) - These filters compensate for an excess of red, orange or yellow.\n80A - These\nare color conversion filters for the use of daylight type color films with artificial light source. 80A increases the color temperature from 3200°K to 5500°K for the use with 3200°K lamps.\n80B - These are color conversion filters for the use of daylight type color films with artificial light source. 80B increases the color temperature from 3400°K to 5500°K for the use of photoflood lamps.\n80C - These are color conversion filters for the use of daylight type color films with artificial light source. Increases the color temperature from 3800°K to 5500°K for\nthe use of clear flash bulbs.\nThis filter is a conversion filter for exposures made on daylight film, or with a digital WB of daylight, under tungsten light. This will correct out the strong yellow-orange cast of the tungsten light. This filter may also be used for a special effect when the strong blue color is desired.\n82A - Reduces excessive red of the light, 3200K flood in early am or 3400K floods in late pm, daylight and daylight negative type films\nfor cooler results\nWarm Series Filters (81A, 81C, 85 series) - These filters compensate for an excess of blue or green.\n81A - These are light balancing filters used to decrease the color temperature slightly for a warmer (redder) tone. Corrects the tendency toward bluish tones. For example, the 81A should be selected when using tungsten Type B color film (3200°K) with photoflood lamps (3400°K)\n81B - These\nare light balancing filters used to decrease the color temperature slightly for a warmer (redder) tone. Corrects the tendency toward bluish tones.\n85 - These are color conversion filters for the use of tungsten type color films in daylight.\n85B decreases the color temperature from 5500°K to 3200°K\nfor the use of Type B color films\n85C decreases the color temperature from 5500°K to 3800°K. The effect obtained is the same as with daylight type color films used in daylight.\nFLA/FLB/ FLD Fluorescent light correction filters - Eliminates the deep blue cast resultant from shooting color film with fluorescent lights."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:ace15bed-3275-4842-a363-34d89dcaa8d2>","<urn:uuid:686efa34-47b9-4cfa-a329-afa28b3e6a2f>"],"error":null}
{"question":"Could virtual reality technology potentially help reduce medical emergencies on flights by helping train flight staff? Please compare the current state of VR technology limitations with the types and frequency of in-flight medical incidents that require intervention.","answer":"While VR has found use in job training applications, its current limitations, particularly cyber-sickness affecting 25-40% of users, could impact its effectiveness for flight staff training. In-flight medical emergencies occur roughly once every 604 flights, with the most common being fainting/light-headedness (37.4%), respiratory symptoms (12.1%), and nausea (9.5%). Flight attendants are already considered adequately trained in using the FAA-required emergency medical kit for treating lesser emergencies and initiating treatment for serious ones. VR training would need to overcome its technical challenges, including sensory conflicts and posture control issues, to be effective in preparing staff for the approximately 44,000 annual in-flight medical emergencies.","context":["And women more so than men.\nThe whole history of fiction shows that alternative realities are an attractive and profitable idea. So back in the 1990s, when electronics had arrived at a point where people could build headsets that blocked off actual reality and replaced it with a virtual version created inside a computer, it looked as if something world-changing might have arrived. Games companies were particularly excited, and Nintendo, Sega and Virtuality duly piled in.\nThe world, however, stubbornly refused to be changed. It might have put up with the low-resolution images, the choppy scene transitions and the poor controls, for these would surely have got better. It might also have put up with the price (the headsets in question could cost up to $70,000), for that would surely have come down. It could not, though, accommodate the dizziness, nausea, eye strain, vomiting, headaches, sweating and disorientation that many of the technology’s users (more than 60%, according to one study) complained of—a set of symptoms that, collectively, have come to be called “cyber-sickness”. Though not fatal to people, cyber-sickness certainly helped damage the industry, which more or less vanished.\nTwo decades later, however, virtual reality (vr) returned from the dead, with better images, smoother transitions and more precise controls. There were also applications beyond games. The upgraded technology has found use in social media, interior design, job training and even pain management. Moreover, a new set of companies, Oculus (now part of Facebook), htc and Sony, have come up with products that do not require a second mortgage to afford.\nDespite these improvements, though, vr has not lived up to expectations. It has done respectably, with sales in 2018 of $3.6bn, according to SuperData Research, a market research firm. But that is only 2.4% of the global market for games. Many people—and not just the usual hypesters—thought that this time around vr would become a blockbuster technology. It has not happened. Part of the reason is that cyber-sickness has not gone away. One study suggests between 25% and 40% of users still experience it.\nDealing with this is difficult, not least because there is an argument about what triggers it in the first place. Two theories dominate. One is that users experience sensory conflict—a mismatch between what they see and what their other senses and their real-world knowledge tell them they should be experiencing. The other is that the underlying cause is individuals’ inability to control their bodies and maintain proper posture when moving around in virtual environments. To complicate matters, both hypotheses could be true.\nSensory conflict there certainly is. For example, when users move their heads they expect what they see to change immediately in response. But time-lags and poor graphics mean their visual input often fails to meet the brain’s expectations. Dealing with this means increasing the “frame rate” at which the virtual world is presented to a user, improving the resolution of the images and reducing the latency of response to a user’s movements. All of these require clever processing by the computer responsible for creating the illusion.\nImprovements in tracking what a user is doing also help. “Room scale” vr systems let people move around in the real world while perceiving similar movement in the virtual one. Following a user’s movement can be done in one of two ways. Outside-in tracking relies on external cameras observing beacons of various sorts scattered around a user’s body. Inside-out tracking is the opposite: the beacons are scattered around the room and detectors on a user’s body employ them as reference points.\nOn top of all this, there is the design of the lenses that sit inside a headset in front of a user’s eyes to adjust optically for the fact that what is actually a nearby image is supposed to be some distance away. Since the shape of these lenses is fixed and the amount of adjustment required varies with what is being looked at, distortion is inevitable. But distortions are particularly noticeable when users move their eyes, says Paul MacNeilage of the University of Nevada, Reno. Some headsets therefore now track a user’s gaze and move the lenses within the headset in response.\nMake the input too credible, though, and you run into a different problem—the contrast between what a user’s eyes are seeing and what the motion-sensors in his inner ear are detecting. To deal with that, some designers program in a “virtual nose”, just visible to the user, to serve as a point of reference.\nThese tactics help. But they do not get rid of cyber-sickness entirely. That is where the second hypothesis, unstable posture, comes in. And it is one that has the virtue of offering an explanation of a mystery about the condition—why women are more likely to be affected than men.\nThomas Stoffregen of the University of Minnesota, who has studied the matter and found women four times as susceptible as men, cites the example of driving a car to explain the unstable-posture hypothesis. When turning the steering wheel, he observes, drivers need to keep their heads oriented to the road. They need to stabilise their bodies, particularly when the car is changing direction and pushing the body in different ways. “When you spend a lot of time in cars, you get used to doing that,” he says. “It’s a skill.” But in virtual environments, where there are no forces to act as signals, people have not learned to adjust their bodies properly. They lean when the virtual car turns, but in fact they are leaning away from stability. He finds this particularly affects women, who have lower centres of gravity than men. That may cause them to sway more. And increased swaying, he has found, correlates with higher rates of cyber-sickness.\nIt is a neat idea. But Bas Rok.ers of the University of Wisconsin-Madison believes there is a simpler explanation for women’s experience of cyber-sickness, which is that headsets are not designed for them. For vr to work properly, sets need to be adjusted to the distance between the pupils of a user’s eyes. In one popular brand, however, Dr Rokers found that 90% of women have an interpupillary distance less than the default headset setting, and 27% of women’s eyes do not fit the headset at all.\nIf Dr Rokers is correct, a big part of the problem of cyber-sickness might be dealt with by a small change to helmet design. If women’s rates of the complaint could be reduced to the level experienced by men, then a lot more people could enjoy vr rather than enduring it. And then, perhaps, it really might achieve its potential.","If you're a health professional, chances are you could be pulled into action if a passenger on a commercial airline experiences a medical problem.\nIt does get busy up in the skies. There are about 44,000 in-flight medical emergencies on commercial airliners worldwide each year, estimate researchers in the departments of emergency medicine at the University of Pittsburgh and East Carolina University.\nThat's an average of one medical emergency for every 604 flights, 16 medical emergencies per each million passengers, the researchers concluded after studying data from a Pittsburgh-based medical command center, for five major airlines, between Jan. 1, 2008 and Oct. 31, 2010.\nFainting and light-headedness account for the most common in-flight emergencies -- at a combined 37.4 percent of medical emergencies during the study period. People can get light-headed when experiencing a sudden drop in blood pressure when standing up or stretching.\nThe next most common medical problems were respiratory symptoms (12.1 percent) and nausea and vomiting (9.5 percent). In only 7.3 percent of the incidents was the medical emergency serious enough to cause diversion of the flight.\nIn nearly a third of incidents (31.2 percent), by the time the aircraft landed at its scheduled destination, the afflicted passenger had recovered sufficiently so that emergency medical service personnel were not requested.\nWhen EMS personnel did meet a flight, the patient was taken to a hospital in 37.3 percent of the incidents studied.\nThe more serious medical emergencies were cardiac symptoms (7.7 percent) and cardiac arrest (0.3 percent), seizures (5.8 percent), abdominal pain (4.1 percent) and possible stroke (2.0 percent).\nCardiac symptoms were responsible for 18.4 percent of all aircraft diversions, possible stroke for 16.4 percent, seizures for 12 percent. Only 0.5 percent of all in-flight emergencies involved obstetrical or gynecological symptoms, but these accounted for 18 percent of aircraft diversions.\nCardiac symptoms (21.5 percent) and cardiac arrest (16.7 percent) were responsible for the most hospital admissions, followed by possible stroke (23.5 percent) and obstetrical or gynecological symptoms (23.4 percent).\nCardiac arrest was responsible for 31 of 36 in-flight deaths during the study period. Fainting accounted for four, respiratory symptoms for one. The passengers who died ranged in age from 1 month to 92 years. The mean age was 59.\nThe emergency medical kit the FAA requires each airliner to carry is sufficient to treat all the lesser medical emergencies and to initiate treatment for the more serious ones, and flight attendants have been adequately trained in its use, the researchers concluded.\nOnboard assistance for afflicted passengers was provided most often by other passengers who were physicians (48.1 percent), nurses (20.1 percent), EMS personnel (4.4 percent) or other health care professionals (3.7 percent).\n\"Airline passengers who are health care professionals should be aware of their potential role as volunteer responders to in-flight medical emergencies,\" the researchers concluded.\nThe study was led by Christian Martin-Gill, Pitt assistant professor of emergency medicine, department of emergency medicine. It was based on calls from five domestic and international airlines to UPMC's STAT-MD Communications Center, a 24-hour physician-directed medical command center.\nThe study, which was funded by the National Institutes of Health, was published in the New England Journal of Medicine May 30.travel - mobilehome\nJack Kelly: firstname.lastname@example.org or 412-263-1476."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:93ec813c-aac3-4876-a4f7-4cf782f36697>","<urn:uuid:3a592517-c721-4ea2-af02-9806d5b9e54a>"],"error":null}
{"question":"Could you explain how both RIVA's compounding process and brivaracetam medication contribute to preventing medical errors, though in different ways?","answer":"RIVA and brivaracetam employ different approaches to prevent medical errors. RIVA prevents errors through automated precision, using gravimetric measurements for exact dose calculations, barcode checking, and image recognition to ensure correct drug selection. It eliminates human variance in compounding, performing identical steps each time to avoid preparation errors. Meanwhile, brivaracetam prevents errors through standardized dosing formats (available in specific tablet strengths of 10, 25, 50, 75, and 100 mg, as well as liquid forms) and clear administration guidelines. The medication comes with specific instructions for proper use, including gradual dose adjustments and guidelines for missed doses, helping to prevent dosing errors during patient treatment.","context":["RIVA uses automation of sterile manipulations and isolation of the compounding area to solve major safety issues with manual compounding, which are accuracy of every dose measurements and assuring sterility of every finished compound.\nAutomating the Chemo Compounding Process\nThom Doherty | ARxIUM\nHow is RIVA able to safely and accurately compound chemotherapy medications?\nTraditional manual compounding uses graduation marks on syringes and the assumed volume of the diluent bag, and both of these are allowed to have a manufacturing variance that can be as high as 10 percent. Instead of relying upon visual inspection of volume measurements to determine the amount of drug or diluent in the dose, RIVA uses weight-based (gravimetric) methods to check the correct amount of drug and diluent are added to preparation. By weighing the drug vial, syringe and bag before and after fluid is transferred between containers, RIVA is able to precisely determine the accurate amount of drug is contained within the finished dose. This level of accuracy assurance is not possible with visual inspection or the traditional “pullback” method to ensure the correct drug, diluent, reconstitution and volume transfer were precisely performed during manual compounding.\nAlso, manual compounding presents risks of introducing viable microorganisms that can cause infection. This is particularly dangerous for chemotherapy patients who may have impaired immune systems. The two largest contributing factors to viable contamination is the sterility of the compounding environment and human technique while performing compounding. RIVA solves contamination risk problems by removing humans from the sterile manipulation process and enclosing the compounding area in an isolated area that is protected from the external environment by HEPA-filtered air. In addition, RIVA uses a patented-pulsed, high-intensity ultraviolet light disinfection system to kill viable microorganisms and spores on ports of drug vials and diluent bags. After disinfection, the ports are exposed only to sterile air to ensure a contaminant-free surface. Notably, RIVA is the only system on the market with this feature.\nDoes RIVA have product features and technologies specific for handling chemo medications?\nRIVA uses the same highly accurate gravimetric measurements for all drugs. In addition, the airflow within RIVA preparing chemotherapy drugs is negatively pressurized and vented externally through HEPA filters. These methods protect pharmacy workers from exposure to acute or long-term exposure risks associated with hazardous chemotherapy drugs.\nRIVA can also use fluid bags that have an attached special administration port spike. This type of spike allows nurses to attach the administration set to bags without risk of puncturing its port and accidentally spilling chemotherapy drugs during patient administration.\nWhat are the benefits from automating the chemo compounding process – when compared to manual processes?\nRIVA uses automation of sterile manipulations and isolation of the compounding area to solve major safety issues with manual compounding, which are accuracy of every dose measurements and assuring sterility of every finished compound. Both of these problems are strongly influenced by inherent flaws in materials and techniques employed by persons performing manual compounding. Humans cannot perform tasks with a high degree of repeatability, so every dose has some degree of variance from ideal. Automation removes this variance since the system can be programmed to perform a precise set of steps and do these actions identically each time.\nIf the wrong drug is selected during the compounding process or dose is not measured accurately, the patient could experience toxic effects from too much drug. Additionally, the patient could receive a drug or dose that will not treat the cancer. RIVA prevents drug and dose errors by checking barcodes or image recognition. Also, RIVA helps ensure the vial is reconstituted correctly and each dose drawn from the vial is accurately transferred into the administration fluid bag or syringe.\nWould it be practical to use RIVA for other processes besides chemotherapy meds?\nRIVA has produced millions of doses worldwide, and a large percentage of these doses have been non-chemotherapy drugs. RIVA is currently being used to prepare many types of injectable medications - antibiotics, electrolytes, cardiac medications and others. RIVA is also being used to prepare precise dilutions of concentrated medications for pediatric and neonatal administration. The risks for these drugs are similar to chemotherapy drugs. More important, RIVA can be used to significantly reduce drug or dosing errors for all patients.\nWhat risks do pharmacists encounter when compounding chemo medications?\nWhen compounding chemotherapy drugs, the pharmacist and pharmacy technician have a risk of being exposed to the drug. Some chemotherapy drugs can cause burns or severe reactions. With long-term exposure, chemotherapy drugs can also cause genetic injury to the pharmacist, such as cancer or reproductive harm. Other risks to staff include repetitive motion injury caused by repeatedly transferring large amounts of fluids out of bags and then adding large volumes of drug solution.\nConsidering Humber River is fully digital and mostly automated, how does RIVA increase efficiency and provide other benefits for such an advanced facility?\nRIVA adds efficiency to the compounding process by allowing more doses to be prepared simultaneously. While the pharmacist or technician is performing other activities, RIVA can prepare doses at the same time. This allows the pharmacist or technician to pay more attention to detailed preparation instructions and techniques, which reducing the risk of an error occurring while manually compounding.\nRIVA also brings waste-avoidance cost reductions to facilities, as chemotherapy drugs are very expensive. If an error occurs in the manual compounding process, the dose must be discarded and prepared again. This wastes drug dollars and time, increasing the total cost to prepare the doses. RIVA’s multiple, redundant checks helps ensure doses are made correctly the first time.\nWithin the digital facility, RIVA enhances record keeping by storing digital images of each drug vial and bag used, records the lot number and expiry of medications, and has reporting capabilities to monitor system performance. By eliminating paper records, RIVA fits well into an all-digital facility.\nWhat’s next for RIVA and how do you see robotics evolving in pharmacy applications in the future?\nARxIUM is focused on meeting our customer’s needs and RIVA is the flagship technology of our company. We are always looking to expand its market and application of its technology and continue to invest in functionality and updates.\nIn addition, IV Automation is a critical safety technology because it removes the most risk-prone element from manual compounding – the human. As IV automation evolves, the number of specialty drugs that can be handled by automation will increase and even more complex preparation methods will be developed. The application of automation across the entire pharmacy enterprise is a rapidly progressing field. It is possible to envision a future in which the entire pharmaceutical handling process could be automated – from receiving to delivery of patient care.\nAbout Thom Doherty, Chief Technology Officer of ARxIUM\nThom is a pioneer of Intelligent Hospital Systems (IH Systems) a member of the ARxIUM group of companies in Winnipeg, Manitoba, Canada. He has nearly three decades of experience developing medical devices, aerospace applications for aircraft, spacecraft and satellites, and naval command and control systems in a variety of platforms. He is the co-inventor of 12 patents for technologies deployed in RIVA, a fully-automated IV compounding system for pharmacies.\nPrior to joining IH Systems, Thom worked for nearly 20 years developing technology, software and IT applications with organizations including Bristol Aerospace, Aircraft Engineering and Avionics Group, and Unisys Defense Products Group. A published author and academic research consultant, Thom received a diploma in computer science from Red River College and has held advisor positions at University of Toronto and University of Manitoba.\nThis post does not have any comments. Be the first to leave a comment below.\nPost A Comment\nYou must be logged in before you can post a comment. Login now.","How does this medication work? What will it do for me?\nBrivaracetam belongs to the class of medications called anti-epileptic medications. It is used by adults in addition to other medications treat and prevent partial-onset seizures in adults with epilepsy who continue to experience seizures while taking other anti-seizure medications. Brivaracetam does not cure epilepsy and only works to control seizures as long as the medication is taken. Brivaracetam works by affecting the transmission of nerve signals in the brain.\nThis medication may be available under multiple brand names and/or in several different forms. Any specific brand name of this medication may not be available in all of the forms or approved for all of the conditions discussed here. As well, some forms of this medication may not be used for all of the conditions discussed here.\nYour doctor may have suggested this medication for conditions other than those listed in these drug information articles. If you have not discussed this with your doctor or are not sure why you are taking this medication, speak to your doctor. Do not stop taking this medication without consulting your doctor.\nDo not give this medication to anyone else, even if they have the same symptoms as you do. It can be harmful for people to take this medication if their doctor has not prescribed it.\nWhat form(s) does this medication come in?\nEach white-to-off-white, round, film-coated tablet debossed with \"u10\" on one side contains 10 mg of brivaracetam. Nonmedicinal ingredients: croscarmellose sodium, lactose monohydrate, betadex (β-cyclodextrin), anhydrous lactose, magnesium stearate, polyvinyl alcohol, talc, polyethylene glycol 3350, and titanium dioxide.\nEach grey, oval, film-coated tablet, debossed with \"u25\" on one side contains 25 mg of brivaracetam. Nonmedicinal ingredients: croscarmellose sodium, lactose monohydrate, betadex (β-cyclodextrin), anhydrous lactose, magnesium stearate, polyvinyl alcohol, talc, polyethylene glycol 3350, titanium dioxide, yellow iron oxide, and black iron oxide.\nEach yellow, oval, film-coated tablet, debossed with \"u50\" on one side contains 50 mg of brivaracetam. Nonmedicinal ingredients: croscarmellose sodium, lactose monohydrate, betadex (β-cyclodextrin), anhydrous lactose, magnesium stearate, polyvinyl alcohol, talc, polyethylene glycol 3350, titanium dioxide, yellow iron oxide, and red iron oxide.\nEach purple, oval, film-coated tablet debossed with \"u75\" on one side contains 75 mg of brivaracetam. Nonmedicinal ingredients: croscarmellose sodium, lactose monohydrate, betadex (β-cyclodextrin), anhydrous lactose, magnesium stearate, polyvinyl alcohol, talc, polyethylene glycol 3350, titanium dioxide, yellow iron oxide, red iron oxide, and black iron oxide.\nEach green-grey, oval, film-coated tablet debossed with \"u100\" on one side contains 100 mg of brivaracetam. Nonmedicinal ingredients: croscarmellose sodium, lactose monohydrate, betadex (β-cyclodextrin), anhydrous lactose, magnesium stearate, polyvinyl alcohol, talc, polyethylene glycol 3350, titanium dioxide, yellow iron oxide, and black iron oxide.\nEach 1 mL of slightly viscous, clear, colorless-to-yellowish, raspberry-flavoured liquid contains 10 mg of brivaracetam. Nonmedicinal ingredients: sodium citrate anhydrous citric acid, methylparaben, carboxymethylcellulose sodium, sucralose, sorbitol solution, glycerin, raspberry flavor, and purified water.\nEach 1 mL of clear, colorless, sterile solution contains 10 mg of brivaracetam. Nonmedicinal ingredients: sodium acetate (trihydrate), glacial acetic acid, sodium chloride, and water for injection.\nHow should I use this medication?\nThe usual starting dose of brivaracetam is 50 mg taken by mouth, 2 times a day. Depending on how well it works and how you react to it, your doctor may gradually increase the dose to a maximum of 100 mg taken 2 times a day.\nBrivaracetam may be taken with or without food.\nThe tablets should be swallowed whole with liquid. Do not chew or crush them. If you are using the liquid, use an oral syringe to measure each dose, as it gives a more accurate measurement than household teaspoons.\nMany things can affect the dose of medication that a person needs, such as body weight, other medical conditions, and other medications. If your doctor has recommended a dose different from the ones listed here, do not change the way that you are taking the medication without consulting your doctor.\nIt is important to take this medication exactly as prescribed by your doctor. If you miss a dose, take it as soon as possible and continue with your regular schedule. If it is almost time for your next dose, skip the missed dose and continue with your regular dosing schedule. Do not take a double dose to make up for a missed one. If you are not sure what to do after missing a dose, contact your doctor or pharmacist for advice.\nStore this medication at room temperature, protect it from light and moisture, and keep it out of the reach of children. Store the liquid in its original container. Any oral liquid left 5 months after opening the bottle should be safely disposed of and a fresh supply started.\nDo not dispose of medications in wastewater (e.g. down the sink or in the toilet) or in household garbage. Ask your pharmacist how to dispose of medications that are no longer needed or have expired.\nWho should NOT take this medication?\nDo not take this medication if you are allergic to brivaracetam or any ingredients of the medication.\nWhat side effects are possible with this medication?\nMany medications can cause side effects. A side effect is an unwanted response to a medication when it is taken in normal doses. Side effects can be mild or severe, temporary or permanent.\nThe side effects listed below are not experienced by everyone who takes this medication. If you are concerned about side effects, discuss the risks and benefits of this medication with your doctor.\nThe following side effects have been reported by at least 1% of people taking this medication. Many of these side effects can be managed, and some may go away on their own over time.\nContact your doctor if you experience these side effects and they are severe or bothersome. Your pharmacist may be able to advise you on managing side effects.\nAlthough most of the side effects listed below don't happen very often, they could lead to serious problems if you do not seek medical attention.\nCheck with your doctor as soon as possible if any of the following side effects occur:\n- delusions (false or strange thoughts or beliefs)\n- hallucinations (seeing or hearing things that aren't there)\n- poor coordination\n- unusual behaviour\n- unusual infections (symptoms may include fever or chills, severe diarrhea, shortness of breath, prolonged dizziness, headache, stiff neck, weight loss, or listlessness)\nStop taking the medication and seek immediate medical attention if any of the following occur:\n- signs of a serious allergic reaction (e.g., abdominal cramps, difficulty breathing, nausea and vomiting, or swelling of the face and throat)\n- signs of a severe skin reaction such as blistering, peeling, a rash covering a large area of the body, a rash that spreads quickly, or a rash combined with fever or discomfort\n- thoughts of suicide or hurting yourself\nSome people may experience side effects other than those listed. Check with your doctor if you notice any symptom that worries you while you are taking this medication.\nAre there any other precautions or warnings for this medication?\nBefore you begin using a medication, be sure to inform your doctor of any medical conditions or allergies you may have, any medications you are taking, whether you are pregnant or breast-feeding, and any other significant facts about your health. These factors may affect how you should use this medication.\nBehaviour changes: Behaviour changes may occur with many medications used to treat seizures. Some people have reported changes in behaviour associated with taking brivaracetam. There have been occasional reports of aggressive behaviour or hostility, anxiousness, disorientation, or decreased memory. If you experience any of these effects or notice them in a family member who is taking this medication, contact your doctor as soon as possible.\nDizziness and drowsiness: Brivaracetam may cause drowsiness or dizziness, affecting your ability to drive or operate machinery. Avoid driving, operating machinery, or performing other potentially hazardous tasks until you have determined how you are affected by this medication.\nHypersensitivity syndrome: A severe allergic reaction called hypersensitivity syndrome has occurred for some people with the use of brivaracetam. Stop taking the medication and get immediate medical attention if you have symptoms of a severe allergic reaction, including fever, swollen glands, yellowing of the skin or eyes, or flu-like symptoms with skin rash or blistering.\nInfection: Brivaracetam can reduce the number of cells that fight infection in the body (white blood cells). If you experience fever, sore throat, fatigue, weakness, or generally feel unwell while taking brivaracetam, contact your doctor as soon as possible. Your doctor will do blood tests regularly to monitor the number of specific types of blood cells in your blood.\nKidney function: There is little information available regarding the effect of decreased kidney function on this medication. If you have decreased kidney function or kidney disease, discuss with your doctor how this medication may affect your medical condition, how your medical condition may affect the dosing and effectiveness of this medication, and whether any special monitoring is needed. Brivaracetam is not recommended for people with end-stage renal disease who are being treated with dialysis.\nLiver function: Liver disease or reduced liver function may cause this medication to build up in the body, causing side effects. If you have liver problems, discuss with your doctor how this medication may affect your medical condition, how your medical condition may affect the dosing and effectiveness of this medication, and whether any special monitoring is needed. Your doctor may want to test your liver function regularly with blood tests while you are taking this medication.\nIf you experience symptoms of liver problems such as fatigue, feeling unwell, loss of appetite, nausea, yellowing of the skin or whites of the eyes, dark urine, pale stools, abdominal pain or swelling, and itchy skin, contact your doctor immediately.\nStopping the medication: Stopping this medication suddenly may cause an increase in frequency or length of seizures. Before stopping this medication, talk to your doctor about the best way to gradually decrease the dose, to avoid these problems.\nSuicidal thoughts and behaviour: Occasionally, people taking medications to treat seizures may experience thoughts of suicide. If you experience these symptoms or any other behaviour change while taking this medication, contact your doctor immediately. Family members or caregivers of people who are taking this medication should contact the person's doctor immediately if they notice unusual behaviour changes.\nPregnancy: There is no information available regarding the safety and effectiveness of this medication if it is taken during pregnancy. This medication should not be used during pregnancy unless the benefits outweigh the risks. If you become pregnant while taking this medication, contact your doctor immediately.\nBreast-feeding: It is not known if brivaracetam passes into breast milk. If you are a breast-feeding mother and are taking this medication, it may affect your baby. Talk to your doctor about whether you should continue breast-feeding.\nChildren: The safety and effectiveness of using this medication have not been established for children.\nWhat other drugs could interact with this medication?\nThere may be an interaction between brivaracetam and any of the following:\n- antihistamines (e.g., cetirizine, doxylamine, diphenhydramine, hydroxyzine, loratadine)\n- antipsychotics (e.g., chlorpromazine, clozapine, haloperidol, olanzapine, quetiapine, risperidone)\n- barbiturates (e.g., butalbital, pentobarbital, phenobarbital)\n- benzodiazepines (e.g., alprazolam, diazepam, lorazepam)\n- birth control pills (estrogen/progestin)\n- chloral hydrate\n- general anesthetics (medications used to put people to sleep before surgery)\n- muscle relaxants (e.g., baclofen, cyclobenzaprine, methocarbamol, orphenadrine)\n- narcotic pain relievers (e.g., codeine, fentanyl, morphine, oxycodone)\n- other seizure medications (e.g., carbamazepine, clobazam, levetiracetam, phenobarbital, phenytoin, primidone, topiramate, valproic acid, zonisamide)\n- selective serotonin reuptake inhibitors (SSRIs; e.g., citalopram, fluoxetine, paroxetine, sertraline)\n- sodium oxybate\n- tricyclic antidepressants (e.g., clomipramine, desipramine, imipramine)\nIf you are taking any of these medications, speak with your doctor or pharmacist. Depending on your specific circumstances, your doctor may want you to:\n- stop taking one of the medications,\n- change one of the medications to another,\n- change how you are taking one or both of the medications, or\n- leave everything as is.\nAn interaction between two medications does not always mean that you must stop taking one of them. Speak to your doctor about how any drug interactions are being managed or should be managed.\nMedications other than those listed above may interact with this medication. Tell your doctor or prescriber about all prescription, over-the-counter (non-prescription), and herbal medications you are taking. Also tell them about any supplements you take. Since caffeine, alcohol, the nicotine from cigarettes, or street drugs can affect the action of many medications, you should let your prescriber know if you use them.\nAll material copyright MediResource Inc. 1996 – 2021. Terms and conditions of use. The contents herein are for informational purposes only. Always seek the advice of your physician or other qualified health provider with any questions you may have regarding a medical condition. Source: www.medbroadcast.com/drug/getdrug/Brivlera"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:ac3bfb3f-eaec-486a-afa7-1f2e7c6a8a48>","<urn:uuid:e05ace3d-373b-477a-8a95-1276c26c042a>"],"error":null}
{"question":"Which is higher in elevation: Mount Magazine in the Ouachita Mountains or Stelvio Pass in the Italian Alps?","answer":"The Stelvio Pass in northern Italy has a higher elevation at 2,757 meters (9,045 feet) above sea level, compared to Mount Magazine in the Ouachita Mountains which has an elevation of 2,753 feet (839 meters).","context":["21 Satellite Photos of Earth that Will Give you a Fresh Perspective\nThe world looks different when seen from above. During spaceflight, astronauts and cosmonauts have reported a cognitive shift in awareness while viewing the Earth from orbit or from the lunar surface; this is known as the “Overview Effect“. This experience inspired Benjamin Grant to launch Daily Overview, an online project that attempts to, “fully appreciate the beauty and intricacy of the things we’ve constructed, the sheer complexity of the systems we’ve developed, or the devastating impact that we’ve had on our planet.”\nWe first profiled Grant’s project last June. Since then, Daily Overview continues to provide a fascinating view of our beautiful planet from high above. We caught up with Grant to shed some light onto the project (see below) and he was kind enough to share a new gallery of incredible images with us.\nFor more, be sure to check out the Daily Overview at the links below.\n1. Arc de Triomphe – Paris, France\nThe Arc de Triomphe is located at the center of twelve radiating avenues in Paris, France. Because of numerous delays, including the abdication of Napoleon, construction of the monument took nearly 30 years to complete.\n2. Bondi Beach – Sydney, Australia\nOverview of Bondi Beach in Sydney. One of the city’s most popular destinations, the beach gets its name from the Aboriginal word “Bondi” that means waves breaking over rocks.\n3. Het Loo Palace – Apeldoorn, The Netherlands\nHet Loo Palace is located in Apeldoorn, Netherlands. “The Great Garden,” situated behind the residence, follows the general Baroque landscape design formula: perfect symmetry, axial layout with radiating gravel walks, parterres with fountains, basins, and statues.\n4. Stelvio Pass – Italy\nThe Stelvio Pass is a road in northern Italy that is the highest paved roadway in the Eastern Alps with an elevation of 2,757 m (9,045 ft) above sea level. Only accessible in the summer months (June-September), the road and its 75 hairpin turns are sometimes scaled during the famous Giro d’Italia cycling race.\n5. Magdeburg Water Bridge – Germany\nThe Magdeburg Water Bridge is a navigable aqueduct in central Germany. As the largest bridge of its kind in Europe, it spans the Elbe River to directly connect two canals, allowing large commercial ships to pass between the Rhineland and Berlin without having to descend into and then out of the Elbe. The structure was built with 24,000 tons of steel and 68,000 cubic meters of concrete.\n6. Rice Terraces – Yuanyang, China\nFor the past 1300 years, the Hani people of Yuanyang County, China have cultivated spectacular, terraced rice paddies on mountainsides.\n7. Dubai Interchange – United Arab Emirates\nA whirlpool interchange connects three major roads by the Miracle Garden in Dubai, United Arab Emirates. When construction of this junction began in 2006, Dubai contained 30,000 industrial cranes – 25% of all cranes on the planet.\nOr do you casually select a location in Google Earth and explore from there?\n“At the outset of the project, we decided that the Overviews would focus only on the areas where humans – for better or worse – have impacted the landscape. Accordingly, every Overview begins with a thought experiment. We consider the places where man has left his mark on the planet and then conduct the necessary research to identify those locations (and the corresponding geo-coordinates) that will convey that idea. To date, a number of themes have developed – such as agriculture, energy, infrastructure, architecture, urban planning – that always provide a good place to start that process.” – Benjamin Grant, Daily Overview\n8. Mount Taranaki – North Island, New Zealand\nMount Taranaki, also known as Mount Egmont, is an active stratovolcano on the west coast of New Zealand’s North Island. A change in vegetation is sharply delineated between the national forest that encircles the volcano and the surrounding land comprised of intensively-farmed dairy pastures.\n9. Olive Tree Plantation – Córdoba, Spain\nAn olive tree plantation covers the hills of Córdoba, Spain. Approximately 90% of all harvested olives are turned in to oil, while the 10% are eaten as table olives.\n10. Golden Gate Bridge – San Francisco, USA\nThe Golden Gate Bridge is a 1.7 mile (2.7 km) long suspension bridge in San Francisco, California that spans the Golden Gate strait, the mile-wide channel between San Francisco Bay and the Pacific Ocean. The bridge’s signature color, known as “international orange”, was selected to complement its natural surroundings and enhance its visibility in fog.\n11. Norfolk Coal Train Depot – Virginia, USA\nTrain cars filled with coal are stationed in Norfolk, Virginia. Operated by the Norfolk Southern corporation, Lamberts Point Pier 6 is the largest coal-loading station in the Northern Hemisphere and serves at the temporary depot for the company’s fleet of 23,000 coal cars.\n12. Port of Rotterdam – The Netherlands\nThe Port of Rotterdam is the largest port in Europe covering 105 square kilometers.\n13. Fishing Nets – Quanzhou, China\nFloating fishing nets are visible in the waters of Quanzhou, China.\n14. Durrat al Bahrain – Bahrain\nDurrat Al Bahrain will consist of 15 connected, artificial islands (including six atolls, five fish-shaped, and two crescent-shaped). Construction costs are estimated at $6 billion and the project is slated for completion in mid-2015.\n“I believe that regularly viewing the Earth from this mesmerizing vantage point has the power to change the way we think about the planet. The project derives its name from “The Overview Effect” – a phrase that refers to the sensation astronauts have when given the opportunity to look down and view the Earth as a whole. These astronauts claim to gain a new understanding of what it means to be alive on our planet. They have an opportunity to appreciate our home in its entirety—to reflect both on its beauty and its fragility. I hope to inspire a similar feeling of awe with this daily dose of fresh perspective.” – Benjamin Grant, Daily Overview\n15. Brasilia, Brazil\nBrasília was founded as the new capital of Brazil on April 21, 1960. Brasília’s urban plan – resembling an airplane from above – was developed by Lúcio Costa and Oscar Niemeyer in 1956 in order to move the capital from Rio de Janeiro to a more central location.\n16. Burning Man – Nevada, USA\nBurning Man is a week-long, annual event held in the Black Rock Desert of Nevada, USA. Drawing more than 65,000 participants in 2014, the event is described as an experiment in community, art, radical self-expression, and radical self-reliance. The developed part of Black Rock City, the temporary residence of the campers, is arranged as a series of concentric streets with the “Man Sculpture” and his supporting complex at the center.\n17. Ships in Singapore\nCargo ships and tankers – some weighing up to 300,000 tons – wait outside the entry to the Port of Singapore. The facility is the world’s second-busiest port in terms of total tonnage, shipping a fifth of the world’s cargo containers and half of the world’s annual supply of crude oil.\n18. Amazon Deforestation – Brazil\nClearcutting operations in the Amazon Rainforest of Para, Brazil branch out from one of the state’s central roads.\n19. Tulip Fields – Lisse, The Netherlands\nVibrant tulip fields sprawl across the landscape in Lisse, Netherlands.\n20. Palmanova, Italy\nPalmanova, located in northeastern Italy, is famous for its concentric fortress plan known as a star fort. The rings that surround the town were completed in 1593, 1690, and 1813.\n21. Turbine Interchange – Florida, USA\nA turbine interchange connects the SR 9A and SR 202 in Jacksonville, Florida, USA. Also known as a whirlpool interchange, this structure consists of left-turning ramps sweeping around a center interchange, thereby creating a spiral pattern of right-hand traffic. This type of junction is rarely built, due to the vast amount land that is required to construct the sweeping roads.\nIf you enjoyed this post, the Sifter","The Ouachita Mountains from Flatside Pinnacle\n|Elevation||2,753 ft (839 m)|\n|State||Arkansas and Oklahoma|\n|Parent range||U.S. Interior Highlands|\nThe Ouachita Mountains (//), simply referred to as the Ouachitas, are a mountain range in western Arkansas and southeastern Oklahoma. They are formed by a thick succession of highly deformed Paleozoic strata constituting the Ouachita Fold and Thrust Belt, one of the important orogenic belts of North America. The Ouachitas continue in the subsurface to the southeast where they make a poorly understood connection with the Appalachians and to the southwest where they join with the Marathon area of West Texas. Together with the Ozark Plateaus, the Ouachitas form the U.S. Interior Highlands. The highest natural point is Mount Magazine at 2,753 feet.\nLouis R. Harlan claimed that \"Ouachita\" is composed of the Choctaw words ouac for buffalo and chito for large, together meaning \"country of large buffaloes\". At one time, herds of buffalo inhabited the lowland areas of the Ouachitas. Historian Muriel H. Wright wrote that \"Ouachita\" is composed of the Choctaw words owa for hunt and chito for big, together meaning \"big hunt far from home\". According to the article Ouachita in the Encyclopedia of Oklahoma History and Culture, \"Ouachita\" comes from the French spelling of the Caddo word washita, meaning \"good hunting grounds\".\nThe Ouachitas are a major physiographic province of Arkansas and Oklahoma and are generally grouped with the Arkansas River Valley. Together with the Ozark Plateaus, the Ouachitas form the U.S. Interior Highlands, one of few mountainous regions between the Appalachians and Rockies.\nThe Ouachitas are dominated by pine, oak, and hickory. The shortleaf pine (Pinus echinata) and post oak (Quercus stellata) thrive in dry, nutrient-poor soil and are common in upland areas. The maple-leaf oak (Quercus acerifolia) is found at only four sites worldwide, all of which are in the Ouachitas. Some native tree species, such as the eastern red-cedar (Juniperus virginiana), are colonizers of human-disturbed sites.\nThe Ouachita National Forest covers approximately 1.8 million acres of the Ouachitas. It is one of the largest and oldest national forests in the Southern U.S., created through an executive order by President Theodore Roosevelt on December 18, 1907. There are six wilderness areas within the Ouachita National Forest, which are protected areas designed to minimize the impacts of human activities.\nBison and elk once found habitat in the Ouachita Mountains, but have since been extirpated. Today, there are large populations of white-tailed deer, coyote, and other common temperate forest animals. Though elusive, hundreds of black bear roam the Ouachitas. Several species of salamander are endemic to the Ouachitas and have traits that vary from one locale to another.\nThe Athens Piedmont consists of a series of low relief ridges, none exceeding 1,000 feet. It is located south of the Ouachitas and extends from Arkadelphia, Arkansas to the Arkansas-Oklahoma border. The Athens Piedmont runs through Clark, Howard, Pike, and Sevier counties in Arkansas and McCurtain County in Oklahoma.\nThe Caddo, Cossatot, and Missouri mountains are a high, compact group of mountains composed of the weather-resistant Arkansas Novaculite. They are located primarily in Montgomery and Polk counties, Arkansas. The highest natural point is Raspberry Mountain at 2,358 feet. The headwaters of multiple rivers are found in this area, including the Caddo, Cossatot, and Little Missouri rivers.\nThe Crystal Mountains are located primarily in Montgomery County, Arkansas. They are so named because of the occurrence of some of the world's finest quartz. The Crystal Mountains are generally taller than the nearby Zig Zag Mountains, achieving elevations over 1,800 feet.\nThe Fourche Mountains are a long, continuous chain of mountains composed of the weather-resistant Jackfork Sandstone. They extend from Pulaski County, Arkansas to Atoka County, Oklahoma and are home to several popular sites of interest, including Pinnacle Mountain State Park near Little Rock, Arkansas. The highest natural point is Rich Mountain at 2,681 feet, which intersects the Arkansas-Oklahoma border near Mena, Arkansas. The Fourche Mountains form a major watershed divide between the Arkansas River Basin to the north and the Red River Basin to the south.\nThe Frontal Ouachita Mountains are located in the Arkansas River Valley and feature a number of isolated landforms. The highest natural point is Mount Magazine at 2,753 feet, which is also the highest natural point of the Ouachitas and U.S. Interior Highlands. The Frontal Ouachita Mountains are structurally quite different from the rest of the Ouachitas and are sometimes considered a separate range.\nThe Zig Zag Mountains are located in Garland County, Arkansas and are home to the thermal springs of Hot Springs National Park. They are so named because of their unique chevron shape when viewed from above, the result of plunging anticlines and synclines. The Zig Zag Mountains are not exceptionally tall, but do reach heights over 1,400 feet.\nThe Ouachitas are formed by a thick succession of highly deformed Paleozoic strata constituting the Ouachita Fold and Thrust Belt, which outcrops for approximately 220 miles in western Arkansas and southeastern Oklahoma. In a general sense, the Ouachitas are considered an anticlinorium because the oldest known rocks are located towards the center of the outcrop area. The Ouachitas continue in the subsurface to the Black Warrior Basin of Alabama and Mississippi where they plunge towards the Appalachian Mountains. To the southwest, the Ouachitas join with the Marathon area of west Texas where rocks of the Ouachita Fold and Thrust Belt are briefly exposed.\nUnlike many ranges in the United States, the Ouachitas are mostly east-west trending. They are unique because metamorphism and volcanism, features that are common in orogenic belts, are notably absent (with the exception of some low-grade metamorphism). Due to the high degree of folding and faulting, the Ouachitas are clustered into distinct subranges, with ridges separated by relatively broad valleys.\nThe Ouachitas are known for some of the world's finest quartz, especially around Mount Ida, Arkansas, the quartz capital of the world. The quartz formed after the Ouachita Orogeny when fractures in rocks filled with silica-saturated fluids and, over millions of years, precipitated crystals up to several feet in length. The Ouachitas are also known for novaculite, a variety of chert that has undergone low-grade metamorphism; particular grades found only in Arkansas are used for making whetstones.\nCambrian through Mississippian strata of the Ouachitas were deposited in a narrow, two-sided basin called the Ouachita Trough, which formed as part of a Cambrian failed rift system. Succeeding Pennsylvanian strata of the Ouachitas were deposited in a foreland basin during the early stages of the Ouachita Orogeny. Subduction of the South American Plate beneath the North American Plate resulted in this mountain-building event. Compressional forces caused the crust to buckle, producing complex folds at all scale levels and several overturned sequences. The area of greatest deformation occurred in the Benton-Broken Bow Uplift, which extends from Benton, Arkansas to Broken Bow, Oklahoma. The total height of the Ouachitas is not known, though they may have exceeded 10,000 feet (based loosely on geologic cross-sections). The terrain has been deeply eroded since the late Paleozoic.\nThe Ouachitas are composed of Cambrian through Pennsylvanian sedimentary rocks. The Collier Shale, located at the core of the Benton-Broken Bow Uplift, is the oldest exposed formation of the Ouachitas. The Atoka Formation, which was deposited much later during the Pennsylvanian, has the largest areal extent of any of the Paleozoic formations in Arkansas. The geologic formations of the Ouachitas are as follows (in order of ascending age).\n|Collier Shale||Late Cambrian and Early Ordovician||1,000 feet|\n|Crystal Mountain Sandstone||Early Ordovician||850 feet|\n|Mazarn Shale||Early Ordovician||2,500 feet|\n|Blakely Sandstone||Middle Ordovician||700 feet|\n|Womble Shale||Middle Ordovician||1,200 feet|\n|Bigfork Chert||Middle and Late Ordovician||750 feet|\n|Polk Creek Shale||Late Ordovician||225 feet|\n|Blaylock Sandstone||Silurian||1,200 feet|\n|Missouri Mountain Shale||Silurian||300 feet|\n|Arkansas Novaculite||Devonian and Early Mississippian||900 feet|\n|Stanley Shale||Mississippian||10,000 feet|\n|Jackfork Sandstone||Early Pennsylvanian||6,000 feet|\n|Johns Valley Shale||Early Pennsylvanian||1,500 feet|\n|Atoka Formation||Early and Middle Pennsylvanian||25,000 feet|\n|Hartshorne Sandstone||Middle Pennsylvanian||300 feet|\n|McAlester Formation||Middle Pennsylvanian||2,300 feet|\n|Savanna Formation||Middle Pennsylvanian||1,600 feet|\n|Boggy Formation||Middle Pennsylvanian||1,100 feet|\nThe Ouachita Mountains contain the Ouachita National Forest, Hot Springs National Park and Lake Ouachita, as well as numerous state parks and scenic byways mostly throughout Arkansas. They also contain the Ouachita National Recreation Trail, a 223-mile-long (359 km) hiking trail through the heart of the mountains. The trail runs from Talimena State Park in Oklahoma to Pinnacle Mountain State Park near Little Rock. It is a well maintained, premier trail for hikers, backpackers, and mountain bikers (for only selected parts of the trail).\nThe Talimena Scenic Drive begins at Mena, and traverses 54 miles (87 km) of Winding Stair and Rich Mountains, long narrow east-west ridges which extend into Oklahoma. Rich Mountain reaches an elevation of 2,681 feet (817 m) in Arkansas near the Oklahoma border. The two lane winding road is similar in routing, construction, and scenery to the Blue Ridge Parkway of the Appalachian Mountains.\nSites of interest\n- Black Fork Mountain Wilderness\n- Caney Creek Wilderness\n- Cossatot River State Park-Natural Area\n- Flatside Wilderness\n- Hot Springs National Park\n- Jack Creek Recreation Area\n- Lake Catherine\n- Lake Hamilton\n- Lake Maumelle\n- Lake Ouachita\n- Mount Magazine State Park\n- Pinnacle Mountain State Park\n- Queen Wilhelmina State Park\nThe mountains were home to the Ouachita tribe, for which they were named. Later French explorers translated the name to its present spelling. The first recorded exploration was in 1541 by Hernando de Soto. Later, in 1804, President Jefferson sent William Dunbar and Dr. George Hunter to the area after the Louisiana Purchase. Hot Springs National Park became one of the nation's first parks in 1832. The Battle of Devil's Backbone was fought here at the ridge of the same name in 1863. In August 1990, the U.S. Forest Service discontinued clearcutting as the primary tool for harvesting and regenerating short leaf, pine and hardwood forests in the Ouachita National Forest.\n- Morris, R.C. (1974). \"Sedimentary and Tectonic History of the Ouachita Mountains\". Special Publications of SEPM. 22: 120–142.\n- \"A Tapestry of Time and Terrain\". U.S. Geological Survey. Retrieved 2007-10-13.\n- Cole, S.R.; Marston, R.A. (2009). Encyclopedia of Oklahoma History and Culture. Oklahoma Historical Society.\n- \"MAG\". NGS data sheet. U.S. National Geodetic Survey. Retrieved 2008-12-16.\n- Harlan, L.R. (1834). \"Notice of Fossil Bones Found in the Tertiary Formation of the State of Louisiana\". Transactions of the American Philosophical Society. 4: 397–403. doi:10.2307/1004838.\n- Wright, M.H. (1929). \"Some Geographic Names of French Origin in Oklahoma\". Chronicles of Oklahoma. 7 (2): 188–193.\n- \"Trees\". Central Arkansas Library System. Retrieved 2017-11-28.\n- \"Ouachita National Forest\". Central Arkansas Library System. Retrieved 2017-11-28.\n- \"\"Wilderness Areas (Ouachita National Forest)\" (PDF). U.S. Forest Service. Retrieved 2017-12-02.\n- \"Stratigraphic Summary of the Arkansas River Valley and Ouachita Mountains\". Arkansas Geological Survey. Retrieved 2017-10-26.\n- Mellen, F.F. (1947). \"Black Warrior Basin, Alabama and Mississippi\". AAPG Bulletin. 31 (10): 1801–1816. doi:10.1306/3d933a55-16b1-11d7-8645000102c1865d.\n- \"Quartz Crystals\". Arkansas Department of Parks & Tourism. Retrieved 2017-11-25.\n- Lowe, D.R. (1985). \"Ouachita Trough: Part of a Cambrian Failed Rift System\". Geology. 13 (11): 790–793. doi:10.1130/0091-7613(1985)13<790:otpoac>2.0.co;2.\n- Shanmugam, G.; Moiola, R.J. (1995). \"Reinterpretation of Depositional Processes in a Classic Flysch Sequence (Pennsylvanian Jackfork Group), Ouachita Mountains, Arkansas and Oklahoma\". AAPG Bulletin. 79 (5): 672–695. doi:10.1306/8d2b1b6a-171e-11d7-8645000102c1865d.\n- Hatcher, R.D., Jr.; Thomas, W.A.; Viele, G.W., eds. (1989). The Appalachian-Ouachita Orogen in the United States (Geology of North America). Colorado: Geological Society of America.\n- http://www.trais.com/tcatalog_trail.aspx?trailid=XFA101-040, accessed 11 Mar 2011\n|Wikimedia Commons has media related to Ouachita Mountains.|\n- Geology of the Ouachita Mountains, from a rockhound's perspective.[dead link|date]\n- Friends of the Ouachita Trail (FoOT)\n- Lakeouachita.org: Lake Ouachita — largest lake in the Ouachita Mountains."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:8fd2ea3e-be31-45df-baf0-08a188268119>","<urn:uuid:42875460-36cf-431a-990f-03df0009014f>"],"error":null}
{"question":"What were the key founding years for baseball organizations in different regions - comparing the establishment of Little League Baseball versus the Dutch Baseball Union?","answer":"Little League Baseball was founded in 1939 in Williamsport, Pennsylvania by Carl Stotz, who started with just three teams sponsored by local businesses (Lycoming Dairy, Lundy Lumber, and Jumbo Pretzel). In contrast, the Dutch Baseball Union was established earlier, in 1912 by J.C.G. Grase, an English teacher who introduced baseball to the Netherlands after experiencing the game during a visit to the United States. Following this, the first continuous Dutch baseball team, Quick Amsterdam, was founded in 1913 by Emile Bleesing, who became instrumental in spreading baseball throughout the Dutch countryside.","context":["Brian Sipe set passing records at San Diego State University and was named the National Football League’s Most Valuable Player in 1980, when he passed for more than 4,000 yards and led the Cleveland Browns to their first playoff berth in eight years. Yet his greatest sports memory remains playing baseball in a dusty, miniature field in Williamsport, Pennsylvania, when he was 11-year-old Little Leaguer. “Every Little Leaguer dreamed of Williamsport, although none of us really knew where it was or how to get there,” he told the San Diego Union-Tribune in 2001.\nHow did this remote town of about 30,000 residents become the dream destination of millions of young baseball players? Ever since Little League Baseball was born in Williamsport in 1939, the town and its World Series tournament for 11- and 12-year-old players have formed the epicenter of American youth sports.\nThe story of Little League can be traced back to a young, ambitious clerk at a local oil-supply company. If Williamsport is the organization’s birthplace, then Carl Stotz is its father.\nIn the summer of 1938, during which Stotz laid the groundwork for his brainchild, he was 28 years old and working at the Pure Oil Company. He later said the idea of organizing youth baseball came to him in a revelation as he played catch with his two nephews in front of his house on Isabella Street. He let the thought germinate. According to Charles Euchner, a former Little League player and author of Little League, Big Dreams, Stotz then asked his nephews a series of questions:\nHow would you boys like to play on a baseball team? How would you like to play in uniforms, just like the major-league players use? With real equipment – a fresh supply of balls and bats, with catcher’s gear. Umpires would call the games, so arguments about balls and strikes, catch or no catch, fair or foul, would not interrupt play. Coaches would teach players. Someone would keep score. At the end of the year, the best teams would play for the championship of the league. What do you think of that, boys?\nIt turned out that the pair liked the idea quite a bit, prompting them to gather their friends for practice the following day. Up to that point, kids could only play organized ball once they reached high school. Although the boys were excited, the real league wouldn’t truly take off until the following spring.\nStotz recruited players at the local schools and churches. He and the recruits cleared a vacant lot, marked out a baseball diamond two-thirds the size of regulation dimensions, built a backstop, and planted grass. The eager Stotz also sought financial support from local businesses, three of which gave in to his pitch and together donated a few hundred dollars. The original three teams, which were managed by Stotz and his two brothers-in-law, bore the names of these sponsors: Lycoming Dairy, Lundy Lumber, and Jumbo Pretzel. On June 6, 1939, Lundy Lumber defeated Lycoming Dairy 28-3 in the inaugural game.\nStotz dubbed the fledgling project “Little League,” and espoused his goals of teaching sportsmanship, fair play, and teamwork to the initial standard of 8- to 12-year-old boys. He started expanding, traveling around central Pennsylvania and then all over the eastern seaboard in order to visit Sunday school classes, school boards, and YMCAs. He told community leaders that boys should be able to play like the big-leaguers they idolized and that these local leagues were the perfect solution.\nAlthough Little League was not the first league to attempt organized youth baseball, it signaled the first such attempt that actually flourished outside of the original community. New leagues started popping up in 1940. In order to provide structure to expansion, the national offices limited each new league to a geographical area encompassing about 20,000 residents. Stotz and the organizers hoped to avoid player disputes and to keep competition fairly even with this approach.\nIn 1947, the first year of the Little League World Series, Hammonton, New Jersey, founded the first Little League outside of Pennsylvania. By 1951, the organization had grown to 776 separate programs. By 1956, the total skyrocketed to more than 4,000, and another thousand had sprung up in just another three years. Former President Herbert Hoover called the vastly popular union of local leagues “one of the greatest stimulants of constructive joy in the world.”\nWith more than 8,000 leagues in more than 80 countries, the Williamsport export is now the world’s largest organized sports program. Millions of players and nearly 200,000 teams participate annually, and almost all of them enter summer tournaments in hopes of reaching the World Series held each August in South Williamsport.\nIn 1947, the Little League board of directors had decided to organize a tournament for all known programs, which at the time amounted to 17. Eleven teams – ten from Pennsylvania and one from New Jersey – accepted the invitation to what was then named the National Little League Tournament.\nAt first glance, the area appears an unlikely site for both the launching of Little League and its premier tournament. Nestled in a picturesque valley next to the Susquehanna River, it looks more a preserved fragment of an earlier, perhaps simpler, time. In the late 1800s, Williamsport was the lumber capital of the world. Long before the town became known for baseball, the logging industry there spawned the highest concentration of millionaires anywhere in the world. The money brought opulent homes, theaters, hotels, restaurants, and public spaces. Vestiges of that wealth can still be seen on Millionaire’s Row, where imposing Victorian mansions still stand.\nHowever, two floods in the 1890s destroyed the city’s industrial structure. As the lumber industry declined, city leaders were forced to take Williamsport in a new direction. The town retains much of the looks and charms of the high-rolling lumber days, but evidence of hard times also covers the buildings and parks, like dust on an ornate antique. A planning document even calls the city’s history since the floods “a story of unceasing struggle for survival.”\nIn many ways, the annual World Series for 11- and 12-year-olds has replaced lumber as the symbol of Williamsport and its surrounding boroughs. Since 1947, the excitement and tourism appeal of the tournament has helped revitalize the area. In the inaugural year, the Maynard Midget League of Williamsport took the title, besting the Lock Haven All Stars 16-7 in a game that drew 2,500 spectators. Those are gaudy attendance numbers for a game between teams of prepubescent players. The modern numbers, however, dwarf those from early years and bring thousands to Williamsport each summer. The championship game routinely draws more than 40,000 fans, and the ten-day tournament attracts well over 250,000 people who breathe life into an otherwise quiet area.\nJust as the spectacle has grown – and the competition has grown from a regional tournament to a four-team national one, then an eight-team international tournament in the ‘50s and its current incarnation as a 16-team contest – so has its location. The tournament has moved from the original small field in Williamsport proper to a state-of-the-art complex across the river on Route 15. The complex contains two stadiums; Howard J. Lamade Stadium, named after an executive of both Little League and local newspaper Grit, was the original field at this site. Little League Volunteer Stadium was completed in 2001, just in time to accompany the expansion of the tournament to 16 teams.\nAnother vital part of the baseball complex is the Peter J. McGovern Little League Museum, which is named after the organization’s first full-time president and one of the chief architects of its rise. The museum celebrates the baseball brand’s past and present. A Hall of Excellence enshrines Little League alumni who have gone on to become adult role models. It includes several former Little League World Series players – such as Gary Sheffield, Jason Bay, Lastings Milledge and Jason Varitek – who went on to careers in the major leagues. However, the Hall of Excellence is not limited to only baseball stars. Notable members represent a broad spectrum of sports and other professions, such as entertainment and politics. Cal Ripken, Jr., Nolan Ryan, Mike Ditka, Troy Aikman, Doug Flutie, Pierre Turgeon, Kareem Abdul-Jabbar, Bruce Springsteen, Danny Devito, Kurt Russell, Senator Joe Lieberman and President George W. Bush are all immortalized with plaques in the museum. Faces of Little Leaguers turned generals, doctors, writers and public servants also grace those walls.\nIn addition to the Hall, the museum features interactive displays, films, and exhibits that bring the players and the evolution of the game to life. Batting and pitching areas even feature instant replay to allow visitors to check their technique. Entrance is $5 for adults, $3 for senior citizens, and $1.50 for children ages 5 to 13 (and free for those younger).\nThe complex also includes an Olympic-style village for the World Series players and staff, who live and eat for free during their stays. Upon arrival, the budding athletes explore the dorms and adjoining training complex, and slide down the “The Hill,” a grassy bank past the outfield at Lamade Stadium on which some fans relax and watch the games. Later, the players go over game film in their dorms with their coaches. Preparations can be grueling, especially after weeks of play just to get to this point.\nThe players go through a rigorous schedule of games for the chance to get to Williamsport and its nationally televised matches on ABC and ESPN. (Twenty-seven World Series games and eight regional finals are now televised. They can draw more viewers than some big-league games, with the current record television audience at almost 10 million viewers.) More than 7,000 teams composed of local all-stars begin the march to Williamsport in the Little League Baseball division during the first week of June, and more than 6,500 are eliminated in the first three weeks of pool play. The teams that survive the local district tournaments move on to the state, province or country tournaments. Those winners go to the regional tournaments. Outside the U.S., the regions are Canada, Mexico, the Caribbean, Latin America, Asia, Pacific, a European-Middle Eastern-African region called EMEA, and a Trans-Atlantic region composed primarily of Americans living abroad. The winners of the sixteen regional tournaments move on to represent their states or countries at Williamsport in late August.\nAll the teams that reach the Little League World Series are undefeated. Some play as many as 20 games in the qualifying tournaments. The World Series features some of the age group’s best players, although some are being drawn to travel baseball teams and competing organizations, such as the Ripken and PONY youth leagues. (Both Ripken and PONY baseball offer field dimensions and equipment closer in size to that of the majors, and the former carries the financial clout and name recognition of Cal Ripken, Jr., baseball’s iron man. While neither yet matches Little League’s participants, both are growing rapidly.) Despite the new competition, Little League still attracts much, albeit not always evenly distributed, talent. Some players tower over their peers, reaching 6-foot-5 and powering the ball deep into the bleachers. Thanks to the fields’ small dimensions, some of the pitchers’ fastballs reach home plate at the equivalent of 90 to 100 miles per hour. A 72-mile-per-hour pitch from a 12-year-old’s arm, for example, gives the batter as much time to react as a 94-mile-per-hour pitch from a professional hurler.\nDespite this, Little League chronicler Charles Euchner contends that the appeal of the league and the Williamsport playoffs doesn’t necessarily lie in the quality of the play. Fans enjoy seeing gifted players who are still developing into their full-blown athleticism. The works-in-progress mold themselves further with each game. The potential and mystery make up part of the charm, Euchner notes. He writes, “There’s no telling which of the kids playing in Williamsport might turn out to be a great athlete, worthy of a pro contract, a college scholarship, or even a starting position on a high school team.” The chance of witnessing a young, unpolished Hank Aaron or Barry Bonds adds electricity to the tournament air.\nFor all the high hopes of the players, as well as the pressure from parents, coaches, and the media, one must remember that the entire event celebrates the game. For many players, the Little League World Series will be the pinnacle of their achievements in the sport. For some of the elite players, it may mark the last moment before the game became a business, an investment. At this stage, everyone still comes in hopes of advancing through the tournament. And if they can’t win the championship, at least they get to play the game they love on bright, manicured grass in front of thousands of people.\nAfter spending two weeks with the teams, coaches, staff, and enthusiasts, Euchner tried to sum up his excitement and concerns. “I was relieved when I saw players from Canada and Guam romp around the Little League complex,” he wrote. “I was impressed to see the Japanese team practice together like dancers – and break into laughter in between routines. I smiled when I heard that the players from Westbrook, Maine, tramped down to the field after their games ended to gather samples of dirt from the infield as souvenirs. These are the things that have a chance of lasting – not just memories, but ways of living – long after the innocent dreams of winning a championship.”\nThe game may be evolving at a frightening pace. Amid steroid allegations and scandal, Major League teams scrutinize ever-younger players, sending scouts to the far reaches of the globe in search of the next can’t-miss prospect. Kids barely into middle school enter farm systems. Teams hope for the next Roberto Clemente, and the 13-year-old hopes for riches and endorsements. Little League is not untouched by this phenomenon, as demonstrated by the many TV cameras and corporate sponsors at the tournaments. Yet for many players and fans at the Little League World Series, the game may briefly be as pure as possible. For a few weeks, the potential of big money may not matter. Only the big stage matters. Only the baseball matters.\n- Euchner, Charles. Little League, Big Dreams. Naperville, IL: Sourcebooks, 2006.\n- Little League Online. 2007. Little League Baseball. 6 Feb. 2008 <http://www.littleleague.org/>.","Baseball is one of the most played sports on the planet. Its popularity is largely unrivaled next to soccer. How did “America’s pastime” become a global game?\nThe four semifinal teams represent three continents and millions of baseball fans across the globe. Let’s go nation by nation and examine each country’s unique baseball origins.\nThe Netherlands has become a baseball powerhouse with one of the top teams in the WBC. It comes from humble beginnings like most empires.\nThe origins of baseball in the Netherlands can be dated to the early 1900s. J.C.G. Grase is credited with introducing the Netherlands to baseball with his foundation of the Dutch Baseball Union in 1912.\nGrase was an English teacher in Amsterdam, and was first introduced to the game on a vacation to the states. His ability to translate the rules from English to Dutch was vital to the growth of baseball in the Netherlands. However, it wasn’t until Emile Bleesing founded the team “Quick Amsterdam” that the game started to grow.\nQuick Amsterdam was founded in 1913, and is the longest continually running baseball team in the Netherlands. Bleesing is the most important baseball pioneer in Dutch history. His trips around the Dutch countryside to spread the game planted the seed that sprouted into what baseball in the Netherlands is today.\nDutch baseball goes farther back than just recent history. A longstanding tradition of baseball dominance in Europe has the Netherlands increasing its baseball empire. The Dutch influence continues to grow with multiple Dutch players in the majors.\nJapan will be making yet another WBC semifinals appearance this week. Their championship pedigree has its roots deep in Japanese history.\nAmericans Horace Wilson and Albert Bates are credited with introducing Japan to baseball. However, it was Hiroshi Hiraoka that helped grow the game.\nHe became a die-hard Red Sox fan while attending school in the states. This lead Hiraoka to found the Shinbashi Athletic Club Athletics in 1878. The evolution of baseball in Japan ended up being much different than that of the Netherlands.\nBaseball in Japan began to grow just after the dawn of the 20th century. Amateur ball became the major form of baseball in the country. Baseball was able to take root at a younger age level since the focus was turned away from the pros.\nKids in public schools and universities became players of the sport. This encouraged them to become baseball fans for life, and led to the development of the pro leagues.\nThe first professional league was founded in 1936. The current highest level of baseball in Japan, Nippon Professional Baseball, was founded in 1949. Japan has come into its own with such a long baseball history.\nThe previous two countries can be traced to a few individuals, but Puerto Rico is much different.\nBaseball was introduced to Puerto Rico by a group of Puerto Ricans and Cubans who had learned the game in the United States. The first impressions by the locals were poor, but the first two teams were founded in 1897.\nThe Almendares Baseball Club, owned by Francisco Alamo Armas, and the Borinquen Baseball Club, owned by Santos Filippi, were the first two baseball clubs on the island. On January 11, 1898, the first baseball game between the two teams was played. Baseball began to explode in Puerto Rico at the end of the Spanish-American War in the summer of 1898.\nPuerto Rico was passed from Spanish possession to U.S. possession with the conclusion of the war. Americans brought baseball with them when the United States began stationing troops in the territory.\nThe U.S. troops on the island formed their own baseball club. They were beaten in 1900 by the Almendares Baseball Club 32-18.\nBaseball began to expand after the war. Towns and schools founded their own teams. Professional ball began in 1938 with the founding of the Puerto Rico Baseball League.\nThe growth of baseball in both public teams like school and town teams and the development of a professional league really set a firm foundation for baseball in Puerto Rico. The island has grown from that foundation to become one of the leading nations in baseball.\nAs “America’s pastime,” baseball has a longstanding history in the United States. Accordingly, the game is almost as old as the country itself.\nBaseball can be traced back to a Pittsfield, Massachusetts law written in 1792, which prohibited the playing of the game within 80 yards of the town meeting house. The first team to organize was the New York Knickerbockers, who were founded in 1845 under the leadership of Alexander Cartwright.\nThe Knickerbockers established the modern rules for baseball. These “Knickerbocker Rules” dealt with laying out the rules of the game, as well as organization. Even with their own rules in place, the Knickerbockers were bested by the New York Nine in the first official game played under the new rules in Hoboken, New Jersey.\nA few years later in 1857, the National Association of Base Ball Players was organized. It was the first entity to govern the sport and establish a championship. The game grew in popularity with the outbreak of the Civil War.\nUnion soldiers introduced their southern counterparts to the game, and it was quickly picked up in the south. The growth of baseball in the south became a uniting factor during Reconstruction. People all over the country were introduced to the game, and its this spread in popularity that lead to it becoming “America’s past time.”\nLuckily for us and the rest of the world, it isn’t limited to just the United States.\n“From Our Haus to Yours”"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:2a1461e1-96e2-42a0-bb79-80745a66e587>","<urn:uuid:9db6e307-b4dc-4ec5-a0e7-3e2255d7ba93>"],"error":null}
{"question":"What's the latest research on Mediterranean diet benefits for brain health, and what bone health risks should Med diet followers watch out for?","answer":"Recent PREDIMED research shows the Mediterranean diet supplemented with extra-virgin olive oil improved frontal and global cognitive function scores, while those supplemented with nuts performed better on memory tests. However, the Mediterranean diet can be low in calcium and vitamin D, which are crucial for bone health. This is a concern since inadequate dietary calcium and low vitamin D levels are risk factors for osteoporosis, a condition where bones become weak and prone to fractures, particularly affecting the wrists, hips, and spine.","context":["This article is a collaboration between MedPage Today® and:\nUnless you've been living without print or electronic media for the past several years, you've heard of the Mediterranean Diet. It focuses on the use of olive oil for cooking and in salads, lots of fruits and vegetables, nuts, some cheese and yogurt, and plenty of fatty fish, with less red meat and butter.\nFull disclosure: I pretty much grew up on this diet, but it wasn't \"Mediterranean\" then. It was just how we ate, strongly influenced by my mother's family – the Greek side – and especially her father. He caught his own salmon as often as possible, used olive oil by the gallon, and cracked nuts in the shell after dinner to eat with dried fruit. His family came from Crete, where the diet is said to have originated. He felt it was healthy to eat this way, but it was also his culture.\nFast forward to a few years in the past and the PREDIMED project, a huge multicenter trial that basically divides people into three groups: two groups counseled to follow the Med Diet supplemented with either olive oil or nuts (a combination of almonds, hazelnuts, and walnuts), and a control group advised to follow a general low-fat diet. The diet was so successful at reducing heart disease risk that it was stopped early so the control group could partake of the Med Diet benefits.\nBeyond Healthy Hearts\nThe researchers also looked into the effects of the diet on memory. A just-published study, a subset of the PREDIMED trials, used the same diet but then tested global cognitive function, memory performance, and a composite of frontal functions, both at the beginning of the study and after the end of the 5-year period.\nHere's the boil-down: compared with the control group, those on the Med diet supplemented with extra-virgin olive oil performed better on both frontal and global composite scores, and subjects on the Med diet supplemented with nuts did better on memory composite tests.\nWhat Do I Like About the PREDIMED Research?\nThe dietary intervention was simple and easy for anyone to implement. The extra-virgin olive oil subjects replaced about two tablespoons of butter and other oils for a similar amount of olive oil or an ounce of nuts. It's about as easy as any dietary change is going to get. This study didn't give specific calorie advice per se or put people on weight-loss diets. Even chocolate was allowed as long as it's the dark stuff.\nThe Med Diet does get a thumbs up from the recent Dietary Guidelines Advisory Committee report. This group also endorsed the DASH diet – Dietary Approaches to Stop Hypertension – that centers on lots of fruits and vegetables and three servings a day of low-fat dairy (although you also get about four ounces of cheese a week). Dairy foods aren't a huge part of the Med Diet, and the diet can be low in calcium and vitamin D. Culturally it wasn't a part of my grandparents' diets, but maybe it should have been – both had osteoporosis.\nThe \"MediterDASHean Diet\"\nNo connection to Kim here. This is my idea of combining the best of both diets. My grandparents might have done better with this diet – they both lived to an old age but had severe osteoporosis, one with hip fractures and all – because it combines the strengths of both endorsed diets. My grandfather would probably approve – he spent many years as a dairy farmer just south of San Francisco.\nHe wouldn't approve of swapping out nuts for nut milk alternatives, though. An almond glass doesn't actually contain many almonds. Crushed almonds, at an ounce a day, would be better.\nAs for olive oil, it could probably be replaced by canola oil, which is also loaded with monounsaturated fats -- but the flavor isn't there. Better to save it for foods and dishes where the olive oil flavors are less useful (this is just a personal opinion, so no emails on that, please).\nBottom line: this latest research underscores that there may be benefits beyond heart health of a diet that includes a modest amount of olive oil and/or nuts like almonds, hazelnuts, and walnuts on a daily basis. I can hear my grandparents yelling that they didn't need researchers to tell them about how good it was.","Late effects: Bone heath & osteoporosis\nDuring childhood and into young adulthood, bone formation usually occurs faster than bone loss, causing bones to grow and become stronger. As a person gets older, the process of bone removal gradually overtakes bone formation, and bones slowly lose strength as part of the normal ageing process.\nOsteoporosis: A silent disease\nOsteoporosis (or osteopenia) is a disorder resulting from too little new bone formation or too much bone loss, causing bones to become weak. Most people do not have symptoms, especially in the early stages.\nAs bones become weaker, fractures may occur after minimal trauma, such as a fall. Osteoporosis may occur in any bone, but most commonly affects the wrists, hips and leg bones. The vertebrae of the spine often collapse, leading to loss of height, spinal curvature, and chronic pain.\nHow is osteoporosis diagnosed?\nAlthough osteoporosis may be suspected based on a person's symptoms and risk factors, the diagnosis is made by measuring bone density with special x-ray techniques called DEXA or bone density scans. These scans do not expose patients to large amounts of radiation, and generally take less than 20 minutes to perform.\nPeople who have osteoporosis should discuss treatment options with their doctor. Medications, such as calcium and vitamin D supplements and bisphosphonates may be appropriate for the treatment of low bone density. In addition, if you have low levels of male or female hormones, you may also benefit from hormone replacement therapy.\nWhat are the risk factors for osteoporosis?\nOsteoporosis is more common in people with the following characteristics:\n- Female (especially after menopause)\n- Family history of osteoporosis\n- Caucasian or Asian race\n- Small, thin frame\n- Older age\nThe following factors may also increase the risk of osteoporosis:\n- Cigarette smoking\n- Inadequate amounts of dietary calcium\n- Low vitamin D levels\n- Lack of physical activity\n- Too much caffeine (more than three cups of tea, coffee or equivalent daily)\n- Too much alcohol (more than two standard drinks per day)\nThe following cancer treatment factors may also increase the risk of osteoporosis:\n- A history of treatment with:\n- Corticosteroids (such as prednisone and dexamethasone)\n- Radiation to weight-bearing bones (legs, hips, spine)\n- Conditions resulting from prior treatment, including:\n- Low levels of female or male hormones\n- High levels of thyroid hormone\n- Chronic graft-versus-host disease requiring prolonged therapy with corticosteroids\n- Prolonged periods of inactivity (bed rest)\n- Other medical treatments, including:\n- Certain anticonvulsants (phenytoin and barbiturates)\n- Aluminium-containing antacids\n- High doses of heparin (used to prevent blood clots), especially with prolonged use\n- Cholestyramine (used to control blood cholesterol)\nMany of the medications on this list are essential treatments for certain medical conditions. If you are taking any of these medications, do not change your dosage or stop taking your medication without consulting with your doctor.\nWhat can I do to reduce the risk of osteoporosis?\nFortunately, there are many things you can do to reduce the risk of osteoporosis.\n- Regular weight-bearing exercise (such as brisk walking, dancing, tennis and jogging) is ideal to develop and maintain healthy bones. Bicycling and swimming are excellent exercises for general fitness, but as these are not weight-bearing exercises, they may be less effective in building strong bones. If you have problems with your heart, or have painful bones or joints, be sure to check with your doctor before starting any new exercise program.\n- A diet high in calcium also is important in preventing osteoporosis. Most doctors recommend 1000-1500 mg a day, which means a diet rich in dairy products (milk, cheese, yoghurt) and leafy green vegetables. Talking with a dietician may help you design a healthy diet. Over-the-counter calcium supplements also may be useful. If you are lactose intolerant, you may drink a calcium-rich soy milk or lactase treated cows milk.\n- Vitamin D is needed in order to absorb calcium. The skin makes this vitamin naturally when exposed to sunlight. Many dairy products also contain vitamin D. In general, you should not take more than 800 units of Vitamin D per day. Taking too much vitamin D may be harmful, so it’s best to check with your doctor before taking any vitamin D supplements.\n- Avoid smoking\n- Limit alcohol and caffeine intake\nWhat screening is recommended?\nAfter reviewing your treatment history and risk factors, your doctor can advise you regarding the need for bone density testing. Follow up scans may be needed for ongoing monitoring of bone density in some patients."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:d30ddea4-d51a-4ce6-8302-d6a1d8c7b55b>","<urn:uuid:977f72f1-8c41-4278-b993-e5d7ad28dd69>"],"error":null}
{"question":"How is hyponatremia diagnosed through laboratory tests, and what are the prevention strategies for athletes at risk?","answer":"Laboratory diagnosis involves checking serum osmolality for hypotonic hyponatremia (normal range 275-290 mosmol/kg) and measuring serum sodium levels, with levels below 135mEq/L confirming hyponatremia. For athletes, prevention strategies include: establishing individualized hydration protocols based on personal sweat rate, supplementing water with electrolyte beverages for exercise lasting over 1 hour, monitoring body weight before and after exercise, consuming adequate dietary sodium, allowing 8-14 days for heat acclimatization, and avoiding excessive fluid intake (>1.5 L/hour).","context":["Physiology of water balance • Almost all dysnatremias are a result of water balance • TBW = 60% total body weight • 2/3 ECF compartment with water that is freely diffusable b/w ICF and ECF to maintain identical osmolality • So, serum osmolality measures all compartments, i.e. -- when total body water is elevated, osmolality falls • ADH – governs the excretion of water by the kidney, which prevents dilution of urine when present\nOsmolality v. Tonicity • Osmolality: total number of particles in an aqueous solution (mosmol/kg H2O) • Normal Posm = 275-290 mosmol/kg • Effective osmolality (tonicity): particles that can exert osmotic force across membranes, via movement of water into or out of cells • Na+, glucose and BUN are major determinants of plasma osmolality • Posm = 2 x plasma [Na+] + [Glucose]/18 + [BUN]/2.8 • Effective osmoles (Na+ , glucose) exert water shifts unlike urea, ethanol\nWhat factors regulate the ECF? • There are multiple sensors (afferent limb that monitors EABV – amount of arterial blood that fills the arterial circulation) • Baroreceptors • Low pressure baroreceptors in venous beds that monitor for volume overload – atria, pulmonary vascular bed • High pressure barocreceptors (carotids) • JG apparatus (located at the thick ascending limb of the Loop of Henle to regulate afferent arteriole) – renin release • Efferent limb – primarily renal • Regulates rate of sodium excretion, which is most significant in the tubules • RAAS system – Ang II • ADH – released by posterior pituitary with 1% change in blood osm • Catecholamine release – directly stimulates sodium reabsorption at PT and LOH\nADH • ADH is created in supraoptic and paraventricular nuclei • Released as granules travels to posterior pituitary gland where it is released as osmolality increases • Site of action is collecting tubule • Regulated by plasma osmolality (released at 280-290), volume, stress, nausea, pregnancy\nApproach to hyponatremia • History and physical often gives clue to etiology of hyponatremia -- so take a good history 1. Check serum osm to make sure – hypotonic hyponatremia – total body water issue 2. Determine volume status • Hypovolemic • ↓ [Na+] = ↓↓TBNa/↓TBW • Euvolemic • ↓ [Na+] = ↔ TBNa/↑TBW • Hypervolemic • ↓ [Na+] = ↑TBNa/↑↑TBW\nApproach to hyponatremia 3. Is ADH response appropriate? Is H2O excretion normal or impaired • Uosm < 100 mosmol/kg indicates that ADH is appropriately suppressed • Primary polydipsia • Reset osmostat (when Posm is below normal) • Low solute intake • Uosm > 100 mosmol/kg occurs in majority of hyponatremic patients and indicates impaired H2O excretion\nHypervolemic Hyponatremia • Increased water much greater than sodium • Usually states of decreased effective circulating volume • CHF, nephrotic syndrome, cirrhosis, renal failure • What is urine sodium in these cases?\nHypovolemic Hyponatremia • Total body sodium loss > total body water loss • Determine if sodium loss is renal or extrarenal • U[Na] < 10 indicated extrarenal loss (Vomiting, diarrhea, third spacing) • U[Na] >20 renal losses (diuretics, mineralocorticoid deficiency, salt-losing nephritis, osmotic diuresis, bicarbonaturia, ketonuria\nClinical manifestations • Depends on rapidity of fall which does not allow for cerebral adaptation • Symptoms typically occurs below 125 mmol/L (if from previously normal levels) • Mostly neurologic symptoms • Nausea, headache, lethargy, ataxia, psychosis, seizures, coma\nSymptomaticHyponatermia • Key points: • 3% saline only if seizures or other neurologic manifestations (can consider faster infusion) • Concomitant lasix helps to eliminate free water • Frequent labs absolutely necessary • What is the risk of too rapid correction?\nCase examples • An 82 y/o woman is admitted from a nursing home with increasing lethargy and confusion. She has a baseline dementia, but is normally animated and interactive with family and staff. She has had a poor appetite over the past year with significant weight loss, and currently eats very little. Two weeks ago HCTZ was added to her medications. Over the past few days, the nurses note some n/v, no diarrhea, fever or other complaints. On exam, she has some dry oral mucosa but she is not orthostatic. There is no evidence of CHF, ascites or edema. She is awake, but lethargic. Neuro exam is nonfocal. Labs: Na 121 (last 130 4 weeks ago), normal renal/liver function. Serum osm 200, urine osm 220, urine Na 30.\nDifferential for hyponatremia • Volume depletion from n/v • Thiazide diuretic – how does this cause hyponatremia? • Tea and toast • SIADH\nHow would you treat this patient? • Stop diuretic +/- IVF (given ?SIADH) • If you gave patient 1L NS and she had SIADH, what would you expect to happen?","Hyponatremia is a medical condition termed for a low concentration of sodium in the blood (serum). By definition, hyponatremia occurs when serum sodium levels in the plasma fall below <135mEq/L. This has been shown to occur in up to 30% of ultra-endurance participants. Hyponatremia is mainly caused by overhydration, but can also be caused by intake of hypotonic fluid in excess of sweat and urine output, excessive sodium losses, or other hormonal dysfunctions that affect the maintenance of sodium stores in the body. The table below shows the risk factors associated with hyponatremia.\nHow do you prevent hyponatremia?\n- Have a hydration plan in place\n- Supplement water with electrolyte beverages, especially if exercise is lasting longer than 1 hour\n- Universal guidelines are not realistic due to the following factors\n- Variation in individual sweat rate\n- Variation in individual sweat sodium concentration\n- Environmental conditions\n- Record body weight before and after exercise to monitor fluid consumption\n- Know the sweat rate to determine fluid consumption during exercise\n- This also helps establish individual hydration plans\n- Know the signs and symptoms of hyponatremia\n- Have an emergency plan in place for dealing with hyponatremia\n- Monitor the duration and intensity of exercise for determining risk of hyponatremia\n- Educate athletes of risks from fluid overload and encourage moderate hydration.\n- Establish individualized hydration protocol based on personal sweat rate and sports dynamic.\n- Consume adequate dietary sodium.\n- Allow 8-14 days of training in the heat for acclimatization.\n- Identify pre-exercise hyponatremia by recording body weight each day\nWhat puts an individual at risk for hyponatremia?\n|Exercise duration greater than 4 hours or slow pace|\n|Low body weight|\n|Excessive drinking (<1.5 L/hour) during the event|\n|Abundant availability of drinking fluids at event|\n|Nonsteroidal anti-inflammatory drugs|\n|Other drugs associated with SIADH (SSRI’s)|\n|Extreme hot or cold environment|\nLook for these symptoms in athletes when hyponatremia is suspected:\n- Signs and Symptoms vary depending on severity and are related to cerebral edema caused by the osmotic flow of fluid into the brain cells\n- Patients that are asymptomatic or mildly symptomatic can present with any of the following:\n- Weakness, dizziness, headache, nausea, and/or vomiting and the resulting serum sodium levels range from 129-134mEq/L\n- Patients with more severe hyponatremia can present with any of the following:\n- Serum sodium levels less than 129mEq/L, presents with signs and symptoms of seizures, coma and death\nHow do you know if this is hyponatremia?\n- Indication of hyponatremia based on onset of symptoms\n- Type, duration, and intensity of exercise\n- Amount of fluid consumed\n- Post exercise body weight is greater than pre exercise body weight\n- Measurement of blood sodium levels\n- A measure <130mEq/L would indicate moderate-severe hyponatremia and coincide with observation of symptoms\n- Measurement of vitals\nWhat else could this be?\n- Exertional Heat Stroke\n- Heat Exhaustion\n- Heat Cramps\n- Cardiac Condition\n- Exertional Sickling\n- Respiratory Condition\nHow do you treat an individual with hyponatremia?\n- Treatment varies depending on severity of hyponatremia\n- DO NOT provide normal saline solution or fluids\n- Asymptomatic or mildly symptomatic\n- Treated with fluid restriction and observed until either serum sodium levels return to within normal limits or there is a resolution of symptoms and spontaneous diuresis\n- Consume oral hypertonic saline (e.g. bouillon) or salty foods such as potato chips, pickles, jerky\n- Hypertonic saline IV should be considered if a blood sodium level can be measured\n- Severe Hyponatremia\n- 3% hypertonic saline should be administered immediately due to the risk of cerebral edema that can ensue if treatment is delayed\n- It is also recommended that patients presenting with hyponatremia receive supplemental oxygen in case cerebral edema leads to hypoxia· The following flow chart represents when an athlete should be transported to the nearest hospital\nWhen can the individual return to activity?\n- Athlete will need to follow up with his/her primary care physician\n- Blood sodium levels will need to measure within normal limits (>135mEq/L)\n- Return to full activity should follow a graded exercise protocol similar what would be done during a period of exercise/heat acclimatization\n- Athlete will need to be educated on proper hydration before, during and post exercise to avoid the risk of suffering from hyponatremia again.\nRecommended Equipment List\n- Hypertonic saline\n- IV equipment\n- Portable blood Na+ analyzer kit (e.g. i-stat)\n- Salty foods (e.g. bouillon cubes, pretzels, canned soup, and potato chips, pickles)\n- Rectal thermometer (used to rule out exertional heat stroke)\n- Blood pressure cuff\n- Almond CS, Shin AY, Fortescue EB, et al. Hyponatremia among runners in the boston marathon. N Engl J Med. 2005;352(15):1550-1556.\n- Armstrong LE, McDermott BP. Exertional hyponatremia. In: Casa DJ, eds. Preventing Sudden Death in Sport and Physical Activity. Sudbury, MA: Jones & Bartlett Learning. 2012:185-199.\n- Binkley HM, Beckett J, Casa DJ, Kleiner DM, Plummer PE. National Athletic Trainers’ Association position statement: exertional heat illnesses. J Athl Train. 2002;37(3):329-343.\n- Casa DJ, Clarkson PM, Roberts WO. American College of Sports Medicine roundtable on hydration and physical activity: consensus statements. Curr Sports Med Rep. 2005;4:115-127.\n- Casa DJ, Armstrong LE, Hillman SK, Montain SJ, Reiff RV, Rich B, Roberts WO, Stone JA. National Athletic Trainers’ Association position statement: fluid replacement for athletes. J Athl Train. 2000;35(2):212-224.\n- Convertino VA, Armstrong LE, Coyle EF, et al. American college of sports medicine position stand. exercise and fluid replacement. Med Sci Sports Exerc. 1996;28(1):i-vii.\n- Hew-Butler T, Ayus JC, Kipps C, Maughan RJ, Mettler S, Meeuwisse WH, Page AJ, Peid SA, Rehrer NJ, Roberts WO, Rogers IR, Rosner MH, Siegel AJ, Speedy DB, Stuempfle KJ, Verbalis JG, Weschler LB, Wharam PM. Statement of the second international exercise-associated hyponatremia consensus development conference, New Zealand. Clin J Sport Med. 2008;18(2):111-121.\n- Montain SJ, Sawka MN, Wenger CB. Hyponatremia associated with exercise: risk factors and pathogenesis. Exer Sport Sci Rev. 2001;29(3):113-117.\n- Noakes TD, Sharwood K, Speedy D, et al. Three independent biological mechanisms cause exercise-associated hyponatremia: Evidence from 2,135 weighed competitive athletic performances. Proc Natl Acad Sci U S A. 2005;102(51):18550-18555.\n- Rosner MH. Exercise-associated hyponatremia. Semin Nephrol. 2009;29(3):271-281.\n- Rosner MH, Kirven J. Exercise-associated hyponatremia. Clin J Am Soc Nephrol. 2007;2(1):151-161.\n- Siegel AJ, Verbalis JG, Clement S, et al. Hyponatremia in marathon runners due to inappropriate arginine vasopressin secretion. Am J Med. 2007;120(5):461.e11-461.e17.\n- Speedy DB, Noakes TD, Rogers IR, et al. Hyponatremia in ultradistance triathletes. Med Sci Sports Exerc. 1999;31(6):809-815.\n- Toy BJ. The incidence of hyponatremia in prolonged exercise activity. J Athl Train. 1992;27(2):116-118."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:0e08c056-d972-4f6f-ace5-94f43d8852b5>","<urn:uuid:e490651c-5647-48eb-833f-7930c913fdbd>"],"error":null}
{"question":"Will the transition from proof-of-work to proof-of-stake affect Ethereum's market dynamics compared to Bitcoin? ⚡","answer":"The transition to proof-of-stake for Ethereum, while Bitcoin remains on proof-of-work, could affect their market dynamics differently. As explained in the documents, market value is influenced by utility, functionality, and network effects. The different consensus mechanisms affect transaction verification times and block creation - Bitcoin takes 10 minutes while Ethereum takes 14 seconds. Additionally, their different supply models (Bitcoin's 21 million cap versus Ethereum's unlimited supply) will continue to influence their respective market values through supply and demand dynamics.","context":["Cryptocurrencies have taken the financial world by storm, with Bitcoin being the trailblazer in 2009. Since then, numerous cryptocurrencies have emerged, each with its own unique features and value propositions. One of the fundamental aspects that intrigues investors and enthusiasts alike is understanding how cryptocurrencies gain value. In this article, we will delve into the factors that contribute to the value of cryptocurrencies and shed light on the mechanisms that drive their market prices.\nSupply and Demand Dynamics\nSimilar to any other asset or commodity, the value of a cryptocurrency is largely influenced by the dynamics of supply and demand. Let’s explore how these factors play a role in determining the value of cryptocurrencies.\nMany cryptocurrencies, including Bitcoin, are designed with a limited supply. For instance, Bitcoin has a maximum supply cap of 21 million coins. This scarcity creates an inherent value proposition, as the limited availability of the cryptocurrency can potentially drive up its price. The concept of scarcity, coupled with increasing demand, often leads to appreciation in the value of a cryptocurrency.\nThe demand for a cryptocurrency is influenced by several factors. First and foremost, the utility and functionality of the cryptocurrency play a significant role. Cryptocurrencies that offer unique features, such as fast transaction speeds, enhanced privacy, or smart contract capabilities, tend to attract more attention and usage, thus driving up demand.\nAdditionally, the perception of a cryptocurrency’s potential for future adoption and its use in real-world applications can also impact its value. News and developments related to partnerships, regulatory clarity, institutional adoption, and technological advancements can significantly influence market sentiment and drive demand.\nInvestor sentiment and market speculation also play a role in determining the demand for cryptocurrencies. Positive sentiment and optimistic outlooks can create a buying frenzy, leading to increased demand and upward price movements.\nNetwork Effects and Adoption\nNetwork effects play a crucial role in the value proposition of cryptocurrencies. The more users, businesses, and developers that adopt and utilize a particular cryptocurrency, the greater its network effects and, consequently, its value.\nA cryptocurrency gains value as more individuals start using it for various purposes. When a cryptocurrency becomes widely accepted as a medium of exchange, it creates a network effect. Bitcoin, for example, has gained recognition as a digital currency and is accepted by an increasing number of merchants and businesses worldwide. The broader the adoption and acceptance, the more valuable the cryptocurrency becomes.\nDeveloper Community and Ecosystem\nThe strength and vibrancy of a cryptocurrency’s developer community and ecosystem also contribute to its value. A robust community of developers drives innovation, enhances the functionality of the cryptocurrency, and expands its use cases. Ethereum, for instance, has a thriving developer community that has propelled the growth of decentralized applications (DApps) and the decentralized finance (DeFi) ecosystem built on top of its blockchain. The active development and continuous improvement of a cryptocurrency’s ecosystem attract investors and users, driving its value.\nCryptocurrency markets are subject to various market factors that can influence their value. Here are a few key factors to consider:\nThe liquidity of a cryptocurrency refers to the ease with which it can be bought or sold in the market without significantly impacting its price. High liquidity is desirable as it allows for efficient trading and ensures that the market price of the cryptocurrency accurately reflects its value. Cryptocurrencies with high trading volumes and widespread availability on exchanges tend to have better liquidity.\nMarket Sentiment and Speculation\nThe sentiment and speculation surrounding a cryptocurrency can significantly impact its value. Positive news, such as regulatory developments, institutional adoption, or significant partnerships, can drive up the price as market participants anticipate increased demand. Conversely, negative news or market uncertainties can lead to a decline in value.\nCryptocurrency markets are relatively new and less regulated compared to traditional financial markets. As a result, they are susceptible to market manipulation, including activities such as pump and dump schemes, wash trading, and insider trading. These manipulative practices can artificially inflate or deflate the value of a cryptocurrency.\nThe value of a cryptocurrency is determined by a combination of factors, including supply and demand dynamics, network effects, adoption, and market factors. The limited supply and increasing demand for a cryptocurrency contribute to its value over time. The adoption by users, businesses, and developers creates network effects, further bolstering its value. Additionally, market factors such as liquidity, market sentiment, and manipulation can also influence the value of cryptocurrencies. Understanding these factors can provide insights into the dynamics of cryptocurrency markets and assist investors and enthusiasts in making informed decisions.","What Is Block Time?\nBlock time is the measure of the time it takes the miners or validators within a network to verify transactions within one block and produce a new block in that blockchain.\nBlockchains were first popularized by Bitcoin when it was introduced in 2009. The technology has grown as more cryptocurrencies are created, each of which can use different or the same blockchain, validation methods, and techniques for creating new blocks.\n- Block time is the length of time it takes to create a new block in a cryptocurrency blockchain.\n- A block is verified by miners, who compete against each other to verify the transactions and solve the hash, which creates another block.\n- Under the proof-of-work consensus mechanism, cryptocurrency is rewarded for solving a block's hash and creating a new block.\nUnderstanding Block Time\nA blockchain is a distributed database that records all transactions within a cryptocurrency network. You can think of a block within the database as a cell in a spreadsheet where transaction information is stored. Miners verify the transactions, which takes time because finding the solution to the block requires the computers to make a vast amount of trial and error calculations.\nThis is called hashing—using an algorithm to verify all the transactions within a block, which validates the authenticity of the transactions and stored information. When the block solution is found, a new block is created. The amount of time to find the solution and create a new block is the block time.\nHere are a few key points to remember if you're trying to understand block time:\n- A block is a file that records a number of the most recent cryptocurrency transactions.\n- Each block contains a reference to the block that preceded it (that's why it is theoretically impossible to alter cryptocurrency).\n- Cryptocurrency \"miners\" race against each other to solve the hash, which is the hexadecimal number generated that verifies the transactions. The winner receives a crypto coin.\nHow Is Bitcoin’s Block Time Different Than Ethereum's?\nEach cryptocurrency has a different block time—Bitcoin takes around 10 minutes, while Ethereum only takes around 14 seconds. The exact amount of time it takes for block generation varies and depends on the difficulty of the hash (the hexadecimal number generated by the hashing algorithm). In other words, block times will not always be the same.\nConsensus mechanisms exist to allow a network to agree that a transaction is valid. Cryptocurrencies can use different consensus mechanisms, which, among other factors, affect the time it takes to verify transactions and create new blocks. Proof-of-work and proof-of-stake are two types of consensus mechanisms that use different methods for verifying a transaction. Ethereum is transitioning to a proof-of-stake consensus mechanism throughout 2022, while Bitcoin remains on the more popular and energy-intensive proof-of-work mechanism.\nHow Many Bitcoins Will Ever Be Created?\nBitcoin has a limit of 21 million. There are nearly 19 million Bitcoins in circulation, and the number of Bitcoins created per year halves every four years. This slows down Bitcoin creation.\nHow Many Ethereum Will Ever Be Created?\nEthereum, unlike Bitcoin, doesn't have an upper limit on the number of coins that will be created.\nHow Do I Get a Bitcoin Block?\nYou never actually receive a Bitcoin block since it is part of Bitcoin's framework. Instead, you receive a Bitcoin when your miner solves the hash and creates another block.\nInvesting in cryptocurrencies and other Initial Coin Offerings (“ICOs”) is highly risky and speculative, and this article is not a recommendation by Investopedia or the writer to invest in cryptocurrencies or other ICOs. Since each individual's situation is unique, a qualified professional should always be consulted before making any financial decisions. Investopedia makes no representations or warranties as to the accuracy or timeliness of the information contained herein."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:66ca9089-ccc9-42b2-a7a2-25835d7e155b>","<urn:uuid:22918f0a-c623-468e-88c4-df7956c6ab78>"],"error":null}
{"question":"How does the concept of convergent evolution differ from the inheritance of acquired characteristics proposed by Lamarck?","answer":"Convergent evolution and Lamarck's theory are fundamentally different mechanisms of evolution. Convergent evolution occurs when unrelated species independently develop similar features due to similar environmental pressures, as seen in examples like wings in birds, bats, and flies, or similar body shapes in sharks and dolphins. In contrast, Lamarck's theory of Inheritance of Acquired Characteristics proposed that new traits arise in organisms because of their needs and are then passed directly to their descendants. However, Lamarck's theory is no longer accepted as a valid scientific theory, while convergent evolution is well-documented and supported by modern evolutionary biology.","context":["3 edition of Convergent evolution in warm deserts found in the catalog.\nConvergent evolution in warm deserts\n|Statement||edited by Gordon H. Orians, Otto T. Solbrig.|\n|Series||US/IBP synthesis series ;, 3|\n|Contributions||Orians, Gordon H., Solbrig, Otto Thomas.|\n|LC Classifications||QH104.5.S6 C66|\n|The Physical Object|\n|Pagination||xiv, 333 p. :|\n|Number of Pages||333|\n|LC Control Number||76056261|\nIn evolution: Convergent and parallel evolution. Convergence is often associated with similarity of function, as in the evolution of wings in birds, bats, and flies. The shark (a fish) and the dolphin (a mammal) are much alike in external morphology; their similarities are due to convergence, since they have evolved independently. Buy Convergent Evolution () (): Limited Forms Most Beautiful: NHBS - George R McGhee, Jr., MIT Press.\nConvergent Evolution vs Divergent Evolution | Shared Traits Explained - Duration: 2 Minute Classroom , views. Master Shi Heng Yi . Convergent Evolution describes the way that unrelated or distantly related organisms develop similar body shapes, organ functions, colors, or adaptations. Convergent evolution is when species of different lineages independently evolve similar features. Examples of Convergent Evolution: 1.\nParallel evolution refers to situations where organisms that are unrelated or distantly related have similar adaptations because of similar environmental pressures. When parallel evolution occurs “in distantly related [organisms] that are morphologically similar in overall appearance” (Armstrong ) it is called convergent evolution. An explanation of convergent evolution. All pictures are from Google. “Convergent Evolution or Common Designer?”:\nHarold M. Reed.\nPhase transformations in xerogels of mullite composition\nControl of Pollution Bill (H.L.), 1974.\nThe way of the panda\nFaces, voices & dreams\nKey Concepts 1\nAmerican country living\neffect of environmental zoning and amenities on property values, Portland, Oregon\nFertility modification thesaurus\nWomen & Fatigue\nIn this book, George McGhee analyzes patterns of convergent evolution on Earth and argues that these patterns offer lessons for the search for life elsewhere in the universe.\nOur Earth is a water world; 71 percent of the earth's surface is covered by water.5/5(1). Convergent Evolution In Warm Deserts: An Examination of Strategies and Patterns in Deserts of Argentina and the United States (US/IBP Synthesis Series Vol.\n3) [Gordon H. Orians, Otto T. Solbrig] on *FREE* shipping on qualifying offers. Convergent Evolution In Warm Deserts: An Examination of Strategies and Patterns in Deserts of Argentina and the United States (US/IBP Author: Gordon H.\nOrians. An example of convergent evolution is the similar nature of the flight/wings of insects, birds, pterosaurs, and bats. All four serve the same function and are similar in structure, but each. Get this from a library.\nConvergent evolution in warm deserts: an examination of strategies and patterns in deserts of Argentina and the United States. [Gordon H Orians; Otto Thomas Solbrig;]. Book: Convergent evolution in warm deserts. An examination of strategies and patterns in deserts of Argentina and the United States.\npppp. Abstract: This book is number 3 in the US/IBP synthesis series and contains a general. Convergent evolution is the independent evolution of similar features in species of different periods or epochs in time. Convergent evolution creates analogous structures that have similar form or function but Convergent evolution in warm deserts book not present in the last common ancestor of those groups.\nThe cladistic term for the same phenomenon is recurrent evolution of flight is a classic example, as flying. Convergent evolution occurs when species occupy similar ecological niches and adapt in similar ways in response to similar selective pressures.\nTraits that arise through convergent evolution are referred to as ‘analogous structures’. They are contrasted with ‘homologous structures’, which. Solbrig, Otto T. and Orians, Gordon H. Convergent evolution in warm deserts: an examination of strategies and patterns in deserts of Argentina and the United States / edited by Gordon H.\nOrians, Otto T. Solbrig Dowden, Hutchinson & Ross ; exclusive distributor Halsted. 10 classic examples of convergent evolution, the process by which different animals in similar ecosystems evolve the same general body plan. Bob Strauss is a science writer and the author of several books, including \"The Big Book of What, How and Why\" and \"A Field Guide to the Dinosaurs of North America.\" our editorial process.\nPlants can also undergo convergent evolution to become more similar. Many desert plants have evolved somewhat of a holding chamber for water inside their structures. Even though the deserts of Africa and those in North America have similar climates, the species of flora there are not closely related on the tree of life.\nBuy Convergent Evolution: Limited Forms Most Beautiful (Vienna Series in Theoretical Biology) by Jr., George R Mcghee, Müller, Gerd B., Schäfer, Katrin, Pradeu, Thomas (ISBN: ) from Amazon's Book Store. Everyday low prices and free delivery on eligible s: 5.\nConvergent evolution is the process by which unrelated or distantly related organisms evolve similar body forms, coloration, organs, and adaptations. Natural selection can result in evolutionary convergence under several different circumstances.\nConvergent Evolution in Desert Lizards Some of the most striking examples of convergent evolution are found in desert lizards throughout the world. Australian and North American deserts each support a cryptically colored lizard species that is specialized to eat ants and is protected by sharp spines.\nConvergent evolution - Desert Plants from Kew Gardens on OOKL - the place to discover what is in your local museums, galleries, historic houses, zoos, botanic gardens plus lots of other things of interest near you and around the world. Several species of panda have evolved an extra digit, a “false thumb” that assists them in scraping the leaves from the bamboo that is their primary food source.\nIn fact, when well-known biologist Stephen Jay Gould wrote a book in support of evolution inhe called it The Panda’s Thumb.\nMcghee, G. Convergent dge, MA: MIT Press. Orians, G. and Solbrig, O. Convergent evolution in warm sburg, Pa. Convergent evolution — the repeated evolution of similar traits in multiple lineages which all ancestrally lack the trait — is rife in nature, as illustrated by the examples below.\nThe ultimate cause of convergence is usually a similar evolutionary biome, as similar environments will select for similar traits in any species occupying the same ecological niche, even if those species are. The main difference between convergent evolution and divergent evolution is that convergent evolution is the development of similar features in two species with different ancestral origins whereas divergent evolution is a process where two different species share a common ancestor.\nKey Areas Covered. What is Convergent Evolution. Examples of convergent evolution are wings of insects, birds, bats, streamlined body of dolphins and shark, whereas that of Darwin finches (kind of birds) is the example of divergent evolution. In convergent evolution, species evolve from the different species but develops similar characteristics, like wings of birds and insects.\nAn analysis of convergent evolution from molecules to ecosystems, demonstrating the limited number of evolutionary pathways available to life. Charles Darwin famously concluded On the Origin of Species with a vision of “endless forms most beautiful” continually evolving.\nMore than years later many evolutionary biologists see not endless forms but the same, or very similar, forms. Convergent evolution refers to the process where different organisms evolve to form similar traits, despite not being closely related.\nThis occurs when independent species have had to evolve to survive in similar habitats or have a specific niche to fill. There tends to be a finite number of ways for nature to deal with certain challenges.Convergent evolution is well-known and documented in the terrestrial realm.\nMarsupial and placental mammals have converged to similar morphologies and ecological function (Fig. 5).The limited variations on the mammalian body plan are evident in the wolf and catlike carnivores, the arboreal gliders, fossorial herbivores, anteaters, and subterranean insectivores that evolved independently in.\nGeneral Overviews. Review papers and textbooks, such as Futuyma tend to focus on how one can identify convergent evolution and on presenting particularly compelling examples of convergence or lack thereof. A few authors have attempted to make broad generalizations based on these observations.\nGould argues that evolution is dominated by historical contingency, while .","Text of Evolution. What is Evolution? Evolution involves inheritable changes in organisms through time...\nWhat is Evolution? Evolution involves inheritable changes in organisms through time Fundamental to biology and paleontology Paleontology is the study of life history as revealed by fossils Explains the development of life\nMisconceptions of evolution Evolution proceeds strictly by chance Nothing less than fully developed structures, such as eyes, are of any use There are no transitional fossils so-called missing links connecting ancestors and descendants humans evolved from monkeys so monkeys should no longer exist\nHistorical Perspective Evolution is usually attributed solely to Charles Darwin, but actually considered long before he was born. ancient Greeks and by philosophers and theologians during the Middle Ages Nevertheless, the prevailing belief in the 1700s was that Genesis explained the origin of life. Contrary views were heresy!\nHistorical Perspective During the 18 th century, naturalists were discovering evidence that could not be reconciled with literal reading of Scripture Scientists gradually accepted a number of ideas: The principle of uniformitarianism, Earths great age Many types of plants and animals had become extinct change from one species to another occurred What was lacking, though, was a theoretical framework to explain evolution\nLamark Jean-Baptiste de Lamarck (1744-1829) is best remembered for his theory of Inheritance of Acquired Characteristics. According to this theory new traits arise in organisms because of their needs Once acquired new traits are somehow passed on to their descendants Lamarcks theory seemed logical at the time and was widely accepted\nDarwin In 1859, Charles Robert Darwin (1809-1882) published On the Origin of Species details his ideas on evolution formulated 20 years earlier proposes a mechanism for evolution\nWhat he noticed Plant and animal breeders practice artificial selection by selecting desirable traits and then breeding plants and animals with those traits to produce more usegul species dogs, cats, vegetables, flowers What if natural processes could do the same thing? Thomas Malthuss essay on population suggested that competition for resources and high infant mortality limited population size What was different about the animals that survived?\nNatural Selection (Key Points) Darwin proposes the idea of Natural Selection Organisms in all populations posses heritable variations. size, speed, agility, visual acuity, digestive enzymes, color, and so forth Some variations are more favorable than others some have a competitive edge in acquiring resources and/or avoiding predators (i.e. baby birds and rabbits) Not all young survive to reproductive maturity, however, Those with favorable variations are more likely to survive and pass on their favorable variations.\nBack to the Giraffes In any population there is bound to be numerous variation in all inherited traits For example giraffe with all different neck lengths (some long some a bit shorter) As environments changed and trees grew taller and taller those giraffe with longer necks had distinct advantage over those with shorter necks. These giraffe were more likely to survive and therefore pass on there characteristics\nSurvival of the Fittest In colloquial usage, natural selection is sometimes expressed as survival of the fittest This is misleading because natural selection is not simply a matter of being the strongest; it involves differential rates of survival and reproduction One characteristic might provide an advantage to the individual in a specific circumstance but nature may favor the something else the smallest if resources are limited the most easily concealed those that adapt most readily to a new food source those having the ability to detoxify some substance and so on...\nLimits on Natural Selection Darwins theory of Natural selection works on existing variation in a population. It could not account for the origin of new variations Some critics also reasoned that traits would blend with other traits and be lost Red hair+blonde hair = strawberry blonde Long neck+ Short neck= medium neck The answer to these criticisms existed but remained hidden until 1900\nGregor Mendel During the 1860s, Gregor Mendel, performed a series of controlled experiments with true-breeding strains of garden peas strains that when self-fertilized always display the same trait, such as flower color or for example dog breedsBoxer+boxer =baby boxer Boxers are a true breeding strain\nMendels Work The parental generation consisted of true-breeding strains : One strain that produced red flowers and one strain that produced white flowers Mendel Cross-fertilized the two strains to yield a second generation all of which had red flower\nMendels Work Mendel then allowed the second generation to self fertilize and produced a third generation From his experiments Gregor determined that traits are controlled by a pair of factors now called genes Genes occur in alternate forms, called alleles One allele may be dominant over another Offspring receive one allele of each pair from each parent\nWhy is this important? The factors (genes) controlling traits do not blend during inheritance Although traits may not be expressed in each generation they are not lost Therefore, some variation in populations results from alternate expressions of genes (alleles) based on inheritance Variation can be maintained!\nModern Genetics Complex, double-stranded helical molecules of deoxyribonucleic acid (DNA) called chromosomes are found in cells of all organisms Specific segments of DNA are the basic units of heredity (genes) The number of chromosomes varies from one species to another fruit flies 8; humans 46; horses 64\nModern Thinking During the 1930s and 1940s, paleontologists, population biologists, geneticists, and others developed ideas that merged to form a modern synthesis or neo-Darwinian view of evolution Modern evolution incorporates chromosome theory of inheritance into Darwins theory of natural selection changes in genes (mutations) only one source of variation\nMost Importantly Lamarcks idea of inheritance of acquired characteristics no longer accepted as a valid scientific theory Problems with politics Lisenkoism Russian agronomist Lisenko believed Lamarcks ideas fit much more closely with communist ideology (no gene could be better than another). Eventually put in charge of Russian Science and purges all evolutionary scientist Responsible for massive wheat famine\nRemember Evolution by natural selection works on variation in populations most of which is accounted for by the reshuffling of alleles from generation to generation during sexual reproduction The potential for variation is enormous with thousands of genes each with several alleles, and with offspring receiving 1/2 of their genes from each parent New variations arise by mutations change in the chromosomes or genes\nMutations Mutations result in a change in hereditary information ONLY mutations that take place in sex cells are inheritable, Can be chromosomal mutations (affecting a large segment of a chromosome) or point mutations ( individual changes in particular genes) Mutations: Random with respect to fitness May be beneficial, neutral, or harmful\nThe Species Species is a biological term for a population of similar individuals that in nature interbreed and produce fertile offspring Species are reproductively isolated from one another Goats and sheep do not interbreed in nature, so they are separate species\nRecipe for a species Speciation is the process by which a new species arises from an ancestral species It involves change in the genetic makeup of a population, which also may bring about changes in form and structure\nAllopatric Speciation During allopatric speciation, species arise when a small part of a population becomes isolated from its parent population The peripheral isolates evolve as a result of genetic constriction and new environmental factors\nYeahbut how long? Although widespread agreement exists on allopatric speciation scientists disagree on how rapidly a new species might evolve Phyletic gradualism- the gradual accumulation of minor changes eventually bring about new species\nPunctuated Equilibrium Holds that little or no change takes place in a species during most of its existence then evolution occurs rapidly Current thought is that evolution is most likely a mixture of these two ideas\nStyles of Evolution Divergent evolution occurs when an ancestral species giving rise to diverse descendants adapts to various aspects of the environment Divergent evolution leads to descendants that differ markedly from their ancestors Convergent evolution involves the development of similar characteristics in dis"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:51dd3d9a-a157-4369-9b72-44ba6293dd54>","<urn:uuid:c3bd5908-3c4f-4b22-b8f0-aa77451df375>"],"error":null}
{"question":"How can holiday decorations incorporate both handmade and eco-friendly elements, and what natural materials are recommended for seasonal decor?","answer":"Holiday decorations can be handmade using natural and eco-friendly materials. For handmade items, one can create decorative candles with personalized images transferred onto them using tissue paper and a printer. For eco-friendly elements, nature provides materials like evergreen sprays, pinecones, nuts, fruits, and berries that can be arranged into centerpieces and displays. Natural materials can be used to create garlands from cranberries, popcorn, bay leaves, and dried fruits. Additionally, recycled materials are increasingly popular, with options including decorations made from recycled glass, metal, and natural fiber fabrics, moving away from non-biodegradable plastic decorations that have been common in the past 50 years.","context":["As the countdown to Christmas kicks off, it’s time to start thinking about those handmade gift ideas.\nIf you’re stumped for something different to create with your own hands this year, I’ve got a great idea for you. You’re going to love this.\nThroughout this post, I’ll walk you through how to make these pretty, decorative candles. They’re super easy to make with only a few supplies.\nIf you have a computer, a printer and a little bit of time, you can easily customize these candles with any image you like.\nMake sure you use candles that have a cylinder shape with the same width from top to bottom. I initially tried this project using tapered candles and the paper was much harder to line up and avoid creases.\nYou’ll also need an image to transfer to an 8 1/2 X 11″ sheet. You can use a photograph, a phrase or anything that can be transferred to an 8 1/2 X 11-inch sheet.\nI liked the idea of using musical notes for a vintage look so I conducted a google-search for vintage sheet music. Loads of pages came up.\nTo counter that, import the image into your photo-editing program and manually increase the resolution.\nYou’ll want to be careful about how you use images that you do not own. Many images you find on-line are copyright protected attached restrictions on usage and penalities for violation.\nThis is a particularly sensitive issue if you plan to use images for commerical purposes. You can easily find what’s called “copyright-free” images which do not have usage restrictions or prohibitions. Just google “copyright free images”.\nNow that you’ve selected an image, let’s get ready to transfer it to tissue paper.\nWhen I first tried this project out, I used vellum which is an-almost clear, lightweight paper that is commonly used in scrapbooking. Vellum does not work, it’s far too thick for the desired result and you’ll just ruin a good candle if you use it.\nCut tissue paper down slightly smaller than an 8 1/2 X 11 inch piece of cardstock.\nUse a tiny sliver of double sided tape across the top edge of the cardstock and adhere the top edge of the tissue paper to the cardstock. Make sure the top edge is nice and flat.\nThe cardstock provides the right amount of support for you to run the tissue paper through your printer.\nOnce the image is transferred to the tissue paper, carefully lift it off the cardstock and remove the edge from the double sided tape.\nBecause tissue paper is extremely fragile you may lose some of the tissue paper if it doesn’t detach completly from the double sided tape. This shouldn’t be a problem as long as you remember to use only a sliver of tape and adhere it as close to the edge as possible.\nLine up the tissue paper with your candle. You’ll need to cut enough tissue paper so that it will wrap completly around the candle.\nApply a small amount of glue to the wrong side of the tissue paper, along the top and bottom edges.\nCarefully adhere the tissue paper to the candle, pressing firmly as you go to smooth out creases or air bubbles.\nHold the candle upright and run the hot air gun along the entire candle. The wax will melt through the tissue paper and then dry on the outside of the tissue. This process totally embeds the tissue paper image into the wax as if it had always been there.\nDon’t put the hot air gun too close to the candle because you don’t want to melt too much of the wax which will cause the candle to lose its original shape.\nIf you have a slight amount of tissue paper overhanging on the bottom before you cut it, simply fold it across the bottom of the candle.\nIf giving a set of candles as a gift you can embellish the front with a holiday sprig. Don’t forget to remind the gift recipient that the candles should not be burned but used for decoration only.\nUse pliers to carefully twist the wire end of the decorative stem to close off that sharp end. Then, wrap the candles in a pretty ribbon and add the decorative stem for a perfect holiday gift.\nIMPORTANT: These are decorative candles ONLY and should NOT be lit. Even though the tissue paper is embedded and coated with wax, once the flame touches the uderlying paper the flame extends beyond the wick and becomes far too wide (the width of the candle) to be considered safe.\nYou could decorate candles to suit any occasion or season to use as home decor or great gifts.\nInstead of giving grandma and grandpa (or other loved ones) a holiday card featuring the family portrait, consider a special candle embedded with the annual family snapshot or a favorite old black and white photo. (These would make great anniversary gifts too).\nThere are tons of possibilities to create your own vintage decorative candles.\nHave fun and happy holidays. ♥","Enriching Your Holidays\nIt’s time for holiday celebrations, and that means it’s time for holiday decorations. Tables, mantels, ledges—virtually any smooth surface becomes a stage for festive arrangements featuring symbols of the holiday: nativity scenes; plump little Santas, reindeer, and sleds; a dreidel collection and menorah; a Kwanzaa altar with a mat, cup, and ears of corn. A lovely centerpiece becomes a focal point on the dining table, while garlands and wreaths offer natural beauty nearby. Inside and out, homes beckon with welcoming lights. Whatever your holiday, it’s easy to be eco-friendly this year when you decorate.\nDécor. Can the Plastic. For the past 50 years, many Christmas decorations have been made of nonbiodegradable plastics, but these days—especially with the ease of online searches—it’s not difficult to locate decorative holiday items for purchase made of wood, or recycled glass or metal. Recycled Christmas tree ornaments are becoming more popular every year; even First Lady Michelle Obama uses them, on the White House Christmas tree. If you’d like, you can create your own recycled decorations, or make them out of natural materials. If you need ideas, there are hundreds of books and websites devoted to recycled Christmas crafts.\nMany decorative items for Hanukkah are also made of synthetics (all those plastic dreidels! Oy!), but eco-friendly wooden options are on the rise, in a circling back to traditional practices. Artisans also make recycled metal dreidels and menorahs of recyled glass, metal, and steel pipe—even bicycle chains. Most are beautiful, many are available on the web, and all are fascinating and functional.\nKwanzaa also offers opportunities for using recycled materials, such as in the woven mat, unity cup, or kinara. There are plenty of books and websites with eco-friendly craft suggestions for this newest of the seasonal holidays. Just start your search engine and type in key words!\nEnlist Mother Nature. Even in winter, when most plants are dormant, nature offers items perfect for holiday decorating. Evergreen sprays can be arranged decoratively in centerpiece bowls featuring nuts and fruits such as pears, apples, and pomegranates. Pinecones may be gathered, destined to become rustic placecard holders (cut a slit into each pinecone, slipping a card into it) or part of a Christmas display—for example, a mix of pinecones, ornaments, berries, and holly. Christmas celebrants can gather to work on a garland of cranberries, popcorn, bay leaves, and dried apricots or other similarly sized dried fruit. The completed garlands can be draped atop mantels, around chandeliers, inside windows, or along interior door frames.\nMother Nature also provided the cotton, linen, and wool in outgrown or worn-out clothing; Christmas stockings are easy and fun to make with such fabrics. Just cut out a pattern, sew the edges right sides together (except for the top of course), turn inside out, and decorate. Don't forget to add a loop for hanging your unique eco-friendly Christmas stocking! Likewise, used natural-fiber fabrics can be recyled to make placemats for Kwanzaa, or a festive table runner upon which Hanukkah items can be arranged.\nLights. Outdoor holiday lighting adds cheer to those frigid, bleak winter evenings when darkness descends by late afternoon. Buying energy-efficient light-emitting diode (LED) lights to replace those inefficient incandescent ones is a sound investment. LED holiday lights stay cool to the touch, use less energy, and come in a wide array of colors and designs. (Come to the Garden’s Wonderland Express exhibition to see 750,000 of them!) A helpful suggestion for recycling your old holiday lights may be found here.\nOn a much smaller scale, if you want to lessen your carbon footprint by not burning paraffin candles during the Festival of Lights, you can find a variety of electric menorahs that use LED lights these days. The same lights may fit into the new electric kinaras available for Kwanzaa.\nCandles. Most families celebrating the holidays do burn candles, as they play a significant role in the traditions of Hanukkah and Kwanzaa, and are featured prominently in Christmas as well. Unfortunately, many of the candles sold specifically for menorahs and kinaras, as well as general decorative holiday candles, are made from nonrenewable petroleum products, primarily paraffin. When paraffin wax is burned, it produces carcinogens and soot. Some of the worst offenders are scented candles, whose aromas often come from petroleum-based synthetic oils mixed into paraffin wax. Fortunately, there are plenty of toxin-free beeswax or soy-based candles for the holidays that burn cleanly, some scented with essential oils. Your main challenge will be choosing from among hundreds of candle makers selling their eco-friendly products on the web; click here to visit just one of them.\nSo…as you ponder unpacking those dusty boxes of old, energy-inefficient, nonbiodegradable holiday decorations and lights, consider leaving their tops on and moving into a new, greener place this holiday: your own house. With natural or recycled decorations, LED lights, and eco-friendly candles, your home will capture the magic of the season while honoring the awesome beauty—and fragility—of nature."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:7d97f143-3e2c-46f6-a4cd-9d0f607a5e32>","<urn:uuid:d4f3c191-0f10-444c-9178-a583db366e1e>"],"error":null}
{"question":"Hey metalworking folks! What's the best way to avoid breaking saw blades when cutting metal? Been struggling with this and it's super frustrating! 😫","answer":"To prevent saw blade breakage, follow these key techniques: 1) Hold the saw lightly - grip it as if holding a small bird, avoiding white knuckles, 2) If the blade binds, relax your grip to allow the blade and metal to reposition rather than bearing down harder, 3) Use high-quality saw blades as cheap ones break more easily due to inconsistent lengths and improper tempering, 4) Maintain proper blade tension so you hear a musical 'ping' when plucking the back edge, 5) Apply beeswax or other lubricant to the back of the sawblade when needed.","context":["Metalsmithing: 25+ Professional Tips to Improve and Master Sawing\nLearning to saw is essential to becoming an accomplished metalworker. Mastering this basic skill expedites the process and eliminates most filing and sanding clean-up. With practice, the saw will be your best friend, a natural extension of your arm and hand.\nSimple Solutions for Sawing Problems\nWe notice an immediate reluctance from most students when instructed to saw out a pattern in class. They immediately suggest it is easier to cut the metal with a pair of shears, even though doing so leaves an inferior crimped edge, in our opinion.\nTips and Hints for Sawing\nWe’ve found that the following techniques and hints result in an immediate improvement of a student’s expertise and attitude:\n- You must be able to see the pattern to have success in sawing.\n- Use a task light for illumination.\n- Put on your glasses.\n- If an optivisor or other magnification is required, wear them.\n- If need be, adjust the height of the chair so the pattern is in focus.\n- If the chair is not adjustable then raise the bench pin so you can see.\n- Mind your posture.\nTom built this portable riser to elevate the bench pin for workshops where worktables are used and chairs not adjustable.\n- Make sure the blade is properly tensioned so that you hear a musical ‘ping’ when you pluck the back edge with your fingernail.\nNo white knuckles, please.\n- Grip the saw lightly in your hand. When the saw is held too tightly the blade is immediately ‘wonked’ to one side moving the sawblade off course. Think of the handle as a little bird in your grip, and don’t squeeze the birdie!\n- Apply beeswax or other cutting lubricant to the back of the sawblade as this is where the blade binds when cutting a curve. Putting wax on the front of the blade causes a buildup of wax that traps the metal filings preventing the clearing of the blade. Relax, breathe.\n- Your arm becomes a fulcrum as it moves steadily up and down in a sewing-machine motion, keeping the sawblade perpendicular to the metal. Don’t push the sawblade forward, instead feed the metal into the blade.\n- Relax, sawing is not a competition – there are no checkered flags just the satisfaction of a job well done.\n- Slower is faster — use the full length of the sawblade in a steady motion. You’ll be surprised at how quickly the blade cuts through the metal.\n- The sound of the sawblade cutting should be quiet and smooth as opposed to the sound of a sawblade pushed at a frantic pace with a tight grip using only a small portion of the sawblade. Using just a small area wears out the blade, leading to breakage.\n- A tip we garnered from an article by Michael David Sturlin: Position your body at 45° to the pattern so your eye’s line of sight is focused on the pattern, the portion of the pattern line being sawn, and then the sawblade.\n- Always saw just outside the edge of the pattern leaving the line. Sawing through the middle of the pattern is not advisable as it leaves a wobbly line. Leaving the pattern lines intact aids in filing and sanding during clean up.\n- Remember, don’t become a contortionist when sawing the pattern, turn the metal not the saw.\n- Saw a little — look a lot.\n- Take short breaks while sawing.\n- Take a deep breath, roll your shoulders, and relax your neck.\n- Apply the lubricant when needed — you’ll hear when the sawblade becomes dry.\n*No beeswax or other lubricant on hand? No worries, you always have ‘nose oil’ with you. Yes, rub your finger along the side of your nose, then apply to the back of the sawblade. Remember, the outside of the nose…. Some recommend that spit can be used, but that’s just icky!\n- If your sawblade binds in the metal don’t just bear down harder, as this causes the sawblade to snap. Rather, relax your grip on the saw allowing the sawblade and metal to reposition, relieving the stress. This may seem counterintuitive but give it a try. Doing so will save you time by not having to install another blade due to breakage.\nOnce you correct all these little problems you’ll find that sawing can become a pleasant, enjoyable experience. Some people we know even consider it to be almost a Zen-like pastime.\n- Always buy the best sawblades you can afford because cheap blades are not really a bargain. You’ll spend more time changing out the inferior ones than you can ever save by buying them on the cheap.\n- Inexpensive blades frequently aren’t of consistent lengths and are often not properly tempered, thus they break more easily.\n- A general rule of thumb is that the sawblade should have 3 teeth to the gauge of metal being sawn. Most jewelry suppliers provide a chart for selecting the proper size blade to the gauge of metal you are using in their print and online catalogs.\nOkay, so we haven’t addressed specific saws yet or our preference for one over another. Here’s a photo of some of the saws we’ve collected over the years. And, yes, we are charter members of Tool-Oholics Anonymous.\nWe acquired the Knew Concepts (red frame) and GreenLion [black handle] saw frames recently.\n- We feel these provide more rigidity and stability to the sawblades when sawing.\n- We have no problems inserting sawblades into them but there has been a lot of chatter about difficulties encountered by many users.\n- We found that our students tend to encounter more issues with the installation and breakage of sawblades using the Knew Concept saw frames during workshops and classes.\n- Surprisingly, the GreenLion frame proved smooth sailing for the students.\n- Kay prefers the Knew Concepts saw frame as the handle fits her hand more comfortably. To her the handle of the GreenLion saw frame is too large.\nThe truth of the matter is that once you master the art of sawing using any or all of the hints/tips we’ve mentioned here, you can use any saw frame you wish. It’s not the saw that is the true issue but one’s sawing ability that matters.\nTom & Kay\nTom & Kay Benham are Contributing Editors to Lapidary Journal Jewelry Artist and author its Ask the Experts column. Have a question for them? Please leave a comment below.\nGet more on sawing and a workshop by Michael David Sturlin workshop in the store, today!!"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:38a3c125-44dd-4820-b2ce-59a1b0833726>"],"error":null}
{"question":"Could you please compare how archaeology was treated in urban planning during the post-WW2 period versus how heritage sites like Shrogg's Park were managed in the Victorian era?","answer":"In the post-WW2 period, archaeology became an essential aspect of town planning, with local authorities being urged to compile consolidated records of ancient monuments by 1969 through the Walsh Committee's recommendations. In contrast, during the Victorian era, as exemplified by Shrogg's Park in the 1870s, heritage site management was more focused on private benefaction and specific conditions of use - for instance, Colonel Akroyd donated the park with strict stipulations about public access, maintenance budgets, and recreational purposes, showing a more individualized approach to heritage management.","context":["By Tony Haskell\nConservation is now an incredible a part of planners', surveyors' and designers' paintings load. This assessment of modern conservation schemes conducted by means of the County Councils in England and Wales will offer a special and crucial reference e-book for pros within the development embarking on 'heritage' paintings. utilizing targeted and highly-illustrated case stories, the publication records over a hundred schemes from commercial archaeology to old parks.\nRead Online or Download Caring for our built heritage: conservation in practice PDF\nBest urban & land use planning books\nDuring the last 25 years an enormous physique of literature has been released on neighbourhood results: the concept residing in additional disadvantaged neighbourhoods has a destructive impression on citizens’ existence possibilities over and above the influence in their person features. the amount of labor not just displays educational and coverage curiosity during this subject, but additionally the truth that we're nonetheless no toward answering the query of ways very important neighbourhood results truly are.\n\"Contemporary city layout perform has many resources to attract on yet those usually lack a versatile method of brand new advanced city occasions. This booklet addresses the present debate surrounding city regeneration and the contradictions of up to date city lifestyles. the writer proposes achievable ideas for the construction of sustainable towns, concentrating on the spatial personality of town and looking out past the fashion obsession of city makeovers to the basic components of city-making.\nThe ebook of the fairway Paper on making plans has magnified the importance of city layout frameworks, improvement briefs and grasp plans. regardless of common popularity that making areas socially, economically and environmentally profitable depends upon excessive criteria of city layout, there's much less knowing of ways strong layout may be brought.\n\"The 6th version of the hugely successfulThe urban Reader juxtaposes the superior vintage and modern writings at the urban to supply the great mapping of the terrain of city reports and making plans outdated and new. the town Reader is the anchor quantity within the Routledge city Reader sequence and is now built-in with all ten different titles within the sequence.\n- Sustainable Urban Development: The Environmental Assessment Methods\n- The Dynamics of Cities: Ecological Determinism, Dualism and Chaos\n- Re-imaging the City: A New Conceptualisation of the Urban Logic of the “Islamic city”\n- Underground Spaces : Design, Engineering and Environmental Aspects (Wit Transactions on the Built Environment)\n- Designing Suburban Futures: New Models from Build a Better Burb\nExtra resources for Caring for our built heritage: conservation in practice\nSubsequently, at Caring for our built heritage: conservation in practice 18 the time of the Norman Conquest, a castle was constructed within the enclosure, making use of the hill-fort defences. Today only the mound, banks and ditches remain; a series of low terraces and platforms outside the hill-fort site perhaps indicate traces of some settlement beyond the defended enclosure. The whole 13-acre site was recently donated to the Arundell Charity, a small local charity which did not have the resources to manage it properly.\nPart of the duties of the Archaeological Officer includes the maintenance and updating of the record to ensure that it is a reliable record of the county’s archaeology. Cheshire County Sites and Monuments Record. A typical example of a primary computer record. ) With the creation of possible for archaeology abridged extract of the encouraged to add the an up-to-date and accessible archaeological record, it is now to play a full part in the planning process. Each District has an SMR for development-control purposes and they are being information to their development-control maps.\nIn the two decades following the War, and the establishment of Town Planning units in many County Councils, the appreciation of our archaeological heritage was developed and, at a time when much town and city redevelopment was underway, was recognized as an essential aspect of both future planning and control. In 1969, the Walsh Committee (set up in 1966 under Sir David Walsh) recommended local authorities be urged to compile consolidated records of all known ancient monuments if they were not already doing so, and, at the same time, consider whether adequate professional archaeological assistance was available to them.\nCaring for our built heritage: conservation in practice by Tony Haskell","- Heritage Category:\n- Park and Garden\n- List Entry Number:\n- Date first listed:\nThe above map is for quick reference purposes only and may not be to scale. For a copy of the full scale map, please see the attached PDF - 1001557.pdf\nThe PDF will be generated from our live systems and may take a few minutes to download depending on how busy our servers are. We apologise for this delay.\nThis copy shows the entry on 28-Jul-2021 at 14:29:04.\nThe building or site itself may lie within the boundary of more than one authority.\n- Calderdale (Metropolitan Authority)\n- Non Civil Parish\n- National Grid Reference:\n- SE 08234 26130\nA public park laid out in the late 1870s and opened in 1881.\nOn 22nd November 1872, Colonel Edward Akroyd, a leading business man and benefactor, promised to build Shrogg's Park in Halifax. The site was a rough, irregular piece of waste land, entirely barren at one end and at the other, thickly covered with dwarf oak scrub, from which the Park gained its name, and pieces of rock. His plans almost came to nothing when the proposed Midland Railway scheme intended to build a line through part of what is now the Park. During a committee meeting of the House of Commons, Akroyd gave evidence of the measures he had undertaken so far and of his intention to provide a place for cricket, bowls, croquet, archery and other games. The railway scheme was turned down and work on the Park commenced. From 24th June 1873, the freehold for the land was leased from Captain Henry Savile of Rufford Abbey, Nottinghamshire for 999 years at a rent of £1. At a cost of over £10,000, work began on building the boundary wall, levelling ground and forming drives and footpaths. On 25th June 1879, Colonel Akroyd handed the partially completed park over to the Halifax Corporation for the benefit of the town. A list of conditions were attached to the generous gift:- the area was to be used only as a public promenade and recreation ground, and kept open during the whole year, including Sundays; that no charge be made for admission; that music and games be allowed under certain regulations; and that the Corporation spend a minimum of £1500 completing the Park and set aside an annual maintenance budget of at least £100 to keep the Park in a proper condition.\nThe final layout of the Park featured over 60,000 trees and shrubs; a fountain basin; a handsome, ornamental drinking fountain; striking bedding out displays and a shelter pavilion. In April 1881, Captain Savile gifted two plots of land in Shrogg's Road to improve the entrance to the Park. Later that year, on the 23rd June, the Park was officially opened to the public. It remains (2001) in public ownership today. DESCRIPTION\nLOCATION, AREA, BOUNDARIES, LANDFORM, SETTING Shrogg's Park is located c 2km north-west of Halifax town centre. It is situated on high promontory overlooking the Shroggs Mills and the Hebble Brook valley to the west. To the north and east the park lies against streets of late C19 stone villas whilst to the west and south the land falls to the industrialised valley. The park is c 10ha and comprises a mixture of landscape elements. The centre of the park is level and is laid out to accommodate a lake, floral displays, sports field, bowling greens, playground and depot. To the west and south-west the land falls steeply to the Shrogg's Road. The slopes are covered with broad leaf scrub and in the north-west of the site, rock outcrops form a striking landscape feature and viewing platform to the south and west. The land to the north and east falls more gently to St. George's Road and Lee Mount Road.\nA dressed stone wall c 1.70m high contains the park. Along St.George's Road and to the west and east of the Lee Mount Road entrance, the wall is reduced to a curb to accommodate iron railings, which were removed in the mid C20 as part of the war effort. Along the north of the park against the Lee Mount School the boundary is marked by a steel security fence c 2.25m high.\nENTRANCES AND APPROACHES The principal entrance, and accompanying lodge, is at the junction of Lee Mount Road and St. George's Road in the east of the park. Three stone gate piers, c 3m high mark the vehicular and pedestrian entrance although the original gates are gone and are replaced with a steel security barrier of late C20 design and construction. To the west and east of the gate piers the wall comprises a low stone curb on which iron railings were located. These were removed in the mid C20 and have not been replaced (2001). A second vehicular and pedestrian entrance is situated at the extreme north of the park at the junction between Lee Mount Road and Wheatley Road. The three stone gate piers are in place although they are not complete as two of them have lost their stone balls that cap the pier.\nIn addition to the two main entrances there are three pedestrian entrances. One is situated on Lee mount Road c 120m west of the Lodge Entrance. Original stone gate piers remain, however the steel gate is from the late C20. Restoration work and repointing to the stone wall to the west and east of the entrance is inappropriate and not of conservation standard. A second entrance is c 150m south of the Lodge Entrance on St. George's Road. The gate and gate piers are missing. Access to the south of the park from Shrogg¿s road is via a flight of stone steps which punctuate the boundary wall. Two stone gate piers, c 2m high, mark the entrance and although the gate is missing there is 0.4m run of original cast iron railings on a stone curb still in situ on either side of the piers. Immediately beyond the entrance a 3.5 m high stone wall retains the steep west bank of the park. Access to the north-west and south-east paths along the bank is provided by two flights of steps which run along the face of the retaining wall. The steps lead to the paths that are surfaced with stone setts, which incorporate a distinctive raised run of setts at frequent intervals. This configuration is known locally as cat steps and was designed to aid grip on the stone paths.\nPRINCIPAL BUILDING The principal building is a stone and slate lodge situated c 20m south of the entrance gates at the junction of St. George's Road and Lee Mount Road. It is still used as accommodation and is in a good state of repair.\nGARDENS AND PLEASURE GROUNDS The five entrances are linked to a perimeter path that encompasses the flatter areas of the park on the top of the hill. Set within the path are the recreational and games facilities including two bowling greens, multi purpose sports areas and two football fields. Between the path and the north boundary wall shrubberies covered banks\nThe principal park features are located in the north-west of the site. Located c 150m south-east of the Wheatley Road entrance a stone edged fountain basin is placed in the centre of gently raised grassed banks. The fountain no longer contains water and is now (2001) turfed. A raised bank for floral displays is situated c15m to the west of the fountain basin however the bank also now (2001) completely turfed . Approximately 25m to the south-east of the basin is a small stone edged serpentine lake c 70m long and c 14m wide. A gothic style, stone drinking fountain set on four steps is situated on the perimeter walk c 60m south-east of the fountain basin.\nShrogg's Road to the west is served by two historical paths which are paved with stone setts with rockery stone edges. A third path, which ran underneath the rock outcrops in the north-west of the park has fallen into disuse. C20 paths were built along the western slope.\nHalifax Antiquarian Society Transactions,1948, p98 The New Shrogg's Park, The Halifax Guardian, 4 June 1881 Shrogg's Park, Colonels fight against railway inroad, The Halifax Guardian, 30 January 1950\nMaps OS 25\" to 1 mile: 2nd edition published 1907 2nd edition published 1919 3rd edition published 1922 3rd edition published 1933\nIllustrations Early C20 postcards of Shrogg's Park, Halifax, Halifax Central Library\nArchival items Halifax County Borough Minutes, 1880-1883, Halifax Central Library\nDescription written: July 2001 Amended: August 2001 Register Inspector: PV Edited: October 2001\nThe contents of this record have been generated from a legacy data system.\n- Legacy System number:\n- Legacy System:\n- Parks and Gardens\nThis garden or other land is registered under the Historic Buildings and Ancient Monuments Act 1953 within the Register of Historic Parks and Gardens by Historic England for its special historic interest.\nEnd of official listing"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:ddf9e2d6-e2c5-4cef-b0e5-5b82957d2001>","<urn:uuid:09d9f0af-cf53-43c3-9f59-ca5ede30b30e>"],"error":null}
{"question":"What unique musical talents did Eldon Rathburn and Alessandro Alessandroni bring to their film compositions that set them apart from their contemporaries?","answer":"Rathburn and Alessandroni each brought distinctive musical abilities that made their work unique. Rathburn was known for his innovative use of folk instruments like banjo, Jew's harp, honky-tonk piano, and calliope, setting him apart from his contemporaries. He was a musical polyglot who experimented with layering multiple styles simultaneously and worked across classical, jazz, folk, pop, Celtic, and country genres. Alessandroni, on the other hand, became famous for his distinctive whistling ability, which helped create the iconic sound of Spaghetti Westerns. He was also a multi-instrumentalist who could play guitar, piano, accordion, sax, flute, mandolin, and was one of the first Italians to master the sitar. Additionally, he founded the octet I Cantori Moderni and worked extensively with composer Ennio Morricone on famous Western films.","context":["On Friday afternoon Carleton University is marking the completion of two major projects featuring the life and work of Eldon Rathburn, a composer best known for his work with the National Film Board.\nRathburn (1916-2008) wrote more than 250 film scores, most of them during his 30-year career as a staff composer for the NFB. He is quite possibly this country’s most prolific composer of film music. In his career, Rathburn experimented with a wide range of styles and instrumental configurations with influences ranging from classical, bluegrass, country, blues, electronic, avant-garde, church and dance music genres, to popular music and jazz. He also was the composer for many of the early IMAX films.\nThe university is marking the completion of a CD of music based on his work. It’s called The Romance of Improvisation in Canada: The Genius of Eldon Rathburn. The album was produced and arranged by Carleton master’s student Adrian Matte and alumna Allyson Rogers. It has recently been released by Justin Time Records of Montreal.\nThe other project is a book by Carleton Prof. James Wright. It’s called They Shot, He Scored: The Life and Music of Eldon Rathburn. It will be published by the McGill-Queen’s University Press in March 2019. In advance of the event, Wright answered some questions about Rathburn.\nQ. I know you as a composer of works such as Letters to the Immortal Beloved, so how did you come to write a book about Eldon Rathburn?\nA. During the last years of Eldon’s life, I had the good fortune to establish a close personal rapport with him. Our collaboration on an international symposium devoted to the chamber music of Arnold Schoenberg gave rise to our first meeting in 2005. As I came to know Eldon better, and earned his trust, I told him of my plan to write a book on his extraordinary life and work. From that time on he seemed to look forward to our meetings and interviews. Eldon was a lively conversationalist, and his memory was unfailingly razor sharp.\nEldon once said that if he had written his own autobiography, it might have been titled Name Dropping. Over time I came to understand that Eldon was keen to share reminiscences about how his work had brought him into close contact with three of the most important creative figures of his time: the visionary filmmaker Norman McLaren, the silent film legend Buster Keaton, and Arnold Schoenberg, the iconic 20th-century Austrian-American composer and music theorist.\nEldon had a personal goal of meeting some of the other leading figures in 20th-century music and he would devote a considerable portion of his summer vacation time to the pursuit of this singular goal. After these “field trips,” he would recount how he had met and discussed musical matters with one or more of the contemporary icons he had sought out.\nThroughout the book, anecdotes abound about Rathburn’s meetings and correspondence with Schoenberg, McLaren, Keaton, Ernst Krenek, Percy Grainger, Edgard Varèse, Charles Ives, Virgil Thompson, Kaikhosru Sorabji, Aaron Copland, Havergal Brian, Jack Shaindlin, Gavin Bryars, José Ray de la Torre, David Raksin and Carice Irene Elgar Blake, Sir Edward and Lady Elgar’s only child. Toward the end of his life, Rathburn spoke of how these close encounters with some of the inhabitants of his personal pantheon were among his most cherished memories.\nQ. How long did the book take?\nA. The book took five years to complete.\nQ. Can you put him in some sort of context for me as a composer?\nA. Eldon was a musical polyglot, and he frequently experimented with the simultaneous layering of two or more styles, perhaps a tip of the hat to the American composer, Charles Ives, whom he idolized.\nIn addition to his skill in scoring for traditional classical and jazz instruments, Eldon’s use of folk instruments such as the banjo (see for example his score for the Gerald Potterton film The Railrodder, featuring Buster Keaton in the starring role), the “Jew’s harp” and honky-tonk piano (see for example his score for Colin Low’s Oscar-winning NFB documentary City of Gold, narrated by Pierre Berton), and the calliope (in concert works such as The Rise and Fall of the Steam Railroad, 1982, and Three Calliope Pieces, 1994), set him apart from his contemporaries. Eldon saw and experienced his country through a uniquely positioned nostalgic lens, and his passion for the railway, historical and folk instruments, Canadian stories, cultures, and places was unequaled by any other composer among his contemporaries.\nHe wrote in classical, jazz, folk, pop, Celtic, country, and even “world music” styles according to the dictates and demands of the film project or concert work on his desktop. In his stubborn refusal to endorse the distinction that so many composers and listeners of his generation made between “high brow” and “low brow” music, and in the ways in which he freely borrowed from both, he was a postmodern composer.\nHe led a remarkable life spanning nearly a century of rapid evolution in media, technology, transportation, and sociological and political upheaval, and he made an important contribution to the awakening of Canadians to the realities, issues, and potential of the nation.\nIn an 1965 article titled “Thoughts on My Craft” he observed that: “Film music differs from traditional concert music in that it is often constructed of short, telescoped phrases, climaxes reached with little preparation, violent colour and textural changes and the lack of long transitional passages. Oddly enough, much present-day modern concert music has many of the above characteristics.” These are all features of Eldon’s concert music, as well as his film music.\nEldon was a dedicated and skillful artist who earnestly sought to represent and interpret Canadian film images and themes through sound. In his film work, Eldon engaged his lifelong fascination with and passion for the immense power of music to enhance and complement moving images on the screen.\nQ. It’s a long way from New Brunswick. How did he get to the big time?\nA. By train, poetically enough, given that “if there’s one single thing that turns on Eldon Rathburn more than others,” Montreal Gazette music critic Eric McLean wrote in December 1982, “it is trains.” Philip L. Scowcroft went a step further. Scowcroft proclaimed Rathburn “the most prolific of all train composers.”\n“Many composers have visited railways more than once,” he wrote. “But Rathburn surely outscores them all comfortably.”\nQ. Rathburn’s connection to IMAX film is interesting to consider, given that IMAX was a Canadian idea.\nA. I agree with your view that (IMAX) is a truly fascinating aspect of the story. To make matters even more interesting and personal for me, the creators of IMAX all went to high school at the Galt Collegiate Institute in my hometown of Galt (now Cambridge) Ontario.\nQ. What did Rathburn do with IMAX?\nA. After so brilliantly scoring the legendary multi-screen large-screen-format film Labyrinth, created by Roman Kroitor, Colin Low and Hugh O’Connor for Chamber 3 of the Labyrinth pavillion at Expo 67 (by far the highest-budget film in the NFB’s history), Eldon became the go-to composer for many of the early (and most award-winning) IMAX films including Tiger Child (1970, which was the first IMAX film), Circus World (1974), Skyward (1985), Transitions (1986), Beavers (1988), The First Emperor of China (1989), The Last Buffalo (1990), Momentum (1992), Flight of the Aquanaut (1993) and Titanica (1995).\nQ. Was composing for IMAX a different kind of experience?\nA. Eldon provides a few answers to this question himself in his personal notebooks (at Library and Archives Canada) and in an interview with Louis Hone (in 1993).\nHe said: “In most IMAX films, there is no narrative, voice-over or other commentary. The music alone must sustain the images and scenes, provide mood, musical commentary, emotion, meaning, and provide connective tissue and continuity. …\n“IMAX films usually need a certain fullness of sound to use the massive screen and quadraphonic speaker system to best advantage. …\n“It is a dangerous game to give a composer a film with no commentary at all … In this case, the composer calls the shots, which may or may not be what the producer had in mind.”\nQ. Can you tell me a bit about the CD.\nA. The core musical materials for this project are drawn from three timeless NFB short films: an Oscar-nominated animated romp through transportation history titled The Romance of Transportation in Canada (Colin Low, Wolf Koenig, Robert Verrall, 1952), Fish Spoilage Control (Wolf Koenig, Gerald Potterton, 1956), a deliciously zany animated film commissioned by Fisheries Canada, and Police (Terence Macartney-Filgate, 1958), a behind-the-scenes look at the daily challenges faced by the Toronto police force. Working with themes from Rathburn’s scores for these films, Adrian Matte and Allyson Rogers created a series of arrangements designed as a springboard for the improvisatory skills and imagination of the five leading Canadian jazz artists who endorsed the project and accepted the challenge.\nThe Romance of Improvisation in Canada was recorded in February 2018 at the NFB’s historic Chester Beachell studio in Montreal, the very studio where Rathburn worked and collaborated so frequently during his career. This versatile all-star ensemble takes the listener on a voyage through bebop to free jazz, tango and mambo, and brings the recording to a touching conclusion with a sentimental ballade. There is something here for all tastes and interests.\nThe CD features Petr Cancura (saxophones), Kevin Turcotte (trumpet, flugelhorn), Marianne Trudel (piano), Adrian Vedady (double bass) and Jim Doxas (drums). There are 12 songs.\nQ. Do we as a society pay enough attention to people such as Eldon Rathburn?\nThe answer is no, very unfortunately. Then again, artists such as Eldon Rathburn are sometimes quite self-effacing. Certainly Eldon did not seek the limelight. To some extent, this comes with the territory of being a film composer, since when the film composer is doing her/his job well, they are complimenting the film’s narrative and images, and rarely (if ever) “upstaging” them. In the end, Eldon simply loved his craft and he loved collaborating with filmmakers and his fellow musicians. He asked for little in return and he felt that the luxury of living a life as a creative artist was the most extraordinary gift one could ever hope for.\nMy mother died on Nov. 10. The comments I have made above about Eldon figure into my dedication of the book to her memory:\n“Music has enriched my life immeasurably, as it did for Eldon Rathburn, in whom I discerned a similarly deep and abiding gratitude for his profession. I am proud to dedicate this book to my mother, with whose loving care, guidance and encouragement I was able to realize my dream of becoming a musician.”\nIf you wish to attend the free wine and cheese event marking these two projects:\nWhen: Nov. 23; 4 p.m. to 6 p.m.\nWhere: Carleton University Art Gallery, Carleton University","Goodbye to Alessandro Alessandroni, the western world's most famous ‘whistle’\nThe composer, conductor and arranger Alessandro Alessandroni died in Rome. He had just turned 92 years-old. Celebrated for his 'whistle' which made many great soundtracks of the spaghetti western genre. 'For a Few Dollars More' is its 'booed' most iconic.\nLa Repubblica ·\nBy Valeria Rusconi and Ernesto Assante\nMarch 27, 2017\n\"It's very simple. I phoned Ennio Morricone and he told me: 'Sandro, come down here for a moment, in the room, we need you to whistle. Well, it was really a whistle, nothing more, but think about what happened next ... When we saw the film, I have to admit that no one thought it would make a penny\". And instead. Instead the 'whistling' really did change everything. Alessandro Alessandroni, the master - it is right to call him that - says the opening words of the most famous of his career and the most iconic of Western movies song that for a Fistful of Dollars, made up by Morricone, which made the film music of Sergio Leone - and practically made all the best western movies - even bigger. \"It was a great professional partnership, we had a wonderful collaboration,\" he told La Repubblica. Morricone, \"knew very well I could play the guitar and was the director of the choir and this was superb. And he knew very well that I could whistle. He had worked on A Fistful of Dollars and on other occasions. Why I chose him to whistle? by chance, I needed a whistle, I asked the musicians working with me who was able to whistle well and others I liked less. He had the courage to try\".\nThe composer, conductor and arranger Alessandro Alessandroni died in Rome, in the city that gave him birth on March 18, 1925, on March 26th. He had just turned 92 years of age. The announcement came on the official Facebook page of the composer: \"It is with great sorrow that I inform you of the death yesterday of the master Alessandro Alessandroni born in Rome on March 18, 1925, composer, multi-instrumentalist, arranger and choir director. There will be a memorial service at his home in Namibia with music and musicians directed by his son Alex Jr. Alessandroni\".\nAlessandroni approached music when he was still a boy. At the time he lived in the country of his mother, in the province of Viterbo. He was 11 years old and listened insistently, whenever he could to classical music. He began playing the guitar with assistance from a friend. The place is one of those details. He told in an interview to the blog Planet Hexacord: \"I started in the barber shop, because in small countries it is a reference point: there were the instruments, the guitar, the mandolin. They worked a little, but it sounded a lot. .. \". While he was attending the last year of high school he formed his first band, with whom he performed for local dance halls. Quick to learn, in a short time he become proficient on several instruments, which he alternates during his performances: as a teenager he already is able to play the guitar, the piano, the accordion, sax, flute, mandolin and sitar, one of the first Italians to try their hand on this complex stringed instrument. He obtained his diploma at the Conservatory in Rome, and found a job in the film production company Fonolux There he meets the great Nino Rota, his senior by 14 years, who wants him in his orchestra. Then came the whistle. It was almost by accident. Alessandroni, at some point, when Rota asked for a volunteer to whistle. Whistling become his new tool to play with and one of the moments that characterized the soundtracks of the Spaghetti Westerns. Music in effect: \"My whistle parts are on the staff,\" explained Alessandroni, \"and woe to miss the pitch, to make mistakes.\" That thought also by Federico Fellini, author of his soprannonme: Alessandroni for him was simply \"The Whistler\".\nIn 1962 he founded the octet I Cantori Moderni, a formation that takes the place of his previous group, the Caravels Quartet. With him, the band is formed by soprano Edda Dell'Orso, Augustus Garden, Franco Cossacks, Nino Dei, Enzo Gioieni, Gianna Spagnuolo and, not the least, his wife Julia De Mutiis.\nThe most important co-operation, long-lived and linked by a sincere esteem Alessandroni remains to this day one with Ennio Morricone: besides the famous whistle of For a Fistful of Dollars he also worked on For a Few Dollars More and The Good, the Bad and the Ugly. Alessandroni was used by all the most important Italian composers of the time, in the 1960s, such as Piero Umiliani, for which he sang along with his wife Giulia in great song Mah-na Mah-na, extracted from the soundtrack of Svezia inferno e paradiso by Louis Scattini (1968) and the master Armando Trovajoli. With the arrival of the seventies, for ARC of the RCA label which was dedicated to the ‘young Italian music’, between beats and 'world exotico', a public-disc collection of twelve songs in the race to the edition of 1969 of Canzonissima. Are recorded, of course, the tune and work on the Hammond organ solo is credited to Ron Alexander, his pseudonym.\nThe name of Alessandroni had become one of worship across the board, and had crossed generations and musical styles, especially he had conquered the library music enthusiasts. Among the last to want in their drive Baustelle, group of Montepulciano, who have chosen it for one of their best albums. \"Alessandro Alessandroni is the oldest guest,\" explained Francesco Bianconi, the singer, \"a wonderful eighty-four and played the sitar, accordion, acoustic guitar and he did blow the whistle\". The song title, not surprisingly, was Spaghetti Western. The Album, Amen.\nBorn: 3/18/1925, Rome, Lazio, Italy\nDied: 3/26/2017, Rome, Lazio, Italy\nAlessandro Alessandroni’s westerns – composer, musician, whistler, choir:\nA Fistful of Dollars – 1964 [guitar, whistle, choir]\nMassacre at Marble City – 1964 [choir]\nFor a Few Dollars More – 1965 [guitar, whistle]\nThe Good, the Bad and the Ugly – 1966 [guitar]\nSeven Dollars on the Red – 1966 [choir]\nAny Gun Can Play – 1967 [composer]\nPayment in Blood – 1967 [choir]\nWanted – 1967 [choir]\nOnce Upon a Time in the West – 1968 [whistle]\nThe Wild and the Dirty – 1968 [composer]\nEl Puro – 1969 [composer]\nRaise Your Hands, Dead Man, You're Under Arrest – 1971 [composer]\nZorro the Invincible – 1971 [composer]\nThe Crazy Bunch – 1974 [composer]\nWhite Fang and the Gold Diggers – 1975 [composer]\nWhite Fang and the Hunter – 1975 [composer]\nLucky Luke – 1991 [whistle]\nLucky Luke (TV) – 1991-1992 [whistle]"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:17a7831d-75ec-4161-9a06-e350f9159fd3>","<urn:uuid:1a728149-280f-4449-aa0c-f52566e200f4>"],"error":null}
{"question":"Compare the recommended rod lengths for saltwater fishing versus ice fishing - what are the typical lengths prescribed for each type of fishing and which one tends to be longer?","answer":"Saltwater fishing rods are typically longer, recommended to be 8½ to 9 feet (2.4 to 2.7 meters) in length. In contrast, ice fishing rods are generally much shorter, with typical lengths ranging from 24 to 36 inches (2-3 feet). For example, specific ice fishing rods like the Shakespeare USGXICE26M is 26 inches long, while the HT IB-36 Ice Blue Jig Rod measures 36 inches.","context":["Saltwater Fishing Basics\nIf you are planning on spending some time away on a saltwater\nfishing trip or vacation, this guide shares\ntips and ideas to help you get the most out of your next\nSaltwater fishing is fishing in water that has high quantities of salt, such as oceans, gulfs and seas.\nSaltwater flows inland in coastal areas, so saltwater fishing is possible near the mouth of rivers and streams in coastal areas.\nSalt water doesn't come from precipitation nor does it come from melting ice and snow.\nThere are hundreds of saltwater fish species, including sea catfish, cod, mackerel, barracuda, tarpon, eels, swordfish, dolphinfish, snapper, mullet, flatfish, turtle, tuna, sharks, garth, bass, flounder and\nSaltwater Fishing Equipment\nSaltwater Rods - A fly fishing basic rod for saltwater fishing should be 8½ to 9 feet (2.4 to 2.7 meters) in length. These cost between $100 and $500.\nAny rod under $100 will probably not be adequate for\nyour needs considering the amount of strain and work it\nwill most likely be doing.\nIf you are a beginner it will be wise to choose a rod in the $100 range. Once you hone your skills, you can buy a more expensive rod if you wish.\nAnother option for beginners is to borrow a rod from someone you know.\nReels - It is a good idea to buy a reel that is resistant to saltwater corrosion. These reels are made from such materials as fiber/resin, stainless steel, titanium and plated steel with components of bronze or brass.\nThis type of reel will run between $100 and $500. To learn which type of reel is best for your area, ask an experienced saltwater angler who has used his reel for more than two years, as this is the point in time when corrosion problems begin to appear.\nSaltwater Line - If you plan on fishing in flat and shallow estuary situations, a floating fly line will\nwork and these are the best lines for beginners.\nIf you plan to fish your fly beneath the water surface, you will be better off with a clear, intermediate fly line.\nIf you'd like a greater advantage, try one of the newer clear, sink tip lines when you're wading. These lines do not tangle around your feet like other fly\nlines tend to do.\nLeaders - Keep it simple. There are a few basic rules related to leaders. Use longer leaders for shy fish. For toothy fish and those with sharp fins use tough,\nuse thick leaders.\nWhen using a floating line and a fly that is weighted, use a long leader in deep water. If you're using a sinking line in deep water, use a short leader.\nSaltwater Flies - Saltwater fly selection can be simple. You have a variety of\nchoices - you can buy flies at bait and tackle shops, on the Internet, or learn to tie your own.\nIf you're a beginner, purchase Crazy Charlies, Surf Candies and Clouser.\nKeep them light and small until you hone your casting skills. A good way to choose flies is to buy those that are endorsed or\nhave been successfully tried by experts in the location where you are fishing. Casting\n- Casting shouldn't be a problem for saltwater fishing if you have experience in fly casting for trout.\nIf not, keep it light. If you have the ability to cast weighted nymphs, then casting weighted Clousers won't present a problem.\nRemember not to 'overline'. Overlining is when you use a line that is over the recommended weight for your rod. Look near the rod butt for the recommended line weight for\nIf you have no experience in fly casting you should consider fly casting lessons that are taught by an expert.\nHooking and Landing - When a fish strikes, set the hook with the line hand.\nDo not lift your rod high into the air and do not fight your catch with continuous pull.\nAlter your initial pull, try from the left, then from below,\nthen from the right.\nTry to upset the fish's swimming pattern by rolling it. This will make for a much easier landing.\nKeep your rod tip low and do not 'high stick' when landing a fish. If you high stick, you are likely to break the tip of your rod. That can be a costly mistake.\nAlways add a pincher (pliers) and gloves to your fishing gear to ensure a safe landing of fish that have abrasive skin or large, sharp teeth.\nA good way to protect yourself, other anglers and the fish, as well as minimize damage to flies is to pinch the barbs down on all of your hooks.\nSaltwater Fishing Bait - There is a large variety of live and artificial bait for saltwater fishing.\nNatural and live baits work well for a wide range of saltwater fish. Almost all saltwater species will take shrimp, so it is a good over-all bait to use.\nBaitfish of all kinds is also good bait, as all saltwater fish eat smaller fish species. Always use bait that is part of your targeted fish's diet.\nOther live baits include crayfish, crabs, oysters, lugworms, sand-eels, crustaceans of all types, razor fish, herring and a wide range of natural baits that include pieces of larger fish species.\nKeep it simple, never overweight and use just enough for the job.\nMatch the size of your hook to the size of your bait, equipment and the fish you are targeting.\nPutting small bait on a large hook looks unnatural and fish will not take it. The lighter the line, the lighter the hook. Follow this rule of thumb to match bait and tackle.\nIf you need help choosing saltwater fishing equipment, bait or need help learning to cast, ask an experienced saltwater angler or guide to help.\nAnother option is to ask for tips at the saltwater bait and tackle shop where you purchase your bait. The staff is always glad to help out when they can.\nWe hope this guide to saltwater fishing has given you\nthe basics you need to tackle your next fishing adventure...To read more about fishing, click\nhere to return to the Fishing Home Page","Fishing is an activity that is loved all around the world and can be done alone or with someone else, but in places where lakes get frozen in winter, fishing might just be too challenging. Nonetheless, it has its own charm, and when you get a good catch at the end of the day, it is all worth it. The question is, “Is there a way to make sure that you do end up catching a fish during this season? Yes, you can do so by getting the best ice fishing rods.\nAccording to experts, the best rods for ice fishing would be sturdy enough or made of high-quality materials. They should also have a comfortable grip and the perfect weight so that even if you fish for a long time, you will not feel too much strain. Today, there are ample kinds and choices when it comes to these fishing rods. Some may be specifically designed for ice fishing while others may be more versatile.\nHowever, before you go ice fishing and shop around for ice fishing rods, you must keep in mind that ice fishing is not exactly for rookies as it requires a lot more gear and you should have the know-how of how it all works. This activity will also require a greater line depth because fishes move down deeper into the water during cold seasons. That is because that is where there is more food or preys for them.\nAs difficult as ice fishing might sound, it is still a comfortable activity as once you are all set, all you just have to do is to sit and wait for the fish to get hooked. Also, chances are there will not be other anglers to compete with for the catch as ice fishing is not everyone’s thing. So, If you are looking for the best ice fishing rods, here are six reliable and even famous ones:\nShakespeare USGXICE26M Ugly Stik GX2 Ice Fishing Rod\nShakespeare is a company that has been producing fishing products for 115 years. The Shakespeare USGXICE26M Ugly Stik GX2 Ice Fishing Rod is a product that has a clean and modern looking rod that carries the strength and innovation that is the namesake of Ugly Stiks.\n- Ugly Tech construction with a combination of Graphite and fiberglass\n- Ugly Tuff guides feature new one-piece stainless steel guides to eliminate insert pop outs\n- Ugly Stik Clear Tip design for extra strength and added sensitivity\n- Durable and lightweight EVA grips\n- Enhanced cosmetics for a more modern look\nThe Shakespeare Ugly Stik GX2 is a 26 inches long fishing rod that has been constructed to do well with ice fishing. This has a medium weight, which is approximately 0.3 ounces, because that is what you will need when going ice fishing. This has been constructed using a combination of fiberglass and granite for better durability and enhanced strength level. Likewise, a clear tip design has been incorporated for more sensitivity while also bolstering strength.\nOn the other hand, the grip incorporated in this rod is a lightweight EVA material. Also, the Ugly Tuff guides are modern single piece items that are made from quality stainless steel materials. With that said, there is no more need for insert pop outs. In addition, there is a proper balance between the lighter and heavier sides of this rod. Hence, this is a new generation design for Ugly Stik but one that still carries the quality and strength of the name brand.\nFurther, if you are one for how a product looks, this is the one for you as well as the manufacturer has added the right cosmetics to make it look modern. It is one of those products that is an all-rounder as it has strong construction, innovative design, and the stamp of a name that is trustable.\n- Easy and comfortable to operate\n- High-quality construction\n- Durable and reliable\n- Does not feel heavy in the arms\n- Great value for money\n- Bends a little in the middle\nBerkley Cherrywood HD Ultralite Spinning Ice Rod\nBerkley or Berkley Fly Co. is a USA-based company that offers fishing rods, lines, baits, and tackles and has been around since 1937.\n- 100% fiberglass blanks\n- Durable rod finish\n- Full cork handles\n- Graphite sliding ring reel seat\n- Stainless steel guides and inserts\nThe Berkley Cherrywood Spinning Ice Rod is a 1.6 ounces and 24 inches long product that is made from fiberglass blanks and has full cork handles. This one too, like most modern fishing rods features stainless steel guides and inserts. These inserts offer more toughness, but with a low weight in comparison with oxide guides. In addition, it also has graphite ring seats that slide really well.\n- Lightweight and sturdy\n- Adequate size and length\n- Stainless steel guides for better functionality\n- Unmatched sensitivity\n- Great value for money\n- Easy to flick the baits and lures to the position you want\n- Suited for novice and experienced anglers\n- May not be suitable for a big catch\nFenwick AICE25MXFS Medium X-Fast Spinning Aetos Ice Rod\nFenwick is a company that has been dedicated to producing fishing products that meet the different needs of anglers for over 50 years. One of the products that they are proud of is the Fenwick AICE25MXFS Medium X-Fast Spinning Aetos Ice Rod, and the reasons behind such are detailed below.\n- Med X-Fast Spinning\n- Provided by Fenwick\n- Ice rod is made for ice fishing applications\nThe Medium X-Fast Spinning Rod from Fenwick is downright one of the strongest rods for ice fishing out there if not the strongest. It is exclusively made for ice fishing and is a 25 inches long rod. In case you did not know, Aetos rods are one of the very first ice fishing rods that were built like open water rods. It features solid graphite blanks and stainless steel guides and inserts. It has immaculate balance and sensitivity thanks to the combination of TAC split cork and cork handle construction.\nThere are multiple lengths and powers in the Fenwick Aetos series, but this one has the perfect length and power for ice fishing. This is perhaps one of the most sensitive rods out there as you will feel even the lightest bites. This is in part due to the fast tips that also give it incredible hook set ability.\n- Sturdy and long\n- Strong grip\n- Highly sensitive\n- Innovative design\n- A bit expensive\nFrabill Fin-S Pro Medium Ice Fishing Rod and Reel Combo\nAs similar to the previous products we discussed, the Frabill Fin-S Pro Medium Ice Fishing Rod and Reel Combo is also manufactured by a company that has been in the industry for several decades.\n- The CMMG, Inc Carbine Gas Tube With Roll Pin\n- Solid carbon fiber blank for increased sensitivity\n- Special stainless steel single foot ice guides\n- 3 plus 1 ball-bearing reel\n- Machined aluminum spool\nFrabill Fin-S Pro is a 30 inches long, medium power ice fishing rod that has a weight of only eight ounces. Sold at a fairly high price, you also get a three plus one ball bearing reel and a machine-made aluminum spool. It also has solid carbon fiber blanks that offer enhanced sensitivity. You can say that it is different that way as many ice fishing rods use fiberglass for lightness. With that said, it basically combines the good qualities of fiberglass and granite.\nIf we talk about the reel in this combo, that too lives up to the expectations. That is because the tapered drag knob helps reduce line catch. Also, the handle, that can be folded quickly, is ambidextrous so virtually anyone can use it.\n- Highly flexible and strong\n- Superior quality and highly efficient reel\n- Can be used for any kind of hard water fishing\n- Great value for money\n- A little expensive\nHT IB-36 Ice Blue Jig Rod 36″ Lt Spin\nThe HT IB-36 Ice Blue Jig Rod 36″ Lt Spin also belongs to a line of product that has been manufactured by an established company.\n- HT IB-36 ice blue jig rod\n- Tough, ice-blue graphite blanks, dark blue custom guide wrappings\n- Comfortable corkalon handles with Rings for reel mounting\nAs the name suggests, this product measures about 36 inches and has ice blue graphite blanks and dark blue custom guide wrappings. It has a weight of about one pound and features a smooth and comfortable corkalon handle with black rings for attaching a reel. On the other hand, they sport snake and stripper guides which are also found in the product line’s previous models. These line guides are made of chromed steel materials.\nThis product’s rod tip resembles a spring bobber which makes it highly sensitive and you would be easily able to tell when a fish bite. It is also a product that is comfortable to work with and is quite conspicuous too, although that is not something of high importance when it comes to fishing. It is the longest of the ultralight action rods from this maker.\n- Extended length\n- Great for jigging\n- Easy to use\n- High sensitivity level\n- Great value for money\n- Long-lasting and durable\n- Great flexibility\n- Might not be strong enough for catching really powerful fishes\n- Sometimes, the advertised length is inaccurate\nSt. Croix Avid Ice Series Jigging Rod\nSt. Croix Rod Company is amongst the most popular USA-based fishing rod manufacturers since 1948. It is the brainchild of brothers who are fond of fishing.\n- Designed specifically for jigging\n- Precision-taper solid carbon blank\n- Super-sensitive carbon handle\n- Kigan stripper guide with lightweight, low-profile running guides\n- Made in U.S.A. (with foreign and domestic materials)\nThe 27 inches long, medium power rod from the Avid Ice Series is sure to give other rods a run for their money. It features a precision-taper carbon blank and Kigan stripper guides that are equipped with low-profile and lightweight running guides. This is also a sensitive rod that can easily increase your catch. It also gives the control in your hands and has super flexible tips. You can use it with ice jigs, jigging spoons, walleye jigs or the Rapalas jigs.\nYou would notice that although it is essentially an ice fishing rod, it has characteristics similar to those found in open water rods. The Avid Ice Series is a favorite among many anglers who already love them since the first time they were introduced. It is definitely a strong choice that is capable of catching a variety of fishes.\n- Perfect for all jigging activities\n- Highly sensitive and lightweight\n- High-quality construction\n- Easy to use and control\n- USA made from top to bottom\n- You might need to use zip ties or electrical tape to attach a reel.\nBest Ice Fishing Rods: The Summary\nEven for a small niche product like ice fishing rods, there are plenty of choices online. Unless you know what exactly you want, it can get a bit confusing. These six rods will take out any guesswork as working with them is quite straightforward. With mostly favorable reviews from customers who have used them over the years, these products definitely deserve to make the cut for the best ice fishing rods.\nChoosing from the products above would guarantee that you get a good catch because they are all from well-known name brands that many anglers are already familiar with, and were constructed using quality materials. Also, these rods have not much rocket science to it. Almost all the products in question meet the requirements of flexibility and sensitivity, which are necessary for fishing. With that said, it comes down to the smallest details as to which appeals to you the most.\nTo give you an idea, the Ugly Stik and Berkeley rods provide greater sensitivity but are easy on the arms as they are light in weight. However, the Frabill Fin S Pro is the perfect choice if you are going for something that is ultralight but also powerful, functional, versatile, and efficient. On the other hand, the Fenwick Medium X-Fast has great balance and is best in terms of comfort.\nAs for pricing, these fishing rods are not that expensive, so you should be able to get any of your choices easily. Still, a few are pricier than others, mainly because of the materials used and the construction. Most rods do not come with a reel, and you have to buy it separately. The Frabill rod comes equipped with a reel and that too with high-quality and great features. As such, if you do not want the hassle of purchasing the reel separately and finding an entirely compatible one, this product should be your go-to choice."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:a21f26de-6596-4420-b6eb-715656436f41>","<urn:uuid:1ccacb98-7cb0-441e-baf8-dc2b329c87c1>"],"error":null}
{"question":"How do plant virus infections compare to bacterial infections in terms of their characteristic symptoms and transmission methods?","answer":"Plant virus infections and bacterial infections show distinct symptoms and transmission patterns. Viruses typically cause mottling, mosaic leaf patterns, and leaf rolling symptoms, and they can spread through plasmodesmata between cells. Bacterial infections, on the other hand, primarily cause vascular wilt that impacts water transport from roots to leaves. Bacteria enter plants through natural openings or mechanical wounds, often aided by free water, while viruses rely on the plant's ER membrane transport system for cell-to-cell movement through plasmodesmata.","context":["Spotting the difference between plant pathogen infections\nHow well do you know vegetable diseases? In this edition of The Front Line, join AUSVEG Biosecurity Officer Zali Mahony as she learns how to improve her disease recognition skills.\nVegetable diseases can be difficult to spot as they can look almost identical to plant disorders such as abiotic stress, nutrient imbalance, herbicide damage, poor light, and water logging.\nSigns and symptoms can be used to spot the difference between plant diseases and plant disorders.\nA ‘sign’ is the physical aspect of what causes a disease. Signs differ depending on whether a plant is infected with a virus, bacteria or a fungus.\nThis can be the white powder on the back of a pumpkin leaf, which is the spores of the fungus that causes powdery mildew. Or it might be galls on roots from infection by nematodes or insects that spread viruses and bacteria, which can cause disease.\nA ‘symptom’ is the physical outcome from the pathogen infecting the plant. Symptoms differ depending on whether a plant is infected with a virus, bacteria or a fungus.\nThis can include mottling, yellowing (chlorosis), curling of leaves, fruit distortion, wilting, rotting, dead cells (necrosis), tumours, leaf spots and lesions.\nImage A – Virus (Cucumber Green Mottle Mosaic Virus)\nImage A shows a zucchini plant infected with Cucumber Green Mottle Mosaic Virus (CGMMV), a virus known for causing significant damage to the cucurbit family.\nWithout doing any diagnostics, what signs and symptoms tell us that it is a virus infection?\nThe mottled, mosaic leaf pattern and leaf rolling are the two biggest indicators that this plant is infected with a virus.\nImage B – Fungus (Sclerotinia species)\nImage B shows iceberg lettuce infected with a fungus called Sclerotinia. This fungus is spread through air and wind when conditions are favourable.\nBut how do we know it is a fungus that is impacting this iceberg lettuce crop?\nThese plants are suffering from wilt and plant collapse, which can be indicative of infection by a fungus. Often there are signs of the Sclerotinia fungus at the base of the lettuce, fluffy grey or white material and hard, dark spores can be present.\nImage C – Bacteria (Ralstonia species)\nImage C shows a tomato plant infected with a bacteria called Ralstonia. Bacteria infects plants via natural openings on plants or via mechanical wounds, often aided by free water.\nBut what signs and symptoms tell us that it is a bacterial infection?\nThe plant is most notably experiencing vascular wilt, meaning its ability to transport water from roots to leaves is being impacted. This is often telltale sign that a plant is infected by a bacterium – although fungi can also cause stem wilts on plants.\nDiagnosing plants in-field without molecular diagnostics can be incredibly difficult as there many signs and symptoms that can occur when plants are infected by different pathogens.\nAustralia is free from many pests and diseases that plague the rest of the world. This absence – and our ability to prove it – allows Australian growers access to markets all over the world. Plant diagnostics are incredibly important and provide strong scientific evidence that our growing regions are free from certain pests and diseases.\nIf you are unsure of signs and symptoms of a pest or disease that you’re seeing in a crop, then modern, quick and accurate diagnostics can ensure good crop management and help you stay on top of good farm hygiene practices and prevent incursions.\nArea wide management\nA multi-million-dollar project responsible for developing an ‘area wide management’ strategy commenced in 2018 to address high-priority viral and bacterial diseases affecting vegetable crops.\nThis strategy included viral diseases transmitted by thrips, aphid and whitefly pests, and phytoplasmas transmitted by leafhoppers, and involved pest management approaches.\nThe second major focus of the project was on managing foliar bacterial diseases and work also involved developing rapid diagnostic test for key bacterial and viral pathogens.\nArea Wide Management of Vegetable Diseases: viruses and bacteria (VG16086) is a strategic levy investment under the Hort Innovation Vegetable Fund, and is set to be completed in May 2022.\nFor further details about the project, please contact Dr Cherie Gambley from the Queensland Department of Agriculture and Fisheries on 0423 200 211 or email firstname.lastname@example.org.\nFind out more\nPlease contact AUSVEG on 03 9882 0277 or email email@example.com.\nCover image: Bacterial wilt in a tomato crop. Image courtesy of Dr Cherie Gambley from the Queensland Department of Agriculture and Fisheries.","Plant viruses undertake plasmodesmata to infect new cells. cell-to-cell trafficking. Pharmacological disruption from the ER network inhibited NSm-GFP trafficking however not GFP diffusion severely. Rabbit polyclonal to ZNF101. In the mutant with an impaired ER network NSm-GFP trafficking was considerably decreased whereas GFP diffusion had not been affected. We also demonstrated which the ER-to-Golgi secretion pathway as well as the cytoskeleton transportation systems weren’t mixed up in intercellular trafficking of TSWV T-705 (Favipiravir) NSm. Significantly TSWV cell-to-cell pass on was postponed in the ER-defective mutant which reduced viral an infection was not because of reduced replication. Based on robust biochemical mobile and genetic evaluation we established which the ER membrane transportation system acts as a significant direct path for intercellular trafficking of NSm and TSWV. Writer Summary Plant infections might use different web host cell transportation machineries to go in one cell to some other through plasmodesmata. The contribution of web host cell transportation systems towards the intercellular motion of multipartite negative-strand RNA place infections including tospoviruses is normally poorly T-705 (Favipiravir) known. We utilized (TSWV) being a model to comprehend the system of intercellular motion of tospoviruses. Within this research using and systems for characterizing membrane protein we identified which the TSWV NSm motion protein was in physical form associated with the ER membrane. NSm indicated in one leaf cell was able to move into neighboring cells along the ER membrane network. The ER membrane in vegetation is a unique structure that runs between neighboring cells via the ER desmotubule of the plasmodesmata and forms a continuous network throughout the flower. Taking advantage of TSWV NSm becoming tightly associated with ER membrane and trafficked between cells through plasmodesmata we shown here by strong biochemical cellullar and genetic evidence the ER membrane transport system of vegetation serves as an important route for intercellular trafficking of the NSm movement protein and TSWV. Our findings have important fresh implications for mechanistic studies on intercellular trafficking of tospoviruses and additional multipartite negative-strand RNA flower viruses. Intro Plasmodesma-mediated macromolecular trafficking takes on important functions in flower growth and development [1-3] and in plant-pathogen relationships [4-6]. Structurally a plasmodesma is composed of the plasma membrane having a central altered appressed endoplasmic reticulum (ER) the desmotubule . Besides the long-established T-705 (Favipiravir) cell-to-cell transport of small molecules via plasmodesmata macromolecules such as proteins and RNAs have been shown in the last two decades to traffic between cells through plasmodesmata (PD). Such macromolecular trafficking is vital for viral illness [4-6] flower defense [8 9 and developmental rules [1-3]. Plant viruses need to move within and between cells to establish systemic infection. To accomplish this task the flower computer virus encodes a movement protein (MP) to help intracellular trafficking of the viral genomes from your replication site to PD and to aid the spread of the viral replication complexes or viral particles between flower cells through PD [5 6 10 Flower viruses not merely T-705 (Favipiravir) make use of viral-encoded MPs or various other viral elements for viral intra- and intercellular motion but also co-opt web host cell transportation machineries because of their motion [13-17]. The cytoskeleton and membrane transportation systems of cells are essential for intracellular motion of vertebrate infections (analyzed in ) needed for organellar trafficking within place cells [18 19 and mixed up in intercellular trafficking of macromolecules [20 21 Regarding the best-studied place trojan (TMV) the ER membrane is normally very important to its association using the viral replication complexes (VRC) and MP granules whereas microtubules and microfilaments facilitated their motion over the ER (analyzed in ). The ER membrane also acts as a significant system for anchoring other viral MPs that are necessary for intracellular motion and viral spread [23-27]. The ER-to-Golgi secretory pathway is involved with PD T-705 (Favipiravir) targeting and intercellular trafficking further."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:9026c1e2-08fe-4ba2-bfc0-5e3270ff6156>","<urn:uuid:090812f4-0e9d-4d06-98af-d7a5d7782181>"],"error":null}
{"question":"How do feral hog populations spread and establish themselves, and what disease risks do they pose to humans and other animals?","answer":"Feral hogs were initially introduced through human activity, such as early Spanish explorers bringing them to Texas over 300 years ago. They have high reproductive capacity and omnivorous diet, allowing them to quickly establish in most habitats on every continent except Antarctica. Regarding disease risks, they carry various dangerous diseases including pseudo rabies, swine brucellosis, tuberculosis, bubonic plague, tularemia, hog cholera, and hoof and mouth disease. These diseases are primarily transmitted through contact. In a notable case, feral swine were linked to an E. coli outbreak in California spinach fields that resulted in three deaths, demonstrating their potential to transmit diseases to humans through indirect contact.","context":["Feral Hogs in Southlake Early Spanish Explorers probably were the first to introduce hogs in Texas over 300 years ago. As colonization increased, hog numbers subsequently increased. They provided an important source of cured meat and lard for settlers. Feral hogs may appear basically the same as domestic hogs and will vary in color and coat pattern.\nA mature feral hog may reach a shoulder height of 36 inches and weigh from 100 to over 400 pounds. Hogs have four continuously growing tusks (two on top, two on bottom) and the contact causes a continuous sharpening of the lower tusks. They have relatively poor eyesight but have keen sense of hearing and smell. Feral hogs are distributed throughout much of Texas generally inhabiting the white-tailed deer range, with the highest population densities occurring in East, South, North and Central Texas. The current population in Texas alone is in excess of 1.5 million.\nCity of Southlake's Hog Management Plan Trapping is the most common method utilized by landowners and municipalities. This method allows for the safe and humane animal removal. The Southlake Department of Public Safety has taken the position that live trapping is the appropriate method of animal control. The animals would be baited and trapped in large groups.\nThese groups would then be removed from the city and humanely euthanized. This option, like others will be a slow and deliberate population control program. This will be a sustained program over months and years to control overall hog populations within Southlake. The hogs have lived in this area for many years which is why total eradication is highly unlikely, but management and control of hog populations is possible through efforts of everyone working together for a common goal. If you have questions please call the Southlake Police Department at 817-748-8114.\nFrequently Asked Questions\nWhat do feral hogs eat?\nIn a word, everything. Feral hogs are omnivorous, meaning they eat both plant and animal matter. They are very opportunistic feeders and much of their diet is based on availability. Foods include, grasses, forbs, roots and tubers, browse, acorns, fruits and bulbs. Animal matter includes invertebrates (insects, snails and earthworms), reptiles and birds. Hogs will also feed on domestic animals if given the opportunity.\nDo feral hogs carry diseases?\nYes. In general, wild hogs carry various diseases. They include pseudo rabies, swine brucellosis, tuberculosis, bubonic plague, tularemia, hog cholera, hoof and mouth disease.\nHow do I keep from contacting disease?\nMost of these disease are transmitted by contact, avoiding contact with wild or feral hogs is the only sure way of avoiding contracting these diseases.\nAre feral hogs dangerous? All wild animals have the potential of being dangerous, especially when wounded or cornered. In a natural state, feral hogs will prefer to run and escape danger, and are not considered dangerous. Extreme caution should be maintained when encountering any wounded, cornered, trapped animal or females with young. \"Their razorsharp tusks combined with their lightning speed can cause serious injury\".\nCan I wipe out a hog population through trapping?\nThe feral hog has managed to survive, adapt, and increase their numbers despite attempts at population control. While it is possible to keep the population in check with continuous control, it is highly unlikely to eradicate a hog population within an established range. The City has established a plan to help control the feral hog population. You can find it’s basic components on the other side of this brochure.","Feral swine -- Control -- Oregon, Feral swine -- Environmental aspects -- Oregon, Wild boar -- Control -- Oregon, Oregon Invasive Species Council\nFeral swine are defined as free roaming animals of the genus Sus that are not being held under domestic management or confinement. Swine have spread from Europe and Russia to habitats around the world via human introduction. Currently, feral swine populations are established on every continent except Antarctica. Unlike other large mammal invaders, swine have a high reproductive capacity and are omnivorous, which allows for a quick assimilation into most habitats. Once a breeding population is established in an area, the population can quickly increase and negatively impact the ecosystem. A successful invasion of feral swine is difficult, and sometimes impossible, to reverse. A feral swine pest risk assessment for Oregon, released in 2004, designated feral swine as a very high-risk species due to high potential for establishment, environmental and economic impacts, and disease transmission to wildlife, livestock and humans. Economic impacts on ecosystems and disease transmission to wildlife are difficult to assess, but restoration of ecosystems and losses to agriculture and livestock have been estimated to exceed US$800 million in the United States each year. Environmental impacts include facilitation of noxious weed invasions, shifts in dominant plant species, reduction of forest regeneration, and soil erosion. Facilitation of noxious weeds and erosion due to feral swine rooting are documented in Oregon. Feral swine in Oregon have not been implicated in disease transmission to humans, but the recent E. coli outbreak from spinach grown on a California farm that caused three deaths has been genetically traced to feral swine excrement deposited in spinach fields. The feral swine population in Oregon is currently small and dispersed. Few disturbances have been documented but state and federal biologists report regular occurrence of disturbances due to feral swine. Actions to prevent the effects of an invasion fall into three categories: management, control or eradication. Of the three categories, only eradication efforts have successfully slowed or reversed the effects of swine invasions. Case studies from California, Australia, Hawaii, the Galapagos Islands and the Channel Islands off the coast of California show that management and control efforts, while effective in the short term, have not successfully kept small feral swine populations from increasing to levels that are unmanageable and uncontrollable. A four-year feral swine eradication plan is proposed. The Plan includes recommended legislative changes to facilitate eradication, outreach and education, population assessment, rapid response, and eradication elements. A 0.5 FTE position is required at the Oregon Department of Fish and Wildlife to implement the plan. Eradication of feral swine in Oregon is estimated to require a four-year, $1.29 million effort. Follow-up control of new releases and escapes will require a maintenance effort estimated at less than $50,000 per year (excluding contingency funds for emergency response). These costs are small relative to the value of the $3.6 billion Oregon agriculture and livestock industries and the investment Oregon has made in riparian restoration efforts. Sustained control of feral swine in Oregon will require a longterm commitment that will include annual domestic swine marking, education, and monitoring.\nSytsma, Mark and Rouhe, Arick Christopher, \"Feral Swine Action Plan for Oregon\" (2007). Center for Lakes and Reservoirs Publications and Presentations. 14."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:f0ed966d-9041-49d0-9c39-d81c37b873dc>","<urn:uuid:905df633-f756-4dc8-9e51-957bd08668f9>"],"error":null}
{"question":"Could you list both the traditional methods of identity theft and the social media-based threats to personal information?","answer":"Traditional methods of identity theft include: dumpster diving for personal documents, skimming credit/debit cards, phishing schemes, changing address forms, and stealing physical items like wallets and mail. On the social media front, threats include attackers collecting personal information from public posts to guess security question answers, impersonating trusted brands or contacts, friend request schemes to access private information, and using professional networks like LinkedIn to gather business emails for phishing attacks. Both traditional and social media-based methods can lead to account takeovers and significant data breaches.","context":["Citizenship readiness involves preparing America’s students to contribute and succeed in our increasingly diverse and global society. It includes the development of character or soft skills such as responsibility, integrity and respect as well as important life skills such as appropriate and effective use of technology.\nSoft skills are those character traits, interpersonal skills and social habits that characterize a person’s relationships with other people, and they are critical for personal and professional success. In fact, many of today’s employers emphasize that soft skills are just as important — if not more — as academic preparation and job-specific skills and training.\nSoft Skills Most In Demand By Today’s Employers\nAbility to organize thoughts and ideas effectively and express clearly and persuasively when speaking or writing\nPositive, Professional Attitude\nDisplaying enthusiasm through words and actions; acting in a manner that is responsible, fair and respectful of others\nAbility to work well with others in a professional manner to achieve a common goal\nCritical Thinking and Problem Solving\nAbility to evaluate a situation and effectively and accurately identify potential problems and solutions\nAbility to prioritize tasks, use time wisely and work on a number of different projects at once\nWillingness to persist in difficult tasks, working to overcome obstacles and produce results\nAbility and Willingness to Learn\nWilling and capable of learning new skills and techniques, seeking to improve personal and overall performance\nHonest and respectful, upholding the company’s or institution’s image and values\nAbility to recognize opportunities for growth as well as the need for change and then implement the steps necessary for achievement\nAbility to design, plan and implement projects and tasks within an allotted timeframe\nSkills to Pay the Bills\nIdentity theft is a serious crime. It occurs when your personal information is stolen and used without your knowledge to commit fraud or other crimes. Identity theft can cost you time and money, destroy your credit and ruin your good name.\nCommon Methods of Identity Theft\nSkilled identity thieves use a variety of methods to steal your personal information. Keep in mind that new methods and techniques are developed every day, especially online, so it is important that you always remain wary, vigilant and informed.\n• Dumpster Diving. Thieves rummage through trash looking for bills or other paper with your personal information on it.\n• Skimming. Thieves steal credit/debit card numbers by using special devices when processing your card or even by using special scanners for cards with RFID (Radio Frequency Identification Systems) technology.\n• Phishing. Thieves pretend to be financial institutions or companies and send spam or pop-up messages to get you to reveal your personal information.\n• Changing Your Address. Thieves divert your billing statements to another location by completing a “change of address” form.\n• Old-Fashioned Stealing. Thieves steal wallets and purses; mail, including bank and credit card statements; preapproved credit offers; and new checks or tax information. They steal personnel records from their employers or bribe employees who have access.\n• Shred financial documents and paperwork with personal information before you discard them.\n• Protect your Social Security number. Don’t carry your Social Security card in your wallet or write your Social Security number on a check. Give it out only if absolutely necessary or ask to use another identifier.\n• Keep your personal information in a secure place at home, especially if you have roommates, employ outside help or are having work done in your house.\n• Don’t give out personal information on the phone, through the mail or over the Internet unless you know with whom you are dealing.\n• Don’t respond to email, text or phone messages that ask for personal information. Legitimate companies don’t ask for information this way. Delete these messages.\n• Never click on links sent in unsolicited emails; instead, type in a web address you know.\n• Use firewalls, anti-spyware and antivirus software to protect your computer, iPad and/or other devices and keep up to date. You should set your computer or device’s operating system, web browser and security system to update automatically and on a regular basis.\n• Don’t use obvious passwords like your birth date, your mother’s maiden name or the last four digits of your Social Security number. Create passwords that mix letters, numbers and special characters.\n• If you shop or bank online, use websites that protect your financial information with encryption. An encrypted site has “https” at the beginning of the web address. The “s” is for secure.\n• If you use a public wireless network, do not send information to any website that isn’t encrypted.\nBe proactive to detect suspicious activity and possible identity theft.\nReview your credit report periodically. You can request a free credit report once every 12 months from each of the nationwide consumer credit report companies: Equifax, Experian and TransUnion. To obtain your free credit report call 1-877-322-8228 or visit http://www.AnnualCreditReport.com.\nRoutinely monitor your financial accounts and billing statements. Be alert to signs that require immediate attention:\n• Bills that do not arrive as expected\n• Unexpected credit cards or account statements\n• Denials of credit for no apparent reason\n• Calls or letters about purchases you did not make\nIf you suspect you are the victim of identity theft, you must take action immediately.\n- Place a “Fraud Alert” on your credit reports, and review the reports carefully. The alert tells creditors to follow certain procedures before they open new accounts in your name or make changes to existing accounts.Each of the three nationwide consumer reporting companies have toll-free numbers for placing an initial 90-day fraud alert, but a call to one company is sufficient.Equifax\n- Close any accounts that have been tampered with or established fraudulently.\n- Call the security or fraud departments of each company where an account was opened or changed without your approval. Follow up in writing with copies of supporting documents.\n- Use the ID Theft Affidavit at http://www.ftc.gov/idtheft to support your written statement.\n- Ask for verification that the disputed account has been closed and the fraudulent debts discharged.\n- Keep copies of documents and records of your conversations about the theft.\n- File a report with law enforcement officials to help you with creditors who may want proof of the crime.\n- Report theft to the Federal Trade Commission. Your report helps law enforcement officials across the country in their investigations.Identity Theft Clearing House\nFederal Trade Commission\nWashington, DC 20580\n1-877-ID-THEFT or 1-877-438-4338 or TTY 1-866-653-4261\nOnGuardOnline.gov is the federal government’s website to help you be safe, secure and responsible online. It includes great tips and resources on avoiding scams, securing your computer and wireless networks, protecting kids online and much, much more.\nFTC.gov/idtheft also provides great information about how to prevent identity theft and what to do if you fall victim.\nTech in the Workplace\nIn every region and in every industry, widespread and increasing use of the Internet, computers and automated systems greatly impacts the way we do business. Daily advances in technology mean there are always new products and methods, new solutions and problems. Although you may already know how to and do use smart phones, apps, social media, iPads and other tablet devices, it is important for you to understand the role such technology can play in building your career.\nEmail has become an integral part of everyday lives. It is also a form of communication essential to most every industry and job. Appropriate and professional use of email can help you not only land a job, but also keep one. Learn more with these Email Etiquette Guidelines.\nVoicemail and Ringtones\nMake sure your outgoing voicemail message is professional while searching for a job. An employer does not want to hear a party in the background when he or she calls to leave a message.\nDisable your “ringback” and use standard ringtones when searching for a job. A simple ring is more professional than your favorite song.\nFacebook, Twitter, Pinterest, YouTube, Instagram, MySpace. The odds are pretty good that you currently use one or more (or all) of these social networks to interact online with friends and other network members by sharing messages, posting photographs, etc. Nearly 70% of all online American adults ages 18 and above use one or more social networks regularly. We expect that number as well as social networking options to continue to grow.\nA common trend for today’s employers is to seek out a candidate’s personal information on search engines such as Google as well as their social networking profile on sites such as Facebook, Twitter, YouTube, MySpace and more. You should be aware that what you do online now, including how and what you share on various social networks, can impact your future career path. As you work to become job ready and to join the workforce, consider these Social Networking Tips.","Social Media Threat Definition\nSocial media offers an outlet for people to connect, share life experiences, pictures and video. But too much sharing—or a lack of attention to impostors—can lead to a compromise of business and personal accounts.\nAttackers often use social media accounts during the reconnaissance phase of a social engineering or phishing attack. Social media can give attackers a platform to impersonate trusted people and brands or the information they need carry out additional attacks, including social engineering and phishing.\nHow Social Media Threats Happen\nBusinesses can’t control what people do in their private lives. But unfortunately, attackers can take advantage of employees who post too much information on social media.\nThe methods used by an attacker depend on the social media platform targeted. Facebook allows users to keep their images and comments private, so an attacker will often friend a targeted user’s friends or directly send a friend request to a targeted user to access their posts. If an attacker can connect to several of the targeted user’s friends, then it’s more likely that the targeted user will accept the friend request based on the number of connected friends.\nLinkedIn is another common social media target. LinkedIn is known for business networking, and users’ networks are typically filled with colleagues and other employees within the same organisation. If an attacker targets a business, LinkedIn is an excellent social media site to collect business emails for a phishing attack. A large enterprise could have several networked employees who list their employer and their titles. An attacker can use this public information to find several employees who have access to financial information, private customer data or high-privilege network access.\nCollecting information to steal data isn’t the only reason to use social media for reconnaissance. The information posted on social media could be used to obtain passwords or impersonate business users. Many online accounts allow users to reset passwords if they enter a security question. With enough information from social media posts, an attacker could guess the answer to these security questions based on the private information posted by a targeted user.\nBrand impersonation is another social media threat. With enough gathered information, an attacker can impersonate a business brand to trick users into sending money, divulging private information or provide an attacker with account credentials. Attackers also use this threat to perform cross-site scripting (XSS) or cross-site request forgery (CSRF) attacks. These attacks can lead to more massive data breaches and business infrastructure compromise.\nExamples of Social Media Threats and What They Look Like\nBecause many social media platforms publicly display user posts, attackers can silently collect data without a user’s knowledge. Some attackers will take further steps into gaining access to user information by contacting targeted users or their friends.\nThe way a social media threat is carried out by an attacker depends on their goals.\nIf an attacker is looking for a high-stakes reward, the best way to quickly earn monetary rewards for their efforts is to target businesses. An attacker might first review LinkedIn for a list of possible targets. Targets can be a mix of high-level corporate employees and low-privilege users who could be tricked into sending additional corporate data or fall for a phishing attack that gives the attacker access to account credentials.\nWith a list of targets, an attacker could then review social media accounts for personal information. Personal information can help the attacker gain the target’s trust in a social engineering attack. It can also be used to guess answers to security questions for an account takeover or used to get closer to a user with higher privileges. The names of pets, favourite sports teams and education history are all potential password clues or answers to questions used to verify the user’s identity to reset a password.\nAfter the attacker collects all the data needed, the next step is to launch the attack. An attacker can use any of the following methods:\n- Social engineering. An attacker might call employees to trick them into sending private data, proving credentials or wiring the attacker money. In a complex attack, the attacker can pretend to be a high-level executive to trick the targeted user into transferring money to the attacker’s account.\n- Phishing. An attacker may use collected social media information to spoof the sender of an email message and trick users into clicking links or sending the attacker private data. A high-level employee’s spoofed email address could send a message instructing the recipient to send money, click a malicious link or reply with sensitive data.\n- Brand impersonation. Using brand employee names, the attacker can trick customers into thinking requests are from the legitimate brand. This type of brand fraud could be used to trick users into divulging personal information or account credentials.\n- Site compromise and data theft. With enough information from social media, an attacker could write malware explicitly targeting the business or perform an attack that would provide internal network access where the attacker can then exfiltrate data.\n- Spread malware. Like brand impersonation, an attacker could create domains and websites that claim to be the legitimate business and trick users into downloading malware or providing credentials.\n- Data breach. If an attacker gains access to account credentials, it could lead to a significant data breach targeting an organisation.\nBecause there are several social media platforms on the internet, an attacker can perform social engineering and phishing using a variety of threat methods. There is no “one size fits all” social media threat for an attacker. But basic reconnaissance and research using social media are the same. Any public information on private and business social media accounts could be used in further attacks.\nWays to Prevent Social Media Threats\nMost social media security threats stem from employees disclosing too much private and business information publicly. These accounts are personal, so businesses can’t stop users from having a social media presence. But they can educate users on the best ways to protect data and their credentials.\nEducation is key to stopping social media security threats. Individuals can educate themselves. But businesses must conduct training programs for every employee so that they can detect and prevent social engineering and phishing. The first step is educating users on the dangers of disclosing too much information online to the public. Even social media accounts set to private could be used in an attack should the attacker gain access to private feeds. Users should never post private corporate information on their social media accounts or information that could be used in an account takeover.\nSome organisations hand out mobile devices and allow users to install social media apps. These companies should provide an acceptable usage policy that determines what users can post using company devices. It’s also critical to protect these devices from malware to avoid company social media accounts from being hacked. Remote wiping software should be installed should an employee physically lose their device or it gets stolen.\nSome other educational points for employees include:\n- Use ad blockers on corporate devices. If ad blockers are not feasible, instruct employees to avoid clicking ads, especially on popups that instruct users to download software to view content.\n- Employees should not share passwords—even if it’s within the same department.\n- Attackers use fear and urgency in their engagements, and employees should recognise this tactic as suspicious. Any messages or social media posts that urge employees to act quickly should be ignored.\n- Don’t accept friend requests from unknown people even if the user has several friends in common.\n- Avoid using social media sites on public Wi-Fi hotspots. Public Wi-Fi is a common location for attackers to snoop on data using man-in-the-middle (MitM) attacks.\n- User account passwords should change regularly. But users should also be encouraged to change their own private social media account passwords.\nIT staff should have social media cybersecurity defences in place to help users avoid being victims of an attack. Email servers can use artificial intelligence applications to catch suspicious emails with malicious attachments and links.\nSuspicious messages can be quarantined and reviewed by administrators to determine if the organisation is the target of an attack. Browser isolation is also an option for organisations that let users browse the internet. This technology allows users to freely browse the internet, but confines personal web activity to a protected container that prevents downloads, uploads and form fills to keep threats out of the environment."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:09e9a4cc-0d97-457d-99e0-ccb1a5cede88>","<urn:uuid:a9a72fed-011a-491c-8fdd-818b9d95a65f>"],"error":null}
{"question":"What is heavier to move - a classic upright piano or a Phonoliszt-Violina instrument?","answer":"A Phonoliszt-Violina is significantly heavier, weighing approximately 1000 lbs (453.592kg), while a classic upright piano weighs around 500 lbs (226.7kg) or slightly more depending on the specific model. The Phonoliszt-Violina's greater weight is due to its complex mechanism combining three violins with a piano, making it one of the largest automatic musical instruments.","context":["NOW: Complete Catalog of All Original Phonoliszt-Violina Rolls Click Here\nThe following article includes text excerpted from works by Q. David Bowers and Art Reblitz listed in the Bibliography.\nDuring the period 1895 to 1935 music was spread geographically through the use of automatic music players controlled mainly with pneumatics. Air pressure and vacuum conducted through a maze of tubing allowed for astonishingly responsive actions needed to actuate a piano action (as with player pianos), organ pipes (imitating string and wind instruments), percussion (drums, xylophone, triangle, etc.) and eventually the most difficult of all – plucking a banjo and bowing real violins. Control was from a punched paper roll that traveled over a metal “tracker bar” that enabled sensing the holes in the roll as they passed over the holes in the tracker bar.\nAutomatic music machines were important to the music scene not only for their technological cleverness and eye-catching appeal, but they did a good enough job musically to enable the spread of a popular or classical tune as a standard, as opposed to individual performances by musical troupes. They also enabled an economic means for many more establishments to have on-site music – restaurants, bars and even houses of ill-repute.\nIn the late 1920s with the advent of electrical devices and sound amplification, the jukebox and radio took over and these machines, quite large physically, were destroyed, with small numbers surviving. Automatic musical instrument makers used organ pipes voiced to sound like a violin for their basic sound or solo voice in many different instruments. The best violin pipes sounded very realistic, but only a few people were inspired to create mechanism to play a real violin automatically with expression. This ultimate music machine would not only sound realistic, but would also have outstanding visual appeal.\nHupfeld, the world’s largest maker of automatic musical instruments in its day, began working on a mechanical violin player around 1900. By 1908, Hupfeld marketed the Phonoliszt-Violina, an instrument combining three real violins with a Phonoliszt expression piano.\n“Phonoliszt” means “Sounds of Liszt.” Franz Liszt (1811-1886) was born in Hungary and became known as the world’s greatest pianist. He lived in Germany for years. His daughter, Cosima, married the renowned German composer Richard Wagner, further endearing people to Liszt’s music\nThe Phonoliszt-Violina is perhaps the ultimate automatic music collectible today due to its rarity, its realistic performance with expression on the piano and the violins and its solo capabilities combined with its visual impact. Its New York City distributor described the Phonoliszt-Violina: “The self-playing Violina is provided with real violins operated by a bow and made of 1344 horse-hairs means the solution of a problem that has been vainly sought for centuries.”\nIn April, 1912 in a testimonial by noted violinist Efram Zimbalist: “Certainly the Phonoliszt-Violina is the eighth wonder and marvel of our time.”\nAbove and below: Various 1912 “The Music Trade Review” articles\nA boost was further given to the machine’s sales when the musicians union went on strike. Technology to the rescue! (note that the “Phonoliszt-Violina Orchestra” mentioned in the article below is just a nickname used by the publication for the Phonoliszt-Violina. They’re not referring to the later Violina Orchestra with drums, ranks of pipes, etc., introduced in the late 1920s.)\nHow the Phonoliszt-Violina Imitates a Human Violinist\nA human violinist plays different notes by pressing the string against the violin fret-board to change its speaking length. Hupfeld’s mechanism has steel fingers with wood finger tips covered with thin rubber or leather pads, to simulate the texture of human fingers.\nA real violin bow uses horsehair to play the strings. Hupfeld’s bow took the form of a large ring holding 1,344 strands of horsehair, tied around little steel pins. To simplify the complex problems of bowing, Hupfeld stood each violin upside down inside the circular bow. Only one of the four strings on each violin plays automatically. One, two or all three violins can play at once to provide solos, duets and occasionally, trios.\nTo keep the horsehair of an ordinary violin bow at the correct tension, a violinist tightens or loosens it with a threaded adjustment. When the violin is in storage, the violinist lowers the tension so it will not deform the shape of the wooden bow. The Hupfeld bow is metal, so there is no need to let down the tension between the performances. A clever spring-loaded mechanism keeps the horsehair tension the same regardless of humidity changes.\nFor good tone quality, a violinist occasionally applies rosin to the bow. In the Phonoliszt-Violina, the owner of the instrument applies rosin as needed by pushing a button. This causes a pneumatic to press a rosin cake against the bow. All violins go out of tune when the strings stretch and the humidity or temperature changes. The Phonoliszt-Violina has three tuning buttons. Each button plays one violin string and its corresponding piano note.\nHupfeld’s music roll editors understood how to arrange the expression control perforations in the rolls for human-like performance with realistic phrasing. The Phonoliszt-Violina is quite impressive when it plays a delicate pianissimo passage of staccato notes, or a quickly sweeping chromatic glissando. It is truly amazing when it plays an intricate phrase with accented notes superimposed on a slow, dramatic crescendo.\nThe roll library includes the usual high quality Hupfeld repertoire, from Handel, Mozart, and Beethoven to salon music, opera, and operetta selections. Hupfeld made popular music rolls for the Phonoliszt Violina as late as the sound-movie era of the early 1930’s.\nIt is not clear from available historical accounts whether the music was arranged by real musicians playing a device that marks a master roll from a recording instrument such as a piano keyboard or whether it’s musically competent professionals actually marking a master roll on a drafting table. If the latter, the process would take a musician who really understood the mechanism as there is much complication to the multiplexing of hole positions to get all the expression and other controls out of the tracker bar layout.\nThe article shown, if accurate, would seem to support the first theory that “the records are made from the actual playing of a piano and violins by skilled musicians.”\nCirca 1912-14 catalogue illustration of Phonoliszt-Violina Model A\nCrandall Model A machine made circa 1916\nHow Does the Phonoliszt-Violina Sound Realistic?\nEach violin has a pneumatic that presses it against the bow. Control perforations in the roll vary the speed of the bow. When the bow turns faster, an adjustable cam mechanism also increases the pressure of the violin string against the bow. Three speed/pressure combinations produce soft, medium and loud play. Three rates of speed/pressure change provide faster or slower crescendos/decrescendos. The mechanism provides two types of accent: Heranbringer stark, causing the violin to move more quickly, and Betoner, which increases the bow speed and pressure. The music rolls use them separately and together for various accenting effects.\nThe vibrato mechanism creates a pleasing wavering in the pitch of the note being played. A human violinist accomplishes this effect by rocking his hand slightly against the string. In contrast, the Phonoliszt-Violina has a mechanism that pulls slightly on the end of each active violin string producing the same effect. A single hole in the roll activates the mechanism, producing one pulse of vibrato. With different hole spacing, the vibrato can be faster or slower, as needed for the music.\nFor an ethereal sound, a violinist attaches a mute to the bridge, damping the tone and loudness. In the Phonoliszt-Violina, a lever touches the bridge in a similar way when the music calls for a mute.\nThe piano expression is a simple but effective mechanism. A suction regulator provides three levels of loudness with gradual or sudden changes from one level to another. The piano hammer-rail is divided into bass and treble, with control of the bass half that allows treble piano solos.\nA Hupfeld Model A Phonoliszt-Violina – Interior\nPhonoliszt-Violina Model A Stack # 3,500\n7’6” x 5’ x 2’11” Wt. 1000 lbs.\nRick Crandall Collection\nRestored by; Reblitz Restorations Colorado Springs, CO\nRestorer Art Reblitz: “I had the violins repaired and polished by Eggen Violins in Denver who conserved the original finish. We cleaned and prepared all metal parts in my shop as we usually do instead of sending them to a plating shop for buffing, since the commercial buffing process often rounds off all the edges. I had them re-plated with electroless nickel, a little less shiny and consequently more original-looking than the typical modern plating job.\nWe installed a new pin-block, Renner hammers, and Renner action parts in the piano as necessary. The high-quality piano was made by Schimmel. There’s no marking on the piano plate, but the stack had the wording “Schimmel-Violina” written in pencil. The mechanical features are early, but not extremely early. It has the conventional spring-loaded tensioners for the bow hair, while the very early ones have manually-adjustable tighteners. The machine was restored from top to bottom, inside and out”\nClose-Up of the Actual Playing Violins and Fingering Assemblies\nThe “D” violin is on the left; the “A” violin at center; and the “E” violin at right. In the Phonoliszt-Violina the violins pivot forward into the circular bow (close up below). The complicated-looking mechanism with many black tubes leading away from it is the fingering mechanism, each finger controlled by a pneumatic taking instruction from the perforated roll. Note the visible lower portion of the circular horsehair bowing mechanism, which crosses each violin near its center.\nReblitz: I used a bow re-hairing jig that a fine local machinist made for me. It counts pins from end to end of each hair, and ensures that each hair is at precisely the correct height on its pins. It takes me between five and six days to re-hair a bow.\nPhonoliszt-Violina on Location\nThe Phonoliszt-Violina was ideal for restaurants, lounges, lobbies and other places where people congregated to relax. The music was rich but not overly loud and music was available for a broad range of tastes from classical to popular. Approximately 940 music rolls were created by Hupfeld over the years from approximately 1910 to 1932.\nA Brief Look at the History of Hupfeld\nHupfeld grew to become the world’s largest distributor and manufacturer of “self-playing” automatic musical instruments, eventually producing a wide variety of disc, pinned-barrel and music-roll operated music machines in its own factories. Some of the automated orchestras crafted were spectacularly large and very complex devices. While other contemporary large and well known manufacturers of “automatics” could boast an employee count well into the hundreds, Hupfeld, in sharp contrast, had a contingent of employees numbering in the thousands.\nSometime around 1880 to 1882 J.M. Grob, along with two partners, founded J.M. Grob & Company, opening a small “art shop” in Leipzig-Eutritzsch, Germany. The new company sold various mechanical musical instruments, such as disc music boxes and small hand-cranked organettes, but soon began manufacturing its own stable of mechanical instruments, which were marketed in the company’s shop alongside products from other companies. By 1886 an attachment for automatically playing pianos and organs, using paper tune-sheets, had been perfected. The ingenious Grob player action was licensed to other manufacturers for incorporation into their own products.\nIn time Grob & Company acquired the distributorship of many prominent musical instrument manufacturers in the Leipzig area, making Grob a well-known entity for both sales and mechanical music innovation. Then, in 1892, Ludwig Hupfeld took over the company, changing the name to Hupfeld Musikwerke.\nTo keep up with the demand for automatic music, the giant 1,000,000 sq. ft. Böhlitz-Ehrenberg factory was built in 1911, with its imposing tower (depicted in the logo above). By 1912 some 1200 employees manned the sparkling new factory, a number that climbed to over 2000 a few years later.\nBy 1925 automatic instrument sales had slumped to a mere trickle, the complicated and often temperamental music machines being replaced by the phonograph and the radio. In 1926, Hupfeld merged with Gebr. Zimmermann, a piano manufacturer.\nProduction of pneumatic automatic musical instruments stopped altogether about 1930. Music roll production ceased about 1934. After the war, what remained of the once huge factory reverted to music-related manufacturing. But this time it made ordinary pianos, continuing to this present day, under the new name of VEB Deutsche Piano Union. After the war any remaining traces of the glorious days of automatic instrument making were destroyed and forever erased from what remained of Hupfeld.\nAlthough a small number of Hupfeld instruments were distributed in the U. S. by Ernst Böcker of New York City, for instance, few of these machines exist today.\nReblitz, Art, The Golden Age of Automatic Music Instruments, Woodsville, NH, Mechanical\nMusic Press, 2001\nOrder from: www.mechanicalmusicpress.com/reblitz\nBowers, Q. David, The Violin Playing Machines: Hupfeld Phonoliszt-Violina, Mills Violano-Virtuoso,\nA Study and Appreciation, Automatic Musical Instrument Collectors’\nAssociation (AMICA), 2012\nOrder from: www.amica.org/Live/Misc/Sales/Books/Violin-Playing/index.htm\nCrandall, Rick, Phonoliszt-Violina Rollography, Aspen, CO, Self-published, 2012\nEntire list of all rolls originally produced by Hupfeld for the Phonoliszt-Violina shown in two formats, one sorted by roll number and the other sorted by composer.\nAccessible at: http://www.rickcrandall.net/pv-rollography/","We Specialise in Piano Removals\nHow many of moving piano engineers will I need to move my piano?The solution is dependent upon both the piano and the folks involved. Professional piano movers are going to have the ability to do more with fewer people and they will know just what is necessary to safely transfer any piano, from the tiniest spinet into the greatest concert grand. Be warned: Many ordinary moving businesses don't have the experience in regards to moving pianos, particularly the bigger horizontal pianos that demands an expert. There's a large difference between a typical moving along with also a moving piano expert. There are several distinct kinds of pianos. The initial step towards successfully moving your piano is to learn which kind it's, how thick it is, and the number of movers will probably be required. The smallest vertical piano may weigh significantly less than 300lbs (21.4 stone/136.078kg) in which a massive concert grand may be greater than 1000lbs (71.4286 stone/453.592kg).\nUpright pianos are divided into four different types.\nSpinets would be the smallest, at approximately 3′ (91.4cm) tall and 4'10\" (147.32cm) long. They consider 200-300lbs (14.2 stone - 21.4 stone) (90.71kg- 136.07kg) and can normally be transferred from room to room by 2 powerful men and women.\nConsole pianos are a bit taller. They vary from 3'4″ to 3'7″ (101.6cm to 109.2cm) in height and do not weigh much over a spinet. Two individuals are usually able to take care of a console providing there are not any stairs or challenging challenges. When there's a flight of stairs, then all pianos will require a minimum of one additional moving engineer.\nStudio pianos are larger. They are roughly the same length, from 3'9″ to 4′ (114.3cm to 121.9cm) in height, and may weigh up to 400lbs (28.57 stone) (181.4kg). They are widely utilized in audio colleges since they are thought of as the best compromise between tone and size. A minimum of 3 individuals will be necessary to move a piano of the dimension.\nClassic uprights will be the biggest of the vertical family. They could weigh 500lb (35.7 stone) (226.7kg) or more based on the specific selection and it'll require four people or more to maneuver you.\nHorizontal (grand) pianos are such a challenging shape they generally have to be disassembled before moving and specialists with expert piano moving gear are unquestionably required. The tiniest petite grand will require at least three or four movers.\nBaby grand is another step up flat pianos. They could be around 5'7″ (170.1cm) in length and weigh 500lb (35.7 stone) (226.7kg) or more. It'll take three or even four individuals to maneuver one once the pliers and legs are eliminated.\nParlour grand pianos are a bit larger but can normally be transferred by a team of exactly the identical size.\nSemi-concert (ballroom) pianos are approximately 7′ in dimension and it will take four or five powerful movers to manage one safely. The greatest of the concert grand is a complete 2′ more and much heavier. It may take anything up to half a dozen individuals to proceed a full-sized concert grand and fantastic care ought to be obtained - a nice example might be worth £30,000 or more.\nEven if your piano is a modest flat, it is always best to acquire expert piano movers to deal with the move. They will have the ability to assist with disassembly and reassembly and they will have all the equipment needed to deal with big and valuable tools. Any piano is a challenging point to move and every one is something of beauty. As any music enthusiast will say they deserve careful therapy."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:aa99786f-e94a-40a5-a1c5-cfbd034cfeb7>","<urn:uuid:47373432-ceb1-42ca-9b84-9e4b230d6791>"],"error":null}
{"question":"What makes eggs good for babies nutrition, and how can you tell if your child has egg intolerance vs allergy?","answer":"Eggs are nutritionally excellent for babies as they contain high-quality protein, good fats, vitamins and minerals. The white contains protein while the yolk provides fat, some protein, and most vitamins and minerals - making them a complete nutritional package. Regarding intolerance versus allergy, a food allergy is caused by an immune reaction that can trigger severe reactions like hives, breathing problems, or anaphylaxis. In contrast, food intolerance is different and often has unknown causes, potentially resulting in symptoms like bloating, diarrhea, gas or rashes. A qualified allergist or immunologist should be consulted to determine whether a reaction is an allergy or intolerance.","context":["When Can I Give My Baby Eggs?\nThe early years of a child’s life are a time of rapid growth and development. For the first six months of their life, breast milk or infant formula supply all the nutrition a baby needs. However from six months of age, foods need to be introduced to complement milk. After the first year, healthy food becomes an important part of a child’s world as milk intake is reduced and more foods are eaten.\nInfants and toddlers should be given and encouraged to eat a wide variety of foods to make sure they get the necessary vitamins and minerals to complement the rapid growth occurring in their bodies. A variety of foods also exposes toddlers to different textures and flavours.\nPlunket recommends including mashed egg in a babies diet from the age of 7-8 months.\nMashed egg is not only an easy food for a young child to eat and digest but eggs are also the base of many healthy well balanced meals. Eggs are very nutritious as they contain a range of nutrients including high quality protein, good fats, vitamins and minerals. It is important to include both the yolk and white in a child’s diet as they provide different nutrients. Egg white contains only protein. Egg yolk contains all the fat, some protein and most of the vitamins and minerals.\nProtein is made up of 20 amino acids and the quality of the protein is determined by the balance of the amino acids present. The protein in egg is called high quality or ‘complete protein’ because it contains all the essential amino acids needed for growth, development and health. Essential amino acids are those that cannot be made by the body and therefore need to be sourced from foods we eat. For their weight eggs provide the highest quality protein of all foods.\nFat is an important nutrient but like many things it is all about balance – not too much and not too little. Eggs are incorrectly thought to be high in fat but in reality a large egg contains only about 5 grams of fat and less than half that is saturated fat. The fat in eggs supplies energy and fat-soluble vitamins, both important for growth.\nImportant: The first time you introduce your baby to any new foods be sure to watch for signs of allergic reactions including hives, difficulty breathing or asthma type symptoms, swelling of the mouth or throat, vomiting, diarrhea and even loss of consciousness. If this occurs seek immediate help and call emergency services to assist.\nCan children eat eggs everyday?\nEggs are an ideal food for inclusion in children’s diets as they are naturally nutritious and provide useful amounts of folate, vitamin A, iron, zinc, iodine and omega-3s in particular. Eggs also provide a very good source of protein for children to support their growth.\nEggs are so versatile and there are many nutritious recipes that kids will love, and they have a very useful role in the diets of children who may be fussy eaters who may refuse to eat other foods.\nDue to their high quality protein and 11 vitamins and minerals, eggs are a great choice for kids and can be enjoyed by most people every day.","If you’re concerned about your baby developing a food sensitivity or allergy, here’s what you need to know.\nYour child’s risk of developing a food allergy\nApproximately six to eight percent of children age two to three years are allergic to one or more foods. The odds of developing food sensitivities increase if a child has a family history of what doctors call “atopic disease”—hay fever, eczema or asthma. Children with one allergic parent run about a 30 percent risk of developing some sort of allergy, including food allergies. Two allergic parents doubles a child’s risk.\nWhat’s the difference between “food allergies” and “food intolerance”?\nIf your child has problems with or is sensitive to certain foods, they are likely allergic or intolerant to them. But “food allergies” and “food intolerance” are not the same thing. A food allergy is caused by an immune reaction. And while some allergies are mild, certain foods may trigger a severe reaction. These foods include peanuts, tree nuts, fish, shellfish, and, in some cases, milk and eggs. A food intolerance is different, and in many cases, the reason for the intolerance is unknown.\nSee your family doctor if your child has lost weight or has bloody or mucousy stools. If your child has had a reaction to a specific food, he or she should be referred to a qualified allergist or immunologist. The specialist will investigate and determine whether the reaction is a food allergy or intolerance, and suggest ways to modify risk factors and develop a management plan.\nIs prevention possible?\nMany experts believe that delaying the introduction of certain foods until a baby’s immune system is more mature may fend off some food allergies. Consequently, most physicians recommend breastfeeding exclusively for six months and switching to formula if you wean before a year. In some instances, your child may have bloating, diarrhea, gas or a rash after eating a particular food. Alternatively, your child may lack an enzyme such as lactase, and will react to a food that contains lactose, such as milk. In this case your doctor may recommend lactose-free milk or lactase tablets.\nEven if neither you nor your partner have a history of allergy, most health professionals now advise waiting to introduce the foods most apt to cause allergies.\n• Milk, soy and egg whites: Wait until baby is 12 months of age\n• Shellfish, peanuts (including peanut butter), tree nuts and seeds: Wait until your child is three years old\nHow do I know if my child is having allergic reaction?\nIf your child has a food allergy, he or she may show the following reactions:\n* Hives, itching or eczema\n* Tingling and swelling of the lips, tongue, back of throat, and other body parts\n* Breathing problems, such as wheezing or coughing\n* Itching or discharge from the nose\n* Stomach cramps, nausea, vomiting or diarrhea\nSome children may have a life-threatening reaction called anaphylaxis. An anaphylactic reaction involves difficulty breathing, or may cause a sudden drop in blood pressure and may lead to unconsciousness or death. Since the first sign of anaphylaxis can be mild and resemble any of the above signs, emergency treatment is critical.\nIf allergies run in your family, consult your doctor for individual recommendations."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:df0f0425-6011-4b9e-92fb-481ea042405c>","<urn:uuid:97623d09-d12a-4aa6-a8f3-d6ae342680bf>"],"error":null}
{"question":"What's the key difference in preventing food poisoning versus stomach flu?","answer":"Food poisoning prevention primarily focuses on food handling practices like cooking food thoroughly, cleaning thoroughly, proper food storage, and separating raw and cooked foods. In contrast, preventing viral gastroenteritis (stomach flu) emphasizes personal hygiene measures like hand washing before eating and after using the washroom, closing toilet lids before flushing, and vaccination - specifically the rotavirus vaccine for children under two years old, which can reduce hospitalization risk by up to 86 percent.","context":["What is food poisoning and what causes it? Food poisoning is when you get sick after you eat contaminated food. Bacteria, such as listeria, salmonella, or E coli, may cause food poisoning. Viruses, such as rotavirus, and parasites, such as giardia, may also cause food poisoning. The exact cause of your food poisoning may not be known. Food poisoning most commonly happens when you eat raw or undercooked food. Meat, seafood, produce, and dairy products are common foods that can become contaminated.\nWhat increases my risk for food poisoning?\nAge: Babies, young children, and older adults are more likely to get food poisoning.\nA weak immune system: Medical conditions such as diabetes, cancer, or kidney problems may weaken your immune system. This means your body may not be able to fight off the germs that cause food poisoning.\nWhat are the signs and symptoms of food poisoning? You may have any of the following:\n- Abdominal cramps or pain\n- Nausea and vomiting\n- Fatigue or weakness\nHow is food poisoning diagnosed? Your caregiver will ask you to describe your symptoms and list the foods you have eaten recently. He will ask when you last ate, and where you were. He will want to know if anyone who ate with you is also sick. Your caregiver will examine your abdomen and check for signs of dehydration. Dehydration can happen if you have diarrhea or are vomiting. You may also need the following:\nVomit or stool tests: Caregivers may test your vomit or bowel movement for the toxin that causes botulism.\nBlood tests: You may need blood taken to give caregivers information about how your body is working. The blood may be taken from your hand, arm, or IV.\nHow is food poisoning treated? The following can help ease your symptoms:\nOral rehydration solution (ORS): You will need to drink fluids or an ORS to prevent dehydration. An ORS contains a balance of water, salt, and sugar to replace body fluids lost during vomiting and diarrhea. Ask what kind of ORS to use, how much to drink, and where to get it.\nBland foods: After you can keep an ORS down for 3 or 4 hours, eat something bland. Examples of bland foods are soup or broth with crackers. Follow a BRATT diet until you feel better. BRATT stands for bananas, rice, applesauce, toast, and tea. Avoid sugary drinks, caffeine, and alcohol because they may worsen your symptoms. Breastfeed as usual if you are a nursing mother. Do this to prevent your baby from becoming dehydrated.\nDiarrhea medicine: This is given to slow or stop your diarrhea.\nVomiting medicine: This is given to calm your stomach and stop your vomiting.\nAntibiotics: This medicine may be given if caregivers believe your food poisoning is caused by bacteria. Take your antibiotics until they are gone, even if you start to feel better sooner.\nWhat are the risks of food poisoning? Diarrhea or vomiting can make you dehydrated. Dehydration can be very serious for children, older adults, and anyone with a weak immune system. Watch a young child closely because he can become dehydrated quickly. Ask your caregiver for more information about the risks of food poisoning.\nHow can food poisoning be prevented? Follow these rules at home to prevent food poisoning:\nCook food all the way through: Cook eggs until the yolks are firm. Use a meat thermometer to make sure meat is heated to a temperature that will kill bacteria. Do not eat raw or undercooked poultry, seafood, or meat.\nClean thoroughly: Wash your hands in warm, soapy water for 20 seconds before and after you handle food. Wash your hands after you use the bathroom, change a diaper, or touch an animal. Rinse fruits and vegetables in running water. Clean cutting boards, knives, countertops, and other areas where you prepare food before and after you cook. Wash sponges and dishtowels weekly in hot water.\nStore food properly: Refrigerate or freeze fruits and vegetables, cooked foods, and leftovers right away. Keep your refrigerator at 40 degrees F or lower and your freezer at 0 degrees F.\nSeparate raw and cooked foods: Keep raw meat and its juices away from other foods to prevent the spread of bacteria. Always put cooked food on a clean platter. Never use a platter that held raw meat.\nWhen should I follow up with my caregiver? Your symptoms should go away in 2 to 5 days. Follow up with your caregiver if your symptoms are not going away after 2 days of treatment.\nWhen should I contact my caregiver? Contact your caregiver if:\n- You are very thirsty and your mouth and tongue are dry.\n- Your diarrhea has lasted more than 3 days.\n- You have bloody diarrhea.\n- You have diarrhea and a fever higher than 101.5°F.\nWhen should I seek immediate help? Seek care immediately if your vomiting, diarrhea, and abdominal pain continue and you develop the following new symptoms:\n- You are vomiting so often that you cannot keep any liquid down.\n- You have a fever and pale skin, and you feel irritated and tired.\n- You are very drowsy or cannot stay awake.\n- Your eyes are sunken and so dry you have no tears.\n- Your arms and legs feel colder than normal, or they look blue.\n- You urinate small amounts or not at all.\n- You feel dizzy or confused.\n- You have severe pain in your abdomen.\nYou have the right to help plan your care. Learn about your health condition and how it may be treated. Discuss treatment options with your caregivers to decide what care you want to receive. You always have the right to refuse treatment. The above information is an educational aid only. It is not intended as medical advice for individual conditions or treatments. Talk to your doctor, nurse or pharmacist before following any medical regimen to see if it is safe and effective for you.\n© 2015 Truven Health Analytics Inc. Information is for End User's use only and may not be sold, redistributed or otherwise used for commercial purposes. All illustrations and images included in CareNotes® are the copyrighted property of A.D.A.M., Inc. or Truven Health Analytics.","What is Gastroenteritis?\nNausea, cramps, stomach aches, and diarrhea — these are the uncomfortable signs of gastroenteritis, which is often called the stomach flu. Despite the moniker, the viruses that cause gastroenteritis are distinct from those that cause the flu. This means getting your flu shot won’t prevent you from catching this infection.\nWhat is viral gastroenteritis?\nViral gastroenteritis damages the gut, causes inflammation, and makes it harder for the body to absorb water leading to vomiting and or diarrhea and dehydration. Due to their weakened immune system, the stomach flu can lead to complications in children and the elderly. In developing countries, viral gastroenteritis leads to more than 200,000 deaths of children per year.\nFortunately, the stomach flu doesn’t last long and in most cases, is treatable at home. The infection typically lasts one to three days and treatment involves hydration and over-the-counter medicines that target the other symptoms.\nWhat causes gastroenteritis?\nGastroenteritis can be caused by bacteria, viruses, or parasites. Viral gastroenteritis, normally called the stomach flu, is mostly caused by viruses like norovirus or rotavirus. Viruses are microscopic machines that hijack our body’s cells to make more copies of themselves. The damage that they cause along the way, as well as the body’s immune response lead to the symptoms of this condition.\nCan you prevent gastroenteritis?\nOne of the main ways that the stomach flu passes between individuals is through the oral-fecal route, or by touch rather than airborne spread[2,3]. This means that viral particles shed in the stool make their way back into the gastrointestinal tract. Good hand hygiene, including washing hands before eating and after using a washroom, and making sure to close the lid on the toilet before flushing will help reduce the spread of the virus[2,3].\nIn addition, these viruses can stick to surfaces, food, and water. Making sure to wash your hands before preparing any food, cleaning fruits and vegetables, and ensuring meats are completely cooked before consumption can help stop the spread of stomach flu[2,3].\nOne of the most effective ways to prevent one type of viral gastroenteritis in children is rotavirus vaccination. Since 2006, several safe and effective vaccines against rotavirus infection have been developed for use in children under two years old. They reduce the risk of hospitalization with diarrhea up to 86 percent. Note that this vaccine does not protect against other viruses, such as norovirus. Speak with a pediatrician to learn about what options are available for your child.\nSymptoms of gastroenteritis\nBoth the rota and noro viruses causes similar symptoms which last several days, including:\n- Vomiting. When it encounters something infectious or damaging, the gut responds by attempting to expel it through vomiting.\n- Diarrhea and dehydration. The rotavirus damages gut cells that would normally absorb water and other electrolytes, leading to diarrhea.\n- Abdominal cramps. Dehydration, damage to the gut and electrolyte imbalances could cause cramping.\n- Low appetite. This could be caused by the body’s general “sickness response”, which fires up the immune system but dampers appetite.\n- Fever. This is the body raising the temperature to help the immune system fight off the virus.\nRotavirus or norovirus?\nRotavirus is the most common cause of gastroenteritis in children. The first symptom of this form of the stomach flu is vomiting. Children remain symptomatic for about three days but will continue shedding virus in their stool for up to 10 days, meaning that adults could catch it without careful hand hygiene. However, many people develop immunity to rotavirus infection early in life, so it is usually asymptomatic in adults.\nNorovirus is the most common cause in adults, but also occurs in children. For norovirus infection, vomiting usually follows abdominal cramps and diarrhea. The norovirus also usually resolves itself within 72 hours or three days.\nThe goal of treating viral gastroenteritis is to rehydrate the body and medicate away any other bothersome symptoms. Treatment includes:\n- Drinking fluids to prevent dehydration. Drinking water, teas, and warm soups can compensate for the fluid loss caused by diarrhea. Sports drinks can help replenish the electrolytes that are lost as well.\n- Medications to prevent vomiting. Over the counter medications like Pepto Bismol or generic formulations with the same active ingredient bismuth subsalicylate can help reduce vomiting.\n- Probiotics and prebiotics to treat diarrhea. Probiotics are beneficial microbes that keep the commensal microbes living in the gut healthy. Prebiotics are foods that feed these microbes. Probiotics and prebiotics could reduce the frequency of diarrhea, especially if taken prior to getting sick.\n- Rest. Sleeping and resting helps the body focus on fighting off the infection faster.\nWhat to eat while you’re sick and recovering\nSimple and easy to digest carbohydrate based foods, such as bananas, rice, apples, and toast are common dietary recommendations for dealing with bouts of diarrhea. However, studies so far haven’t shown that this diet is actually better for recovery. If foods can’t be tolerated, ensure that fluids consumed include some carbohydrates and electrolytes.\nFor recovery, it is recommended that you eat as normally as possible, starting with small amounts of food. Avoid highly processed, very spicy, or fried foods while recovering. Some people experience milk lactose intolerance immediately after gastroenteritis and have to limit dairy products for a short period of time.\nWhen should you see a doctor?\n- Difficulty hydrating or retaining fluids orally. In this case, saline or other intravenous fluids are needed to rehydrate. During the hospital admission, staff will carefully monitor your hydration and electrolyte levels. This can also occur as a result of prolonged bouts of diarrhea.\n- Fever higher than 39 degrees. High fevers can be dangerous, especially for children, and can cause further dehydration.\n- Uncontrollable vomiting. If you or your child are unable to get vomiting under control, it may be necessary to receive stronger prescription medication. In some cases, it also requires hospital admission.\n- Other conditions or comorbidities. Metabolic conditions such as diabetes, as well as pregnancy, and many other medical conditions could put you at extra risk.\nViral gastroenteritis — more commonly known as the stomach flu — causes nausea, cramps, vomiting, and diarrhea. Improving hand hygiene, food handling practices, and vaccination can reduce the risk of catching the stomach flu. Most cases are treatable at home through hydration and over-the-counter medications.\n- Stuempfig, N.D., Seroy, J. Viral gastroenteritis. (2022). StatPearls. Treasure Island (FL): StatPearls Publishing.\n- Guix, S., Pintó, R. M., & Bosch, A. (2019). Final consumer options to control and prevent foodborne norovirus infections. Viruses, 11(4), 333.\n- Mattison, C. P., Dunn, M., Wikswo, M. E., Kambhampati, A., Calderwood, L., Balachandran, N., … & Hall, A. J. (2021). Non-norovirus viral gastroenteritis outbreaks reported to the national outbreak reporting system, USA, 2009–2018. Emerging Infectious Diseases, 27(2), 560.\n- Burnett, E., Parashar, U. D., & Tate, J. E. (2020). Real-world effectiveness of rotavirus vaccines, 2006–19: a literature review and meta-analysis. The Lancet Global Health, 8(9), e1195-e1202.\n- Crawford, S. E., Ramani, S., Tate, J. E., Parashar, U. D., Svensson, L., Hagbom, M., Franco, M. A., Greenberg, H. B., O’Ryan, M., Kang, G., Desselberger, U., & Estes, M. K. (2017). Rotavirus infection. Nature reviews. Disease primers, 3, 17083.\n- Government du Quebec. Gastroenteritis (stomach flu).\n- Government du Quebec. Foods to eat when you have gastroenteritis."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:0a6a109f-f7e3-472c-b140-98c1efd6d9a1>","<urn:uuid:41f268a5-d931-4e51-b769-18b42139606d>"],"error":null}
{"question":"Which famous typeface introduced by Christophe Plantin in the Southern Netherlands can still be found on modern computers?","answer":"Garamond, which was one of the elegant French typefaces Plantin introduced to the Southern Netherlands, can be found on every computer today.","context":["The new Plantin-Moretus Museum, a UNESCO World Heritage Site, opened today. The museum plans to draw visitors into the remarkable story of the pioneering publisher Christophe Plantin and the Moretus family into which he married. With cinematic interventions, soundscapes, and hands-on activities, the house, the publishing business and the family are brought to life more than ever before.\nParts from the press release, 29 September 2016\nA new phase commences today. On the renovated museum’s ground floor, visitors encounter the multifaceted Plantin as a family man, manager, businessman and top-quality printer.\nChristophe Plantin: the Netherlands’ leading publisher\nChristophe Plantin was originally from Saint-Avertin, near Tours in France. The sixteenth-century publisher settled in Antwerp around 1550 and ran his business like a modern CEO. His publishing house, the ‘Officina Plantiniana’, grew into a multinational with branches in Leiden and Paris. With the multilingual bible, the Biblia regia, he was able to convince King Philip II of Spain of the quality of his printing, and was given exclusive rights to export liturgical works to Central and South America. He became the founding father of the Plantin-Moretus publishing dynasty. ‘De Gulden Passer’, the family home and publishing business on Antwerp’s Vrijdagmarkt, remained in the family for nine generations.\nPlantin was a trendsetter when it came to design. He created a new market for books with refined engraved copperplate illustrations. The Frenchman introduced a variety of elegant French typefaces to the Southern Netherlands, such as Garamond. Today, this font can be found on every computer. With his childhood friend Peter Paul Rubens, Plantin’s grandson Balthasar developed the lay-out of the Baroque book.\nUpstairs, the focus is on the publishing house with which Plantin and his descendants put Antwerp on the map. The main achievements are divided into four themes: language, science, religion, and people and society. Leading authors and scientists found their way to Antwerp’s Vrijdagmarkt, and Plantin was able to spread their ideas throughout the world.\nThe exhibition layout puts ten major exhibits in the spotlight, real bestsellers that have left their mark on history, such as Ortelius’ maps or Stevin’s mathematical works.\nThe exhibition design is the work of Studio Caroline Voet and Leen De Brabandere, who have already demonstrated their abilities at Castle d’Ursel in Hingene. Voet-De Brabandere is an agency that is conscious of the need for sustainability and the value of a UNESCO site, and attaches great importance to the authenticity of the historic house. By involving designer Geoffrey Brusato, they have also managed to give a place to the rituals of handling a book in the museum visit. Digital media will be present, but will play a subordinate role: the book is central.\nTo increase visitors’ comfort, the museum has created more rest areas, improved reception areas, better workshop spaces and a more attractive museum shop with a wider range of products. The museum’s presence on Vrijdagmarkt will be even more prominent thanks to improved illumination and signage.\nDepot and reading room\nThe depot with the new reading room is the work of noAarchitecten. The building of the depot means that the collection can be packed up and stored away properly to be carefully preserved for future generations.\nUNESCO has welcomed this initiative by the city, which allows the collections to be preserved in a responsible manner on location. The organisation also appreciates the fact that the new building is a contemporary functionalist creation which interprets the essence of the traditional architecture without explicitly quoting it.\nThe collection will also be looked after better in the permanent exhibition. Paper is like textile: it cannot withstand lengthy exposure to light and temperature fluctuations."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:1d00fbb6-d7e1-489e-9a4a-cf923d7bdd91>"],"error":null}
{"question":"在引力波和宇宙微波背景辐射的研究中，科学家们如何处理信号校准的挑战？How do scientists address calibration challenges in gravitational wave and cosmic microwave background radiation studies?","answer":"In both cases, scientists developed specific techniques to ensure accurate measurements. For the CMB polarization measurements, researchers used polarized light from Milky Way dust as a calibration source, since this light hasn't traveled as far and is less likely to be affected by dark energy or dark matter. This allowed them to precisely determine their instrument orientation and confirm the rotation in the light was real. For LIGO's gravitational wave detection, scientists built two identical facilities in different locations (Washington State and Louisiana) and compared data between them to rule out local effects that might mimic gravitational wave signals, ensuring only genuine events seen by both detectors were considered valid.","context":["A twist in the universe’s first light could hint that scientists need to rethink physics.\nA pair of Japanese scientists looked at the polarization or orientation of light from the cosmic microwave background radiation, some of the earliest light emitted after the universe’s birth. They found the polarization of photons, or light particles, might be slightly rotated from their original orientation when the light was first produced. And dark energy or dark matter may have been responsible for that rotation. (Dark energy is a hypothetical force that is flinging the universe apart, while proposed dark matter is a substance that exerts gravitational pull yet does not interact with light.)\nThe rotated signature of the photon polarization tells the scientists that something may have interacted with those photons — specifically something that violates a symmetry physicists call parity. This symmetry or parity says that everything looks and behaves the same way, even in a flipped system — similar to how things look in the mirror. And if the system was following this parity rule, there wouldn’t be this rotation change.\nParity is shown by all subatomic particles and all forces except the weak force. However, the new results suggest that whatever the early light might have interacted with might be violating this parity.\n“Maybe there is some unknown particle, which contributes to dark energy, that perhaps rotates the photon polarization,” said study lead author Yuto Minami, a physicist at the Institute of Particle and Nuclear Studies (IPNS) of High Energy Accelerator Research Organization (KEK) in Japan.\nWhen the cosmic microwave background radiation, or CMB, was first emitted 13.8 billion years ago, it was polarized in the same direction. Looking at how the light’s polarization has rotated over time allows scientists to probe the universe’s history since then, by looking at how the light has changed as it travels across space and time.\nPreviously, scientists have studied the CMB’s polarization and how it’s been rotated over time, but they weren’t able to measure it accurately enough to study parity because of large uncertainty in the calibration of the detectors that measure the photon’s polarization. In the new study, reported Nov. 23 in the journal Physical Review Letters, researchers figured out a way to precisely measure the rotation of the instruments by using another source of polarized light — dust from within the Milky Way. Because this light hasn’t traveled as far, it’s likely not strongly affected by dark energy or dark matter.\nUsing the dusty Milky Way light, the scientists were able to figure out precisely how their instruments were oriented, so they knew the rotation in the light was real, not something caused by their instruments. This allowed them to determine the polarization rotation of CMB light was non-zero, which means that the light has interacted with something that violates parity. It’s possible something in the early universe affected the light, but it’s more likely that it was something along the light’s path as it traveled toward Earth, Minami told Live Science.\nThat something could be dark energy or dark matter, which would mean that the particles that make up these mysterious substances violate parity.\nThe authors reported their findings with 99.2% confidence, meaning there’s an 8 in 1,000 chance of getting similar results by chance. However, this isn’t quite as confident as physicists require for absolute proof. For that, they need five sigma, or 99.99995% confidence, which likely isn’t possible with data from just one experiment. But future and existing experiments might be able to gather more accurate data, which could be calibrated with the new technique to reach a high-enough level of confidence.\n“Our results do not mean a new discovery,” Minami said. “Only that we found a hint of it.”\nOriginally published on Live Science.\n#Twisted #light #beginning #time #reveal #brandnew #physics","It's not just the postman who rings twice.\nFor the second time this year, scientists working with a sensitive gravitational wave experiment say they have picked up the vibrations of two distant black holes colliding in space.\nThe find confirms what scientists were hoping for when they switched on the advanced Laser Interferometer Gravitational-Wave Observatory (LIGO) last fall: Space is aquiver with signals generated by the violent motion of massive objects, and their detector is quite capable of picking them up.\nLIGO made headlines in February when scientists reported for the first time that they had measured gravitational waves directly – triumphantly verifying a century-old prediction by Albert Einstein.\nAt the time, physicists noted that the detection may have been a lucky break because it involved the collision of two unexpectedly massive black holes, each about 30 times heavier than the sun. The event was detected on Sept. 14, 2015. As they spiralled in toward each other and collided, their gravitational energy rattled spacetime far and wide, producing a textbook signal that was immediately recognized by LIGO 1.3 billion light years away.\nThe second event, detected on Dec. 26 but only reported on Wednesday, was both more subtle and more typical of what advanced LIGO was built to detect. In this case, the two black holes measured about 14.2 and 7.5 times the sun's mass, and they produced a pulse of gravitational waves that was only one-third as strong as the first event, even though they were coming from about the same distance.\n\"We had to dig a little bit deeper into our noise to be able to see it,\" said David Reitze, executive director for the LIGO experiment, headquartered at the California Institute of Technology.\nThe team also announced a third possible signal spotted in October at the limit of the experiment's sensitivity. Although it was too weak to report as a definitive detection, scientists are enthusiastic that the universe appears to be giving LIGO plenty to listen to, with the prospect of more to come when science observations resume later this year.\n\"It's definitely important and encouraging that these weaker signals are there and are beginning to show up,\" said Harald Pfeiffer, a researcher at the Canadian Institute for Theoretical Astrophysics in Toronto and a member of the LIGO team.\nThe more events that the experiment is ultimately able to detect, the more researchers say they will be able to learn about the nature of black holes – bizarre objects with gravity so strong that not even light can escape them – and the history of their formation in the universe.\nGravitational waves offer the only direct way of observing what happens when two black holes merge into one, an extreme event that pushes the limits of current theory.\nThe waves are ripples in the fabric of space that cause everything they encounter to momentarily stretch and squeeze as they pass by. To detect them, researchers supported by the U.S. National Science Foundation built two identical facilities – one in Washington State and one in Louisiana – where laser light is reflected back and forth through four-kilometre-long tunnels that are constructed at right angles to each other.\nA gravitational wave appears as a momentary difference in the time it takes light to travel down one tunnel relative to the other. By comparing data from the two facilities, scientists can rule out local effects that might mimic a gravitational wave signal and only focus on events that are seen by both.\nA third gravitational wave detector, dubbed VIRGO and located near Pisa, Italy, is expected to come online by the end of the year. As VIRGO's sensitivity improves to match the LIGO detectors, the three-part network should vastly improve researchers' ability to pinpoint where in the sky different bursts of gravitational waves are coming from – and so improve the odds that astronomers may have time to zero in on a distant flash of light that corresponds to a black-hole collision or some other event.\nThose other events might include the collisions of smaller but nearer objects, such as neutron stars in our own Milky Way galaxy. But even more tantalizing would be a signal unlike anything that physicists have predicted LIGO will see.\n\"That would be just wonderful,\" said David Shoemaker, a senior team member and director of the LIGO Laboratory at the Massachusetts Institute of Technology. \"For me, that would be the proof that we were doing something that was going to lead science forward rather than verify science that has been done.\""],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:40db6cb7-b421-4664-9af2-c3d3f360641d>","<urn:uuid:fb4a6637-ccf4-47f7-a7dd-a4c60baebe18>"],"error":null}
{"question":"What are the advancements in AI-powered tools for improving telehealth mental health services, and what are the current limitations of teletherapy that need to be addressed?","answer":"AI-powered tools are being developed to improve behavioral telehealth delivery by analyzing video and audio in real-time to measure patient engagement. These tools use artificial intelligence and computer vision systems to monitor speech patterns, facial expressions, and gaze patterns, helping clinicians overcome the limitations of videoconferencing. However, teletherapy still faces significant limitations, including technical difficulties that require reliable internet connections, limited ability to pick up nonverbal cues which impacts therapeutic relationships and clinical assessments, restrictions on certain therapeutic modalities like touch-based therapies, and privacy concerns when sessions are conducted in public places or with unsecure technology.","context":["Computer Science and Psychiatry Unite to Improve Behavioral Telehealth Services\nExperts from the University of Maryland, College Park and the University of Maryland School of Medicine are working to create new tools powered by artificial intelligence to improve behavioral telehealth delivery, which has replaced most office visits during the coronavirus pandemic.\nWith so much human contact channeled through shaky video links these days, connecting can be harder. For mental health clinicians—who are trained to assess social and emotional well-being, reactions to medications and other important factors through observation and interaction—the drawbacks of videoconferencing can be more than just awkwardness.\nA new research project is seeking to break down that electronic divide with artificial intelligence-based tools, bringing together computer scientists from the University of Maryland, College Park and behavioral health clinical experts from the University of Maryland School of Medicine at the University of Maryland, Baltimore. It was funded this fall by a COVID-inspired seed grant from the MPowering the State initiative, which harnesses the joint research power of both institutions.\nThe collaboration began to take shape during the spring when the pandemic started shutting down businesses shuttering people in their homes. It quickly became clear that behavioral health providers needed to find better ways to engage patients and clients who used to come to their offices, but whom they now encountered exclusively online during a time when half or more of U.S. respondents to polls indicated their mental health had declined.\n“We switched overnight from in-person to telehealth care for a lot of our patients; the profession had to adapt without training, because there was no time,” said Gloria Reeves M.D., a psychiatrist and associate professor at the medical school. “The ability to assess nonverbal cues, how they are responding and interacting—I lose a lot of that through virtual care.”\nAniket Bera, an assistant research professor in the Department of Computer Science and the University of Maryland Institute for Advanced Computer Studies (UMIACS), meanwhile, had been working on ways to gauge emotions and behavioral traits with artificial intelligence and computer vision systems that monitor speech patterns, facial expressions or where a subject’s gaze wanders\nWhen the two began to talk, it became clear they could combine their expertise to seek ways to improve mental telehealth services. The project, which is focuses on rural child behavioral telehealth delivery, is aimed first at finding an effective way to measure caregiver-patient engagement—a necessity for successful outcomes.\nWith the MPower funding, Bera and his team are building an artificial intelligence-based algorithm to analyze video and audio in real time to measure engagement by sorting through a complex set of measures that are much harder for mental health professionals to pick up through videoconferencing, which lacks true eye contact, and creates a kind of tunnel vision that prevents the caregiver from understanding how a patient is reacting to their environment, or seeing most of their bodily movements. But creating technology to do this is far from simple, he said.\n“Your eyes tell one story, your face tells a different story, your speech tells a different story. Which is more important?” Bera said. “How do we automatically figure out what to pay attention to so we can measure the level of engagement?”\nBera and Reeves hope to use the seed funding to build the foundation for a larger project that will move on to measure other factors—psychiatric symptoms, reactions to medicine and more—and create a broadly useful tool clinicians can use to help their patients, and which could have other uses as well.\nEven if the pandemic ends within several months, telehealth is likely to continue to grow, Reeves said; among other things, patients like the convenience and it could lower costs.\n“I don’t think we know yet what the new normal is, but I don’t think we should assume it will be exactly what it was,” she said.\nMaryland Today is produced by the Office of Marketing and Communications for the University of Maryland community on weekdays during the academic year, except for university holidays.\nFaculty, staff and students receive the daily Maryland Today e-newsletter. To be added to the subscription list, sign up here:Subscribe","Teletherapy, or therapy conducted through videoconferencing or phone, has become increasingly popular in recent years, especially during the COVID-19 pandemic. As a result, many psychologists and psychotherapists may wonder whether teletherapy is as effective as traditional, in-person therapy. In this blog post, we will explore the research on the effectiveness of teletherapy and consider its benefits and limitations.\nThe Research on Teletherapy\nResearch on the effectiveness of teletherapy has been growing in recent years, and the findings suggest that it can be as effective as traditional, in-person therapy for many clients. A meta-analysis of 39 studies on the effectiveness of teletherapy for the treatment of mental health conditions found that it was as effective as traditional therapy for a range of disorders, including depression, anxiety, and PTSD (Cuijpers et al., 2019).\nSimilarly, a randomized controlled trial comparing in-person therapy to teletherapy for the treatment of depression found no significant differences in treatment outcomes between the two groups (Hubley et al., 2016). Additionally, a systematic review of the use of teletherapy for the treatment of PTSD found that teletherapy was an effective treatment option for this condition, with no significant differences in treatment outcomes between teletherapy and in-person therapy (Simpson et al., 2018).\nBenefits of Teletherapy\nTeletherapy has a number of benefits for both clients and therapists. These benefits include:\n1. Accessibility: Teletherapy can increase access to mental health services for those who live in rural or remote areas, have mobility issues, or have other barriers to accessing traditional, in-person therapy.\n2. Convenience: Teletherapy eliminates the need for travel, reducing the time and expense associated with attending in-person appointments.\n3. Flexibility: Teletherapy allows for greater flexibility in scheduling appointments, making it easier for clients to fit therapy into their busy schedules.\n4. Comfort: Many clients feel more comfortable participating in therapy from the privacy of their own homes, reducing anxiety and stress associated with attending in-person appointments.\n5. Cost-effectiveness: Teletherapy can be more cost-effective than in-person therapy, particularly when travel and other expenses are factored in.\nLimitations of Teletherapy\n1. Despite its benefits, teletherapy has some limitations that may impact its effectiveness for some clients. These limitations include:\n2. Technical difficulties: Teletherapy requires a reliable internet connection and the necessary technology (e.g., computer, smartphone, or tablet). Technical issues can disrupt therapy sessions and impact the quality of the therapeutic relationship.\n3. Limited nonverbal cues: Teletherapy can make it more difficult for therapists to pick up on nonverbal cues, which can impact the therapeutic relationship and the accuracy of clinical assessments.\n4. Limited therapeutic modalities: Some therapeutic modalities, such as touch-based therapies, are not possible through teletherapy, limiting the range of therapies available to clients.\n5. Privacy concerns: Teletherapy raises privacy concerns, particularly if sessions are conducted in public places or if the technology used is not secure.\nIn conclusion, the research suggests that teletherapy can be as effective as traditional, in-person therapy for many clients, and has a range of benefits. However, it also has some limitations that may impact its effectiveness for some clients. As such, psychologists and psychotherapists may want to consider teletherapy as an option for their clients, particularly for those who have difficulty accessing in-person therapy or who prefer the convenience and comfort of teletherapy. However, it is important to carefully consider the benefits and limitations of teletherapy and to ensure that clients have access to the necessary technology and support to participate in therapy effectively."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:96ca38e8-a305-4b71-be5f-97c8a3ffc324>","<urn:uuid:9a953d8b-776c-4bb3-b1ee-2bbfa826492a>"],"error":null}
{"question":"Please tell me what training equipment is used to practice whale disentanglement in Hawaii?","answer":"For training, they use a wooden whale tail draped with various sizes of fishing line attached to the bow of the support boat. This serves as a stand-in for a live animal, allowing crew members to practice throwing grappling hooks and cutting lines while managing a large knife at the end of a 14-foot or longer pole.","context":["01/10/23 – FIRST RESPONDERS TRAIN FOR HUMPBACK WHALE DISENTANGLEMENTSPosted on Jan 10, 2023 in Aquatic Resources, Boating & Ocean Recreations, News Releases, slider\n|JOSH GREEN, M.D.\nFor Immediate Release: January 10, 2023\nFIRST RESPONDERS TRAIN FOR HUMPBACK WHALE DISENTANGLEMENTS\nTo view video please click on photo or view at this link: https://vimeo.com/788036457\n(Maalaea, Maui) – A dozen or more times each season, humpback whales while on their principal breeding and calving grounds within the Hawaiian Islands Humpback Whale National Marine Sanctuary (sanctuary) or nearby waters get spotted entangled in fishing gear or marine debris. In the worst cases this material can kill the animal.\nWhen a report of a tangled whale comes in, a specialized, highly-trained group led by federal and state workers head out on a search and rescue mission. Freeing an entangled whale can take hours or even days.\nChad Yoshinaga, Safety Program Manager at NOAA’s Pacific Islands Fisheries Science Center, said, “My analogy is we’re looking for a single needle in a stack of needles in a gigantic haystack.” The quicker they receive reports about distressed whales from mariners or people on the shoreline the faster they can intercept it and begin the “rescue” part of their mission.\nIn December, experienced and novice whale disentanglement specialists took to the sea for several days of training and refreshing of their skills.\nEd Lyman wears several hats for NOAA, but during whale season in Hawai‘i he is the sanctuary’s Regional Large Whale Entanglement Response Coordinator under NOAA’s Marine Mammal Health and Stranding Response Program. He is leading this season’s training; the first since before the pandemic.\n“We’re working around enormous, moving animals, at times in heavy seas and always from moving boats. The safety of our disentanglement teams is paramount. We obviously want to free the whales, but we have to do it without getting anyone hurt,” Lyman explained.\nTraining begins with a thorough on-board briefing, which includes a check on the experience level of each team member, their comfort level in performing various tasks, and how they’re feeling in general.\nResponses often involve two vessels. The support boat that carries an inflatable boat that is aired-up in route and then launched when a tangled whale is spotted.\n“It’s risky business trying to free a 40-ton whale, so you want to deal with the what-ifs. So, one boat is going to approach and work on the whale, while the other one is there to protect all the people involved,” Lyman said.\nFor training, the bow of the support boat carries a wooden whale tail, draped with various sizes of fishing line. It becomes the stand-in for a live animal to give everyone an opportunity to practice or learn how to throw grappling hooks and cut lines while bouncing around in the waves; all while managing a large knife at the end of a 14-foot or longer pole. It’s not easy work and requires years of practice and experience.\nWhale disentanglement crew members earn designations that are part of an Incident Command System (ICS) from one to five, from least experienced to most experienced. Lyman says the ideal number of people to have involved in a disentanglement is eight.\n“You need two or three people on the inflatable approach boat and you need a good five on the support boat to address all the roles. A helms person, a crew member, someone doing documentation, a gear person, and a safety officer. That’s someone who is not doing anything but watching the big picture.”\nOn the approach boat, the team typically includes a bow person watching the animal and holding onto gear, a helm person, and a safety person.\nThe DLNR Division of Aquatic Resources (DAR) is the state agency responsible for conserving and protecting all of Hawai‘i’s wildlife. DAR staff often partner with NOAA on whale rescues. For the latest training staff from Kaua‘i, O‘ahu, Maui, and Hawai‘i Island participated.\nThe DLNR Division of Boating and Ocean Recreation (DOBOR) also has a role to play.\n“Together DAR and DOBOR deal with marine mammals, fishing, boats, moorings, fish aggregation devices and other things that whales get entangled in,” according to Jeannine Rossa, Acting State Co-Manager for the Hawaiian Islands Humpback Whale National Marine Sanctuary. “We have a marine debris reduction program, and we want to be part of the solution in reducing entanglement hazards,” she said.\nIt takes years of experience to become a top-level disentanglement expert, but no matter their level of experience the people who free whales are dedicated and passionate about what they do. It’s hard work and when a whale is freed they all agree there’s no better feeling.\n# # #\nHD video – Hawai‘i Whale Disentanglement Training web feature:\nHD video – Whale disentanglement training media clips (Dec. 6, 2022):\nPhotographs – Whale disentanglement training (Dec. 6, 2022):\nSenior Communications Manager"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:947194e2-d238-4324-a1bc-ca96072ff337>"],"error":null}
{"question":"How do project evaluation methods compare between traditional programming education and game development courses?","answer":"Game development courses employ a diverse evaluation approach combining individual and group development assignments, game critique assignments, and multiple exams to assess student progress. Traditional programming education evaluation is more focused on hands-on practical work where students' progress as programmers is primarily assessed through their ability to write and implement code during practical programming sessions. Both approaches involve testing student understanding, but game development includes additional evaluation of design and analytical skills through critique assignments.","context":["Information Technology 108\nITEC 108: Introduction to Game Development.\nCredit Hours: (3) Two hours lecture; two hours laboratory\nAn introduction to problem solving and programming in the context of game development. Topics follow the framework laid out by the International Game Developers Association (IDGA) and will touch on each of the core topics: Games and Society, Game Design, Game Programming, Visual Design, Audio Design, Interactive Storytelling, Game Production, and Business of Gaming.\nDetailed Description of Content of Course\n1. Critical Game Studies - Criticism, Analysis & History of electronic and non-electronic games.\n2. Games and Society - Understanding how games reflect and construct individuals and groups, as well as how games reflect and are constructed by individuals and groups.\n3. Game Design - Principles and methodologies behind the rules and play of games.\n4. Game Programming - Aspects of traditional computer science and software engineering – modified to address the technical aspects of gaming.\n5. Visual Design - Designing, creating and analyzing the visual components of games.\n6. Audio Design - Designing and creating sound and sound environments.\n7. Interactive Storytelling - Traditional storytelling and the challenges of interactive narrative.\n8. Game Production - Practical challenges of managing the development of games.\n9. Business of Gaming - Economic, legal and policy aspects of games.\nDetailed Description of Conduct of Course\nConcepts of game development are covered in the lecture portion of the course. These concepts are reinforced by the programs and critiques that the students write. A significant portion of the lab time is spent in the microcomputer lab. This provides the opportunity for close contact between the student and the instructor while the student is designing and implementing games and writing critiques. The lab time may also be used to cover specific design details.\nGoals and Objectives of the Course\nStudents who complete the course will be able to:\n1. Articulate a brief history of video games, covering the evolution of the major genres, platforms, publishers, and developers of the last several decades.\n2. Describe the sociology of games, including audience demographics, societal reactions to sex and violence, and the emergence of online communities.\n3. Explain ludology – the academic study of games – including the issues and individuals central to this rapidly growing field.\n4. Explain the theories, processes, and design considerations that form the foundation of game creation.\n5. Describe the nature of fun, including ideas such as game structure, game flow, and the role of choice in generating an entertaining interactive experience.\n6. Discuss the specifics of actually designing a game, from high-level conceptualization and design documentation, to specific topics such as interface design, play mechanics, platform modifications, and performance testing.\n7. Explain programming teams and processes, and common game programming languages.\n8. Explain fundamental concepts in computer programming including variables, looping, and branching.\n9. Describe how to debug games and explore their use of system resources.\n10. Articulate the basics of math and physics used in game development – geometry, applied trigonometry, vectors and matrices, transformations, general physical concepts, real-time game physics, rigid body simulations, and particle systems.\n11. Explain general visual design principles, such as graphic design, color theory, and user interfaces.\n12. Describe the “real-world” aspects of the game industry, including the domains of producers, attorneys, and game business professionals.\nCourse will include both individual and group development assignments as well as individual game critique assignments. Multiple exams will also be used to assess student progress.\nOther Course Information\nReview and Approval\nFebruary 2010 Initial Course Approval Art Carter, Chair\nRevised: June 1, 2012","The Basics of Computer Programming\nLike most disciplines, you will begin by learning the fundamentals of computer programming. Depending on your instructor or curriculum, you will probably be introduced to the history of programming and its languages and find out about what has occurred over the years through a timeline.\nYou will also be introduced to the basic concepts and theories of programming and how they have evolved over the years. You’ll be able to see how fast programming has progressed over the centuries and learn the significant developments in this field. You will also encounter topics such as computer hardware, software, systems and language. You will have to learn these basics in order to understand how your field of specialization can contribute. This may seem too troublesome but really, you need to have a good background in the progress of programming to help give you a good grasp of its fundamentals.\nThe result of all your hard work is actually the computer software, so expect this topic to be included in your introductory course. Some of the topics you’ll find under this subject include application software, programming software and system software. During classes dealing with these subjects, you’ll learn how to use programming tools, database management systems, assemblers, debuggers, text and source code editors, and the like.\nFinally, you will be introduced to the topic you’ve been raring to learn – programming. Here you’ll learn different types programming processes, styles and methods. You will learn the different types of programming including concurrent, functional, declarative (event-driven), imperative, object-oriented and Parsing.\nProbably the next topics you’ll learn are the basic components of every computer program, such as the source code and the API or application programming interface. You’ll also learn how instruction is carried out to command a computer to execute a particular set of directions.\nYou’ll also learn programming languages, which will introduce you to the kind of language you have chosen to specialize in. Your instructor might also present your class with a simple comparison of the different types of languages in use today and you’ll also probably learn the types of languages that have lost favor or are already obsolete. You’ll learn semantics, dialects and theories.\nThis is also where you’ll begin learning how to program or write codes. Although your learning at this point will consist of lectures, a good part of your class will be spent working hands-on so you can begin practicing what the instructor has taught you. This is how your progress as a computer programmer will be evaluated.\nThe process of programming\nOne of the earliest topics you will encounter when learning computer programming is the process with which codes and computer languages are designed and produced. The process of programming includes several steps, such as:\n- Definition of the problem.\n- Design or plan of the solution.\n- Design of the code to be used for the program.\n- Testing and evaluation of the program.\nDebugging, Testing and Maintenance\nProbably the final list of topics you’ll learn as your introduction to computer programming is application. In these topics, you’ll learn how to test the program you have written, spot and locate any errors and correct them."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:56f5f24b-4be7-4ec9-812f-b5f25458a148>","<urn:uuid:0d6a3676-6bd4-4952-88cc-17196b23104b>"],"error":null}
{"question":"What are the key differences between resizing images in Adobe Captivate versus creating data visualizations in Infogr.am for presentations?","answer":"Adobe Captivate and Infogr.am offer different approaches to visual content. In Adobe Captivate, you can resize images using manual handles or the Properties Inspector, with options to constrain proportions to avoid distortion, rotate images, and precisely adjust width and height values. The Properties Inspector also allows you to set exact X/Y coordinates for positioning. In contrast, Infogr.am focuses on creating data visualizations with automated tools - it provides form-based data entry similar to Google Docs and comes with various pre-designed templates for organizing information. While Captivate gives granular control over individual image properties, Infogr.am streamlines the process of turning data into visual reports with less manual adjustment required.","context":["How to Work with Images and Shapes Adobe Captivate\nAdobe Captivate allows you to import images and graphics into the program for use on your slides. You can import several different image and graphic formats, including Photoshop documents (PSD), Bitmaps (BMP), Graphics Interchange Format (GIF), Joint Photographic Expert Group (JPG or JPEG), icons (ico), MetaFiles (WMF), Enhanced Metafiles (EMF), Portable Network Graphics (PNG), and PowerPoint templates (POT). All images that you import will be located in the Library in Adobe Captivate for use on any slide.\nInserting an Image onto a Slide\nTo insert an image onto a slide, select the slide on the Filmstrip.\nNext, go to the Toolbar, and click the Media button. You will then see the Media dropdown menu.\nSelect Image from the dropdown menu (pictured above).\nSelect the image on your computer that you want to use, then click the Open button.\nThe image then appears on your slide.\nManually Resizing an Image\nNotice that the image inserted onto the slide appears in the center of the slide. If you have other objects on the slide, it will appear in front of them. For that reason, you will most likely have to move and resize the image whenever you insert an image onto a slide.\nTo resize an image, click on the image to select it. You will see a bounding box appear around the image with small white squares in the corners and on the side. These white squares are handles.\nYou can click and drag inward on any handle to reduce the image's size. Drag outward to increase the image's size.\nHowever, beware. Resizing an image using the handles can cause the image to become out of proportion, as pictured below.\nReturning an Image to Its Original Size\nIf you're not happy with the new size of an image, you can restore it to its original size by double clicking on the image to open the Properties Inspector.\nClick the Reset to Original Size button, as pictured below.\nThe image is restored to its original size.\nResizing and Image Using the Properties Inspector\nIn addition to resizing images manually, you can use the Properties Inspector to resize images – and also to constrain the proportions so the image isn't distorted.\nTo resize images using the Properties Inspector, double click the image on the slide to open the Properties Inspector.\nClick on the Options tab.\nGo to the Transform section of the Properties Inspector.\nMake sure the Constrain Proportions box is checked. This means if you adjust the width of the image, the height will be adjusted accordingly – and vice versa.\nThen, you can click on either the value for the width (W) or height (H) to change the size of the image.\nYou can also change the position of the image on the side by changing the value for X – which represents the horizontal position of the image – or Y, which represents the vertical position of the image on the slide.\nRotating an Image\nTo rotate an image, you can use the handle that appears above the image, as highlighted below.\nHover your mouse until the cursor has a curved arrow below it, then move the mouse to the left or right to rotate the image.\nYou can also rotate the image by going to the Properties Inspector.\nGo to Angle.\nYou can then drag the grey line inside the circle up or down to rotate the image.\nYou can also type in a value for the degree of rotation.\nStacking Images or Objects\nStacking images or objects is the process of moving one image or object behind or in front of another. For example, when we first inserted an image onto the slide, we discussed how the image might appear on top of other objects on the slide. We may want the image to appear behind the other objects – or behind just some of the objects. To fix this, we need to change the stack order.\nTo stack images or objects, first select the image or object that you want to move forward or backward.\nNext, go to Modify on the Menu Bar, then Arrange. Select an option.\nBring Forward brings the image or object forward. Let's say we want to move Image A forward. Image B, Image C, and Image D are in front of it – in that order. Selecting Bring Forward will move the image in front of Image B, but not C or D. If we want to move it in front of Image C, we would go to Modify>Arrange>Bring Forward again.\nSend Backward sends the object backward – or below another object. If Image A appears in front of Image B, selecting Send Backward will place it behind Image B.\nBring to Front brings the image or object in front of all other images or objects on the slide.\nSend to Back sends the image or object behind all other images or objects on the slide.\nWhen you crop an image, you cut out the outer edges of the image. To crop an image that appears on a slide in Adobe Captivate, first click on the image to select it.\nGo to the Properties Inspector, then click the Style tab.\nNext, click the Edit Image button.\nYou will then see the Resize/Crop Image dialogue box, as pictured below.\nSelect Crop, as shown below.\nIf you want to constrain proportions, but a check beside the box.\nDrag the handles on the corners and sides of the image to crop the image. To use the handles, hover your mouse over a handle until you see a two-way arrow. You can then drag the handle inward to crop away edges of the image.\nAs you can see, we've cropped away the edges of our image.\nClick the OK button when you're finished.\nNOTE: You can also use the dialogue box above to adjust the brightness, sharpness, contrast, alpha, hue, and saturation of the image. Just use the sliders or change the numerical values in the boxes to the right of the sliders.\nClick the OK button when you're finished.\nResizing an Image to Fit a Slide\nIn the last section, we worked with the Resize/Crop Image dialogue box. Let's return to that dialogue box to learn how to resize an image to fit a slide.\nTo do this, simply select the Fit to Stage option, then click the OK button.\nFlipping an Image\nYou can also use the Resize/Crop Image dialogue box to flip or rotate an image. To do this, you will use the following buttons in the dialogue box.\nFrom left to right:\nFlip Image Horizontal flips the image on its horizontal axis.\nFlip Image Vertical flips the image from its vertical access.\nRotate Right rotates the image to the right.\nRotate Left rotates the image to the left.\nRemove a Background Color from an Image\nTo remove a background color from an image, select the image on the slide, then go to the Properties Inspector.\nClick the Style tab in the Properties Inspector.\nClick the dropdown arrow beside the Make Selected Color Transparent icon, shown below.\nClick on the Eyedropper tool, as pictured below.\nClick on the background color in the image that you want to remove.\nDon't expect to receive perfect results with this tool. For best results, use an appropriate editing program, such as Adobe Photoshop, to edit images and other objects.\nAdobe Captivate comes with characters that you can insert onto your slides. Characters are cut outs of people. They can be portraits or illustrations.\nTo view the characters that you can insert onto your slides, go to the Toolbar. Click the Media button to see the dropdown menu, then select Characters.\nYou will then see the Characters dialogue box.\nFrom the Category dropdown menu, select the type of characters you want to view. We are going to select Business.\nAs you can see above, on the left hand side of the dialogue box, you see the different characters you can use. Simply click on a character to select that character.\nTo the right of the characters, you can see cutouts of that character in different poses.\nSelect a pose by clicking on it, and you'll see it in the far right of the dialogue box. You can then choose to show the full character, a close up of the character, or half of the character. Just click on your selection.\nIn the snapshot above, you see the full character. Pictured below is half:\nBelow is a close up.\nOnce you've selected your character, click the OK button.\nAlong with characters that are built into Adobe Captivate, you can also download images, templates, characters, and more from the eLearning Brothers website. There are over 30,000 different assets you can use, and they are free with your Adobe Captivate license.\nTo gain access to these templates, click Assets on the Toolbar.\nYou will then see this dialogue box:\nIf you already have an eLearning Brothers account, you can sign in. If not, click the Create Account button and follow the instructions on the screen.\nInserting Smart Shapes\nIf you've enjoyed using Smart Shapes in other programs, such as PowerPoint, you'll be happy to know that you can also insert Smart Shapes onto your slides in Adobe Captivate.\nTo insert a smart shape, go to the Toolbar.\nClick the Shapes button. You will then see the dropdown menu.\nSelect a shape from the dropdown menu, then draw it on your slide by clicking and dragging your mouse.\nYou can use the Properties Inspector to format the shape.\nCreating an Image Slideshow\nIf you have a lot of images on your computer, you can use Adobe Captivate to create a slideshow.\nTo create a slideshow, go to File>New Project>Image Slideshow.\nChoose a size for the slideshow, then click the OK button.\nSelect all the images you want to add to the slideshow by pressing the Control key as you select images in the Open dialogue box (shown above).\nClick the Open button after you select the images.\nAdobe Captivate creates the slideshow for you. Depending on how many images you have, this may take a few minutes.\nUse the Timing Inspector to adjust the duration for each slide. The Timing Inspector is found with the Property Inspector.\nSimply click on the slide duration, and type in a new value.\nUsing the Library\nAll assets that you use in your project are stored in the Library. The library can store background images, images, animations, linked PowerPoint presentations, and more. The assets stored in the Library can be used in your project multiple times and on multiple slides.\nWe looked at the Library earlier in this course. Remember, the button for the Library is located above the Properties Inspector. Let's click that button now, and open the Library.\nLet's look at some features of the Library.\nThe Used Count column shows you how many times an asset has been used in your project.\nAs you can see, there are also columns for the file name, the size, status, and date modified.\nIf you click on an asset in the Library, it will show in the Preview section at the top of the Library Inspector.\nBelow the preview are tools and buttons to allow you to work with assets in the Library. Let's cover those from left to right.\nOpen Library. This allows you to use resources from another Captivate project. Click the button, then select another Captivate project.\nImport allows you to import assets into the Library.\nExport allows you to export assets and save them to your computer.\nEdit allows you to edit the resource in the appropriate editing program that's installed on your computer. For example, if you have Adobe Photoshop installed, image assets would be opened in Adobe Photoshop when you selected the asset, then clicked the Edit button.\nProperties allows you to see the asset's properties in a dialogue box like the one pictured below.\nUsage shows the usage of the asset.\nUpdate allows you to update the asset with any changes. Press the Update button in the dialogue box pictured below to update the asset.\nSelect Unused Items can help you to clean up your Library by selecting any items in the Library that are unused. You can then delete them if you want.\nDelete. To delete an asset, you can select the asset, then press this button.\nIf you delete an image or asset from a slide, it still appears in the Library. To delete an asset from the Library, you can click the Delete button. You can also right click on the asset, then select Delete.\nTo add an asset to a slide from the Library, simple drag the asset name in the Library to your slide in the work area. (The slide must be selected in the Filmstrip and showing in the work area.)\nTo rename an asset, right click on the asset, then select Rename from the context menu. The asset will appear as selected in the Library. Simply type the new name for the asset, then press Enter on your keyboard.\n- Getting Started with Adobe Captivate\n- Screen Recording with Adobe Captivate\n- How to Add Quizzes and Other Interaction with Adobe Captivate\n- How to Import Media and Audio into Adobe Captivate\n- Adobe Captivate Tools Pointer Paths, Highlight Buttons, and More\n- Working With Documents in Adobe Illustrator\n- Adobe Premiere: Creating Video Effects\n- All About Creating Slideshows and Creating Labels in Adobe Photoshop Lightroom\n- How to Create PDF Portfolios\n- Adobe Premiere: How to Edit Audio Tracks\n- How to Restore and Backup MySQL Databases\n- How to Link and Consolidate Your Spreadsheets in Excel 2019\n- Adobe Premiere: What is the Timeline?\n- How to Work with Symbols in Adobe Edge\n- Editing Images and Working with Basic Selections in Adobe Photoshop","Data Visualization Tools are used to create cool and beautiful infographics. Infographics are “graphical representation of information and data.” Infographics are often used to represent data and statistics, or relationships or differences between two or more issues concisely.\nWhen reading an article, it is always desirable to visually find the information since our brain will still digest and remember it more easily. Moreover, the data representing graphically will allow displaying more information in less space.\nWe all know that no longer people show interest in reading long and detailed articles. We use data visualization tools to represent the data more concisely in a graphical format so that users can scan and recall the information quickly.\nWhat can you Draw with Infographics using data visualization tools?\n- Chronology: Typically, to illustrate the history, evolution, and changes of a brand, a product, or a problem.\n- Camemberts: The Camemberts is used, for example, to compare parts of a budget granted to certain positions, aspects of specific sectors in an economy, an ecosystem of sale, etc..\n- Bar charts compared: Comparative bar graphs for comparing percentages expressing different opinions in a poll or survey.\n- Profiles compared: Combined with text, allow to answer the question: “What type of user are you?”\n- Comparative tables: The comparative tables are used to compare the costs of some consumer products between countries.\n- Treemaps: The treemaps are used, for example, to make a contrastive analysis to visualize at a glance the relative part of an element in a set.\n- Organizational: Organizational charts are used to perform a logical demonstration, a report of causes and effects.\n- Venn Diagrams: Venn diagrams are geometric patterns (circles) intended to show the relationship between different items that can be contained in one or more sets, usually represent notions.\n- Annotated maps: The maps are recorded, for example, to create maps to demarcate different situations or data from several countries (with the aid of color, a text section, etc.).\nWhy use data visualization tools to create cool Infographics?\n- Data visualization tools are simple to use and are very quick in creating infographics.\n- Any complex issue with an infographic is simple\n- Infographics are short, easy reading\n- Users love to see infographics and share them on social networks\n- The use of infographics can be more effective than any text\n- They can be used for any sector: education, science, marketing, medicine, journalism, etc …\n- They are a convenient mechanism to entice readers.\n- They help reduce the amount of informational text.\nTips to Create Effective Infographics using data visualization tools.\n- Define the purpose of an infographic: Translate only the complex data value to compare the information or clarify a trend or evolution, creating a balance, etc.. And all this in a single image.\n- Choose an idea or theme clearly: What computer graphics to display or show.\n- Favoring simplicity: A classic mistake is to overload the computer graphics for information, making it difficult to read at the end. It is essential to plan and strict while selecting the data and items that must be put into the graphics.\n- Relying on data achieved from (public) reliable sources: listed at the bottom of the infographic.\n- Check the format: Vertical or horizontal.\n- Caring visual storytelling: The elements of computer graphics should allow capturing the general sense within seconds. The text should be as small as possible.\n- Conclude: The elements of conclusions help to give a clear sense of infographics.\n- Sign infographics: To care for your reputation and show their origin.\nHere are several freeware data visualization tools to create our own original infographics. Depending on the needs us more fit either, and basically all are easy to use without extensive technical knowledge.\nPowToon free business presentation software animated video maker and PowerPoint alternative\nA web application to create video presentations and infographics designed for dummies. Everything is convenient and straightforward. Now comes with a gallery of icons, but you can also upload your own images and even audio.\nOnce you sign up and create your account, you just have to choose to create a new presentation and put all the textual content you have and decorate it with icons and music. Once finished, you can export it to your social networks, Youtube, or download it to your computer.\nInfogr.am Create Infographic and Online Chart\nOne of the most exciting tools is available for free on the internet is infogr.am, which lets you create a variety of computer graphics with many personalized options.\nWith Infogr.am, creating the data flow is very simple, and you have a large number of designs to choose from, with different ways of organizing information that will depend on what we capture on our infographic.\nData is added via form, which is very convenient, and you end up saving a lot of time. The form is like using Google Docs, so if you have used Google Docs, you will find it very convenient to make some eventual reports with concrete data. Being free, it’s an exciting way to apply computer graphics to individual businesses.\nVisual.ly Infographics and Data Visualization Tool\nThis data visualization tool is used to create custom infographics based on one premise: to tell stories with specifics detail. This tool is ideal for those who do not want to waste too much time creating infographics since it comes with preloaded templates.\nOne of the most compelling infographics is comparing different Twitter accounts, allowing you to make fair competition analysis without investing too much time. Such reports can be handy.\nYou have a total of about a dozen templates that you can use for different purposes. Facebook Insights is also one of the most useful tools, making a quick and visual analysis.\nExclusively for creating infographics related to performance in social networks. The data are obtained automatically from our accounts, so we have almost no way to edit, but it’s fascinating to have a fast panning.\nEasel.ly Create and Share Visual Idea Online\nThis data visualization tool is a favorite of many to create infographics quickly. As the name suggests, the task of Easel.lyis providing free web-based software to make the data information we want in infographics.\nAlthough it is still in the beta stage and could see some improvement over time, this tool’s interface is effortless and minimalist operation is to drag and drop items to form the structure according to our needs. You can also make some customizations in design.\nIn addition to some templates that allow you to save time, you can use those already on hand.\nEasel.ly is a recommended tool for those who do not have any previous experience creating infographics but do not want something completely automated as Visual.ly. It allows you to do customization after creating your infographics.\nCreately Online Diagram Software to Draw Flowcharts\nNow delve a little deeper into what the collaborative work to create infographics. Creately is a must tool for you, which allows you to work with others and create charts and tables of data flow easily.\nAt an intermediate point between a fully automated tool and more personalized, with Creately, you can choose between different types of diagram to create an infographic. Of course, you have their details, and you will have to have some aesthetic knowledge to get a good result.\nThis tool is for people who have a piece of relatively basic design knowledge, and they don’t want to create an infographic absurdity with accurate data. The idea is to do something good looking, so we have to consider that we will not have an automatic thing to help us.\nDipity Find Create and Embed Interactive Timelines\nDipity is a friendly service that allows you to do something a little different. Unlike previous tools, the differential value of Dipity is that you can create a timeline in which you organize your information.\nDipity is the idea of being a supplier to provide organized information differently than can be inserted into web pages, which can be consumed strictly in a visual form allowing users to have prolonged use of text.\nTimelines can be considered as something boring, but this tool does have some fun. We have different designs to choose from and put them in a fine display of data that anyone will miss.\nThis tool is for those looking for a different alternative that is not related to the typical infographic on the internet.\nVizualize.me (Best Data Visualization Tools to create a free resume in a single click)\nThis online tool allows you to all those with just one click to give an original touch to your resume with a fun and professional design. It will enable you to display your professional achievements with a simple custom design and compelling turn as you generate an excellent visual summary—ideal for optimizing your LinkedIn profile.\nINFO TO Free Android app for Infographics\nIf you use your android to take lots of pictures, Free INFOTO can be an exciting tool for making photographs. This tool takes the EXIF data associated with your photos and makes them into fantastic infographics. Its interface is inspiring, and they also have the paid version, which costs 99 cents.\nWordle Beautiful Word Cloud Data Visualization Tool\nWordle is defined as a tool to create a ” tag cloud “with a bunch of strings. You may use different fonts, templates, and color schemes.\nStat Planet Interactive Map Visualization\nDownload free tools to create fully customizable maps and interactive charts.\nPiktoChart Infographics, Graphics Designing for non Designers\nPiktoChart allows us to drag images to the browser to easily create our own charts and graphs, or use some of the predefined themes.\nFrom different templates, you can develop infographics online. Offers various graphic elements integrated into computer graphics by simply dragging and dropping them in the desired location. The free version provides few templates with limited features. Infographics can be downloaded in PNG format.\nHohli (Online Data Visualization Tool )\nHohli is a simple online graphics generator. It allows you to create diagrams, figures, and graphs.\nGoogle Public Data Google, public Data explorer\nAnother interesting tool if you need to show Google public domain information in your infographic.\nManyEyes (Simple and easy Data Visualization Tool)\nManyEyes tool is proprietary of IBM. It is a powerful tool to create infographics based on our personal or public data.\nSome more data visualization tools to create easy infographics:\n- Knoema: Huge database, environmental … economic data exportable data.\nDataboard Google: Google Information on mobile devices.\n- Google Think Insights: Tendenciasde marketing, technology, and internet collected by Google.\nAzure Data Market: Database Microsoft payment.\n- Crunchbase: Database opened businesses, individuals, and investors in the technology world.\n- UNData : An information service containing the databases of UN information.\n- Mailchimp: Not only is the ideal place to send emails to a specific group of users but contains information metrics e-mailing campaigns by industry tool: bounce, open rate, etc..\n- SurveyMonkey: It’s a great way to generate surveys for a particular segment of your user-community, your company, your friends, to gather information about a topic. Other options are Typeform and drive through google.\nSocial Bakers: Statistics and metrics about Twitter, Facebook, Youtube, and Linkedin. Datamobs: A variety of available data sets of different themes: art, crime, health, among many.\n- Infochimps: Specialists in Big Data with lots of case studies, whitepapers, and resources.\n- Market Data: Upload and download data sets and create open views.\n- Google: If all else is missing, a specific search can give you the information you seek.\nInformation marketing, advertising, and Internet\n- Comscore: One of the primary gauges Internet audience. Ask some of the information it collects.\n- Nielsen : Market Information\n- Alexa: It gives you an idea of traffic a website receives.\n- Open Site Explorer: To compare the authority and external factors of a website.\n- Google trends: If you want to compare search trends.\nSocial and economic information:\n- INE: Demographics Spanish: from unemployment to middle age.\n- CNN Money: Financial information concerning significant media worldwide.\n- Worldbank: Economic data, development, and poverty in countries.\n- USA Census: All information on U.S. government census\nIdeas and Websites infographics\n- Daily Infographic: An infographic a day, only the best.\n- The Infographic of the day of FastCompany: Infographics FastCompany day.\nInfosthetics: Information is shown aesthetically, whether or not to use infographics.\n- Information is beautiful: More to data visualization. Simple and beautiful.\n- Dribbble: A place for designers to showcase their work and interact.\n- Behance: An online tool for diseñaadores portfolios, where it is effortless to find quality content.\n- Maps Milhaud: Facebook page in Spanish for lovers of cartography.\n- 500 Infographics for the Community Manager classified in 35 categories\n- The New York Times: Some of the best graphics that you’ll see on the Internet. In his summary of 2012, you can find some fantastic.\n- Pinterest: Almost any company in one area often have boards with infographics and other visual material, and the specific accounts infographics.\nWebsites with high-quality vector images for infographics:\n- I DesignMoo\n- premium pixels\n- Kits Infographics on Shutterstock\n- Kits Infographics on Graphicriver\n- More than 50 sets of user interfaces on flat design. Some of these elements may be useful in our design infographics.\nWorld maps in vector formatwith different designs, layouts… from the typical globe to pixel art.\n- Maps of Spain and the world: It has various designs but has hydrographic maps, roads, coastal … all in Vector, and in Spain in particular detail. Up regions.\nSome Desktop Data Visualization Tools\nIt seems obvious, but the best way to create some infographics that fit precisely what you want to work with design tools allows you to move your idea just like in your head. The problem is that they require more time, effort, and knowledge, but if you dare, here are some tools:\n- Adobe Illustrator: vector design software excellence. Ideal for infographics.\n- Adobe Photoshop: Indispensable if you need to work on photographs or images.\n- Adobe After Effects: If you’re into animated graphics, this is your program.\n- Sketch: The alternative to Photoshop that is gaining much market relevance"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:7b5f42ae-6626-4330-8248-3aabed6bdb69>","<urn:uuid:d10d479d-52ae-43db-8c54-27f924da85cc>"],"error":null}
{"question":"How do the aging processes of Bogle's Phantom Chardonnay and German Riesling wines differ in terms of their maturation characteristics?","answer":"Phantom Chardonnay relies on barrel fermentation and American oak aging for its maturation, which imparts a creamy, luscious mouthfeel with subtle accents of vanilla and baking spices. In contrast, Riesling wines are typically bottled immediately after fermentation with very rare cases of barrel aging. However, Riesling has a unique ability to mature in the bottle for decades due to its high acidity levels, developing elegant aromas of aromatic butter, honey, and honeybee wax over time, despite having a relatively low alcohol content of 7-9 degrees.","context":["Products 1-11 of 11\nItem #: 7430208371 -\nNotes: Phantom Chardonnay entices with its rich layers. Green apple and pear transform into spicy flavors of freshly baked apple pie, while barrel fermentation imparts a creamy, luscious mouthfeel.\nItem #: 7430278924 -\nWINEMAKING NOTES: Thirteen months aging in American oak imparts subtle accents of vanilla and baking spices, while maintaining fruit vibrancy. TASTING NOTES: This richly hued garnet beauty opens with notes of creme brûlée, Bing cherries, sassafras, and hints of pipe tobacco. A soft, smooth entry gives way to a plush, velvety middle and full mouthfeel. FOOD PAIRINGS: This versatile wine pairs well with a variety of foods like margherita pizza, aged white cheddar and duck breast with a raspberry...\nItem #: 7430279453 -\nWINEMAKING NOTES: Our Cabernet Sauvignon grapes lingered on the vines well into Autumn, soaking up sunfilled California days and cool, crisp nights to achieve their complex flavors. We think the wait was worth it. TASTING NOTES: Opening with dense fruit notes of dried cherry and plum compote, our Cabernet Sauvignon captivates the nose and palate. Hints of clove, nutmeg and burnt caramel are imparted through 14 months of aging in American oak barrels. Dusty tannins give way to a concentrated...\nItem #: 743020523818 -\nWINEMAKING NOTES: The deep, dark color of this wine creates an expectation of weight and purpose, however, the Essential Red’s first impressions are subtle and nuanced. Faint notes of sweet garden mint and eucalyptus tantalize the senses, while hinting at the complexity yet to come. TASTING NOTES: Upon the first sip, the rich, juicy mouthfeel takes over, expressive with flavors of blueberry and blackberry. After aging in American oak for 12 months, the wine finishes with round, plush and...\nItem #: 7430282132 -\nWINEMAKING NOTES: Classic techniques, such as cold fermentation in stainless steel tanks and reductive winemaking, showcase the crisp and vibrant character of this Sauvignon Blanc. TASTING NOTES: A lively entry of boxwood and freshly cut grass greets the senses, while ripe, tropical passion fruit softens the mouthfeel. Just a touch of Pinot Grigio combines to create a playful midpalate, while flavors of quince and lime are mouthwatering, from first sip to refreshing finish. FOOD PAIRINGS: This...\nItem #: 7430283200 -\nWinemaking Notes: Bogle winemakers have sourced fruit from the best growing regions in California for the varietal. The cool Russian River Valley and coastal Monterey hills both grow fruit of character and distinction. Complementing a core of premium Lodi fruit, the resulting wine is an elegant, classic Pinot Noir. Tasting Notes: Heady scents of ripe summer strawberries make a lovely first impression, while hints of crushed violets and sweet dried herbs resonate on the nose. Refined and...\nItem #: 7430283158 -\nWINEMAKING NOTES: Our California Chardonnay, the most popular wine we produce, is a crowd pleaser with wide appeal. With welcoming aromatics, bright and juicy apple and pear flavors, a soft and creamy texture and toasty, spicy tones of American oak, a glass of this has a little something for everyone. Handcrafted and award-winning, this bottle will delight wine drinkers with its lovely, approachable style. TASTING NOTES: Green apple and pear aromas classically characterize this wine as...\nItem #: 7430285473 -\nA Hauntingly Delicious Wine:Phantom, the mysterious apparition of ripe berry and relentless spice, returns to haunt wine lovers. Full of concentration and intensity, this wine will tease, tantalize and linger long after the last sip is gone.\nItem #: 743020523918 -\nWINEMAKING NOTES: Ripe and juicy Merlot grapes are crushed, pressed and fermented to retain their vibrant freshness, then aged for twelve months in American oak, creating a well-balanced wine known for its soft, round and silky texture. TASTING NOTES: This richly-hued garnet beauty opens with aromatics of Bing cherries, sassafras, and hints of pipe tobacco. The smooth and supple red fruits on the entry give way to a plush velvety middle, while this approachable and appetizing wine finishes...\nItem #: 7430288847 -\nWINEMAKING NOTES: Head-trained, dry farmed Zinfandel vines planted by early California pioneers have endured for generations, unwavering through a myriad of challenges and the test of time. Producing small, concentrated clusters of grapes, these vines demonstrate the reward for patience and determination. It is these noble vines that Bogle winemakers rely on to create our intriguing Old Vine Zinfandel. TASTING NOTES: Classic Zinfandel is typically characterized by spice, and this wine is no...\nItem #: 7430290519 -\nWINEMAKING NOTES: In French, saignée literally means “to bleed” and has been used as a traditional method of Rosé winemaking for centuries. Red grapes are crushed, then the lightly colored juice is “bled” off after just a moment of skin contact. This classic winemaking process has yielded Bogle’s crisp and refreshing Rosé. TASTING NOTES: True to the Provence-style of winemaking, this Rosé just faintly colors the glass with hues of soft, pale salmon. Aromatics of watermelon, strawberry patch...","A Beginner's Guide To Riesling Wine\nGiving its best in cold climates but loving a good exposure to the sun, Riesling is among the most prestigious and elegant white grapes in the world. And Riesling wine fully preserves the excellent characteristics of the varietal.\nSo, welcome to the prestigious world of the refined and elegant white wines! Riesling – whose origins are German – is now considered an international vine.\nIt is esteemed by winemakers and wine lovers alike, for its extraordinary elegance, class, and, in particular, for its surprising ability to age in bottle or casks, improving its exceptional bouquet along the years.\nIn fact, Riesling is one of the few white wines, if not the only, who develop their characteristics in time.\nThe best Riesling wine, thanks to its strong acidity and to a considerable amount of antioxidants, can mature for dozens of years. Practically a record among the whites.\nFor this reason, Riesling is sought after by wine enthusiasts and various producers. And although the grape gives its best in cool climates and sunny areas, it is today widespread in every wine region of the world.\nA Short History\nIt’s not quite clear what is Riesling’s exact area of origin. Theories suggest it might have originated in the valley of the Rhine area, in Mosel or Pfalz; all three areas are in today’s Germany, which leads to the conclusion that Riesling is German.\nReliable historical evidence tells that Riesling was widespread and widely cultivated in all areas along the Rhine river as early as the fifteenth century. However, some earlier sources suggest that it was already cultivated in the ninth century by order of the sovereign Louis the German.\nBut Riesling might have been cultivated in Germany since the second millennia BC; if this were confirmed to be true, Riesling would be one of the oldest grapes in the world, together with other German varieties such as Elbling, Räuschling, and Silvaner.\nRecommended: Looking for cheap Riesling wine suggestions? We recommend our favorite affordable options.\nThe importance of Riesling has been blurred for years by other varieties obtained through hybridization. This is the case of Müller Thurgau, a grape variety whose notoriety encouraged winemakers to give up on Riesling almost completely and replace it with this variety.\nBy 1980s, Riesling became an almost unknown variety that covered no more than 19% of the vineyards in Germany. In the 90s, its notoriety started to improve and the harsh winters of the decade exalted the resistance of Riesling compared to the “new” varieties. The productive efforts to improve the quality of Riesling wines contributed to the affirmation of this fine white grape.\nRiesling is a vine that tends to produce an abundant crop and, surprisingly, it maintains high levels of acidity when it reaches full maturity. This contributed to the affirmation of Riesling’s reputation. The excellent results obtained by winemakers in Mosel region represented the advent of this wine.\nThe vine has been crossed pollinated with other varieties to obtain new vines. Noteworthy is Incrocio Manzoni, resulted from the crossing of Riesling and Pinot Blanc and widespread in the northeast of Italy.\nRiesling is a variety that has an excellent cold resistance, and that’s the reason why it is mostly grown in cold climate wine areas. But resistance to cold doesn’t mean that the grapes don’t need appropriate care and conditions to give the best yields. Yet, the quality of the grapes is not affected by the vine’s tendency to produce abundant yields.\nThe vine is resistant to harsh winter frosts and it has a late ripening. In fact, the harvest is usually carried out between middle October and the beginning of November.\nThe grapes are small and grow in rather compact bunches, characteristic that makes Riesling very sensitive to molds. And that’s one of the reasons why in warm climates the vine doesn’t give the best of itself. In warm climates, Riesling ripens faster and this often affects the quality of the wines, which are flatter and expose less elegant aromas.\nIn cool climate areas, where the grapes have a slow ripening, Riesling develops elegant aromas and intense flavors, while maintaining its high level of acidity.\nAnd that’s one of the reasons why Germany produces some of the best Riesling wines in the world. It is even believed that the vine manages to give its best on the steep slopes of the Mosel-Saar-Ruwer region, where sunlight caresses the grapes most of the day. However, Riesling is now widespread in almost all wine countries.\nThere should be made a clear distinction between Riesling and Italian Riesling, which is a completely different variety. In fact, in Italy, Riesling is called Riesling Renano (Rhine Riesling) while what they call Riesling Italico is a different grape variety.\nFor beginners and connoisseurs alike, Riesling wine represents the exaltation of the enology. Almost all Riesling wines are bottled immediately after fermentation, and very rare cases involve maturation in a barrel. Despite this, Riesling develops its character over the time, and aging on a shelf defines its flavors and aromas.\nWines produced with the Riesling variety are quite varied. From dry to sweet, there is a wide range of varieties to choose from. But what is awesome about the sweet ones is their impressive balance maintained by the high acidity of the grapes. However, the tendency of most winemakers is to produce dry Rieslings.\nThe alcohol content is generally quite low, around 7° to 9°. Few Rieslings reach 12°, which make this wine pleasant to drink even in larger quantities.\nWhat is peculiar about this wine is its tendency to mature in the bottle despite its low alcohol concentration. In fact, most white wines with similar alcohol content just go bad or turn into vinegar. So, what preserves this wine? It's acidity! Thanks to this characteristic, Riesling wine can mature in the bottle for decades, improving its organoleptic qualities. That’s why only a few Rieslings don’t exceed at least three years of aging.\nFrom a visual point of view, Rieslings come in a wide palette, depending on the type of wine in the bottle. Young dry Rieslings bottled immediately after fermentation – most of the affordable Rieslings available on the market – have a greenish-yellow shade and low viscosity.\nSome young dry wines that have been aged in barrels for a few months to a year may have a straw yellow color.\nVintage dry Rieslings, aged either in the bottle or in barrels, have characteristic straw yellow and golden hues. Sweet Rieslings develop golden yellow shades that vary to intense amber tones.\nRiesling wine is extremely interesting from an olfactory point of view. Non-vintage varieties develop aromas similar to many other white wines, which make for an interesting wine flight between a non-vintage Riesling and a Pinot Blanc, for example.\nHowever, these common characteristics don’t make Riesling less interesting from an aromatic point of view. Young wines made from unripe grapes develop rather “sour” fruity aromas of green apple, citrus, lime, and lemon, as well as flowery aromas of jasmine, chamomile, wisteria, and hawthorn.\nWine produced in certain areas, such as those from Mosel, also acquire mineral notes conferred by the soil, enriching the aromatic notes mentioned above.\nThe same aromas develop in young wines made from grapes grown in a cool climate region.\nRieslings produced with ripe grapes, or those made from grapes grown in warm climate areas, have rounder and less harsh aromas of grapefruit, peach, apricot, pear, apple, and exotic fruits. Sweet Rieslings have more strong aromas of peach and apricot that dry ones, in which the aromas of grapefruit and apple prevail.\nRefining periods allow the development of the organoleptic properties and vintage Riesling wines impress with aromas of aromatic butter, honey, and honeybee wax. These elegant aromas, as strange as they might seem, are very pleasing and give style to this beverage.\nSome sweet Riesling wines, and in particular those made from grapes affected by Botrytis Cinerea or other noble molds, develop elegant spicy aromas of cinnamon, anise, and ginger. Aromas of moss, dried fruit, candied apricot, walnut, almond, and fruit jam are also common in vintage sweet Rieslings.\nIn vintage and non-vintage wines grown in cool climate regions also develop slight aromas of sage, thyme, green tea, nettle, and tobacco.\nAs said above, it’s rare for winemakers to age Riesling in barrels, but when this happens, the wine also develops characteristic “barrel” aromas of vanilla, chocolate, and toasted wood.\nRiesling Wine Flavors\nConsidering the rich variety of wines made from Riesling grapes, the gustatory qualities of these wines are just as rich.\nIn dry wines, acidity is the predominant gustatory character, and some wines develop an interesting minerality, depending on the terroir. These are the main characteristics of German Mosel Riesling, whose taste is often defined as metallic.\nBut this doesn’t mean the wine isn’t refined. Despite its strength, this acidity is pleasant and the wine is extremely balanced, refreshing the palate without disturbing the taste buds in any way. This acidity is also an essential factor that defines the balance of sweet Rieslings from Germany, such as Eiswein and Trockenbeerenauslese.\nThanks to the low alcoholic content, that is rarely higher than 12°, Riesling wine expresses a tasteful elegance and an incredible balance.\nRiesling Wine And Food Pairing\nRiesling is a versatile wine that is easy to pair with a wide range of foods. Some of the freshest sparkling versions of Riesling make an excellent aperitif and pair perfectly with sea finger foods, in particular with mollusks and especially with scallops.\nOther seafood and shellfish also pair well with dry Riesling wine, thanks to the mineral notes of the beverage. These notes blend perfectly with the iodized flavor of fish, making it a perfect match for raw fish and sushi. Probably this explains why Riesling is one of the most popular wines in Japan, a country renowned for its cuisine and culinary culture.\nServed with the main course, Riesling wine makes a harmonious match with poultry and white meats in general. Goat cheese and Riesling is another winning combination, while similar cheeses also benefit from this pairing.\nSweet Riesling pairs wonderfully with fruit-based desserts, such as citrus or lemon cake. Late harvest Rieslings and some vintage varieties pair well with sponge cakes and dry sweets such as biscuits and cookies.\nThe French Riesling d’Alsace is one of the most popular white wines in the world that exalts all flavors and characteristics of the French cuisine. From the Alsatian choucroute to matelote, palette de porc fumée, and other traditional French dishes, this wine works wonders when paired with these foods.\nThis wine can also be paired with the French brown soup or the shrimp cocktail, with seafood and, in particular, with lobster.\nWhen it comes to the Italian cuisine, there are countless combinations to consider. Riesling is the perfect wine for the Italian first courses, such as tagliolini al limone or risotto with figs. Octopus and potato salads, croutons, and bruschetta with truffle cream also pair wonderfully with Riesling.\nThe wine is also easy to pair with fish main courses, such as grilled swordfish, tuna or salmon. Raw prawns and scampi served with Riesling are another popular pairing, while roasted lobster or cod also have their flavors exalted by this elegant beverage.\nBesides desserts, vintage and sweet Riesling wine pairs perfectly with deer and other game meat. As for Italian cheeses, the intense and pungent flavors of Taleggio cheese pairs wonderfully with a vintage dry German Riesling.\nOther foods to consider are monkfish and clams, buffalo mozzarella, and other creamy cheeses. Without a doubt, there are dozens of combinations to make with Riesling wine."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:988fd16c-5ada-4da8-92f1-fbbdec5bf6c1>","<urn:uuid:218f8700-ff73-49d3-a3d7-f9a7f00ff027>"],"error":null}
{"question":"¿Qué medidas se deben tomar para el control de energía peligrosa en el workplace, and how do secondary energy sources factor into hand injury prevention?","answer":"For hazardous energy control, proper lockout/tagout procedures must be implemented, and special attention must be paid to secondary sources of energy, including bleeding off stored energy in cylinders, receivers, and pipelines to prevent injuries. Additionally, modern safety systems like KIRK's trapped key interlocks ensure hazardous energy is properly isolated during maintenance operations. These systems are particularly important in various industrial applications, such as switchgear maintenance, UPS systems, and concrete mixing plants, where they prevent inadvertent re-energization and ensure worker safety by enforcing a predetermined sequence of operations. The combination of proper energy control procedures and interlock safety systems provides comprehensive protection against both primary and secondary energy sources.","context":["There is literally nothing that occurs in the\nwork place that does not require the use of hands. It is not surprising then\nthat hand injuries are the most common injury in the work place. These injuries\ninclude cuts, punctures, amputations, fractures, crush injuries and burns. How\ndoes one avoid these types of injuries? Our first impulse is to say “better\nglove usage” but is that really true? A review of accident reports will likely\ntell you that employees often are wearing appropriate gloves when they injure\ntheir hands. What is the answer then if gloves are not enough? Further review\nof the accident report will likely show that the injured worker had his hands\nin a position where injury was likely. The hands were in the “danger zone”.\nA simple example that we all can relate to is\nwhere you place your hands when you close a door. Keeping your hand on the\nhandle is a good hand position and allows you to close the door safely. Using\nthe edge of the door to close it and failing to withdraw your hand quickly\nenough results in a painful pinching of the fingers. The hand was left in the\ndanger zone. Distraction only makes the situation worse.\nThe primary method to avoid hand\ninjuries is to keep hands away from hazards or “out of the danger zone”. The secondary method to avoid hand injuries\nis to provide protective covering for the hand so that if a hazard is\nencountered the glove can protect against that hazard. OSHA 1910.138 states\nthat employers shall select and require employees to use appropriate hand\nprotection when employees’ hands are exposed to hazards such as those from skin\nabsorption of harmful substances; severe cuts or lacerations; severe abrasions;\npunctures; chemical burns; thermal burns; and harmful temperature extremes.\nIt is the responsibility of the employer to\nreview job tasks to ensure that hands are kept out of the danger zone with the\nway the process is set up. If hazards are found, can they be eliminated to make\nthe job safer? Ensure that employees do not have to place their hands under\nsuspended loads. Machines with moving parts must be guarded with guards left in\nplace at all times. An effective barrier must be maintained between hands and\nhazards by using tools or other aids (i.e., using a pusher device to push wood\nthrough a saw when the cut is close). Adherence to lock out/tag out is critical\nto protect hands.\nCare must also be taken to ensure that secondary\nsources of energy are also addressed (i.e., bleeding off stored energy in\ncylinders, receivers, pipelines) to ensure that injury does not occur from this\nsource. Good work station housekeeping will ensure that injuries do not occur\nas a worker is rummaging through debris to find work tools. Work rules should\ninclude a prohibition on loose clothing on the upper body around any moving\nmachinery. It is too easy for the loose clothing to get caught in the machinery\nand pull the person into the machinery, including a loose sleeve that would\npull a hand into the machinery.\nRings also pose a special problem in that they\ncan get caught on moving machinery or parts and be pulled off the finger, along\nwith the flesh and muscle of the finger.\nEmployees should always be supplied with the correct tools for the job\nand tools that are in good condition. Employees who have to exert force,\npushing or pulling, should be taught to be prepared for an unexpected slip or\nGloves can provide a great second line of\ndefense against hand injury. Gloves are designed to protect against specific\nhazards and should be chosen accordingly. It is important that gloves are\nproperly sized, in good condition and regularly worn.\nA toolbox talk to use with your employees is\nfound at www.asa.net.\nThis tenth step on the path to an effective\nsafety program can positively impact your productivity, the health and\nwell-being of your employees, and a better bottom line.\narticle was written in conjunction with participants in the OSHA and ASA\nAlliance. It does not necessarily reflect the official views of OSHA or the\nU.S. Department of Labor.\nPath to Safety: Step Ten\nApril 1, 2010","Isolating & Controlling Hazardous Energy;\nProtecting People & Assets\nKIRK’s comprehensive product offering of mechanical, electro-mechanical, motion sensing, and integrated technology interlocks form a complete interlock safety system customized for your unique safety application needs.\nSalvo Loading Dock Safety Systems\nSalvo loading dock safety systems prevent drive-aways during loading/unloading by interlocking the trailer’s air brakes with the dock door. This ensures that the trailer cannot depart until loading/unloading is completed and the dock door is closed. Salvo keeps your personnel and equipment safe by – eliminating human error.Learn More\nKIRK®’s access interlock product offering provides solutions for all guarding applications, ensuring access permissions only once hazardous energy has been isolated. Incorporating access interlocks with time delay units or electro-motive force units adds additional safeguards to ensure residual energy has been fully dissipated and isolated prior to access.Learn More\nWithin a substation, KIRK® trapped key interlocks are used to ensure the isolation of hazardous energy for several switchgear maintenance applications. Preventing the paralleling of two energy sources, ensuring a breaker is locked open (or closed) for maintenance operations, preventing the disconnection of breakers under load, and minimizing the potential of a hazardous arc flash are just a few applications where trapped key interlocks can be found.Learn More\nUninterruptible Power Supply\nPower outages in environments where power is critical can have drastic implications and risks. Data centers, medical facilities, telecommunications centers, and more rely on an uninterruptable power supply, or UPS, during unstable weather or power conditions. A KIRK® trapped key interlock system ensures that regular maintenance can be performed safely, and the UPS system can be placed in maintenance bypass mode, eliminating the risk of a redundant power source and protecting against hazardous energy.Learn More\nKIRK® safety interlocks protect the safety of your employees and equipment by ensuring a predetermined sequence of operations is followed every time, without fail. When performing maintenance on or emptying hoppers, electrodes in excess of 10,000 volts present a serious risk to life. To ensure the safety of employees performing maintenance, it is imperative that the hazardous energy is isolated and cannot be inadvertently re-energized during maintenance procedures. KIRK® trapped key interlocks ensure that the power is isolated and grounded before hopper doors can be accessed. A typical ESP application includes trapped key interlocks on switchgear, transfer switches, access doors, and valves.Learn More\nWorking with concrete introduces safety hazards that can place workers in danger and put their lives at risk. Concrete mixing plants must perform regular maintenance on mixers to ensure proper working conditions and efficiencies. Maintenance can involve accessing the mixer’s entry points for cleaning and servicing of paddles. To ensure worker safety, power\nmust be isolated prior to entry of the mixer and at no time during maintenance can power be inadvertently re-energized.\nImplementing a trapped key interlock safety system into the safety procedures for power isolation can eliminate human error and drive a pre-determined sequence of operations to ensure worker safety.Learn More\nElectric fracking fleets are beginning to replace traditional diesel fuel fleets due to the higher operation costs of diesel fleets as compared to electric fleets. Also, electric fleets help to minimize emissions, noise pollution, and dust build up common in the diesel fleets.\nThe introduction of electric fracking fleets have therefore introduced unique safety measures to ensure worker’s safety when connecting or disconnecting power for operations.\nKIRK trapped key interlock safety systems ensure a predetermined sequence of operations are followed each time power is isolated to ensure couplers are de-energized before connecting or disconnecting from the main power source.Learn More\nAround the wind tunnel, there are several full body access doors to allow for maintenance. It is critical to ensure no one enters the tunnel while in operation. Incorporating a trapped key interlock system ensures the proper sequence of energy isolation is performed.\nIntroducing electromechanical interlocks within the system allows contacts to be tied into a PLC system, signaling when an interlock system has been engaged and the tunnel doors have been accessed. This process prevents unexpected startup until all maintenance is complete and everyone is safely out of the tunnel.Learn More\nBlack Liquor Recovery Boiler\nIn the Pulp and Paper industry, Black liquor recovery boilers require careful control of operations to ensure safety and mitigate risk of an explosion.\nTo minimize this risk, implementing a trapped key interlock safety solution ensures a sequential safety process takes place each time – keeping employees & equipment safe.Learn More"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:e2014824-d506-46a9-b7e5-a8c167b2e13c>","<urn:uuid:d79dd9ad-46c6-4d67-b6a9-4f59bcdebb00>"],"error":null}
{"question":"What are the key differences between business risk management and business continuity management in terms of their primary focus and goals?","answer":"Business risk management and business continuity management have distinct focuses and goals. Business risk management primarily examines and understands risks due to changes in processes, systems, and business operations, with the goal of identifying, tracking, prioritizing, and addressing risks to minimize adversities from unexpected events. In contrast, business continuity management (BCM) specifically focuses on ensuring the continuity of business processes even during disasters, with the primary goal of preventing disruption to key business processes and ensuring the enterprise's survival. While both are part of risk management, BCM uniquely considers the chronology of disruptions and concentrates exclusively on the availability aspect of resources, whereas business risk management takes a broader approach to risk assessment and mitigation.","context":["What is business risk management?\nBusiness risk management is a subset of risk management that is used to examine and understand the risk occurring due to changes in the processes, systems, or other business operations. A business risk framework identifies, tracks, prioritizes, and addresses risks to minimize adversities from unexpected events. Companies can gain the ability to make more informed risk-based decisions with the help of business risk management plan.\nWith a business risk management plan, businesses can prepare for the unexpected by minimizing risks and extra costs before they happen. By having a risk management plan in place, companies can also save money and make the organization’s future secure.\nBusiness risk management process\n- Identifying risks – Identifying the evolving risks by analyzing internal and external factors that affect the key business objectives.\n- Analyzing risks – It includes the standardization and creation of probability distributions of outcomes for each material risk.\n- Responding to risk – Once potential risks are identified and analyzed, an appropriate strategy needs to be incorporated to address the risk. This is done either by establishing new processes or eliminating the risk, depending on the type and severity of the risk.\n- Monitoring risk and opportunities – The final step in a business risk management process involves continually measuring the risks and opportunities of the business environment. Companies must also keep a check on the performance of different management strategies.\nBusiness risk management challenges and how to overcome them\nSpeed of information\nIn an era where news and information travel faster than wildfire, businesses do not have the luxury of time to undertake decision-making and formulate strategies as a part of business risk management once the news of a risk event is released. In several cases, a single risk event is attached to other unrelated risk events and when combined it may rapidly begin to erode the organization’s reputation and goodwill. To address such situations, some organizations are working proactively to consider their organization’s responses and business risk management strategies more robustly and well in advance of an actual event. Having different response playbooks that have business risks management strategies and responses identified in advance helps them to quickly respond to risk issues and diffuse some of the adverse effects on a timely basis.\nComplexity of business\nCyber threats, disruptive innovation, regulatory shifts, and changing social demographics may trigger significant risks for an organization. Furthermore, these risk drivers may be related to or can trigger other risks, adding to the complexity of the business risk management challenge. Despite this, the top management in most companies fail to recognize the value of embracing a more holistic and team-based enterprise-wide approach to risk assessment and mitigation. To overcome such setbacks, some organizations are rethinking how they approach risk identification and assessment to find ways to bring together the collective minds of a number of individuals to think through potential risk drivers explicitly and proactively. This is done based on the perceived benefits of putting several minds to work when identifying and assessing risks. It is essential to have varied perspectives on complex risk issues in order to face the realities of today’s complex business environment.\nIntegration of risk oversight and strategy\nSome organizations may experience a disconnect between their organization’s business risk management and strategic planning activities. In many companies, business risk management is viewed as a compliance or regulatory activity. This means that often risk management in organizations are transferred to a lower level, non-strategic position. As a result, the organization’s business risk management efforts are often inadequately integrated with strategic planning. To address this challenge, rather than starting off by analyzing what drives value for the organization, companies must first understand what risks are on the horizon. By starting the conversation with what is strategically important to the business and then asking what might prevent that from succeeding, business leaders will be able to identify how business risk management can be positioned to provide strategic value.","When The Unexpected Happens\nBusiness Continuity Management Keeps Everything Up and Running\nBe Prepared - Whether an enterprise prospers and flourishes hinges in no small part on the continuity of its business processes. Preventing disruption to key business processes even when disaster strikes, and ensuring that such a contingency will not jeopardize the existence of the enterprise - this is what business continuity management (BCM) is all about. BCM serves to systematically prepare for managing incidents or disruptions and is part of enterprise governance systems for risk management. With BCM increasingly mandated by law or other regulatory frameworks, it is essential for enterprises to establish BCM practices.\nThe Phases of BCM\nBusiness continuity management is carried out in a six-phase process which comprises an ongoing cycle:\n• Phase 1: Identify business processes\nThis step identifies the business processes that are critical to the company's success and therefore of relevance for business continuity management.\n• Phase 2: Business impact analysis (BIA)\nThe BIA is a systematic investigation of the adverse impacts that can arise over the course of a disruption to business processes. Having pinpointed the impacts, a recovery time objective is defined for each process - the acceptable length of time to restore the process. The BIA also investigates which resources and services the processes rely on in order to function. The BIA results in a set of evaluated availability requirements.\n• Phase 3: Risk analysis\nRisk analysis investigates what threats the business processes and their resources are exposed to, and the probability that these threats will prevent recovery time objectives from being met - in other words, what probability there is that the maximum acceptable downtime will be exceeded.\n• Phase 4: Planning and orchestrating measures\nWherever an unacceptable risk is identified, appropriate mitigation measures must be planned, decided upon and enacted. Measures can be either preventive or reactive in nature. They serve to secure the availability of resources, the objective being to prevent critical interruptions of business processes and the adverse impact that can result from such interruption.\n• Phase 5: Create business continuity plans\nRecovery following a major incident tends to be complex.\nSince such incidents occur only seldom in real life, the essential activities must be documented in business continuity plans in order to ensure everything runs smoothly.\nOne of the tasks in developing business continuity plans is to establish dedicated disaster response teams comprising management personnel and selected specialists. These teams are only activated in the event of a real-life contingency. Their task then is to restore business operation as quickly as possible and stage recovery (backup) operation to ensure the survival of the enterprise.\n• Phase 6: Business continuity testing\nBusiness continuity measures, particularly recovery procedures and resources, must be tested regularly to verify that they will work as intended in a real-life disaster scenario. The rehearsals also serve to train the staff who will be charged with particular roles.\nBusiness continuity management is based on specially defined roles that are part of the enterprise organisation. BCM roles can comprise a multilevel structure such as the following:\n• One BCM officer for the enterprise. Ideally, this individual belongs to a central department of the management board, or at least reports directly to the board. He or she develops and represents the strategic aspects of BCM to corporate management and coordinates all BCM activities.\n• BCM officers in the organisational units: these individuals are the points of contact for BCM issues in the units they serve. They are responsible for all BCM-related activities within their units and ensure that BC plans are kept up to date.\nTouch Points with Other Organizational Issues\n• An ongoing process which must be embedded in the corporate culture.\n• An issue which cuts right across the enterprise, embracing every part of it. As such, BCM has interfaces with other enterprise processes.\nIn particular, due consideration must be given to the interdependencies with the following areas:\n• Risk management\nRisk management considers all the risks of the enterprise. BCM addresses part of the operational risks. Unlike general risk management, however, BCM also considers the chronology of a disruption or incident.\n• Crisis management\nCrisis management entails defining precautionary measures - alarm procedures, forms of organisation, systems and procedures which will come into operation in a crisis situation. The objective of crisis management is to prevent a crisis from compromising the company's ability to operate or to take and enact decisions; it also enables the crisis to be managed in a focused and coordinated manner.\n• Health and safety\nHealth and safety embraces the technical, organisational and personal prerequisites which ensure safety at work for employees. Touch points between health and safety and BCM include the planning of appropriate measures to prevent emergencies, and designing how work will be conducted under emergency conditions.\n• Information security management\nThe purpose of information security is to protect the availability, confidentiality and integrity of the enterprise's own information and the information entrusted to it by customers and business partners. Here, too, the objective is to prevent or limit the damage that can arise owing to undesired eventualities. Unlike information security, BCM does not consider confidentiality and integrity to be its goals - rather, it concentrates exclusively on the availability aspect. However BCM takes a wider view on the resource perspective: it considers all the resources that are required for business continuity, not just information resources.\nBusiness continuity management, custom-developed and designed, offers an organisation the security of knowing it is equipped to deal with disaster. The focus on critical processes and resources, and on risk exposure and probability, keep the investment of effort to the level of what's necessary."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:70a7e1e4-4d34-4708-8ffc-19683a216447>","<urn:uuid:8b1a7a28-30cf-43e9-9d32-bd0b18d8ae6c>"],"error":null}
{"question":"Which fish needs warmer water to thrive - the Zebra Angelfish or Gold Gourami? Really need to know for my tropical tank setup! 🌡️","answer":"Zebra Angelfish require warmer water temperatures compared to Gold Gourami. Zebra Angelfish need water temperatures between 79-83 degrees Fahrenheit and cannot survive significant temperature changes. In contrast, Gold Gourami can thrive in slightly cooler water, with an acceptable temperature range of 72-82 degrees Fahrenheit (22-28°C). Both species need stable temperatures, but Zebra Angelfish have a narrower and warmer temperature requirement range.","context":["Zebra angelfish are one of the most popular aquarium fish available in a wide range of colors and patterns.\nThey are simple to maintain and require minimal effort on the part of the owner. This makes them an excellent choice for beginner fish owners or people who don’t have time for a more high-maintenance companion.\nIn this article, we’ll go over everything you need to know about caring for zebra angelfish, including the best diet, habitat, and tank mates.\n|Scientific Name||Pomacanthus semicirculatus|\n|Minimum Tank Size||30 gallons|\n|size||10 inches (25 cm)|\n|Ease of Care||Moderate|\n|pH||6 – 7.4|\n|Temperature||79 – 83 degrees|\nZebra Angelfish Origins & Habitat\nZebra Angelfish (Pterophyllum scalare) is native to the Amazon River Basin, Orinoco Basin, and other tributaries of South America’s Guiana Shield.\nThey can be found in swamps and flooded regions with dense vegetation around clear or silty water in their natural environment.\nThese beautiful angels prefer marshes and underwater bushes, where they can swiftly hide. Also, they are a relatively calm, sociable species that may be observed congregating in large groups while swimming.\nWhat Are the Features of Zebra Angelfish?\nZebra angelfish have long, triangular dorsal and anal fins, a lengthy forked tail, a tiny mouth, and a spine positioned on the lower cheekbone.\nThe female zebra angelfish is light blue with a black band around her eyes and black vertical stripes on the top and bottom of her tail.\nHowever, the male zebra angelfish is pale blue with a zebra pattern of numerous thin, dark vertical lines.\nAlso, zebra angelfish species can be found in other hues, including:\n1. Silver Zebra Angelfish\nThey have dark brown or black longitudinal stripes and are generally black, gray, or silver body.\n2. Blue Zebra Angelfish\nThis fish has a blue body with a large striped pattern.\nZebra angelfish grow to a length of up to 10 inches (25 cm).\nIs Zebra AngelfishAngelfish Hardy?\nZebra angelfish (pterophyllum scalare) are relatively hardy and easy to keep and can tolerate a wide range of water conditions. This is one of the reasons why they are such a popular choice for aquariums.\nHow to Care for Zebra Angelfish?\n1. Water change\nAlthough they are hardy fish, high water quality is still essential for their health.\nYou should change at least 10-15% of the water in your aquarium every week. Also, make sure to remove any uneaten food or waste from the tank before doing a water change.\n2. Water Temperature\nThe Zebra Angelfish, like most South American cichlid species, prefers soft waters with a temperature range of 79 to 83 degrees Fahrenheit.\nBecause this aquatic creature cannot survive significant changes in water temperature, it’s critical to keep a consistent environment by utilizing an aquarium heater.\n3. pH Level\nSince fluctuations in pH levels can stress them out and cause health problems, you should use a pH test kit to keep the pH level stable.\nZebra Angelfish grow big and tall, so they need a lot of space to swim and explore. A minimum tank size of 30 gallons is ideal for a single fish.\nHowever, if you want to house them in a group of three species or more, you’ll need a tank aquarium of at least 55 gallons.\n2. Tank Decoration\nZebra angels prefer to hide in aquarium plants and river rock formations since they will feel safer.\nAmazon sword plants (Echinodorus) or other large-leaved plants like elodea would be ideal for providing cover, nesting spots, and keeping the fish calm.\nIn addition, you can add sandy or fine gravel substrate, driftwood roots, and small caves to make their environment more natural and comfortable.\nZebra Angelfish thrive on excellent water quality and gentle water movement. Therefore, to maintain suitable water quality and retain beneficial microorganisms, you should install a high-quality filtration system.\nThis species will benefit from using an external canister filter, which has a tiny powerhead to provide gentle water movement.\nZebra Angelfish Compatibility\nThe zebra angelfish (pterophyllum scalare) is a sociable species that live in groups.\nAs juveniles, they are peaceful schooling fish. However, when Zebra angel fish reach maturity, they pair off and become more territorial.\nHowever, it is not suggested to keep them with other tiny fish since zabra angels will feed on any other fish that may fit in their mouths, such as neon tetras and mosquito danios.\nZebra Angelfish Diet\nThe zebra angelfish is a species of omnivore that should be fed a variety of meats and vegetables.\nGenerally, their diet should consist of:\n- Tubifex Worms\n- Flake foods\n- Frozen meals\nWhen it comes to feeding frequency, they should be fed twice a day in the amount of food that they will consume in 5 minutes.\nHowever, if they are kept in an aquarium with many other fast-swimming species, it would be necessary to feed them three times a day.\nZebra Angelfish Breeding\nZebra angelfish are egg layers that dwell in nuclear families. They are open breeders and lay their eggs on submerged leaves in the wild.\nIn captivity, they are ready to breed when they are 6 to 12 months old, generally around 2 inches long.\nWhen you notice that two fish paired off and the male is chasing the female, it’s a good indication that breeding is about to happen.\nTo induce spawning, there are a few things you can do:\n- Place a flowerpot, a piece of slate, or a leafy plant in the tank for the pair to lay their eggs on\n- Feed a diet of protein-rich foods\n- Maintain a pH level of 6.5\n- Maintain water hardness of about 5° dGH\n- Keep the temperature between 80 and 85° F\nAfter that, the female will lay around 1000 eggs on a clean surface when ready to breed. Then the male embraces her and fertilizes them.\nIf the parents don’t devour the eggs right away, they’ll hatch after three or four days and the little fry will be free swimming in around a week.\nFor the first few weeks, you can feed the fry newly hatched baby brine shrimp until they can consume finely crushed flake food on their own.\nZebra Angelfish Gender Difference\nThe way a zebra angelfish behaves and its size are the only ways to distinguish between male and female zebra angelfish.\nAs zebra angelfish mature, males grow larger and more aggressive, while females become smaller and more docile.\nIf a male dies or is removed from the leadership of his group by an external force such as illness then it’s possible that the next zabra angel in line for power could turn into a male.\nPossible Diseases and Prevention\nWhite Spot Disease\nZebra Angelfish are susceptible to the same diseases that affect other saltwater angelfish in captivity, particularly if their habitat is disrupted or they are housed with unsuitable tankmates.\nThe most common disease affecting tangs and angelfish is white spot disease, also known as Marine Ich, Saltwater Ich, and Crypt.\nThe most prominent signs of Marine Ick include constant scratching that leads to a large number of white patches.\nThe velvet disease, Oodinium ocellatum (also known as Amyloodinium ocellatum or Branchiophilus Maris), is a flagellate that affects fish.\nMarine Velvet symptoms include:\n- Peppery covering and hooked fins\n- Respiratory difficulties (breathing rapidly as seen by frequent or rapid gill movements)\n- Eye cloudiness\n- Possible weight loss\nParasites on aquarium fish kept in tanks with live rock or in a reef tank are notoriously hard to get rid of.\nZebra angels infected with parasites will show the following symptoms:\n- Loss of appetite\n- Scratching on rocks or decorations\n- Excessive mucus production\n- Weight loss\nMetronidazole and other anthracyclines are effective and safe in the treatment of a variety of protozoan and anaerobic bacterial infections.\nAlso, you can raise the temperature of your tank gradually for external parasites to at least 82° F (28° C) since this will prevent the parasite from completing its life cycle.\nHow Big Do Zebra Angelfish Get?\nZebra angels can grow up to 10 inches long.\nWhat Is the Difference Between Male and Female Zebra Angelfish?\nThe main difference between male and female zebra angelfish is their size. Males are larger and more aggressive, while females are smaller and more docile.\nWhat Do Zebra Angelfish Eat?\nZebra angels are omnivores and will eat a variety of food, including live, frozen, and flake foods.\nHow Many Eggs Do Zebra Angelfish Lay?\nFemales can lay up to 1000 eggs which will hatch in 3-4 days. The fry will be free swimming in around a week.\nWhat Is the Minimum Size for a Zebra Angelfish Tank?\nThe minimum tank size for a zebra angelfish is 30 gallons.\nZebra angels are a beautiful and popular saltwater fish that make a great addition to any aquarium.\nThey are relatively easy to care for, but there are a few things to keep in mind, such as their minimum tank size and their diet.\nWith proper care, your zebra angel will thrive and provide you with years of enjoyment.\nWe hope you enjoyed reading this and found it helpful. If you have any questions that were not answered here, please feel free to ask in the comments below.","Discover the alluring world of Gold Gourami care! These captivating freshwater fish boast a dazzling golden hue with streaks of orange and black. To ensure your Gold Gouramis stay healthy and happy, here’s what you need to know about their habitat, feeding habits, and potential challenges.\nA spacious tank with plenty of plants and hiding spots is key. Create a stable environment with temperatures between 72-82°F (22-28°C). Regular water changes are important to maintain good water quality and prevent illnesses.\nGold Gouramis have an omnivorous diet. Provide high-quality pellets or flakes as the staple food. Supplement with live or frozen foods like brine shrimp or bloodworms. Feed them in small portions multiple times a day to avoid overfeeding.\nDuring breeding season, male Gold Gouramis build bubble nests. Add floating plants like Indian Fern or Amazon Frogbit to help create successful breeding cycles.\nWhen introducing new tank mates, research species that exhibit peaceful behavior towards Gold Gouramis. This will create a harmonious community tank.\nFollow these guidelines for proper Gold Gourami care. This will let their dazzling beauty shine while they swim gracefully through their aquatic home. With the right care and attention, your Gold Gouramis will be healthy and happy!\nBasic Information about Gold Gourami\nThe gold gourami is a popular choice among fish lovers. Its golden hue and long fins make it a striking addition to any aquarium. These creatures are native to Southeast Asia, in slow-moving rivers and flooded forests.\nThey need warm water temperatures between 72-82 degrees Fahrenheit, and a pH level of 6.0-7.5. Soft water mimicking their natural environment helps them thrive.\nGold gouramis have interesting behaviors. They can gulp air at the surface using a specialized organ, allowing them to breathe when oxygen levels are low.\nTo keep them healthy, feed them a balanced diet with plant matter and protein-rich foods like brine shrimp or bloodworms. Don’t forget to include high-quality commercial flakes or pellets.\nCreate a natural environment with hiding spots like caves or vegetation. This will offer them shelter and give them space to swim. Floating plants also provide shade and filter out excess nutrients, reducing algae growth.\nFollow these guidelines to create a beautiful and fulfilling home for your gold gourami. Witness their captivating beauty and fascinating behaviors – they’re a delight to behold!\nSetting Up the Aquarium\nCreating a home for your gold gourami needs thoughtfulness. Follow this 6-step guide to make sure they have a comfortable environment.\n- Tank Size: Pick an aquarium that’s the right size. Have at least 20 gallons for their active lifestyle.\n- Water: Install a filtration system and do regular water changes. Gold gouramis like pH 6.0-7.5 and 22-28°C.\n- Substrate and Decor: Use sand or small pebbles as substrate, and add hideouts with rocks, driftwood, or live plants.\n- Lighting: Use full-spectrum lights for 10-12 hours each day. This will let them show their colors.\n- Tank Mates: Pick peaceful fish like tetras or corydoras. Avoid aggressive ones that may stress out your gourami.\n- Feeding: Feed with flake foods, pellets, frozen or live food (bloodworms, brine shrimp). Give them small portions twice a day.\nMonitor water parameters with a test kit. If your gourami is sick, attend to it promptly.\nA hobbyist once watched a pair of gold gouramis protect their brood. It was a stunning display of devotion. With the right care, you can experience these moments too.\nFeeding Gold Gourami\nGold Gourami require a balanced diet to stay healthy. Here are three key considerations when feeding these colourful creatures:\n- Offer a wide variety of foods – Gold Gourami eat both plants and meat, so offer them a mix of flakes/pellets, live/frozen treats like brine shrimp or bloodworms.\n- Feed in small portions – Gold Gourami have small stomachs, so feed them multiple small meals a day rather than one large meal.\n- Check water conditions – Unconsumed food can damage water quality, so remove any uneaten food after a few minutes.\nPlus, they may nibble algae, but don’t make it their only food source. Surprisingly, Gold Gourami’s colour is the result of selective breeding – they are a combination of genetics from various gourami species.\nMaintenance and Care\nTaking proper care of your gold gourami is essential for their wellbeing. Here’s what you need to know:\n- A tank of at least 20 gallons is necessary to provide enough space for them to swim around.\n- Keep the water temperature between 72 to 82°F and the pH level between 6.0 and 7.5.\n- Clean the tank regularly by removing debris, changing the water, and using a filter.\n- Provide both natural and artificial lighting.\nFor optimal health, here are some more details:\n- Gold gouramis need peace, so select tankmates wisely.\n- Feed them a balanced diet with flakes, pellets, live or frozen brine shrimp.\n- Offer them hiding spots like plants or caves.\nTo further enhance care for your gold gourami, here are some tips:\n- Use appropriate kits to check the ammonia, nitrate, and nitrite levels.\n- Add live plants to the tank, to imitate their natural habitat and enhance water quality through oxygen production.\n- Stick to a regular feeding schedule, making sure not to over or underfeed.\nBy following these suggestions, you can ensure that your gold gourami stays healthy and happy. Good maintenance and care are key for its wellbeing.\nBreeding Gold Gourami\nWhen breeding Gold Gourami, a separate tank is needed for each pair. This allows privacy and reduces aggressiveness.\nTank size should be at least 20 gallons. Water parameters should be pH 6.0-7.5, temperature 77-83°F, and good filtration. Live plants like Java fern or Amazon sword should be added for egg-laying and hiding spots for the male.\nA balanced diet of high-quality pellets, frozen foods, and live foods like brine shrimp or bloodworms should be provided.\nLighting should mimic natural conditions with an adjustable aquarium light timer set at 10-12 hours of light per day. This helps maintain a regular reproductive cycle.\nFinally, proper conditioning techniques such as gradually increasing temperatures and providing a nutritious diet can enhance reproductive activity.\nGold Gouramis are amazing creatures! To keep them healthy in an aquarium, it’s important to take proper care of them. If you heed this advice, your Gold Gourami will live happily and healthily.\nThese fish coexist peacefully with other species in a community tank. But beware: during breeding season, they may become territorial. To avoid conflicts, give them enough space and hiding spots.\nWhen it comes to nutrition, Gold Gouramis have varied tastes. Offer them a range of food, including flakes, pellets, brine shrimp, and bloodworms. This way, they’ll get all the necessary nutrients for their well-being.\nAlso, the water quality matters. These fish prefer slightly acidic to neutral water conditions with pH from 6.0 to 7.5. Monitor the water parameters and regularly change the water to make sure the conditions stay optimal.\nFun fact: Gold Gouramis belong to the labyrinth fish family. They have a labyrinth organ which allows them to breathe air directly from the surface. Thanks to this adaptation, they can survive in oxygen-deprived environments like stagnant waters or rice paddies (Source: FishBase). Truly incredible!\nFrequently Asked Questions\nFAQ 1: What do Gold Gouramis eat?\nGold Gouramis are omnivores and will eat a variety of foods. Their diet should include high-quality flake or pellet foods specially formulated for tropical fish. They also enjoy live or frozen foods like brine shrimp, bloodworms, and daphnia. It is important to offer a varied diet to ensure their nutritional needs are met.\nFAQ 2: How big do Gold Gouramis grow?\nGold Gouramis can grow up to 4-6 inches in length, depending on their environment and care. Females tend to be slightly smaller than males. Providing them with a spacious tank will allow them to reach their full size potential.\nFAQ 3: How many Gold Gouramis can I keep in a tank?\nGold Gouramis are generally peaceful fish and can be kept in pairs or small groups. A minimum tank size of 20 gallons is recommended for a pair, and then an additional 10 gallons for each additional fish. It is important to provide adequate space and hiding spots to minimize aggression.\nFAQ 4: What water conditions do Gold Gouramis prefer?\nGold Gouramis thrive in water that is slightly acidic to neutral with a pH range of 6.5-7.5. The water temperature should be maintained between 75-82°F (24-28°C). A good filtration system is necessary to maintain water quality, and regular water changes should be performed to keep the tank clean.\nFAQ 5: Can Gold Gouramis be kept with other fish?\nGold Gouramis are generally peaceful and can be kept with a variety of compatible fish species. Avoid keeping them with aggressive or fin-nipping fish, as they have delicate, flowing fins. Good tankmates include peaceful community fish like tetras, danios, and other gourami species.\nFAQ 6: How can I create a suitable environment for Gold Gouramis?\nGold Gouramis appreciate a well-planted aquarium with plenty of hiding spots created through the use of rocks, driftwood, and plants. Floating plants can be added to provide shade and simulate their natural habitat. Ensure the tank is secure and well-maintained to provide a stress-free environment for your fish."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:81a60340-6cb5-4783-b943-29be2ed84245>","<urn:uuid:962a0cdf-2d67-4e4f-a0c1-df297043322d>"],"error":null}
{"question":"What are the specific impacts of illegal levee development on flooding along the Upper Mississippi River?","answer":"Illegal levee development along the Upper Mississippi River increases flood heights and worsens flooding downstream. Specifically, 80 miles of levees between Muscatine, Iowa, and Hamburg, Illinois, have been raised without required state or federal approvals. This unauthorized development has serious consequences - for example, during extreme flood events, Hannibal, Missouri experiences an additional foot or more of floodwaters due to neighboring levee raises. These levees also destroy critical riverside and floodplain habitat for fish and wildlife.","context":["Climate change and illegal levee development threaten public safety, river health\nEileen Shader, American Rivers, (570) 856-1128\nElliot Brinkman, Prairie Rivers Network, (217) 344-2371, x202\nChristine Favilla, Sierra Club, (618) 462-6802\nDavid Stokes, Great River Habitat Alliance, (314) 918-1007\nMelissa Samet, National Wildlife Federation, (415) 762-8264\nRob Moore, Natural Resources Defense Council, (312) 651-7923\nMaisah Khan, Missouri Coalition for the Env., (314) 727-0600, x113\nWashington, D.C. – American Rivers today named the Upper Mississippi River among America’s Most Endangered Rivers® of 2019, citing the grave threat that climate change and illegal levee raises pose to public safety and river health. American Rivers and its partners called on state and federal agencies to prohibit the reckless raising of levees and promote better flood protection solutions.\n“The America’s Most Endangered Rivers report is a call to action to save rivers that face a critical decision in the coming year,” said Eileen Shader with American Rivers. “It’s time to stop the illegal levee development on the Upper Mississippi that is putting people and river health at serious risk.”\n“We are already feeling the impacts of climate change in the Midwest, including more frequent and severe flooding, and it’s only going to get worse. Abusing and degrading the Mississippi River will make us more vulnerable to these threats. Protecting and restoring the river will make us better prepared to face future floods and safeguard communities. It’s our choice to make.”\nThe Upper Mississippi River is threatened by levees that are being raised (i.e., made taller) without required permits and approvals. Eighty miles of levees between Muscatine, Iowa, and Hamburg, Illinois, have been raised without obtaining the required state or federal approvals. These levees not only destroy critical riverside and floodplain habitat for fish and wildlife, they also make flood heights higher and increase flooding downstream. For example, during the most extreme flood events, Hannibal, Missouri, is projected to experience an additional foot or more of floodwaters because their neighbors have raised their levees without regard to the impacts.\nAmerican Rivers and its partners called on the U.S. Army Corps of Engineers, the Federal Emergency Management Agency, and the states of Illinois, Iowa and Missouri to take corrective action to stop and resolve these levee violations. Further, the groups called on the agencies to advance 21st century flood protection solutions that deliver multiple benefits to people and nature.\n“We have to stop the circle of absurdity where we spend enormous sums of money to build larger levees which make the next flood even worse and costs us millions more in emergency funds, only to have the entire cycle repeat year after year,” said David Stokes with the Great River Habitat Alliance.\n“We must move beyond this outdated vision of flood control that foolishly relies on bigger and higher levees and floodwalls to a new vision that makes room for rivers and allows nature-based solutions to protect us,” said Elliot Brinkman with the Prairie Rivers Network.\nThe threats posed by these unlawful changes are real and getting worse as climate change is leading to more frequent floods and intense storms in the Upper Mississippi River Basin and across the country. The three highest-volume rain storms ever recorded in the U.S. have occurred in the last three years, in line with climate scientists’ projections that extreme downpours in the U.S. could increase by 400 percent by the end of this century. Munoz et al. (2018) determined that the magnitude of 100-year flood events in the Mississippi Basin has increased by 20 percent over the past 500 years, with much of that increase being caused by the combination of river engineering and climate change. The increased risk of flooding is the reason some levee districts have pursued higher levees, but their actions are intensifying the impacts of flooding for their neighbors.\nThe Mississippi River is a globally significant flyway used by hundreds of species of birds and provides unique habitat for fish, mussels, reptiles and mammals. This significant ecosystem supports commercial and recreational fishing, hunting and boating, which contribute $24.6 billion to the region’s economy and an estimated 421,000 jobs. The river has been the lifeblood of many cultures throughout history and has served as the inspiration for a rich heritage of American music, art and literature.\nThe annual America’s Most Endangered Rivers® report is a list of rivers at a crossroads, where key decisions in the coming months will determine the rivers’ fates. Over the years, the report has helped spur many successes including the removal of outdated dams, the protection of rivers with Wild and Scenic designations, and the prevention of harmful development and pollution.\nSome portion of the Mississippi River was previously included on this list in 1991-1992, 1994-1996, 2000-2001, 2004, 2011, 2014 and 2018. Other rivers in the region listed as most endangered in recent years include the Buffalo National River (2019, 2017) and Middle Fork Vermilion River (2018).\nAmerica’s Most Endangered Rivers® of 2019\n#1 Gila River, New Mexico\nGov. Grisham must choose a healthier, more cost-effective way to provide water to agriculture than by drying up the state’s last major free-flowing river.\n#2 Hudson River, New York\nThe U.S. Army Corps of Engineers must consider effective, nature-based alternatives to storm-surge barriers that would choke off this biologically rich tidal estuary.\n#3 Upper Mississippi River, Illinois, Iowa, Missouri\nState and federal agencies must enforce laws that prohibit illegal levees, which increase flood risk for communities and degrade vital fish and wildlife habitat.\n#4 Green-Duwamish River, Washington\nLocal leaders must produce a flood protection plan that safeguards communities and restores habitat for chinook salmon — fish that are essential to the diet of Puget Sound’s endangered orca whales.\n#5 Willamette River, Oregon\nThe U.S. Army Corps of Engineers must immediately improve 13 dams to save wild chinook salmon and steelhead from going extinct.\n#6 Chilkat River, Alaska\nThe Japanese investment firm, DOWA, must do the responsible thing and back out of a mining project that could decimate native salmon.\n#7 South Fork Salmon River, Idaho\nThe U.S. Forest Service must safeguard endangered fish by denying a mining proposal that could pollute this tributary of the Wild and Scenic Salmon River.\n#8 Buffalo National River, Arkansas\nGov. Hutchinson must demand closure of an industrial hog-farming facility that pollutes groundwater and threatens endangered species.\n#9 Big Darby Creek, Ohio\nLocal leaders must use state-of-the-art science to craft a responsible development plan that protects this pristine stream.\n#10 Stikine River, Alaska\nThe International Joint Commission of the United States and Canada must protect the river’s clean water, fish and wildlife, and indigenous communities by stopping harmful, polluting mines.\n2019’s “River of the Year”: Cuyahoga River, Ohio\nAmerican Rivers celebrates the progress Cleveland has made in cleaning up the Cuyahoga River, fifty years since the river’s famous fire that sparked the nation’s environmental movement.\nABOUT AMERICAN RIVERS\nAmerican Rivers believes every community in our country should have clean water and a healthy river. Since 1973, we have been protecting wild rivers, restoring damaged rivers and conserving clean water for people and nature. With headquarters in Washington, D.C., and offices across the country, we are the most effective river conservation organization in the United States, delivering solutions that will last for generations to come."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:5946720d-7051-47b0-a1fd-3eb3da363daa>"],"error":null}
{"question":"How do traditional mechanical design safety approaches compare with contemporary design thinking strategies for managing business risk?","answer":"Traditional mechanical design safety relied on specific mathematical methods like the factor of safety method (where safety factor n = strength/stress) and permissible stress method with defined allowable stress ranges. In contrast, contemporary design thinking manages business risk through iterative prototyping, smart failures, and continuous experimentation. Design thinking reduces risk by emphasizing human centricity, foresight, and creative meaning through storytelling and multimedia approaches, moving beyond purely mathematical calculations to include cultural and social factors in risk assessment.","context":["Standard Handbook of Machine Design\nAuthor: The McGraw-Hill Companies\nCategory: Technology & Engineering\nTo the late Joseph Edward Shigley Joseph Edward Shigley was awarded bachelor degrees in electrical (1931) and mechanical (1932) engineering by Purdue University, and a master of science in engineering mechanics (1946) by The University of Michigan. His career in engineering education began at Clemson College (1936-1956) and continued at The University of Michigan (1956-1978). Upon retirement, he was named Professor Emeritus of Mechanical Engineering by the Regents in recognition of his outstanding achievement and dedicated service. At the time when Professor Shigley began thinking about his first book on machine design, many designers were unschooled, and textbooks tended to give results with only a brief explanation—they did not offer the reader many tools with which to proceed in other or new directions. Professor Shigley's first book, Machine Design (1956), showed his attention to learning and understanding. That milestone book is currently in its fifth edition. Other books followed, among which are Theory of Machines and Mechanisms (with John J. Uicker, Jr.), Mechanical Engineering Design (with Charles R. Mischke), and Applied Mechanics of Materials. Early in the 1980s, Professor Shigley called Professor Mischke and said, \"I've never done a Handbook before; there is no precedent in machine design, and it is time there was one. I propose we do it together. Take a couple of months to consider what ought to be in it, the organization and presentation style. Then we can get together and compare notes.\" The result was the first edition of the Standard Handbook of Machine Design (1986), which won the Association of American Publishers Award for the best book in engineering and technology published in 1986. Eight Mechanical Designers Workbooks followed. Professor Shigley received recognitions such as the grade of Fellow in the American Society of Mechanical Engineers, from which he also received the Mechanisms Committee Award in 1974, the Worcester Reed Warner Medal in 1977, and the Machine Design Award in 1985. I believe he would have given up all the above rather than give up the effect he had as mentor and tutor to students, and in guiding boys toward manhood as a scoutmaster. He indeed made a difference. Charles R. Mischke PREFACE TO THE SECOND EDITION The introduction of new materials, new processes, and new (or more refined) analytical tools and approaches changes the way in which machines are designed. Complementary to the urge to update and improve, it is useful to look back in order to retain a perspective and appreciate how all this fits into the fabric of machine design methodology. Many of the machine elements we know today were known to the ancients. We have the advantage of improved materials, better manufacturing methods, and finer geometric control, as well as insightful theory and the opportunity to stand on the shoulders of the giants among our predecessors. Assuring the integrity of a contemplated design, its components, and the aggregate machine or mechanism has always been a problem for the engineer. The methods of record include the following: • The Roman method This method, developed in the Macedonia-Roman period, was to replicate a proven, durable design (with some peripheral improvements). Encyclopedic \"books\" were compiled for the guidance of designers. In strengthlimited designs, the essential thought was, \"Don't lean on your element any harder than was done in the durable, extant designs of the past.\" There are times when contemporary engineers still employ this method. • The factor of safety method (of Philon of Byzantium) In today's terms, one might express this idea as loss-of-function load strength n = : —— = impressed load stress for linear load-stress relations. Alternatively, loss-of-function load Allowable load = n or AA lIlI owabuil e s^t ress = strength n for linear load-stress relations. The factor of safety or design factor was experiential and came to consider uncertainty in load as well as in strength. • The permissible stress method Since the concept of stress was introduced by Cauchy in 1822, some engineers have used the idea of permissible stress with load uncertainty considered, and later with the relevant material strength included, as for example in 0.405, < (aall)bending < 0.605, It is not clear whether the material strength uncertainty is included or not. When the word \"allowable\" or \"permissible\" is used among engineers, it is important to clearly define what is, and what is not, included. • Allowable stress by design factor The definition of allowable stress oan is expressed as strength °all = ~^n n\nUsing Design to Achieve Key Business Objectives\nAuthor: Thomas Lockwood,Thomas Walton\nPublisher: Skyhorse Publishing, Inc.\nHow can design be used to solve business problems? That's the question answered, in many innovative ways, by Building Design Strategy. Mark Dziersk, EunSool Kwon, Arnold Levin, Laura Weiss, and many more top-name contributors share their experience and insights. Topics explore the full range of issues today, including thinking ahead; adapting to challenges; developing tangible strategies; using design to convey ideas; choosing worthwhile projects to help growth; using design to create fiercely loyal customers.\nThe Essential David Orr\nAuthor: David W. Orr\nPublisher: Island Press\nFor more than three decades, David Orr has been one of the leading voices of the environmental movement, championing the cause of ecological literacy in higher education, helping to establish and shape the field of ecological design, and working tirelessly to raise awareness of the threats to future generations posed by humanity’s current unsustainable trajectory. Hope Is an Imperative brings together in a single volume Professor Orr’s most important works. These include classics such as “What Is Education For?,” one of the most widely reprinted essays in the environmental literature, “The Campus and the Biosphere,” which helped launch the green campus movement,and “Loving Children: A Design Problem,” which renowned theologian and philosopher Thomas Berry called “the most remarkable essay I’ve read in my whole life.” The book features thirty-three essays, along with an introductory section that considers the evolution of environmentalism, section introductions that place the essays into a larger context, and a foreword by physicist and author Fritjof Capra. Hope Is an Imperative is a comprehensive collection of works by one of the most important thinkers and writers of our time. It offers a complete introduction to the writings of David Orr for readers new to the field, and represents a welcome compendium of key essays for longtime fans. The book is a must-have volume for every environmentalist’s bookshelf.\nAn Agenda for Governance Reform\nAuthor: Richard Tomlinson,Marcus Spiller\nPublisher: CSIRO PUBLISHING\nSince the early 1990s there has been a global trend towards governmental devolution. However, in Australia, alongside deregulation, public–private partnerships and privatisation, there has been increasing centralisation rather than decentralisation of urban governance. Australian state governments are responsible for the planning, management and much of the funding of the cities, but the Commonwealth government has on occasion asserted much the same role. Disjointed policy and funding priorities between levels of government have compromised metropolitan economies, fairness and the environment. Australia’s Metropolitan Imperative: An Agenda for Governance Reform makes the case that metropolitan governments would promote the economic competitiveness of Australia’s cities and enable more effective and democratic planning and management. The contributors explore the global metropolitan ‘renaissance’, document the history of metropolitan debate in Australia and demonstrate metropolitan governance failures. They then discuss the merits of establishing metropolitan governments, including economic, fiscal, transport, land use, housing and environmental benefits. The book will be a useful resource for those engaged in strategic, transport and land use planning, and a core reference for students and academics of urban governance and government.\nHow to Survive and Grow in the Age of Digital Business Models\nAuthor: Barry Libert,Megan Beck,Jerry Wind\nPublisher: Harvard Business Review Press\nCategory: Business & Economics\nDigital networks are changing all the rules of business. New, scalable, digitally networked business models, like those of Amazon, Google, Uber, and Airbnb, are affecting growth, scale, and profit potential for companies in every industry. But this seismic shift isn’t unique to digital start-ups and tech superstars. Digital transformation is affecting every business sector, and as investor capital, top talent, and customers shift toward network-centric organizations, the performance gap between early and late adopters is widening. So the question isn’t whether your organization needs to change, but when and how much. The Network Imperative is a call to action for managers and executives to embrace network-based business models. The benefits are indisputable: companies that leverage digital platforms to co-create and share value with networks of employees, customers, and suppliers are fast outpacing the market. These companies, or network orchestrators, grow faster, scale with lower marginal cost, and generate the highest revenue multipliers. Supported by research that covers fifteen hundred companies, authors Barry Libert, Megan Beck, and Jerry Wind guide leaders and investors through the ten principles that all organizations can use to grow and profit regardless of their industry. They also share a five-step process for pivoting an organization toward a more scalable and profitable business model. The Network Imperative, brimming with compelling case studies and actionable advice, provides managers with what they really need: new tools and frameworks to generate unprecedented value in a rapidly changing age.\nenergy and technology in architecture\nAuthor: Ralph W. Crump,Martin J. Harms\nPublisher: Van Nostrand Reinhold Company\nCategory: Technology & Engineering\nRapid Technology Adoption for Digital Transformation\nAuthor: Stephen J Andriole,Thomas Cox,Kaung M. Khin\nPublisher: CRC Press\nCategory: Business & Economics\nThe pace of technological change is accelerating, hyper competition is growing, opportunities for business model disruption are exploding, and comprehensive cloud delivery is readily available. These factors challenge every aspect of business technology strategy. The Innovator’s Imperative: Rapid Technology Adoption for Digital Transformation prepares twenty-first century businesses leaders for competing and leading in this disruptive digital environment. Five years of research conducted by the authors suggests that leading companies have all but abandoned the requirements analysis and modeling best practices of the twentieth century. Accordingly, the authors put forth the innovator’s imperative that contends: All companies wanting to be competitive should adopt emerging and disruptive technologies as quickly as possible, and in many cases, immediately. Technology is driving business strategy, and companies are rethinking their technology strategy, especially the governance that determines how and why technology investments are made. Based on their research the authors have developed a five-step framework for digital transformation: Model and simulate Identify high-leverage opportunities Prioritize transformational targets Identify digital opportunities Find courageous leaders The book explains each of these steps to guide business leaders in architecting digital transformation projects according to their organization’s market positions, budgets, objectives, and corporate culture. Hyper-competitive, disruptive companies are jumping across technology adoption phases without regard to any phasing whatsoever. Companies focused on digital transformation often adopt emerging technologies immediately. They have become early adopters of technologies that can impact existing—and create whole new—business models and processes. This book examines this jump into new technologies, processes, and business models to prepare twenty-first century business leaders to make that leap.\nTools & Techniques for Managing the Design Process\nAuthor: David Holston\nPublisher: Simon and Schuster\nThe design profession has been asking itself some important questions lately. How do designers deal with the increasing complexity of design problems? What skills do designers need to be competitive in the future? How do designers become co-creators with clients and audiences? How do designers prove their value to business? Designers are looking for ways to stay competitive in the conceptual economy and address the increasing complexity of design problems. By adopting a process that considers collaboration, context and accountability, designers move from 'makers of things' to 'design strategists.' The Strategic Designer shows designers how to build strong client relationships, elevate their standing with clients, increase project success rates, boost efficiency and enhance their creativity.\nAuthor: Kingston Heath\nSustainable design requires that design practitioners respond to a particular set of social, cultural and environmental conditions. 'Vernacular Architecture and Regional Design' defines a set of strategies for understanding the complexities of a regional setting. Through a series of international case studies, it examines how architects and designers have applied a variety of tactics to achieve culturally and environmentally appropriate design solutions. • Shows that architecture and design are inextricably linked to social and environmental processes, and are not just technical or aesthetic exercises. • Articulates a variety of methods to realise goals of socially responsible and environmentally responsive design. • Calls for a principled approach to design in an effort to preserve fragile environments and forge sustainable best practice. 'Vernacular Architecture and Regional Design' will appeal to educators and professional practitioners in the fields of architecture, heritage conservation and urban design. Dr. Kingston Wm. Heath is Professor and Director of the Historic Preservation Program at the University of Oregon. Previously he was Professor of Architecture at the University of North Carolina, Charlotte where he taught seminars on vernacular architecture and regional design theory. He holds graduate degrees from the University of Chicago and Brown University. In addition to numerous articles in scholarly journals, he is the author of Patina of Place, and winner of the Abbott Lowell Cummings Award from The Vernacular Architecture Forum for excellence in a scholarly work. He has earned an international reputation in the field of vernacular architecture and has directed field schools in Italy and Croatia.\nAuthor: Lihui Wang,Fengfeng Xi\nPublisher: Springer Science & Business Media\nCategory: Technology & Engineering\nThis book presents a collection of quality chapters on the state-of-the-art of research efforts in the area of smart devices and novel machine design, as well as their practical applications to enable advanced manufacturing. The first section presents a broad-based review of several key areas of research in smart devices and machines. The second section is focused on presenting an in-depth treatment of a particular device or machine. The book will be of interest to a broad readership.\nDriving Superior Returns on Marketing Investments\nAuthor: Michael Dunn\nPublisher: John Wiley and Sons\nCategory: Business & Economics\nMaking accountable marketing decisions to improve the efficiency of spending In this practical guide, Prophet CEO Michael Dunn teams up with marketing effectiveness expert Chris Halsall to help marketing managers and CMOs make better marketing spending decisions and better evaluate the success or failure of these decisions. They show how to sort through the clutter of metrics, measurement, and analytic options, and provide the practical information needed to help establish the marketing accountability imperative--highlighting the critical need for more effective stewardship of marketing spending.\nAuthor: David Gerrold\nLeft alone on the moon, Chigger and his two brothers are unable to return to an Earth that has descended into chaos and decide to leave Geosynchronous Station to find a planet where they can build new lives for themselves, but their plans are threatened by an interplanetary manhunt after the powerful synthetic intelligence that the three boys are rumored to be carrying. 20,000 first printing.\nNatural Design for the Real World\nAuthor: Victor J. Papanek\nPublisher: Thames & Hudson\nIn this book Papanek looks at the exciting possibilities for the future if architecture and design were to become environmentally and socially responsible. He shows how people can contribute to the well-being of the planet through awareness of design.\nAn Annotated Bibliography, 1960-1986\nAuthor: Suresh Kumar Gupta,I. C. Gupta\nPublisher: Concept Publishing Company\nAuthor: Anastassia Lauterbach,Andrea Bonime-Blanc\nThis practical guide to artificial intelligence and its impact on industry dispels common myths and calls for cross-sector, collaborative leadership for the responsible design and embedding of AI in the daily work of businesses and oversight by boards. • Provides a strategic framework for corporate boards and executive leadership teams to remain competitive in the age of AI • Offers practical and clear advice on AI and machine learning, introducing technical concepts and translating research trends into practical applications while simultaneously incorporating critical governance, ethics, sustainability, and risk considerations • Provides traditional businesses and their boards with practical questions to ask their teams, suppliers, and technology partners and offers guidance on market trends and players to which to pay attention","[Book Review] Design Thinking for Strategic Innovation\nThe ‘traditional’ ways of running a business do not seem to be working as well as they did in today’s connected always-on digital era. Design thinking is emerging as a more appropriate way for business, management, marketing and development.\nDesign Thinking for Strategic Innovation is a practical toolkit to apply design concepts for use in everyday work. Presented in the manner of a coffee-table book, with plentiful photographs and large quotes, the material explains how design thinking can bring about creative solutions to solve complex business problems. The author covers the values of design thinking, approaches for eight key challenges that most businesses face, and an application framework via exercises, activities, and resources.\nIdris Mootee is the CEO of Idea Couture (www.ideacouture.com), a global innovation firm with offices in San Francisco, Shanghai, Toronto, London, Dubai, and Mexico City. He has worked with clients such as Amex, Burberry, BMW, Boeing, Cisco, De Beers, Kraft, Nike, Samsung, and Pepsi. He is also the author of the book 60-Minute Brand Strategist.\n“As technological innovation has accelerated, people, communities, and organisations have become more connected than ever before. We talk more, share more, and expect more. This disruption has changed the way consumers do business,” Mootee begins. Technology exponentially interconnects people, places, events, ideas and objects in increasingly new ways.\n20th century management was based on fixed organisational boundaries, predictability, command and control, risk aversion, value capture, and competitive advantage. In contrast, 21st century management is about speed, agility, fluid boundaries, creative empowerment, value creation, entrepreneurship/intrapreneurship, and comparative advantage.\n“Design thinking is the search for a magical balance between business and art, structure and chaos, intuition and logic, concept and execution, playfulness and formality, and control and empowerment,” explains Mootee.\nDesign thinking as a discipline is more human, cultural, social, smart, and agile, and puts innovation at its core. It helps organisations imagine, organise, mobilise and compete in new ways, and creates organisational cultures which are more purposeful, passionate, disruptive, and inspired.\nRapid prototyping, empathy, a mindset for curiosity, deep exploration, and continuous experimentation are hallmarks of such a multi-disciplinary approach. Design thinking “advances knowledge from mystery to heuristic to algorithm,” according to Roger Martin, author of The Design of Business.\nDesign thinking is even more relevant in an age of ‘data paralysis,’ where the volume, variety and velocity of digital data almost overwhelm us. This calls for better sensemaking and deeper intuition for effective decision making.\nMootee explains the 10 design thinking principles applied to management: action-orientation (‘design doing’), comfort with change, human centricity, foresight, iterative construction (prototyping), empathy with users, risk reduction (through smart failures), creative meaning (via multimedia and stories), enterprise-level creativity, and competitive logic (sustainable innovation).\nHiring design thinkers is not enough – companies should build design thinking into their organisation’s DNA and business models, Mootee advises. This can be done by adapting design thinking to eight key challenges faced by businesses. I have summarised these approaches in Table 1; the book also offers worksheets, checklists and charts to illustrate these principles in greater detail.\nTable 1: Design thinking approaches to business challenges\n|Business Challenge||Design Thinking Approach||Dynamics|\n|Growth||Storytelling||Stories which inspire employees and executives: engaging, performative, tangible, fun, plausible|\n|Predictability||Strategic foresight||Critical inquiry to identify ‘wicked problems’ and weak signals; context mapping, scenarios|\n|Change||Sensing||Structuring the unknown through framing, visioning, imagining, communicating, connecting|\n|Relevance||Value redefinition||Overcoming brand mythology: understanding customer perception of problems, solutions, value|\n|Extreme competition||Experience design||Overcome commodification: address customer emotions, intensity, triggers and engagement level|\n|Standardisation||Humanisation||Focus the business narrative not just on efficiency but context and relationships|\n|Creative culture||Prototyping||A culture of creativity at play and work: testing, iterating, collaborating, multiple feedback loops|\n|Strategy and organisation||Business model design||Open innovation, customer co-marketing, community validation, cross-media|\nThe most successful practitioners of design thinking love stories and storytellers, according to Mootee; effective stories go beyond numbers and use archetypes and structured narrative to cohesively weave hopes, dreams and aspirations of employees and customers.\nSense-making goes beyond sensing to cultivate sources outside the organisation, harness social media and create integrated mental models. Cross-functional collaboration helps improve the ‘creative confidence’ of an organisation.\nEffective business models driven by design thinking will focus on emerging consumer behaviours, identifying unmet needs, market segmentation, new distribution models, changes in triggers and drivers, ecosystem partners, and even payment methods.\nOne major shortcoming in the book is a lack of examples to illustrate these principles; only a few are briefly mentioned, eg. Amazon, Zappos and Easyjet are companies that have done a good job of identifying and redefining value; Pixar University reinforces a creative culture through a range of courses.\nThe concluding chapter addresses the bigger picture of design thinking and how it can help create value-centred businesses which focus on social and environmental sustainability in addition to profitability (‘conscious capitalism’). Our educational system unfortunately does not address the ‘creativity deficit’ in society since B-schools and D-schools rarely collaborate with each other.\nThere is too much focus on planning (driven by analysis) and not enough on holistic strategy (driven by synthesis). In an era of increasing ‘kinship’ thanks to globalisation and digital media, graduates of tomorrow will need not just knowledge but meta-knowledge of multiple disciplines to solve the problems of our planet.\nIt would be fitting to end this review with some of the useful inspirational quotes in the book; inspiration helps us ‘reach a little higher, dig a little deeper, dream a little bigger,’ says Mootee.\nThe test of a first-rate intelligence is the ability to hold two opposed ideas in the mind at the same time. – F.Scott Fitzgerald\nThe problem with the rat race is that even if you win, you’re still a rat. – Lily Tomlin\nThe illiterate of the 21st century will not be those who cannot read and write, but those who cannot learn, unlearn and relearn. – Alvin Toffler\nIf history were taught in the form of stories, it would never be forgotten. – Rudyard Kipling\nThe best way to predict the future is to create it. – Peter Drucker\nMinds are like parachutes; they only function when open. – Thomas Dewar\nBehind complexity, there is always simplicity to be revealed. Inside simplicity, there is always complexity to be discovered. – Gang Yu\nData is no substitute for intimacy. – Roger Martin"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:917113fc-8686-4642-9d7c-4b540dfed54c>","<urn:uuid:a00ae6d0-e089-4ca7-a459-927963ff9971>"],"error":null}
{"question":"What's the biggest speed difference between Bluefin tuna and Noturus nocturnus when hunting their prey? Would love to know which one is the faster hunter! 🐟","answer":"Bluefin tuna is significantly faster than Noturus nocturnus when hunting. Bluefin tuna can reach speeds of up to 80 kilometers per hour (approximately 50 mph) when pursuing prey. The Noturus nocturnus, being a lie-in-wait/ambush predator, does not rely on speed for hunting but rather waits for prey to come near.","context":["Picture by Chad Thomas, Texas State University-San Marcos\nSaline River near Benton railroad bridge, AR (Jordan and Gilbert 1886).\nEtymology/Derivation of Scientific Name\nNoturus, Greek, meaning “black tail,” in reference to the connection of the adipose fin and tail fin; nocturnus, Latin for “nocturnal” from its black color (Pflieger 1997).\nNoturus nocturnus Jordan and Gilbert 1886:6; Cook 1959:142.\nMaximum size: 138 mm SL (Ross 2001).\nColoration: Axial streak inconspicuous; dorsal, anal and caudal fins with dark edges; lower lip and chin heavily speckled with dark pigment (Hubbs et al.1991). The back and sides are uniformly yellowish to dark brown (dark gray in preservation), and the ventral surface is generally unpigmented, with scattered melanophores on the lower jaw and sides of the belly. The nasal and maxillary barbles are dark. The pelvic and pectoral fins are only pigmented along the basal half in small specimens (Ross 2001).\nCounts: 5-6 gillrakers, 6-7 dorsal rays, 16-18 (15-20) anal rays, 8-10 (7-11 pectoral rays, and 9 (8-10) pelvic rays (Ross 2001).\nBody shape: Moderately elongate. Posterior corners of premaxillary tooth patch rounded or obtusely angulate (Boschung and Mayden 2004). Lower jaw underslung (Hubbs et al. 1991).\nMouth position: Subterminal (Hubbs et al.1991).\nExternal morphology: Pectoral spine serrated; adipose fin joined to caudal fin or separated from it by not more then a shallow notch; eyes present (Hubbs et al.1991).\nDistribution (Native and Introduced)\nU.S. distribution: Lower and central Mississippi basin and other Gulf of Mexico tributaries in Alabama, Mississippi, Louisiana, Texas, as well as lower half of Ohio basin in KY, IN, and IL (Rhode 1980).\nTexas distribution: Found primarily in eastern Texas from Red River southward to Brazos Basin (Hubbs et al. 1991).\nAbundance/Conservation status (Federal, State, NGO):\nNot listed as threatened or endangered by Texas Parks and Wildlife Department (2006). Populations in southern United States are currently stable (Warren et al. 2000).\nMacrohabitat: Inhabits clear to moderately turbid streams of medium to larges size having permanent flow and low to moderate gradients (Rhode 1980).\nMesohabitat: In riffles over gravelly or rocky bottom (Rhode 1980; Burgess 2003). In southern Mississippi, it also occurs in association with sticks, root masses, and submerged logs, especially along undercut banks. Young individuals will shelter in beverage cans and soft-drink and beer bottles, but adults are generally too large to fit through openings (Clark 1978). In Illinois, breeding males were found in beverage cans (Burr and Mayden 1982). N. nocturnus is an intolerant species sensitive to environmental conditions and typically first to disappear following a disturbance; fluvial specialist having narrow range of habitat use. Associated more with unchannelized reaches of the South Sulpher River, Texas, and generally occupying riffle habitat. (Burgess 2003). In South Sulpher River, Texas, species associated with higher velocities and with riffle-habitat types and shallower depths that occurred during the low flow range (Morgan 2002).\nSpawning season: In southeast Missouri, females with fully developed eggs were collected in late May, suggesting a spring-early summer spawning season (Pflieger 1975). In summer, in southern Mississippi (Clark 1978), and from May-July in Illinois.\nSpawning habitat: Speleophils (hole nesters; Simon 1999); nests located in areas with some current, in water 10-15cm deep (Burr and Mayden 1982).\nReproductive strategy: Guarders; nest spawners (Mayden and Walsh 1984; Simon 1999).\nFecundity: Mature ova range from 1.8 to2.3mm in diameter and number from 85-116 in females of 67 -75 mm SL (Burr and Mayden 1982).\nAge at maturation: Males reach maturity by third summer and females by their second (Burr and Mayden 1982).\nGrowth and population structure: Growth initially rapid, reaching half of first year’s growth in only eight weeks. At one year fish average 64-66 mm SL, and average 77-79 mm SL and 84-86 mm SL by their second and third years respectively (Burr and Mayden 1982).\nLongevity: 4.5 years (Burr and Mayden 1982).\nFood habits: Invertivore; benthic; lie-in-wait/ambush feeding behavior (Goldstein and Simon 1999). Aquatic insect larvae, especially larvae of mayflies (Ephemeroptera), caddisflies (Trichoptera), and midges (Diptera). Black fly larvae are more prevalent in the fall (Burr and Mayden 1982). In southern Mississippi, smaller Noturus leptacanthus were consumed, indicating piscivory occasionally occurs. As with other madtoms feeding activity is greatest at night (Clark 1978). Nesting males apparently do not feed (Burr and Mayden 1982).\nPhylogeny and morphologically similar fishes\nIt can be distinguished from the Noturus gyrinus by having an inferior (versus terminal) mouth (Ross 2001). N. gyrinus, found in Texas, is among the species to which N. nocturus is most closely related (Grady and LeGrande 1992).\nCommercial or Environmental Importance\n[Additional literature noting collection of this species from Texas locations includes, but is not limited to the following: Big Sandy Creek (Evans and Noble 1979); Village Creek (Moriarty and Winemiller 1997); El-Hage et al. (1999).]\nBurgess, C.C. 2003. Summer fish assemblages in channelized and unchannelized reached of the South Sulpher River, Texas. M.S. Thesis. Texas A&M University, College Station, Texas. 94 pp.\nBoschung, H.T., Jr., and R.L. Mayden. 2004. Fishes of Alabama. Smithsonian Books, Washington. 736 pp.\nBurr, B.M. and R.L. Mayden. 1982. Life history of the freckled madtom, Noturus nocturnus, in Mill Creek, Illinois (Pisces: Ictaluridae). Occ. Pap. Mus. Nat. Hist. Univ. Kans. 98:1-15.\nClark, K.E. 1978. Ecology and life history of the speckled madtom, Noturus leptacanthus (Ictaluridae). Master’s thesis, Univ. S. Mississippi, Hattiesburg.\nCook, F.A. 1959. Freshwater fishes in Mississippi. Mississippi Game and Fish Commision, Jackson. 239 pp.\nEl-Hage, A., D.W. Moulton, P.D. Sorenson. 1999. Evaluation of Selected Natural Resources in Part of the North-Central Texas Area. Resource Protection Division. Texas Parks and Wildlife, Austin. 36 pp.\nEvans, J.W., and R.L. Noble. 1979. Longitudinal distribution of fishes in an East Texas stream. American Midland Naturalist 101(2):333-343.\nGoldstein, R.M., and T.P. Simon. 1999. Toward a united definition of guild structure for feeding ecology of North American freshwater fishes. pp. 123-202 in T.P. Simon, editor. Assessing the sustainability and biological integrity of water resources using fish communities. CRC Press, Boca Raton, Florida.\nGrady, J.M. and W.H. LeGrande. 1992. Phylogenetic relationships, modes of speciation, and historical biogeography of the madtom catfishes, genus Noturus Rafinesque (Siluriformes: Ictaluridae). pp. 747-777. In: Systematics, historical ecology, and North American freshwater fishes. R.L. Mayden ed. Stanford Univ. Press, Stanford, Calif.\nHubbs, C., R.J. Edwards and G.P. Garret. 1991. An annotated checklist of freshwater fishes of Texas, with key to identification of species. Texas Journal of Science, Supplement 43(4):1-56\nJordan, D.S. and C.R. Gilbert. 1886. List of fishes collected in Arkansas Indian territory, and Texas, in September, 1884, with notes and descriptions. Proc. US. Nat. Mus. 9(15):1-25.\nMayden, R.L., and S.J. Walsh. 1984. Life history of the least madtom Noturus hildebrandi (Siluriformes: Ictaluridae) with comparisons to related species. American Midland Naturalist 112:349-368.\nMorgan, M.N. 2002. Habitat associations of fish assemblages in the Sulpher River, Texas. Master’s thesis. Texas A&M University, College Station, TX. 58 pp.\nMoriarty, L.J., and K.O. Winemiller. 1997. Spatial and temporal variation in fish assemblage structure in Village Creek, Hardin County, Texas. Texas Journal of Science, Supplement 49(3):85-110.\nPflieger, W.L. 1997. The Fishes of Missouri. Revised Edition. Missouri Department of Conservation. Jefferson City. 372 pp.\nRoss, S. T. 2001. The Inland Fishes of Mississippi. University Press of Mississippi, Jackson. 624 pp.\nRhode, F.C. 1980. Noturus nocturnus (Jordan and Gilbert), Freckled madtom. pp.466 in D.S. Lee et al. Atlas of North American Freshwater Fishes. N.C. State Mus. Nat. Hist., Raleigh, i-r+854 pp.\nSimon, T. P. 1999. Assessment of Balon’s reproductive guilds with application to Midwestern North American Freshwater Fishes, pp. 97-121. In: Simon, T.L. (ed.). Assessing the sustainability and biological integrity of water resources using fish communities. CRC Press. Boca Raton, Florida. 671 pp.\nTexas Parks and Wildlife Department, Wildlife Division, Diversity and Habitat Assessment Programs. County Lists of Texas' Special Species. [30 May 2006]. http://gis.tpwd.state.tx.us/TpwEndangeredSpecies/DesktopModules/AcountyCodeKeyForWebESDatabases.pdf\nWarren, L. W., Jr., B. M. Burr, S. J. Walsh, H. L. Bart, Jr., R. C. Cashner, D. A. Etnier, B. J. Freeman, B. R. Kuhajda, R. L. Mayden, H. W. Robison, S. T. Ross, and W. C. Starnes. 2000. Diversity, Distribution, and Conservation status of the native freshwater fishes of the southern United States. Fisheries 25(10):7-29.","Bluefin Tuna is one of the most expensive fish in the world and is largely sought after for its exceptional taste and tenderness. Bluefin Tuna is hunted by commercial fisheries all over the world, but they are on the verge of extinction.\n- Status: Critically Endangered, depends on species.\n- Species: Albacore Tuna, Atlantic Bluefin Tuna, Bigeye Tuna, Pacific Bluefin Tuna, Southern Bluefin Tuna.\n- Estimated numbers left in the wild: Unknown but likely ranging in the hundreds of thousands.\nThe tuna’s population has declined by 90% since the 1950s due to overfishing, which is why it’s endangered.\nIt was first caught commercially in 1908 and now there are only a few thousand left worldwide. Bluefin tuna can grow up to 10 feet long and weigh more than 1,500 pounds.\nThe Bluefin population has been severely depleted because of high demand from sushi restaurants around the world who prize this species for its light red meat to consume that remains moist when cooked or frozen.\nBluefin is one of the most expensive fish in the world, with Bluefin Tuna Sashimi selling for up to $24 per piece in Tokyo.\nThe Bluefin is very popular because it’s extremely fatty and tender, which makes it a favorite among sushi lovers. Avoiding Bluefin tuna products would be an easy way to save this fish from extinction.\nBluefin tunas are all hunters. They prey mostly on smaller fish that form schools or small squid that exhibit schooling or swarming behavior.\nHowever, they will also eat pelagic red crabs, krill, and certain sessile animals, such as sea anemones. Tuna are active predators who can put on spurts of up to 80 kilometers per hour to catch other fish.\nTo achieve this performance, they are warm-blooded. The bluefin species have the most control over their internal temperature. Very high blood hemoglobin levels oxygenate the tunas’ muscles for strength and power.\nSee Related: Fun And Interesting Devilfish Facts\nAnatomy and Appearance\nBluefin tuna are large predatory fish, stocky and sharp-finned, whose size can range up to 4.5 meters and whose weight can be as high as 450 kilograms. Their coloration tends to be striking, with metallic blue upper surfaces and, short pectoral fins, metallic white underparts.\nThis color gives these five species of tuna their general name of “bluefins,” and it serves a vital function in the species’ lives. The blue upper surfaces provide camouflage from above, while the silvery underparts help conceal the prowling tuna from below, allowing them to close more effectively with their prey.\nThe various tuna species are found in the Atlantic Ocean near Newfoundland and Iceland; the Gulf of Mexico; the Mediterranean; other areas of the Atlantic; and the Pacific Ocean. Tunas are deepwater fish that need a thriving biome to survive since they are predatory and feed on schools of smaller fish.\nSee Related: Environmental Organization in Europe\nBluefin Tuna Habitat\nIt is found in both the Atlantic, Pacific, and mediterranean sea. They inhabit a wide range of habitats, including open seas, coastal waters, bays, and estuaries. Bluefin Tuna are migratory fish and can travel long distances in search of food.\nThey are most commonly found in deep water, but they can also be found in shallow waters near the coast.\nBluefin Tuna Diet and Nutrition\nThese species are apex predators and have a very diverse diet. They mostly eat small fish, but they will also eat squid, crustaceans, and other types of prey.They are a very important part of the marine food chain and help to keep the populations of other fish in check.\nBluefin Tuna Mating Habits\nBluefin Tuna is a large fish that can grow to a weight of 1000 pounds and lengths over 10 feet. It takes from 7-10 years to reach full maturity, but they only reproduce once at this age. They are highly migratory, which makes them difficult to track by scientists.\nTuna are a migratory species and gather together in large numbers at chosen spawning grounds to produce their eggs to seek food.\nA single female tuna can produce anywhere from 5 million to 30 million eggs, though, of course, only a tiny fraction of the fry will ever grow to adulthood. If not caught by fishermen, a bluefin tuna can potentially live for anywhere from fifteen to thirty years.\nSee Related: Is a Fish an Animal? Here’s What You Need to Know\nAtlantic Bluefin Tuna vs Pacific Bluefin Tuna\nAtlantic Bluefin Tuna and Pacific Bluefin Tuna are both Bluefin Tuna, but they are different species.\nAtlantic tunas are the most common tuna and are found in the Atlantic Ocean. Pacific Bluefin is a rarer species and is found in the Pacific Ocean. Atlantic tuna is larger than Pacific tuna. Pacific tuna is more torpedo-shaped, while Atlantic tuna is more rounded.\nBluefin Tuna and Human Relationship\nThe Bluefin has been hunted by commercial fisheries for years all over the world for its exceptional taste and tenderness. Humans are among the leading cause of why such wonderful species is facing threats of endangerment.\nTuna is a prized catch, and because of this, its population has declined by 90% since the 1950s. The fish is a vital part of the marine ecosystem, and if it becomes extinct, it will have a profound impact on the marine food chain.\nThe main reason Bluefin tuna is endangered is overfishing and illegal fishing.\nTuna are being caught faster than they can reproduce, and if this trend continues, the species will become extinct. Bluefin is also hunted for their meat, and because the demand for this fish is so high, the prices for Bluefin have skyrocketed.\nThe species are a vital part of the marine ecosystem, and if it becomes extinct, it will have a profound impact on the marine food chain.\nThe main reason tuna is endangered is overfishing. They are being caught faster than they can reproduce, and if this trend continues, the Bluefin tuna will become extinct.\nBluefin Tuna Facts\nHere are the interesting facts about Bluefin Tuna that you need to know.\n- Tuna is the fish that is served at Nobu\n- Bluefin can swim up to 40 miles per hour\n- They are vulnerable because they are slow-growing and have a high demand\n- The aquatic predator is a large, predatory fish that is found in the Atlantic, Pacific, and western Mediterranean oceans.\n- Tuna can weigh up to 1,500 pounds and reach up to 10 feet in length.\n- Bluefin are commercially valuable fish and are hunted by fisheries all over the world.\n- Unfortunately, Bluefin is on the verge of extinction due to overfishing.\n- They have declined by 90% since the 1950s due to excessive hunting.\nAtlantic Bluefin tuna is a large, predatory fish that is found in the Atlantic and Pacific oceans. Bluefin is one of the most expensive fish in the world and is largely sought after for their exceptional taste and tenderness.\nBluefin is hunted by commercial fisheries all over the world, but they are on the verge of extinction. Tuna has declined by 90% since the 1950s due to overfishing, which is why it’s listed as an endangered species.\nOverfishing is the chief threat to all varieties of bluefin tuna. They have a migratory behavior of these large fish make it difficult for conservation efforts by any one government to make a significant difference in their overall fate, increasing the difficulty of tuna conservation.\nSushi and sashimi are among the most common uses of this fish. Demand and prices are very high in Japan, providing an ongoing market for fish caught despite various agreements, with 80% of the world catch going to Japan.\nSome secondary threats could also exist if the acidification of the oceans, caused by global warming, starts to affect the bluefin tunas’ food supplies.\nSee Related: Endangered Species in California\nSeveral good faith conventions have been made to limit fishing of these important members of the pelagic ecosystem, but how well they are observed depends largely on local decisions by fishers and governments.\nBoth Australia and Japan are attempting farming as an alternative to catching wild tuna, but the fish are difficult to raise due to the length of time it takes them to mature. Thus, there’s a need to conserve these giant beauties. The tuna were also under teh care of the national marine fisheries service.\nSee Related: Fascinating Facts About Conservation\nMonterey Bay Aquarium\nMonterey Bay Aquarium is a public aquarium located in Monterey, California. It is considered the sister institution to the Scripps Institution of Oceanography. The aquarium is home to thousands of marine animals and contains over 50 large tanks of water that are 10 feet high and 100 feet long, which house 3,500 different aquatic species.\nMonterey Bay Aquarium conducts research projects and tagging to study migration, habitats, diets, populations and protect different marine species like the Bluefin tuna.\nOceana is an international organization working to protect the world’s oceans. Oceana works with governments around the world in order to create policies that will help preserve our marine ecosystems so we don’t lose any more Bluefin Tunas or other marine life because of human actions such as fishing or pollution\nBluefin Tuna is one of the most expensive fish in the world and they are largely sought after for their exceptional taste and tenderness.\nBluefin tuna have declined by 90% since the 1950s due to overfishing, which is why it’s endangered.\nAccording to Monterey Bay Aquarium, tuna can swim up to 40 miles per hour and reach up to 10 feet in length. Bluefin tunas’ migratory habits make them difficult to track by scientists and if not caught by fishermen a bluefin could live anywhere from 15-30 years.\nSome secondary threats exist with Bluefin because they are slow-growing species that depend on food supplies from healthy oceans as well as acidification from global warming affecting their prey source.\nBluefin tuna is a commercially valuable fish and is hunted by fisheries all over the world. Bluefin is listed as an endangered species due to excessive hunting.\nBluefin tuna can swim up to 40 miles per hour, reach up to 10 feet in length, their migratory habits make them difficult for conservation efforts by any one government, 80% of the world catch go to Japan, and it takes about 15-30 years to mature.\nOceana is the largest international organization focused only on ocean conservation, protecting marine ecosystems and endangered species like the Bluefin Tuna. The Monterey Bay Aquarium conducts research projects and tagging Bluefin tuna in order to study migration, habitats, diets, Bluefin populations and more.\nBluefin have declined by 90% since the 1950s due to overfishing, which is why it’s endangered.\nWhat are Bluefin Tuna?\nBluefin Tuna are deep-sea fish that have a dark blue upper body and silvery-white underbelly.\nThey can grow up to 10 feet long and weigh more than 1,500 pounds. Bluefin is one of the most expensive fish in the world and is largely sought after for its exceptional taste and tenderness.\nBluefin tuna is hunted by commercial fisheries all over the world, but they are on the verge of extinction.\nWhy Bluefin tuna is endangered?\nBluefin Tuna is endangered due to overfishing by commercial fisheries.\nThink about it this way: there used to be a lot of these fish in the ocean, but now they’re almost all gone. That sounds kind of like the whole world ending if we don’t start protecting them soon.\nWhat can I do to help Bluefin tuna?\nYou can help Bluefin tuna by avoiding Bluefin products.\nIf there is no demand for Bluefin, then the fisheries will stop hunting it. You can also contact your local congressman to ask them to create laws that would protect Bluefin tuna.\nWhat will happen if Bluefin tuna becomes extinct?\nIf Bluefin tuna becomes extinct, the marine ecosystem will be disrupted. This could lead to the extinction of other species and a decline in the overall health of the ocean.\nThe loss of Bluefin tuna would also be a major economic blow to the Bluefin tuna industry. Bluefin tuna has declined by over 90% since 1950s, which is why it’s endangered.\nOther Species Profiles"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"sensitive"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:cb511ada-8e34-40f5-86d1-2a4688ab5db9>","<urn:uuid:7911b493-3211-49cc-a8b2-34f5d228cd7e>"],"error":null}