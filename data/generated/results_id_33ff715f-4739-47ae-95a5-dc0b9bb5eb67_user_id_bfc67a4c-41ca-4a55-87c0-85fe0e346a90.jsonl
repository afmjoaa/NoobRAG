{"question":"How do the learning approaches in microlearning compare to the skill development requirements in leatherworking in terms of hands-on practice?","answer":"Microlearning focuses on short, digestible content lasting 10-15 minutes where students often create content and apply concepts through social media platforms like Twitter and Snapchat. In contrast, leatherworking requires extensive hands-on practice developing specific physical abilities including manual dexterity, arm-hand steadiness, and finger dexterity for manipulating and assembling objects. While both involve practical application, leatherworking demands more intensive physical skill development through repeated practice.","context":["Got 10 minutes? Then you have time to learn something.\nMicrolearning, or a short burst of learning that lasts from 10 to 15 minutes, isn’t just a new trend you’ll find on teaching blogs. Educators have been doing it for years without labeling it as such.\n“It’s an old concept. Flashcards are an example of microlearning,” says Lindsey Sudbury, an academic instructional technologist at Northeastern University who recently co-authored an article on the topic and presented the research at EDUCAUSE’s 2017 conference. “It started out as analog, but now there are digital versions of flashcards. It is just the idea that you can take any information and just do it as you have time.”\nWhat Is Microlearning?\nAs educators look to help students integrate what they already know into new content, Sudbury says microlearning can help students use that knowledge.\nThese 10-or 15-minute learning bursts have students reiterate concepts they are learning in hyper-focused, digestible content. The Northeastern article cites one example of microlearning as having students apply their knowledge of chemical processes after reviewing a five- to 15-second clip of a chemical reaction.\n“We focus on microlearning where students sometimes consume, but often create content,” she says. “It’s usually created quickly after a lot of thought and integrating what they already know.”\nAt Northeastern, students flex their knowledge on Twitter and Snapchat to create posts for other students, or even faculty, to consume.\nHow Microlearning Is Helping Prevent Student Burnout Syndrome\nWith students constantly being taught more complex concepts, breaking education into smaller pieces can help to reduce the cognitive overload and the student burnout syndrome that can come with that.\n“With microlearning, you’re constantly getting this information over and over again, so it’s allowing for you to really synthesize information and connect those dots more frequently,” says Clair Waterbury, an academic instructional technologist at Northeastern and Sudbury’s co-author.\nThese short bursts of educational material, often in the form of a video, or in Northeastern’s case, a social media post, also fit today’s learners better.\nWith its digital nature, microlearning content can be accessed anywhere and allow students to learn at their own pace, an Oust Labs blog reports.\nMicrolearning Platforms: Leveraging Social Media for Students\nTo appeal to today’s learners, Sudbury and Waterbury find social media to be the perfect platform to engage in microlearning.\n“Our students and faculty are already doing a lot of microlearning very informally, and without even knowing it, on social media,” says Waterbury.\nRather than asking students and teachers to use an entirely new digital tool to engage in microlearning, Sudbury and Waterbury asked faculty and students to simply formalize the processes they already had.\nWaterbury and Sudbury say successful social microlearning should do three specific things:\nProvide opportunities to deepen information retention\nCreate learning communities\nIncrease student engagement\nOn Twitter, for example, teachers could have students post using a classroom hashtag before or after class to stimulate conversation outside class, further engagement with their students and allow students to apply what they are learning in class to interactions outside of class.\n“One of the great things about social microlearning is that you are leaving the classroom and you’re still thinking about the concept, you’re following different experts and you’re learning from real-world experience,” says Waterbury. “The biggest benefit was just breaking the walls of the classroom.”","Leatherworking & Upholstery\nTypes of Degrees Leatherworking & Upholstery Majors Are Getting\nThe following table lists how many leatherworking and upholstery graduations there were in 2018-2019 for each degree level.\n|Education Level||Number of Grads|\nWhat Leatherworking & Upholstery Majors Need to Know\nPeople with careers related to leatherworking were asked what knowledge areas, skills, and abilities were important for their jobs. They weighted these areas on a scale of 1 to 5 with 5 being the highest.\nKnowledge Areas for Leatherworking Majors\nAccording to O*NET survey takers, a major in leatherworking should prepare you for careers in which you will need to be knowledgeable in the following areas:\n- Production and Processing - Knowledge of raw materials, production processes, quality control, costs, and other techniques for maximizing the effective manufacture and distribution of goods.\n- Mechanical - Knowledge of machines and tools, including their designs, uses, repair, and maintenance.\n- Customer and Personal Service - Knowledge of principles and processes for providing customer and personal services. This includes customer needs assessment, meeting quality standards for services, and evaluation of customer satisfaction.\n- Mathematics - Knowledge of arithmetic, algebra, geometry, calculus, statistics, and their applications.\n- English Language - Knowledge of the structure and content of the English language including the meaning and spelling of words, rules of composition, and grammar.\nSkills for Leatherworking Majors\nWhen studying leatherworking, you’ll learn many skills that will help you be successful in a wide range of jobs - even those that do not require a degree in the field. The following is a list of some of the most common skills needed for careers associated with this major:\n- Critical Thinking - Using logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions or approaches to problems.\n- Active Listening - Giving full attention to what other people are saying, taking time to understand the points being made, asking questions as appropriate, and not interrupting at inappropriate times.\n- Operation Monitoring - Watching gauges, dials, or other indicators to make sure a machine is working properly.\n- Speaking - Talking to others to convey information effectively.\n- Judgment and Decision Making - Considering the relative costs and benefits of potential actions to choose the most appropriate one.\nAbilities for Leatherworking Majors\nAs a leatherworking major, you will find yourself needing the following abilities:\n- Near Vision - The ability to see details at close range (within a few feet of the observer).\n- Manual Dexterity - The ability to quickly move your hand, your hand together with your arm, or your two hands to grasp, manipulate, or assemble objects.\n- Arm-Hand Steadiness - The ability to keep your hand and arm steady while moving your arm or while holding your arm and hand in one position.\n- Finger Dexterity - The ability to make precisely coordinated movements of the fingers of one or both hands to grasp, manipulate, or assemble very small objects.\n- Control Precision - The ability to quickly and repeatedly adjust the controls of a machine or a vehicle to exact positions.\nWhat Can You Do With a Leatherworking & Upholstery Major?\nBelow is a list of occupations associated with leatherworking:\n|Job Title||Job Growth Rate||Median Salary|\nHow Much Do Leatherworking & Upholstery Majors Make?\nSalaries According to BLS\nAverage salaries range from $29,800 to $35,920 (25th to 75th percentile) for careers related to leatherworking. This range includes all degree levels, so the salary for a person with just a bachelor’s degree may be a little less and the one for a person with an advanced degree may be a little more.\nTo put that into context, according to BLS data from the first quarter of 2020, the typical high school graduate makes between $30,000 and $57,900 a year (25th through 75th percentile). The average person with a bachelor’s degree (any field) makes between $45,600 and $99,000. Advanced degree holders make the most with salaries between $55,600 and $125,400.\nAmount of Education Required for Careers Related to Leatherworking & Upholstery\nSome careers associated with leatherworking require an advanced degree while some may not even require a bachelor’s. Whatever the case may be, pursuing more education usually means that more career options will be available to you.\nFind out what the typical degree level is for leatherworking careers below.\n|Education Level||Percentage of Workers|\n|Less than a High School Diploma||25.7%|\n|High School Diploma - or the equivalent (for example, GED)||59.8%|\n|Post-Secondary Certificate - awarded for training completed after high school (for example, in agriculture or natural resources, computer services, personal or culinary services, engineering technologies, healthcare, construction trades, mechanic and repair technologies, or precision production)||0.2%|\n|Some College Courses||11.7%|\n|Associate’s Degree (or other 2-year degree)||1.1%|\nOnline Leatherworking & Upholstery Programs\nIn the 2018-2019 academic year, 13 schools offered some type of leatherworking and upholstery program. The following table lists the number of programs by degree level, along with how many schools offered online courses in the field.\n|Degree Level||Colleges Offering Programs||Colleges Offering Online Classes|\n|Certificate (Less Than 1 Year)||11||0|\n|Certificate (1-2 years)||7||0|\n|Certificate (2-4 Years)||0||0|\n|Doctor’s Degree (Research)||0||0|\n|Doctor’s Degree (Professional Practice)||0||0|\n|Doctor’s Degree (Other)||0||0|\nIs a Degree in Leatherworking & Upholstery Worth It?\nThe median salary for a leatherworking grad is $30,110 per year. This is based on the weighted average of the most common careers associated with the major.\nExplore Major by State\nMajors Related to Leatherworking & Upholstery\nYou may also be interested in one of the following majors related to leatherworking.\n|Major||Number of Grads|\n|Precision Metal Working||56,353|\n|Other Precision Production||177|\n|Precision Production Trades||14|\n- College Factual\n- College Scorecard\n- National Center for Education Statistics\n- O*NET Online\n- U.S. Bureau of Labor Statistics\n- Usual Weekly Earnings of Wage and Salary Workers First Quarter 2020\n- Image Credit: By Steven M O’Kelley under License\nMore about our data sources and methodologies.\n|Request Info||Southern New Hampshire University You have goals. Southern New Hampshire University can help you get there. Whether you need a bachelor's degree to get into a career or want a master's degree to move up in your current career, SNHU has an online program for you. Find your degree from over 200 online programs. Learn More >|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:ac3d33b5-0394-41ba-ad25-c2828841ad7b>","<urn:uuid:175b1a21-cd50-4175-a6fc-f487a249bcd9>"],"error":null}
{"question":"When configuring debugging for ASP.NET applications, what are the important considerations for both development and production environments?","answer":"In development, debugging requires two key steps: activating the ASP.NET debugger in the project's Property Pages and enabling debugging in the web.config file by setting debug='true'. For production environments, it's recommended to set compilation debug to false to prevent application slowdown. When debugging a deployed application, you must attach to the ASP.NET worker process using Visual Studio, but caution is needed as setting breakpoints will halt all production users at that point. Additionally, debugging requires higher user rights than just running the application, so proper permissions must be granted.","context":["Generally we debug our ASP.NET web application from Visual Studio. Visual Studio has its own ASP.NET engine, which is capable enough to run and debug your web sites inside Visual Studio. However, if your site is hosted on IIS and you want to debug that site directly, how would you debug it? When we host sites on IIS, the Worker Process (w3wp.exe) is used to run the web application. We need to attach to this particular process from Visual Studio to debug the web application. This article describes the overall idea of debugging an application using this method. It also describes the Worker Process, Application Pool and selecting a particular process if there are multiple Worker Processes running on IIS, using\niisapp.vbs. I hope you will enjoy this article and provide your valuable suggestions and feedback.\nVisual Studio has its own integrated debugging engine, which debugs our code when we run the application in Visual Studio. If we are developing a site and need to debug the code, we just set breakpoints and do the debugging (Note: In this article I do not describe how to set the debug mode).\nWhen we run the application, execution breaks when certain a breakpoint is reached. It is very simple, because when an ASP.NET application is running in Visual Studio, it is under the control of the ASP.NET Engine which is integrated with Visual Studio. If you want to check which process is running for debugging, run the web application from Visual Studio: you will get a popup notification as shown below.\nFig. 1: Taskbar popup when debugging is started from Visual Studio\nThis indicates a process is starting to run the ASP.NET application. Double-click on the icon and a popup window will appear to show the details.\nFig. 2: Development Server process details\nBehind the running process is WebDev.WebServer.exe. When We press F5 to run the application, this process starts to execute the it. If you want run the application from command prompt, you have to perform the following steps.\nSteps to run a web application from the command prompt:\n- Open The Visual Studio command prompt\n- Run WebDev.WebServer\nThe following screen will come up. Check the Example section there.\nFig. 3: WebDev.WebServer usage notification\nNow back to IIS debugging. IIS comes into the picture when we deploy or host the site. After deploying the site on IIS, if we want to debug the site there, we can't do it directly as in Visual Studio. IIS has its own\nWorker Process which takes care of all execution and maintenance of deployed web applications. I will describe the details of the Worker Process in a later section. So, if we have running process in IIS and we need to debug the application, first of all we have to attach to the correct process from Visual Studio. Before describing that, let's just have a look at the Worker Process and Application Pool.\nThe Worker Process (w3wp.exe) runs ASP.NET applications within IIS. All ASP.NET functionality runs under the scope of the Worker Process. When a request comes to the server from a client, the Worker Process is responsible for generating the request and response. Its also maintains the InProc session data. If we recycle the Worker Process, we will lose its state. For more information, read this article: A Low-Level Look at the ASP.NET Architecture\nThis is one of the most important things that you should create for your own application in a production environment. Application Pools are used to separate sets of IIS Worker Processes that share the same configuration. Application Pools enable us to isolate our web application for better security, reliability, and availability. The Worker Process serves as the process boundary that separates each Application Pool, so that when one Worker Process or application has an issue or recycles, other applications or Worker Processes are not affected.\nFig. 4: Relationship between Application Pool and worker process in IIS\nThe name of the default application of IIS 6.0 is DefaultAppPool. After hosting the site on IIS, if we check the properties of the virtual directory, we can to view that information as follows.\n- Start Menu → Run command →\n- Expand DefaultWebSites or Other Web Sites, where you have created the virtual directory\n- Right Click on the virtual directory\n- Click on Properties\nThe following virtual directory properties screen will come up, showing the Application Pool name which is assigned to the selected site.\nFig. 5: Virtual directory properties showing Application Pool name\nIf you want to check the list of all Application Pools in IIS, you have to expand the Application Pool node on IIS Server.\nFig. 6: List of Application Pools\nNow, each and every Application Pool should have the minimum of one Worker Process which takes care of the operation of the site which is associated with the Application Pool. Right-click on the Application Pool → go to the Performance tab, check near the bottom of the tab, there is a web garden section, and by default, the number of Worker Processes is 1. An Application Pool containing more than one Worker Process called a Web Garden.\nFig. 7: Application Pool properties showing Web garden\n- Open the IIS Console, right-click on the Application Pools folder, select New\n- Give the Application Pool ID and click OK.\n- Now, right-click on the virtual directory and assign the newly created Application Pool to that virtual directory.\nNow, this web site will run independently, within StateServerAppPool, so any problem related to other applications will not affect this application. This is the main advantage of creating a separate Application Pool.\nWhat I have said up to now give you a good idea of Worker Processes and Application Pools. You should have a clear understanding on these before going on to the next part. Now I will show you how to debug a site which is hosted on an IIS Server.\nFor the demonstration, I have created a web site called SampleWebSite and hosted it on to my local IIS. Below is default page output.\nFig. 9: Sample web site\nNow, as I have already explained, the process name is w3wp.exe, so we can check it from our Task Manager whether or not the Worker Process is running.\nFig. 10: Task Manager showing the running IIS process\nNow we are going to attach to the process. In Visual Studio, go to Debug → Attach to Process\nFig. 11: Opening the Attach to Process window\nAfter clicking Attach to Process, the following screen will come up\nFig. 12: Attach to Process window, showing a single Worker Process running\nNow we are able to see that the Worker Process is running, and we need to attach that process. Select the process and click on the Attach button. After that, look at the two images below:\nFig. 13-1: Process attached successfully\nFig. 13-2: Process not attached\nDid you notice the breakpoint symbol? If the Worker Process attached successfully, within the code, the breakpoint symbol should be a solid circle. Otherwise it will have a warning icon as shown. For a single Worker Process, this scenario is not common. However, when we have multiple Worker Processes running on IIS, then we can have some confusion. I will discuss the same in a later section.\nNow if we click the Debug button after successfully attaching to the process, execution will stop at the breakpoint.\nNext, let's have a look at what to do if we have multiple Worker Processes running.\nNow, when this scenario will come up? When we have multiple sites hosted on IIS, and those sites have their own Application Pool. Now, multiple Application Pools means multiple Worker Processes are running.\nHere I have three Application Pools in my IIS. They are:\n- Default Application Pool\n- Generic Application Pool\n- State Server Application Pool\nNow, my SampleWebSite is associated with the DefaultAppPool. Now, I want to attach the process to debug my SampleWebSite. Follow the same steps as before. Open the Process Attach window:\nFig. 14: List of multiple Worker Process\nJust have a look, there are three Worker Processes currently running, and you have to attach one of them. But, you do not know which Worker Process is the default Application Pool's. What you do is, you select any one of them at random, let's say the one with process ID = 4308\n, and suppose it is not the Worker Process for the default Application Pool. So what will happen if you attach to a wrong process? Check the image below:\nFig. 15: Breakpoint when the process is not attached correctly\nNow what is the solution for the previous case? Here is a quick tip:\n- Start → Run command → cmd\n- Change directory to \\Windows\\System32\n- Run the command:\nand wait for the output. Wow! You get a list of running Worker Process, Process ID and Application Pool Name!\nFig. 16: List of running Worker Processes with PID and Application Pool name\nFrom here you can easily identify the correct Application Pool name and its process ID. Now, return to Visual Studio → Attach Process. Now you know that the process ID for Default Application Pool is\n1772, so Attach to that process.\nFig. 17: Attach the correct process for debugging\nNow, enjoy debugging!\nFig. 18: Breakpoint is ready\nSometimes we need to debug our application which is hosted on IIS. For that, we need to attach the running Worker Process to the Visual Studio. If we have multiple Worker Processes running on the IIS server, we can identify the appropriate Worker Process by using the command\nI hope this article will help beginners who are still struggling with debugging applications that are hosted on IIS. Please give your feedback and suggestions to improve the article.","Dealing with errors is an important part of every application. Web applications aren’t an exception, in the contrary, they should be even better in graceful error handling, because of their huge amount of users.\nWe have three possible locations of caching errors in an ASP.NET application. The first one is the source of the error itself, by wrapping our code, which is likely to fail, in a try-catch block. This is a very good solution for the problem, since the error gets treated on the spot of its occurrence. You can decide to bubble the error forth, and catch it in the Page_Error event, or even further, in the Application_Error event, defined in global.asax. There’s a fourth opportunity, but it isn’t the best solution: define custom error pages in the customErrors section of your web.config. They are part of the apologize, not the solution for the problem, so you should restrict the use of them. Even worse, when you are on a custom error page, you have no way to get and deal with the error lead you there.\nBefore writing error-handling code, make sure that you do everything to prevent errors from happening. The best way to do so is to use a massive amount of validation. String.Empty and the Exists method should be very close friends of you.\nBut if the worse happened, you should fail elegantly, and without showing any inner workings of your application. Hold the detailed error messages to server administrators, and give user-friendly and meaningless errors to the everyday users. Also, you should log the exception (Health monitoring comes handy for this task).\nContinue reading “Establish an error-handling strategy”\nTo debug an ASP.NET application, first you need to configure debugging. This is a process requires two steps to be taken. First, you must activate the ASP.NET debugger for your current project. To do this, right click on the project in solution explorer, and select Property Pages. In the dialog box, then select Start Options. Look for the Debuggers section in the bottom, and make sure ASP.NET is checked.\nThe second step is to enable debugging either for your whole application, or just different pages of it. To do so, in the compilation section of the web.config file, set debug=”true”. This causes debugging symbols to be added to your whole page. If you want to debug only some pages, you should set Debug=”true” in the @Page directive of them.\nIf you have the necessary rights for debugging (the application is running locally under your own user entity, or you’re an administrator) you can debug by now. If it is not the case, you should seek a way to grant yourself these rights. It’s because debugging an application needs more rights than just running it. Debugging can be harmful if not implemented carefully.\nIf you need to perform remote debugging then check back later, I’ll post how to do it very soon.\nWhen you want to debug a deployed application (which is currently in production usage) you need to attach to the (possibly) remote ASP.NET worker process, and then use Visual Studio to debug it. Note that when you set a breakpoint in the application, any production user will be halted there, so be careful when using one.\nWhen you published your web application to a production server, it is suggested that you set compilation debug to false, because it may slow down your application.\nContinue reading “Configure Debugging and Custom Errors”"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:0a59f5a2-1cb3-46a7-a308-8ec82891f241>","<urn:uuid:7029bc14-ed97-42e0-860e-25caa395b242>"],"error":null}
{"question":"What are the key differences between cash flow budgets and income statements when tracking business performance?","answer":"Cash flow budgets and income statements differ in several key ways when tracking business performance. A cash flow budget is a forward-looking tool that records sales and expenses according to when they are actually received or paid, showing the amount and timing of expected cash movements. It helps identify when cash will be in surplus or deficit and assists in planning borrowing needs. In contrast, an income statement (P&L) tracks changes in the overall financial position of the company, including non-cash items like asset depreciation. The P&L captures value changes beyond just cash movements, showing a broader picture of profits and losses from all business activities.","context":["The Role of Budgeting\n• TEACHING OBJECTIVES\n• 1. Introduce the purpose of budgeting.\n• 2 Identify Cashflow Budgeting\n• 3. Show the benefits & limits of budgets.\n• 4. Show how the budgeting process works.\n• 1. Introduction\n• Once a farm has identified customer needs & changes\nthrough forecasting, it needs to determine if it can be met\n• A . Knowing how to budget is certainly part of this process.\n• B. A budget is a master financial plan or a \"blueprint for\naction\" in the future.\n• 11. The Purpose of a Budget\n• A. A budget is a formal estimate of future revenues & costs\n• 1.A detailed breakdown of all costs & revenues is necessary\nfor attaining profit goals: Farms have to analyze operations\nto develop reliable estimates of revenues & costs.\n• 2. If budgeting is done right, it forces better thinking about\nthe farm's goals & purpose & how to achieve them. It forces\nmgmt to ask what to be done if certain target levels of sales\n& costs are to not being realized.\n• B. Making realistic budgets requires clear thinking; As a\nfinancial plan of firm’s expectations over time, it shld be a\nan assessment of what each part of the firm can accomplish\n• Make separate budgets for each part of business:\n• 3. Follows with Cost & Expenses Preparation:\nRequires forecasting variable operating & fixed\nexpenses. It uses accounting principles in its\n• V. The Cash Flow Budget\n• 1 To identify cash flow budgeting as a tool for financial\ndecision making & business analysis\n• 2 To understand structure & component of cash flow budget\n• 3 Illustrate the procedure for completing a cash flow budget\n• 4 To describe both the similarities and differences between\na cash flow budget and an income statement\n• 5 Discuss advantages & potential uses of a cash flow budget\n• 6 To show how to use a cash flow budget when analyzing a\npossible new investment\n• Characteristics of a Cash Flow Budget\n• 1. Records sales, & expenses according to when they are received or\npaid:CFB shows amount & timing of cash expected to flow in & out\nof the firm during budget period. –i.e. its a summary of projected cash\ninflows & outflow for a business over a given period of time in an\norganised time sequence.\n• a. Cash Inflows: Come from sales, services, borrowing, sale of capital\nitems, & from payments on accounts receivable.\n• b. Cash Outflows: Include payments for goods & services purchased,\ndebt, taxes, salaries, capital assets.\n(sales, new loans etc)\n• Cash outflows\n(expenses, debt payment\nloans payments etc)\n• 2. CFB shows Cash Receipt & Disbursements: Shows when\ncash shld be available & when cash payments must be made\n– i.e. assist mgmt plan when cash will be in surplus/ deficit\n• 3. CFB is a forward way of cash planning. It serves as a\ntool for investing excess cash & borrowing needed cash:\nCFB allows mgmt to invest surplus cash to earn extra\nincome or help to decide when & how much to borrow in\ndeficit periods & ability to repay loanns\n• Structure Of A Cash Flow Budget\n• Table 1 a condensed form of structure & format of a CFB is\nTable 1 Simplified Cash Flow Budget\nTime Prd 1 Time Prd 2\n• 1. Beginning cash balance $1,000 $ 500\n• Cash inflow (Sources):\n2. Farm product sales $2,000 $12,000\n3. Capital sales 0 5,000\n4. Miscellaneous cash income 0 500\n5. Total cash inflow $3,000 $18,000\n• Cash outflow (Uses):\n6. Farm operating expenses $ 3,500 $ 1,800\n7. Capital purchases 10,000 0\n8. Miscellaneous expenses 500 200\n9. Total cash outflow $14,000 $ 2,00\n• 10. Cash balance (line 5 - line 9) -11,000 16.000\n11. Borrowed funds needed $11,500 0\n12. Loan repayments (principal and interest) 0 11,700\n• 13. Ending cash balance (line 10 + line 11 - line 12) 500 4,300\n• 14. Debt outstanding $11,500 $ 0\n• Potential Sources of Cash:\n• 1. The beginning cash balance or cash on hand\n• 2. Product sales or cash revenue from business operation\n• 3. Capital sales - cash received sale assets like land,\nmachinery, breeding livestock, & dairy cattle\n• 4. Non-business cash receipts – such as non-farm cash\nincome, cash gifts, & other sources of cash\n• 5. New borrowed capital or loans received\n• The last source is not included in the cash inflow section\nbecause borrowing requirements are not known until the\ncash outflows are matched against the cash inflows.\n• In prd 1, total cash inflow of $3,000 includes beginning\ncash balance. The total cash outflow = $14,000. Projected\ncash balance = -$11,000. This deficit will require borrowing\n$11,500 to provide a $500 minimum ending cash balance.\n• Uses of Cash:\n• 1. Farm operating expenses – i.e. the usual cash expenses\nincurred in producing the farm revenue\n• 2. Capital purchases – i.e. full purchase price of new capital\nassets e.g. land, machinery, & dairy/breeding livestock\n• 3. Non-business & other expenses – i.e. cash used for living\nexpenses, income & social security taxes, etc.\n• 4. Principal payments on debt – i.e. Interest payments shld\nalso be included here unless they were included as part of\nthe operating expenses.\n• Ending Cash Balance:\n• Difference btwn total cash inflows & total cash outflows for\nany time period.\n• Constructing a Cash Flow Budget\n• The following steps summarize the process & info needs.\n– 1. Develop a business plan. It’s impossible to estimate cash\nrevenues & expenses without knowing what to be produced.\n– 2. Estimate crop pdn & livestock feed reqr’mts. Most, if not all, of\nthis info should be found in the whole farm plan.\n– 3. Estimate cash receipts from livestock enterprises. include sales\nof livestock as well as livestock products such as milk & wool.\n– 4. Estimate cash crop sales.\n– 5. Estimate other cash income. Include interest & dividends on\ninvestments & non-farm sources of cash revenue.\n– 6. Estimate cash operating expenses.\n– 7. Estimate personal & non-farm cash expenses. e.g. cash needed\nfor living expenses, income & social security taxes.\n– 8 Estimate purchases & sales of capital assets e.g. purchase price\nof buildings, breeding livestock, land to be purchased & total cash\nto be received from capital assets sale\n– 9. Record scheduled principal/interest payments on existing debt.\n• Uses For A Cash Flow Budget\n• Primary use of CFB is to project timing & amount of new\nborrowing & loan repayment a business will need during the\nyear. Other uses and advantages are:\n• 1. CFB can prevent excessive borrowing & shows how\nrepaying debts ASAP will save interest.\n• 2. CFB may suggest ways to rearrange purchases &\nscheduled debt repayments to minimize borrowing.\n• 3. CFB combines both business & personal financial affairs\ninto one complete plan.\n• 4. A lending agency can offer financial advice & spot\nweaknesses/strengths in a business based on completed CFB\n• 5. Can assist managers to obtain discounts on input\npurchases by making a prompt cash payment.\n• 7. CFB can help spot imbalance btwn short, intermediate &\nlong-term credit and suggest ways to improve the situation.\n• VIII. Budget Benefits\n• A. It helps managers better understand their business\n• B. It provides a \"yardstick\" by which business\nperformance can be measured by others.\n– 1. should be checked frequently to see progress\n– 2. if negative deviations are found, it permits quick\ncorrective action before things get worse\n• IX. Summary\n• A. Budgeting is a critical step in business planning\n• B. It puts ideas into numbers for profit or loss\n• C. Budgets are valuable tools in good management","What is an asset?\nToday I’m going to be talking about assets and their place in the financial planning landscape. Broadly speaking an asset is something that has lasting value and that can be sold. We’ll get into the specifics of different asset types later. First, let’s take a look at how assets work financially.\nAssets on the cash flow statement\nIt’s often said that cash is king. New and existing businesses look to their cash flow to understand potential dangers to the business and evaluate how much ready cash they have to carry out new projects. However relying on cash flow entirely doesn’t give you the full picture of your business. This is particularly true when it comes to assets, which only make an appearance on the cash flow when they are bought or sold. In most cases, assets are bought by companies and then used until they are either no longer fit for purpose and are then either written off or sold on for a small fee.\nAssets on the profit and loss statement\nOn the Profit & Loss Statement, asset purchase and disposal are recorded, along with any depreciation or appreciation of the asset. The P&L tracks changes in the financial position of the company, which takes into account more than just changes in the flow of cash in and out of the business. The P&L displays changes in value through tracking the business’ profits and losses.\nWe often think of profits and losses as purely to do with sales and expenses paid by the business – cash movements in short. But businesses can make profits and losses from changes in the value of their assets as well. Two examples from everyday life are cars and investments. A car gradually loses value by depreciating. The amount of value lost would be recorded as a loss on the P&L. Eventually the car might not be worth anything at all! Whereas an investment may sometimes lose value, but will generally increase in value. Any decrease in value would be recorded as a loss on the P&L, while increases in value would be recorded as profit.\nAssets on the balance sheet\nAssets are a major element on the balance sheet – the third and final of the major financial reports. The balance sheet completes the picture hinted at by the P&L, not just displaying the profit or loss arising from the business’ assets, but their value at any given time.\nThe purpose of a balance sheet is to lay out the things that make up the value of the business. These are split into three categories – assets, liabilities and equity. These must ‘balance’ in order for everything in the business to be accounted for. As equation at the root of the balance sheet puts it…\nAssets = Liabilities + Equity\nSo what role do assets play in balancing the business?\nAssets are a measure of what the business owns. If a business buys assets its value increases. But they also provide security. Owning assets gives the business a means of paying off its debts if necessary, without impacting its shareholders and reducing their equity.\nThere are several subcategories of asset, some of which are treated in different ways to others.\nCurrent and fixed assets\nThe current/fixed asset classification divides assets in terms of their liquidity – how available they are to be turned into cash. This classification is used on most balance sheets. But there are other classifications of assets as well.\nCurrent Assets are assets that can be turned into ready cash in a short amount of time. They include…\nFixed (or ‘Non-current’) assets\nFixed assets, by contrast, are not readily convertible into cash. They can be sold, but may not be able to be sold quickly enough to cover business debts.\nPlant & equipment\nFixtures and fittings\nTangible and intangible assets\nTangible and intangible assets are classified based on their physicality. An asset is tangible if it physically exists. Intangible assets are often not covered by other asset classifications – they include such things as goodwill, brand, copyrights, patents and trademarks. Intellectual property would be accounted for as an intangible asset – but valuing these kinds of assets can be tricky. Definitely seek advice if the value of these assets is going to be important to the business’ finances.\nOperating and non-operating assets\nPut simply, operating assets are required for the running of the business, while non-operating assets are owned by the business but not a part of its day-to-day operations. Cash machines and delivery vehicles would be operating assets, while investments are non-operating assets in most businesses.\nPlanning assets in Brixx\nIn Brixx you can rename, and thus reclassify assets as you wish. The Brixx asset, investment and inventory components give you the tools you need to build a coherent pictures of a business’ assets, populating the plan’s dashboard, cash flow, P&L and balance sheet."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:13a0b212-5d2f-4bdf-b7bf-786c4fe06d86>","<urn:uuid:35dcf3f9-bc1c-4621-b6fb-91db3bc97d77>"],"error":null}
{"question":"Russia reforms success vs population decline 1991-present?","answer":"While Russia initially succeeded in defeating the Soviet coup and establishing new freedoms in 1991, its reforms were ultimately less radical than they appeared, with elites preferring 'managed democracy' to rule of law and media freedom withering. On the demographic front, Russia experienced significant population challenges, briefly dropping below 142 million in 2009. Though there has been some recovery through migration and increased fertility rates, Russia still faces long-term population decline, with projections showing continued decreases through 2050 despite immigration helping to slow the losses.","context":["An American diplomat on the ground in 1991 explains why pushing back the reactionary coup 20 years ago was the easy part.\nBoris Yeltsin and Mikhail Gorbachev at the extraordinary fifth session of Peoples' Deputies of the Soviet Union On the 3rd Septemberб 1991. Photo: ITAR TASS\nTwenty years ago in Moscow popular opposition defeated the reactionary putsch intended to turn back the clock of reform in the dying Soviet Union. The experience was, initially, similar to the recent ‘Arab Spring’.\nWhat went right?\nThe putsch failed quickly, sparing Russia a trauma like Syria or Libya today. Crucially, the Russian armed forces remained professional, sparing Russia the militarization of politics seen in Germany in the Twenties or Yugoslavia in the Nineties. Yeltsin jettisoned the past quickly – both the Communist Party and the Soviet empire – to focus Russian efforts and resources on Russia’s future. Doors previously closed to the outside world were opened for Russians to explore new lands and ideas. Freedom of speech and the media attained heights never seen in Russia before or, sadly, since. Youth was welcomed into the halls of power. The Cold War, radically scaled back by Gorbachev, was abandoned. Russia turned West and sought a genuine European identity.\nWhat went wrong?\nIt is vastly easier – and surer – to tear down a poor edifice than to design and build a replacement. The vacuum of power at all levels and in all fields attracted both the best and the worst, with the former a distinct minority. Youth and former dissidents demonstrated their talent at debate, but not at organization, administration or compromise. Ideologies and reform experiments imported from the West – especially in economic stabilization – often proved woefully wrong for Russia and deepened the damage left by the Soviet collapse. Economic failures tarnished nascent efforts at political reform. This led to a vacuum of democratic legitimacy and ultimately to the restoration of the ‘vertical of power’: neither neo-Soviet nor proto-democratic. A genuine threat to Russian integrity in Chechnya provoked a cure worse than the disease. As Aleksandr III once declared Russia’s only friends were its army and navy, today the state rests on the pillars of oil and gas, which corrupt even as they enrich.\nWhy did things go so wrong?\nSeven decades of Soviet misrule infected almost every field of public policy: agriculture, industry, energy, investment, infrastructure, security, politics, civil society, religion, health, education, media. The Soviet Union was not so much under-developed as critically mis-developed, with fundamental reform needed in every sector. Where to start? Historian General Dmitriy Volkogonov once told me that many good people were needed in every field, but there simply were nowhere near enough to go around.\nExpectations of a new and improved standard of living – “to live like normal people” – were high while understanding of the challenges was low. How do you quickly reform an economy lacking even double-entry bookkeeping to know whether an enterprise adds or destroys value? Some Russians were less willing than their Chinese counterparts to learn from the outside world, while many continued to believe “here is better.”\nRussia did not take part in the transformation of former Warsaw Pact states, in part because Europe could not afford it, but in large part because Russia chose not to. European integration requires significant surrender of sovereignty and of pretensions to Great Power status. Russia took a go-it-alone approach that deprived it of many benefits of a global economy. Russia remains today an outlier in most fields, by choice.\nRussia’s reforms – even under Yeltsin – were less radical than they appeared. Elites preferred ‘managed democracy’ to rule of law. Political parties never matured, while a free media withered. Russians today enjoy vastly greater freedoms than did their parents, but these are personal freedoms divorced from genuine political liberty. Russians know the difference and judge their leaders on the basis of material progress rather than legitimacy. Millions of the most talented younger people have sought new lives abroad. Their loss reflects the continuing alienation of Russia’s ruling elite from its own people – an old Russian story.\nFinally, the outside world, including the United States, was timid in engaging the new Russia to fulfill the rhetoric of a “Europe whole and free”. Europe and America welcomed the demise of Cold War institutions in the East, but maintained them in the West, especially NATO. As reforms failed in Russia, Western advocates of unworkable policies – the “Washington consensus” – blamed the failures on inherent Russian dysfunction rather than on bad policies.\nSome observers of Russian affairs, both at home and abroad, believe the country is approaching another historical turning point, perhaps a revolutionary shift. If so, the ‘Russian Spring’ of the early Nineties teaches that revolution is easy, but reform is hard. Discarding the Soviet past required courage, enthusiasm and hope. Building a better Russia demanded realism, patience and stamina – and still does.\nE. Wayne Merry was the American Foreign Service Officer in charge of reporting and analysis on Russian domestic politics at the United States Embassy in Moscow, 1991-94.","Soviet Republics – Demographic Divergence by EurasiaNet\nA EurasiaNet Partner Post from: RFE/RL\nAfter 25 years of independence, some former Soviet republics are experiencing record population decline while others are soaring to new highs. This is a story about demographic destiny.\nPopulation: Opposite trends\nThe extent of population loss in many former Soviet republics has been staggering. Ukraine has lost more than 6 million people since gaining independence in 1991, while the Baltic states have lost a combined 20 percent of their population. Russia’s population briefly dipped below 142 million in 2009 — a post-Soviet low — but has recently rebounded due to migration, increasing fertility, and declining mortality. In the Caucasus, Armenia and Georgia have experienced similar population decreases while Azerbaijan has surged.\nData from Central Asia tell a very different story. Kyrgyzstan, Tajikistan, Turkmenistan, and Uzbekistan all have youthful booming populations that are at historic levels. Kazakhstan’s population fell for over a decade after the dissolution mainly due to an exodus of ethnic Russians and Germans, but has grown overall thanks to strong fertility.\nRussia has been the main destination for migrants from the post-Soviet space. Many of these immigrants are ethnic Russians once dispersed throughout the U.S.S.R. seeking to reunite with their families, while newcomers tend to go to Russia for education or economic opportunity. A common lingua franca and shared sociocultural characteristics continue to make Russia a preferred choice for migrants from ex-Soviet republics — especially Ukrainians, 3 million of whom now call Russia home. Baltic emigrants have also preferred to settle in Russia, although many have permanently settled in the United Kingdom or Germany.\nEducated young people are disproportionately likely to emigrate. This phenomenon has led to accelerating brain drain, thereby weakening labor-market competitiveness and creating long-term structural demographic imbalances.\nIn the 1980s, the Soviet Union implemented nationwide pronatalist policies that effectively boosted birthrates in Russia. But this was a temporary boon. The disintegration of the U.S.S.R. was followed by a rapid downturn in births across all former republics. Many state-run day-care centers were shut down or privatized, meaning that childcare costs increased significantly. Economic instability discouraged large families as the cost of living increased dramatically, impoverishing many families with children.\nTwenty-five years later, Russia has the one of the highest fertility rates in Europe — though still well under 2.1, which demographers stress is the level needed for natural population balance. Central Asia experienced an overall drop in fertility, but all five of its post-Soviet republics show a fertility rate that is well above replacement level. Fertility rate is one of the determinant factors in population growth or decline.\nThe life expectancy of a Turkmen born in 2015 is about 65 years — well over a decade less than an Estonian. There are large disparities in life expectancy across the post-Soviet space. Estonia, Latvia, and Lithuania — all members of the European Union and Schengen zone — lead the pack in life expectancy at birth and GDP per capita but are experiencing severe population downturns. Russia and the Eastern European states fall in the middle of the pack. Central Asia is encountering relatively low life expectancy and high population growth rates on average.\nDemographic decline worries governments because it may go hand in hand with geopolitical weight, economic might, and military prowess.\nIn 1989, there were 289 million Soviet citizens — making the U.S.S.R. the third most populous country in the world, ahead of the United States and behind only India and China. Twenty-five years after its disintegration, the combined population of the 15 former republics stands at just under 294 million. But by 2050, the combined population of former Soviet countries is projected to decrease to just 284 million, a lower estimate than Nigeria’s.\nUkraine, once home to more than 50 million people, will likely continue to suffer acute population loss and will be surpassed by Uzbekistan in the coming decades. Immigration will help to slow Russia’s losses but not reverse the overall trend of decline throughout post-Soviet Europe. Only Central Asia and Azerbaijan will weather the demographic storm affecting the rest of the former Soviet Union.\nEditor’s note: Copyright (c) 2016. RFE/RL, Inc. Reprinted with the permission of Radio Free Europe/Radio Liberty, 1201 Connecticut Ave., N.W. Washington DC 20036."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:32f0bf8c-ea2b-4c68-92c3-4fceeab7b896>","<urn:uuid:a45d50ba-def0-4261-a7d1-c18647a5805b>"],"error":null}
{"question":"How do the three different types of audience targeting data collection methods compare in terms of their sources? I need this information for a marketing strategy report.","answer":"First-party data is collected directly from an audience, including behaviors, interests, and CRM stats. Second-party data is someone else's first-party data that digital marketers buy from companies that own it. Third-party data comes from external collectors who gather information from various websites and platforms, buy it from first-party owners, and then sell it to third parties.","context":["Performance marketing is the new bae; it has become one of the most valuable marketing strategies used by businesses worldwide. This is because this marketing system has proven profitable with other advertising mediums. Businesses use performance marketing to monitor and optimize business results.\nAlso, performance marketing enables tracing of customers tracking third-party follower based and budgets. It is a method used to create customer awareness and generate more revenue. Performance marketing combined with audience targeting gives a remarkable result and a focused marketing system. Audience targeting can be used to reach specific audiences for different ads.\nWhat is Audience Targeting?\nAudience targeting is a strategy employed by digital marketers to get their ads to people who are particularly interested in the goods or services they have to offer. It is a method of identifying people based on their interests and other characteristics specific to the ads to be shown. Psychographic data is important in audience targeting; data such as customers' values, lifestyles, interests, beliefs, and options effectively target an audience. Location, gender, behavior, income rate, and educational level are examples of demographic data included in audience targeting to solve customer issues.\nAudience targeting in performance marketing helps digital marketers segment audiences according to their wants. This goes a long way in creating more conversions and revenues for companies and brands. Although it's not magic, audience targeting has proven to be effective and resourceful in performance marketing by showing brands and companies the right people to target at the right time.\nTypes of Audience Targeting -\n- Demographic audience targeting: The demographic audience type of targeting depends on demographic data. This segmentation deals with family size, gender, age, religion, ethnicity, etc. These data are segmented into different market categories, and it is important to know how to efficiently use the demographic audience targeting. Combining different variables makes demographic audience targeting more effective. It provides specific information about your potential customers in a group. It allows marketing analysts to decide their needs and which group will create the most conversion on a specific product or service. Demographic audience targeting aims to determine subgroups, their characteristics, and their interest in a population of people. An example is showing your business site or product to men under the age of 40 interested in workout equipment and earning up to $200,000. Demographic audience targeting is the best way to get your product to a specific audience.\n- Psychographic audience targeting: This type of audience targeting is also known as interest targeting. This focuses more on the interest of the audience, their opinions, lifestyle, values, personality traits, and the activities they engage in. When these data are collected, an ad specific to these groups of people can be created. An example is showing organic and natural wine to vegan communities.\n- Behavioral audience targeting: This type of audience targeting is particular about the audience's behavior. An example is showing ads or creating one, particularly for an audience that has visited or purchased certain brands of clothes or hair products. It tracks the audience's activities, such as the website they visit and follow, ads they have clicked on, items they have searched for on the search engine, and items they have purchased previously. Simply put, this type of audience targeting uses people's activities to determine the advertisement that will attract them. It creates a personalized marketing system that is good for businesses and companies.\nImportance of Audience Targeting in Performance Marketing -\n- Audience targeting is cost-effective and more efficient: The right audience will always generate conversions and more profit for a business or a brand. This is why audience targeting is vital in performance marketing. When business ads are pointed toward the right set of people— customers looking for or needing a particular product, more sales will be made. This process is cost-effective and ensures that ads are only shown to audiences that are interested and likely to convert. This helps in maximizing the money spent and monitors an effective result.\n- Customer loyalty and trust: Audience targeting gives audiences a personalized experience, thereby strengthening audience loyalty and trust. Through effective audience targeting and providing the audience with the right product at the right time, customers feel comfortable visiting businesses or websites again. Audience targeting also helps in reaching existing customers and winning them over again.\n- Audience targeting generates high-quality leads: Audience targeting helps generate quality traffic and bring in customers that will convert. With quality leads come more profits and revenue for businesses and companies.\nHow to get data for audience targeting in performance marketing -\n- First-Party Data: The first-party data is mostly used by digital marketers. It is information collected directly from an audience. This includes; their behaviors, interest social data, subscription data, CRM stats, customer feedback, completing surveys, etc.\n- Second Party Data: Second-party data belongs to another person. It is someone else's first-party data. The digital marketer buys these data from companies that own them. A digital marketer has to seek out companies with first-party data on their websites before having access to it.\n- Third-Party Data: Third-party data is usually gotten from the outside. These sources are not the initial collectors of the data. The collectors sell data they collect from various other websites and platforms where all the information was generated. These collectors pay the first party or data owners for the information they collect from them and sell it to a third party.\nThe products you have available and ready to be purchased need personalized product landing pages. Creating a good one helps your product stand out in the online market and helps your website or product rank in the search engine. Your business gains more trust and consistent users when your landing pages are simple and easy to navigate through. The more personalized your product landing pages are, be it single or multiple, the more conversions and profit will be made. Excellent mapped ads and post-click pages make landing page creation easier and conversion better."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:c0806fdf-47c6-4260-a69b-1c3eb12e6c37>"],"error":null}
{"question":"What's the basic first aid for animal bites, and what immune system factors increase allergy risks?","answer":"For animal bites, immediately hold a towel or cotton to stop bleeding, clean the wound with soap and water, and cover with a clean bandage or gauze pad. Regarding allergy risk factors, having a family history of allergies, having asthma, or having a weakened immune system increases your chances of developing insect allergies. If you have these risk factors and get bitten, you may need antibiotics to prevent infection, especially if you have conditions that weaken your immune system.","context":["Best Techniques to Treat Animal Bites and Insect Stings\nHow do I treat animal bites and scratches?\nIf you or your child gets a bite, follow these steps to treat the wound:\n- Hold a towel or cotton on the area to stop the bleeding.\n- Clean the wound with soap and water.\n- Cover it with a clean bandage or gauze pad.\nHow do I treat bee, wasp, and other insect stings?\nHere’s what to do:\n- If the insect has left behind a stinger, remove it from the skin so less of the venom gets into your body. Don’t squeeze the stinger. You might release more of the venom into your skin.\n- Once the stinger is out or if there is no stinger, wash the area around the sting with soap and water.\n- Hold an ice pack or cool washcloth to the sting to stop it from swelling.\n- Spread calamine lotion or baking soda mixed with water to relieve pain.\n- To prevent itching, use a spray or cream containing hydrocortisone or antihistamine.\nHow do I treat a mosquito bite?\nHere’s what to do:\n- Apply firm pressure to the bite for 10 seconds to help stop the itch.\n- Use a baking soda paste or hydrocortisone cream 4 times a day to relieve itching. Don’t have either on hand?\n- Holding ice or a wet washcloth on the bite will also help.\n- Take an antihistamine if the bite is very itchy.\nHow do I treat a spider bite?\nFor most of the harmless types of spiders, you’ll find at home, treatment is pretty simple:\n- Wash the area with soap and water.\n- Hold an ice pack or cool washcloth to the bite to relieve pain and bring down swelling.\nWhen should I see a doctor for an animal bite?\nFor any animal bite, you may need an antibiotic to prevent infection. So, it’s always a good idea to call your doctor, especially if you have medical conditions that weaken your immune system:\n- The bite was caused by an unknown animal, or by any wild animal like a raccoon, skunk, or bat. You may need tetanus or rabies vaccine.\n- The bite is large, or it doesn’t stop bleeding after you’ve held pressure on it for 15 minutes. It may need to be closed with stitches.\n- You think the bite may have damaged a bone, tendons, or nerves because you can’t bend or straighten the body part or you’ve lost feeling in it.\n- The wound is red, swollen, or oozing fluid.\nWhat are the signs that the child is allergic to the insect?\nIt’s normal for the skin around the insect sting to swell up and get red. But go to the emergency room if you see any of these signs of an allergic reaction:\n- Hives — red, itchy bumps on the skin\n- Stomach cramps, vomiting, or diarrhea\n- Swelling of the tongue\n- Trouble breathing, wheezing\nAnyone who has allergies to bees, wasps, or other stinging insects should keep an epinephrine auto-injector at home, work, and school in case of a sting.\nHow do I know if a spider is poisonous?\nSpiders might be creepy and crawly, but most of them aren’t poisonous. The poisonous spiders to watch out for are the brown recluse and black widow. Here’s how to spot them:\n- Brown recluse spiders are about 1/2-inch long. They’re brown and have a mark in the shape of a violin on their back.\n- Black widow spiders are black with a red hourglass-shaped mark on their stomach.\nWhat should I do for a poisonous spider bite?\nIf you think you were bitten by a poisonous spider like a brown recluse or black widow, go to the doctor. Look for these signs:\n- A red or purple color around the bite\n- Pain in the bite area\n- Swelling around the bite\n- Muscle pain and cramps\n- Stomach pain\n- Nausea and vomiting\n- Trouble breathing\nLeave a ReplyWant to join the discussion?\nFeel free to contribute!","by Rosalyn Carson-DeWitt, MD\nInsect allergies are an abnormal reaction to insects. It may be a reaction to:\nReactions can range from mild to severe.\nIt is not known what causes allergies to start. An abnormal immune system reaction is what causes the symptoms. Venom from a sting or fluid from a bite may start the reaction.\nCommon stinging insects linked with allergies include:\nCommon biting insects linked with allergies include:\nInsects that leave debris in the house that cause reactions include:\nThese insects can cause reactions all year long. They can also set off asthma.\nFactors that may increase your chance of insect allergies include:\nSymptoms will depend on the type of allergy.\nA bite or sting can cause:\nStings or bites can cause severe reactions. It is rare but can be deadly. The reaction called anaphylaxis can cause:\nInsects that live in the house can cause problems in the respiratory system. In this case, symptoms may include:\nYou will be asked about your symptoms and past health. A physical exam will be done. The doctor may suspect an allergy on how your body reacted to bite or sting. A doctor that specializes in allergies can help.\nTests for an allergy may include:\nSome reactions cause trouble breathing. If this is the case, call for emergency medical services right away.\nGeneral treatment may include:\nAllergy shots may help to decrease or stop an allergic reaction. It is done over a series of shots. Each shot has a very tiny amount of insect venom. It allows your body to get use to the venom. May be used for severe allergies to honeybees, yellow jackets, hornets, wasps, or fire ants.\nIf you have had severe reactions:\nThere are not steps to keep you from developing allergies. However, you may be able to prevent flare ups. To help reduce risk of insect bite or sting:\nIf you have had an allergic reaction to insects around the home:\nAmerican Academy of Allergy, Asthma & Immunology\nFamily Doctor—American Academy of Family Physicians\nAbout Kids Health—The Hospital for Sick Children\nAllergic rhinitis. EBSCO DynaMed Plus website. Available at: https://www.dyname... . Updated July 9, 2018. Accessed October 1, 2018.\nHymenoptera sting allergy. EBSCO DynaMed Plus website. Available at: http://www.dynamed... . Updated April 6, 2017. Accessed October 1, 2018.\nInsect sting allergy. American College of Allergy, Asthma & Immunology website. Available at:\n...(Click grey area to select URL)\nAccessed October 1, 2018.\nRank MA, Li JT. Allergen immunotherapy. Mayo Clin Proc. 2007;82(9):1119-1123.\nVenom immunotherapy. EBSCO DynaMed Plus website. Available at: https://www.dyname... . Updated June 21, 2018. Accessed October 1, 2018.\nLast reviewed September 2018 by EBSCO Medical Review Board Monica Zangwill, MD, MPH\nLast Updated: 10/1/2018\nEBSCO Information Services is fully accredited by URAC. URAC is an independent, nonprofit health care accrediting organization dedicated to promoting health care quality through accreditation, certification and commendation.\nThis content is reviewed regularly and is updated when new and relevant evidence is made available. This information is neither intended nor implied to be a substitute for professional medical advice. Always seek the advice of your physician or other qualified health provider prior to starting any new treatment or with questions regarding a medical condition.\nTo send comments or feedback to our Editorial Team regarding the content please email us at email@example.com. Our Health Library Support team will respond to your email request within 2 business days."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:1ef68c6a-3490-41b4-87af-6d7bf51a520f>","<urn:uuid:8c8aff96-506a-43a7-8a31-6cff15435707>"],"error":null}
{"question":"I work in cybersecurity - could someone explain the historical evolution from Physical Access Control to newer Azure Policy governance? Make it organized!","answer":"The evolution from Physical Access Control to Azure Policy shows a progression in access management approaches:\\n\\n1. Physical Access Control Era:\\n- Focused on physical restrictions to facilities\\n- Used for controlling access to secure facilities like SCIFs\\n- Primarily relied on physical, electronic, or human controls\\n\\n2. Logical Access Control Development:\\n- Emerged as a counter to Physical Access Control\\n- Introduced LDAP-based access management\\n- Implemented controls for data retrieval and manipulation\\n\\n3. Modern Azure Policy Governance:\\n- Provides comprehensive IT governance through policy-based control\\n- Enables creation and management of organizational policies\\n- Offers automated compliance evaluation of resources\\n- Implements systematic rules and effects over resources\\n- Integrates with existing security systems while maintaining corporate standards","context":["Overview#Access Control (or Privilege Management) is a process where an Authoritative Entity (Trustor) who grants a permission to a Trustee\nAccess Control is typically implemented within an Access Control Service\nAccess Control decides \"Who\" can do \"What\" on which Resourcees\nThe action of Access Control may be referred to as Resource Provisioning\nAccess Control may (and probably should) use a Policy Based Management System\nAccess Control Importance#Access Control is the primary reason we perform all of the following activities:\nAccess Control Process#Access Control is defined within a Access Control Policy and enforced by a Policy Enforcement Point based on the decision from the the Policy Decision Point which has acquired information from a Policy Retrieval Point and Policy Information Points. Logical Access Control term originated as a counter to Physical Access Control Access Control Models for implementation of Access Control. LDAP server, an Access Control provides a mechanism for restricting who can get access to various kinds of data within the DIT.\nThe Access Control provider may be used to control a number of things, including:\n- Whether or not a DUA can retrieve an LDAP Entry from the DIT.\n- Which attributes within the LDAP Entry the DUA is allowed to retrieve.\n- Which values of an attribute the DUA is allowed to retrieve.\n- The ways in which the DUA is able to manipulate DIB for the directory.\nA number of things can be taken into account when making Access Control decisions, including:\n- The DN as whom the user is authenticated.\n- The Authentication Method by which the client authenticated to the DSA.\n- Any groups in which that user is a member.\n- The contents of the authenticated LDAP Entry\n- The contents of the Target Resource LDAP Entry.\n- The address of the DUA system.\n- Whether or not the communication between the client and server is secure.\n- The time of day and/or day of week of the attempt.\nSee the documentation for details on the Access Control syntax used by the LDAP Server Implementation vendor.unauthorized access.\n2. (I) A process by which use of system resources is regulated according to a security policy and is permitted only by authorized entities (users, programs, processes, or other systems) according to that policy. (See: access, access control service, computer security, Discretionary Access Control, Mandatory Access Control, Role Based Access Control.)\n3. (I) /formal model/ Limitations on interactions between subjects and objects in an information system.\n4. (O) \"The prevention of unauthorized use of a resource, including the prevention of use of a resource in an unauthorized manner.\" I7498-2\n5. (O) /U.S. Government/ A system using physical, electronic, or human controls to identify or admit personnel with properly authorized access to a SCIF.OpenDS is one we are aware, also provides a Privilege Management Infrastructure that can be used to control what a user will be allowed to do. One of the privileges available is the \"bypass-acl\" privilege, which can be used to allow that DUA to bypass any restrictions that the Access Control subsystem would otherwise enforce. WEB Access Management are Access Control products that are specific to WEB Access Control.\nMore Information#There might be more information for this subject on one of the following:\n- API Management\n- API Service Delivery\n- Access Control Engine\n- Access Control Entry\n- Access Control List\n- Access Control Models\n- Access Control Policy\n- Access Log\n- Access Proxy\n- Adaptive Policy-based Access Management\n- Authorization Header\n- Best Practices for LDAP Security\n- Cloud Access Security Broker\n- Context Based Access Control\n- Cross-site scripting\n- Data Protection\n- Device Inventory Service\n- Digital Context\n- Discretionary Access Control\n- Enterprise Directory\n- GCP ACL\n- GCP IAM Policy\n- GCP Identity\n- GCP Storage Products\n- Geneva Framework\n- Glossary Of LDAP And Directory Terminology\n- Google Cloud IAM\n- Google Cloud Storage\n- Graded Authentication\n- HTTP Authentication Framework\n- IDSA Integration Framework\n- IMA Policies\n- ISO 10181-3\n- Identity Aware Proxy\n- Identity Credential and Access Management\n- Identity Lifecycle Management\n- Identity Management\n- Identity and Access Management\n- JSPWiki Permission\n- Java Authentication and Authorization Service\n- LDAP Authentication\n- Life Management Platform\n- Logical Access Control\n- NAM Access Manager\n- NDS Authentication\n- NIST.SP.800 Computer Security\n- Non Permissioned System\n- OAuth Scope Example\n- Object ACL\n- Open Policy Agent\n- Oracle Access Manager\n- Password Administrator\n- Password Management\n- Password Policy Administrator\n- Payment Card Industry Data Security Standard\n- Permissioned Systems\n- Permissionless System\n- Physical Access Control\n- Policy Access Decision Management Engine\n- Privilege Conflict\n- Privilege Management\n- Privileged Access Management\n- Privileged Account\n- Real Risk\n- Resource Inventory Service\n- Resource Provisioning\n- Resource Server\n- SOC 2\n- Sensitive But Unclassified\n- Session Management\n- Subscriber Identification Module\n- Technical Positions Statements\n- User-Managed Access\n- User-centric Identity\n- Vendor Relationship Management\n- Web Blog_blogentry_010117_1\n- Web Blog_blogentry_010317_1\n- Web Blog_blogentry_030117_1\n- Web Blog_blogentry_031017_1\n- Web Blog_blogentry_070817_1\n- Web Blog_blogentry_230717_1\n- Web Blog_blogentry_280717_1\n- Web Blog_blogentry_300717_1\n- Zero Trust\n[#1] Loosely adapted from http://en.wikipedia.org/wiki/Access_control - 2012-09-30","What is Azure Policy?\nIT Governance ensures that your organization is able to achieve its goals through an effective and efficient use of IT. It does this by creating clarity between your business goals and IT projects.\nDoes your company experience a significant number of IT issues that never seem to get resolved? Good IT governance involves planning your initiatives and setting priorities on a strategic level to help manage and prevent issues. This is where Azure Policy comes in.\nAzure Policy is a service in Azure that you use to create, assign and, manage policies. These policies enforce different rules and effects over your resources, so those resources stay compliant with your corporate standards and service level agreements. Azure Policy does this by running evaluations of your resources and scanning for those not compliant with the policies you have created. For example, you can have a policy to allow only a certain SKU size of virtual machines in your environment. Once this policy has been implemented, it will then be evaluated when creating and updating resources, as well as over your already existing resources. Later on in this documentation, we will go over more details on how to create and implement policies with Azure policy.\nAzure Policy's compliance evaluation is now provided for all assignments regardless of pricing tier. If your assignments do not show the compliance data, please ensure that the subscription is registered with the Microsoft.PolicyInsights resource provider.\nHow is it different from RBAC?\nThere are a few key differences between policy and role-based access control (RBAC). RBAC focuses on user actions at different scopes. For example, you might be added to the contributor role for a resource group at the desired scope. The role allows you to make changes to that resource group. Policy focuses on resource properties during deployment and for already existing resources. For example, through policies, you can control the types of resources that can be provisioned. Or, you can restrict the locations in which the resources can be provisioned. Unlike RBAC, policy is a default allow and explicit deny system.\nRBAC Permissions in Azure Policy\nAzure Policy has permissions represented as operations in two different Resource Providers:\nSeveral of the Built-in roles have various levels of permission to Azure Policy resources, such as Security Admin that can manage policy assignments and definitions but cannot view compliance information and Reader that can read details regarding policy assignments and definitions, but cannot make changes or view compliance information. While Owner has full rights, Contributor does not have any Azure Policy permissions. To grant permission to view Policy compliance details, create a custom role.\nThe journey of creating and implementing a policy in Azure Policy begins with creating a policy definition. Every policy definition has conditions under which it is enforced. And, it has an accompanying effect that takes place if the conditions are met.\nIn Azure Policy, we offer some built-in policies that are available to you by default. For example:\n- Require SQL Server 12.0: This policy definition has conditions/rules to ensure that all SQL servers use version 12.0. Its effect is to deny all servers that do not meet these criteria.\n- Allowed Storage Account SKUs: This policy definition has a set of conditions/rules that determine if a storage account that is being deployed is within a set of SKU sizes. Its effect is to deny all storage accounts that do not adhere to the set of defined SKU sizes.\n- Allowed Resource Type: This policy definition has a set of conditions/rules to specify the resource types that your organization can deploy. Its effect is to deny all resources that are not part of this defined list.\n- Allowed Locations: This policy enables you to restrict the locations that your organization can specify when deploying resources. Its effect is used to enforce your geo-compliance requirements.\n- Allowed Virtual Machine SKUs: This policy enables you to specify a set of virtual machine SKUs that your organization can deploy.\n- Apply tag and its default value: This policy applies a required tag and its default value, if it is not specified by the user.\n- Enforce tag and its value: This policy enforces a required tag and its value to a resource.\n- Not allowed resource types: This policy enables you to specify the resource types that your organization cannot deploy.\nIn order to implement these policy definitions (both built-in and custom definitions), you will need to assign them. You can assign any of these policies through the Azure portal, PowerShell, or Azure CLI.\nKeep in mind that a policy re-evaluation happens about once an hour, which means that if you make changes to your policy definition after implementing the policy (creating a policy assignment) it will be re-evaluated over your resources within the hour.\nTo learn more about the structures of policy definitions, review Policy Definition Structure.\nA policy assignment is a policy definition that has been assigned to take place within a specific scope. This scope could range from a management group to a resource group. The term scope refers to all the resource groups, subscriptions, or management groups that the policy definition is assigned to. Policy assignments are inherited by all child resources. This means that if a policy is applied to a resource group, it is applied to all the resources in that resource group. However, you can exclude a subscope from the policy assignment.\nFor example, at the subscription scope, you can assign a policy that prevents the creation of networking resources. However, you exclude one resource group within the subscription that is intended for networking infrastructure. You grant access to this networking resource group to users that you trust with creating networking resources.\nIn another example, you might want to assign a resource type whitelist policy at the management group level. And then assign a more permissive policy (allowing more resource types) on a child management group or even directly on subscriptions. However, this example wouldn't work because policy is an explicit deny system. Instead, you need to exclude the child management group or subscription from the management group-level policy assignment. Then, assign the more permissive policy on the child management group or subscription level. To summarize, if any policy results in a resource getting denied, then the only way to allow the resource is to modify the denying policy.\nFor more information on setting policy definitions and assignments, see Create a policy assignment to identify non-compliant resources in your Azure environment.\nPolicy parameters help simplify your policy management by reducing the number of policy definitions you must create. You can define parameters when creating a policy definition to make it more generic. Then you can reuse that policy definition for different scenarios. You do so by passing in different values when assigning the policy definition. For example, specifying one set of locations for a subscription.\nParameters are defined/created when creating a policy definition. When a parameter is defined, it is given a name and optionally given a value. For example, you could define a parameter for a policy titled location. Then you can give it different values such as EastUS or WestUS when assigning a policy.\nFor more information about policy parameters, see Resource Policy Overview - Parameters.\nAn initiative definition is a collection of policy definitions that are tailored towards achieving a singular overarching goal. Initiative definitions simplify managing and assigning policy definitions. They simplify by grouping a set of policies as one single item. For example, you could create an initiative titled Enable Monitoring in Azure Security Center, with a goal to monitor all the available security recommendations in your Azure Security Center.\nUnder this initiative, you would have policy definitions such as:\n- Monitor unencrypted SQL Database in Security Center – For monitoring unencrypted SQL databases and servers.\n- Monitor OS vulnerabilities in Security Center – For monitoring servers that do not satisfy the configured baseline.\n- Monitor missing Endpoint Protection in Security Center – For monitoring servers without an installed endpoint protection agent.\nLike a policy assignment, an initiative assignment is an initiative definition assigned to a specific scope. Initiative assignments reduce the need to make several initiative definitions for each scope. This scope could also range from a management group to a resource group.\nFrom the preceding example, the Enable Monitoring in Azure Security Center initiative can be assigned to different scopes. For example, one assignment can be assigned to subscriptionA. Another can be assigned to subscriptionB.\nLike policy parameters, initiative parameters help simplify initiative management by reducing redundancy. Initiative parameters are essentially the list of parameters being used by the policy definitions within the initiative.\nFor example, take a scenario where you have an initiative definition - initiativeC, with policy definitions policyA and policyB each expecting a different type of parameter:\n|Policy||Name of parameter||Type of parameter||Note|\n|policyA||allowedLocations||array||This parameter expects a list of strings for a value since the parameter type has been defined as an array|\n|policyB||allowedSingleLocation||string||This parameter expects one word for a value since the parameter type has been defined as a string|\nIn this scenario, when defining the initiative parameters for initiativeC, you have three options:\n- Use the parameters of the policy definitions within this initiative: In this example, allowedLocations and allowedSingleLocation become initiative parameters for initiativeC.\n- Provide values to the parameters of the policy definitions within this initiative definition. In this example, you can provide a list of locations to policyA’s parameter – allowedLocations and policyB’s parameter – allowedSingleLocation. You can also provide values when assigning this initiative.\n- Provide a list of value options that can be used when assigning this initiative. When you assign this initiative, the inherited parameters from the policy definitions within the initiative, can only have values from this provided list.\nFor example, you might create a list of value options in an initiative definition that contain EastUS, WestUS, CentralUS, and WestEurope. If so, you are unable to input a different value such as Southeast Asia during the initiative assignment, because it is not part of the list.\nMaximum count of Policy objects\nThere is a maximum count for each object type for Azure Policy. An entry of Scope means either the subscription or the management group.\n|Policy Assignment||Exclusions (notScopes)||100|\n|Policy Rule||Nested Conditionals||512|\nRecommendations for managing policies\nWhile creating and managing policy definitions and assignments, here are a few pointers we advise you to follow and tips to keep in mind:\n- If you are creating policy definitions in your environment, we recommend starting with an audit effect, as opposed to a deny effect, to keep track of the impact of your policy definition on the resources in your environment. If you have scripts already in place to autoscale up your applications, setting a deny effect may hinder those automations tasks you already have in place.\n- It is important to keep organizational hierarchies in mind when creating definitions and assignments. We recommend creating definitions at a higher level, for example at the management group or subscription level, and assigning at the next child level. For example, if you create a policy definition at the management group level, a policy assignment of that definition can be scoped down to a subscription level within that management group.\n- We recommend always using initiative definitions instead of policy definitions, even if you only have one policy in mind. For example, if you have a policy definition – policyDefA and you create it under the initiative definition - initiativeDefC, if you decide to create another policy definition later for policyDefB with goals similar to that of policyDefA, you can add it under initiativeDefC and track them better that way.\n- Keep in mind that once you have created an initiative assignment from an initiative definition, any new policy definitions added to the initiative definition automatically roll under the initiative assignment(s) under that initiative definition. However, if there’s a new parameter introduced to the new policy definition, you need to update the initiative definition and assignments by editing the initiative definition or assignment.\n- Once an initiative assignment is triggered, all policies within the initiative will be triggered as well. However, if you needed to execute a policy individually, it is better to not include it in an initiative.\nThe following overview of Azure Policy is from Build 2018. For slides or video download, please visit Govern your Azure environment through Azure Policy on Channel 9.\nNow that you have an overview of Azure Policy and some of the key concepts, here are the suggested next steps:\n- Assign a policy definition\n- Assign a policy definition using the Azure CLI\n- Assign a policy definition using PowerShell\n- Review what a management group is with Organize your resources with Azure management groups\n- View Govern your Azure environment through Azure Policy on Channel 9"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:c4ebbe54-68c3-44f4-8b0b-12e950a200a7>","<urn:uuid:4d8f56e7-f89c-4e5a-a110-a815885eb6a7>"],"error":null}
{"question":"Hey, just found out I have a small kidney stone! Will it pass naturally or do I need treatment? 😰","answer":"Small kidney stones may pass at home with extra fluids. However, if the stone becomes lodged and cannot pass, you may need treatment. Options include medication or shock wave lithotripsy to break up the stone. You should not wait longer than six weeks to seek treatment if the stone doesn't pass naturally.","context":["Kidney Stones Sound Wave Treatments\nWhat is shock wave lithotripsy? Shock Wave Lithotripsy (SWL) is the most common treatment for kidney stones in the U.S. Shock waves from outside the body.\nShock Wave Lithotripsy (SWL) is a treatment for kidney stones that uses sound waves to break stones into smaller pieces. It is by far the least invasive surgical approach and can be the ideal approach.\nTreatment For Lodged Kidney Stone 1 Aug 2016. Welcome to our chat on Kidney Stones Treatment Options with Dr. Sri. However , when a stone becomes lodged and cannot pass, there are. 30 Sep 2019. Video thumbnail for Kidney Stone Treatments. 0:00. Off Air. Larger stones can get trapped in\nOne aspect of the study focused on the effects of diet, water conservation, space travel and microgravity on kidney health.\nDocs clear heart block with shockwave therapy – Indore: In a first for the state, a team of doctors of Apollo Hospital have performed Lithotripsy — a shock wave therapy used for breaking down kidney stones — to clear the calcified blockage from the.\nDo you have kidney stones? Learn about extracorporeal shock wave lithotripsy, a nonsurgical treatment for stones in the kidney and ureter.\nThe treatment you'll need will depend on the size and type of kidney stone you.\nultrasound (high-frequency sound waves) to pinpoint where a kidney stone is.\nShock Wave Lithotripsy SWL is the most common kidney stone treatment. It works best for small or medium stones. It's noninvasive, which means no cuts are made in your skin.\nHer mom said with as common as they’ve become, she wishes more clinics like this one could be available to help children.\nSmall kidney stones may pass at home with extra fluids. For others, you may need medication or shock wave therapy to break up the stone, or a ureteroscopy. But you should not wait longer than six.\nA urologist can remove the kidney stone or break it into small pieces with the following treatments: Shock wave lithotripsy. The doctor can use shock wave lithotripsy to blast the kidney stone into small pieces. The smaller pieces of the kidney stone then pass through your urinary tract. A doctor can give you anesthesia during this outpatient procedure.\nTreating large kidney stones Shock wave lithotripsy (SWL) SWL involves using ultrasound (high-frequency sound waves).\nUreteroscopy. Ureteroscopy involves passing a long, thin telescope called a ureteroscope through.\nPercutaneous nephrolithotomy (PCNL) PCNL involves using a thin telescopic.\nFor kidney stones that do not pass on their own, a procedure called lithotripsy is often used. In this procedure, shock waves are used to break up a large stone into smaller pieces that can then pass through the urinary system. Surgical techniques have also been developed to remove kidney stones when other treatment methods are not effective.\nExtracorporeal Shock Wave Lithotripsy (ESWL) for Kidney Stones.\nHigh-energy sound waves pass through your body without injuring it and break the stone into.\nIf you have a larger stone, you may need more ESWL or other treatments.\nNASA astronaut Christina Koch made the most of her first trip to the International Space Station by breaking the record for.\nKidney stones are one of the most common disorders of the urinary tract.\ndoctor may recommend treatment using extracorporeal shock wave lithotripsy (ESWL),\nUsing high-energy sound waves known as “shock waves”, lithotripsy sends.\nLarger obstructive kidney stones are most often treated using extracorporeal shock wave lithotripsy (ESWL) or high-energy sound waves.\nTreatment. Treatment for kidney stones varies, depending on the type of stone and the cause. Small stones with minimal symptoms. Most small kidney stones won't require invasive treatment. You may be able to pass a small stone by: Drinking water. Drinking as much as 2 to 3 quarts (1.9 to 2.8 liters) a day may help flush out your urinary system.\n3 Jul 2018.\nThe sound waves break down the stones into small pieces.\nkidney stone treatment as having insignificant fragments of kidney stones of less.\nKidney stone treatments for those that do not pass on their own include medication to assist in passing the stone, destruction by sound waves (extracorporeal shock wave lithotripsy), and minimally invasive surgical options including percutaneous nephrolithotomy and ureteroscopy.\nNew York, January 22, 2020: The report covers a detailed competitive outlook including the market share and company profiles of the key participants operating in the global market. Key players.\nLithotripsy is a medical procedure used to treat kidney stones. Learn why it's.\nLithotripsy uses sound waves to break up large kidney stones into smaller pieces .\nSmall kidney stones may pass at home with extra fluids. For others, you may need medication or shock wave therapy to break up.\nApr 11, 2018 · Treatment consists of noninvasive low-intensity sound waves that pass through erectile tissue, restoring natural erectile function by clearing plaque out of blood vessels and encouraging the growth.\nShock Wave Lithotripsy (SWL) is the most common treatment for kidney stones in the U.S. Shock waves from outside the body are targeted at a kidney stone causing the stone to fragment. The stones are broken into tiny pieces. lt is sometimes called ESWL: Extracorporeal Shock Wave Lithotripsy®. These are what the words mean:"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:0fa63f12-60da-419c-a9f4-d0cf6c037fa7>"],"error":null}
{"question":"How to prevent tick-borne diseases during outdoor activities? ¿Cuáles son los pasos más importantes para protegerse de las picaduras de garrapatas?","answer":"To prevent tick-borne diseases, wear insect repellent with DEET, long sleeves that fit wrists closely, and long pants tucked into socks. Wear close-toed footwear and do daily tick checks. When removing ticks, use tweezers to grasp the head and mouth parts close to the skin, pull slowly without squishing or twisting, then wash the site with soap and water. Additional preventive measures include avoiding areas with bushes and tall grass, wearing light-colored clothes to keep ticks away, using tick repellents with permethrin, and tucking shirts into pants and pants into boots. For areas known to have ticks, consult local public health offices about infestations.","context":["8 Summer Health Hazards Canadians Face Each Year\nSummertime is all about trips to the cottage, lazy days at the beach, hikes in the woods and meals cooked on the grill. Here's how to handle the most common summer health hazards so you can keep the good times going.\nMosquitoes, bees, wasps, ants and spiders. Is your skin crawling yet? The itching, swelling and pain of insect bites are due to the venom and other substances left behind. Sometimes there is a delayed reaction with additional symptoms (hives, painful joints, fever and swollen glands). Although most people react mildly, bites can be treated by removing the stinger, if there is one, and washing the area with soap and water.\nA small number of people experience a severe reaction, with symptoms such as swelling of the throat and lips, nausea, respiratory problems, faintness, dizziness, rapid heartbeat, confusion and shock. If you’re experiencing these symptoms, get emergency help right away. People with known allergies to insect bites should carry self-injectable epinephrine (EpiPen).\nHealth Canada advises minimizing exposure to insects, covering up, and apply insect repellent (after sunscreen).\nSpread by deer ticks and western black-legged ticks, Lyme disease is a serious illness with two stages. The first stage is a circular rash around the bite. This rash appears three days to a month later, with symptoms like fever, chills, fatigue, headache, and joint and muscle pain. Without antibiotic treatment, victims develop rashes, weakness, stiff and swollen joints, an abnormal heartbeat, extreme fatigue and nervous system problems. The second stage involves neurological symptoms and arthritis.\nTicks live in areas that are wooded or have tall grass. According to Health Canada, those at a greater risk of Lyme disease are those who are golfing, hiking, fishing, camping and hunting.\nConsult your local public health office about infestations. When visiting these places, wear insect repellent with DEET, long sleeves that fit wrists closely, long pants tucked into your socks, and close-toed footwear. Health Canada says Lyme disease can be treated effectively in 2 to 4 weeks with antibiotics.\nDo a daily tick check. To remove ticks, use tweezers to grasp the head and mouth parts as close to the skin as you can, and slowly pull without squishing or twisting. Wash the site with soap and water, and save the bug in a container or sandwich bag. For more information, visit Health Canada. If you experience any symptoms, contact a doctor.\nSunburn is the painful reddening of the skin after overexposure to sunlight. So to avoid getting burned, stay in the shade, especially during peak hours (11 a.m. to 4 p.m.). Be sure to cover up with clothes and a wide-brimmed hat and apply broad-spectrum sunscreen with minimum SPF 15 to exposed skin. Don’t forget to reapply sunscreen regularly, especially after sweating or swimming.\nIf sunburned, Health Canada advises taking a cool shower and drinking extra fluids for two to three ways. Apply aloe gel, but avoid lotions that keep heat in the skin.\nIf the burn is very painful or blistered, or if there are additional symptoms like facial swelling, nausea, fever or chills, rapid pulse, rapid breathing, confusion, dizziness or signs of skin infection, get immediate medical help.\nKamloops, B.C., is the Canadian city with the most days hitting 30 degrees Celsius or higher, so we asked local experts for advice on heatstroke, a condition in which body temperature rises to 40 degrees Celsius or higher.\nThe body is usually able to regulate temperature via sweating or blood-flow changes to the skin, explains Dr. Nick Balfour, regional medical director with BC Ambulance Service (BCAS). “However, in extreme heat, high humidity, or during vigorous physical exertion, the body may not be able to dissipate heat and the body temperature rises. Heatstroke is a very serious medical condition that can have damaging or potential fatal implications if not immediately treated.” Note: Symptoms of heatstroke include an extremely high body temperature; red, hot, dry skin; a rapid pulse, a throbbing headache, nausea, dizziness, confusion, and unconsciousness.\nAvoid overheating by staying in the shade and drinking plenty of water, advises Troy Clifford, a primary care paramedic with BCAS. “If you notice that an individual is experiencing the signs and symptoms associated with heatstroke, call 911 immediately and get out of the sun. Emergency medical dispatchers will provide instruction and support while paramedics are en route.”\nPoison Ivy, Poison Oak and Poison Sumac\nThe sap of these plants can cause allergic skin reactions: itching, blisters, burning, redness and swelling. They can also affect the eyes and mouth. If you touch one, wash the affected area with soap and water to prevent a reaction within an hour of contact. Flush out your eyes with water, too, and wash your clothes. Relieve itching with an antihistamine ointment.\nRashes usually aren’t serious, but if the reaction is severe, seek medical attention. If you think you’ve been in contact with Poison Ivy, Health Canada recommends washing the affected area with soap and cold water immediately.\nIf you’ve been splashing around at the lake or beach and now your ear is inflamed or irritated, you’ve likely got swimmer’s ear. Symptoms include itchiness, pain, greenish or yellowish discharge, and hearing loss. Your doctor may prescribe antibiotic ear drops, plus medications for itching, inflammation and pain.\nBacteria and pollution cause swimmer’s ear, but so do objects lodged in the ear, scratching the ear or irritating the skin by trying to clean wax from the canal. Dry your ears thoroughly, avoid dirty water, and don’t stick anything in your ear canals!\nThere are 11 million cases of foodborne illness in Canada annually, and many people who get sick don’t realize what’s happening. Pathogens such as salmonella, shigella, campylobacter, E. coli and listeria are uninvited guests at summer get-togethers.\nDepending on the microorganism, they can cause symptoms like fever, chills, abdominal pain, diarrhea, bloody stools, nausea, vomiting and dizziness, hours or days after exposure. Serious cases can lead to death.\nSunlight, including light bouncing off water, sand and concrete, can burn your corneas, a painful condition known as photokeratitis. Over time, exposure to UV can age your eyes’ lenses, leading to cataracts, macular degeneration and other vision problems.\nProtect your eyes with a hat and sunglasses that shield against UVA and UVB rays. You could also spend less time outdoors when the sun is strongest (11 a.m. to 4 p.m.).","Babesiosis is one of the numerous tick-borne health problems that can be quite enfeebling for certain individuals. Know all about the symptoms, prevention and treatment options of this disorder.\nWhat is Babesiosis?\nIt is a parasitic disease that resembles malaria and is caused by the protozoal piroplasm genus named Babesia. This infectious condition of the red blood cells is transmitted when a person gets bitten by a tick. It can occur both in humans as well as in dogs and cattle animals. The Babesia parasites are the second most frequent blood parasites affecting mammals after the protozoan parasites named Trypanosomes.\nThe condition is most commonly caused by the Babesia species called Babesia microti. The Babesia duncani species have also been reported to lead to this disorder. The tick species that transmits Lyme disease, I. scapularis, is generally responsible for the transmission of Babesia microti parasites.\nThe microscopic parasites Babesia microti and Babesia duncani are the main causes of the disease. These parasites infect the RBCs (red blood cells) after entering the bloodstream through a tick bite. The parasites may also get transmitted when contaminated blood is transfused into a healthy individual. A woman can pass the infection to her baby if she gets affected by the parasites at the time of pregnancy or delivery. But the congenital form of the disease is very rare.\nThe symptoms of this condition resemble those of Lyme disease. The onset of the condition generally occurs with high fever along with chills. The following signs can be noticed in the patients with the progression of the infection:\n- Muscle aches\n- Drenching sweats\n- General malaise\n- Respiratory Symptoms\nThis condition remains asymptomatic in many patients. However, it can turn life-threatening in elderly patients and individuals with weak immune system (such as HIV patients) and those with no spleen.\nIt is possible to reduce the chances of developing this tick-borne infection by taking certain preventive measures. These measures of prevention are more important for people with an increased risk of getting infected by Babesia. The ways of prevention include:\n- Avoiding places where ticks are most likely to be present, such as areas with bushes and tall grass\n- Wearing long-sleeved shirt, full pants and socks while working outdoors (such as in fields or gardens)\n- Wearing light-colored clothes as they keep the ticks away\n- Using pest repellants and tick repellents with permethrin\n- Tucking shirt into the pants and the pants into the boots\n- Checking for ticks on the entire body after coming back from outdoor activities\nThe diagnosis can be quite tricky in case of patients without any evident symptoms. In symptomatic patients, a diagnostician collects blood samples from the patient and examines them under a microscope to detect any Babesia parasites inside the RBCs. Blood smear examination is another common diagnostic test used for this purpose. However, this process cannot be used for making an accurate diagnosis unless used within the first 2 weeks of the disease. The diagnostician may have to perform multiple smears before it can confirm the presence of the parasite in the blood.\nVarious commercial tests can be useful for making the diagnosis. However, they only work on some specific Babesia species.\nPolymerase Chain Reaction (PCR) Test\nThis exam is useful for finding out if Babesia DNA is present in the blood of patients.\nFluorescent In-Situ Hybridization (FISH) Test\nIn this assay, thin blood smears are examined to detect the presence of ribosomal Babesia RNA in them.\nRegular blood test is also performed to see if the blood contains antibodies to Babesia.\nSometimes, several different diagnostic procedures may be necessary for confirming the diagnosis. It is also possible that some of the tests will show a negative result, but it is not advisable to rule out the treatment due to these test results.\nBabesiosis Differential Diagnosis\nThe symptoms of this infectious disease often resemble those resulting from various other conditions. Due to this reason, such conditions should be eliminated by a diagnostician to confirm the diagnosis of this disorder:\n- Insect Bites\n- Acute Anemia\n- Colorado Tick Fever\n- Q Fever in Emergency Medicine\n- Lyme disease\n- Typhoid Fever\n- Rocky Mountain Spotted Fever\n- Tick-Borne Diseases\n- Relapsing fever in some emergency medicine\n- Tularemia in some emergency medicine\nMost cases of the infection do not require any special treatment as they resolve themselves. Symptomatic patients are generally treated with a two-drug regimen management plan. The regimen of Clindamycin and Quinine is not very effective for this treatment, leading to various complications in the patient. According to recent researches, the regimen of Atovaquone (Malarone, Mepron) and an erythromycin-type medicine such as Azithromycin, Telithromycin or Clarithromycin can be effectively used for treating the patients.\nSometimes, the infection can turn life threatening and needs to be treated with exchange transfusion. This procedure involves the removal of the Babesia infected RBCs and their replacement with fresh ones. The treatment may continue for several months if patients continue to suffer from long-term infection. In these cases, the condition may lead to relapses which need prompt treatment.\nThe prognosis is positive in most cases. However, severe cases may have comparatively poor prognoses and can result in a number of complications. Individuals who need to remain hospitalized for more than two weeks, or are kept in the ICU for more than two days, often show a poor outcome. The infection is associated with a mortality rate of around 5%.\nThe possible complications of this disease include the following:\n- Extremely low blood pressure\n- Various liver problems\n- Severe Hemolytic Anemia (a condition characterized by the breakdown of RBCs)\n- Kidney failure\n- Congestive heart failure\nCalculating its exact incidence is difficult due to its similarities with other disorders. The Babesia infection can occur in people from all over the world, but it is believed to be more common in temperate climates. Both children and adults can develop this parasitic disease.\nIt is a very common health problem among dogs from different regions of the world. Due to this reason, various vaccines have been developed against the Babesia species affecting dogs. Babesia canis canis infection (protozoa responsible for Babesiosis in dogs) can be prevented by a certain vaccine. However, this vaccine does not work against Babesia canis rossi. The disorder results in a number of serious symptoms in dogs and needs proper treatment.\nHere are some images of the ticks that transmit the infectious disorder in humans.\nPicture 1 – Babesiosis\nPicture 2 – Babesiosis Image\nBabesiosis is a potentially fatal protozoal infection which may or may not cause symptoms. Comparatively severe cases require early treatment so that the patients can attain complete recovery. Individuals can easily prevent it by taking certain measures to avoid getting bitten by ticks."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:1e9e6dff-0e8a-4432-a29c-35b537e31d37>","<urn:uuid:2adaf25d-289e-4ebb-b5dd-3e67a20496bb>"],"error":null}
{"question":"How long do cookies like _ga and fr stay active compared to session cookies?","answer":"The cookies have different lifespans: _ga is a HTTP cookie that lasts for 2 years, while fr is a HTTP cookie stored for 3 months. In contrast, session-based cookies like _gat, _gid, and Dynamicweb.SessionVisitor only last for the duration of the user's session and are deleted when the session ends.","context":["What is the General Data Protection Regulation?\nIn legal terms, the GDPR is a European Union law intended to strengthen and unify data protection rules and rights for the benefit of EU citizens. Put in other words, to give control of personal data back to the user. While great news for individuals, it presents complex problems for companies.\nThe new rules apply to all organizations (of any size) that provide goods and services to the EU or that utilize tracking technologies (like cookies or tracking pixels) to monitor EU users’ behavior.\nWhile simple in theory, the law is dense and complex and requires a comprehensive understanding of the data you collect, whether it's personal or not, how you store and use it, and how you expose or remove data upon request. To do so, you must look at every single process and line of software code to outline your data processes.\nIn most cases, your data collection will require valid consent following May 25 - not just going forward, but also from all your existing users. Under the GDPR, consent can't be implied or inferred from someone's actions. Instead, valid consent must be specific to the data being collected, by an affirmative action that is unambiguous.\nLearn more about the General Data Protection Regulation (GDPR)\n1. Personal Information - What we collect and why\nWe offer certain site features, services, applications, and tools that are available only through the use of the following tracking technologies. You are always free to block, delete, or disable these technologies if your browser, installed application, or device so permits. However, if you decline cookies or other similar technologies, you may not be able to take advantage of certain site features, services, applications, or tools.\nGenerally, these technologies allow our sites, services, applications, and tools to store relevant information in your browser or device and later read that information in order to identify you to our servers or internal systems. Where applicable, we protect our cookies and other similar technologies to help ensure that only we and/or our authorized service providers can interpret them by assigning them a unique identifier that is designed for interpretation only by us.\nThis website collects and uses personal information for the following reasons:\n1.1. Google Analytics\nLike most websites, this site uses Google Analytics (GA) to track user interaction. We use this data to determine the number of people using our site, to better understand how they find and use our web pages and to see their journey through the website.\nAlthough GA records data such as your geographical location, device, internet browser and operating system, none of this information personally identifies you to us. GA also records your computer’s IP address which could be used to personally identify you but Google do not grant us access to this. We consider Google to be a third party data processor (see section 2 below).\nDisabling cookies on your internet browser will stop GA from tracking any part of your visit to pages within this website.\nLearn more about Google Analytics.\n1.2. Google Tag Manager\nWe are constantly trying to improve the customer experience on our website by providing visitors with more personalized and targeted campaigns and offerings. To do so, we use Google Tag Manager (GTM).\nGTM is a little snippet of code that helps us track user behavior across our sites and then pushes the data to our Google Analytics account. Then, all the data is perfectly organized and ready for us to assess and review for potential site improvements and remarketing campaigns.\nWe consider Google to be a third party data processor (see section 2 below).\nLearn more about Google Tag Manager.\n1.3. Contact, signup and download forms etc.\nShould you choose to contact us using i.e. the contact/signup form on our pages or download gated content from our website, your information will be stored in our backend and collated into an email and sent to us over the Simple Mail Transfer Protocol (SMTP).\n1.4. E-mail newsletter\nOn the website of Migatronic A/S, users are given the opportunity to subscribe to our enterprise's newsletter. A confirmation e-mail will be sent to the e-mail address registered by a data subject for the first time for newsletter shipping, for legal reasons, in the double opt-in procedure. This confirmation e-mail is used to prove whether the owner of the e-mail address as the data subject is authorized to receive the newsletter.\nThe personal data collected as part of a registration for the newsletter will only be used to send our newsletter. In addition, subscribers to the newsletter may be informed by e-mail, as long as this is necessary for the operation of the newsletter service or a registration in question, as this could be the case in the event of modifications to the newsletter offer, or in the event of a change in technical circumstances.\nThe subscription to our newsletter may be terminated by the data subject at any time. The consent to the storage of personal data, which the data subject has given for shipping the newsletter, may be revoked at any time. For the purpose of revocation of consent, a corresponding link is found in each newsletter. It is also possible to unsubscribe from the newsletter at any time by contacting us.\nThe newsletter of Migatronic A/S contains so-called tracking pixels. A tracking pixel is a miniature graphic embedded in such e-mails, which are sent in HTML format to enable log file recording and analysis. This allows a statistical analysis of the success or failure of online marketing campaigns. Based on the embedded tracking pixel, Migatronic A/S may see if and when an e-mail was opened by a data subject, and which links in the e-mail were called up by data subjects.\nSuch personal data collected in the tracking pixels contained in the newsletters are stored and analyzed by the controller in order to optimize the shipping of the newsletter, as well as to adapt the content of future newsletters even better to the interests of the data subject. These personal data will not be passed on to third parties. Data subjects are at any time entitled to revoke the respective separate declaration of consent issued by means of the double-opt-in procedure. After a revocation, these personal data will be deleted by the controller. Migatronic A/S automatically regards a withdrawal from the receipt of the newsletter as a revocation.\n1.5. Website cookies\n- In connection with log-in information: \"DW_Extranet\" (only if the solution contains Extranet)\n”DW_Extranet” is a ”persistent cookie”. It contains encrypted information about username and password to the extent you are using a log-in function on the Website. The lifespan of the cookie is one month, and it will therefore be deleted one month after the last time you have used the Website's log-in function. This cookie is used to remember you when you return to the Website, so that you won't have to log in again.\n- In connection with the date of your last visit: ”Dynamicweb.VisitDate”\n”Dynamicweb.VisitDate” is a persistent cookie. it contains information about the date of your last visit to the Website and is used in connection with statistics. The cookie has a one year lifespan and it is therefore deleted one year after your last visit to the Website.\n- In connection with previous visits: ”Dynamicweb.VisitorID”\n”Dynamicweb.VisitorID” is a persistent cookie. It contains a unique ID which you have been given upon your visiting the Website. It is used in connection with statistics. The cookie has a one year lifespan and it is therefore deleted one year after your last visit to the Website.\n- In connection with current session: ”Dynamicweb.SessionVisitor”\n\"Dynamicweb.SessionVisitor\" is a session based cookie. It preserves users states across page requests.\n- In connection with each session: \"ASP.NET_SessionID\"\nThis cookie preserves the visitor's session state across page requests.\n- In conncection with statistics: \"_ga\"\n\"_ga\" is a 2 year HTTP cookie. Registers a unique ID that is used to generate statistical data on how the visitor uses the website.\n- In conncection with each session: \"_gat\"\n\"_gat\" is a session cookie, used by Google Analytics to throttle request rate.\n- In connection with statistics: \"_gid\"\n\"_gid\" is a session cookie. Registers a unique ID that is used to generate statistical data on how the visitor uses the website.\n- In connection with marketing: \"ads/ga-audiences\"\n\"ads/ga-audiences\" is a session cookie. Used by Google AdWords to re-engage visitors that are likely to convert to costumers based on the visitor's online behaviour across websites.\n- In connection with marketing: \"fr\"\n\"fr\" is a HTTP cookie stored for 3 months. Used by Facebook to deliver a series of advertisement products such as real time bidding from third party advertisers.\n- In connection with marketing: \"tr\"\n\"tr\" is a session based tracking pixel. It tracks the actions that users take on the website using both standard events and custom events.\n2. Our Third Party Data Processors\nWe use a number of third parties to process personal data on our behalf. These third parties have been carefully chosen and all of them comply with the legislation set out in the EU General Data Protection Regulation 2018 (GDPR).\n- Microsoft Office 365 (Privacy Statement)\n- Microsoft Dynamics 365 (Security and Compliance)\n3. How Long do We Store Your Information\nWe will retain your personal information for the period necessary to fulfill the purposes outlined on our 'Consent page'. You can always contact us, if you want your personal data 'erased' from our databases (see Section 6). We will respond without undue delay (and in any event within one month, although this can be extended in difficult cases).\n4. Data Breaches\nWe will report any unlawful data breach of this website’s database or the database(s) of any of our third party data processors to any and all relevant persons and authorities within 72 hours of the breach if it is apparent that personal data stored in an identifiable manner has been stolen.\n5. Data Controller\nThe data controller of this website is: Svejsemaskinefabrikken Migatronic A/S, with company number (CVR): 34485216 whose registered office is:\nPhone: +45 96 500 600\n6. Right to Access and To Be Forgotten\nPlease contact us, if you want to request access to your personal information stored in our databases, or if you want your personal data 'erased' from our databases. We will respond without undue delay (and in any event within one month from receiving your request, although this can be extended in difficult cases).\nPhone: +45 96 500 600\n7. Privacy Questions\nPhone: +45 96 500 600\nWhen a privacy question or access/download request is received we have a dedicated team which triages the contacts and seeks to address the specific concern or query which you are seeking to raise. Where your issue may be more substantive in nature, more information may be sought from you."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:991c2fe9-1627-484b-9ccd-be7bab67b8ae>"],"error":null}
{"question":"How is Australia protecting sharks through legal measures, and what threats are these animals facing globally from commercial fishing?","answer":"Australia has implemented various legal protections for sharks, including listing several species under the Environment Protection and Biodiversity Conservation Act (EPBC Act). The Great White Shark was listed in 1997, the Grey Nurse Shark received Critically Endangered status on the east coast, and the Scalloped Hammerhead was listed as Conservation Dependent in 2018. Live shark finning is now illegal in all Australian waters. Globally, sharks face severe threats from commercial fishing, with approximately 73 million sharks killed annually for the shark fin soup trade. Additionally, millions more are killed as bycatch in various fisheries, including shrimp trawling, tuna purse seine, and billfish longline fisheries. One-third of open-ocean shark species are at risk of extinction in the coming decades, with some populations declining by over 90% in recent years.","context":["27,705 of 28,000 Signatures\n16,090 of 20,000 Signatures\nHSI and AMCS Shark/Marine Achievements\nHSI and AMCS Shark/Marine Achievements\nNominated Great White Shark for protection\nIn 1997, HSI successfully nominated the Great White Shark to be listed under the Endangered Species Protection Act 1992 and later as Vulnerable under the Federal Environment Protection and Biodiversity Conservation Act (EPBC Act) 1999.\nLive shark finning banned in Australia\nThanks to AMCS, live shark finning at sea is now illegal in all Australian waters.\nNominated Grey Nurse Shark for protection\nHSI successfully nominated the Grey Nurse Shark for Critically Endangered status on the east coast of Australia under the Federal EPBC Act.\nSecured the Great Barrier Reef as a marine park\nAMCS led and built the campaign, resulting in the declaration of the Marine Park in 1974 and later a World Heritage Area in 1982.\nNominated Scalloped Hammerhead for protection\nAs a result of a HSI nomination, the Scalloped Hammerhead was listed as Conservation Dependent in 2018 under the EPBC Act.\nReducing sharks caught in the Great Barrier Reef\nAMCS has reduced the amount of sharks that can be fished by 300t in Queensland’s east coast fishery which spans the entirety of the Great Barrier Reef.\nNominated School Shark for protection\nAs a result of a HSI nomination, the School Shark was listed as Conservation Dependent in 2003 under the EPBC Act.\nProtected 17,500km2 of WA coastline from shark fishing.\nIn 2018, AMCS ensured areas surrounding Australia sea lion colonies were closed to commercial shark fishing.\nShark species removed from QLD Government’s hit list\nFollowing HSI’s legal action against shark culling in the Great Barrier Reef, the Queensland Government removed seven species of shark from its target list in 2018. This means that if found alive on a lethal drumline in Queensland, the sharks will no longer be shot dead.\nNingaloo Reef saved\nFamous for whale sharks and manta rays, AMCS prevented a major marina development and secured 34% of the Ningaloo Marine Park in green zones, and most recently a World Heritage listing in 2011.\nPassage of Federal EPBC Act 1999\nHSI was one of the key NGOs behind the passage of the Federal EPBC Act in 1999, legislation under which 13 species of sharks are protected.\nSecuring habitat protection for the Grey Nurse shark\nAMCS improved the protection of the (endangered) grey nurse shark by securing the protection of critical habitats in New South Wales and Queensland.\nMore than 100 species/habitats protected under Australian environment laws\nHSI is responsible for nominating more than 70 species for protection under Australian environmental laws, and 28 of the 78 ecological communities protected by Federal legislation.\nMarine Parks in state waters\nIn collaboration with state based groups, AMCS secured marine parks across Victoria, in central NSW, across SA, parts of WA and Queensland.\nInternational Protection for Great White Shark\nHSI was behind the ground-breaking global protection given to the Great White Shark from trade in its jaws and fins at the Convention on International Trade in Endangered Species of Wild Fauna And Flora (CITES). With us as their champions, many sharks are now protected at CITES.\nNon-Government Organisation representative on the Shark-plan Representative Group (SRG).\nThe group meets annually to discuss current issues in the conservation and management of sharks around the country, and is made up of representatives of the commercial and recreational fishing sector, government agencies and NGOs. The group assesses Australia’s progress on the National Plan of Action for Sharks, Australia’s guiding documents on the conservation and management of sharks.\nChairing Shark Working Group\nHSI co-chairs a Shark Working Group of campaigners fighting for sharks under international law, resulting in 34 species of sharks and rays being protected internationally.\nSustainable Seafood revolution\nThe highly successful Australia’s Sustainable Seafood Guide helps Australians protect sharks from fishing by empowering them to choose sustainably sourced seafood. The guide is available in paperback and as an app.\nChallenge to Shark Fishery\nHSI successfully challenged a decision to declare the Southern and Eastern Scalefish and Shark Fishery (SESSF) an ecologically sustainable Wildlife Trade Operation under the EPBC Act 1999. This resulted in increased protections for the Australian sea lion, eastern gemfish, Harrison’s dogfish and threatened albatross and petrels.\nStopped the Super Trawler\nSecured changes to federal environmental laws enabling new, untried and destructive fishing methods (including the MV Margiris super trawler) in Australian waters, to be scientifically assessed and excluded.","Sharks consistently rank near the top of lists of American’s greatest fears. In reality, they have much more to fear from us than we do from them. Because of our actions, many species of sharks are on the verge of extinction. A recent International Union for the Conservation of Nature Shark Specialist Group report shows that fully 1/3 of open-ocean species of sharks are in danger of extinction in the next few decades. Many shark species have had population declines of over 90% in the last few decades.\nThe life history strategy of sharks is very different from that of other commercially exploited fishes, and this makes them more vulnerable to overexploitation. Several species of sharks don’t reproduce until they are older than ten years old, and some only have a few young every other year (or in some cases, every three years). It’s easy to see how this inability to rapidly replace themselves could become an existential problem when modern industrial fishing techniques are involved.\nWhile few sharks are targeted for their flesh, which is considered unpalatable except for a few species, most species are targeted for their fins. The fins, which have absolutely no meat, flavor, or nutritional value whatsoever, are made into an Asian delicacy called shark fin soup. They provide only texture to the spiced chicken broth. While it is impossible to know exactly how many sharks are killed in this global, largely unregulated fishery, the best scientific estimates we have say that the number is as high as 73 million each year.\nBeing targeted isn’t the only thing problem facing sharks-bycatch is another major threat to many shark species. Millions of sharks each year are killed by fishing gear simply because they are swimming near what fishermen are trying to catch- the ultimate example of being in the wrong place at the wrong time. Though few fisheries are blameless from a bycatch perspective, particular culprits include the shrimp trawling fishery, the tuna purse seine fishery, and the billfish longline fishery.\nSince sharks serve as apex predators in most marine ecosystems, their declines pose major troubles both to the environment and to the countless humans who depend on that environment for food and to make a living.\nThe problem is a major one, and we need to solve it.\nIt’s easy to become discouraged when considering the enormity of the problem, but we must not give up. We must focus on the goal, and work towards it!\nTo paraphrase an old joke about my fellow Jews, if you ask three conservationists what their goal is, you’ll likely get four answers. This post is about my goal, which isn’t necessarily the goal of the entire ‘save the sharks’ movement. I expect that many of my conservationist friends will disagree with parts of it, and I look forward to a lively discussion.\nSharks are being harvested (or killed accidentally as bycatch) at wildly unsustainable rates. This needs to stop, and sharks need some strong legal protections to ensure this.\nThe form that these legal protections will take is the subject of much debate. A (very) few countries like Palau make fishing for sharks in any form illegal in their territorial waters. Hawaii now bans the selling, purchasing, or possession of shark fins within state boundaries. U.S. fisheries management policy presently makes it illegal to kill some species of shark and sets size limits on some other species. However, most countries have no legal protection at all for sharks, and the number of species with worldwide protection (at least on paper, since these are difficult to enforce in the middle of the ocean) can be counted on one hand.\nThough this may shock some of my readers, I do not think that global shark conservation policy needs to be as extreme as Palau’s “you can’t kill any sharks ever” law. I do not object to the sustainable harvest of sharks for food. Sustainably harvesting animals that have so few young so late in life is extremely difficult, and most times that it has been tried, the fishery has collapsed within a few decades. That doesn’t mean that it is impossible and it doesn’t mean that we should ban all shark fishing. However, for me to be satisfied, the world of commercial fishing is going to need to undergo some drastic changes.\nThe goal for finning\nWhile I can accept sustainable fishing for some shark meat, I object to the shark fin soup fishery. In most parts of the world, this fishery is brutal, wasteful, and unsustainable. Sharks of any species and size have their fins cut off, and the rest of the animal is dumped overboard to bleed to death or drown- all to provide texture to a delicacy for the rich. The few countries that have shark finning regulations at all have different strategies to manage it.\nSome, like Canada, require that fishermen land the rest of the shark in addition to the fins (not attached to each other), and they enforce this by weighing total fins and total shark carcasses. This is silly, because different shark species can have a drastically different fin-to-body weight ratio. Other countries require that fishermen land sharks with the fins still attached, which is better and is starting to become the standard.\nI would feel differently about shark finning if it provided a staple food item for the world’s poor instead of a delicacy for the rich. I would feel differently about shark finning if the shark’s meat was used, instead of just cartilage for texture. I would feel differently if fishermen targeted only certain species of a certain size instead of every shark they find. As it stands, though, my goal for the shark finning fishery is its complete abolition.\nUpdated 7/8/12 To clarify, this personal opinion applies to fins that are provided to the market via the wasteful practice of finning. Fins that are provided to the marketplace via well-regulated comprehensive shark fisheries are a separate issue.\nThe goal for bycatch\nThe threat sharks face from bycatch is harder to regulate. In some cases, simple gear modifications can minimize the amount of sharks caught without greatly influencing the catch of target species. In other cases, simply placing gear in slightly different locations or depths can greatly reduce the number of sharks caught accidentally. Some of these changes have been made already, most have not been. Conservationists who fight for long-term large-scale goals should sometimes fight for easy fixes that will still make a lot of difference. My goal is for every single known and feasible bycatch reduction strategy to be implemented. This won’t eliminate bycatch, but it will reduce it significantly.\nSome fishing gear is so destructive (to sharks and many other ocean animals) that simple fixes just won’t help. In these cases, my goal is for that gear to be banned entirely. This is not unprecedented- the U.N. banned large drift nets almost 20 years ago because of the huge amount of bycatch they caused.\nThe goal for marine protected areas\nWhile I don’t think that we need a global ban on shark fishing modeled after Palau’s policy, some small-scale areas where shark fishing is banned would be very helpful. Research performed on a marine protected area in Belize has shown that many species of shark remain in a small area for much of their lives, showing that a small region where shark fishing is illegal can have an effect. However, some species, like the Great White shark, can swim thousands of miles in a year and wouldn’t stay in a small protected area very long. Although they won’t help all shark species, marine protected areas will protect many. My goal is a large worldwide network of marine protected areas that protect sharks and other marine animals.\nMy goal for fishermen\nThe global commercial fisheries industry is at a crossroads. There are too many fisherman chasing too few fish, and overfishing is rampant. However, contrary to the claims and insinuations of some conservationists, fishermen are not evil people trying to destroy the environment. They are hardworking people who are just trying to provide for their families, and they are correct when the point out that most policies that will protect marine life will harm them financially. However, if nothing is done, there will be no fish to catch and fishermen will be harmed financially anyway. My goal is for there to be fewer commercial fishing vessels and a much lower global catch, and I am open to suggestions on how to help the fishermen that this policy would negatively impact.\nMy goal is for an end to unsustainable shark fishing, a ban on the shark fin soup fishery, the implementation of bycatch reduction policies, a global network of marine protected areas, and some form of incentive or regulation to encourage fishermen to catch fewer fish overall. Some parts of this goal would be more effective for protecting sharks than others. Some are more achievable than others. I believe that all are worth fighting for.\nHow to get there\nIt’s easy to dream big and come up with impossible goals. It’s much harder to draw a realistic map showing how to get from where we are to where we want to be.\nMost of you reading this already don’t eat shark fin soup, and many of you don’t eat foods with high shark bycatch. That’s great, but while I have a pretty high opinion of myself, even I don’t believe that I reach enough people through my writing to make a difference in a major global issue. Not directly, at least.\nThe key to achieving the goals of the shark conservation movement (and the conservation movement in general) is education. Maybe I’m too much of an optimist, but I fervently believe that sharks aren’t in trouble because no one cares what is happening to them. I believe that sharks are in trouble because no one knows that sharks are important to a healthy ecosystem, and no one knows that sharks are in trouble.\nThe absolute best thing you can do is to learn about sharks and tell others. Tell your friends, tell your family, tell your classmates or tell your co-workers. Tell them that sharks matter, and tell them that sharks are in trouble. Tell them not to eat shark fin soup, and not to eat seafood with high shark bycatch. Tell them to support shark conservation legislation by calling their elected officials.\nWhat you should NOT do is support violent groups that claim to “fight for the sharks” through “direct action”. These groups are not only ineffective, but they are counterproductive to the cause of conservation. The conservation movement is a PR war, and we will win through facts and persuasive argument- NOT through trying to hurt people who disagree with us.\nAnother common (and flawed) solution is to not eat seafood at all because of environmental concerns. If all of the people who care about the oceans stop eating seafood, it’s impossible for conservation-minded folks to “vote with their wallets” and support more environmentally friendly methods of catching fish. I instead recommend eating Marine Stewardship Council certified sustainable seafood.\nGraduate students such as myself lack the resources to donate significant amounts of money to conservation NGO’s, but if any readers are looking for my opinion on what NGO’s to trust, I have a few. Oceana doesn’t focus exclusively on sharks, but I love almost all of what they do. WildAid also has a broad focus, but their anti-finning campaigns are wonderful (they recruited Yao Ming, who is a huge celebrity in China, to be their spokesman). The Save Our Seas Foundation does a lot of inspiring work with educating children about the importance of sharks and other sea life. The Shark Research Institute is a small but great organization that focuses on both conservation and science. Sonja Fordham’s Shark Advocates International is a new organization, but Sonja is legendary within the shark conservation community and I know she’ll accomplish amazing things with SAI.\nIf you are looking for a source for shark-themed gifts that help sharks, I have a few suggestions. Iemanya Oceanica’s “Adopt a Shark” program makes a good gift, and promotes shark research. The American Elasmobranch Society student store raises money for young shark scientists to do important research. My own Southern Fried Science store sells “Sharks Matter/No finning gear”, which raises money for the charities I’ve listed above.\nMany people claim that it’s too late to save the planet. I couldn’t disagree more.\nThe problem is a big one. The goals are difficult, but they are achievable in some form. Now that you know what to do, get to it.\nTo paraphrase a famous Donella Meadows quote, we have exactly enough time to save sharks and save our oceans… starting now.\nBaum, J. (2003). Collapse and Conservation of Shark Populations in the Northwest Atlantic Science, 299 (5605), 389-392 DOI: 10.1126/science.1079777\nBonfil, R. (2005). Transoceanic Migration, Spatial Dynamics, and Population Linkages of White Sharks Science, 310 (5745), 100-103 DOI: 10.1126/science.1114898\nClarke, S., McAllister, M., Milner-Gulland, E., Kirkwood, G., Michielsens, C., Agnew, D., Pikitch, E., Nakano, H., & Shivji, M. (2006). Global estimates of shark catches using trade records from commercial markets Ecology Letters, 9 (10), 1115-1126 DOI: 10.1111/j.1461-0248.2006.00968.x\nConrath, C., & Musick, J. (2007). The Sandbar Shark Summer Nursery within Bays and Lagoons of the Eastern Shore of Virginia Transactions of the American Fisheries Society, 136 (4), 999-1007 DOI: 10.1577/T06-107.1\nCortés, E. (2000). Life History Patterns and Correlations in Sharks Reviews in Fisheries Science, 8 (4), 299-344 DOI: 10.1080/10408340308951115\nDulvy, N., Baum, J., Clarke, S., Compagno, L., Cortés, E., Domingo, A., Fordham, S., Fowler, S., Francis, M., Gibson, C., Martínez, J., Musick, J., Soldo, A., Stevens, J., & Valenti, S. (2008). You can swim but you can’t hide: the global status and conservation of oceanic pelagic sharks and rays Aquatic Conservation: Marine and Freshwater Ecosystems, 18 (5), 459-482 DOI: 10.1002/aqc.975\nMusick, JA (2000). Management of Sharks and their relatives (Elasmobranchii) Fisheries\nPikitch, E., Chapman, D., Babcock, E., & Shivji, M. (2005). Habitat use and demographic population structure of elasmobranchs at a Caribbean atoll (Glovers Reef, Belize) Marine Ecology Progress Series, 302, 187-197 DOI: 10.3354/meps302187\nTopelko, K., & Dearden, P. (2005). The Shark Watching Industry and its Potential Contribution to Shark Conservation Journal of Ecotourism, 4 (2), 108-128 DOI: 10.1080/14724040409480343\nWalker, T. (1998). Can shark resources be harvested sustainably? A question revisited with a review of shark fisheries Marine and Freshwater Research, 49 (7) DOI: 10.1071/MF98017"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:27b3442d-9359-4793-8bf3-9e2ac9c637d9>","<urn:uuid:4f23ef1a-bdcc-49bd-bfee-b87cf4c0b3d9>"],"error":null}
{"question":"What are the key monitoring methods for detecting microplastics versus macroplastics in ocean pollution?","answer":"For microplastics, the main monitoring method is using blue mussels as bio-indicators, along with sediment analysis and sediment-dwelling organisms like worms and bivalves. For larger plastic debris, Ocean Voyages Institute uses GPS satellite trackers placed on nets, drones, and lookouts to locate and recover macroplastic waste. The tracking system has proven that one tagged fishing net can lead to finding other nets within a 15-mile radius, as ocean currents tend to concentrate debris in specific areas.","context":["OVI: Over 100 tons of plastics recovered in largest-ever open ocean cleanup\nOcean Voyages Institute’s (OVI) marine plastic recovery vessel, S/V Kwai, docked at the port of Honolulu on 23 June 2020, after a 48-day expedition, successfully removing 103 tons of fishing nets and consumer plastics from the North Pacific Subtropical Convergence Zone, more commonly known as the Great Pacific Garbage Patch or Gyre.\nOcean Voyages Institute has set a new record with the largest at sea cleanup in the Gyre to date, more than doubling its own results from last year.\n“We exceeded our goal of capturing 100 tons of toxic consumer plastics and derelict ‘ghost’ nets, and in these challenging times, we are continuing to help restore the health of our ocean, which influences our own health and the health of the planet,” Mary Crowley, founder and executive director of Ocean Voyages Institute, commented.\n“The oceans can’t wait for these nets and debris to break down into microplastics which impair the ocean’s ability to store carbon and toxify the fragile ocean food web.”\nCrowley has developed effective methods to remove significant amounts of plastics out of the ocean, including 48 tons of toxic plastics during two ocean clean-ups in 2019, one from the Gyre and one from the waters surrounding the Hawaiian islands.\n“There is no cure-all solution to ocean clean-up: It is the long days at sea, with dedicated crew scanning the horizon, grappling nets, and retrieving huge amounts of trash, that makes it happen,” Locky MacLean, a former director at Sea Shepherd and ocean campaigner in marine conservation for two decades, said.\nAs explained, the GPS satellite trackers used by Ocean Voyages Institute since 2018 are proving Crowley’s theory that one tracker can lead to many nets. The ocean frequently sorts debris so that a tagged fishing net can lead to other nets and a density of debris within a 15 mile radius.\nThe Pacific Gyre, located halfway between Hawaii and California, is the largest area with the most plastic, of the five major open ocean plastic accumulation regions, or Gyres, in the world’s oceans.\n“We are utilizing proven nautical equipment to effectively clean-up the oceans while innovating with new technologies,” Crowley said.\nOVI will be unloading the record-breaking haul of ocean plastic debris while docked alongside Pier 29 thanks to the support of Honolulu-based Matson, in preparation for upcycling and proper disposal.\n“In keeping with our commitment to environmental stewardship, Matson has been searching for a way to get involved in cleaning up the Pacific Gyre,” Matt Cox, chairman and CEO, said.\n“We’ve been impressed with the groundbreaking efforts of Ocean Voyages Institute and the progress they’ve made with such a small organization, and we hope our support will help them continue this important work.”\nAn expanded 2020 expedition\nKwai’s mission began at the Hawaiian port of Hilo on 4 May, after a three-week self-imposed quarantine period to ensure the health of crew members and safety of the mission, in the face of the COVID-19 pandemic.\nDuring the expedition, the crew collected marine plastic pollution with the help of GPS satellite trackers that Ocean Voyages Institute designed with an enginner from Pacific Gyre.\nThese beacons are placed on nets by volunteer yachts and ships. Drones, as well as lookouts up the mast, enable the ship’s crew to hone in on the debris. They then recover the litter, place it in industrial bags, and store it in the ship’s cargo hold for proper recycling and repurposing at the end of the voyage.\nThe marine plastic recovery vessel and OVI are planning a second voyage to the Gyre departing the end of June to continue cleanup of this area, which is so besieged by toxic debris. The length of a second summer leg will be determined by how successful Ocean Voyages Institute is in securing additional donations.\n“Our solutions are scalable, and next year, we could have three vessels operating in the North Pacific Gyre for three months all bringing in large cargos of debris,” Crowley further said.\n“We are aiming to expand to other parts of the world desperately needing efficient clean-up technologies.”\n“There is no doubt in my mind that our work is making the oceans healthier for the planet and safer for marine wildlife, as these nets will never again entangle or harm a whale, dolphin, turtle or reefs,” Crowley concluded.","iNsight by Anette Jæger\nThe sea and oceans are facing a huge challenge with the large amounts of plastics. The European Chemicals Agency (ECHA) has defined microplastics as follows: “Microplastics are synthetic, water-insoluble polymer items smaller than 5 mm, which are considered to be of particular concern for the aquatic environment.” The potential impact of microplastics on the aquatic life and human health have generated major concerns in Member States of the European Union and worldwide.\nWe use big amounts of plastic every day, and in many countries, there is no collection or good recycling programs for this type of litter. The plastic often ends up being washed by the rain into the sewers or rivers and eventually ends its journey in the sea. This creates a lot of litter that is very slowly broken-down, 50 – 400 years, floating around in the oceans. The physical impact the plastic litter has on wildlife, has been demonstrated numerous times in the field, but the impact microplastics have on the marine environment is not that obvious. It is however harmful for living organisms, physical effects caused by the particles themselves and transportation of toxic chemicals bonded to the microplastics that are released within the organisms. This can further lead to potential effects on populations, communities and ecosystems.\nSources for plastics are as varied as it is enormous; bottles, food containers, pipes, textile, fishing gear, films, bags, cigarette butts, tyres, balloons etc. Some microplastics are manufactured for specific applications, such as industrial scrubbers or personal cleaning products such as toothpaste. All plastics can be subject to fragmentation on environmental exposure and degradation into (secondary) microplastics. The proportion of plastic reaching the ocean to become plastic litter depends on the effectiveness of the re-use, recycle and waste management chain.\nMicroplastics in the Oil & Gas Industry\nToday we do not have any special restrictions on the use of microplastic particles in products. NEMS is responsible for the NEMS Chemicals database containing data on biodegradability, bioaccumulation and toxicology (HOCNF (Harmonized Offshore Chemical Notification Format)) on all the chemical products used and discharged by the oil and gas industry into the North Sea, the Norwegian Sea and the Barents Sea. A new proposition to include microplastics in the HOCNF format is underway, if it is included in the HOCNF it would be possible to track how much microplastics are released to sea by the oil and gas industry.\nA survey was done by EOSCA (European Oilfields Specialty Chemicals Association) in 2018 to estimate how much microplastic is used in EOSCA products sold in Norway, the United Kingdom, Denmark, the Netherlands and Ireland. Out of 3252 products only 3,5% contained microplastics. As we can see from the pie-charts below, the amount of known microplastics in chemicals is very small. We should however try to reduce the discharge of microplastics in any circumstance.\nMonitoring of microplastics in the ocean\nThere is a high focus on microplastics due to the direct effect this pollution has on living organisms. When the microplastic enters the ecosystem, the organisms have trouble processing it. Plastic is persistent and living beings do not have the ability to process it.\nOver time microplastics is degraded into nanoplastic by UV- (sun)light, mechanical/physical degradation, microbial degradation, hydrolysis and heat. This is impossible to see for the naked eye in the fish we put on our dinner plates.\nAs of today more long term research is needed to find out how microplastic affect the marine environment. Today Blue mussels is the main method we monitor for microplastic pollution. Sediments are often thought to be the final destination for most microplastics in the environment. Monitoring the sediments would give us a better understanding of the long-term trends. However, due to the complexity of sediment analysis, it might be more suitable to use sediment dwelling organisms, such as worms and bivalves feeding off and in the sediment.\nCleaning up plastics from the ocean\nWhen microplastics started making headlines in mainstream media, many people and authorities started to think of possible solutions to this problem. In Norway a campaign called “fishing for litter” was launched. Fish boats are used to collect litter from the ocean and deliver it for onshore processing. In 2017 there was collected 84 tonnes of litter (not only plastics).\nIn the United States the Ocean Concervancy organization has started a programme called the International Coastal Cleanup which engages volunteers from over a 100 countries to pick up litter around their coastlines each year.\nIn the Netherlands The Ocean Cleanup project has developed a system to collect floating plastic in the open oceans. A 120-meter-long curved “pipeline” with a four-meter skirt underneath collects plastic floating near the surface. The Ocean Cleanup project has done a lot of research on how the plastic behaves and are now testing their first clean-up system. It was set afloat late in 2018, but in the last days of 2018 it was running into trouble. When transported to land it had collected two tonnes of plastics, now it is onshore to have improvements done to the system so it can eventually gather up to one tonne a week of floating plastic debris.\nIn the Pacific Ocean a plastic “island” known as the Great Pacific Garbage Patch was identified by Alaskan researchers in 1988. The Ocean Cleanup project have identified and measured the island that has been created as a result of the currents in the North Pacific. Their researches have reported that it covers 1.6 million square meters. Measuring a 100kilograms of plastics per square kilometre in the centre. The average piece of plastic is only 0.5 cm long. And the total amount of plastic is estimated at an astounding 80.000 metric tonnes.\nHow to make a difference\nThere are several ways to make an impact, from supporting organisations, participating in coastal cleanups, to making sure you recycle and throw away your litter in the correct bin. The most important thing is to do something. How you choose to pitch in is up to you. Companies can also participate, this can be done through having good routines on Waste Management and focusing on sustainability in their operations. Many companies release Corporate Sustainability Reports each year to highlight their work.\nReport done by NIVA for Miljødirektoratet;\n- “Testing of methodology for measuring microplastics in blue mussels (Mytilus spp) and sediments, and recommendations for future monitoring of microplastics (R & D-project)”\nEOSCA presentation in the SKIM meeting 24.05.2018:\n- “SOURCES, FATE AND EFFECTS OF MICROPLASTICS IN THE MARINE ENVIRONMENT: A GLOBAL ASSESSMENT” by GESAMP, Joint Group of Experts on the Scientific Aspects of Marine Environmental Protection\n- \"The Quantitative Distribution and Characteristics of Neuston Plastic in the North Pacific Ocean, 1985-88. (Final Report to U.S. Department of Commerce, National Marine Fisheries Service, Auke Bay Laboratory. Auke Bay, Alaska)\" by Day, Robert H.; Shaw, David G.; Ignell, Steven E. (1988)."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:7420b8fa-6c28-4ac2-9c05-acbac8ab0306>","<urn:uuid:5b1f5ebc-b419-4519-b5b9-9aeb2f3f3899>"],"error":null}
{"question":"What's the difference between loudspeaker diffraction loss compensation and wave interference patterns?","answer":"Loudspeaker diffraction loss compensation involves correcting a 6 dB bass reduction using specific electrical networks (like R-L networks) that mirror and counteract the loss. Wave interference, on the other hand, is a natural phenomenon where waves combine to either amplify (constructive interference) or reduce (destructive interference) their overall amplitude. While diffraction loss is a specific acoustic phenomenon requiring deliberate compensation, wave interference is a fundamental property of all waves that occurs whenever multiple waves interact.","context":["Technical Discussions of Audio and Loudspeaker Issues\nTopic No. 2\nLoudspeaker Diffraction Loss\nLoudspeaker enclosure \"diffraction loss\" occurs in the low frequency range of loudspeakers in enclosures that are located in the open, away from walls or other surfaces. The essence of it is this: At high frequencies the speaker is radiating into \"half space\" i.e. it is only radiating into the forward hemisphere. No significant energy is radiated to the rear of the speaker. At low frequencies the speaker is radiating into both the forward hemisphere and the rear hemisphere. That is, at low frequencies the speaker radiates into \"full space\". Because the \"energy density\" at low frequencies is reduced there is a loss of bass. In short, speaker systems designed for radiation into half space (mounted flush on an infinite plane) exhibit a loss of bass when implemented in typical speaker enclosures. Fortunately, this bass loss can be accurately modeled and subsequently compensated.\nMost loudspeaker modeling is performed based on the assumption of radiation into half space. A speaker radiating into half space plays 6 dB louder than the same speaker radiating into full space. This is the crux of the diffraction loss. A full range speaker finds itself radiating into half space at the upper frequencies but radiating into full space at lower frequencies. As a result, there is a gradual shift of -6dB from the highs to the lows. This is what is called the \"6 dB baffle step\" or the enclosures \"diffraction loss\". The center frequency of the transition is dependent on the dimensions of the baffle. The smaller the baffle the higher the transition frequency.\nThe shape of the diffraction loss frequency response curve depends on the size and shape of the enclosure. Olson has carefully documented the diffraction loss of enclosures of various shapes (see references below). All enclosure shapes exhibit a basic 6 dB transition (or \"step\") in the response with the bass ending up 6 dB below the treble. A spherical enclosure exhibits this transition clearly with a very smooth diffraction loss curve. In the curves below I have taken the liberty of extending the frequency range of Olson's original graphs from 100 Hz to 20 Hz at the low end and from 4kHz to 5 kHz at the high end. The low frequency response was extended to more clearly reveal the \"stepped\" nature of the response. I wanted it to be clear that the response levels off at the low end. Olson's own reproductions of the measured diffraction loss of a sphere by Muller, Black, and Davis tend to confirm that my extensions to the responses are correct.\nMore \"angular\" enclosures exhibit the underlying 6 dB step along with a series of response ripples that are dependent on the placement of the speaker with respect to the baffle edges. The worst case appears to be placing the driver at the center of a circular baffle so that it is the same distance from all diffracting edges.\nPlacing the driver on the baffle so that it is a different distance from each edge tends to minimize the response ripples and make the diffraction loss look more like the smooth loss of the sphere. Olson's rectangular enclosure is an improvement over the cube and the cylinder face but the driver is still equidistant from three edges. Other authors report further reduction in the ripples with careful driver placement and edge rounding.\nBecause the spherical diffraction loss is a common element for the diffraction of all enclosures and the response ripples are much more difficult to predict (and can be minimized anyway) it makes sense to approximate the diffraction loss of a loudspeaker as the diffraction loss of the equivalent sphere.\nOne simple electrical circuit which produces a 6 dB step reduction in the bass response is shown below.\nIf we let R1 = R2 = R then a 6 dB attenuation results at low frequencies. At higher frequencies (where C1 becomes a low impedance) the attenuator is effectively bypassed and the signal is passed without attenuation.\nIt can be shown that the 3 dB \"center\" frequency for the above network is given by:\nThe frequency response of diffraction modeling network typically looks like this:\nCareful inspection of Olson's spherical diffraction loss curve reveals a -3dB frequency of about 190 Hz for the 24\" sphere. Assuming that the 3 dB frequency is inversely proportional to the baffle diameter I have arrived at the following approximation for calculating the -3dB frequency as a function of baffle diameter.\nOnce the diffraction loss is known it is possible to design a simple electrical network that will exactly mirror the spherical diffraction loss and restore the lost bass to a speaker system. Loudspeaker designers have traditionally compensated for the diffraction loss by reducing the level of the tweeter and making other adjustments in the crossover. The method I propose is to design for half space but then do a precise mirror image compensation for the diffraction loss by way of an R-L network wired in series with the (impedance compensated) speaker. Alternately, the diffraction loss can be compensated at line level with a simple R-R-C network. Line level correction would reduce the requirement for the large inductors typically needed for a speaker level compensation network.\nA simple electrical network which produces a 6 dB step reduction in the treble response is shown below.\nHere R2 represents the loudspeaker load impedance. If we let R1 = R2 = R then a 6 dB attenuation results at high frequencies. At lower frequencies (where L1 becomes a low impedance) the attenuator is effectively bypassed and the signal is passed to the driver (R2 here) without attenuation.\nThe frequency response of 6 dB diffraction compensation network looks like this:\nTo design an RL network which will compensate for diffraction loss of a particular system we start by setting:\nNext, you can use my empirically derived equation to calculate the value of the inductor L1:\nI arrived at this equation for L1 by forcing the 3 dB frequency of the compensating network to match the 3 dB frequency for the diffraction loss of the baffle.\nThe resulting RL network should be wired in series with the speaker system it is compensating. The correction will be most accurate if the loudspeaker itself approximates a resistive load.\nWinSpeakerz models the diffraction loss of the enclosure as a simple spherical diffraction loss. Provided the driver is located \"irregularly\" on the baffle this gives very good approximation to the actual diffraction loss of the enclosure. The frequency of the transition is controlled by the \"Baffle Width\" parameter at the System Editor page 1. The response of the speaker can be viewed with or without the diffraction loss and the diffraction loss can also be viewed separately.\n25Jun99 A follow-up post on this topic:\nbeen researching the idea of adding a baffle step compensation circuit\nThe 6 dB loss is correct for a speaker enclosure in free space. When the enclosure is placed in a room it will encounter various effects due to the room (reverb, standing waves, boundary effect, cavity effect . . .)\nDiffraction loss and room effects are independent and completely different effects. The diffraction loss is nicely predictable whereas the effects of the room are highly variable, not only from room to room but also with speaker placement and room furnishing. This typically means that each listening environment will be unique and will require unique compensation.\nI suggest the 6 dB diffraction loss correction as a correction for the diffraction loss alone. I don't suggest that it will neutralize all the effects due to a unique listening environment. Others suggest you \"deal with diffraction\" in the crossover, usually by just lowering the tweeter level a bit.\nIn some situations 3 or 4 dB of diffraction loss correction may result in an overall response that is closer to neutral (flat). But the most correct way to compensate the room would be to do it separately from any diffraction loss correction. Room compensation might take the form of several notch filters tuned to the worst peaks resulting from room modes. Next you might want to tilt the treble up a smidge to compensate for reverberation that has significant treble loss. Dark room reverb will make the playback sound a little darker. Bright reverb . . . bright. Next, depending on the size of the room and speaker response, you might need to compensate for the cavity effect. In larger rooms cavity effect can be ignored but in vehicle cabins it is a major effect.\nDiffraction loss compensation is only part of the job of precisely compensating for the difference between a theoretical half-space acoustic load and what happens when we place an enclosure in a real world listening room. Reducing the degree of diffraction loss compensation MAY reduce the coloration from the room effects as these effects largely tend to \"boost the bass\" but such an adjustment is imprecise at best.\nIf we can systematically identify each source of color between our half space model and our particular listening room then we can then take steps to precisely neutralize the response in our own listening room. Spherical diffraction compensation is one effect we can correct with a high degree of precision. As we move toward a better understanding and modeling of our listening rooms I'm sure we will work out more practical and precise ways to compensate our rooms.\nComments and critique are welcome. :-)\nLoudspeaker Diffraction Technical References\nWright, J. R.\nRasmussen, Soren and Rasmussen, Karsten Bo\nGonzalez, Ralph E.\nPorter, James, and Geddes, Earl\nBews, R. M., and Hawksford, M. J.\nKral, Robert C.\nOlson, H. F.\nMuller, G.G., Black, R., and Davis, T. E.\nAudio Home Page | Catalog | Tech\nTopics | Audio Links | Book\nYour comments are welcome at firstname.lastname@example.org","Presentation on theme: \"Waves A disturbance in a medium that transfers energy and momentum.\"— Presentation transcript:\nWaves A disturbance in a medium that transfers energy and momentum\nTo produce a Wave: A vibration (disturbance) A medium – a substance to travel through.\nExamples of Waves Sound Light Water\nThere are two types of waves\nTransverse Transverse – the individual wave particles move perpendicular to the velocity of the wave. Examples: Electromagnetic waves (light waves, radio waves, microwaves, x-rays) Wave on a string\nLongitudinalLongitudinal – the individual wave particles move parallel to the velocity of the wave. Examples: Sound Waves\nParts of a wave: Amplitude Wavelength Frequency – The number of wave cycles in 1 second. Units 1/s = Hertz (Hz)\nWave Interference – The combination of two or more waves.Interference Constructive interference – Two waves combine to make a bigger wave. Destructive interference – Two waves combine to make a smaller wave.\nwavelength (m) Period (s) velocity wavelength = (velocity)(Period) wavelength (m) frequency (hz)\nThe Wave Equation v = velocity of the wave (m/s) λ = wavelength (m) f = frequency (1/s = Hz)\nExample1: A sound wave has a frequency of 256 Hz. What is the wavelength? The speed of sound is 340m/s.\nExample 2: A radio wave has a frequency of 96.9MHz. What is the wavelength? The speed of light is 3.0 x 10 8 m/s.\nStanding Waves on a String The velocity of a wave on the string depends on the mass per length of the string and the tension in the string. v = velocity of the wave (m/s) F T = Tension in the string (N) m = mass of the string (kg) L = length of the string (m)\nThe fundamental frequency 1 st Harmonic. L\nThe fundamental frequency 2 nd Harmonic. L\nThe fundamental frequency 3rd Harmonic. L\nThe fundamental frequency 4th Harmonic. L\nThe fundamental frequency 5th Harmonic. L\nSummary f n =nf 1 f n = nth harmonic n = 1, 2,3, ….. f 1 =1 st harmonic (fundamental frequency)\nConditions for interference L2L2 L1L1 P δ = path difference = L 2 – L 1 Constructive Interference δ = 0, λ, 2λ, 3λ ……. δ = nλ n = 0, 1, 2, 3, … Destructive Interference δ = λ/2, 3λ/2, 5λ/2 ……. δ = (n+ ½)λ n = 0, 1, 2, 3, ….…\nSound Waves The speed of sound in air at room temperature is 340m/s. The speed of sound increases with increasing temperature. The speed of sound in water is 1500m/s. The speed of sound in aluminum is 5100m/s.\nPhysics Human Perception frequency Intensity/Amplitude loudness Pitch\nPressure fluctuations in air due to a vibrating tuning fork. Applet\nFrequency range of the human ear.\nSound intensity and the decibel scale\nBeats Beats occur when two sound waves have slightly different frequencies interfere with one another. The number of beats per second is called the beat frequency. The beat frequency is determined by subtracting the two frequencies.\nStanding Sound Waves in a Tube The wave travels at the speed of sound (340m/s) Open ends must have an antinode Closed ends must have a node. A pressure wave is set up in the tube. A tube open at both ends acts just like the string. A tube closed at one end only has odd harmonics.\nOpen Tube Just like the string\nClosed Tube Odd Harmonics\nResonance occurs when the driving frequency matches the natural frequency, resulting in large amplitude vibrations. Here are some examples of resonance Pushing someone on a swing. The Tacoma Narrows bridge. Breaking a wine glass with a sound wave Earthquakes totally destroying some buildings and not damaging others.\nThe Doppler Effect is a change in frequency (pitch) due to the relative motion of the sound source and observer. As the sound and listener approach each other the frequency is higher. As the sound and listener move away from each other the frequency is lower. The Doppler effect also occurs with light producing the red and green shift of distant stars. Doppler radar is used to track weather systems"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:32abda9b-c1df-486a-979b-bd04dc4a1a40>","<urn:uuid:c4288816-73f9-4723-aa3c-68e395bd0d3a>"],"error":null}
{"question":"Hi! Could you give me a list of the key factors that made this wildlife artist fall in love with Africa and start his artistic career? ✨","answer":"The artist fell in love with Africa immediately upon arriving there in 1981. He began his artistic career because: 1) He had no job or car when he moved to Pietermaritzburg, 2) He started by drawing and received positive feedback from people he was staying with, 3) They encouraged him to work with color, leading him to buy pastels, though it took him about five years to develop his skills to a satisfactory level.","context":["Conserving wildlife with a paintbrush\n05 November 2018 | Art and Entertainment\nAn art exhibition titled Call of the Wild displaying works by Paul Dixon was recently launched at the Fine Art Gallery in Swakopmund.\nSpeaking to Erongo prior to the launch, Dixon explained why it is important for him to use his talent to raise awareness to preserve wildlife.\n“There is a lot of stuff going on these days with poaching and human wildlife conflict. Namibia needs a lot of awareness and support for charities dealing with these issues. I became involved through Martina (owner of the Fine Art Gallery), mostly with the Desert Lion Trust, the Desert Lion Human Relations Aid, the Desert Elephant Foundation and AfriCat and Cheetah Conservation Foundation which are all Namibian organisations.”\nDixon says he has been visiting Namibia regularly from Cape Town and it is good to put something back because he makes a living painting animals.\n\"It’s good to do what I can to look after animals, otherwise what would I paint? If there are no animals, I would have to paint landscapes and my landscape painting is not that good.”\nHe explained how he got involved in a movement which helps to raise funds in the fight against poaching.\n“Me and eight other artists formed a group called artists ambassadors against poaching. We do awareness exhibitions, talks and fundraising. Every little bit of money helps. It’s never enough. What amazes me with the human race is that governments spend billions on things to kill people but they won’t even spend millions on conserving wildlife. But we all share this planet and we are all linked, even a little ant performs an important role. If you took away the leaf cutting ants in the rain forest there would be an inundation of animals that feed off those ants dying. Even the small little animals matter but we’re busy popping them out,” he said.\nHe explained how he became involved in art.\n\"I met a woman in England who is from Zimbabawe in the 1970s. She was in the UK on a working holiday. We got married in the UK. She was homesick for Africa and wanted to come visit. Ee left and came to live in Pietermaritzburg, which is about 80 km from Durban, in 1981. The moment we stepped off the plane in 1981 I fell in love with Africa. When we moved to Africa, I didn’t have a job and I didn’t have a car so I decided to draw. People that we were staying with said that they were quite good and said I should do them in colour. So I bought a box of pastels and that is where I started. It took me about five years before I did anything which was half decent.\"\nDixon started off doing pastels about 13 years ago and decided to teach himself oil painting because it is a lot easier to manage.\n\"There is no glass and frame to worry about, you can roll them up and overseas people can take them home with them. Also, for people around the world oil painting is taken more seriously than pastels.”\nHe urged artists to keep drawing as it helps them with the basic skills of being an artist. “I also do quite a lot of drawing so for this exhibition I decided to do half and half, half oil paintings and half drawings.”\nHe also enjoys drawing.\n\"I think a lot of artists paint all the time and we don’t always do enough drawing. Drawing teaches you hand eye coordination and it teaches you to see more what you’re doing. I draw mostly from photographs and the photographs are mine.”"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:d2be6d41-839d-40bc-8bff-8f8aa967e90d>"],"error":null}
{"question":"Do both Maryland CPAs and Professional Engineers need ongoing education to maintain their licenses?","answer":"Yes, both professions require continuing education. CPAs in Maryland must complete 80 hours of Continuing Professional Education (CPE) every two years, including 4 hours in professional ethics. For Professional Engineers, 42 states have Continuing Professional Competency (CPC) rules, with a general requirement of 15 professional development hours (PDHs) per year for relicensure.","context":["Having a Professional Engineer’s License (or PE) tells others that you are a competent engineer of high integrity and have high ethical standards. It is important for many chemical engineers right now and could be even more critical in the future as regulations and laws governing the practice of engineering change and as the culture of chemical engineering changes.\nGet perspectives on the PE Exam\nProfessional Engineering FAQ\nWhat is a PE?\nA Professional Engineer (PE) is an engineer that has been licensed by a state. The license symbolizes that the engineer has completed certain training and has demonstrated minimum competency in a field of engineering. The specific training required depends on the specific state where one seeks a licensure. In most cases this currently requires a BS from an ABET accredited engineering program, successful passing of the Fundamentals of Engineering Exam (FE), 4 years of practical experience, and passing the Principles and Practice of Engineering (PE) Exam.\nWhy should I get a PE?\nThere are many reasons to obtain a PE. These include:\n- Your engineering career can extend over 40-50 years and it is almost impossible to predict what you will need many decades in the future. Having a PE gives you maximum flexibility.\n- It is generally much easier to obtain your PE early in your career while technical content is fresh in one’s mind, so why not do it? Plan for your future.\n- In some cases only a PE may attest to certain work products.\n- You may want to be a Private Practitioner (whether now or 20 years in the future). If so, a PE will be required to advertise or offer services to the public.\n- All things considered, having a PE may well make you stand out from those who do not. Obtaining your PE will give you a feeling of real accomplishment.\nWhat is the process to become a PE?\nThe four general requirements for becoming a PE are:\n- Graduation from an accredited engineering curriculum\n- Successful completion of the Fundamentals of Engineering exam (FE)\n- Four years of engineering experience\n- Successful completion of the Principles and Practice of Engineering exam (PE)\nWhat is the exam format?\nThe PE Chemical exam became a computer-based format (CBT) exam in January 2018. The new computer-based PE Chemical exam allows year-round testing at approved Pearson VUE test centers. The only reference material allowed in the new CBT format is the online PE Chemical Reference Handbook. Please see more details at https://ncees.org/engineering/pe/chemical/.\nChemical Reference Handbook and NCEES Access\nThe PE Chemical Reference Handbook is available for download. It contains charts, formulas, tables, and other information that may help you answer questions on the PE Chemical exam. However, it does not contain all information required to answer every question; theories, conversions, formulas, and definitions that examinees are expected to know have not been included. Log into MyNCEES to download your free copy.\nTo report errata in the PE Chemical Reference Handbook, send your corrections or comments using the chat feature on the NCEES website.\nHow do I prepare for the PE exam?\nTake AIChE's Chemical PE Exam Review Course, designed to prep you for the actual exam with online lectures, sample problems with solutions, timed quizzes, and a final exam.\nAlso, The National Council of Examiners for Engineering and Surveying (the organization that administers the exam) offers study materials.\nDo all states have the same requirements?\nMost do—in order to aid reciprocity. However, several vary from the general pattern for local reasons. State-by-state variations are possible, because licensure laws are exclusively under the control of the individual state legislatures.\nWhat if I want to be licensed in several states?\nMost states allow an engineer licensed in one state to become licensed, without further examination, as long as the requirements of the state that originally granted licensure at least equal their minimum standards. The actual process, documentation, requirements, etc. can vary from state to state.\nHow do I find out what my state's requirements for licensure are?\nTo learn more about professional registration and Continuing Professional Competency (CPC) requirements in your state, contact your state's board of licensure. The following web sites have links to each state's board as well as other information on professional licensure.\n- The National Council of Examiners for Engineering & Surveying (NCEES) Visit: http://ncees.org/licensing-boards/\n- The National Society of Professional Engineers (NSPE) Visit: https://www.nspe.org/resources/licensure/licensing-boards\nDo I have to take courses in order to renew my license?\nCurrently, 42 states have CPC rules in effect for relicensure. Each state maintains their own requirements but they all follow the same general pattern—again for reciprocity. The general requirement is 15 professional development hours (PDHs) per year. PDHs can be acquired for several activities, including coursework and attending technical meetings. The NCEES offers a convenient method for logging your hours and comparing with state requirements at https://ncees.org/cpc/.\nDid you know?\nAIChE offers liability insurance for chemical engineering professionals. Reduce your risks, protect your income and assets with a solid E&O Plan. Affordable liability policies are offered to chemical engineers, chemical engineering educators, chemists, and professionals who are AIChE members.\nDiscuss PE Licensure\nHead over to AIChE Engage to ask chemical engineering professionals about their experience with the PE exam prep course and why getting certified is important.\nThe National Council of Examiners for Engineering and Surveying (NCEES) is a nonprofit organization dedicated to advancing professional licensure for engineers and surveyors. AIChE works closely with NCEES so our members can become certified and stay certified.","According to O*Net, a U.S. Department of Labor-sponsored resource, job growth for auditors and experienced accountants in Maryland over the next few years is expected to jump by 10 percent. That’s going to result in an estimated 3,630 job openings per year through 2028, a combination of new job creation and normal turnover for existing positions as the old guard transitions into retirement.\nThese kinds of job growth projections indicate a lot of opportunities for anyone learning how to become a CPA in Maryland in the coming years.\nThose jobs will be opening up at big corporations including Marriott International and Lockheed Martin, two of the Fortune 500 companies that are headquartered here. They’ll also be opening up at the traditional Big Four accounting giants, like KPMG, which has offices in Hyattsville and Baltimore. And there are a healthy crop of smaller regional and local firms scattered across the state too, including Ellin & Tucker in Baltimore and Sigma in Columbia.\nIn fact, in Accounting Today’s list of the 100 Best Accounting Firms to Work For, Maryland figures prominently, with firms like Bormel, Grice & Huyett coming in first in the state and number 16 nationally in 2020. Along the Baltimore Washington Corridor, there is a big demand for talented CPAs, and accounting firms know how to keep them in the ranks with strong starting offers and attractive retention packages.\nLearn how to become an accountant in Maryland in five steps.\n- Get your Education in Maryland\n- Take the Maryland Uniform CPA Exam\n- Take the Uniform CPA Exam in Maryland\n- Get your Maryland CPA License\n- Continuing Education in Maryland\n1. Get Your Education\na. Request information from universities in Maryland offering programs in accounting. The Maryland Board of Public Accountancy requires all certified public accountants to hold a bachelor’s degree or higher with a major in accounting, and a total of 150 semester hours of college credit.\nWith the standard bachelor’s degree in accounting consisting of just 120 semester hours, going on to earn a post-baccalaureate certificate or master’s in accounting represents the most tried and tested way to get those 30 additional credits. Many of these programs are available entirely online. You can also find specialized five-year CPA track programs that offer a blended bachelor’s and master’s curriculum to give you the 150 semester hours you need to meet CPA requirements in Maryland.\nb. If you’re already enrolled in an accounting program or have already earned your degree, confirm that the program is approved by the Maryland Board of Public Accountancy. In Maryland, programs must be accredited by one of the following associations:\n- Association to Advance Collegiate Schools of Business\n- Accreditation Council for Business Schools and Programs\n- Middle States Association of Colleges and Schools\nIf your program is not accredited by one of these entities, it must be evaluated by the Maryland Board of Public Accountancy to see if it fulfills the state’s education requirements so that you can sit for the Uniform CPA Examination. Non-United States school transcripts must be evaluated by the NASBA International Evaluation Service (NIES).\nc. Be sure to enroll in the right classes. In Maryland, the requirements include: the completingon of at least 150 undergraduate semester hours or 225 undergraduate quarter hours, earning a minimum of a bachelor’s degree. Additionally, encompassing: your coursework must include a certain number of hours from each of the following subject groups:\n- Group 1: Accounting and Ethics Education – at least 30 undergraduate semester hours (45 undergraduate quarter hours) must come from this group. Mandatory courses include:\n- 3 semester hours in cost accounting\n- 3 semester hours in auditing, managerial accounting or cost accounting\n- 3 semester hours in U.S. Federal Income Tax\n- 3 semester hours in business ethics or 3 semester hours in accounting ethics or 3 semester hours in philosophy of ethics\n- 9 semester hours in financial accounting\n- 9 semester hours in elective accounting courses\n- Group 2: Business-Related Education – at least 21 undergraduate semester hours (32 quarter credit hours) must come from this group. Courses must be taken in five of these nine subject areas:\n- Computer science/information systems\n- Quantitative methods\n- Business communication\n- U.S. business law\n- Corporation or business finance\n2. Take The Uniform CPA Exam\nOnce you’ve satisfied Maryland’s educational requirements, you’re eligible to sit for the Uniform CPA Exam.\na. Begin the application process online.You will start by completing the Core Course Inventory Worksheet, which you will refer to as you fill out the online application. You will be told what needs to be mailed to the Division of Occupational and Professional Licensing, such as college transcripts and fees, and the address to which to send them.\nb. You will be notified by mail of your approval to sit for the examination. Once you have received a Notification to Schedule from the National Association of State Boards of Accounting (NASBA), visit Prometric’s website to schedule your exam at a Maryland testing site. They include:\nc. Report to the exam site on the day of your examination prepared for testing.\nd. After the exam, NASBA will report your grades to the Board, who will notify you by email that your grades are posted online. Instructions on how to access your grades will also be included.\nFor more information or to request special accommodations, call the Maryland Board of Public Accountancy at (410) 230-6258. For detailed information on the Uniform CPA Exam, click here.\n3. Gain The Necessary Experience\nAfter passing the Uniform CPA Exam, you’ll need to satisfy Maryland’s experiential requirements as the final step to being eligible for licensure.\nBegin the practical experience portion of your licensing requirements. This should consist of paid employment and must be documented and verified by a supervising licensed CPA. Opportunities can be found through your school’s career center. Your employment must meet the following criteria:\n- At least 2000 hours (one full year) of practical accounting-related experience\n- This experience must be verified, endorsed and approved by an active licensed CPA.\n- This experience must occur within three years of applying for your Maryland CPA license.\n- Employment may be within the areas of government, academia, public practice or industry.\n- Services that must be provided by the employer must fall within the areas of attest, financial advisory, management advisory, consulting, or tax.\nCompetencies that should be covered during your practical experience include:\n- Communications and leadership skills\n- Critical thinking and strategic skills\n- Focus on the client, customer and market\n- Interpretation of converging information\n- Technological adeptness\nResponsibilities of the Verifying CPA\n- Must hold an active CPA license\n- Obtain and fill out the applicant’s Report of Practical Work Experience. (Use this form for practical work experience gained within Maryland, and this form for practical work experience gained outside of Maryland)\n- Verify the applicant’s work history and education information\n- Verify the applicant’s description of his or her work under you\n- Provide information on the applicant’s practical work experience, including an assessment of time management skills, the applicant’s performance, and a narrative describing the applicant’s work\n- Mail the Report of Practical Work Experience to the Board in the envelope provided to you by the applicant\nResponsibilities of the Applicant\n- Choose an actively licensed CPA for supervision, endorsement and verification of your practical work experience\n- Complete applicable sections in the Report of Practical Work Experience, including documentation of your duties, a description of duties, and the time involved\n- Provide your Report of Practical Work Experience to the licensed CPA for completion\n- Provide the licensed CPA with a pre-addressed stamped envelope to return the Report of Practical Work Experience to the Maryland Board of Public Accountancy 500 North Calvert Street – Room 308, Baltimore, Maryland 21202-3651\n4. Get Your Maryland CPA License\nNow that you’ve passed the exam and completed the practical work experience requirement, you’re ready for licensure. Here’s a checklist of everything you’ll to have done up to this point:\n- Complete education requirements of 150 undergraduate semester hours. Have your official school transcript sent directly from your school to the CPA Examination Coordinator, Third Floor, 500 N. Calvert St., Baltimore, MD 21202\n- Apply online to take the Uniform CPA Examination.\n- Take and pass the Uniform CPA Examination.\n- Complete 2000 hours (12 months) of Practical Work Experience in accounting under the supervision of a licensed CPA.\n- Submit the Report of Practical Work Experience completed by you and the verifying licensed CPA.\nb. Apply for your Maryland CPA license. The licensing process begins with the Maryland Board of Public Accountancy’s online licensure application.\nInterstate Reciprocal License\n- Option 1: Candidates who hold an active CPA license in another state and have four years of experience in the past 10 years since passing the Uniform CPA exam must submit the Report of Practical Work Experience and all transcripts and exam scores. Apply for your license through the State of Maryland Department of Labor, Licensing and Regulation. The CPA Reciprocal Initial Application can be found here.\n- Option 2: Candidates who hold an active CPA license in another state and have passed the Uniform CPA Exam must complete the Reciprocal Application Course Checklist, have all official school transcripts sent to the Maryland Board of Public Accountancy, and complete and submit a Report of Practical Work Experience. Apply for your license through the State of Maryland Department of Labor, Licensing and Regulation. CPA- Transfer of Grades Application can be found here.\nInternational Reciprocal License\nThe American Institute of Certified Public Accountants (AICPA) along with NASBA has concluded that CPAs or Chartered Accountants from any of the following international jurisdictions is substantially equivalent to requirements for CPA licenses and certificates in United States jurisdictions:\n- Canadian Institute of Chartered Accountants (CICA)\n- Instituto Mexicano De Contadores Publicos (IMCP)\n- Institute of Chartered Accountants in Ireland (ICAI)\n- Institute of Chartered Accountants in Australia (ICAA)\n- New Zealand Institute of Chartered Accountants (NZICA)\n- Hong Kong Institute of Certified Public Accountants (HKICPA)\nThe Maryland Board of Public Accountancy accepts CPAs and chartered accountants credentialed through these six international bodies for international reciprocity. If you are a chartered accountant or CPA from one of these approved international jurisdictions, you must:\n- Request a Letter of Good Standing to be submitted from your country’s credentialing agency to NASBA\n- Apply here to take the International Uniform Certified Public Account Qualification Examination (IQEX). Mail your application and fees to: NASBA, Attn: IQEX Coordinator, P.O. Box 198469, Nashville, TN 3724419-8469.\n- You will receive a Notice to Schedule (NTS) the IQEX by mail or email (whichever method you have previously chosen) and be able to schedule your test via Prometric’s website.\n- Test results will be mailed to you as they are available.\nIf you’re a chartered accountant or CPA from an international jurisdiction not listed here, you must follow the standard process and take the Uniform CPA Exam in Maryland and have your educational credentials evaluated by the NASBA International Evaluation Service (NIES).\n5. Stay Current Through Continuing Professional Education in Maryland\nThe Maryland Board of Public Accountancy requires each licensed CPA in the state to complete continuing professional education (CPE) every two years in order to maintain licensure. Only programs that relate directly to the professional competencies of a CPA qualify for credit. The knowledge gained from the CPE must be useful to the CPA and not redundant.\na. No Continuing Professional Education is required for your first license renewal.\nb. For the second and successive license renewals, 80 hours of CPE are required every two years. Of that 80 hours:\n- 4 hours must be in professional ethics\n- College-credit or self-study courses must include a final examination\n- A maximum of 76 credit hours of CPE may be carried over to the next reporting period if you have exceeded 80 hours in a two-year licensing period (a 4 hour professional ethics course must still be taken during the next licensing period).\nc. Each CPA must maintain CPE records for four years documenting attendance, course outline and instructor\nNow that you’re a CPA in Maryland\nCongratulations! You’ve made it! You’re a licensed, certified public accountant in Maryland! You may want to consider joining the American Institute of CPAs (AICPA), an organization providing professional development and networking opportunities, professional guidance, as well as discounts for members from office supply companies and shipping firms. Other professional CPA societies exist within Maryland that you might want to become a member of include the Maryland Association of CPAs (MACPA) and the MSATP: Maryland Society of Accounting & Tax Professionals.\nConsider specializing! Specializations popular among Maryland CPAs include forensic accounting, information technology, auditing and assurance services, advisory or consulting services, tax, and compliance services."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:9efa0616-b6d2-4de7-adac-036b6a098e29>","<urn:uuid:26f31871-cd0a-431c-b5ba-9de200367259>"],"error":null}
{"question":"need to know about mushroom documentation techniques. how to properly record mushroom findings and what chemical understanding needed?","answer":"Proper mushroom documentation requires both photography and careful record-keeping. As demonstrated by photographer Ron Wolf, this includes maintaining detailed databases of photos, providing clear identifications, and submitting images to scientific databases like CalPhotos.berkeley.edu. Regarding chemical understanding, it's important to know that fungi interact with about twenty essential chemical elements found in nature. These interactions are part of complex stoichiometric reactions that go beyond simple test-tube chemistry, involving various elements like carbon, iron, hydrogen, zinc, oxygen, nitrogen, calcium, potassium, and chlorine, which have been naturally selected through evolution for their roles in biological processes.","context":["Early in our work on each issue of the magazine, we send out a call for photos to more than 400 local photographers and artists. The idea is maybe they have some images on file that fit with stories we have in the next issue. It always feels a bit like a leap of faith. What are the chances that every time we’re going to get great images?\nWell, we seem to have won the gamble again. Our cover photographer, Ron Wolf, sent a package of more than 100 mushroom photos, including the stunning jack-o-lantern mushrooms on our forthcoming October issue cover. (Out in a few weeks! Not a subscriber? Order by September 17 to get the October issue!)\nThe half dozen shots we used are just the tip of the iceberg for Wolf’s mushroom photos: “What I have posted on Flickr is 976 fungi photos. That’s what’s posted publicly,” he says. “In my database, I’ll probably five or six or seven times that. Multiple views and shots I haven’t processed and stuff like that.”\nBut Wolf’s not even a mushroom-specialist: “I fell into fungi through the backdoor. I am primarily a bird photographer, then a wildflower photographer. When I went out on my various forays, there were times when the birds weren’t cooperating, the wildflowers weren’t in bloom.”\nSo Wolf’s reason for photographing mushrooms is the same reason we think mushroom hunting is a great winter pursuit, even in places where it’s illegal to pick and even for those of us (myself included) who wouldn’t know a poisonous mushroom from a supermarket special.\n“What do you do in the middle of winter in California?” Wolf asks. “All the migrant birds are gone except the usual shorebird suspects, and there are no wildflowers out there, so the populations of insects and other pollinators are down. But because of the winter rains in the Santa Cruz Mountains, we get an incredible array of fungi. It’s like the Garden of Eden here. The place just blooms with every kind of mushroom imaginable.”\nHow does he find so many picturesque fungi? A lot of it is simply being outdoors, year after year.\n“I have been around in the woods longer than I care to admit, 55 years or so,” says Wolf, “and I have always been in touch with my inner eight year old. You know at eight the best thing was to get out of school and splash through creeks and find salamanders and climb trees and look into nests and things like that.”\nSo splashing around in creeks and on trails is how Wolf gets his shots, but he says that’s only half the work. The other half is documenting what the photos show and then keeping track of them. His careful records mean he can post clear IDs on his Flickr stream and also submit images to CalPhotos.berkeley.edu, where his photos led to connections with educators as far away as Turkey.\n“There are a lot of people out there who are much much better photographers than I am,” he says, “but somehow or another people find their way to me. It doesn’t matter how good the photo is if someone can’t identify what it is.”\nWhen it comes to cataloging photos, Wolf credits his career as a reporter and editor, including at the San Jose Mercury News: “I have spent a lot of years in a newsroom doing journalism, which is in a sense one big, long detective mystery. Life is a staggeringly large crossword puzzle in which you’re trying to fill in the blanks, which is not all that different from figuring out the taxonomy of species.”\nAnd his favorite mushroom haunt? Portola Redwoods State Park.\n“It’s the one that’s easy for me to pop over to from Palo Alto,” he explains, “but it’s on the road to nowhere, so you don’t take that road unless you’re going to Portola Redwoods. It’s also chronically on the governor’s hit list for closure because it doesn’t generate enough patronage to pay for itself, but it is one of those that gets an astonishing number of species from about mid-December on through the end of March. Great stuff all over the place and if one is an aficionado of fungi, it seems to me that this ought to be a global heritage site.“\nOur cover story is actually focused on the mushrooms of the East Bay Regional Parks, but wherever you hike this winter, keep an eye out for the otherworldly colors and shapes of our local mushrooms. And don’t forget your camera.\nMost recent in Plants and Fungi\nPhytophthora tentaculata, a new and particularly pernicious strain of dangerous plant pathogens that has been on a federal watch list, was found throughout one of the SFPUC's restoration sites in central Alameda County.\nPlants and Fungi","One of the main tenets of the New Age pseudosciences is that we and everything around us are all part of a greater whole, working in concert and connected by a mystical energy or life-force operating with the four classic elements - earth, wind, fire and water. While the idea of a life-force held within the molecules of living things was generally discarded in the nineteenth century when Wohler created urea in his test-tube there is still perhaps some truth in the idea that we are part of a greater whole. That whole to the scientist though is the massive chemical ecosystem of our planet and beyond it the energy source and entropy drain that is our nearest celestial neighbour the Sun. The idea finds its logical conclusion in the Gaia hypothesis in which our planet is viewed more as a superorganism than a collection of individual systems. Even assuming the bare essentials of this concept can lead to some interesting ideas.\nBiologists perceive this world system as being driven by the living things within it perhaps doffing their collective cap only to the molecular on the scale of controls such as DNA and proteins. While chemists often view living things as being driven by the molecules themselves. There is an element of truth in both perspectives where biological evolution proceeds through chemical changes - mutations, deletions and transpositions in the coils of nucleic acid - and living things respond blindly by altering their environment so that only those with chemistry suited to that environment survive intact to perpetuate the story.\nThere is an alternative viewpoint that takes both sides of the story to a more fundamental level. The presence of a mere twenty or so chemical elements and how they interact in ways far more complex than the simple stoichiometric reactions of the average test-tube are available to life and have been since the time of its inception. This underlying physical chemistry has yielded and continues to yield evolutionary diversity but as we upset the balance, evolution may begin to have an unexpected impact.\nThe earth settled down early to an iron core, an oxide, silicate and sulfide mantle, an atmosphere of oxygen and nitrogen, and a thin smear of oxygen dihydride over two thirds of its surface. To reach this state the various other elements underwent a selection process through inorganic phase changes and competition between elements for sites in crystalline materials. Chemical affinities, electronic configurations at the fundamental level forced some elements out of the emerging picture while others were placed in optimum states for further reactions including those involved in life. An unsuitable oxygen affinity and the element was effectively selected out by either becoming locked away in deep rock or boiling off into space leaving behind the twenty or so common ones from which emerging life then chose.\nAs life began to emerge, each of those elements found a place in the chemistry of life and the selection of the elements has been sufficient for all life until now. Each member of the list, which includes, carbon, iron, hydrogen, zinc, oxygen, nitrogen, calcium, potassium, chlorine etc were selected as a particular element found a niche within an organism and fulfilled a role that better equipped the organism for survival and reproduction in its particular environment. Human activity, however, has moved well outside this grouping of elements. We evolved with twenty in our biology but industrialised with those we could render from the rocks. We now even create our own elements in laboratories.\nWe might consider ourselves immune to the effects of evolution - as if technology has overridden the natural selective pressures of our environment - although to know for certain whether we have evolved or not, a complete map of our present genome and that of our ancestors would be needed for comparison. We have though remained stayed pretty much the same since we began recording our history in words, pictures and hypertext.\nThe present pressures we are applying to our environment, however, involve massive adjustments to the balance of the twenty or so elements naturally selected by nature. The effect could be to accelerate our move into a future variant on the human species.\nEven if we manage to redress the imbalance will other environmental effects - emerging viruses for instance - force us down an unsuspected genetic path of change? If we carry on as we are will we pile on the pressure to the point where we begin to select ourselves out? Perhaps those with a gene that provides them with greater protection against pollutants - such as estrogenic compounds with their alleged effects on fertility - will survive the changes. The rest of us might begin to succumb to such toxic effects before we produce offspring and so drop out of the putative evolutionary scheme altogether.\nThe Natural Selection of the Chemical Elements, R J P Williams and J J R Frasto da Silva, Oxford University Press, Oxford, 1996.\nNature's Building Blocks: An A-Z Guide to the Elements, John Emsley, Oxford, April 2002.\nBack to the sciencebase home page\nA wild recipe for hot soil\nby David Bradley\nThe French have always had a penchant for fungi, but one day you may be more likely to find a cep cleaning up after a terrorist bomb or a nuclear accident than being served up in a wild mushroom\nEdible mushrooms might not be the most obvious choice for cleaning up after a nuclear accident or the explosion of a so-called \"dirty\" bomb, a conventional explosive carrying radioactive material. But, French scientists reckon that a wild mushroom might soak up radioactive caesium-137 ions just as easily as it can olive oil. Caesium-137 was released in vast quantities by the explosion at the Chernobyl nuclear power station eleven years ago and could be a major contaminant from a terrorist dirty bomb.\nRemoving metal and radioactive contaminants from exposed land is a crucial task. Aside from the immediate threat to the environment and the health of those living on or near such land, toxic metal ions can be carried into the food chain by vegetation growing on the land. One clean-up solution, known as bioremediation, involves deliberately planting plant species that might absorb the metals from the soil and then harvesting plants for safe disposal.\nWhen it comes to the alkali metal caesium, however, there are no plant species that thrive on soil contaminated with it. So, if not a plant, why not a fungus?\nAnne-Marie Albrecht-Gary and her colleagues at the Louis Pasteur University and the University of Strasbourg think they have found the solution in the unlikely form of the tasty bay boletus, Xerocomus badius. \"Fungi often exhibit a remarkable ability to accumulate a large variety of elements, ranging from the heaviest of the transition metals such as lead or mercury, to the alkali metals, including radioisotopes like caesium-137,\" explains Albrecht-Gary in a recent issue of Chemical Communications. But, she adds, little is known about how these fungi take up such metal ions.\nShe and her colleagues have studied the chemistry of the two pigments that give the inside of the bay boletus cap its bright yellow colour - norbadione A and badione A. These chemicals can act like molecular crab claws grabbing hold of metal ions in a pincer movement known as chelation. The yellow colour of the pigments provided the team with the means to test how well each latches on to metals, such as ceasium. They exploited the pigments' strong absorbtion of ultraviolet wavelengths to record a spectrum of the free pigment molecules and their spectra in the presence of caesium ions are markedly different. UV spectroscopy coupled with chemical analysis revealed that norbadione A in particular can bind to radioactive caesium very strongly. In fact, so strong is the norbadione claw that it can bind two caesium ions, whereas its weaker sibling badione A only has the strength to grip one at a time.\nAlbrecht-Gary and her colleagues believe that norbadione gets its strength from a so-called allosteric effect. When one caesium ion enters the claw, the molecule's chemistry changes slightly so that a second gripping position opens up to accept another caesium, working like a double claw. Badione A, on the other hand has only one possible grip.\nThe researchers believe that norbadione A makes the bay boletus so good at sequestering radioactive caesium ions from the soil in which it grows that it should be the bioremedial agent of choice for removing this hazardous metal from contaminated land. \"Obviously, fungi can be very efficient at accumulating toxic metals and radioelements and constitute an excellent and elegant tool for soil bioremediation,\" says Albrecht-Gary, \"However, the limitation on this very potent application is controlled growing of the mushrooms.\"\nWhile norbadione A will almost certainly have a role in bioremediation, the team has dashed hopes for its medical use in removing toxic metals, such as radioactive caesium-137 cadmium and nickel, from the body. Its grip on other alkali metals, such as the essential minerals sodium and potassium is just too strong.\nOf, course one problem remains: what to do with the radioactive fungi…one can hardly cook them in an omelet."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:d59fdc02-d2e1-450a-94d2-94eaa64f130f>","<urn:uuid:75b22a1f-0b92-45e6-a6ec-ced17c421a24>"],"error":null}
{"question":"Which sea-routes más antiguos: the early British settlers' routes to Chesapeake Bay or the Asian wanderers' explorations of Pacific islands?","answer":"The Asian wanderers' explorations of the Pacific islands predate the British settlers' routes to Chesapeake Bay. The Pacific islands were inhabited by Asian wanderers who explored vast distances in archaic boats early on, while the British settlements around Chesapeake Bay like Jamestown and St. Mary's City were among the first European settlements in North America, coming much later.","context":["Difference between revisions of \"Chesapeake Bay\"\nRevision as of 16:37, 11 September 2008\nThe \"Great Shellfish Bay,\" as it was known to Algonquins, is the largest estuary in the United States, at a full 200 miles long, and as wide as 30 miles. A good 10,000 years ago, this region was a valley lying along the Susquehanna River on its way to the Atlantic, but was flooded as the end of the last ice age led to rising oceans.\nThe Bay is one of the most naturally productive bodies of water in the world, in terms of aquatic life, because of its brackish salt-freshwater mix, and its shallow depth. The average depth of the bay is a mere 30 feet! These attributes combined to make the Bay an extraordinarily attractive for fishing, especially for shellfish like blue crabs, oysters, and mussels. Given the nature of the Bay, a famous Japanese fish farmer once boasted that, were the U.S. government to hand the Bay over to him, he could feed the entire world from farming just the Chesapeake alone.\nGiven its extraordinary productivity, the Bay has throughout its human history always been a major population center in the region. Before European settlers arrived, the shores were populated by Algonquian tribes, such as the Powhatan, Conoy, and Nanticok, as well as the Iroquoian Susquehanna in the north. Early British settlers gravitated towards the Bay for much the same reasons of easy fishing, and the communities surrounding the Bay such as Jamestown and St. Mary's City are some of the oldest European settlements in North America.\nToday, however, the Great Shellfish Bay has been in a state of long-term decline for decades. Over fishing has been a problem, but may not have been possible if it were not for pollution. The Bay is plagued by agricultural and residential run-off of fertilizers into the Bay's tributaries, which causes enormous algae growth, which in turn chokes off the natural plant life of the bay upon which the fish rely for food. Environmental reforms have been enacted to protect the Bay (most strictly in Maryland, where the Save the Bay movement originated) but they differ state-to-state, and the tributaries of the Bay run through six states, making coordination difficult. This all has been a disaster for the fishing communities (especially the small island communities) around the Bay, who relied on hauls for almost their entire livelihood. Fishing is now tightly regulated, and the regulations have a good deal of support even from the fishermen, who realize that their way of life is threatened by the diminishing fish stocks.\nFlora & fauna\nIf travelling from far away, the best way to get in is probably BWI Airport. It is close to the major ports of Baltimore and Annapolis. BWI Airport is served by many major airlines and passenger rail service via Amtrak.\nThe best way to access the sights mentioned in this article is to use a boat. Getting access to a boat is sometimes a bit tricky, but here are some suggestions:\nSome people prefer boats powered by the wind, others prefer those powered by motors.\nIf you are using the aforementioned wheeled conveyance to visit these sights, there are a fine collection of roads, but only three crossing points in the 120 mile length of the bay. This makes some itineraries inconvenient.","About one third’s of earth’s surface is covered by the deepest and largest ocean, the Pacific Ocean, covering 1181,300,000 sq. km. The Pacific Ocean’s southern part is known by the name of the South Sea. The Pacific Ocean derives its name from the Latin Tepre Pacificum, meaning “peaceful sea”, bequeathed to it by the Portuguese traveler and explorer, Ferdinand Magellan.\nThe Pacific Ocean’s floor has a depth of 4,300m average and is mostly a deep-sea plain. The maximum known depth of 10,911.5m is located in the Challenger Deep. The ocean is characterized by the plains rising into volcanic swells, guyots and seamounts.\nExplorers and Settlers through the Pacific\nThe explorer from Spain, Ferdinand Magellan, when he came across this vast sheet of water during his voyages named it as the Pacific Ocean.\nThe islands situated in the south and west of the Pacific were inhabited by Asian wanderers who explored the seas, crossing huge distances in the open ocean, in archaic boats. Marco Polo and other European explorers had hinted its existence around late 15th Century; commercial traders sailed around Africa to the ocean’s western edge, though the first distinguishing recognition of the Pacific, distinct from Atlantic Ocean came only when Balbao sighted the Ocean’s eastern shore in 1513.\nIn 1520-21 Spanish explorer, Magellan crossed the Philippines initiated a chain of explorations, which included huge areas, from Bering to Vancouver. By the end of 18th century, he had discovered the major coastlines. It was the Spanish and Portuguese who dominated the Pacific Ocean in 16th Century, and by the 17th English and Dutchmen took over, and in 18th Century the Japanese and Germans sailed through the Pacific Ocean, establishing their supremacy, while it was only in the 19th Century the American whalers and Sealers sailed towards the Pacific Ocean. The Yankee explorers entered the Pacific trades in the late 18th Century and early 19th Century.\n14,500 km Pacific Coverage Area\nThe Pacific Ocean covers a huge area, extending from the Arctic to Antarctic expanse between South and North America on the eastern side, while on the west, Australia and Asia. It is in the Pacific Ocean the International Date Line passes through. Bering Strait connects the Pacific to the Arctic Ocean, and the Drake Passage links it with Atlantic Ocean, as also the Magellan Strait and the Panama Canal; Malay Archipelago connects it with the Indian Ocean, through its passages between Antarctica and Australia.\nThe coastline from deep seafloor rises into the heights of mountains on land, along the eastern shore of the Pacific Ocean, along with a narrow continental shelf. Comparatively the Asian coastline of the Pacific Ocean is low, indented and on the fringes of which islands rise through a wide continental shelf. There are volcanic series, the Circum-Pacific Ring of Fire, edging the basin of the Pacific Ocean.\nPacific Ocean Ocean’s Currents\nIn the Pacific Ocean, major oceans currents form huge whirls, which are found near the southern and northern equator, separated by the Equatorial Counter Currents. The Pacific Ocean has a number of feeder currents which constantly circulate the waters of ocean, giving them varying temperature and saline profiles.\nShipping and Trade\nThe main commercial fishing centers are located in the continental shelf’s shallow waters, where the main catch are halibut, salmon, sardines, herring, and tuna. Many transpacific sea-lanes go through the Islands of Hawaii, while the chief ports in the Pacific Ocean are brisk trading centers. Most of the islands located are important tourism centers."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:a2299b2a-ab93-4a3c-b8dc-a15195c5dc42>","<urn:uuid:47e22963-6e21-4c92-a022-4d3c6520d15f>"],"error":null}
{"question":"Compare safety risks of damaged springs in washing machines versus garage door torsion springs during repair work.","answer":"Damaged springs in washing machines primarily pose risks of internal damage to the washer, especially during high-RPM spin cycles. In contrast, garage door torsion springs present significantly more dangerous safety risks during repair - they can cause life-threatening injuries or loss of fingers if they snap due to the high tension. This is why garage door spring repairs often require professional expertise, while washing machine spring issues, though requiring attention, don't carry the same level of personal injury risk.","context":["In order to balance the washtub, there are suspension springs installed around.\nIf these springs have been worn out or damaged then you may consider fixing them and If they go bad they are most often replaced.\nThese springs are also known as suspension springs, tub springs, or counterweight springs.\nIf the spring is broken then you may notice that your washtub is tilted towards one side.\nA worn-out spring may result in loud noise from the washer during a wash cycle.\nUsing your washer with a damaged or worn-out spring for a prolonged period of time may cause internal damage. The major damage may occur during the spin cycle because of the high RPM.\nLet’s take a quick look at the Causes of Worn-out OR damaged washing machine springs and solutions.\nCauses of Worn-out Washing Machine Springs & Preventive measures\nOne of the primary factors that cause the washing machine springs to wear out is aging. As your washer ages, the constant wear and tear amplify the damage. Having said that it is not the only factor that causes the springs to wear out.\nHere are some key factors responsible for worn-out or damaged washing machine springs.\nAge of the washer\nUnlike other components of the washer, the washtub springs may need a replacement after specific years of usage.\nThe common problem associated with an aging washer is rusting and springs are no exception.\nOver time, springs may get affected by rusting issues, thereby losing their strength. This eventually leads to a broken spring.\nSince these springs are designed to hold a specific amount of weight, Overloading them may loosen them.\nIt’s recommended not to overload the washtub as it puts a lot of stress on the washing machine suspension system.\nWith repeated abuse by overloading the washer, the spring may lose its effectiveness and this is where you may notice that the inside part is tilting towards one side.\nFabrics loaded in an uneven manner may lead to putting immense pressure on either side of the washtub.\nThis results in an imbalanced washtub and impacts the washtub during the wash cycle, especially during a spin cycle.\nThe springs are connected from both ends, and if these connecting hooks or components have been damaged then it may result in worn-out OR damaged springs.\nWhile it is rare, rusting caused by aging can certainly wear out the connecting hooks.\nIf the washer is placed on a surface that is tilting towards one side, then there is a possibility of springs being impacted by the stress.\nAn uneven surface not only impacts the springs but also puts a lot of stress on other internal components.\nWashing Machine Stand\nWashing machine stands usually have four tiny supporting legs or wheels attached.\nStands are placed in order to move a washer with ease and also help protect the base surface of the washer.\nIf the washing machine stand has worn out OR if it has lost its alignment, then it may cause the washer to tilt slightly which may not be noticeable right away.\nIf this is not addressed, over time with constant stress on the suspension system the springs will certainly wear out.\nNow that you know the common causes of washing machine springs wearing out, let’s take a quick look at the solution.\n- While loading the laundry, always keep the capacity of your washer in mind. Loading a laundry size a little bit less than your washer’s capacity can not only optimize the performance of your washer but also prolong the lifespan of the suspension system.\n- While running a wash cycle, always remember to load the fabrics evenly. The uneven load will cause the washer to vibrate and may impact the suspension system.\n- Replace or fix the connecting ends of the springs if damaged or worn out, in order to prevent further damage to the springs.\n- Always place the washer on a plain surface to avoid any damage caused to the balancing components including the spring.\n- If your washer looks tilted due to a damaged stand then simply replace it with a strong and suitable washing machine stand.\nWith worn-out springs one can’t do much as replacement is the only option.\nRepairing it won’t make sense simply due to the cost-benefit factor.\nOverloading and Aging are the two common factors that damage the internal components of the washer.\nThis can surely be avoided by loading an even laundry load.\nAlways avoid using the washer if you notice any unusual behavior during the wash cycle. Quickly stop the cycle and get the cause diagnosed and fixed.\nFrequently asked questions\nHere are some common questions related to washing machine springs.\nWhy is my washing machine dancing?\nExcessive vibration caused by damaged or worn-out internal components may give you the impression that your washer is dancing. Having said that excess vibration is not normal and needs your attention.\nYou can get rid of excess vibration by following simple tips such as:\n1.) Putting even load inside the washer.\n2.) By placing the washer on an even surface.\n3.) By not overloading the washer.\n4.) By using only the desired quantity of detergent.\nCan you fix an unbalanced washer?\nYes, depending on the cause you can fix an unbalanced washer. Causes such as overloading, uneven loading, etc. can be quickly fixed by simply adjusting the load. Other causes such as worn-out washtub belts, springs, bearings, etc. may require special expertise to fix OR replace the damaged components.","Replacing Garage door Torsion Springs – Safety precautions\nReplacing torsion springs is a dangerous affair. This is because the springs are under a lot of tension and if it snaps you can lose your fingers or your life. If you have not any experience with torsion springs, it would be wise to get a professional to fix it for you. Before you embark on any repairs ensure that you take safety precautions first.\nHow torsion does springs work?\nTorsion springs use mechanical energy physics to operate. Energy is stored when the springs are tightened and twisted. They operate by winding up to move the garage door down and are mounted at the top of the garage door. When you want to open the garage door, then springs will unwind and enable the cables to lift the heavy door. With time, the springs will wear out and be in need of repair. If the spring snaps then it cause life-threatening injuries.\nTorsion springs tend to have a lifespan of between 5 to 7 years. This will give you about 1,000 cycles assuming you close your garage door 3 to 5 times a day.\nWear safety glasses and avoid standing on loose chairs or stools; use a ladder instead. You can avoid injuries by clutching the bars firmly and holding the end that is farthest from the plugs. At all times assume that the springs will break; this keeps you alert.\nTo avoid ripping your flesh or wrapping your clothes on the spring keep your hands away from the plugs. This is because if the winding bar slips off the plug your hand may jerk up and rip your flesh. Always keep your head off the path of the winding plug.\nBe aware when using old winding cones, especially those made for 5/8″ bars; you will discover that the holes are too small. When doing repairs do not use ½” bar but try to grind down the cone to fit; the potential for injuries with the ½” bar is very high.\nMost of the extension springs have cables that act as a backup in case the torsion springs break. But to fix the springs, you will need first to disconnect the cables which are again dangerous. The cables can snap it the springs have rust and are worn out. The other problem is having the unsupported doorframe falling on you.\nWhen you are replacing worn out torsion springs always replace both springs. Avoid buying used spare parts because it can be difficult to estimate the life cycle. When you have a new and old spring operating, then you will experience uneven wear on your garage door repair. It is more dangerous due to the excess tension on the old spring.\nYou will know that your springs need replacement when the garage door opens slowly, or it will not open from a closed position. Also if you have problems with your opener or there is a loud bang before door stops functioning.\nReplacing torsion springs can be very dangerous when you decide to do it yourself. Injuries are life-threatening and it is recommended to talk to a professional before trying it yourself."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:e2466859-f1e0-42fd-8149-5aa131a47a31>","<urn:uuid:b549c115-81b5-44ec-8e85-da56fa2aeb99>"],"error":null}
{"question":"Are microplastics affecting both pristine and urban marine environments today?","answer":"Yes, microplastics are affecting both pristine and urban marine environments. Even supposedly pristine areas like the federally protected White Salmon River have been found to contain microplastics, though in small quantities (3 particles per cubic meter). Urban coastal areas, such as those in British Columbia, show much higher contamination levels of up to 3,200 microplastics per cubic meter. The School of Marine Studies has also found microplastics present in all near-shore water samples from around Fiji, demonstrating that this is a widespread issue affecting various marine environments regardless of their proximity to urban centers.","context":["Marine Pollution and Toxicology\nMission and Research Lines\nOur oceans and aquatic resources are endangered due to pollution, mainly from human action, and sources of pollution are very diverse as well as its effects.\nAt the School of Marine Studies we are working mainly on establishing baseline data for the presence of chemical pollutants such as metals, oil and nutrients and associated biological effects in aquatic organisms (so called biomarkers). Marine plastics are also an area of research mainly the presence of microplastics. The data will be useful for future monitoring programs and environmental risk evaluation.\nThe effects of these pollutants (biomarkers) are being studied in aquatic organisms (bioindicators) to understand the mode of action of these pollutants and their negative impact to the wellbeing of these organisms and how these organisms deal with the exposure to these pollutants.\nIn more detail, our research focus in three main lines: 1) establishment and validation of biomarkers and bioindicator species as early warning tools for the presence of classical and emerging contaminants, in estuarine and coastal environments, 2) study the regulation and functioning of detoxification processes in fish species and to evaluate the potential of emergent contaminants to modulate them, and 3) assessment for the presence of microplastics in marine ecosystems and potential effects to the biota.\n● Assessment of damage caused to the aquatic ecosystem from the sewage spillage in the Cunningham River\nSewage spillages are among the major contributors to aquatic pollution in estuaries and coastal areas. Raw human wastewater contain a mixture of contaminants, that include high concentrations of organic compounds such as carbon, nitrogen and phosphorous. Biodegradation of the sewage organics result in the production of inorganic nutrients (such as nitrate and ortho-phosphorous) which lead to eutrophication of the aquatic environment. Eutrophication is a known consequence of sewages discharges that seriously impacts the health and development of most organisms inhabiting any aquatic environment. Sewage also contains heavy metals and these can bio-accumulate in fish and shellfish making them unhealthy and unsafe for consumption. On December 6 2014, strong winds and floodwaters severely impacted the Central Division of Fiji causing flash floods in low lying areas of Suva. As a result of the heavy downpour and strong winds, the major Suva-Kinoya sewer line located across the Cunningham River at the 4 miles bridge collapsed, sending about 200 litres per second of raw sewage into Cunningham Creek, through Samabula River and into Laucala Bay. This environmental disaster holds severe repercussions for different habitats and in particular for coral reefs and the fauna assemblages that inhabit them as well as the benthic in-fauna inhabiting estuaries and embayments. This investigation will therefore be centred on assessing the immediate and medium term consequences of the sewage spillage over Laucala Bay. The aquatic ecology scope of the work will constitute the bulk of the study by monitoring likely agents of impact of the wastewater discharge on the aquatic ecology and biomarkers in different organism with different levels of complexity.\n● Identification of sentinel species and biomarkers for monitoring Polycyclic Aromatic Hydrocarbons (PAHs), metals and microplastics in Suva coastal area.\nProtecting marine ecosystems is of crucial importance, especially in Pacific Island countries, because they are extremely dependent on marine resources for food (both subsistence and export), and other economically relevant activities, such as tourism. However, ubiquitous pollutants such as oil, metals and plastics can compromise the marine environment and ultimately the quality of seafood for human consumption. It is therefore critical to monitor oil, metals and plastic pollution in coastal waters and to identify early warning signs of stress due to the human health risks associated with oils, metals and plastic contamination. Biological changes in sentinel species are considered early warning signs, and therefore can be used for risk assessment and evaluation. Measuring the levels of pollutants in fish tissues provides valuable information about human exposure to contaminants that are accumulated in fish tissues. Pollutants can also decrease the nutritional quality of the food. The goal of this project is therefore to perform a first assessment for the presence of oil related pollutants, metals and plastics in Suva area and correlated biological effects in fish species. In addition, it will allow for test and identification of sentinel species and biomarkers to be used in future monitoring programmes in Fiji and in USP member countries. Moreover, the project will attempt to evaluate tourism impact on pollution and pollution impact on tourism and recreational activities.\nResearch Team and Projects\nPrincipal Researcher, Associate Professor\nDeputy Head of School for Learning and Teaching\nRufino Robert Varea\nPhD Title: “Applying biomarkers for monitoring the effects of pollution in the marine environment in Pacific Island Countries”.\nPollution in the marine environment is a cause for concern, as the ocean is the largest natural resource for Pacific Island Countries, and we are heavily reliant on marine resources for livelihood security. Over the years, human activity has threatened the natural order and sustainability of our oceans resources. Now we have reached a pivot point ─ to continue with our old ways and risk jeopardizing the natural state of our greatest resource, or change the way we do things and figure out how to better our actions for the sake of the environment. One approach to changing for the better is the application of biomarkers on marine sentinel organisms (vertebrate and invertebrate species) to monitor the effects of pollution and detect early warning signs of organismal health deterioration. The purpose of my PhD study is to use biomarkers to identify problems at early stages in the health of the organism and propose ways to mitigate the issue before it reaches stages that threaten the population of that organism, the resident communities, and/or the entire ecosystem. The process is called biomonitoring and this research is to set baseline data for Fiji and Pacific Island Countries.\nRufino obtained a degree in Environmental Studies in 2016 with the School of Geography, Earth Science, and Environment in the Faculty of Science Technology and Environment at the University of the South Pacific. In the same year, he pursued his postgraduate diploma in Environmental Studies before upgrading to a Master’s of Science in Marine Science with the School of Marine Studies. In 2018, Rufino made the decision to take his master’s research further into a PhD and was awarded a doctoral candidature after a vetting process of his proposal by local and international reviewers. Rufino is a passionate advocate for a pollution-conscious Pacific.\nVeitayaki J., Waqalevu V., Varea R., Rollings N. (2017) Mangroves in Small Island Development States in the Pacific: An Overview of a Highly Important and Seriously Threatened Resource. In: DasGupta R., Shaw R. (eds) Participatory Mangrove Management in a Changing Climate. Disaster Risk Reduction (Methods, Approaches and Practices). Springer, Tokyo.\nPhD Title : “The transport and origin of marine plastic pollution on the foreshores of Fiji islands”.\nPlastic pollution in the ocean has become a recognized problem world wide and Fiji is no exception. The devastation that macro and micro plastics bring to marine organisms across all trophic levels has been well documented and urgent actions are required to save the marine ecosystem. Identifying the main sources of plastic pollution in Fiji will assist the Fijian government and environmental policy makers to manage the pollution. We predict that majority of the plastic washed up on the beaches of Fiji is generated locally and carried by the rivers into the ocean. To prove this the macro plastic debris will be collected, characterized and analyzed from multiple beaches of Viti Levu (including Suva) that are affected by the river outflow. This will be compared to a multiple sites carefully selected on the smaller Fiji islands distant from the rivers. We will use multiple beach transects and quadrats for plastic debris collection. We predict that the majority of the macro plastic pollution washed up on Fiji foreshore is carried by the river transport as opposed to the ocean transport. Rivers have been identified as main transport for global marine plastic pollution (Schmidt et al 2017) but this will be a first study carried out in the Pacific Islands.\nMAppSc, Marine Biology, James Cook University, Townsville, Australia\nMAppSc, Physics/Electronics Engineering, Kiev Polytechnic University, Ukraine\nBondarenko, Olga; Kininmonth, Stuart; Kingsford, Michael “Deployment of wireless sensor network to study oceanography of coral reefs”, 2010, International Journal On Advances in Networks and Services, vol 3, no 1\nBondarenko, Olga; Kininmonth, Stuart; Kingsford, Michael “Underwater Sensor Networks, Oceanography and Plankton Assemblages”, 2007, In Proceedings for ISSNIP 2007, Melbourne, Australia\nBondarenko, Olga; Kininmonth, Stuart; Kingsford, Michael “Coral Reef Sensor Network Deployment for Collecting Real Time 3-D Temperature Data with Correlation to Plankton Assemblages”. In Proceedings for SENSORCOMM 2007, Valencia, Spain\nContact: email : firstname.lastname@example.org, ph +679 904 9599\nMSc Title: “Mangrove health assessment in relation to macroplastic and microplastic concentrations within and outside mangrove forests”\nMicroplastics are plastic particles which are less than 5 mm either by design (primary microplastics) or formed when larger plastics undergo processes such as the hydrodynamic processes that break them into microplastics (secondary microplastics) and are further distributed the world over via ocean currents (Claessens, Van Cauwenberghe, Vandegehuchte, & Janssen, 2013). Mangrove ecosystems are seen to entrap plastic litter, bags, straws and bottles (to name the least), within their tree surface and dynamic root areas. Hydrodynamic processes that occur within the mangrove ecosystems break these larger plastics down into microplastics (Claessens et al., 2013). Lugworms, amphipods and barnacles are a few organisms that have been proven to ingest microplastics (do Sul, Costa, Silva-Cavalcanti, & Araújo, 2014). Since plastics are common in the oceans due to its wide distribution, many organisms are exposed to this pollutant.\nThis project will assess the concentration of macroplastics and microplastics found in the sediments collected within mangrove root ecosystems, as compared to that of the open coastal areas (mudflats without mangroves) in Navakavu and along the Nasese seawall. The overall health of the mangrove plants trapping these plastics will then be assessed to find out whether or not the entrapment of plastics can be affecting the health of mangrove ecosystems. Additionally, sampling will be done during the wet and dry seasons to compare the amount of plastics that are potentially washed down from rivers in the wet season. At the end of this experiment, the project is expected to highlight the importance of maintaining our mangrove forests to entrap litter which could easily be cleaned when washed up ashore rather than when they’re floating around out at sea.\nClaessens, M., Van Cauwenberghe, L., Vandegehuchte, M. B., & Janssen, C. R. J. M. p. b. (2013). New techniques for the detection of microplastics in sediments and field collected organisms. Marine Pollution Bulletin, 70(1-2), 227-233.\ndo Sul, J. A. I., Costa, M. F., Silva-Cavalcanti, J. S., & Araújo, M. C. B. J. M. p. b. (2014). Plastic debris retention and exportation by a mangrove forest patch. Marine Pollution Bulletin, 78(1-2), 252-257.\nBSc, Marine Science, The University of the South Pacific, Suva, Fiji\nPGDSc, Marine Science, The University of the South Pacific, Suva, Fiji\nContact: email: email@example.com or firstname.lastname@example.org, ph: (+679) 9067883\nMSc Title: The Abundance and Distribution of Microplastics in Surface Waters Around Fiji.\nThe conditions in the Pacific coastal waters and oceans are in decline mainly due to increasing levels of land-based pollution, coastal development and habitat destruction. Global plastic production has increased twenty-fold in the past half century and is expected to double again the next 20 years, by the year 2050 it is expected that there will be more plastic than fish in the oceans, a large percentage of this would be microplastics (MPs). MPs are tiny plastics fragments used to add scrubbing grit in cosmetics and air-blasting and more commonly the product of the breakdown of larger plastics. An emergent body of research on the ecotoxicological effects of MPs has unanimously yielded negative responses to all levels biota. Aside from the inherent risks of ingesting MPs, toxic responses are also the result of both the leaching of chemicals found in MPs and the presence of foreign pollutants which are found at high concentrations adhering to the surface of MPs. A particular concern is the effect of plastics on coral reefs whereby a likelihood of disease increases from 4% to 89% when in contact with plastic. Currently, research being conducted at the University of the South Pacific School of Marine Studies has shown the presence of MPs in all near-shore water samples from around Fiji (n=50). There have been no studies previously done on MPs in Fiji waters and consequently the quantity of MPs which originate from Fiji as well as the amount which is brought in from other places by the South Pacific gyre is not known. High levels of MPs in the marine environment will impact significantly on the health and vitality of marine resources and marine ecosystem services. Pacific islanders who depend heavily on the marine environment are expected to be disproportionately affected by plastic waste, most of which will be sourced from highly populous developed and to an increasing extent, developing countries. The objective of this study is to provide a first assessment on the amount of MPs present in surface waters around Fiji. The completion of the study will provide valuable insight into the levels of MPs found in surface waters around Fiji and consequently the degree to which the Fiji marine environment is inundated with MPs of foreign origins. The research will aid in establishing baseline data on the levels of MPs which will be the key in developing long term monitoring programs to detect environmental changes and evaluating the effectiveness of management actions related to plastic pollution control.\nBSc, Marine Science, The University of the South Pacific, Suva, Fiji\nPGDSc, Marine Science, The University of the South Pacific, Suva, Fiji\nContact: email: email@example.com or firstname.lastname@example.org, ph: (+679) 8335274\nMSc Title: “Life history characteristics and polycyclic aromatic hydrocarbon exposure in coral reef fish species Naso lituratus (Forster, 1801) in Fiji waters.”\nThe Pacific Island Countries and Territories (PICTs) depend heavily on marine fisheries resources as a source of protein and income. Fiji, as part of PICTs, is known to have majority of its human population relying on in-shore marine fisheries for subsistence and economic needs. With prediction that human population will be rising, food security in PICTs is under threat as fish stocks are decreasing. Marine fisheries management strategies are constantly evolving to ensure exploitation of marine resources are sustainable. Such strategies involve seasonal bans, marine protected areas, gear restrictions and size-catch limits. In PICTs, size-catch limits are often overestimated or underestimated as these are restricted to family instead of being species specific. Indeed, according to the Fisheries Act [Cap 158], size-catch limits are placed under the entire family level, however species under each family may reach maturity at different size. The problem with finding better marine management strategies is the massive research gap in coral reef fish species biological data. Therefore, as a pilot study, this master’s thesis will be looking into finding the key fisheries biological information for Naso lituratus. This key information includes the size-at-maturity, age-at-maturity, batch fecundity and diet according to sizes. These will be used to evaluate the effectiveness of current management strategies and to improve the species’ marine fisheries management, in particular by identification of a minimum catch-size. While rapid human population growth poses a threat to food security, there is also an increase in pollution that affects the environment as well as the fish that human consume. This study will also assess the presence and eventually the level of exposure that the species have to polycyclic aromatic hydrocarbons.\nBSc, Environmental Science, The University of the South Pacific, Suva, Fiji\nPGDipSC, Geography, The University of the South Pacific, Suva, Fiji\nContact: email: email@example.com; phone:(+679) 8335274\nMSc Title: Evaluation of trophic level transfer of microplastic from Mytilus Spp (Mussels) to Trachinotus blochii (Snubnose dart)\nThe project chosen looks at the trophic level transfer of microplastics based on a predation relationship between two nearshore species. The species being studied are the Snubnose dart (Trachninotus blochii) which is the predator and the mussels (Mytilus spp) which are the prey located along the Marine campus rock jetty. The two species are chosen as the mussels are one of the most susceptible to microplastic exposure being filter feeders and the Snubnose dart is a specialized feeder on hardbodies organisms. Hence the project will look at microplastics within the organisms and try and establish a relationship between microplastics within mussels and their contribution to microplastics in dependent feeders such as the Snubnose dart.\nPGDip Environmental Management, University of the South Pacific, Suva, Fiji\nBA Environmental Studies, University of the South Pacific, Suva, Fiji\nPh +679 9575993\nEduardo Estevan Barrientos\nMSc thesis: Presence and abundance of microplastics in bivalve Batissa violacea in Viti Levu Island, Fiji: A preliminary study.\nMSC Thesis: Abundance of Microplastics in water column, sediments and fish guts in Fijis coastal environment.\nLinks to the individual page at SMS page","RACINE, Wis., July 22, 2019 – SC Johnson today announced evidence of microplastics in a federally protected waterway in south central Washington, raising broader concerns that even preserved environments are susceptible to the plastic waste crisis. In a study funded by SC Johnson in conjunction with the Ocean Wise Conservation Association (Ocean Wise), findings reveal the White Salmon River contains small quantities of microplastics, small microscopic pieces of plastic that are turning up in waterways from Monterey Bay to the deep ocean.\n“I’ve always been intensely connected to nature, which is why I’m disappointed that even small quantities of microplastics were found in this pristine river,” said Fisk Johnson, Chairman and CEO of SC Johnson, during a recent visit to the White Salmon River. “The fact that microplastics were found here speaks to the need for all of us to work hard to tackle this critical issue.”\nOcean Wise examined 1,000 liters of near-surface water at one location of the river. A total of three microplastics were discovered in one cubic meter of a single sample, which included one polyethylene film and two polyethylene fragments. The small quantity of microplastics found is typical of that seen in remote oceans or unpolluted coastal areas, while surface waters near urbanized areas like British Columbia, Canada, can contain up to 3,200 microplastics per cubic meter, according to Ocean Wise.\n“Microplastics can now be found everywhere, highlighting our inadvertent contamination of waterways around the world,” said Dr. Peter S. Ross, Vice-President of Research at Ocean Wise. “The challenge we face is to translate this ‘bad news’ into ‘good news’ by providing meaningful research that identifies these microplastic particles, leads us back to the source, and enables solution-oriented changes.”\nConsidering the White Salmon River and many similar rivers connect to the Columbia River, the region’s largest waterway emptying into the Pacific Ocean, these findings indicate one of the many ways plastic particles get into to our oceans, but to a far lesser degree than the eight Asian rivers and two African rivers that contribute to the bulk of the problem1.\nAs a global consumer product company that relies on plastics to package many of its products, SC Johnson is assessing how harmful plastic waste disrupts natural ecosystems and poses a global risk. The company has partnered with Plastic Bank and the Ellen MacArthur Foundation to help reduce the flow of plastics into our oceans. Further efforts to keep environments clean include subjecting product ingredients to strict aquatic toxicity standards, outlined by the company’s rigorous GreenlistTM ingredient selection program.\nMicroplastics are small pieces of plastic no more than five millimeters in length2 , though they are a growing concern among scientists who are just beginning to comprehend their abundance in our waterways and throughout all levels of marine food webs3 . In fact, an Ocean Wise study found the particles in at least two key species of zooplankton in the northeast Pacific Ocean4 , species at the base of the food chain, indicating possible contamination among larger predators. New research also suggests corals, vulnerable animals facing worldwide decline, may also be heavily impacted by microplastics’ ubiquity.\nOcean Wise is a not-for-profit organization whose vision is a world in which oceans are healthy and flourishing. www.ocean.org\n1Export of Plastic Debris by Rivers into the Sea\n2What are microplastics?\n3The vertical distribution and biological transport of marine microplastics across the epipelagic and mesopelagic water column\n4Ingestion of Microplastics by Zooplankton in the Northeast Pacific Ocean"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:2db0acb3-b278-4b0d-9598-d81ee36cbfcd>","<urn:uuid:9800ab0e-0a09-43d0-ad38-9e3441267e19>"],"error":null}
{"question":"How do the physical challenges faced by competitors compare between the Blenheim Indoor Arena World Cup Grand Prix and the Mongol Derby across Mongolia?","answer":"The Blenheim World Cup Grand Prix challenged riders with a technical indoor course featuring 13 obstacles including a demanding triple combination, with only 82 seconds to complete it. In contrast, the Mongol Derby presented far more extreme physical challenges across 1000km, with riders facing semi-wild horses, potential injuries from falls and bucking, severe illness, dehydration, heat exhaustion, and the need to navigate across the Mongolian steppe. The Mongol Derby's intensity is evidenced by its 50% withdrawal rate, while the Blenheim competition, though technically demanding, was contained within a controlled arena setting with significantly fewer physical risks.","context":["The Blenheim Indoor Arena was bursting at its seams this evening during the $50,000 Blenheim World Cup Grand Prix, presented by Summit General Insurance Agency. Equestrian fans of all ages got to witness the veteran rider Rusty Stewart and his incredible 10-year-old mount Bristol ride a perfect round and win his second consecutive World Cup Qualifier Grand Prix. The pair has been on a roll all season but it takes the perfect pair to stay on their game and post back-to-back World Cup Qualifier victories. Stewart knew Bristol was just as good indoors and could without question perform just as well. Stewart was right on the money.\n\"I said it would be big,\"course designer Guilherme Jorge confirmed before the class got underway, \"but that's the point. It's a World Cup Qualifier.\" Riders were asked to pilot their horses through a very technical course that included a 1.55M vertical-vertical combination, a 1.60M wall, and a very wide triple bar and only 82 seconds to clear it in. The nail biter was the triple combination that had riders set up for an oxer with two strides to another oxer then quickly adjust in one stride to a vertical. The crowd cheered ecstatically for each rider that was able to make it through the combination without fault.\nNicole Shahinian-Simpson and her young stallion Imothep were the first pair to clear all thirteen obstacles, but with caution comes time faults. Shahinian-Simpson set the standard with one time fault in 84.48 seconds. Nineteen year old Lucy Davis and her thirteen-year-old Holsteiner Nemo 119 had one unfortunate rail early in the course but kicked it into gear and cleared every other obstacle with ease in 78.59 seconds for second place at that point of the competition.\nFour rounds to go in the $50,000 Blenheim World Cup Grand Prix, crowd favorite Rusty Stewart and the almighty Bristol trotted into the arena with sure confidence. \"After walking the course, I knew it was going to be a tough course, but the time allowed was the biggest worry.\" Stewart piloted his ten-year-old gelding through one obstacle at a time, setting him up for a solid approach eliminating the risk of knocking a rail. Stewart had one scary rub on an awkwardly angled vertical by the in gate but was able to recover and stop the clock for a clear round in 78.11 seconds, moving into first place. \"It was a really big track,\" Stewart confirmed, \"but it was a track that you had to have your game on from beginning to end in order to get through it. I could not do this without Bristol. He is so amazing\".\nNo other team could surpass Stewart resulting in no jump-off and Stewart's second consecutive World Cup Qualifier and HITS Millions Grand Prix Qualifier victories. \"Rusty (Stewart) is on a roll,\" course designer Jorge smiled, \"it was a great class and a great show. The whole idea was to keep it to the FEI standard. It was a legitimate World Cup Qualifier course and clearly the best man won.\"\nRusty Stewart and Kandi Stewart own and run the breeding and training operation at Grey Fox Farm. Bristol, the 10-year-old bay gelding, was the Stewart's first homebred colt and has clearly demonstrated what an amazing program they have created.\nPress release: Blenheim EquiSports\nThis photo has been added to your cart !Your shopping cart »","1000km horse race across Mongolia is won by female rider for the first time in 5 editions\nFirst rider across the line Devan Horn fails vet inspection after riding ‘near immaculate race’ and incurs 2 hour penalty handing dramatic victory to Lara who finished an hour later\nHalf of the 30 riders who began the race have already withdrawn adding clout to the race’s claim to be the longest and toughest race on the planet\n19 year old Lara Prior-Palmer from Hampshire, UK has won the Mongol Derby today in dramatic fashion. She is the first British rider, the first female rider and also the youngest person ever to win the race since it’s launch in 2009.\nAmerican 20 year old Devan Horn crossed the finish line first following a tight contest with Lara in the final few days of the race that began back on Sunday 4th August.\nHowever, race rules stipulate each rider’s horse must pass a strict veterinary inspection at the end of each leg and Devan’s horse’s heart rate did not recover in the required time and she was issued a 2 hour penalty.\nWhen Lara crossed the line an hour later she passed the vet inspection and was therefore declared the winner. Agony for the American rider after a near perfect race over 1000 km and ecstasy for the niece of well known British equestrian Lucinda Green MBE (6 times Badminton champion and eventing legend).\nThe world’s longest horse race is a recreation of Genghis Khan’s ancient postal system – a mammoth network of 25 horse stations across the Mongolian steppe. Riders change their semi-wild Mongolian horses at each station approximately 40km apart and stay with the local nomadic herding families that run the stations and provide the horses.\nJust after crossing the line 1st placed Lara said:\n“I can’t really believe it … I came into the first station last because my horse was so slow and I had to walk him in. I thought that would be the end of my Mongol Derby.\n“I knew that there were 30 people and nearly all of those 30 wanted to win and I really just wanted to finish. If you compare my first few days to my last few days I was going so much slower … and suddenly I just got the hang of it and how to ride the horses and what to do to catch up with the rest.”\nDevan Horn, the American rider first across the line but placed 2nd following her penalty, said:\n“I really have had an amazing ride, I’m feeling mixed emotions, I’m feeling a little bit disappointed, but I’m also feeling very elated that I finished. There’s definitely a little bit of rivalry going on – I thought I’d beaten her [Lara] The horse looked great … it was a kick in the teeth after riding 700 miles.\n“Apparently we’ve set a time record and since James [Johnston, the youngest rider in the field withdrew through injury] I’m actually the youngest finisher, ever!”\nThe two riders approached the race with starkly contrasting styles and tactics. Devan had a precise plan to ride “as fast as my body would allow” and was mentored by 2010 Mongol Derby winner and former US Marine Justin Nelzen on how to assess then select the best horse at each station. Picking a fast horse from among the 35 or so on offer makes a huge difference.\nLara on the other hands says she “just sort of bumbled into it” adding that she thought she was very lucky. Rather than painstakingly assessing which horse to pick at each station she said “I always just let the herders choose for me” and admitted to not being the finest navigator the race has seen.\nBoth riders however demonstrated exceptional horsemanship. Richard Dunwoody, the official race photojournalist and former champion jockey, said he’d witnessed “phenomenal riding” and that both Lara and Devan had “set a scorching pace”.\n“Clare Twemlow and Kirsten Melis aren’t far behind” he went on to say, “and I imagine Chloe Phillips-Harris is very close behind them so we’re looking forward to seeing them in tomorrow and certainly this year is one for the girls – they’ve secured the first 5 places and really put one over the lads this year!”\nOfficially the world’s longest horse with a Guinness World Record set in 2010, the Mongol Derby went a long way to confirming it’s reputation as the most gruelling horse race around as well.\nHalf of the 30 riders who started have withdrawn from the race, with only 15 now expected to complete.\nMany have fallen off or been unceremoniously bucked off their semi-wild horses or sustained injuries. Richard Dunwoody said that “it’s been a very tough year, a lot of riders have been thrown from their horses and there’s been illness through the riders and crew too … Certainly it can hold its head high and say that it is the worlds toughest horse race.”\nLara added there is an element of luck in staying fit and healthy:\n“Day 4 was tough, I was seriously knackered … I was riding a really fantastic horse this morning and it just somersaulted into a marmot hole, literally. It had been bolting so it was going really fast and then it landed on me and I was so lucky not to get hurt – it was a really intense and quite exciting experience.”\nBoth rider and horse were unhurt thankfully but every rider has similar stories that demonstrate the dangers involved (if the 50% attrition wasn’t evidence enough).\nSecond placed Devan Horn said:\n“On Day 4, I was riding along and my horse started bucking really, really hard. I dropped my lead rein and without thinking I bent to catch it and unbalanced myself and the horse threw me, and then ran off!\n“I had to hike the 10km back to his home ger where he luckily was headed. So I never lost my horse but I had to hike for a long time and I remember thinking while I was hiking ‘what am I doing here, why did I decide to do this with my summer vacation?’”\nDevan was also kicked by her horse and experienced severe illness on the same day but along with many other riders showed a willingness to fight through severe conditions, intense pain, and a lot of chafing, scrapes and bruises to carry on riding.\nWhile the horses are looked after by a team of equine vets, the riders are backed up by a team of emergency medics provided by Prometheus Medical, they’re a specialist team with experience of managing medical needs and emergencies in remote environments. They have dealt with everything from rashes and sores to severe gastrointestinal problems, dehydration and heat exhaustion among others.\n14 riders are still on the race course and expected to finish over the next two days. Those riders can be tracked live on the Mongol Derby Tracker. The race team post regularly on Twitter at @MongolDerbyLive."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:e6e7835a-1aac-4184-9de1-bc17c6c1cbb1>","<urn:uuid:dff09be3-969a-4658-b6bd-da5ceead3ecc>"],"error":null}
{"question":"Could you compare how both Angela Merkel and Goh Chok Tong used diplomatic relationships to achieve their countries' economic goals?","answer":"Goh Chok Tong used personal diplomacy through a golf game with US President Bill Clinton to secure the USSFTA during Singapore's economic struggles after the Asian Financial Crisis. Angela Merkel, on the other hand, worked closely with French President Nicolas Sarkozy to broker deals aimed at containing damage to the euro currency during the European debt crisis. While Goh focused on bilateral trade agreements to expand Singapore's economic space, Merkel's approach centered on maintaining European economic stability and integration.","context":["The fundamentals of Singapore’s existence have not changed. We are located in the heart of Southeast Asia and surrounded by bigger neighbours. We have to make ourselves relevant to the rest of the world so that other countries have an interest in our continued survival and prosperity as a sovereign and independent country. We need to remain competitive, be able to differentiate ourselves from others in a positive way, and yet maintain good relations with our partners.1\nOur founding fathers understood the importance for Singapore to be plugged into the global networks since the early days of our independence. Back in the 1960s, it was conventional wisdom for developing countries to protect their domestic industries and reject foreign investment and trade. Our founding fathers went against the tide, and invited international companies to invest and manufacture in Singapore, as well as to trade with Singapore.2 In February 1972, Former Minister for Foreign Affairs, Mr S Rajaratnam, articulated his vision of Singapore as a “Global City”, with the world as our hinterland, rather than just an entrepot serving the region.\nWatch the video below by Institute of Policy Studies (IPS) - Singapore Perspectives 2022 to learn more about Mr S Rajaratnam’s vision of Singapore as a Global City:\nOver the years, we have built a secure, transparent and business-friendly environment, based on good governance and effective economic management, for international companies to operate in. We also strive to discern future trends and position ourselves such that we are able to grasp opportunities ahead of others. 3 For a small country like Singapore, we must remain nimble and seize opportunities quickly, just like what we did when Singapore sealed the USSFTA over a game of golf.\nExample: United States – Singapore Free Trade Agreement (USSFTA) – Sealed Over a Game of Golf\nAs a small, open economy, Singapore relies on free trade and open markets. We support multilateral systems which promote a stable and predictable and predictable international trading environment such as the World Trade Organisation (WTO). We also continue to work with like-minded partners to build a broader and deeper scope of cooperation.\nAs explained by Ambassador-at-large Dr Tommy Koh in 2019, our FTAs help us to “expand our economic space and link our small economy to the economies of other bigger countries… (so that) Singapore will be more deeply connected to the global supply chain and our exporters will have lower tariff or non-tariff barriers”.4\nIn the late 1990s, our economy was struggling after the Asian Financial Crisis and multilateral global deals at the WTO were stalled. Faced with dim prospects, we decided to chart our own economic future by pushing for FTAs with our main trading partners, such as the United States (US). Despite a downturn in our bilateral relations arising from the sentencing of American teenager Michael Fay, then-Prime Minister Mr Goh Chok Tong sealed the USSFTA deal with then-US President Mr Bill Clinton, over a game of golf.\nGoh Chok Tong’s midnight golf game with US President Bill Clinton in 2000: The untold story. (2014, October 20). The Straits Times.","The reunification of Germany\nThe swift and unexpected downfall of the German Democratic Republic was triggered by the decay of the other communist regimes in eastern Europe and the Soviet Union. The liberalizing reforms of President Mikhail Gorbachev in the Soviet Union appalled the Honecker regime, which in desperation was by 1988 forbidding the circulation within East Germany of Soviet publications that it viewed as dangerously subversive. The Berlin Wall was in effect breached in the summer of 1989 when a reformist Hungarian government began allowing East Germans to escape to the West through Hungary’s newly opened border with Austria. By the fall, thousands of East Germans had followed this route, while thousands of others sought asylum in the West German embassies in Prague and Warsaw, demanding that they be allowed to emigrate to West Germany. At the end of September, Genscher, still West Germany’s foreign minister, arranged for their passage to West Germany, but another wave of refugees from East Germany soon took their place. Mass demonstrations in the streets of Leipzig and other East German cities defied the authorities and demanded reforms.\nIn an effort to halt the deterioration of its position, the SED Politburo deposed Honecker in mid-October and replaced him with another hard-line communist, Egon Krenz. Under Krenz the Politburo sought to eliminate the embarrassment occasioned by the flow of refugees to the West through Hungary, Czechoslovakia, and Poland. On the evening of November 9, Günter Schabowski, a communist functionary, mistakenly announced at a televised news conference that the government would allow East Germans unlimited passage to West Germany, effective “immediately.” While the government had in fact meant to require East Germans to apply for exit visas during normal working hours, this was widely interpreted as a decision to open the Berlin Wall that evening, so crowds gathered and demanded to pass into West Berlin. Unprepared, the border guards let them go. In a night of revelry tens of thousands of East Germans poured through the crossing points in the wall and celebrated their new freedom with rejoicing West Berliners.\nThe opening of the Berlin Wall proved fatal for the German Democratic Republic. Ever-larger demonstrations demanded a voice in government for the people, and in mid-November Krenz was replaced by a reform-minded communist, Hans Modrow, who promised free, multiparty elections. When the balloting took place in March 1990 the SED, now renamed the Party of Democratic Socialism (PDS), suffered a crushing defeat. The eastern counterpart of Kohl’s CDU, which had pledged a speedy reunification of Germany, emerged as the largest political party in East Germany’s first democratically elected People’s Chamber. A new East German government headed by Lothar de Maizière, a long-time member of the eastern Christian Democratic Union, and backed initially by a broad coalition, including the eastern counterparts of the Social Democrats and Free Democrats, began negotiations for a treaty of unification. A surging tide of refugees from East to West Germany that threatened to cripple East Germany added urgency to those negotiations. In July that tide was somewhat stemmed by a monetary union of the two Germanys that gave East Germans the hard currency of the Federal Republic.\nThe final barrier to reunification fell in July 1990 when Kohl prevailed upon Gorbachev to drop his objections to a unified Germany within the NATO alliance in return for sizable (West) German financial aid to the Soviet Union. A unification treaty was ratified by the Bundestag and the People’s Chamber in September and went into effect on October 3, 1990. The German Democratic Republic joined the Federal Republic as five additional Länder, and the two parts of divided Berlin became one Land. (The five new Länder were Brandenburg, Mecklenburg–West Pomerania, Saxony, Saxony-Anhalt, and Thuringia.)\nTest Your Knowledge\nLet’s Move: Fact or Fiction?\nIn December 1990 the first all-German free election since the Nazi period conferred an expanded majority on Kohl’s coalition. After 45 years of division, Germany was once again united, and the following year Kohl helped negotiate the Treaty on European Union, which established the European Union (EU) and paved the way for the introduction of the euro, the EU’s single currency, by the end of the decade.\nThe achievement of national unification was soon shadowed by a series of difficulties, some due to structural problems in the European economy, others to the costs and consequences of unification itself. Like most of the rest of Europe, Germany in the 1990s confronted increased global competition, the increasing costs of its elaborate social welfare system, and stubborn unemployment, especially in its traditional industrial sector. However, it also faced the staggering added expenses of unifying the east and west. These expenses were all the more unsettling because they were apparently unexpected. Kohl and his advisers had done little to prepare German taxpayers for the costs of unification, in part because they feared the potential political consequences but also because they were themselves surprised by the magnitude of the task. The core of the problem was the state of the eastern German economy, which was far worse than anyone had realized or admitted. Only a handful of eastern firms could compete on the world market; most were woefully inefficient and also environmentally destructive. As a consequence, the former East German economy collapsed, hundreds of thousands of easterners faced unemployment, and the east became heavily dependent on federal subsidies. At the same time, the infrastructure—roads, rail lines, telephones, and the like—required massive capital investment in order to provide the basis for future economic growth. In short, the promise of immediate prosperity and economic equality, on which the swift and relatively painless process of unification had rested, turned out to be impossible to fulfill. Unemployment, social dislocation, and disappointment continued to haunt the new Länder more than a decade after the fall of the Berlin Wall.\nThe lingering economic gap between the east and west was just one of several difficulties attending unification. Not surprisingly, many easterners resented what they took to be western arrogance and insensitivity. The terms Wessi (“westerner”) and Ossi (“easterner”) came to imply different approaches to the world: the former competitive and aggressive, the product of what Germans call the West’s “elbow society”; the latter passive and indolent, the product of the stifling security of the communist regime. The PDS became the political voice of eastern discontents, with strong if localized support in some of the new Länder. Moreover, the neofascist German People’s Union (Deutsche Volksunion), led by millionaire publisher Gerhard Frey, garnered significant support among eastern Germany’s mass of unemployed workers. In addition to the resentment and disillusionment over unification that many easterners and some westerners felt, there was also the problem of coming to terms with the legacies left by 40 years of dictatorship. East Germany had developed a large and effective security apparatus (the Stasi), which employed a wide network of professional and amateur informants. As the files of this organization began to be made public, eastern Germans discovered that many of their most prominent citizens, as well as some of their friends, neighbours, and even family members, had been on the Stasi payroll. Coming to terms with these revelations—legally, politically, and personally—added to the tension of the postunification decade.\nDespite the problems attending unification, as well as a series of scandals in his own party, Kohl won a narrow victory in 1994. In 1996 he surpassed Adenauer’s record as the longest-serving German chancellor since Bismarck. Nevertheless, his popularity was clearly ebbing. Increasingly intolerant of criticism within his own party, Kohl suffered a humiliating defeat when his first choice for the presidency was rejected. Instead, Roman Herzog, the president of the Federal Constitutional Court, was elected in May 1994 and fulfilled his duties effectively and gracefully. As Germany prepared for the 1998 elections, its economy was faltering—unemployment surpassed 10 percent and was double that in much of eastern Germany—and some members of Kohl’s party openly hoped that he would step aside in favour of a new candidate; instead the chancellor ran again and his coalition was defeated, ending his 16-year chancellorship. Kohl was replaced as chancellor by Gerhard Schröder, the pragmatic and photogenic leader of the SPD, which formed a coalition with the Green Party.\nSchröder’s government got off to a rocky start, the victim of the chancellor’s own indecisiveness and internal dissent from his party’s left wing. The coalition also suffered from internal dissension within Foreign Minister Joschka Fischer’s Green Party, which was divided between pragmatists such as Fischer and those who regarded any compromise as a betrayal of the party’s principles. In 1999 the government’s problems were swiftly overshadowed by a series of revelations about illegal campaign contributions to the CDU, which forced Kohl and his successor, Wolfgang Schäuble, to resign their leadership posts. In April 2000 the CDU selected as party leader Angela Merkel, who became the first former East German and first woman to lead a major political party in Germany.\nSchröder’s government focused much of its efforts on reforming the German social welfare system and economy. In particular, the government wanted to reduce the costs of the generous but bloated welfare system; as the population was aging, the number of beneficiaries was increasing at a rate exceeding the number of contributors, threatening the solvency of the system. Moreover, the government attempted to relieve the burden on businesses of the country’s high taxes and labour costs, which had driven away foreign investment and encouraged German firms to close German plants and move them overseas. The government also aimed to eliminate the country’s reliance on nuclear power, agreeing to phase out its use by about 2022. In 2010 the government extended that deadline into the 2030s.\nWhen the 2002 election campaign began, the government’s efforts to improve the economy had not succeeded. Economic growth remained sluggish, and unemployment (particularly in eastern Germany) remained high. Faced with a vigorous challenge from Edmund Stoiber, the head of Bavaria’s government, Schröder based much of his campaign on opposition to U.S. policy regarding the Iraqi regime of Ṣaddām Ḥussein—a view that was widely shared throughout Germany. As a result, Schröder and the Greens were able to win a narrow victory in September 2002. The new government attempted to build a consensus for economic reforms, which would require sacrifices from trade unions and other important parts of the Social Democrats’ constituency. At the same time, Schröder sought to repair the damaged relationship with the United States, though he opposed U.S.-led military action against Iraq in 2003. As the country’s economy continued to worsen, early elections were held in 2005. The CDU and CSU won a narrow victory, and a coalition government was formed with Merkel as chancellor; she became the first woman to hold that office.\nAt the start of the new millennium, Germany remained a leader in Europe and was the key to the continent’s security, stability, and prosperity. For more than 50 years, from Adenauer to Kohl, Schröder, and Merkel, Germans had played an important role in the creation of European institutions. Germany remains essential to the success of both the EU’s ambitious program of economic and political integration and its efforts to expand to include members from the former Soviet bloc. Germany will also be an important part of European efforts to craft a new security strategy, based on an enlarged NATO and a revised relationship with the United States.\nIn Germany’s parliamentary elections on September 27, 2009, Merkel’s mandate as chancellor was renewed, this time with the CDU-CSU and the FDP winning enough seats to form a coalition. The SPD, which since 2005 had served as the junior partner in a grand coalition with the CDU-CSU, thus was forced into opposition. Germany comfortably weathered the debt crisis that shook the rest of the euro zone, and Merkel and French Pres. Nicolas Sarkozy brokered a series of deals that were intended to contain the damage to the single currency.\nWhile Merkel’s international presence was on the rise, she suffered domestically. The resignations of Pres. Horst Köhler in 2010, Defense Minister Karl-Theodor zu Guttenberg in 2011, and Pres. Christian Wulff in 2012 were all blows to Merkel’s prestige. After Japan’s Fukushima nuclear accident in March 2011, Merkel pledged to phase out nuclear power in Germany by 2022, but this move came too late to boost the CDU’s performance in state elections later that month. In contrast, the Green Party, which had long opposed nuclear power, captured enough support to form a government in Baden-Württemberg, a CDU stronghold since 1953. Joachim Gauck was elected president of Germany in March 2012, becoming the third person to hold that office in as many years. Unaffiliated with any political party, Gauck was a popular choice for the largely ceremonial role because of his history as a pro-democracy dissident in East Germany and his supervision of the Stasi archives after the fall of the Berlin Wall. For the first time since Germany’s reunification, the posts of both chancellor and president were held by individuals from the former East Germany.\nAs the campaign for the 2013 federal election began to intensify, the CDU coalition continued to suffer setbacks at the state level. Elections in Lower Saxony in January 2013 shifted the balance of power in the Bundesrat, giving the Greens and the SPD a majority in the upper house of Germany’s legislature. Peer Steinbrück, the SPD candidate for chancellor, had served as finance minister under Merkel in the grand coalition government from 2005 to 2009. While his performance in that role was widely praised, its connection with the Merkel administration made it difficult for Steinbrück to set himself apart from the incumbent. The sole televised debate between the candidates was inconclusive, and Merkel’s personal popularity was bolstered by strong economic numbers, which included an unemployment rate that was the lowest since reunification.\nHer handling of the economy and her approach to the euro-zone debt crisis appeared to receive a huge endorsement from the German electorate when the CDU and CSU captured nearly 42 percent of the vote in the September 22, 2013, election, winning almost an absolute majority of the seats and setting up Merkel to become the third chancellor in the post-World War II era to win three elections. Because her government’s junior partner, the FDP, failed to reach the 5 percent threshold for representation for the first time in the postwar period, Merkel faced the possibility of forming another grand coalition with the SPD (which finished second with about 26 percent of the vote) or bringing the Green Party (which finished just behind The Left Party with about 8 percent) into government, though neither party was likely to come without a great deal of bargaining. After two months of negotiations, a grand coalition between the CDU-CSU and SPD was proposed, but it hinged on the approval of SPD members in an unprecedented party ballot. In December 2013 more than three-fourths of SPD voters voiced their support for the coalition. Among the stated priorities for the new government were the continued transitioning of Germany’s energy system to renewable sources and the adoption of the country’s first minimum wage law."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:3f605e73-f418-449f-b561-9250291172e2>","<urn:uuid:34071a96-26d9-4510-be57-e8049c242398>"],"error":null}
{"question":"What are the symptoms of sleep apnea, and how does it contribute to excessive daytime sleepiness?","answer":"Sleep apnea is characterized by periods of no breathing between snoring intervals. During these episodes, there is a drop in blood oxygen levels, irregular pulse, and increased blood pressure. The accumulation of carbon dioxide and fall in oxygen cause brief periods of awakening. This condition leads to excessive daytime sleepiness (EDS), which manifests as an overwhelming urge to sleep during the day despite having had a full night's sleep. People with sleep apnea-induced EDS experience difficulty concentrating, feeling tired and sluggish throughout the day, and have trouble staying awake for extended periods.","context":["Deepthy P Thomas\nIst year MSc nursing\nGovt college of nursing\nSLEEP AND SLEEP\nDEFINITION OF SLEEP\nSleep is a naturally occurring altered state of\nconsciousness characterized by decreases in\nawareness and responsiveness to stimuli.\nPHYSIOLOGY OF SLEEP\nControlled by recticular-activating system and\nbulbar synchronizing system.\nWakefulness occurs when the reticular system is\nThe hypothalamus has control centres for several\ninvoluntary activities of the body, one of which\nconcerns sleeping and waking.\nInjury to the hypothalamus may cause\na person to sleep for abnormally long\nBiological rhythms that follow a cycle of about 24\nhours are termed circadian rhythms\ncirca means ―about and dies means ―day\nCiracdian synchronization exists when an individual\nsleep-wake pattern follows an inner biological clock.\nwhen physiologic and psychological rhythms are\nhigh or most active, the person is awake and when\nthese rhythms are low, the person will sleep\nElectro- physiologic Approach\nelectro-physiologic changes in brain waves, eye\nmovements, and muscles show five sleep stages.\nInvolves the reticular activating system (RAS) and a\ndynamic interaction of neurotransmitters.\nSerotonin - decrease the activity of the\nRAS, thereby inducing and sustaining sleep\nacetylcholine and nor-epinephrine appear to be\nrequired for the REM sleep cycle\nfast theta waves on the EEG.\nrespirations become even.\npulse rate decreases.\nThis stage usually lasts only a few minutes and if\nawakened the person may say he or she was\nBursts of sleep spindles appear on the EEG\nRolling eye movements continue and snoring.\nBody functions continue to slow.\nStage 3 and stage 4:\ndelta sleep seen on the EEG.\nthe muscles are relaxed but muscles tone is\nrespirations are even\nVital signs, urine formation and oxygen\nconsumption by muscle decrease.\nIn these stages snoring, sleepwalking and bed\nwetting are most likely to occur.\nRapid Eye Movement:\nREM sleep closely resembles wakefulness\nexcept for very low muscle tone, indicated\nby a reduction in amplitude of the EMG.\nBlood pressure and pulse rate show wide\nvariations and may fluctuate rapidly.\nRespirations are irregular and oxygen\nVaginal secretions increases in women and\nerections may occur in men.\nSorting and discarding of\nCharacter reinforcement and adaptation.\nNewborn and Infant\nToddler & Preschooler\nAdult and Older adult\nSchool-Age Child and\nAverage amount of sleep per day\nNewborn - up to 18 hours\n1–12 months - 14–18 hours\n1–3 years -12–15 hours\n3–5 years - 11–13 hours\n5–12 years - 9–11 hours\nAdolescents - 9-10 hours\nAdults, elder - 7–8 (+) hours\nPregnant women -8 (+) hours\nAvoid napping during the day.\nEnsure adequate exposure to natural light..\nEstablish a regular bedtime routine.\nTry to avoid emotionally upsets before sleep.\nAssociate your bed with sleep..\nsleep environment is pleasant and relaxing.\nWhen you think about your sleep, what\nkinds of impressions come to mind?\nDo you fall asleep at inappropriate times?\nHow long does it take you to fall asleep?\nHave you been told that you stop breathing\nDo you fall asleep during physical activities?\nA sleep diary is a daily account of sleeping and\nwalking activities. The client or personnel compile the\ninformation in a sleep disorder clinic.\nto evaluate insomnia\nThe Epworth Sleepiness Scale\n0 = would never doze or sleep.\n1 = slight chance of dozing or sleeping\n2 = moderate chance of dozing or\n3 = high chance of dozing or sleeping\nSitting and reading ____\nWatching TV ____\nSitting inactive in a public place ____\nBeing a passenger in a motor vehicle\nfor an hour or more\nLying down in the afternoon ____\nSitting and talking to someone ____\nSitting quietly after lunch (no alcohol) ____\nStopped for a few minutes in traffic\nTotal score (add the scores up) ------\nNasal and oral airflow.\nChest and abdominal respiratory effort.\nOxygen level in the blood.\nMultiple Sleep Latency Test\nasked to take to a daytime nap of 20 minutes at 2-\nare repeated four or five times throughout the day.\nRested person take a time of atleast 15 mts for\nsmall, wrist mounted device records activity\nplotted against time, usually 1-3 weeks. there is a\ncorrelation between the rest/activity recorded by\nactigraph and wake/sleep pattern determined by\nInternational classification of diseases\nof circadian rhythm\nINTRINSIC SLEEP DISORDERS\nSleep apnoea syndrome.\nPeriodic limb movement\nRestless leg syndrome.\nis troubling or difficulty in falling\ndecreased feeling of wellbeing during the day, a\ndeterioration of mood and motivation, decreased\nattention span, low levels of energy and\nconcentration and increased fatigue.\nPsycho physiological insomnia\nusually not sleepy during the day but function\npoorly in terms of cognitive skills and also report\nNarcolepsy is a condition characterized by an\nuncontrollable desire to sleep\nfall asleep while standing up,\ndriving a car or while swimming.\nDisrupted night time sleep.\nMultiple sleep latency test.\nStimulant medications such as\nmethylphenidate, methamphetamine, dextro\namphetamine, and modafinil are generally\nused. Dependency is usually common.\nHypersomnia is a condition\ncharacterized by excessive\nsleep, particularly during the day.\nIn some cases sleep drunkenness seen.\ntwo to three days of sleeping 18-20\nhours per day, hypersexual\nbehaviour, compulsive eating, and\nSLEEP APNOEA SYNDROME\nSleep apnoea refers to periods of no breathing\nbetween snoring intervals.\nObstructive sleep apnoea\nCentral sleep apnoea syndrome\nMixed-type sleep apnoea syndrome\nthere is a drop in the oxygen level of the\nblood, the pulse irregular and the BP increases.\nThe accumulation of carbon dioxide and the fall\nin oxygen cause brief periods of awakening\nPERIODIC LIMB MOVEMENT\nit is also called nocturnal myoclonus. In\nthis syndrome, sleep is disturbed by\nrepetitive jerky flexion movements of the\nlimbs which occurs in the early stages of\nTreatment includes small doses of\nlevodopa 100-200 mg a\nnight time or a dopamine\nRESTLESS LEG SYNDROME\nUnpleasant sensations in the legs that\nare ameliorated by moving the legs\noccur when patient tired in the evenings\nand at the onset of sleep\nTreatment: clonazepam 0.5 to 2 mg,\nsmall doses of levodopa 100-200 mg or\ndopamine agonists at night\nEXTRINSIC SLEEP DISORDER\ninadequate sleep hygeine.\ninsomnia associated with psychiatric\ninsomnia caused by a medical\ninsomnia caused by a drug or\nClinical features of insomnia:\nComplain about inability to sleep long or well\nenough to awaken feeling rested or restored.\nDaytime consequences like feeling tired or\nfatigued , trouble concentrating.\nStimulus control therapy\nSleep restriction therapy:\nSleep hygiene education\nParasomnias are conditions associated with\nactivities that cause arousal or partial arousal\nusually during transitions in NREM periods of\ncarry an automatic motor activities\nthat range from simple to complex.\nThe child screams, exhibiting autonomic\narousal with sweating, tachycardia and\nSleep-wake transition disorder\nsudden jerking movements of the legs often\noccurs as a person is falling asleep.\nParasomnias usually associated with\nNightmares are frightening dreams that arise\nin REM sleep and are often vividly recalled on\nBruxism is an involuntary, forceful grinding of\nteeth during sleeping . treated by biofeedback\nmechanism, providing rubber tooth to protect tooth.\nBedwetting is uncontrolled passage of urine who\nhave previously continent for 6-12 months.\nTreatment consists of bladder training exercises\nand behaviour therapy,desmopressin 0.2 mg\nHS, oxybutynin chloride 5-10 mg HS or\nimipramine 10-50 mg HS.\nMEDICAL AND PSYCHIATRIC SLEEP\nAssociated with mental disorder\nAssociated with neurological disorders\nAssociated with medical disorders\nPROPOSED SLEEP DISORDER\nShort sleeper, long sleeper, menstrual\nassociated sleep disorder, pregnancy\nassociated sleep disorder, sleep related\nSleep deprivation refers to a decrease in the\namount, consistency and quality of sleep.\nThe manifestations progress from irritability and\nimpaired mental abilities to a total disintegration\nof personality. Partial sleep deprivation may\nresult in loss of concentration and pose serious\nsafety risks. The strange environment of the\nhospital, physical discomfort and pain, the effects\nof medications and the need for 24 hour nursing\ncare may all contribute to sleep deprivation in the\nDRUG INDUCED SLEEP\nDiscontinue agents with potential to cause drug\ninduced sleep disturbances when possible.\nIf unable to discontinue potentially causative\n*change time of administration to earlier in the day.\n*reduce dose to decrease symptoms\nTREATMENT OF SLEEP DISORDERS\nSedative or hypnotic medications\nBenzodiazapines bind with GABA-A receptors and\nmodulate the effect of GABA.\nTemazepam and estazolam\nDiazepam is a long acting one\nsafer hypnotic agents are lorazepam, temazepam,\nSide effects include (REM sleep rebound, daytime\nmemory impairment respiratory depression in patients\nwith pulmonary disease and may lose sleep-inducing\nefficacy with prolonged use\nOther Sedating Agents\nIn patients with chronic insomnia, 22% report using\nethanol as a hypnotic.\nOver-the-counter sleeping pills contain sedating\nantihistamines, usually diphenhydramine\nSedating antidepressants include the tricyclics\n(amitriptyline, imipramine, nortriptyline, etc.), trazo\ndone, and the newer agents mirtazapine and\nNarcolepsy is treated with stimulants such as\ndextroamphetamine sulfate or methylphenidate.","What is excessive daytime sleepiness (EDS)?\nExcessive daytime sleepiness (EDS) is a common problem that affects both adults and children. It occurs when a person experiences an overwhelming urge to sleep during the day, despite having had a full night’s sleep. A variety of medical conditions can cause EDS, including sleep apnea, depression, narcolepsy, and sleep deprivation, as well as lifestyle choices such as alcohol or drug use. It can also be a side effect of certain medications.\nCauses of EDS\nDaytime sleepiness is a condition that can undermine a person’s quality of life. While occasional episodes of daytime sleepiness are normal, chronic EDS can have serious underlying causes.\nOne of the most common causes of excessive daytime sleepiness is not getting enough sleep at night. The average adult needs between 7-9 hours of sleep every night, but many people do not get enough. Sleep deprivation can cause a wide range of symptoms, including daytime sleepiness.\nAnother common cause of daytime sleepiness is sleep apnea. Sleep apnea is a condition in which a person’s breathing is interrupted while they are sleeping. This can lead to poor quality sleep and excessive daytime sleepiness.\nPoor sleep hygiene can also lead to excessive daytime sleepiness. Sleep hygiene refers to habits and activities that promote better sleep. Poor sleep hygiene can include things like drinking caffeine late in the day, using electronic devices in bed, and eating an enormous meal before bed.\nMedications can also cause excessive daytime sleepiness. Many medications, including sedatives and antihistamines, can cause drowsiness. It is important to talk to a doctor before taking any medication, as some medications can have serious side effects.\nNumerous medical conditions can cause excessive daytime sleepiness. Conditions such as narcolepsy, thyroid problems, and depression can all cause symptoms of daytime sleepiness.\nSymptoms of EDS\nThe most common symptom of Excessive Daytime Sleepiness is a powerful urge to sleep during the day, even when one has had enough sleep the night before. This can lead to difficulty in concentrating and an inability to focus on tasks.\nOther symptoms include:\n- difficulty in waking up in the morning,\n- feeling tired and sluggish throughout the day,\n- and difficulty in staying awake for extended periods of time.\nDaytime napping is another symptom of EDS, as well as having difficulty in waking up from naps. People with EDS may also experience feelings of irritability, depression, and anxiety because of their lack of sleep.\nLifestyle changes can be an efficient way to reduce excessive daytime sleepiness. These changes include getting regular exercise, reducing caffeine consumption, establishing regular sleep and wake times, avoiding alcohol and other drugs, and avoiding huge meals and arduous exercise close to bedtime. Creating a comfortable sleep environment, such as keeping the bedroom dark, cool and quiet, can help to promote a restful sleep. Medication can also treat EDS.\nStimulant medications, such as modafinil, are commonly prescribed to increase alertness and reduce fatigue. Other medications, such as sodium oxybate, are used to improve the quality of sleep. In addition, medications such as antidepressants and anti-anxiety medications can help to reduce sleep disruption and improve sleep quality.\nWhen treating excessive daytime sleepiness, it is important to talk to a healthcare provider to determine the best course of action. Depending on the severity of the condition, lifestyle changes and/or medication may be necessary. It is also important to note that lifestyle changes may take several weeks to take effect, while medications may take several days to become effective.\nWith the right combination of lifestyle changes and medication, we can manage excessive daytime sleepiness.\nExcessive daytime sleepiness can have serious implications for an individual’s physical, mental, and emotional well-being. It can lead to impaired concentration and memory, mood swings, and a decrease in productivity. It can also be a sign of an underlying sleep disorder or medical condition, so it’s important to address the issue and seek professional help as soon as possible. With proper diagnosis and treatment, EDSs can be managed and even eliminated.\n- NCBI – WWW Error Blocked Diagnostic. (n.d.). https://pubmed.ncbi.nlm.nih.gov/33840518/\n- Pacheco, D. (2022, June 10). Causes of Excessive Sleepiness. Sleep Foundation. https://www.sleepfoundation.org/excessive-sleepiness/causes\n- Roland, J. (2021, July 13). Why Do I Feel Excessively Sleepy? Healthline. https://www.healthline.com/health/excessive-sleepiness\n- Sleep Disorders and Hypersomnia Treatment. (2000, January 1). WebMD. https://www.webmd.com/sleep-disorders/hypersomnia-treatments"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:8de5fd90-279d-44dd-b8ed-c576ebb6082a>","<urn:uuid:846a0e8f-f3dc-4836-b65e-b5cc2cfa6768>"],"error":null}
{"question":"What are the essential metrics for measuring success in agile testing, and how should teams adapt their communication approach for different audience groups?","answer":"Essential metrics for measuring agile testing success include test coverage, defect density, test execution progress, cycle time, defect turnaround time, customer satisfaction, agile test velocity, and escaped defects. These metrics should be used judiciously alongside qualitative assessments. Regarding communication, teams must adapt their approach based on the audience: For end-users, they should use simple language and avoid technical jargon, with studies showing jargon-free content is understood 40% faster. For developers, clear and concise technical information with code samples is crucial. For system administrators, communication should focus on security, maintenance, and configuration details. Success in both metrics tracking and communication requires continuous monitoring and adjustment based on audience feedback and engagement metrics.","context":["Writing for specific audiences is crucial in ensuring that your content appeals to the right people and meets their unique needs. In this article, we will explore techniques for writing for three primary audience types: end-users, developers, and system administrators. Mastering these techniques will help you create well-crafted, targeted content that effectively addresses the specific requirements and concerns of each audience group.\nUnderstanding the Importance of Writing for Specific Audiences\nUnderstanding the importance of writing for specific audiences is essential in delivering effective communication. Tailoring your content to resonate with the intended audience ensures clarity, relevance, and engagement. By considering their knowledge level, language proficiency, and unique needs, you can craft technical information that is accessible, user-friendly, and maximizes its impact.\nIdentifying End-Users, Developers, and System Administrators\nLet's take a closer look at these three primary audience groups:\n- End-users: These are the individuals who interact with your product or service daily. They could be consumers or employees within an organization.\n- Developers: This audience encompasses software developers, engineers, and programmers. They often work on building, modifying, or maintaining software applications.\n- System administrators: They are responsible for managing and maintaining computer systems, networks, and servers, ensuring overall system security and performance.\nNow that we've identified our target audience groups let's explore unique techniques for writing for each of them.\nTips for Writing for End-Users\nSimplifying Technical Jargon\nWhen writing for end-users, avoid using overly-technical language and jargon. Instead, opt for simpler language that makes it easy for non-experts to grasp your message. A 2016 study conducted by the Nielsen Norman Group found that people understand jargon-free content 40% faster than technical-heavy content.\nFocusing on User Experience and Benefits\nEnd-users prioritize the practical aspects of your product or service, such as ease-of-use, convenience, and benefits. Describe features and make sure to highlight their value and utility for the end-user.\nUtilizing Visual Aids and Demonstrations\nImages, videos, and step-by-step instructions are effective ways to demonstrate the use of a product or service for end-users. Visual aids not only make it easier for readers to understand complex concepts but also improve content engagement. Use a platform like Guidde to easily create engaging how-to video guides, GIFs and images that will aid your technical writing.\nMastering Technical Writing for Developers\nPrioritizing Clear and Concise Communication\nDevelopers value clear, accurate, and concise information. In your writing, accurately describe technical processes, components, and features that will enable developers to effectively use and understand your product or service.\nIncluding Code Samples and Technical Documentation\nCode samples, API references, and technical documentation offer invaluable practical guidance for developers. Including these resources will help them understand and implement your product more effectively.\nAddressing Relevant Programming Languages and Tools\nWhen writing for developers, it is vital to address programming languages and tools relevant to your product. Describing essential settings, frameworks, and libraries will provide developers with the context and understanding they need.\nEffectively Communicating with System Administrators\nEmphasizing System Security and Maintenance\nSecurity and maintenance are crucial concerns for system administrators. Make sure to provide comprehensive information on security features and procedures that will help them maintain the health and safety of their systems.\nProviding In-Depth Configuration Guides\nSystem administrators rely on detailed configuration guides to set up, manage, and customize various systems, networks, and servers. Ensure that your writing includes precise instructions accompanied by relevant code snippets and examples.\nStaying Current with Industry Trends and Best Practices\nSystem administrators value up-to-date information on the latest industry trends and best practices. Devote time to researching and staying informed about the system administrator community and incorporate relevant insights into your writing.\nAdapting Tone and Language for Each Audience Group\nAdapting tone and language for each audience group is a critical aspect of effective communication. Different audience groups may have varying levels of technical expertise and familiarity with the subject matter. By adjusting your tone and language to align with their knowledge and preferences, you can establish a stronger connection and enhance understanding.\nFor technical information aimed at experts, a more formal and technical tone may be appropriate. In contrast, when communicating with non-technical audiences, using plain language, avoiding jargon, and providing clear explanations are essential to ensure comprehension. Adapting your tone and language helps create a tailored experience that resonates with your audience and facilitates effective communication.\nNavigating the Overlap Between Different Audience Types\nNavigating the overlap between different audience types can be a challenge when presenting complex technical information. Often, there is a diverse range of audience members with varying levels of technical knowledge and expertise. Some may be beginners seeking basic information, while others may be experienced professionals looking for advanced details.\nTo address this overlap, it is crucial to strike a balance in your content. Provide introductory explanations for those who are less familiar with the topic, while also offering in-depth insights and practical examples for those with more expertise. By acknowledging and addressing the different needs within your audience, you can ensure that your content remains engaging and relevant to all, fostering a deeper understanding and appreciation for your technical information.\nMeasuring the Success of Audience-Specific Writing\nMeasuring the success of audience-specific writing is essential to ensure that your technical content effectively resonates with your target audience. One way to measure success is through audience feedback and engagement metrics. Encourage your audience to provide feedback, whether through surveys, comments, or user testing sessions. Analyzing these responses can provide valuable insights into how well your content meets the needs and expectations of different audience segments.\nAdditionally, monitoring engagement metrics such as page views, time spent on page, and click-through rates can give you an indication of how effectively your audience is interacting with your content.\nIn conclusion, understanding and catering to the distinct requirements and expectations of end-users, developers, and system administrators will help you establish trust and rapport with these audience groups. By doing so, you significantly improve the chances of your content performing well and achieving its goals — all while providing enjoyable and informative reading experiences.","Agile testing is any test which occurs to support an agile methodology. Below we break down some of the best practices for agile testing in software. If you want to start testing in agile with Global App Testing, you can get in touch here.\nAgile testing has become a critical part of application lifecycles and has had a significant impact on software development, testing and quality assurance. It has also gained widespread acceptance as a crucial driver for the delivery of high-quality products. In this article, we take a deep dive into the world of Agile testing to better understand how it works and how it can help you.\nIn order to understand agile testing, it’s important to understand what the Agile development methodology involves. It’s an umbrella term, encompassing many practices that are quite different from traditional development techniques.\nLet’s start by looking at the key principles of agile software development. The four core values are:\nAs the name implies, an Agile methodology is focused on responding to change. There are many frameworks teams might use, such as Scrum or Kanban, but at the center of it is a collaborative approach.\nA traditional development approach might separate team members based on the area they’re working on, and slowly add pieces together to create a finished product. With Agile, continuous integration is key - the whole team collaborates and new features are added as they work. It creates a completely different software development life cycle - which is why teams need to implement agile testing methods to help.\nOur definition of agile testing is testing which occurs in and is appropriate to an agile software development environment. Many of the kinds of testing which are appropriate for other software development methodologies are suitable for agile testing – regression testing, feature testing, and so forth. But their methodology – how they fit with the software release cycle; the way that the tests are planned and success is understood – is often different. Global App Testing provides tester supply which is elastic and which entails a rapid turnaround, meaning you can expand your team instantly in the case of tests which can’t be automated.\nAgile testing operates under the philosophy that continuous testing is a crucial part of development, on a par with coding.\nIn Agile, testing is integrated directly into the development process so that bugs are discovered as early and as often as possible. As a result, testers can identify problems at every point in the development process, moving the product quickly towards release.\nTo keep things from breaking in the customers’ hands, testers attempt to break it first - and then have it fixed.\nIn the traditional waterfall method of development, the sequence of events is:\nRequirements > System Design > Implementation > Integration and Testing > Deployment of System > Maintenance.\nThe Agile Testing Life Cycle is an iterative process that aligns with the overall Agile software development life cycle. It includes various phases that focus on continuous testing, collaboration, and improvement. Here's a breakdown of the Agile Testing Life Cycle:\nThe Agile Testing Life Cycle iterates through these phases in alignment with the development sprints, promoting continuous improvement, rapid feedback, and ongoing collaboration. This approach allows the team to adapt to changes and deliver high-quality software throughout the development process.\nThere are three simple benefits to adopting Agile testing: a happier team, a higher-quality product and faster delivery. But that trifecta is worth the effort put into developing an effective Agile testing framework.\nHowever, no system is perfect. Improperly implemented, Agile testing can weaken team structure and product development, preventing a viable product from ever being released. Even when properly used, all Agile methodologies have their weaknesses. For example, exploratory testing can lack the structure necessary to ensure a product is comprehensively tested; ATDD accounts for customer feedback, but not for business outcomes.\nThe emphasis Agile testing places on people can also be its downfall. If Agile testers are excluded from the team that they need to be closely integrated with, they are rendered useless. If a single skilled Agile tester leaves, it can prove to be a major setback for the development of the product.\nFinally, since everyone in the team performs testing, the muddied hierarchy could lead to confusion and conflict. Methodologies like Scrum attempt to circumvent this by having ‘scrum masters’, but this has the potential to fall back into a more traditional method rather than staying truly Agile.\nWhile Agile methodologies offer numerous benefits for software development, they also have some disadvantages when it comes to testing. Here are a few potential drawbacks of testing in Agile:\nIt's important to note that these disadvantages are not inherent to Agile methodologies themselves but rather potential challenges that can arise if testing is not effectively managed within an Agile context. With proper planning, collaboration, and adaptation, many of these drawbacks can be mitigated.\nWith dedication, each of these pitfalls can be overcome and the three powerful benefits experienced. The first step towards successful Agile testing is determining when Agile testing should not be used. Blind adoption of Agile testing can result in a weak, crash-prone product.\nHere are a few guidelines for cases in which Agile may not be the best way to test:\nOnce you have determined that Agile testing will benefit your team, your product and your customers, you should spend as much time as necessary to pick the right methodology and to create a process for testing using the four-quadrant model.\nTo counteract the possibility of testers' exclusion, testers should work in as close physical proximity to the developers as possible. They should meet with them often to see what they are currently working on and to give them a chance to review the tests that have been developed. Taking an iterative approach here, as well as in the testing process itself, can help connect the teams early and help with later collaboration.\nTesters can open doors for themselves by providing useful feedback based on interactions with both developers and customers. In short, they should make themselves indispensable to developers in order to be able to perform their job well.\nThe greatest thing that can be done to ensure the success of Agile testing for a product is to hire people who have the essential characteristics of an Agile tester, and to build a culture of self-organisation and independent thinking in the entire organisation.\nThat environment will naturally result in ‘stable infra’ without sacrificing speed, resulting in happier workers delivering a better, more valuable product - faster - to a satisfied customer.\nTesting in an agile environment, it's important to focus on metrics that provide meaningful insights into the quality, progress, and effectiveness of testing activities. Here are some of the most appropriate metrics to consider:\nTest Coverage: This metric measures the extent to which the test cases cover the requirements and functionality of the system. It helps identify gaps in test coverage and ensures that critical areas are adequately tested.\nDefect Density: Defect density measures the number of defects identified per unit of code or functionality. It helps assess the effectiveness of testing by indicating how many defects are found in relation to the amount of tested code.\nTest Execution Progress: This metric tracks the progress of test execution within a sprint or iteration. It provides visibility into the percentage of test cases executed and helps identify any bottlenecks or delays in testing activities.\nTest Execution Efficiency: This metric measures the ratio of passed tests to the total number of tests executed. It indicates the efficiency of the testing process by highlighting how many tests are passing successfully and how many are failing.\nCycle Time: Cycle time measures the time it takes for a user story or a task to move through the entire testing process, from creation to completion. It helps identify bottlenecks and optimize the testing workflow.\nDefect Turnaround Time: This metric measures the time taken to identify, report, fix, and retest a defect. It helps assess the effectiveness of defect management and the overall responsiveness of the team in addressing issues.\nCustomer Satisfaction: Although not directly related to testing, customer satisfaction is a crucial metric to gauge the quality of the product. Feedback from customers and stakeholders can provide valuable insights into the effectiveness of testing efforts.\nAgile Test Velocity: Test velocity measures the rate at which testing tasks or user stories are completed within an iteration. It helps the team understand their capacity for testing and provides insights into the progress of testing activities.\nEscaped Defects: Escaped defects are defects that are identified by customers or end-users after the software has been released. Tracking and analyzing escaped defects helps identify areas of improvement in testing and quality assurance processes.\nRemember, metrics should be used judiciously and in conjunction with qualitative assessments. It's crucial to select metrics that align with the project goals, adapt them as needed, and use them as a tool for continuous improvement rather than as mere performance indicators."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:f4185c5e-d8f3-4f5f-8ad5-fce95c3549d2>","<urn:uuid:6f1ef25d-80e7-4d97-9bdc-e494651ff67d>"],"error":null}
{"question":"What are the primary causes of brain damage from lack of oxygen: drowning vs other medical conditions?","answer":"Both drowning and various medical conditions can cause brain damage from oxygen deprivation. For drowning, brain damage can occur within minutes of submersion, with children being particularly vulnerable as they can drown in as little as 2 inches of water. When brain cells are deprived of oxygen for 10 minutes, severe damage occurs. Other medical conditions that can cause brain damage from lack of oxygen include heart attacks, electrical shocks, childbirth complications, carbon monoxide poisoning, choking incidents, surgical complications, and inadequate blood flow to the brain.","context":["Drowning Fact Sheet\nDrowning accidents are the leading cause of injury/deaths among children under five. A temporary lapse in supervision is a common factor in most drownings and near-drownings. Child drownings can happen in a matter of seconds–in the time it takes to answer the phone. There is often no splashing to warn of trouble. Children can drown in small quantities of water and are at risk in their own homes from wading pools, bathtubs, buckets, diaper pails, and toilets as well as swimming pools, spas, and hot tubs.\nDeath and Injuries\nA swimming pool is 14 times more likely than a motor vehicle to be involved in the death of a child age 4 and under. Each year, approximately 1,150 children ages 14 and under drown; more than half are preschoolers (ages 0-4). An estimated 5,000 children ages 14 and under are hospitalized due to near-drownings annually in the United States. Of children surviving near-drownings, 5-20 percent suffer severe and permanent disability.\nWhere Drownings Happen\nApproximately 50 percent of preschooler drownings occur in residential swimming pools. Each year, more than 2,000 preschooler near-drownings occur in residential pools. Of preschooler pool drownings, 65 percent occur in the child’s home pool and 33 percent at the homes of friends, neighbors or relatives. Each year, 350 drownings (for all ages) happen in bathtubs and approximately 40 children drown in five-gallon buckets. In ten states–Alaska, Arizona, California, Florida, Hawaii, Montana, Nevada, Oregon, Utah, and Washington– drowning surpasses all other causes of death to children ages 14 and under.\nHow and When Drownings Happen\nOf all preschoolers who drown, 70 percent are in the care of one of both parents at the time of the drowning. Of all preschoolers who drown, 75 percent are missing from sight for five minutes or less. Two-thirds of all drownings happen between May and August with 40 percent occurring on Saturdays and Sundays. It is the artificial method of circulating blood and oxygen through a body and attempting to keep the brain alive. CPR does work. When initiated within four minutes, the survival rate is 43 percent. When initiated within four to eight minutes, the survival rate is ten percent.\nWhy Learn CPR?\nOne in seven people will have the opportunity to use CPR in their lifetime. Ninety percent of the time, CPR will be done on a family member or close friend. More than 650,000 people die annually from heart attack in the United States each year. More than 350,000 die before reaching the hospital. When the brain starts to go four to six minutes without oxygen, brain damage/death begins. http://www.elcajonfirefighters.org/drownings.htm\nWater-Related Injuries: Fact Sheethttp://www.cdc.gov/ncipc/factsheets/drown.htm\nCenters for Disease Control and Prevention at Department of Health and Human Safety Overview\nIn 2003, there were 3,306 unintentional fatal drowning’s in the United States. averaging nine people per day. This figure does not include 473 drowning’s in boating-related incidents (CDC 2005).\nFor every child 14 years and younger who dies from drowning, five receive emergency department care for nonfatal submersion injuries.\nMore than half of these children require hospitalization (CDC 2005). Nonfatal drowning’s can cause brain damage that results in long-term disabilities ranging from memory problems and learning disabilities to the permanent loss of basic functioning (i.e., permanent vegetative state).\n- Drowning is the second leading cause of injury death of infants and children younger than 15 in the U.S.\n- Children less than 5 and adolescents between the ages of 15-24 yrs have the highest drowning rates\n- For every child who drowns, four children are hospitalized for near-drowning.\n- One third of near-drowning pediatric victims who are comatose on admission to the hospital will suffer significant neurologic damage\n- The annual cost of care per year in a chronic care facility for an impaired survivor of a near-drowning event is approximately $100,000.\n- The annual lifetime cost attributable to drowning and near-drowning in children less than 15 years of age is $384 million.\n- Children less than 1 year of age most frequently drown in bathtubs and buckets\n- Children between the ages of 1-4 years most often drown in home or apartment swimming pools. Most of these children drown by entering the pool from their home through the unprotected side of the pool. In the majority of cases, the children were last seen in the home, but were out of eye contact for only a moment and the immersion was silent (no screams or splashing was heard).\n- Children between 5-19 most often drown in lakes, ponds, rivers and pools.\nChildren are our precious love ones. You need a “layer system” of protection to injure their safety. Susan Reeves sent me the following information\nSecurity layers of protection (like protecting the President)\n1. Child‘s ability to swim (Rated on a scale)\n2. Device on the child (“Pool Turtles” or vest) (Pool turtles are worn\nlike a wrist watch with an alarm in the house. When the sensor gets wet –\nthe alarm sounds. The children wear these every moment they are not in\nwater, and that includes sleeping with them on.)\n3. Device in the water that detects ripples\n4. Fence layer – with lock and basic water safety equipment that consists of a pole, rope and personal flotation device (PFD). A swimming pool should always have this equipment in working condition nearby.\n5. House alarms on doors\n6. Parental Awareness/Sitter education/Visitors -“Pool Master” similar to\nlifeguard, does nothing but watch water at a party – can be rotated among\nattending adults or a teenager specially hired for the occasion. The poolmaster is needed even when the children are wearing floating devices. While personal flotation devices (PFD) are generally safe, the pool is still a place where children must be supervised. For example, if the device suddenly shifts position, loses air, or slips out from underneath, the child is left in a dangerous situation. A PFD is not a replacement for parental supervision. Never leave a child alone at the poolside\nI have also seen security cameras that monitor the pool, and the image\nappears in the corner of your computer screen.\nNever leave an infant or small child unattended in the bathroom, even for a few moments.\nTeach children water and swimming skills as early as possible\nTake special precautions if you own a pool:\nUse layers of barrier protection between the child and water to warn and impede. Pool and spa owners can take practical steps to make their pool and spa less dangerous by installing “layers of protection.” These include:\nKeep enticing objects that might attract a child out of the pool area\nDrain standing water off spa and pool covers: children can drown in as little as 2 inches of water!\nInstall a phone poolside with emergency numbers posted and programmed into speed dial. Also post CPR instructions poolside.\nJoan E writes, My sister had a pool in Melrose Park which my parents had built for their grandchildren. I would watch 11 of them all by myself! Both my sister and Henry’s sister worked, so they left their kids with me to watch in addition to our four. But one of the closest calls we had was when my sister and I were just sitting on the stairs in the her pool talking to each other, and all of a sudden my sister noticed our daughter gurgling under water looking at her, behind my back! She had taken off her safety belt and jumped in the pool!\nI was very lucky that I learned early on through all that, that DROWNING IS VERY QUIET! Since then, I have repeated that a million times to my kids and grandchildren and visitors! In the movies they always show someone sinking, splashing and screaming for help, not so! I can’t tell you the times we have had guests here, that let their little ones run around and the kids will take off their water wings or tube off, and then they forget to put them back on and then will start to get back in the pool without them.\nWhat is really scarey is that they assume the kids will know that they can’t go back in the pool without them, but there have been many times I’ve caught the children just climbing back in without their lifesavers! My own kids knew my rules and made their little ones keep the things on. That is why I always sat sitting in the direction of the large shallow kid’s end of the pool and talked to people without looking at them but kept my eyes on the children. Otherwise I was in the pool sitting and watching them. It always shocked me how easily people can forget about their little non-swimmers and be talking and looking away. I was so happy when my last of 14 grandchildren learned how to swim! I taught them all myself. It was quite an accomplishment, especialy since one grandson is a handicapped child but now is a great deep water swimmer! He loves the pool and even though he doesn’t talk much, he understood me enough to learn how to swim. I think I got them all swimming by 4 or less.\nI figured out a great method that worked so well. I would put a toy on the stairs under the water and ask them to get it. Then I put it on the next lower stair and they had to get it. I went down the stairs, and they eventually had to learn to put their faces in the water, and even open their eyes to look for it, especially because sometimes I would move it on them. THEN, finally I would get the toy on the bottom step and next the floor. Then their little rear ends would bob up trying to get down there for the toy. They found out they had to paddle and fight to get down to the bottom stair or floor, and that they didn’t just fall or sink to the bottom. And that taught them to hold their breath and keep their mouths shut. SO, then I moved the item a few feet in front of them away from the stairs, and they really had to use their arms and kick to get down there, and lo and behold, they were actually swimming! Then the farther away the item was, they naturally were diving down to get it! If you have any other little ones who still aren’t swimming, try this method. It won’t happen in one lesson, but it will pretty quickly!\nThe swimming motion actually comes very naturally. The key is they have to learn to hold their breath when they put their faces under water and open their eyes. Once they learn that, you are half way there! Your little George must have breathed in some water. It doesn’t take much, my friend lost a 3 year old who was sitting on a potty chair on the toilet while the tub was just beginning to be filled. She went to answer the door for the grocery delivery and he got off the toilet and dropped his bear into the tub and fell in after it and was gone by the time she got back upstairs and there wasn’t must water in the tub yet.!\nIn the event of a drowning–\nRemove the victim from the water, have someone call 9-1-1 or your local emergency number. Check consciousness and breathing.\nIf the victim is not breathing, open the airway and attempt\nrescue breathing.If breaths do not go in, re-tilt the head and attempt rescue breathing again. If air still does not go in, give abdominal thrusts (Heimlich maneuver) for children and adults to clear the airway.\nOnce the airway is clear, provide rescue breathing or CPR as needed.\n- Filer’s Files 37 2019 -Was a space alien killed in NJ in 1978? - September 9, 2019\n- Filer’s Files #10 – 2018 Planetary Defense - March 13, 2018\n- UFO Hunters ‘Discover’ Crashed Alien UFO Drone In NASA Mars Rover Photo - November 4, 2015","Traumatic brain injuries (TBIs) occur frequently to all age groups for a variety of reasons. If you have a brain injury, then it can change your life forever, making it difficult to attend school, work at a job or care for a family. A severe brain trauma can also leave you in a comatose condition.\nHere is a list of the most common causes of traumatic brain injuries.\n1: Vehicular Collisions Involving Automobiles, Motorcycles or Trucks\nVehicular collisions that involve automobiles, motorcycles and trucks are one of the most common causes of a brain injury. By wearing an over-the-shoulder seat belt correctly while you are driving a vehicle or riding as a passenger, you are less likely to suffer a brain injury from a collision. These safety devices can keep you from flying through a windshield or from coming into contact with the other vehicle without protection.\nIf you are using a motorcycle, scooter or other type of vehicle that is not equipped with seat belts, make sure to wear a helmet that fits correctly over your head.\nAdditional safety precautions include turning the vehicle’s lights on in the evening or during inclement weather. Make sure that you are always alert while driving a vehicle to avoid an accident and never consume alcohol or use drugs while driving.\n2: Lack of Oxygen to Your Brain from an Illness or Accident\nIf your brain doesn’t receive enough oxygen for only a few seconds, then you can incur brain damage. Lack of oxygen to the brain can occur for several reasons, including near drowning or suffocation incidences.\nAdditional reasons for lack of oxygen to your brain include:\n- An electrical shock\n- Heart attack\n- Childbirth complications\n- Carbon monoxide poisoning\n- Choking incidents\n- Complications during surgery\n- Lack of adequate blood flow to the brain\nWithin 10 minutes of having no oxygen to your brain, its cells are damaged severely. Experts know that young children are more likely to recover from brain trauma that involves cold temperatures, but this does not always prevent medical problems that require many years of treatment and therapy.\n3: Near Drowning Incidences in Swimming Pools and Other Situations\nDuring the summer, more individuals are swimming in pools or natural waterways, and this can lead to an increase in near drowning incidences. If you are underwater and unconscious for only a few minutes, then you can incur traumatic brain damage.\nChildren are more likely to experience a near drowning incident because toddlers and younger children frequently do not know how to swim, but they will enter water without adult supervision. An infant or toddler can drown in a bathtub or bucket with only a couple inches of water.\nFor instance, if a parent is using a bucket of water to pour on a garden’s vegetable plants or to wash a vehicle, then a child can fall inside and incur a traumatic brain injury. Additional causes of near drowning incidents occur in flooded regions when a driver is inside a vehicle that fills with water while trapped inside.\nIt is important to understand what to do when this situation occurs to avoid a near drowning incident, but you must act quickly.\n4: Injuries While Playing Sports at Home or School\nTo prevent a traumatic brain injury while playing sports, athletes must wear safety equipment to protect their head, face and neck. A trauma injury to your brain or neck during sports can occur when players bump into each other while running or walking.\nIn addition, a player who falls on the ground can experience an injury from having someone walk on his head or neck. Hard flying projectiles such as footballs or soccer balls can also damage your brain or neck. Players who are swinging baseball bats or tennis rackets can hit someone in the head, causing a brain trauma.\nFor information about TBI, check out these Common Symptoms of Brain Trauma."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:730adaab-db58-4d00-8e94-f561d774d575>","<urn:uuid:079317f6-aaae-4bfc-96cb-2962b2a658ce>"],"error":null}
{"question":"Can directors face personal liability for privacy breaches under new laws in Quebec vs Australia?","answer":"In Quebec's Bill 64, the focus is on organizational liability with penalties applying to companies and no explicit mention of director liability. In Australia, while the Privacy Act itself only imposes penalties on corporations, regulators can hold directors personally liable under their duty of care, skill and diligence established by the Corporations Act 2001. Australian directors' failure to implement privacy compliance procedures may constitute a breach of their duties to the company.","context":["Privacy protection in Quebec: an overview of amendments to the law governing the private sector\nI. Modernizing privacy legislation\nOn June 12, the Quebec government introduced bill 164, An Act to modernize legislative provisions as regards the protection of personal information (“the Bill” or “Bill 64”), first announced nearly a year ago. Once adopted, the Bill will result in significant changes to various laws in order to modernize the regulatory framework for the protection of personal data in Quebec.\nThe modernization process will target private and public sector institutions as well as political parties, and will require compliance efforts by all these organizations. Indeed, the nature of the new requirements and the hefty penalties for violations mean that privacy protection can no longer be ignored with impunity.\nAmong other things, the Bill proposes granting new rights to individuals regarding data portability, the right to be forgotten and the right to de-indexation. In order to implement and uphold these rights, many companies will have to modify their business processes or adopt new ones.\nOur team can assist with this exercise by analyzing your existing processes, identifying gaps and formulating implementation recommendations to comply with the amended law.\nWe begin this series of publications about the Bill with an overview of the key amendments to the Act Respecting the Protection of Personal Information in the Private Sector (“PPIPS” or the “Act”), which applies to any business operating in the province.\nThe scope of the Act will remain essentially unchanged as far as businesses are concerned. However, the Bill states that:\n- the personal data concerned includes personal data collected by the company, even in instances where it is stored by third party.\n- information relating to job title function (name, title, business address) will no longer be subject to the PPIPA; this puts an end to the divided case law from the Commission d’accès à l’information (CAI) regarding the characterization of business contact information as personal information.\nThe Bill explicitly introduces the principle of accountability by the company collecting the data, which is one of the basic principles of privacy protection.\nMost significantly for businesses, the responsibility for the protection of personal information, or role of “Chief Privacy Officer”, will now rest with the highest ranking officer of the company. This person will now be responsible for the implementation of, and compliance with the provisions of the Act. Contact details for this person or the person to whom the role is delegated will have to be published on the company’s website or, in the absence of a website, made available through other means.\nBill 64 proposes that all companies be required to adopt governance policies and practices to ensure that personal data is protected. These policies and practices should provide a framework for the following aspects, among others:\n- data retention and destruction;\n- staff member roles and responsibilities;\n- a complaints process.\nWithin the governance component, the Bill also establishes a requirement for the organization to conduct a risk assessment for any project involving the collection or use of personal information. As with any obligation of this type, organizations will need to generate and maintain adequate documentation.\nThe future Section 3.3 also introduces the requirement to ensure that the collected data is portable and can be made available in a valid format.\nThe Bill also clarifies the concept of consent for the collection and use of personal information.\n- Consent must be manifest, free, informed, solicited for specific purposes and separately from any other information provided;\n- For sensitive personal information, i.e. information that entails a high level of reasonable expectation of privacy, the consent must be express.\n- Under the proposed provisions, the secondary use of personal information will be permitted without the prior consent of the person concerned, as long as:\n- the use is for purposes consistent with those for which it was collected (and not for commercial or philanthropic prospection, which are specifically excluded);\n- the use is for the benefit of the person concerned;\n- the use is necessary for study or research or for the production of statistics, and the information is de-identified (i.e. no longer directly identifies the person concerned).\nThe Bill proposes to broaden the information to be disclosed at the time of collection as well as the company’s obligations in this regard.\n- In addition to specifying the purpose of the collection, the company will need to specify:\n- the means used;\n- the person’s right to withdraw consent;\n- where applicable,\n- the name of the third party for whom the data is being collected;\n- the possibility that the information may be transmitted outside Quebec.\n- Bill 64 proposes to end the exception provided for in the PPIPS for the collection, use and disclosure of personal information for commercial or philanthropic purposes. In fact, any organization using personal data for such purposes will have to disclose it, and the person concerned will have the option to withdraw his or her consent to such use.\nThe Bill requires that organizations disclose, in advance, their use of technology that can identify, locate or profile users, and then provide users with the means to disable the identification, location or profiling features.\nThe following definition for the term “profiling” has been suggested: “the collection and use of personal information to assess certain characteristics of an individual, in particular for the purpose of analyzing that individual’s work performance, economic situation, health, personal preferences, interests or behaviour.”\nThe Bill proposes clarifications to the rules applicable to the disclosure of personal information collected to service providers.\nSuch disclosure will be subject to certain conditions, including that any such service provider have measures in place to maintain the confidentiality of the information.\nThe Bill also proposes to fill a significant gap by expressly introducing an exception to allow the release of personal information in the course of a commercial transaction, as permitted under other Canadian laws.\nThe Bill reinforces the rules governing the cross-border transfer of personal information by businesses. These rules are currently set out in PPIPS sections 17 and 20.\n- Before communication of any information outside Quebec, a business will have to conduct an assessment of the following privacy-related factors:\n- the sensitivity of the information;\n- the purpose for which it will be used;\n- the applicable security safeguards;\n- the legal regime in the jurisdiction, and particularly its degree of equivalence with respect to the principles governing privacy protection in Quebec.\nIf the assessment shows that the level of data protection would be equivalent to that in Quebec, and subject to the conclusion of a written agreement, the data may be disclosed.\nFor the greater benefit of businesses, the government is following the European Union’s approach and has announced that the minister will publish a list of jurisdictions with legal frameworks deemed to be equivalent.\nThe Bill clarifies that organizations may either destroy personal information or anonymize it; the latter option allows organizations to retain information when the purposes for which it was collected or used are achieved (subject to statutory retention periods).\nThe Bill finally introduces mandatory breach notification in the event of a breach of security safeguards involving personal information. Since 2011, the Commission d’accès à l’information (CAI) has been recommending such a notification obligation, and this is in keeping with the obligations imposed by the Canadian Parliament and the European Union, both of which adopted mandatory notification programs in recent years.\nHere are the key points to bear in mind:\n- The term “confidentiality incident” includes:\n- unauthorized access, use or release of personal information;\n- loss of personal information or any other breach in the protection of that information.\n- When there is reason to believe that a breach involving personal information has occurred, the organization must take reasonable steps to reduce the risk of injury and to prevent new incidents of the same nature.\n- In the event of an incident involving a risk of serious harm, the organization must notify the CAI, as well as any person whose personal information is concerned by the incident.\n- To guide businesses in determining the risk threshold, the Bill lists the factors to be considered in assessing the risk of harm:\n- the sensitivity of the information;\n- the anticipated consequences of its use;\n- the likelihood that it will be used for injurious purposes.\n- The content and method of the notices will be determined by regulation.\n- All companies must maintain a record of every breach of security safeguards, which must be sent to the CAI upon request. This register can prove very useful in carrying out due diligence on a supplier or an acquisition target.\n- The CAI will have the power to order the performance of any measure aimed at protecting the rights granted to affected persons under this law, for the time and under the conditions the Commission determines.\nOrganizations that collect personal information through technological products or services will now have to ensure that the parameters of the product or service provide the highest level of confidentiality by default. This will entail changes to the digital application deployment process.\nThe modernization effort also takes into account the deployment of applications supported by artificial intelligence. The Bill proposes that, when a decision is based exclusively on automated processing, the organization must inform individuals affected by that decision of the parameters used in the decision process and of the procedure for requesting that a staff member review that decision.\nSection 28.1 proposes recognizing an individual’s right under certain circumstances to require an organization to cease distributing personal information about him or her and to de-index any hyperlink that provides access to that information, particularly if such a distribution contravenes the law or a court order.\nA person could also make such a request when the following conditions are met:\n- the dissemination of this information causes the person serious injury in relation to the person’s right to respect of his or her reputation or privacy;\n- the injury is clearly greater than the public interest in knowing the information or the right to free expression (the balance of convenience criterion);\n- the remedy requested does not exceed what is necessary to prevent the perpetuation of the injury.\nIn assessing the balance of convenience criterion, the following, in particular, must be taken into account:\n- the person’s notoriety;\n- if the person is a minor;\n- the accuracy of the information being disseminated;\n- the sensitivity of the information;\n- the context in which the information is disseminated, and the time elapsed between the beginning of the dissemination and the request to halt it.\nThe Bill also provides an exception for the release of personal information to a spouse or close relative on the death of a person. This exception to non-disclosure applies when the disclosure is likely to assist the applicant in the grieving process. Furthermore, the deceased person must not have refused such right of access before his or her death.\nFinally, the Bill’s adoption will significantly strengthen corporate accountability by levying hefty fines for violating the law and imposing administrative penalties for failing to meet the obligations specified in the PPIPS.\n- First, concerning the administrative penalties, Bill 64 stipulates that these may be imposed, inter alia, when someone collects or uses personal information in contravention of the provisions of PPIPS or fails in his or her duty to report a confidentiality incident.\n- Bill 64 gives the CAI a mandate to develop a general framework for the application of these administrative penalties, which should specify the following elements in particular:\n- the objectives associated with the implementation of such a regime;\n- the criteria that must guide the decision-maker in imposing a penalty, including:\n- the seriousness of the violation;\n- the sensitivity of the information;\n- the number of people affected;\n- the measures put in place to remedy the violation;\n- the level of cooperation demonstrated by the organization;\n- the compensation offered to the individuals affected.\n- The maximum amount of the administrative penalty is $50,000 (for individuals) and $10,000,000 (for businesses) or, if greater, 2% of worldwide turnover for the preceding year.\n- Bill 64 also modifies the penal penalties already prescribed in PPIPS and significantly increases their scope. For a corporation, a violation of the PPIPS will result in a fine ranging between $15,000 and $25,000,000 or, if greater, 4% of worldwide turnover for the preceding year. In the event of a subsequent offence, the fines are doubled.\n- The offences covered by the penal regime include any collection, possession, release or use of personal information that is contrary to the dictates of PPIPS or any failure to report a confidentiality incident.\nFinally, Bill 64 establishes a right for persons affected by an unlawful infringement of the rights conferred by the PPIPS to sue the non-compliant organization for damages. It provides for punitive damages of at least $1,000 to be awarded where the infringement is intentional or the result of gross negligence.\nBased on our preliminary analysis, the adoption of the rules proposed in Bill 64 would ensure consistency with the provisions of the General Data Protection Regulation (GDPR).\nThe Bill currently provides for a one-year transition period between its adoption and the coming into force of the new provisions, except for the right to portability, for which the Bill proposes a three-year deferral of implementation.\nGiven the number of proposed changes and new requirements, such periods are needed to allow companies to review their current practices, identify gaps and implement the necessary changes to ensure compliance.\nTo view the article with footnotes, click here.","13 Aug Is non-compliance with the Privacy Act a breach of directors’ duty?\nOrganisations subject to the Privacy Act 1988 (Cth) may receive a penalty for privacy breaches. However, can a director also be personally liable for a privacy breach?\nWhat does the Privacy Act say?\nThe Notifiable Data Breaches (NDB) scheme, introduced on 22 February 2018, requires organisations subject to the Privacy Act to notify affected individuals and the Office of the Australian Information Commissioner (OAIC) when a data breach is likely to result in serious harm to an individual whose personal information is involved.\nSerious or repeated failure to comply with the Privacy Act, or interference with an individual’s privacy, may result in civil penalties of up to 2,000 penalty units (approximately $420,000).¹ A failure by an entity to meet any of the requirements of the NDB scheme is an interference with the privacy of an individual.² Legislative amendments are currently being drafted to raise the amount of fines for failure to resolve minor privacy breaches (see New Privacy Laws to be introduced in 2019).\nThe OAIC is also required, in most circumstances, to investigate a complaint made by an individual about an interference with the individual’s privacy,³ which would include a failure to notify an individual at risk of serious harm of an eligible data breach where required to do so.\nThe Australian Competition and Consumer Commission’s (ACCC) most recent report calling for higher penalties for breaches of the Privacy Act and the introduction of a new privacy code for digital platforms has been accepted outright by the government.\nDirectors owe a duty of care care, skill and diligence to their company. This is reinforced by section 180(1) of the Corporations Act 2001 (Cth).\nWhile the Privacy Act grants Courts the power to impose civil penalties for contraventions of the NDB scheme on corporations only, regulators are taking a wider approach to hold directors personally liable for failing to observe a company’s breaches of the Privacy Act and non-compliance with the new NDB scheme. Under the ASIC Act,⁴ a body corporate could be fined a maximum of 10,000 penalty units ($2,100,000).\nAs an example, HealthEngine, Australia’s biggest medical appointment booking app, is currently facing multi-million-dollar fines from the ACCC for selling patient data to law firms and insurance brokers in exchange for payments. The Company also faces separate investigations by the OAIC and the Australian Digital Health Agency. Time will tell if the company’s directors themselves will be held personally liable for allegations of such serious misuse of patient data.\nA director’s failure to implement compliance procedures for data and privacy protection may constitute a breach of their duty of care, skill and diligence owed to the company.\nDirectors, therefore, need to ensure that the company’s privacy policies, cyber security measures and appropriate data breach notification training are in place to comply with the Privacy Act and fulfill their directors’ duties.\nDISCLAIMER: We accept no responsibility for any action taken after reading this article. It is intended as a guide only and is not a substitute for the expert legal advice you can get from marshalls+dent+wilmoth and other relevant experts.\n¹ Privacy Act s13G.\n² Privacy Act s13(4A).\n³ Privacy Act s36.\n⁴ ASIC Act 2001 (Cth) s12GB(3)."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:49ad3ab8-4576-49c4-a731-39d1c07baa27>","<urn:uuid:73a1e4e0-72ba-47eb-a357-94ae6be19e4a>"],"error":null}
{"question":"What's the key difference between traditional passenger data collection methods and new security screening technologies in terms of accuracy?","answer":"Traditional passenger data collection methods (surveys, observations) have intrinsic limitations like incorrect answers and dependency on interviewee availability, while new security screening technologies like security scanners provide more accurate and reliable detection capabilities for both metallic and non-metallic threats, processing up to 240 passengers per hour with improved precision through automated target recognition.","context":["The paramount goal of the European transport policy, as defined in the European Commission’s 2011 White Paper on Transport, is to “establish a system that underpins European economic progress, enhances competitiveness and offers high quality mobility services while using resources more efficiently”. In line with these objectives, the long-term vision for the European aviation sector outlined in the report ‘Flightpath 2050 - Europe’s Vision for Aviation’ envisages a passenger-centric air transport system thoroughly integrated with other transport modes, with the ultimate goal of taking travellers and their baggage from door to door predictably and efficiently while enhancing passenger experience and rendering the transport system more resilient against disruptive events.\nIn contrast with this high-level vision, ATM operations have so far lacked a passenger-oriented perspective, with performance objectives and decision criteria (e.g., flight prioritisation rules) not necessarily taking into account the ultimate consequences for the passenger. Further research is needed to provide new insights on the interactions between the ATM system and passengers’ needs, choices and behaviour. However, current methods used to collect data on passengers’ activities are limited in accuracy and validity: traditional methods based on observations and surveys present intrinsic limitations (e.g., incorrect and imprecise answers, dependence on the availability and willingness to answer of the interviewed persons, etc.), and they are also expensive and time-consuming; useful data can also be collected from other sources such as air traffic databases, travel reservation systems or market intelligence data services, but these data typically fail to capture important information, such as door-to-door origin-destination pairs and travel times. The generalised use of geolocated devices in our daily activities opens new opportunities to collect rich data and overcome many of the limitations of traditional methods. The very same ICT tools that are enabling new forms of bidirectional communication with the passenger are also making it possible to gather permanently updated information on passengers’ activity and mobility patterns, with an unprecedented level of detail.\nThe goal of BigData4ATM is to investigate how different passenger-centric geolocated data can be analysed and combined with more traditional demographic, economic and air transport databases to extract relevant information about passengers’ behaviour, and to study how this information can be used to inform ATM decision making processes. The specific objectives of the project are the following:\nto develop a set of methodologies and algorithms to acquire, integrate and analyse multiple distributed sources of non-conventional ICT-based spatio-temporal data — including mobile phone records, data from indoor geolocation technologies, credit card records and data from Internet social networks, among others — with the aim of characterising passengers’ behavioural patterns;\nto develop new theoretical models translating these behavioural patterns into relevant and actionable indicators for the planning and management of the ATM system;\nto evaluate the potential applications of the new data sources, data analytics techniques and theoretical models through a number of case studies relevant for the European ATM system, including the development of passenger-centric door-to-door delay metrics, the improvement of air traffic forecasting models, the analysis of intra-airport passenger behaviour and its impact on ATM, and the assessment of the socio-economic impact of ATM disruptions.\nTo find more about the project, download the BigData4ATM Position Paper.","Smart Security, a joint initiative of the International Air Transport Association (IATA) and Airports Council International (ACI), envisions a future where passengers proceed through security checkpoints with minimal inconvenience, where security resources are allocated based on risk, and where airport facilities are optimised, thus contributing toward an improved journey from curb to airside. Guido Peetermans looks at the progress being made, and reports on innovations that may soon be coming to an airport near you.\nAirport security checkpoints are a critical element of the aviation security system, and in the face of an ever-evolving threat picture, authorities and front-line staff are working hard every day to stay ahead of people with malign intent.\nThat doesn’t mean though that security measures necessarily have to be disruptive to efficient airport operations or a major stress factor for the passenger. In fact, it is entirely within the realm of possibilities to design checkpoints that are highly effective in detecting threats, while at the same time processing higher numbers of passengers and reducing the hassle factor.\nUnder the Smart Security programme, the International Air Transport Association (IATA) and Airports Council International (ACI) have been working with forward-thinking governments, airports, airlines, and solution providers to demonstrate the viability of innovative concepts and technologies that will contribute to more effective security, increased operational efficiency and an enhanced passenger experience.\nFor most passengers, the idea of passing through airport security with minimal interruption may appear to be far removed from everyday reality, but in fact great strides have already been made to turn this compelling vision into reality, and a new wave of innovations is on the verge of maturity.\nTraditionally, passenger screening processes focused mostly on the detection of metallic threats using walk-through metal detectors (WTMDs). In many jurisdictions, these have now been supplemented with manual pat-downs and/or additional measures such as explosive trace detection (ETD) swab tests.\nSecurity scanners provide a readily available alternative, which addresses metallic and non-metallic threats in a single process while better respecting the privacy of passengers thanks to the anonymised format of images and automatic target recognition, allowing for targeted search and thus reducing the need for full body pat-downs.\nSmart Security trials have demonstrated that up to 240 passengers per hour can be processed with a single security scanner in a sustainable manner; through the utilisation of multiple resolution screens, this number can be further increased. Hence, in most operational environments, this type of equipment can be deployed as primary screening device without negative impact on throughput; where higher throughput is required or where other factors come into play, these systems can be deployed as a secondary screening method. Either way, they will increase the detection capability compared to a conventional setup with WTMDs, without negative impact on operational efficiency, and while enhancing the passenger experience.\nOver time, detection capabilities will further improve while false alarm rates will drop, largely due to the evolution of detection and decision support algorithms. We expect to see standards emerge that will enable decoupling of hardware and software, which will spur even more innovation in this area.\nDue to current limitations of some passenger screening equipment, in some jurisdictions passengers still need to remove their shoes for screening. As simple as this requirement might seem, it negatively impacts passenger experience and is disruptive to the process. With the emergence of new technologies such as non-touch ETD, it should be possible to find an effective solution to this problem.\nIn the longer term, the combination of different technologies into a single piece of screening equipment will open the door to material discrimination (i.e. detecting the nature of the objects found) and an overall improved detection capability in the face of ever-evolving threats.\nCabin Baggage Screening\nConventional stand-alone, single-view X-ray equipment has been the standard for a long time, and the effectiveness is highly dependent on the operators’ training and experience. Multi-view X-ray equipment, which is increasingly prevalent, provides the operator with more information by showing multiple viewing angles of the same bag or tray. The capabilities of these systems are now expanding, and enabling the deployment of advanced equipment intelligence – but thus far this hasn’t led to a reduction in divestment requirements."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:661abfea-cb39-4533-90c9-ecce3d5db109>","<urn:uuid:f48573a0-6e57-4c62-861e-18639a1b5972>"],"error":null}
{"question":"How do sporting venues incorporate local cultural elements in their branding, and what technological infrastructure is required for safe event management?","answer":"Sporting venues incorporate local cultural elements through targeted branding, as exemplified by Traverse City's baseball team being named the Pit Spitters to reflect the region's cherry-growing heritage, with their logo cleverly integrating local geographic features like Michigan's peninsulas using baseball and cherry imagery. For safe event management, venues must implement comprehensive technological infrastructure including CCTV-equipped control rooms, dedicated wireless systems, GPS-enabled instructions, RFID/app-based visitor tracking, sensor systems for monitoring heat/smoke/noise levels, and data analytics capabilities for crowd simulation. They should also maintain dedicated websites and social media accounts for authentic information dissemination and use SMS and pre-recorded voice messages for important announcements.","context":["Click to enlarge\nThe area around Traverse City, Mich., is known as the Cherry Capital of America (the local airport is even called Cherry Capital Airport), which explains yesterday’s announcement that the town’s new baseball team, slated to play in the college summer/wood-bat Northwoods League, will be called the Traverse City Pit Spitters.\nOn some level, this is just another boilerplate Brandiose treatment (furrowed-brow mascot, overly thick black lines — check and double-check), but I really like this one. For one thing, pit-spitting is actually a thing in northern Michigan (additional info here and here). For another, I love how the secondary logo shown at top-right uses a baseball glove and some cherry leaves to simulate Michigan’s lower and upper peninsulas. Michiganders often refer to the Lower Peninsula as “the Mitten,” so depicting it as a baseball glove is a clever move. And I’m a fan of just about anything that acknowledges the U.P., which is the most inconspicuous and underappreciated part of the lower 48 states.\nI’d like all of this even more if the mascots were more smile-y and less furrowed-brow-y. Still, this is a Brandiose package I can get behind.\nClick to enlarge\nNew ESPN column: My annual Uni Watch Super Bowl Preview will be published today, with lots of uni-related tidbits about this Sunday’s big game (including the fact that the Rams will be wearing the same uniform they wore in the Super Bowl in the 1978 movie Heaven Can Wait, as shown above).\nLink coming soon. Update: My editor just told me that publication has been pushed back to tomorrow. Sorry for the false alarm.\nGoing out on top: Journeyman catcher Jarrod Saltalamacchia has retired. When he debuted with the Braves in 2007, his 14-letter surname set the record for the longest NOB in MLB history. Twelve years later, he still holds that record.\nSalty played for seven teams during his MLB career (none of which, happily, was the Yankees). You can see how all seven of those teams squeezed his name onto the back of a jersey in this Uni Watch post from 2017.\nThis gives me an excuse to once again post the photo of former A’s farmhand Eric Stuckenschneider’s spring training nameplate. Stucky would have beaten Salty by two letters, but he never made it to the bigs (click to enlarge; R.I.P., Tucker):\nClick to enlarge\nWinter (Olympics) wonderland: Reader Steven Marks visited the Lake Placid Olympic Museum earlier this month and photographed a bunch of cool stuff (including the 1952 Team USA jacket shown above).\nOne of the more interesting displays was this set of wings, which Olympic torch bearers wore in 1980 (click to enlarge):\nYou can see all of Steven’s photos here.\nRaffle reminder: The good folks at Vintage Brand are using the week leading up to the Super Bowl to run another raffle. The lucky winner will get to choose any item from the Vintage Brand site (like the cool Rams canvas shown above, for example).\nTo enter, send an email to the raffle address by this Thursday, Jan. 31, 7pm Eastern. One entry per person. I’ll announce the winner on Friday. Good luck!\nBy Lloyd Alaban\nBaseball News: The Rangers posted a cryptic tweet of two people poring over colored fabric swatches. Could there be a uniform overhaul in the works? (From Jay Burnam.) … Mets P Noah Syndergaard has a pinstriped Mets bathrobe, complete with his number on it (from Jason Criss). … @BSmile found this gif of Pirates SS Honus Wagner in a sharp-looking sweater. … The Fresno Grizzlies, Triple-A affiliate of the Nationals, have a new look (from multiple readers). … Last week, we ran a Ticker item that showed a collage of minor league hats forming the alphabet. Every letter was accounted for except “U” and “X.” Well, now we have all 26 letters (from Malcolm McMillan)! … New uniforms for Gonzaga (from multiple readers). … New unis for Youngstown State. … Cal baseball has raised batting helmet logos decals (from Gilbert Lee). … The Richmond Flying Squirrels, Double-A affiliate of the Giants, will wear cat-themed jerseys for a game in April. Fans will get to vote on which cat will be on the jersey, with proceeds from going to the Richmond SPCA (from Aryn Keen). … The Reading Fightin Phils, Double-A affiliate of the Phillies, will become the Reading Pretzels for select games this season. … Here’s an old photo of the late Rodney Dangerfield in a full Mets uni, next to fellow actor Paul Newman (from Matthew Wilemski). … Ted Bundy is wearing a Mariners T-shirt in this screenshot from the Netflix documentary Conversations with a Killer: The Ted Bundy Tapes (from Ian Irwin). … New uniforms for Arizona softball. … New uniforms for the Japanese team Chunichi Dragons (from Graveyard Baseball). … Here’s some old video footage of Mariners P Matt Young wearing No. 1.\nNFL/CFL News: Randy’s Donuts in Inglewood, Calif., painted their famous donut-shaped sign in Rams blue and yellow ahead of the team’s appearance in the Super Bowl. Too bad about the Nike logo (from Andy Garms). … Thanks to Richard Stover, who sent us this picture of a Patriots-themed buoy he took near Scituate and Marshfield, Mass. … According to this tweet, the NFL is considering allowing teams to use tinted visors in-game for the 2019 season (from @WolfeNorthwest). … Looks like the Chiefs may be modifying their Lamar Hunt perma-memorial patch to do double duty as a 60th-season patch next season (from Todd Engle). … This vintage Saints pennant features a haloed Saint — a mascot trope that the team has rarely used (from Russell Goutierez). … Here’s a rare shot of Broncos RB Floyd Little wearing the team’s 1966 uniform. Little was drafted in ’67, so he never wore that uniform in a regular season game, but the team re-used its ’66 unis in the ’67 preseason. … An artist has developed a series of NBA City Edition-inspired NFL jersey concepts (from Taylor Brandine). … A buddy of Bill Schaefer came across this ad featuring the Saints’ black helmet. He says that other papers had the same ad so it was likely a nationwide campaign. … Gregg Elkin found these CFL stickers in a set of Legos he gave to his son. … Here’s a Media Day shot of former Giants TE Howard Cross — the only Giant to play for both the 1990 and 2000 NFC Championship teams — in a gorgeous varsity jacket (from Mike Colvin). … The AAF has been holding scrimmages, which have provided us with our first look at how the league’s uniforms look on the field.\nHockey News: Reader Greg Enright sent us this article about the Penguins changing from double-blue to black and gold in the middle of the 1979-80 season. There are lots of neat little details, including the Bruins protesting the move and the Pens ordering their new unis from the Bruins pro shop. … Speaking of the Pens: Former C and current owner Mario Lemieux wore a gold, logo-accurate jersey for his fantasy camp (from Jared Grubbs). … The Kootenay Ice of the Western Hockey League are moving to Winnipeg to become the Winnipeg Ice. Their logo will remain the same — including the hidden “ice” lettering on the left side of the logo (from multiple readers). … Here’s a “How It’s Made” segment about the production of goalie masks (from Wayne Jones).\nNBA News: Nets PG Shabazz Napier made a three-pointer with one-and-a-half shoes last night (from Chris Chmura). … The uniforms for the Rising Stars game during All-Star weekend in Charlotte will be based on the Carolina Cougars’ 1970s unis — which, in case you’ve forgotten, looked like this and this (from Chris Marsicano). … Cross-listed from the football section: An artist has developed a series of NBA City Edition-inspired NFL jersey concepts (from Taylor Brandine). … Lincoln Prep High School in Kansas City, Mo., is poaching the Warriors’ logo (from Ryan Atkinson).\nCollege Hoops News: Here are retail shots of Kansas men’s new uniforms (from Across the State Line). … Here’s a new state-flag-themed uniform for Nevada men’s. … If you’re a follower of Kentucky men’s basketball, you’ve probably noticed some of the players wearing bright, mismatched, multi-colored sneakers. Here’s the story behind them (from Josh Hinton). … Maryland wore red at home against Northwestern last night, and the cheerleaders wore Spider-Man-themed uniforms (from Matt Shevin). … Jeff Flynn found this misspelled Pitt jersey worn by former G Trey Ziegler. … @run_100mi Michigan players have a bump between their shoulder blades. Luke Aaron says it’s a GPS tracker. … Mississippi State G Nick Weatherspoon is blaming the team’s shooting troubles on Nike balls. State uses an Adidas ball for home games but has to use other balls when playing on the road against a Nike- or Under Armour-outfitted team (from Joey Harvey).\nSoccer News: New kits for the Portland Timbers (from Jason Schwanz). … It looks like Atlanta United D Franco Escobar has leaked the club’s new shirt. The caption reads, “If we’re talking about perfection…” in Spanish (from Austin Perry). … The new USL Championship franchise set to play in the Oakland area has filed a trademark for “East Bay Tempo FC” (from Josh Hinton).\nGrab Bag: Nike is being accused of “insulting Islam” by releasing an Air Max shoe logo that looks like “Allah” in Arabic (from J. Max Weintraub). … Washed Up Goalie showed us this beautiful letterman sweater from the early 1970s. … An increasing number of curling teams are wearing helmets (from Ted Arnold).","While planning for large events the management needs to take note of (i) type and duration of event, (ii) size of the expected crowd, gender, and age profile of attendees, and (iii) locational characteristics.\nThe event organizers have to accordingly plan, rehearse and undertake safety drills with the help of police, fire, health, forest, revenue, and public works departments. For example, in a religious events, depending on the estimated crowd size, duration of the mela or darshan can be extended to avoid a larger gathering.\nVolunteers and others for help\nHelp of volunteers os often taken for organising various events. It is important to take care of the following:\n- Uniform, and identity cards for volunteers for ease of recognition.\n- Crowd management training; how to frisk visitors, how to operate metal detectors, how identify trouble makers, and suicide bombers.\n- Ensure that they frisk bidi, cigarette, match box, lighter, and others to avoid fire incidence.\n- First aid training including triage, CPR, handling and transport of injured for paramedics.\n- Putting in place disaster protocol, and standard operating procedure (SOP) for all nearby by hospitals.\n- Central control room equipped with CCTVs to monitor, and spot crowd buildup areas.\n- Loud speakers, and public address systems for making important announcements, and keeping masses informed.\n- Temporary observation towers, if required.\n- Deployment of UAV / drones for monitoring crowd movement, crowd density, and risk.\n- Dedicated wireless system for communication between personnel.\n- Traffic congestion delays response, rescue, and relief operations.\n- Coordinate with railway, transport department, and private bus operators.\n- Charge high entry, and parking fee to discourage private vehicles.\n- Provide shuttle bus service between venue, and the nearest railway station, and bus terminal to ensure rickshaws, and taxis do not crowd the venue.\n- Ensure strict enforcement of traffic, and parking rules even for VIPs.\nEntry tickets and display\n- Provide seat numbers, and entry passes. General admission makes crowd control, and movement of people difficult.\n- Assign parking, and seating arrangements with colour coded path ways.\n- People often ignore written instructions, and keep asking volunteers. Arrangement should therefore be made for regular multi-lingual announcements, particularly related to crowd movement. This would facilitate effective communication even for the illiterates.\n- Accordingly, multilingual sign-boards or display boards should be put up to disseminate information about entry, and exit routes, food, water, and rest room facilities, help desk location for lost, and found items, and children.\nPathways and hawkers\n- Hawkers, and sellers should be prohibited in corridors, and pathways.\n- Sale of cigarettes, and all tobacco products should be prohibited.\n- Hawkers should not be allowed to use stoves, loud whistles, scary masks, fire crackers, and other such items that could be misused by miscreants to scare people.\n- Hawkers should be allowed at exit points rather than at entry points.\n- If the shrine is atop a hill, or in the mountains, there should be separate track for pedestrians, and ponies or horses.\n- There should be adequate facilities for light, ventilation, drinking water, and toilets- along the pathways.\nEntry – exit barricades\n- Doors must not be suddenly opened, or suddenly closed.\n- Multiple exits must be provided.\n- Routes of ingress, and egress must be separate.\n- Entry, and exit points must have strong but non-permanent, and manoeuvrable barricades. The barricades should not have strong metal spikes; else these might cause injuries during stampede.\n- Strict adherence should be maintained to time, and punctuality as delay causes anger, and restlessness in the crowd.\nFreebies, autographs and others\n- There should be multiple, and well distributed points for freebies, if any.\n- Volunteers should ensure that a single distribution point is not overcrowded.\n- The freebies should never be allowed to be thrown randomly at the crowd, like SRK did at Vadodara railway station during the promotion of his film Raees.\n- Celebrity should not be allowed to mingle with the crowd as it might (i) compromise personal security, and (ii) trigger rush of people for his glimpse or autograph.\n- Number of persons should be strictly limited in accordance with the bearing capacity of podium, lift or temporary stairs.\nElectric and fire hazard\n- Kitchen, and cooking facilities should be away from the main event.\n- Proper care should be taken in handling LPG stoves, firewood, and electric fitting.\n- Circuit breakers, fuse boxes, switchboards, fuel tanks must be kept in isolated location with security guard.\n- Electrical wires should be underground, or overhead, and always away from the pathways to minimise tripping hazards.\n- Appropriate fire extinguishing equipment should be kept ready with trained personnel.\n- Dustbins should be provided, and there should be no littering, particularly of food items that could attract dogs, monkeys, and elephants.\nUse of S&T and ICT\n- Use of Aadhar linked barcoded passes, together with authentication at both entry, and exit points would ensure exact details of persons actually present at the venue at the time of the disaster.\n- This data can be utilised for crowd characteristics assessment, and providing specialized facilities or assistance, if required.\n- Special applications could be crated for digital entry pass, and GPS enabled instructions for parking, and entry – exit points.\n- With the use of RFID or App based visitor passes real time monitoring of crowd buildup can be resorted to, and accordingly necessary preventive measures can be put in place.\n- Sensors can be installed to monitor heat, smoke, and noise levels at various points, and data from these could be utilised for estimating crowd buildup.\n- CCTV, UAV, and drones can be utilised for crowd monitoring.\n- Data collected during the event could be used later for big-data analytics with crowd simulation. This would help in effective management of future events.\n- Use of SMS, social media, prerecorded voice mails to communicate, and disseminate important information.\n- Use of dedicated website, social media account, toll-free IVRS number to disseminate authentic information, and to prevent rumor mongering.\n- Used of RFID, and barcode together with photographs for the identification of dead bodies, and personal belongings.\n- Logistics: material, medicine, blood donors, inventory management, and personnel management – all could be managed efficiently using ERP software.\nDM after stampede\n- Event volunteers, and paramedics to commence rapid triage, first aid, and referral of injured.\n- Distribute patients to earmarked hospitals in a coordinated manner, so that relatives do not face inconvenience in locating them.\n- A control room,and helpdesk to handle all the inquiries.\n- Police personnel, and relief workers to ensure proper tagging, documentation, and safe custody of personal belongings of victims.\n- Psycho-social supportbe arranged for the survivors, and the persons who lost their loved ones."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:2216d1d9-5fe4-4598-b2c4-988854e18958>","<urn:uuid:3e782f37-a547-440f-92b8-c7ad10b9b454>"],"error":null}
{"question":"Having recently returned from Africa, I noticed the challenges in disease diagnosis - could you compare how bacterial infections are detected in Praesens Foundation's mobile labs versus the diagnostic approach for traveler's diarrhea in traditional settings?","answer":"The diagnostic approaches are quite different. The Praesens Foundation emphasizes rapid, accurate, and easy-to-use diagnostics that can be deployed close to affected communities, using innovative technologies in their mobile labs. They focus on providing field-applicable technologies that local health workers can use long-term. For traveler's diarrhea, diagnosis is typically based on symptoms (such as abdominal cramps, dehydration, fever) and travel history to high-risk areas, rather than immediate laboratory confirmation. The bacterial causes (like E. coli, Campylobacter, Shigella, or Salmonella) are often assumed based on clinical presentation rather than real-time testing, and treatment begins before definitive laboratory confirmation.","context":["WHAT WE DO\nPast and recent disease outbreaks (e.g. SARS, MERS, Ebola, Zika, Dengue) have shown that infectious diseases constitute to affect lives of people while also representing national, economic and health security threats that can quickly evolve into global health crises. In essence, current (international) responses are mostly reactive in nature, often operating in ‘crisis’ mode with little or no preparedness, standard procedures, trained personnel or appropriate equipment and tools, resulting in both human and economic devastation.\nThe Praesens Foundation is therefore developing, implementing and providing easy to train and use solutions that contribute to better epidemic preparedness, early warning and rapid response for existing and emerging infectious diseases and medicine in general. We work closely together with partners to provide them with effective diagnostic tools and to develop innovative approaches to deliver (mobile) health services to those in need wherever they are. We invest in developing new tools to prevent and monitor infectious diseases that impose the greatest burden and carry epidemic or pandemic risks.\nWe are focusing on key areas to improve laboratory testing capacity and epidemic preparedness. These include: real-time disease tracking systems, laboratory networks and training rapid response teams to prevent or react to disease outbreaks.\nWith the lack of field-applicable technologies, we have recognized the need for comprehensive and sustainable technologies that local health workers can use in the long-term. Our aim is to provide capabilities for fast ramp up of diagnostic testing both in central lab settings and at the points of need.\nIn order to achieve this, we are collecting funds and applying for grants for research, development and implementation of mobile and modular response capacities and technologies that are rapidly deployable in case of public health emergencies.\nWe believe the most important public health problems can be solved through collaborative efforts and we therefore develop interdisciplinary research collaborations across science, humanities, social science and innovation teams.\nHOW IT ALL STARTED\nIt was the Ebola outbreak in 2014 and his diagnostic interest that got Dr. Rudi Pauwels back to Africa, in his capacity of Founder and CEO of Biocartis. After having spent the better part of his life in laboratories, he wanted to observe firsthand how the world is dealing with outbreaks of that scale in the 21th century. He witnessed the best of humanity, the local healthcare workers, international community, risking their lives and stigmatization by their communities. But he also identified the gaps and needs for rapid, accurate and easy-to-use diagnostics, close to the affected communities. Epidemic preparedness helps to reduce the peak burden on health care infrastructure and ultimately, to diminish the overall caseload and health impact. This is contrasted to reactive approaches that are fire-fighting for an already significant problem.\nOn his flight back home, he started to make a sketch on a napkin of what would turn out to be the first generation Mobile Lab. With the help of a series of early believers among which passionate collaborators, sponsors and technology providers, the sketch became reality in less than two years.\nDriven by the motto “Vision without execution is hallucination”, he created the Praesens Fund in 2016, under the Belgian King Baudoin Foundation. Its name is related to the Latin-derived word praesens, and means ‘being here now, making an impact’. We would like to extend our special thanks to Dr Susana Zanello, a NASA scientist who shared Rudi’s passion to improve the human condition on earth and beyond, and helped lay the first building blocks. Together with Mr. Lee Lennox, they designed the Praesens logo which symbolizes the care for our planet and our people who are under threat of infectious diseases.\nAs the project entered the next stage in 2017, Dr. Rudi Pauwels founded the Praesens Foundation based in Belgium.\nThe Board of Directors is composed of Dr. Rudi Pauwels, Prof. dr. Peter Piot and Steven Pauwels. The day-to-day running of the Foundation is in the hands of Steven Pauwels (Executive Director) and Aurélie Cappuyns (Programme Manager).\nThe Praesens Foundation is operating at the intersection of global health technology innovation and social impact.\nOur team believes innovation should be at the level of populations, and technology can only be successful when it reaches the communities across the world and increases access among the vulnerable populations, irrespective of their location and resources. Our work focuses on a more holistic and integrated approach: not only building the autonomous mobile lab but also offering safe operating procedures, training, innovative technologies on board, etc.\nOur objective is to turn innovative ideas into real-world solutions. The solutions created by the Praesens Foundation should improve surveillance and rapid deployment in case of disease outbreaks in areas regularly affected by epidemic and endemic diseases. We want to drive change and make countries safer from epidemics - by working not only for but in particular with the local partners- with the aim to create more sustainable solutions and further expand the local healthcare capabilities.","Traveler's DiarrheaSkip to the navigation\nWhat is traveler's diarrhea?\nTraveler's diarrhea is a common medical problem for people traveling from developed, industrialized countries to developing areas of the world.\nHigh-risk areas for traveler's diarrhea include developing countries in Africa, Asia, the Middle East, and Latin America. Low-risk areas include the developed countries of North America, Central Europe, Australia, and Japan.\nWhat causes traveler's diarrhea?\nTraveler's diarrhea is usually caused by a bacterial infection. Bacteria such as Escherichia coli (E. coli), Campylobacter, Shigella, or Salmonella are the most common causes. These bacteria are in water contaminated by human or animal stools. Drinking water, water used to wash food, or irrigation water may be affected. When the traveler drinks this water or eats contaminated food, he or she is likely to get diarrhea.\nCommon sources of bacteria that cause diarrhea are undercooked or raw foods, contaminated food, or contaminated water (including ice cubes).\nWhat are the symptoms of traveler's diarrhea?\nTraveler's diarrhea can be mild to severe. Most people who develop traveler's diarrhea experience symptoms within the first 2 weeks, and often within 2 to 3 days, of arriving in a developing area. Symptoms include:\n- Abdominal cramps.\n- Mild to severe dehydration .\n- General lack of energy, nausea, and vomiting.\n- Fever, vomiting, and stools with blood or mucus. These symptoms mean you have serious diarrhea, which is more likely to lead to problems with dehydration. Dehydration may alter the effect of any medicines being taken, such as oral contraceptives or antimalarials.\nHow is traveler's diarrhea treated?\nTreatment for traveler's diarrhea includes drinking fluids to avoid dehydration, taking nonprescription medicines, and in some cases, antibiotics and intravenous (IV) fluids.\n- Let your stomach rest. Do not eat for several hours or until you are feeling better.\n- Take frequent, small sips of bottled or boiled water or a rehydration drink and small bites of salty crackers.\n- If possible, drink a solution made with World Health Organization (WHO) oral rehydration salts. Packets of the salts are available at stores and pharmacies in most developing countries. Add one packet to boiled or treated water, making sure to read the instructions regarding the proper amounts of salts and water. Drink the solution within 12 hours if kept at room temperature, or within 24 hours if refrigerated.\n- Begin eating a simple diet of bland foods, such as crackers, rice, bread, potatoes, or bananas, which usually will help slow diarrhea. After your diarrhea is gone, you may eat a regular diet again.\nChildren 2 years old or younger are at high risk of dehydration from diarrhea. If your child has diarrhea:\n- Give your child a solution of WHO rehydration salts in addition to his or her regular food as long as diarrhea continues. If your baby has trouble keeping the liquids down, try giving frequent sips by spoon.\n- Continue breastfeeding normally. Bottle-fed babies should continue their usual formula.\n- Feed your child starches, cereals, yogurt, fruits, and vegetables.\n- Seek medical help immediately if you or your child has bloody diarrhea, fever, or persistent vomiting, and give rehydration fluids in the meantime.\nNonprescription medicines may help treat diarrhea. Use nonprescription antidiarrheal medicine if you do not have other signs of illness, such as fever, abdominal cramping or discomfort, or bloody stools. If you have fever, bloody stools, or vomiting, antibiotics may be needed.\nBismuth subsalicylate, or BSS (such as Pepto-Bismol or Kaopectate), has been shown to be effective in preventing and treating traveler's diarrhea. It is usually not recommended for treatment in children younger than age 12 years. Bismuth subsalicylates may reduce the effectiveness of medicines taken to prevent malaria, should not be used for more than 3 weeks, and should not be taken by those who can't take aspirin. They may cause you to have a black tongue or black stools. The black color is usually not serious. Brushing your teeth and tongue after taking a BSS may keep your tongue from turning black.\nIf your child or teen gets chickenpox or flu , do not treat the symptoms with over-the-counter medicines that contain bismuth subsalicylate or aspirin (such as Pepto-Bismol, Kaopectate, or Alka-Seltzer). If your child has taken this kind of medicine and he or she has changes in behavior with nausea and vomiting, call your doctor. These symptoms could be an early sign of Reye syndrome , a rare but serious illness.\nNonprescription medicines to slow diarrhea, such as loperamide (for example, Imodium), may be used to treat diarrhea but should not be used to prevent traveler's diarrhea because they can cause constipation.\nIf you have a high-risk medical condition such as diabetes or cancer, you take prescription medicines that cause diarrhea, or you are traveling with a child 11 years old or younger, seek advice from your doctor to determine what medicines you may want to take on your trip. Be aware that dehydration caused by diarrhea may alter the effectiveness of any medicines you are taking for other medical conditions.\nCan I prevent traveler's diarrhea?\nThe best way to prevent traveler's diarrhea is to avoid food or water that may be contaminated. A good rule of thumb for food safety is, \"If it's not boiled, well-cooked, or peeled, don't eat it.\" Raw seafood and milk products usually are high-risk foods for bacterial contamination. Dry foods, such as breads, or fruits that you can peel are safe to eat.\nAvoid drinking local water where you are traveling. Beverages that are usually safe to drink include:\n- Tea and coffee if made with boiled water.\n- Carbonated bottled water or soda pop.\n- Bottled beer and wine.\nWater also can be filtered or treated with iodine to make it safe to drink.\nAlso, be aware that contaminated water may be used to wash fruits and vegetables, clean utensils and plates, and make ice cubes. Brushing your teeth with untreated water also may increase your risk of infection.\nAvoid eating food from street vendors where flies can transmit bacteria and poor hygiene practices are more likely to contaminate foods. If you purchase food at an outdoor market, make sure you boil it, cook it thoroughly, or peel it before you eat it.\nGood hand-washing is important in preventing the spread of infectious diseases. Washing with treated water or using alcohol wipes or antibacterial gels to disinfect your hands are good ways to reduce your risk of getting an infectious disease.\nTalk with your doctor about antibiotics you can carry with you on your trip and instructions on when to use them just in case you should develop diarrhea.\nOther information sources\nIn the United States, the Centers for Disease Control and Prevention (CDC) maintains current information on infectious diseases around the world. Local health departments can access this information to help you determine what prevention measures-such as vaccines, antimalarial medicine, or supplies to treat water-are appropriate for the area of the world you are traveling to. The CDC website (www.cdc.gov/travel/default.aspx) also updates information for travelers.\nResources for medical care in a foreign country include embassies or consulates and major hotels. For English-speaking travelers, multinational corporations or credit card companies also may have referrals for local medical care in the foreign country.\nPrimary Medical Reviewer E. Gregory Thompson, MD - Internal Medicine\nKathleen Romito, MD - Family Medicine\nAdam Husney, MD - Family Medicine\nSpecialist Medical Reviewer W. David Colby IV, MSc, MD, FRCPC - Infectious Disease\nCurrent as ofDecember 8, 2017\nCurrent as of: December 8, 2017"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:e5ed176b-d793-4818-9fca-e364d312a641>","<urn:uuid:1e1bc781-1fb6-465b-a6c8-f925af1f2b19>"],"error":null}
{"question":"What strategies can investors use to protect their portfolio using CFDs during adverse market conditions?","answer":"Investors can protect their portfolio during adverse market conditions by taking out CFD positions in the opposite direction of their portfolio position. For example, if an investor holds an ASX 200 index, they can use a CFD contract to short it. This way, when the market falls, the losses in the physical portfolio will be offset by the gains on the short positions. Additionally, traders can control losses by placing stop losses, which act like an insurance premium providing an extra layer of protection. However, it's important to note that losses are not limited to the initial deposit, and traders may be called upon to pay additional funds if the market moves against them.","context":["A CFD stands for Contract for Difference. It’s a derivative product involving a contract between a CFD provider and an investor. It consists of an underlying security, which might be a stock on an overseas or local share market, a currency, debt security, a commodity, or an overseas or local stock index. Through CFDs, the investor is buying and selling the price movement of the security, rather than directly owning the shares or securities. The CFD contract is a representation of a theoretical buy or sell order. The profit and loss are calculated by the difference between the opening and closing price, just when the position is closed.\nIndividuals opening a CFD position must put down a deposit on the value of shares. This can be as little as 5%. The CFD contract mimics the performance of the shares. CFD providers thus allow their clients to enter a short position at the same expense of entering a long one. Trading CFDs give traders the opportunity to trade long or short. For instance, an investor can sell a stock or short it using a CFD contract if he/she thinks that the stock is going to fall.\nCosts Involved in Using CFDs\nCFDs are usually provided by CFD providers. They tend to charge traders a premium for using CFDs. This can come in many forms described below.\nInvestors can trade securities by investing as little as 3% in some cases of the underlying asset’s value. The CFD provider offers exposure to the balance while the investor gains exposure to the whole amount of the transaction. Financing costs are charged on the portfolio’s balance in addition to the initial deposit. The CFD provider takes out a hedge to protect its own exposure to the underlying asset. It then passes on the cost of that hedge on to the investor in the form of a financing charge. Financing costs are usually calculated as a margin which can vary from 1.25 to 2% in some cases.\nCFD providers charge a commission on a user’s initial deposit. In some cases, they offer flat commission rates regardless of the transaction size. Many brokers commonly offer a flat commission of 0.10 or 0.20 percent. Others charge commissions on a sliding scale ranging from 0.05% to 0.2%.\nMinimum Opening Balance\nThe requirements for minimum opening balance can range from zero to as high as $5000 or $10000 in the case of some brokers and providers.\nMonthly fees depend mostly on the provider or broker chosen. Some have no monthly fee and do not charge for live market feeds. Others charge a monthly account fee but have packages for frequent traders that waive them off.\nAdvantages and Features of CFDs\nTraders who want a cost-effective, leveraged way to access different markets should use CFDs. They can take advantage of the market volatility by implementing various short-term techniques. However, they are not suited for individuals who are searching for wealth accumulation through private portfolios, or for retirees who are looking for efficient risk management.\nNo Expiry Date\nOne of the major advantages that CFDs have over other derivative trading instruments is that they do not have an expiry date, unlike warrants or options. This allows investors to keep their CFDs open for as long as they prefer. This gives CFDs a high degree of flexibility.\nIn recent years CFD providers have been modifying their products to appeal to traders and investors who prefer long-term strategies. Thus, these traders can use CFDs in the following ways:\nTrading with leverage\nTraders can use CFDs as a margin loan to get access to greater market exposure. They can control losses by placing stop losses in the correct positions. A stop loss can be likened to an insurance premium, providing an additional layer of protection. Traders should always realize that the losses they encounter while trading CFDs are not limited to the deposit paid. If the market moves against the CFD holder, he/she may be called upon to pay additional funds. To avoid such scenarios, the use of a normal as well as a guaranteed stop loss is recommended.\nDeferring Capital Gains\nIt may so happen that an investor builds up an overnight position in a well-performing stock and wants to diversify away from that high-risk exposure. They can then use CFDs as a way to sell against his stock position. It has the effect of locking in a selling price, thereby freeing up cash for other investments.\nCFDs can help protect a portfolio against adverse market environments. One can do this by taking out a CFD in the opposite direction of the portfolio position. For instance, if one holds an ASX 200 index, he/she can use a CFD contract to short it. As a result, the losses in the physical portfolio will be offset by the gains on the short positions when the market falls.\nThe longer CFDs are in the market, the better people’s understanding of it seems to be. In today’s markets, there are various short and long-term investors and other self-directed individuals who add CFDs to their portfolio. Compared to other derivatives, they are easily understandable especially if one is already a share investor. Additionally, many online brokers and CFD providers have started offering training sessions and other educational resources to educate traders and investors about CFD trading."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:7644c07f-0565-43db-84ca-72c841b684f8>"],"error":null}
{"question":"What are the key differences between natural tree gaps in old-growth forests and managed forest gaps in terms of their formation and characteristics?","answer":"Natural gaps in old-growth forests form when old trees die from disease, insects, or wind, creating a gradual process that includes ripping branches from neighboring trees and creating jagged openings in the canopy. These gaps contribute to forest complexity with snags, downed wood, and multiple canopy layers. In contrast, managed forest gaps are deliberately created through thinning operations, typically following specific size prescriptions (like half-acre gaps per 10 acres) and shapes. While natural gaps create immediate structural complexity, managed gaps initially lack features like snags and downed wood, though they do successfully promote tree regeneration with studies showing up to 3,600 stems per acre of new growth.","context":["Title: Chapter 12: The variable-density thinning study at Stanislaus-Tuolumne Experimental Forest\nAuthor: Knapp, E.; North, M.; Benech, M.; Estes, B.\nSource: In: North, Malcolm, ed. 2012. Managing Sierra Nevada forests. Gen. Tech. Rep. PSW-GTR-237. Albany, CA: U.S. Department of Agriculture, Forest Service, Pacific Southwest Research Station. pp. 127-139\nPublication Series: General Technical Report (GTR)\nPrior to historical logging and fire suppression, forests of the Sierra Nevada were extremely heterogeneous. Frequent low- to moderate-intensity fire was partly responsible for this heterogeneity, which in turn helped make forests resilient to high-severity stand-replacing events. Early observers of forests on the west slope of the Sierra Nevada noted the arrangement of large trees as grouped or clustered (Dunning 1923, Show and Kotok 1924) (fig. 12-1). Show and Kotok (1924) described the mixed-conifer forest as \"uneven aged, or at best even-aged by small groups, and is patchy and broken; hence it is fairly immune from extensive devastating crown fire.\"\nA major emphasis in forest management today is improving the resilience of stands to large-scale crown fires. To put forests on the path toward resilience after a long period of fire exclusion, stands are often first mechanically thinned, typically using some variation of thinning from below, which targets the smaller trees and retains the larger and more fire-resistant dominant and codominant individuals. With thinning from below, crowns of individual trees are typically separated from each other, which can lead to a relatively even forest structure. This evenness has sometimes been perceived to be in conflict with management of habitat for wildlife and other forest species. Thinning that produces a more grouped arrangement of trees may be one means of creating heterogeneity at a scale beneficial for wildlife species that prefer different forest structures for nesting, roosting, and foraging, and understory plant species that thrive in different light environments, while simultaneously increasing resilience to wildfire.\nThe high-variability thinning prescription described in this chapter is part of a new variable-density thinning study on the Stanislaus-Tuolumne Experimental Forest (STEF) designed to investigate the ecological effects of structural variability retained during forest thinning operations (Stanislaus National Forest 2010). Three forest structure treatments (high variability, low variability, and an unthinned control), all with or without prescribed burning as a followup treatment, are being compared. The objective of the high-variability thinning treatment is to produce an arrangement of trees and degree of spatial complexity similar to what was once found in historical forests prior to logging and fire suppression. The study planning predates publication of U.S. Forest Service General Technical Report GTR 220 (North et al. 2009) and is therefore not among the projects designed specifically to implement principles therein. We include it here because the objective of the highvariability treatment is similar to a core concept in GTR 220 of increasing spatial heterogeneity and thus provides a useful illustration.\n- We recommend that you also print this page and attach it to the printout of the article, to retain the full citation information.\n- This article was written and prepared by U.S. Government employees on official time, and is therefore in the public domain.\n- You may send email to firstname.lastname@example.org to request a hard copy of this publication. (Please specify exactly\nwhich publication you are requesting and your mailing address.)\nXML: View XML\nKnapp, E.; North, M.; Benech, M.; Estes, B. 2012. Chapter 12: The variable-density thinning study at Stanislaus-Tuolumne Experimental Forest. In: North, Malcolm, ed. 2012. Managing Sierra Nevada forests. Gen. Tech. Rep. PSW-GTR-237. Albany, CA: U.S. Department of Agriculture, Forest Service, Pacific Southwest Research Station. pp. 127-139.\nGet the latest version of the Adobe Acrobat reader or Acrobat Reader for Windows with Search and Accessibility","Maybe it was disease, or insects or wind, but the day finally came for the old-growth tree.\nFirst came the pops and creaks as the wood fibers began to stretch and break on one side of the trunk and collapse on the other. Then the weight of the trunk began to shift in earnest. As momentum built, the sound gathered and rushed into a roar that culminated in a thud that shook the forest floor.\nIn its downward progress, the tree ripped branches from neighboring trees or toppled them completely, creating a long, jagged gap in the forest’s canopy. As the sounds faded and the leaves came drifting down, the forest floor was illuminated with sunlight (Photo 1) that eventually will bring plants, young trees, and wildlife eager to colonize this new largess of energy and space.\nMultiply these gaps across the forest, add the effects of growth, decay, and renewal across the entire forest over many years, and the result is the complex world of the older forest. Snags, downed wood, multiple canopy layers, gaps and places of dense growth provide a range of habitat for plants and wildlife.\nBy contrast, nature has not yet run this course in the younger, managed forest. Trees often are closely spaced, with a single canopy layer and no gaps.\nTo diversify the structure of these young stands and to increase revenue from thinning operations, forest managers may deliberately create gaps in the canopy by removing trees. Yet how close do these gaps come to mimicking nature? In 2015, the Washington State Department of Natural Resources (DNR) decided to find out.\nA New Concept in Thinning\nWhen the Olympic Experimental State Forest (OESF) was established on the western Olympic Peninsula in 1992, DNR was faced with a different kind of gap: between vision and reality. The vision was a forested landscape with openings and young, mature, and old-growth stands arranged in an irregular pattern, capable of supporting northern spotted owls and other native species. The reality was the second growth forest. Because of extensive clearcutting in the previous three decades, over half of the forests DNR managed in the OESF were structurally simple and less than 40 years old.\nOne way to address this challenge was to use variable density thinning. With this type of thinning, trees are removed in an irregular pattern: some areas are not thinned at all, some areas are gaps, and others are thinned to different densities. The idea is to put a single-canopy stand on the fast track to becoming habitat while also supporting healthy tree growth for revenue production.\nVariable density thinning in the OESF was based in part on practical experience in how forests grow, and in part on the recommendations of forest scientists such as Andrew Carey from the US Forest Service Pacific Northwest Research Station. Carey recommended variable density thinning of second growth to better support populations of northern flying squirrels, a major prey species of northern spotted owls. He also incorporated this technique into “biodiversity pathways,” a landscape-level management approach for meeting multiple objectives that DNR later adopted as part of its agency-wide silvicultural approach.\nThe challenge for DNR was writing variable density thinning prescriptions for large areas. DNR instructed loggers to create half-acre gaps for every 10 acres of thinning. Loggers were asked to avoid thinning in sensitive areas (called “skips” because loggers skip those areas) and to retain certain species of trees. They also were given a target relative density that ranged between 35 and 50. The result was a stand that was thinned more heavily in some places than others. Techniques have been refined over the years, but the basic concepts have remained the same.\nFor patterning the gaps, DNR had little to go on. How common are they? What shape do they tend to be? Despite decades of forest research, the scientific literature was curiously silent on gap geometry in the old-growth forests of the Pacific Northwest. Without those answers, DNR’s success was hard to gauge. So DNR began a study appropriately named “Mind the Gap.”\nFor this study, DNR wanted to understand how the managed forest responds to gaps and how to make the gaps (size, shape, and frequency) resemble those found in older forests. The study was done in three parts: a look at the half-acre gaps created at least 10 years ago in western hemlock and Douglas fir stands, an analysis of gaps in mature and old-growth forests, and a test of a common gap shape and size in a timber sale. The end product would be refined prescriptions for creating gaps.\nFor the first part of the study, DNR compared aerial photos taken before thinning to those taken recently and took detailed field measurements. Results are still preliminary. But generally speaking, and despite a lack of site preparation and planting, the forest had surged into the gaps. Nearly 90 percent of the gaps measured were occupied by trees. Western hemlock averaged 1,400 to 2,100 stems per acre. One gap had as many as 3,600 stems per acre, which is many more than the surrounding forest (Photo 2 and Graph 1). Gaps also saw recruitment (establishment) of Douglas fir, Sitka spruce, western redcedar, and Pacific silver fir, albeit in lower numbers. Height growth in the gaps ranged from 16 inches per year for silver fir, hemlock and redcedar to a robust 30 inches per year for Douglas fir. Shrubs were seldom dominant, easing fears that gaps would create “brush holes” in the forest.\nWhat about gap shape? When gaps were first created, DNR feared that wind would gather speed across the opening and slam into the trees on the windward side, pushing them to the ground. It did happen. But it happened only in a quarter to a third of the gaps, and gaps only expanded a tenth to a quarter of an acre. And some tree crowns along the edge widened into the gap by as much as three feet, seemingly in response to increased sunlight.\nTo study the naturally-created gaps in older forests, DNR analyzed light detection and range (LiDAR) data and followed up with field verification. With LiDAR, lasers mounted on a small airplane are used to take measurements of the forest and ground. From these measurements, DNR creates a canopy surface model, which is essentially a topographic map of the top of the tree canopy, and a digital elevation model, which provides the contours of the ground. Between the two, one can determine the location, size, and shapes of gaps.\nBut what is a gap? Is it a place where one tree fell or several? Is it bare ground or can it be filled with young trees? If several gaps seem to be connected by thin spaces between trees, is that actually one gap? And how do you quantify the shape of gaps? Nature is messy and seldom obliges with something as straightforward as a square.\nTo solve the first problem, DNR applied filters to the data. For example, the gap had be a certain size and the difference in height between young trees in the gap and the overstory (Figure 1) had to fall within a defined range.\nThe second problem was tricky. Consider the shape in Figure 2. How long is it? One could measure across the points that seem the farthest apart, but which two points?\nTo solve this challenge, project researchers wrote a computer program to determine gap length. The program measures the distance between every point that describes the outer edge of the shape. That exercise creates a dense spider web of lines. Then, the program uses those measurements to find the shortest path between the two points farthest from each other (Figure 2).\nAnalysis of the older forest continues. In the meantime, the team took advantage of a planned variable density thinning in a 40-year-old western hemlock stand to test the most prevalent gap shape seen so far in the older forest: long and skinny. The team instructed loggers to create 20 rectangular gaps and, for comparison, 20 circular gaps ranging in size between one eighth and one quarter acre and randomly distributed across the stand. Growth in and along the edges of the rectangular gaps will be compared to growth in the round gaps and a thinned area with no gaps. The first post-treatment measurements will be taken later this year.\nMind the Gap\nSo far, canopy gaps have been an ingenious way to balance revenue production and ecological values in the OESF, also called the learning forest. The trees removed to create the gap generate revenue and the gap itself supports ecological values by enriching the structure of the stand. And although the gap will eventually fill in with trees, chances are other gaps will be created through thinning or natural forces as DNR works toward a more complex forest.\nCan the gaps be more effective? This study will continue to probe that question. More complete results will be shared as DNR continues to mind the gap in the OESF.\nBy Cathy Chauvin, DNR writer, editor; and Daniel Donato, Ph.D., DNR research scientist. For questions about this study, contact: daniel.donato@DNR.wa.gov [article originally published in The Learning Forest e-Newsletter.]"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:6867e7b3-0450-42c1-b1d5-33a057c6349c>","<urn:uuid:f9523031-1ea1-4733-b60e-c52378c9d5b4>"],"error":null}
{"question":"What is the connection between rural areas and renewable energy development, and what safety considerations affect rural driving in these areas?","answer":"Rural areas are seeing increased renewable energy deployment that positively impacts local development through royalties and taxes paid to communities, which help improve service delivery and create maintenance/operation job opportunities. However, these installations can compete with other land uses and face community opposition. Regarding rural driving safety, these areas require extra caution as country roads are characterized by hazards like blind bends, hidden crests, and lack of dedicated paths for pedestrians and cyclists. Drivers must constantly look for clues like skid marks or broken fences that indicate potential danger spots, and maintain appropriate speeds around 40mph rather than the posted 60mph limit to ensure adequate stopping distance.","context":["From incredibly tight bends to herds of sheep, country roads are full of hazards that you’re unlikely to find on your daily commute. In fact, on average, three people die on country roads every day. Plus, there are 10 times as many fatalities on rural roads than on motorways, according to the RAC Foundation. Therefore, if you’re looking to embark on your first drive through the countryside, it’s worth preparing for the journey in advance.\nHere you’ll find our top tips for driving on country roads, which will help to keep you, your passengers, and other drivers safe. Read on to find out more.\nAdjust your speed\nMost UK country roads have a speed limit of 60mph. However, this is rarely a safe speed to travel, according to road safety charity Brake.\nOn country roads, you should pay less attention to speed limits and, instead, adjust your speed according to the conditions. Rural roads tend to be narrow with blind bends, and rarely have pavements or cycle paths. Therefore, you need to be travelling at a speed that allows you to react to any hazards quickly and effectively.\nWhen you’re driving at 60mph, your stopping distance will be approximately 73 metres — that’s the length of three tennis courts. So, if you turn a corner and encounter an oncoming vehicle or group of pedestrians, you’ll have no chance of stopping in time. Speeds of around 40mph are more appropriate when you’re driving in the countryside.\nLook out for clues\nYou need to be very vigilant when driving on country roads, and should constantly be looking for clues of what lies ahead.\nFor example, if you see skid marks or notice a broken fence at the side of the road, there may have been an accident there recently. So, it’s wise to take your time so you can react to any hazards in plenty of time.\nIt’s also vital that you keep an eye out for road-side poles that display instructions or warnings. If you find one with a number of signs, you should read it from the top down and be prepared to deal with any hazards in that order.\nExpect the unexpected\nAs we’ve mentioned, there are far more hazards on country roads. From slow-moving tractors to herds of cows, you should be prepared to encounter the unexpected.\nYou should move at a steady pace, and stay alert. Sharp turns, dips in the road, and hiddencrests are all common hazards that you’re likely to come across when driving on rural roads, so you need to be ready to slow down or stop at a moment’s notice.\nKeep overtaking to a minimum\nWhen driving on country roads, you should try to overtake as little as possible. When you do need to overtake, make sure that you won’t be putting yourself or other drivers in danger. The best way to do this is to anticipate what might happen when you pull out to overtake. Are you sure that the vehicle in front of you isn’t going to turn right, and that no traffic is going to join the carriageway from a side road? If you aren’t 100% sure that it’s safe to overtake, you should hang back — it isn’t worth putting yourself in danger to get to your destination slightly earlier.\nIf you don’t have much experience, driving on rural roads can be overwhelming. But, if you worry too much, you run the risk of getting distracted. So, while you need to remain alert for your entire journey, you should also try to relax and take everything as it comes.\nIn their guide to de-stressing on your drive, Lookers recommends preparing well for your trip and creating a relaxing atmosphere in your vehicle. This will help to keep you calm and collected while you’re tackling those country roads for the first time.\nNext time you’re driving on rural roads, keep these five tips in mind. They’ll help keep you safe and calm until you reach your destination.","Central government policy alone cannot ensure a green transition – cities, regions and communities can also be catalysts for environmental policy solutions. National, regional and local policy makers have pursued urban, regional and rural development through initiatives that seek to reduce greenhouse gas emissions, and increase resource efficiency while beginning to steer their economies out of the global financial crisis. Experimentation and learning at the local level can provide essential experience and, when successful, lead to bottom-up diffusion of approaches between cities and regions as well as to influence national and even international levels of actions. Co-ordinating governance issues can help achieve the most cost-effective option in attaining green growth, particularly in the areas of green investment and innovation.\nIn co-ordination with national, regional and local governments, the OECD has been working to bridge the current divide between achievement of ambitious environmental goals and economic development.\nCities are home to over half of the world’s population and characterise many of today’s environmental challenges. The OECD’s Green Cities Programme seeks to assess how urban green growth and sustainability policies can contribute to improve the economic performance and environmental quality of metropolitan areas and thus enhance the contribution of urban areas to national growth, quality of life and competitiveness.\nUrban action is a cornerstone of efforts to limit or avoid climate impacts on infrastructure, people and economies. With their in-depth knowledge of the local landscape, urban policymakers are at the frontlines of efforts to adapt and reduce vulnerabilities to climate change. Focusing on the economic costs and benefits of action, the OECD has identified strategies to increase cities’ contribution to adaptation in both developed and developing countries.\nAs regions often have significant populations and economic activity, and have a bigger natural asset base than cities, they provide another opportunity to implement green growth initiatives on a practical scale. Local and regional governments have a key role to play in the implementation of national green growth strategies because:\nOECD work on regional development\n- Regional and local policies are needed to make sense of green job creation, due to having a better knowledge of the characteristics of the local labour market, and regional institutions are best equipped to provide training tailored to local needs.\n- Regional and local green growth initiatives are crucial for fostering innovation and stimulating demand for green technologies. For example, local and regional governments can directly promote the demand for green products and services through their large purchasing power.\n- National and international green growth financing mechanisms are more effective when coordinated with regional and local financing mechanisms.\nRenewable energy in rural areas\nWhat is the impact of renewable energy deployment in rural areas, in terms of economic development? The OECD has organised an international research project, encompassing 16 case studies in Europe and North America to answer this question.\nPreliminary findings demonstrate that renewable energy deployment can positively affect the development path of rural areas. For instance, royalties and taxes paid by developers to local communities help them to improve service delivery. New resources are used to build schools, senior residences, or increase broadband access in sparsely populated areas, for instance. Renewable energy installations can also create some employment opportunities in maintenance and operation activities and, under certain conditions, spur self-employment and entrepreneurship.\nYet, the research shed also light on important challenges that can impinge upon policy outcomes. For instance, national and regional renewable energy policies, under the influence of the “green growth narrative”, have set very ambitious targets and high incentives for renewable energy production that have caused distortions. Incentives have triggered rent-seeking behaviours, and installations have started competing with agriculture and tourism for the use of land or landscape amenities. In this context, many local communities have started opposing further deployment. Potential links with rural industries such as forestry or manufacturing are not developed due to the lack of an integrated approach to renewable energy deployment. Reducing the use of spatially blind incentives, and taking into account the characteristics and specific needs of hosting economies could be a way to capitalise on the investment in renewable energy in terms of economic development.\nBy empowering local governments, national policies can leverage existing local experiments, accelerate policy responses, foster resource mobilization and engage local stakeholders. A multilevel governance framework is needed to successfully manage the coordination of green growth strategies at national, regional and local government levels, as well as with civil society and the private sector. The working paper Cities, Climate Change and Multilevel Governance shows that advancing governance of climate change across all levels of government and relevant stakeholders is crucial to avoid policy gaps between local action plans and national policy frameworks, and to encourage cross-scale learning between relevant departments or institutions in local and regional governments.\nOECD work on multi-level governance\nLocal economic and employment development\nMost national and local governments have made ambitious commitments to mitigate climate change and to adapt the new environmental and regulatory conditions, while combating unemployment. Cities, regions and communities need to pursue economic strategies with a flexible approach to labour market, environment and economic policies, while ensuring their coordination. Building capacity on local economic and environmental policies will be essential to effectively support job creation in the transition to a green economy.\nMeasuring the potential of green growth is a project that aims to define key indicators of area-based transition to a low-carbon economy. The objective is to define measurable indicators at regional/local level that can inform over time of transition to low-carbon economic and industrial activities addressing the two aspects of the green growth economy: fostering job creation and economic development in new areas of growth and sustainable development.\nThe Climate Change, Employment and Local Development project aims to help national and local authorities put in place good quality greener jobs by developing lower-carbon activities. The final report Enabling Local Green Growth: Addressing Climate Change Effects on Employment and Local Development provides guidance on policy interventions and actions to develop quality employment in the greener economy, to meet the needs for new skills, and to manage the transition of local labour markets to a low-carbon economy.\nFor 2012, a follow-up project on improving the effectiveness of green local development initiatives will analyse in further detail some of the aspects arising from the report. It will notably identify approaches to support the adaptation of the public sector to the green economy in view of removing the barriers to the emergence and expansion of greener practices and activities in the private sector.\n- OECD Metropolitan Reviews and OECD National Urban Policy Reviews: chapters on urban responses to environmental, climate change and green growth challenges (e.g. Reviews of Guangdong, Venice, Toronto, Korea, Poland).\n- Green growth issues are also dealt with in the OECD Regional Innovation Reviews, Rural Policy Reviews and Territorial Reviews series, including recent studies on Québec, Canada, Guangdong, China, Chicago, USA, and the NORA Region.\n- Cities and Carbon Market Finance: Taking Stock of Cities’s experience with Clean Development Mechanism (CDM) and Joint Implementation (JI) - Environment Working Paper No. 29 (2010)\n- Cities and Climate Change (2010)\n- Cities and Climate Change: Key Messages from the OECD (flyer)\n- Cities and Green Growth – key points (flyer)\n- Cities and Green Growth: A Conceptual Framework, OECD Regional Development Working Papers, No. 2011/08.\n- Cities and Green Growth: Case study of the Paris/Ile-de-France Region, Working paper\n- Cities, Climate Change and Multilevel Governance, Environmental Working Papers N° 14 (2009)\n- Competitive Cities and Climate Change, Regional Development Working Papers N° 2 (2009)\n- Enabling Local Green Growth: Addressing Climate Change Effects on Employment and Local Development OECD Local Economic and Employment Development (LEED) Working Papers no. 2012/01\n- Framework and Tools for Assessing and Understanding the Green Economy at the Local Level OECD Local Economic and Employment Development (LEED) Working Papers no. 2011/08\n- Greening Jobs and Skills: Labour Market Implications of Addressing Climate Change, OECD Local Economic and Employment Development (LEED) Working Papers no. 2010/02\n- The Implementation of the Korean Green Growth Strategy in Urban Areas (Regional Development Working Paper) (2011)\n- Measuring the Environmental Performance of Metropolitan Areas with Geographic Information Sources, OECD Regional Development Working Papers no. 2012/05\n- OECD Regions at a Glance 2011: Chapter 3. Environmental Sustainability in Regions and Metropolitan Areas (2011) (pictured)\n- OECD Regional Outlook 2011: Building Resilient Regions for Stronger Economies, Special Focus: Innovation and Green Growth in Regions\n- OECD Territorial Reviews: The Chicago Tri-State Metropolitan Area, including a focus on green growth (pictured).\n- Recession, Recovery and Reinvestment: The role of local economic leadership in a global crisis (2009)\n- Regional Development Policies in OECD countries (2010)\n- Regions Matter: Economic Recovery, Innovation and Sustainable Growth (2009)\n- Urban Trends and Policy in China, OECD Regional Development Working Papers, 2009/1 (2009)\n- Urban Trends and Policies in OECD Countries: Working paper (2012)\nOECD work on adaptation to climate change\nLocal Economic and Employment Development (LEED) Programme\nInternational Transport Forum\nOECD work on green growth\nGreen growth and energy\nGreen growth and transport"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:38e68074-6b32-45a2-8946-3d9ecd4c56a7>","<urn:uuid:58a86291-7230-48f2-ab7f-ad744d97b973>"],"error":null}
{"question":"Can you compare the different types of horse competitions that existed historically versus now? First the old times, then modern ones!","answer":"The first documented cutting competition was held in 1898 in Haskell, Texas, with just 11 horse/rider teams competing for $150 in prize money. In modern times, the competition landscape is much more diverse and extensive. NCHA now holds over 1,300 events annually with over 130,000 entrants and $36 million in prize money. Similarly, AQHA offers various modern competition formats including All-Novice shows, Special Events, Double Judged/Double Point shows, Split Combined shows, and Alliance Shows. These modern competitions also include specialized categories like Versatility Ranch Horse competitions and Equestrians With Disabilities programs.","context":["\"The NCHA promotes and celebrates the cutting horse, whose origin on Western ranches allows us to support ranching and its western heritage. By establishing rules for the conduct of cutting horse shows, NCHA strives to give cutters a level playing field and a progressive class structure, which accommodates everyone from the beginner to the advanced competitor. NCHA draws on the diverse talents and background of its members, and encourages their participation in helping it achieve these goals.\"\n-- NCHA mission statement\nIn 1898 the first cutting contest was held in Haskell, Texas, with 11 horse/rider teams and 1,500 spectators. $150 in prize money went to team of Sam Graves and his 22-year-old horse, Hub.\nIn 1946 the National Cutting Horse Association (NCHA) was formed by a group of 13 cowboys and ranchers who wanted to promote competition, standardize rules and preserve the cutting horses’ Western heritage. Then, the first NCHA cutting was held in September of 1946 in Dublin, Texas.\nThe rider selects one cow from the herd of 60, separates cow from the herd and prevents the cow from returning. The cow’s instinct is to return to the herd. Trained cutting horses are incredibly intelligent and instinctive athletes. The competition is judged based on difficulty and how well the horse anticipates and reacts. This is the only equine competition where the horse is required to think.\nNCHA fans enjoy the sport of cutting across the globe in North and South America, Australia and Europe, with love of the Western lifestyle and horses in common.\nNCHA is composed of more than 15,000 affluent, rural horsemen and women with large, close families, who lead a very active Western lifestyle focused on the cutting horse.\nNCHA member demographics compare strongly with other equine sport groups associated with the luxury lifestyle, such as polo and thoroughbred racing.\nThere are more than 15,000 members of the NCHA that occupy 50 states and 20 countries.\nTrainers originally were employed by ranchers and, over time, progressed into the professional trainers of today. Today, trainers have various backgrounds with one thing in common: love for the horse. Professional trainers develop intelligent, agile and athletic horses and are the experts in:\n- Equine health care\n- Cutting and training techniques\n- Equine nutrition\nTop earners in the NCHA have earned nearly 50% more than the top earning athletes in associations such as PRCA or PBR.\nThe heart and soul of the NCHA are our affiliates, who create the first impression with cutting horse fans. There are 103 Affiliates globally, producing over 1,300 weekend NCHA events annually and operate progressive competition classes so everyone has a level playing field. They have one-on-one relationships with prospective new members as well as current members and fans.\nNCHA also has a youth division, which is designed to provide an engaging western lifestyle experience through two strategies: COMPETITION - Western sports competition opportunities: local, regional and national NCHA events. LIFE EXPERIENCE - Life experience foundation to include: leadership, social interaction, lifelong friendships, family, education, community involvement, sportsmanship and responsibility of caring for their horse. NCHA also offers $200,000 in scholarships each year while also recognizing the riders in a Youth Hall of Fame.\nEvents and Prizes\nOver 1,300 NCHA events are held annually with over 130,000 entrants paying in excess of $36m in prize money. There are 20 National NCHA-produced events annually.\n- $10,000,000+ in prize money\n- 7,700+ entrants\n- 30,000+ spectators\n- Over 110 days of competition\n- 10 sold-out spectator days\n- In excess of $119,000,000 in local economic impact\nSome of the people you may recognize in the cutting horse industry are Kix Brooks of the country duo “Brooks and Dunn”, Tanya Tucker, Pro Golfer Tom Watson, film producer, Charles Roven, Exxon Mobil’s Rex Tillerson, Nike’s Phil Knight, Walmart owner, Alice Walton and Pro Football Hall of Famer, Mel Blount.\nWe have Amateur and Non-pro classes. Amateurs must have eligibility earnings of $100,000 ($50,000 Weekend/$50,000 Limited Age) or less at the beginning of the point year. In addition there are several other criteria for Amateur status. An Amateur must not:\n- have ridden or trained horses for remuneration\n- have assisted in training horses or riders for remuneration within the last 10 years\n- have been married to or lived with a professional trainer in the last 10 years\n- have resided on the premises with a parent, step-parent or foster parent who was, while living there, a professional.\n- be directly or indirectly employed by a professional trainer or work at a horse training operation\n- have been an apprentice trainer at any time.\n- see complete Amateur Rules\nNCHA rules define a professional as anyone who has trained horses astride in any equine discipline for direct or indirect remuneration.\nNon-professionals are those who have not received direct or indirect remuneration to show, train, or assist in training a cutting horse or cutting horse rider. Non-professionals may not train horses in any equine discipline. However, NCHA does not consider professional cutting horse trainers’ spouses or employees who do not teach cutting horse riders or train cutting horses on cattle to receive indirect remuneration. Those individuals can show as Non-Professionals.","Most AQHA shows offer a variety of classes (English, halter, western) and divisions (youth, amateur, open) for competitors of different skill levels. Some shows may offer Novice classes for the youth and amateur divisions, and some offer the special Select classes for amateur exhibitors who are 50 years of age and over. Below are additional show formats that various show managements offer to meet exhibitors' needs.\nAll Novice Shows (**All Nov**)\nHave some fun showing while getting your feet wet at all-Novice shows. These events are specially-designed for eligible youth and amateur exhibitors who are eligible to compete at the Novice level. This means you'll compete in classes with people of similar skill and experience levels. All-Novice shows are hosted by AQHA state and provincial affiliates, and are usually held as stand-alone events or can be held during an open show.\nVisit www.aqha.com/novice to learn more about AQHA's Novice level.\nAQHA is introducing AQHA-approved classes to run during any open or 4-H horse show; in fact, these AQHA classes themselves can be held within other classes at the show. For example, AQHA members exhibiting in the open show’s western pleasure class can also receive points based off their placings against other AQHA members in that class. The shows are Novice-driven, but show management can choose to offer open, amateur and youth classes, as well. Though classes will incorporate some relaxed rules to accommodate their new format, they will continue to uphold the core AQHA show standards and rules. Exhibitors will be able to earn AQHA points as is the case for all other AQHA shows, and all classes will be judged by AQHA judges. AQHA Incentive Fund and world show qualifying points will not be paid on points earned at these shows.\nLearn more about introductory shows.\nLivestock Shows and Fairs\nSome of the largest AQHA shows are held during livestock shows and fairs. These collective events, which feature shows for other livestock, offer all levels of competition including strong youth classes. The number of entries may be high and you can find competitors seeking points due to the large class size as well as the casual exhibitor.\nThe AQHA Regional Championship shows delivers the ultimate American Quarter Horse experience to 10 destinations across North America. In addition to a fun and relaxed AQHA competition, you will experience great shopping, test rides on an American Quarter Horse and AQHA Professional Horsemen clinics and seminars.\nLearn more about AQHA Regional Championships.\nSpecial Events (**SpEv**)\nWant to meet more people who show in the same event as you? A special event just might be the ticket. Special events, as the name implies, may feature two single events like team penning and cutting, barrel racing and pole bending or roping events like team roping and tie-down roping. The serious and the casual competitor attend these special events. A single set of points is awarded at each special event.\nDouble Judged / Double Point (**DJ/DP**)\nWant to earn points fast? Then a double judged/double point show might just be the ticket for you. This format features one show with two judges, meaning that your top placings could earn two sets of points without having to exhibit twice. Double judged/double point shows are primarily found at major livestock shows where there are a large number of exhibitors. The majority of exhibitors who attend these shows are highly competitive, so expect top-quality exhibitors and American Quarter Horses. Expect to pay two entry fees.\nSplit Combined (**S/C**)\nAnother efficient way for exhibitors to rack up more points is to attend a split/combined show. Any two consecutive shows (like a Saturday and Sunday show) can be combined into one show and split over two days. There are two judges and two sets of points and the class is held only once, a real bonus for exhibitors who are trying to qualify for the world shows or earn year-end awards. Expect to pay two entry fees which is the norm for most split/combined shows.\nAlliance Shows (**All**)\nYou can earn AQHA points by competing at shows hosted by AQHA alliance members National Cutting Horse Association, National Reining Horse Association, National Reined Cow Horse Association, National Snaffle Bit Association and United States Team Penning Association. These approved events award points based on the AQHA system to those exhibitors who like to show in both organizations. You can expect all levels of competitors from the Novice to the professional. AQHA rules are applicable and exhibitors must meet AQHA ownership and eligibility requirements.\nMeet AQHA's alliance partners.\nVersatility Ranch Horse Competition\nVersatility Ranch Horse competition demonstrates the versatility of the working ranch horse in five categories – ranch riding, ranch trail, ranch cutting, working ranch horse and ranch conformation. To be eligible for points in the Versatility Ranch competition, one rider/one horse must enter all five classes. Credits will be applied per class according to the placing received based on the number of horses competing in that particular class. AQHA points are awarded based on the total earned credits that determine the final placing. There is an open division for horses shown by the recorded owner or by immediate family members or shown by a full-time employee (six months or more). A youth division also is offered to exhibitors 18 years of age or younger (age as of January 1) as long as they are the recorded owner or exhibit a horse owned by his or her immediate family members. Youth exhibitors may show horses owned by a ranch where the exhibitor's family is a full time employee (for six months or more). The Versatility Ranch Horse competition promotes the athletic ability and versatility of the horse.\nLearn more about the Versatility Ranch Horse competition.\nEquestrians With Disabilities\nAQHA and AQHYA members have a new type of competition that offers people with certain mental and physical challenges the thrill of showing an American Quarter Horse. It provides an arena for everyone to enjoy the rewards of hard work, determination and perseverance. This program allows you to show in three classes and earn points for year-end, high-point awards, along with the satisfaction of a job well done.\nLearn more about the Equestrians With Disabilities program.\nSee more AQHA Partner benefits\nPlease use our contact form.\nCall Customer Service\nAmerican Quarter Horse Association\n1600 Quarter Horse Drive\nAmarillo, TX 79104"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:9aeee926-8595-439e-9fcd-decc73820528>","<urn:uuid:66fa6610-5d32-4103-8aa2-34bb9f5983cb>"],"error":null}
{"question":"How do WordPress accessibility plugins handle color contrast compared to standard WCAG guidelines?","answer":"The WP Accessibility plugin provides a color contrast checker tool that tests whether foreground and background colors match the Web Content Accessibility Guidelines. According to WCAG 2.1 standards, text needs a minimum contrast ratio of 4.5:1 (Level AA) or 7:1 (Level AAA), with exceptions for large text which can have lower ratios of 3:1 (Level AA) or 4.5:1 (Level AAA).","context":["Do you want to improve accessibility on your WordPress site? Most of the times accessibility gets neglected in our effort to create more beautiful websites. This creates problems and bad user experience for people with disabilities. In this article, we will show you how to improve accessibility on your WordPress site.\nWhat is Accessibility in Web Design in WordPress?\nAccessibility is a term used to describe design techniques that make a product accessible to users with disabilities.\nIn web design, there are some common best practices that are recommended by experts to make websites more accessible. The same best practices can also be used in your own WordPress website.\nBy making your website more accessible, you can make it easier for many people to use your website without requiring assistance.\nThe problem is that most people using WordPress don’t know much about web design, accessibility, or design standards. Majority of the people just install a theme that looks great and helps them do what they want to do. We at WPBeginner are guilty of this too, but we are working on improving things around our site.\nLet’s take a look at how you can improve the accessibility of your WordPress site without writing any code.\nImproving Accessibility of Your WordPress Site\nFirst thing you need to do is install and activate the WP Accessibility plugin.\nUpon activation, you need to go to Settings » WP Accessibility to configure the plugin.\nThe first section is to remove the title attribute from tag clouds and archives. The title attribute is considered to be useless by some accessibility experts. Most screen readers usually ignore the title attribute and instead read the anchor text.\nIn the next section, you can enable the skip link on your website. A skip link allows users to jump directly to the content. This is an extremely useful feature for people using screen readers. Without a skiplink they will have to hear through lots of things like navigation menus before they can reach the content part.\nWP Accessibility provides a variety of accessibility settings, under miscellaneous accessibility settings section. You can go through each option and see if you need it on your site.\nSome of these options will be checked by default. These options are removing target attribute from links, force search error on empty search submission, and removing tabindex from focusable elements.\nWP Accessibility plugin comes with an accessibility toolbar. Enabling it will add a toolbar on your website where users can resize fonts or view your site in high contrast color mode.\nLastly, you will see the color contrast checker tool. Using this tool, you can test the foreground and background color contrast ratio and whether they match the Web Content Accessibility Guidelines. You may also want to see our guide on choosing the perfect color scheme for your WordPress site.\nYou can find out the colors your theme is using in the stylesheet, or you can use Eye Dropper, a color picker extension for Google Chrome.\nTo learn more about the accessibility features of the plugin, take a look at WP Accessibility Plugins page on WordPress accessibility team website.\nWe hope this article helped you improve accessibility of your WordPress site. You may also want to check out our guide on how to add breadcrumb navigation links in WordPress.","Color Contrast Checker\nThe tool tests the contrast ratio of background and text colors for accessibility. You can use it to visualize different color combinations for your website design that are in compliance with Web Content Accessibility Guidelines (WCAG) and international legislation based on it like the EU Web Accessibility Directive, the Americans with Disabilities Act (ADA), or the Accessibility for Ontarians With Disabilities Act (AODA).\nColor Contrast Tool Guide\nHow to Interpret the Color Contrast Ratios\nWCAG 2.1 Level AA\nLarge text - minimum contrast ratio of 3:1.\nWCAG 2.1 Level AAA\nLarge text: minimum contrast ratio of 4.5:1\nPlease note that incidental text such as images that are purely decorative or part of an inactive user interface component, and logotypes, such as parts of a logo or brand name, have no minimum contrast requirement.\nWhy Use a Color Contrast Checker?\nUse Monsido’s web color contrast checker to quickly check color combinations, and ensuring that all your branded content assets and design elements are accessible to everyone. It can also be used to test color contrast with other legislation, e.g. as an ADA contrast checker.\nNeed additional help?\nSee how we can help you make your website more accessible. Book a free web accessibility scan today.\nFrequently Asked Questions\nColor is such a vital element of web design as it is used to convey personality, attract attention, symbolize action, and indicate importance. As color carries a lot of significance in both being visually pleasing as well as conveying meaning, users must be able to perceive the content of different colors on a webpage. Color accessibility is important as it helps users with visual impairments like low vision or color blindness to properly distinguish content elements and read/view them effectively.\nA color contrast checker is a tool that measures the difference in perceived luminance between two colors to ensure that is perceivable to users with visual impairments or insensitivity.\nThe difference is measured on a ratio scale that starts at 1:1 (for white on white, to 21:2 (black on white). According to the WCAG level AA, the minimum contrast ratio that colors can have for the visual presentation of text and images of text is 4.5:1.\nWCAG 2.1 Level AA requires the visual presentation of text and images of text to have a contrast ratio of at least 4.5:1, except for large text, which should have a minimum contrast ratio of 3:1.\nWCAG 2.1 Level AAA requires a contrast ratio of at least 7:1 for normal text and 4.5:1 for large text (14 point and bold or larger, or 18 point or larger).\nImages must pass the WCAG contrast requirements. Images that contain text must ensure that the contrast between the image background and the text is sufficient, especially if the images are of low quality and if the image needs to be enlarged in any way. Images of text must have a minimum contrast ratio of 4.5:1.\nFor images that do not contain text, but still convey meaning, the image components must still have sufficient contrast to ensure that the overall image is perceivable. WCAG 2.1 level AA specifies that graphical objects and author-customized interface components such as icons, charts, and graphs, buttons, form controls, and focus indicators and outlines, have a contrast ratio of at least 3:1."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:2e6ce20c-f3a2-40e5-848e-e0cebc373942>","<urn:uuid:829f0ada-f08f-4987-835c-90a206d14cd8>"],"error":null}
{"question":"What's the relationship between choke points and door problems in level design, and how do these affect gameplay flow in combat encounters?","answer":"Choke points and door problems are related level design concepts that affect combat flow. A door problem occurs when players can exploit doorways to fight enemies safely from cover instead of engaging in dynamic combat within an arena. This creates dull, shooting gallery-style gameplay rather than exciting encounters. Similarly, choke points are deliberately designed narrow areas where teams meet and battle for control, typically placed before objectives. The key difference is that while door problems represent a design flaw to be solved through techniques like adding cover footholds or creating layered arenas, choke points are intentionally crafted to enhance gameplay by controlling flow and pacing. Effective choke points are carefully timed so teams arrive nearly simultaneously, limit entrances to 1-2 pathways, and support various combat styles like sniping or close-quarters combat.","context":["Let’s say I’m making a level for a classic first person shooter. To start, I build an arena and add some monsters. I don’t want the player to be attacked as soon as they start the game, so I add a hallway to one side of the arena and start the player there.\nMy level is simple, but I’m happy with what I’ve built, so I invite a friend to playtest. My friend walks along the hallway, enters the arena, and alerts the monsters, all according to plan. Then things go wrong. Instead of fighting in the arena, my friend steps back into the hall and fights from the doorway as the enemies funnel in. Instead of a dynamic gun ballet of dodged projectiles and swirling destruction, my friend has turned my level into a shooting gallery: dull, safe, and slow.\nThis is a door problem. Specifically, this is the door problem of combat encounter design. This is the problem of drawing players into gameplay spaces and pushing them to play in exciting ways.\nIf the door is the problem, why not make it bigger, or have the hall open directly to the arena? But the door itself isn’t the problem. The problem is the relationship between these two spaces, a problem that the player experiences when crossing the threshold, which is often a door.\nIf we widen the doorframe so the hall feeds into the arena, we get another version of the same problem. In some ways it’s better, in other ways worse. Even with the bigger threshold, there is nothing about the arena that draws the player in, nor anything about the hall that pushes the player out.\nBefore we look at some techniques for solving this problem, let’s explore what’s going wrong and why.\nWhat Am I Really Designing?\nFirst, the fundamentals. When we build a level for a classic first person shooter, what are we making? If we can ignore the thematic and narrative functions of a level, what is the level even about? What are we trying to build when we design a combat encounter?\nBuilding a level for a classic shooter is not about killing scary monsters with cool guns, though this is part of their appeal. A classic shooter level also isn’t about its sequence of locks and keys. These are both means to an end, and that end is map control. As the player moves through a level, they are taking territory from their enemy and locking the level into a solved state.\nThis fight for territory is one aspect of map control, but there are other aspects to consider. In an abstract sense, map control is about a player developing their options while limiting the options available to their opponent. These options depend on resources, which include map position, but also health, items, and ammo. For example, if the player has health and ammo, they can press an attack through a dangerous space to a stronger position in an exchange of resources. Without their resource of health and ammo, this option doesn’t exist.\nConversely, when the player dies, it is partly because they lost the game of map control and ran out of options. Of course, first person shooters are also about attention, target prioritization, and the player’s ability to internalize gameplay patterns. When the player dies, attrition and imprecision also play a role. But as the player becomes comfortable with these fundamentals, the game becomes increasingly about map control.\nFor a combat encounter, map control means understanding the relationship between the enemies and the environment and the resources available. For the player, map control means reducing the number of ways for enemies to attack while also developing the number of ways they can attack the enemy.¹\nApplying Map Control to The Door Problem\nFor my level with the door problem, what does map control mean? When my friend first stepped into the arena and alerted the monsters, my friend had a choice:\n- My friend can dance around the arena, trusting their ability to dodge the enemy attacks.\n- My friend can retreat to the hall where they have cover and can limit the enemies’ angles of attack.\nThis choice depends on several unknowns. If the player fights in the arena and enemy reinforcements arrive, then the player may be overwhelmed and should have fought from the door instead. Or, if the player lacks the firepower to kill the monsters as they approach, then the player is out of options and will die in the hallway. This choice depends on the player’s understanding of the game and the conventions of its level design.\nWe can describe games of map control as graphs of positions, with attention to the positions that the player can attack.\nNow here’s a simplified version of my level with the door problem:\nThis abstraction shows how stepping into the arena exposes the player to more angles of attack than they may be able to manage. To successfully fight in this arena, the player would need a deep, internalized understanding of the AI behavior and game mechanics. Instead, most players will fight from the door.\nSeeing Through The Player’s Eyes\nAnother way to diagnose the door problem is with value diagrams. These are a tool to abstract how the player perceives the level, assigns values, and forms plans.²\nTo construct a value diagram, we have to consider our game’s mechanics and how the level geometry supports or hinders them. For shooter gameplay, convex corners make strong cover; they afford the opportunity to step out, fire a shot, and step back with minimal risk. Other forms of level geometry, like deadends or killzones, can repel the player because of how they limit the player’s options to move and shoot without taking damage.\nFor shooter gameplay, the values of the level geometry change as the player and enemies move and fight. The values also change based on the types of enemies and the whole range of gameplay systems. If the player sees a monster that fires bouncing grenades, the player needs to evaluate the level differently; the cover that was strong against hitscan enemies is now more dangerous than the open floor space.\nThis dynamism invites a kind of play that Matthias Worch called “prioritization choice” in his GDC 2014 talk on “Meaningful Choice for Game Level Design”. Worch defined prioritization choice as “the complex interplay of systems that are easily understood individually, but that combine into situations that don’t have a consistent and obviously superior tactic.” This means the player gets to form opinions about the best plan for solving this dynamic environment.\nThat is to say, with shooter gameplay, a value diagram describes a moment of the player’s perception and evaluation. In another moment, as the arena shifts, the value diagram may be different, with new threats at different priorities.\nIf we apply these diagrams to my level with the door problem, we get an idea of what’s going wrong. The whole arena space repels the player with vulnerability and unknowns. But the hallway offers cover where the player can safely attack this group of enemies.\nThis value diagram tells us what we already knew. But, by thinking of the level in terms of the player’s perception and evaluation, we have a hint at how to solve the door problem. If I want my friend to fight in the arena, I need to change the level geometry so the space is more positive and inviting than fighting from the door.\nTechniques for Solving the Door Problem\nNow that we have the concept of map control and the tool of value diagrams to understand how the player evaluates a level, let’s look at a few techniques for solving our door problem. This isn’t a comprehensive list, but it should get us started.\nFoothold of Cover\nThe easiest solution is to add a foothold of cover. This is a strong position to draw the player into the arena. From this foothold, the player can push deeper into the arena to fight. The only reason for the player to retreat to the doorway at this point is if the foothold is too exposed or if the enemies can easily surround the foothold and push the player back.\nHere our foothold is a simple block that provides full cover. The player can’t see the enemies on the far side of the block or around the edges.\nFrom the perspective of map control, we can see how this foothold of cover limits the angles of attack for the enemies and makes the arena easier for the player to manage.\nFrom the perspective of a value diagram, we can see how this foothold of cover draws the player into the arena.\nReward for Risk\nWe can also affect the player’s evaluation of a level by adding powerups and items. If we place a strong powerup in the middle of the arena, this may attract the player to risk the danger.\nHowever, once the player has the powerup, there is no longer a reason for staying in the arena, and the player may return to the hall. Depending on the effect of the powerup, this technique is not sufficient to solve the door problem.\nAnother problem with this technique is that we can only give a powerup to the player every so often. If the player in the hallway is still receiving the benefits of a previous arena’s powerup, then the powerup in the new arena offers little of value.\nIn games of map control, one tactic is to divide and conquer. We can encourage this tactic by partitioning the arena into layers. Once our arena is divided, there is no longer a position that can see everything; the player has to keep moving to be aware of their enemies.\nThe walls that hide the information also function as islands of cover that may attract the player into the arena. As the player alerts the enemies and combat begins, these walls become options for the player to control while fighting.\nIn a layout like this, information becomes another resource of map control. The player can spend time and positioning to gain information, or they can pay the opportunity cost of information to stay where they are. Even when there are no monsters in a dense, partitioned arena, the player may feel apprehensive about the hidden information and feel drawn into orbiting the space to control that information. In terms of a value diagram, this apprehension is an average negative with pockets of positive space at the cover corners drawing the player in.\nHidden information also discourages the player from retreating. Here, if the player retreats to the hall, they are giving up map control to an unknown group of enemies; there may be more monsters in the arena than the player can survive by fighting from the door. Retreating gives up the options to improvise as the hidden information reveals itself.\nOne aspect of the door problem in my level is that the enemies rush toward the player and limit the player’s movement. We can modify the level geometry of our arena to keep the enemies at a distance on islands of territory, like leashing a dog to pole. This means the player has to go on the offense instead of letting the enemies funnel into the door.\nWith classic shooter levels, the easiest way to leash enemies is with height differences in the floor. Depending on the specifics of the game, the AI may not be able to drop down or climb up from a height greater than a step, which means they are stuck on the island and can only attack. With modern games, we have more tools to affect AI behavior with zones, defense volumes, path weighting, and one-off scripting.³\nAs with the reward for risk technique, leashing AI is not sufficient to solve the door problem. This is a technique to use in combination with our other techniques for drawing the player into the arena.\nOne Way Paths\nWe can also use more forceful techniques to make the player fight in the arena. We can require the player to drop down, or we can close the door behind them. We could have the player enter the room through a one-way elevator, or use a teleport.\nFor modern games, we could play a cutscene and take the moment to develop our characters and remind the player of their goal while we gate off the previous area of the level. But, for classic first person shooters, there is an expectation for secrets and rewards for exploration. In this older context, one-way paths break conventions and deny player agency. When using this technique in this context, open new routes for backtracking or create loops in the layout.\nPutting it All Together\nNow that we understand the problem and have some techniques to solve it, let’s put it all together.\nWithout changing the number of enemies, or drastically increasing the size of the arena, I applied several of the techniques:\n- Footholds of cover to draw the player in before the enemies are alerted, and to give the player positions to control.\n- Hidden information and AI leashing to divide the arena into layers for the player to fight through.\n- Reward for risk with the super shotgun, to draw the player in, and another with ammo and health behind some cover.\n- One way path with the drop down, so the player can’t retreat to the door and has to commit to the arena.\nWith my example level throughout this post, this may sound like a new mapper’s problem. Of course an arena needs cover! Of course we should divide arenas into layers of hidden information!\nBut this door problem remains relevant. My most recent map for Quake suffered from the door problem, and it wasn’t the only one. With each new level I make, and each new combat encounter I design, I think about how I am drawing the player into the space and how I am addressing the door problem.\nAs a designer, I want my players to interact with the deeper game of map control. I want to offer prioritization choices and opportunities to form plans and tactics instead of reducing gameplay to a shooting gallery.\nI hope this article will help you identify door problems in your own work. And I hope some of the techniques I outlined will prove useful in overcoming those problems.\nThank you for reading,\nFootnotes and Further Reading\n If you want to understand the concept of map control better, I recommend watching the Rapha versus Cooller match in Quake Live: https://youtu.be/XdkDjsBiO58?t=155. What appears to be a game of reflexes, attention, and precision, becomes a game of tactics as well. Although this is a multiplayer example, the concept of map control still applies. The main difference is that we design singleplayer combat encounters to be solved, similar to what chess problems are for chess.\n The concept for value diagrams began with Randy Smith’s GDC 2006 talk “Level Building for Stealth Games”. I first learned about these diagrams as “valence theory” in Robert Yang’s “Dark Pasts (Part 4)” analyzing the level design of immersive sims. More recently, Aubrey Serr adapted Smith’s diagrams to action game design in his GDC 2019 talk “Radically Nonlinear Level Design”.\nFor more thoughts on how player perception affects their movement into an arena, check out Blake Rebouche’s GDC 2018 talk “Balancing Action and RPG in Horizon Zero Dawn Quests”. Especially of interest is about 15 minutes in, when he describes the bunker sections of the game.\n For more on these modern techniques for AI combat encounters, check out Matthew Gallant’s GDC 2017 talk on authored and systemic AI in Uncharted 4.\nThe original version of this article was posted at https://andrewyoderdesign.blog/2019/08/04/the-door-problem-of-combat-design on August 4th, 2019.","Choke points are areas of the map where the attacking team meets resistance from the defending team before reaching the objective. Choke points are also called control points or bottlenecks.\nThe attacking team (Terrorist in defuse maps and Counter-Terrorist in hostage rescue maps) must fight through the choke point to reach the objective or retreat and try a different route/strategy.\nChoke point areas are specifically designed to enhance gameplay. They are used to control flow, pacing and balance within the map. Whether you are playing Dust (Underpass choke point), Office (Side Hall choke point) or Nuke (Outside choke point), each of these areas are manually crafted. The architecture, cover placement and timing are used to channel each team to attack or defend.\nIn this blog post I will cover 6 principles of choke point design and choke points used in most played official maps.\nYou will learn:\nPRINCIPLE 1: ENHANCE AND FACILITATE GAMEPLAY\nChoke points must enhance and facilitate gameplay (combat). To do this you must narrow the flow of your map through architecture down to a single (or double) viewable entrance, such as a hallway, doorway, tunnel or alleyway. This area becomes a choke point where two teams meet and battle for control.\nFew examples of choke points:\nDust Underpass/Overpass choke point:\nAztec Double Doors and Bridge:\nItaly at Long Hall and after Apartments Alleyway rounding the corner to T spawn:\nYou want to spend time crafting your choke points because the players will be spending a lot of time in this area.\nPRINCIPLE 2: CHOKE POINT PLACEMENT\nChoke points must be placed before the attacking team reaches the map's objective. The attacking team needs to fight through the choke point in order to reach the objective (rescue hostages or plant the bomb). You must design your map layout to allow for that. The defending team arrives at the objective and has to defend it by not allowing the attacking team to break through the choke point. This is the key to effective map layout in Counter-Strike.\nFor example look at Inferno B site Banana choke point, CTs must defend the alleyway entrance:\nMirage site A at Palace Tunnel and Palace Interior choke points:\nPRINCIPLE 3: TIMING\nTiming is very important in choke point design. You want both teams to arrive at the choke point almost at the same time. Defending team can reach the choke point few seconds earlier to set up position. The important part is that the attacking team should never be able to rush through the choke point while the defending team is just arriving there.\nTiming choke point arrivals are done in BSP block in stage of your map creation.\nHere is the process I use. At the beginning of the round I switch to knife so I can travel at maximum speed and run to the choke point. I use the game clock (round timer) to keep track of the time in seconds it takes me to reach the choke point. Once I get there I write down how long it took me. Then, I do the same thing for the other team side. If the times are different I move the choke point or the spawn points for each team, making sure that the arrival is about the same or slightly earlier for defending team.\nSometimes depending on the map, the defending team can arrive at the objective way before the attacking team. Dust 2 site A is a good example:\nPRINCIPLE 4: NUMBER OF ENTRANCES/EXITS\nLimit entrance options to the objective within a choke point down to one or two entrances. The attacking team should not easily take over the objective. Most maps in Counter-Strike have a single pathway choke point.\nDust 2 (Upper Tunnel) single tunnel leading to the objective.\nAztec (Double Doors):\n2 pathway entrance through a choke point offer a choice and strategy for the attacking team. It makes what could be a boring choke point and adds strategy.\nIf you are going to create 2 pathway entrance through a choke point, make sure that each entrance is clearly visible to the defending team within the same point of view. Avoid more than 2 entry locations to the objective within the same choke point that is not visible from same point of view. Control your choke points and you will control gameplay.\nDust (Underpass and Up the Stairs to Overpass) - both are visible and can be seen at the same time, but giving a strategy option for that choke point:\nInferno (Apartments or Long) two options for the attacking team but manageable for the defending team:\nYou have to effectively narrow down the options to one or two entrances for the attacking team to get through and plant the bomb. Bottle neck the layout design to funnel teams to these positions.\nPRINCIPLE 5: PLAYING STYLES\nEach map's choke points should support various playing styles - sniping, close quarter combat or stealth. The more gameplay styles you can support within the map, the more it will appeal to wider range of players. You want to design for strategy and skill. To do this effectively, use distance and cover as a design layout element.\nNuke is a good example of using distance to allow variety of gameplay styles. Outside choke point is good for sniping. Hut, Squeaky and Radio allows for medium and close quarter battles as well as some stealth.\nYou can also use distance vertically (height) as design gameplay element.\nAztec: Double Doors (short and long) good for sniping and close quarter battles:\nTrain: Middle (short, medium) good for medium/close quarter battles and stealth:\nMilitia: interior of the house (close quarter combat and stealth)\nPRINCIPLE 6: DYNAMIC CHOKE POINTS\nChoke points in hostage rescue map are dynamic. Hostage rescue does not require very precise and timed approach as it does for defuse maps. It is because choke points will change based on if Terrorist team plays aggressively (attacking) or passively (defending). So when designing hostage rescue maps, you will need to think how the defending team may play.\nThe main thing you want to do is limit pathways to hostage rescue locations down to 2 or 3.\nItaly has 3 main pathways routes from which CTs will come from:\nOffice also has 3:\nLet's me explain a bit further about dynamic choke point design of hostage rescue maps.\nItaly is great example. If CTs go right through the market there are 2 battle areas where they may encounter Terrorist.\nIf terrorist rush, Market will become the choke point:\nIf Terrorist defend and stay near spawn then Long Hall becomes the choke point.\nThis defend/attack choke point map dynamic is what you want to create in your own hostage maps.\nHere is how to come up with dynamic choke points:\nMake sure to read this in-depth guide about multiplayer map layout creation.\nIDEAS FOR CHOKE POINT DESIGN:\nNow that you know the principles let's take a look at some ideas for areas. I will keep this section short because this will depend on the theme you have for your map. Hallways and Doorways will seem like a natural choke point in an interior (office) type map, while Alleyway or Streets is the natural choice for urban (Inferno) setting type.\nBattle Areas: these are more open ended choke points with variety of options and cover within a given area. An example of these are Mirage (Middle), Italy (Market) and Train (Site A):\nRecommended Reading: CSGO Multiplayer Map Layout Design (In-Depth How to Guide)\nAll content on this website is copyrighted ©2008-2022 World of Level Design LLC by Alex Galuzin. All rights reserved.\nDuplication and distribution is illegal and strictly prohibited.\nWorld of Level Design LLC is an independent company. World of Level Design website, its tutorials and products are not endorsed, sponsored or approved by any mentioned companies on this website in any way. All content is based on my own personal experimentation, experience and opinion. World of Level Design™ and 11 Day Level Design™ are trademarks of Alex Galuzin.\nTemplate powered by w3.css"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:ede7b776-ffbd-4c79-8596-1b3ae111c499>","<urn:uuid:777a1f07-de26-4bcb-8c21-0d8985e8f022>"],"error":null}
{"question":"What are the similarities and differences between the US government's and Japanese institutions' approach to indigenous peoples' rights regarding consent and consultation?","answer":"Both the US government and Japanese institutions have implemented policies that fall short of true indigenous consent. The US government interprets 'free, prior and informed consent' as merely requiring consultation with tribal leaders, not necessarily their agreement, effectively allowing the government to dictate actions affecting indigenous peoples without their actual consent. Similarly in Japan, the guidelines for Ainu research were developed without appropriate consultation of the broader Ainu population, with the Ainu Association of Hokkaido representing less than 10% of the Hokkaido's Ainu population. Both approaches violate Article 19 of UNDRIP, which requires obtaining free, prior and informed consent from indigenous peoples through their representative institutions before implementing measures that affect them.","context":["US President Barak Obama, standing before a conference of Indian government, Alaskan Native and Hawaiian Native leaders, announced that his government “will support” the United Nations Declaration on the Rights of Indigenous Peoples (UNDRIP). When that announcement was made I expressed pleasure with the decision and yet urged caution until the Department of State published its written explanation of the US government policy. That policy is now available and the news is both good and not good. The US government position on the UNDRIP is clear on US policy support for “enhancing self-determination of federally recognized tribes,” but ambiguous at best and negative at its worst on interpretations and meanings of key principles built into the Declaration: The meaning and breadth of self-determination (“self-determination specific to indigenous peoples”), “free, prior and informed consent” (“consultation with tribal leaders, but not necessarily the agreement of those leaders, before … actions… are taken.”).\nThe principle of self-determination is at the core of virtually all international human rights instruments of policy and law. The internationally recognized right of self-determination is the basis on which more than 140 independent states came into being after World War II. States like Israel, Slovakia, Republic of Georgia, Tuvalu, and the Federation of Micronesia exist today because of that important principle. The United States government tenderly walks around the principle by saying that it endorses that principle “specific to indigenous peoples.” The principle contemplates the right of a people to “freely determine their political status and freely pursue their economic, social and cultural development” as stated in Article 3 of the UNDRIP. As has been the US government’s policy for forty years, economic, social and cultural development receive fairly consistent support in administrative, legislative and usually judicial policies. The US UNDRIP policy on these matters stands as consistent with long-standing policy through several US governments from Lyndon Baines Johnson to Barak Obama. That policy has seen enhancement of education, health, environmental, and social advancements as well as enhanced protections for cultural artifacts to the benefit of American Indian, Alaskan Native and even Hawaiian Native communities. While the policy has not always been perfectly applied, it has been applied.\nThe central and missing piece in the US government’s endorsement of “self-determination” and thus the slight of hand reference to “self-determination specific to indigenous peoples” is the matter of freely determining the political status of an indigenous people. The US government has held fast to the idea that the right to choose one’s political status must be limited for indigenous peoples. Indigenous peoples domestically and presumably internationally must be held in perpetual tutelage under the control of each states’ government–even if a state government demands fealty through force of violence. Holding to the fiction of the UN’s non-binding conception of “non-self-dismemberment” the US Department of State references UNDRIP Article 46 by saying “the Declaration does not imply any right to take any action that would dismember or impair, totally or in part, the territorial integrity or political unity of sovereign and independent States.” In fact the referenced article does suggest a restriction, but the restriction emphasizes “any activity or to perform any act contrary to the Charter of the United Nations.” There is no restriction on dismembering or impairing the territorial integrity of a sovereign and independent State if changing the political status of a people (perhaps choosing independence, free association or autonomy within an existing state) is freely chosen in accord with the UN Charter. The Declaration simply does not “authorize” dismemberment of existing states. That is reasonable, but it is equally reasonable to understand that freely choosing a political status can and indeed is encouraged if done within the framework of the UN Charter. Freely choosing a political status is the most basic of concepts built into the principle of self-determination. Without that right, there is no “self-determination.” The US position is to essentially nullify the right of indigenous peoples to freely make decisions about how they will organize as a political community.\nThere is a finer point on this discussion that can be made when we note that the US Department of State contemplates the UNDRIP principle of “free, prior and informed consent” as meaning, essentially, that American Indian, Alaskan Natives and Hawaiian Natives have the right of “free, prior and informed consent” unless the United States disagrees with the decision made by the indigenous people.\nThe US Department of State’s explanation of the US government’s support for the UNDRIP includes this rather contradictory statement: “…the United States recognizes the significance of the Declaration’s provisions on free, prior and informed consent, which the United States understands to call for a process of meaningful consultation with tribal leaders, but not necessarily the agreement of those leaders, before the actions addressed in those consultations are taken.” In other words, the United States may dictate actions and policies that affect the lives and property of indigenous peoples without their consent, but they may be informed. That is a position utterly inconsistent with the concept of “free, prior and informed consent”\nThe US government apparently rejects Article 10 of the UNDRIP which declares that “Indigenous peoples shall not be forcibly removed from their lands or territories…without the free, prior and informed consent of the indigenous peoples concerned….”\nThe US position strikes Article 11, para 2 and Article 28 of the UNDRIP which call for provision of mechanisms of redress “developed in conjunction with indigenous peoples” with their “free, prior and informed consent or in violation of their laws, traditions and customs.\nArticle 19 is struck down by the US position since it too requires the exercise of free, prior and informed consent before the state adopts and implements legislative or administrative measures. The US position is that “Consultation” satisfies this requirement event if consent is not secured.\nThe US position also flies in the face of Article 32 paragraph 2 that calls for obtaining the free, prior and informed consent before approval of projects affecting indigenous lands and territories.\nIt is a serious matter that the US government arrogates to itself the right and power to decide for American Indians, Alaskan and Hawaiian Natives without obtaining their free, prior and informed consent. It is equally serious that the US government wishes to hold up this approach internationally as a “model” reflecting its commitment to human rights. Other indigenous peoples are clearly made more vulnerable by the US position when states’ governments with which they must deal point to the US position and claim for themselves the right to decide and act in ways contrary to the interests of indigenous peoples.\nThe US policy of promoting and enhancing self-determination and self-government within the framework of the UNDRIP has considerable merit and benefit for American Indian, Alaskan Native and Hawaiian Native governing bodies. Unfortunately, the most important right, the right to choose and to consent, is denied and rejected out of hand. The “yes but no” approach can therefore receive both congratulations and denunciation. Much work now must focus on developing the full expression of self-determination including the full right of self-government–the right to choose and consent based on free, prior and informed engagement between peoples.","CEMiPoS director Hiroshi Maruyama critiques guidelines for the ethical research of indigenous peoples co-written by the Anthropological Society of Japan, the Japanese Archaeological Association, and the Japan Society of Cultural Anthropology. He explains that the new guidelines, written without the appropriate consultation of Ainu, do not sufficiently outline a process for repatriating Ainu ancestral remains, and therefore do not respect the rights guaranteed to indigenous peoples by UN Covenants.\nCentre for Environmental and Minority Policy Studies\nTrans. Mashiyat Zaman\nIn recent years, museums and universities around the world have repatriated the unjustly excavated ancestral remains of indigenous peoples to their rightful communities[i]. Nonetheless, last December in Japan, remains of the Indigenous Ainu people, which had been under the unethical management of twelve Japanese universities, were “aggregated” against the will of many Ainu people at the newly built Symbolic Space for Ethnic Harmony in Shiraoi, Hokkaido [ii]. The Ainu Association of Hokkaido has since solicited public comments on a draft of “Guidelines for Ethical Research of the Ainu People,” co-written with the Anthropological Society of Japan, the Japanese Archaeological Association, and The Japan Society of Cultural Anthropology.\nThis article examines the draft of ethical research guidelines, especially with regard to the research of Ainu remains, in three respects: scholarly injustice, the guidelines on the repatriation of ancestral remains, and the decision-making process. It demands that the aforementioned academic societies commit to the decolonization of their indigenous studies, based on the United Nations Declaration on the Rights of Indigenous Peoples (UNDRIP) adopted by the General Assembly in 2007.\n1. Scholarly Injustice\nThrough such injustices as fraudulent medical examinations of Ainu people and the robbery of their remains and burial accessories, the invasive study of Ainu by Wajin researchers continued unabated for nearly a century, beginning with the former Tokyo Imperial University’s Koganei Yoshikiyo in the late 19th century, and carried on by Kodama Sakuzaemon and Yamazaki Haruo of the former Hokkaido Imperial University [iii]. As this research was justified by and propagated fallacious colonialist ideologies such as social Darwinism and eugenics, not only was the process unjust, but the goal as well.\nNot only was a large sum invested into this research by the Japanese government [iv], but laws in Hokkaido concerning the exhumation of human remains were loosened for the researchers’ convenience [v]. Hospitals, police, and even station masters across Hokkaido were made part of a local network collecting body measurement data and Ainu remains [vi]. Thus, all of Japanese society was complicit in this act of scholarly injustice against the Ainu.\nOver the course of two years, beginning in 1980, Kaibazawa Hiroshi repeatedly brought Hokkaido University’s scholarly integrity into question, only for the University to ignore his criticism [vii]. In 2008, when Ogawa Ryukichi went as far as filing for a review under the Administrative Appeal Act, the University did not release any documents related to its management and study of Ainu remains and burial accessories [viii].\nAlthough Hokkaido University released its first investigative report in 2013, the scope of the investigation itself was limited to internal documents, and failed to recognize past injustices [ix].\nAnd today, far from taking actions towards repatriation, Hokkaido University, with eleven other institutions that had also participated in the cruel research of Ainu remains, has ignored many Ainu’s objections and “aggregated” its hoard at Shiraoi [x], committing yet another scholarly injustice against the Ainu people. The draft of Guidelines for the Ethical Research of Ainu People, rather than criticizing this history of scholarly injustice, and offering neither apology nor reflection, demands only that a system of studying the Ainu remains be established as quickly as possible.\n2. Guidelines for the Repatriation of Ainu Remains\nAs a result of Ogawa Ryukichi and Jounoguchi Yuri’s efforts to bring the matter of the repatriation of Ainu remains to court [xi], in June 2014 the Japanese government officially published its “Guidelines Concerning the Repatriation of Identified Ainu Remains.” Then, in December 2018, in order to include unidentified remains, the government published the updated “Guidelines Concerning the Repatriation of Ainu Remains Collected by Universities to their Excavation Site” [xii]. However, in the latter case, not only must the government authorize the organizations representing the regions to which the remains will return, but the application period is limited. In other words, authority over the Ainu remains has merely shifted from the universities to the government, violating Article 12 of the United Nations Declaration on the Rights of Indigenous Peoples, which ensures the repatriation of human remains for indigenous peoples. Furthermore, the aggregation of Ainu remains at Shiraoi under the Japanese government curtails the burden of responsibility of the aforementioned twelve universities and facilitates greater access to them, raising concerns that research into Ainu remains may continue to grow.\nWhile the Guidelines Concerning the Repatriation of Ainu Remains suggests that it is still possible for the Ainu to claim the return of ancestral remains from Shiraoi, the draft of Guidelines for Ethical Research, prepared under the supervision of the Ainu Association of Hokkaido, does not explicitly state that Ainu remains buried before the Meiji era cannot be used as objects of research, giving rise to inconsistencies as to how they should be handled.\nThus, the draft of Guidelines for the Ethical Research of Ainu People is intrinsically flawed – instead of considering the repatriation of Ainu remains, it actually promotes their continued research.\n3. The Decision-Making Process\nAs of 2016, the Ainu Association of Hokkaido had 2,300 members, however this number does not exceed even one-tenth of Hokkaido’s Ainu population [xiii]. In other words, the draft of Guidelines for the Ethical Research of Ainu People does not reflect the opinion of at least 90% of the Ainu population in Hokkaido. As an organization, the Ainu Association of Hokkaido is not representative of the Ainu people, and thus fails to uphold Article 19 of the UNDRIP, Article 27 of the International Covenant on Civil and Political Rights and Article 15, paragraph 1 (a) of the International Covenant on Economic, Social and Cultural Rights.\nAccording to Article 19 of the UNDRIP, “States shall consult and cooperate in good faith with the indigenous peoples concerned through their own representative institutions in order to obtain their free, prior and informed consent before adopting and implementing legislative or administrative measures that may affect them.” The aforementioned International Covenants add that states are responsible for ensuring the effective participation of indigenous people in deciding legal and protective measures which may affect their cultural practices [xiv], and also guarantee their free, prior and informed consent in all decisions concerning their rights [xv]. Furthermore, the International Convention on the Elimination of All Forms of Racial Discrimination advocates legislation that ensures diverse groups within indigenous populations are not disregarded by the law [xvi].\nThe Anthropological Society of Japan, the Japanese Archaeological Association, and The Japan Society of Cultural Anthropology must publicly recognize Japan’s history of scholarly injustice against the Ainu people and the invasive research of their ancestral remains. Furthermore, they must resolve the contradictions regarding the repatriation of Ainu remains between the Guidelines for the Repatriation of Ainu Remains and the draft of the Guidelines for the Ethical Research of the Ainu People. Finally, following the direction of the UNDRIP, Ainu organizations other than the Ainu Association of Hokkaido should also be represented in dialogue concerning the repatriation and reburial of Ainu remains. In other words, Ainu research practices must be fundamentally changed.\nIn order to decolonize their indigenous studies, the academic societies mentioned above, as well as the twelve universities and the Japanese government, are obliged to respect and reinforce the Ainu people’s right to self-determination and the repatriation of their ancestors’ remains. Thus, it is only appropriate that these establishments not only return the collected Ainu remains, but also facilitate their reburial at the kotan where they once rested.\n[i] Maruyama, Hiroshi. Forthcoming. “Restitution and Resistance: The Enduring Legacy of the Colonial Robbery of Ainu Graves”. In The Editorial Board of Critical Studies of Indigenous Policy (ed.) Post-UNDRIP Policy towards Indigenous Peoples (working title), Uppsala: The Hugo Valentin Centre, Uppsala University.\n[ii] 北海道アイヌ協会. 2019. 「『アイヌ民族に関する研究倫理指針（案）』に関する御意見・情報の募集について」 (https://www.ainu-assn.or.jp/news/files/6393b7df3a4874e847a1e2980841c264c23fc9eb.pdf)\n[iii] Maruyama, Hiroshi. Forthcoming. “Restitution and Resistance: The Enduring Legacy of the Colonial Robbery of Ainu Graves”. In The Editorial Board of Critical Studies of Indigenous Policy (ed.) Post-UNDRIP Policy towards Indigenous Peoples (working title), Uppsala: The Hugo Valentin Centre, Uppsala University.\n[iv] 国立大学法人北海道大学. 2013. 『北海道大学医学部アイヌ人骨収蔵経緯に関する調査報告書』pp. 18-21\n[v] 同上, pp. 35-6.\n[vi] Low, Morris. 2012. “Physical Anthropology in Japan”. Current Anthropology 53 (3): p. s64.\n[vii] 市川利美, 平田剛士. 2016. 「過ちに真摯に向き合えない北海道大学」, 北大開示文書研究会編著『アイヌの遺骨はコタンの土へ』, 緑風出版, pp. 168-9.\n[viii] 殿平善彦. 2016. 「大量のアイヌ遺骨がなぜ全国の大学にあるのか」, 北大開示文書研究会編著『アイヌの遺骨はコタンの土へ』, 緑風出版, pp. 8-9.\n[ix] 国立大学法人北海道大学. 2013. 同上書, 総括, pp. 113-17.\n[x] 北大開示文書研究会. 資料室（http://www.kaijiken.sakura.ne.jp/archives.html）\n[xi] Maruyama, Hiroshi. Forthcoming. “Restitution and Resistance: The Enduring Legacy of the Colonial Robbery of Ainu Graves”. In The Editorial Board of Critical Studies of Indigenous Policy (ed.) Post-UNDRIP Policy towards Indigenous Peoples (working title), Uppsala: The Hugo Valentin Centre, Uppsala University.\n[xii] 文部科学省. 2018. 「大学の保管するアイヌ遺骨等の出土地域への返還手続きについて」（https://www.kantei.go.jp/jp/singi/ainusuishin/pdf/181226_chiiki-guidelines.pdf）\n[xiii] Morris-Suzuki, Tessa. 2018. “Performing Ethnic Harmony: The Japanese Government’s Plans for a New Ainu Law.” Japan Focus 16 (2): pp. 5-6.\n[xiv] Committee on Civil and Political Rights. 1994. General Comment No.23, Paragraph 7. (https://www.refworld.org/docid/453883fc0.html).\n[xv] Committee on Economic, Social and Cultural Rights. 2009. General Comment No. 21, Paragraph 37. (https://www.refworld.org/docid/4ed35bae2.html).\n[xvi] Committee on the Elimination of Racial Discrimination. 2018. Concluding observations on the combined twenty-second and twenty-third periodic reports of Sweden: Paragraph 17(c) (https://tbinternet.ohchr.org/_layouts/15/treatybodyexternal/Download.aspx?symbolno=CERD/C/SWE/CO/22-23&Lang=En)この文書にはサーミのことが書かれているが、それはアイヌにも当てはまる。"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:55c154b4-9110-45d4-945c-3e3c7e1e6ffb>","<urn:uuid:5cf7c216-f93d-4911-9713-245f4c5401d1>"],"error":null}
{"question":"I'm studying early American governance. Could you compare how Benjamin Franklin and Alexander Hamilton approached the role of government institutions in building the nation?","answer":"Franklin and Hamilton both made significant contributions to early American governance through different institutions. Franklin focused on the postal system, serving as postmaster from 1737 until 1774, using it to create a distributed public sphere through affordable newspaper distribution and exchange networks. He implemented policies allowing publishers to distribute newspapers for fixed fees, enabling widespread information sharing. Hamilton, on the other hand, focused on building strong executive institutions, particularly through the Treasury Department. He reorganized the nation's finances, balanced accounts, paid off war debts, and established the foundation for the Federal Reserve Bank. He advocated for 'energy in the executive' as essential to good government and believed in strong central authority to protect property and liberty.","context":["My dear friend danah boyd led a fascinating day-long workshop at Data and Society in New York City today focused on algorithmic governance of the public sphere. I’m still not sure why she asked me to give opening remarks at the event, but I’m flattered she did, and it gave me a chance to dust off one of my favorite historical stories, as well as showing off a precious desktop toy, an action figure of Ben Franklin, given to me by my wife.\nIf you’re going to have a favorite founding father, Ben Franklin is not a bad choice. He wasn’t just an inventor, a scientist, a printer and a diplomat – he was a hustler. (As the scholar P. Diddy might have put it, he was all about the Benjamin.) Ben was a businessman, an entrepreneur, and he figured out that one of the best ways to have financial and political power in the Colonies was to control the means of communication. The job he held the longest was as postmaster, starting as postmaster of Philadelphia in 1737 and finally getting fired from his position as postmaster general of the Colonies in 1774, when the British finally figured out that he was a revolutionary who could not be trusted.\nBeing in charge of the postal system had a lot of benefits for Ben. He had ample opportunities to hand out patronage jobs to his friends and family, and he wasn’t shy about using franking privileges to send letters for free. But his real genius was in seeing the synergies between the family business – printing – and the post. Early in his career as a printer, Franklin bumped into one of the major challenges to publishers in the Colonies – if the postmaster didn’t like what you were writing about, you didn’t get to send your paper out to your subscribers. Once Ben had control over the post, he instituted a policy that was both progressive and profitable. Any publisher could distribute his newspaper via the post for a small, predictable, fixed fee.\nWhat resulted from this policy was the emergence of a public sphere in the United States that was very different from the one Habermas describes, but one that was uniquely well suited to the American experiment. It was a distributed public sphere of newspapers and letters. And for a nation that spanned the distance between Boston and Charleston, a virtual, asynchronous public sphere mediated by print made more sense that one that centered around physical coffee houses.\nFranklin died in 1790, but physician and revolutionary Benjamin Rush expanded on Franklin’s vision for a post office that would knit the nation together and provide a space for the political discussions necessary for a nation of self-governing citizens to rule themselves. In 1792, Rush authored The Post Office Act, which is one of the subtlest and most surprising pieces of 18th century legislation that you’ve never heard of.\nThe Post Office Act established the right of the government to control postal routes and gave citizens rights to privacy of their mail – which was deeply undermined by the Alien and Sedition Acts of 1798, but hey, who’s counting. But what may be most important about the Post Office Act is that it set up a very powerful cross subsidy. Rather than charging based on weight and distance, as they had before Franklin’s reforms, the US postal system offered tiered service based on the purpose of the speech being exchanged. Exchanging private letters was very costly, while sending newspapers was shockingly cheap: it cost a small fraction of the cost of a private letter to send a newspaper. As a result, newspapers represented 95% of the weight of the mails and 15% of the revenue in 1832. This pricing disparity led to the wonderful phenomenon of cheapskates purchasing newspapers, underlining or pricking holes with a pin under selected words and sending encoded letters home.\nThe low cost of mailing newspapers as well as the absence of stamp taxes or caution money, which made it incredibly prohibitively expensive to operate a press in England, allowed half of all American households to have a newspaper subscription in 1820, a rate that was orders of magnitude higher than in England or France. But the really crazy subsidy was the “exchange copy”. Newspapers could send copies to each other for free, with carriage costs paid by the post office. By 1840, The average newspaper received 4300 exchange copies a year – they were swimming in content, and thanks to extremely loose enforcement of copyright laws, a huge percentage of what appeared in the average newspaper was cut and pasted from other newspapers. This giant exchange of content was subsidized by high rates on those who used the posts for personal and commercial purposes.\nThis system worked really well, creating a postal service that was fiscally sustainable, and which aspired to universal service. By 1831, three quarters of US government civilian jobs were with the postal service. In an almost literal sense, the early US state was a postal service with a small representative government attached to it. But the postal system was huge because it needed to be – there were 8700 post offices by 1830, including over 400 in Massachusetts alone, which is saying something, as there are only 351 towns in Massachusetts.\nI should note here that I don’t really know anything about early American history – I’m cribbing all of this from Paul Starr’s brilliant The Creation of the Media. But it’s a story I teach every year to my students because it helps explain the unique evolution of the public sphere in the US. Our founders built and regulated the postal system in such a way that its function as a sphere of public discourse was primary and its role as a tool for commerce and personal communication was secondary. They took on this massive undertaking explicitly because they believed that to have a self-governing nation, we needed not only representation in Congress, but a public sphere, a space for conversation about what the nation would and could be. And because the US was vast, and because the goal was to expand civic participation far beyond the urban bourgeois (not universal, of course, limited to property-owning white men), it needed to be a distributed, participatory public sphere.\nAs we look at the challenge we face today – understanding the influence of algorithms over the public sphere – it’s worth understanding what’s truly novel, and what’s actually got a deep historical basis. The notion of a private, commercial public sphere isn’t a new one. America’s early newspapers had an important civic function, but they were also loaded with advertising – 50-90% of the total content, in the late 18th century, which is why so many of them were called The Advertiser. What is new is our distaste for regulating commercial media. Whether through the subsidies I just described or through explicit mandates like the Fairness Doctrine, we’ve not historically been shy in insisting that the press take on civic functions. The anti-regulatory, corporate libertarian stance, built on the questionable assumptions that any press regulation is a violation of the first amendment and that any regulation of tech-centric industries will retard innovation, would likely have been surprising to our founders.\nAn increase in inclusivity of the public sphere isn’t new – in England, the press was open only to the wealthy and well-connected, while the situation was radically different in the colonies. And this explosion of media led to problems of information overload. Which means that gatekeeping isn’t new either – those newspapers that sorted through 4300 exchange copies a year to select and reprint content were engaged in curation and gatekeeping. Newspapers sought to give readers what an editor thought they wanted, much as social media algorithms promise to help us cope with the information explosion we face from our friends streams of baby photos. The processes editors have used to filter information were never transparent, hence the enthusiasm of the early 2000s for unfiltered media. What may be new is the pervasiveness of the gatekeeping that algorithms make possible, the invisibility of that filtering and the difficulty of choosing which filters you want shaping your conversation.\nIdeological isolation isn’t new either. The press of the 1800s was fiercely opinionated and extremely partisan. In many ways, the Federalist and Republican parties emerged from networks of newspapers that shared ideologically consonant information – rather than a party press, the parties actually emerged from the press. But again, what’s novel now is the lack of transparency – when you read the New York Evening Post in 1801, you knew that Alexander Hamilton had founded it, and you knew it was a Federalist paper. Research by Christian Sandvig and Karrie Karahalios suggests that many users of Facebook don’t know that their friend feed is algorithmically curated, and don’t realize the way it may be shaped by the political leanings of their closest friends.\nSo I’m not here as a scholar of US press and postal history, or a researcher on algorithmic shaping of the public sphere. I’m here as a funder, as a board member of Open Society Foundation, one of the sponsors of this event. OSF works on a huge range of issues around the world, but a common thread to our work is our interest in the conditions that make it possible to have an open society. We’ve long been convinced that independent journalism is a key enabling factor of an open society, and despite the fact that George Soros is not exactly an active Twitter user, we are deeply committed to the idea that being able to access, publish, curate and share information is also an essential precursor to an open society, and that we should be engaged with battles against state censorship and for a neutral internet.\nA little more than a year ago, OSF got together with a handful of other foundations – our co-sponsor MacArthur, the Ford Foundation, Knight, Mozilla – and started talking about the idea that there were problems facing the internet that governments and corporations were unlikely to solve. We started asking whether there was a productive role the foundation and nonprofit community could play in this space, around issues of privacy and surveillance, accessibility and openness, and the ways the internet can function as a networked public sphere. We launched the Netgain challenge last February, designed to solicit ideas on what problems foundations might take on. This summer, we held a deep dive on the question of the pipeline of technical talent into public service careers and have started funding projects focused on identifying, training, connecting and celebrating public interest technologists.\nWe know that the digital public sphere is important. What we don’t know is what, if anything, we should be doing to ensure that it’s inclusive, generative, more civil… less civil? We know we need to know more, which is why we’re here today.\nI want to understand what role algorithms are really playing in this emergent public sphere, and I’m a big fan of entertaining the null hypothesis. I think it’s critical to ask what role algorithms are really playing, and whether – as Etyan Basky and Lada Adamic’s research suggests – that echo chambers are more a product of user’s choices than algorithmic intervention. (I argue in Rewire that while filter bubbles may be real, the power of homophily in constraining your access to information is far more powerful.) We need to situate the power of algorithms in relation to cultural and individual factors.\nWe need to understand what are potential risks and what are real risks. Much of my current work focuses on the ways making and disseminating media is a way of making social change, especially through attempting to shape and mold social norms. Algorithmic control of the public sphere is a very powerful factor if that’s the theory of change you’re operating within. But the feeling of many of my colleagues in the social change space is that the work we’re doing here today is important because we don’t fully understand what algorithmic control means for the public sphere, which means it’s essential that we study it.\ndanah and her team have brought together an amazing group of scholars, people doing cutting edge work on understand what algorithmic governance and control might and can mean. What I want to ask you to do is expand out beyond the scholarly questions you’re taking on and enter the realm of policy. As we figure out what algorithms are and aren’t doing to our civic dialog, what would we propose to do? How do we think about engineering a public sphere that’s inclusive, diverse and constructive without damaging freedom of speech, freedom to dissent, freedom to offend. How do we propose shaping engineered systems without damaging the freedom to innovate and create?\nI’m finding that many of my questions these days boil down to this one: what do we want citizenship to be? That’s the essential question we need to ask when we consider what we want a public sphere to do – what do we expect of citizens, and what would they – we – need to fully and productively engage in civics. That’s a question our founders were asking almost three hundred years ago when Franklin started turning the posts and print into a public sphere, and it’s the question I hope we’ll take up today.\nAlso published on Medium.","H. GEORGE FREDERICKSON\nHamilton Note: Significant parts of this article are taken from Public Administration with an Attitude. Passages in quotations are from The Federalist Papers or Papers on Public Credit, Commerce, and Finance.\nRare it is when the theories and practices of public administration are the subject of a Broadway musical; indeed, Hamilton is so rare that every bureaucrat should rejoice and sing along. LinManuel Miranda describes Alexander Hamilton as the “bastard son of a whore,” the “founding father, without a father.” All serious students of public administration know he was not only one of the nation’s founding fathers; Hamilton was the father of American public administration. Some argue that Woodrow Wilson is the father, but Vincent Ostrom, in The Intellectual Crisis in American Public Administration, destroyed that argument. It is Ostrom’s claim that Madison and Hamilton together crafted the American theory of democratic administration based on management in the context of the separation of powers and overlapping jurisdictions. This claim is pushed even further in Bertelli and Lynn’s brilliant Madison’s Managers: Public Administration and the Constitution. But, here the focus is on Hamilton and his particularly compelling story, the quintessential American story. He was born in St. Croix in the Caribbean, the illegitimate son of James Hamilton, an itinerant Scot, and Rachel Faucett, of Huguenot decent. Prior to meeting James, Rachel had been jailed for declining to live with her husband. Although still married, she and Hamilton had two sons, James and Alexander. Not long after Alexander was born, his father left. Rachel kept a provisions store in St. Croix to support her children. Alexander was bright, had good early schooling and, at an early age, apprenticed as a clerk to a merchant-trader. At 14, he sailed alone to New York with virtually no money. He worked as a clerk, put himself through Kings College, now Columbia University, and read the law. A hero of the Revolutionary War, he served as one of General Washington’s primary aides. At 32, he was appointed Secretary of the Treasury in Washington’s first cabinet and served throughout the president’s first term. It is generally agreed that Hamilton’s organization of the Treasury Department was fundamentally important to the early stability and effectiveness of American government. He took accounts that were in shambles and put them in order, balanced the books, paid off both the national Revolutionary War debt and states’ war debts and built the foundation for what is now the Federal Reserve Bank. He died at 47, killed in a duel with\nthen-Vice President Aaron Burr. He is buried in the yard of Trinity Church in lower Manhattan, two blocks from the World Trade Center. Hamilton’s story is compelling and his service to his country remarkable. Yet it is his words and ideas that have endured. More than any other founder, he shaped the Federalist perspective; that perspective has always shaped American public administration. Here are some of his words and ideas.\nOn the Powers of Government: “A government ought to contain…every power requisite to the…accomplishment of the objects committed to its care, and to the complete execution of the trusts for which it is responsible, free from every other control but regard to the public good and to the sense of the people.”\nOn the Executive Branch: “Energy in the executive is a leading character in the definition of good government. It is essential…to the steady administration of the laws, to the protection of property against…irregular and high-handed combinations, to the security of liberty against the enterprises…of faction.” “The vigor of government” is “essential to the security of liberty.” “When the dimensions of a State attain to a certain magnitude, it requires the same energy of government…which [is] requisite in one of much greater extent…The citizens of America have too much discernment to be argued into anarchy. And… experience has…wrought a deep…conviction… that greater energy of government is essential to the welfare…of the community.” “[T]he true test of a good government is its aptitude and tendency to produce a good administration.” An energetic executive is necessary “to the protection of property against those irregular and high-handed combinations [factions] which sometimes interrupt the ordinary course of justice; to the security of liberty against the enterprises and assaults of ambition, of faction, and of anarchy.”\nOn the Legislative Branch: “The tendency of the legislative authority to absorb every other, has been fully displayed...In governments purely republican, this tendency is almost irresistible.”\n“[T]he representatives…in a popular assembly seem sometimes to fancy that they are the people themselves, and betray strong symptoms of impatience and disgust at the least sign of opposition from any other quarter; as if the exercise of rights, by either the executive or judiciary, were a breach of their privilege and an outrage to their dignity. They often appear disposed to exert an imperious control over the other departments; and as they commonly have the people on their side, they always act with such momentum as to make it very difficult for the other members of the government to maintain the balance of the Constitution.”\nconstitution, must necessarily be supreme over those societies, and the individuals of whom they are composed. It would otherwise be a mere treaty, dependent on the good faith of the parties, and not a government, which is only another word for political power and supremacy.”\nOn the Judicial Branch:\nOn the Separation of Powers and Checks and Balances:\n“The independence of the judges is…requisite to guard…the rights of individuals from the effects of those ill humors, which the arts of designing men, or the influence of particular conjectures, sometimes disseminate among the people…and which…have a tendency…to occasion…serious oppressions of the minor party.” “[T]he interpretation of the laws is the proper and peculiar province of the courts.” The courts must “do their duty as faithful guardians of the Constitution, where legislative invasions of it had been instituted by the major voice of the community.”\nOn the Direct Democracy: “It has been observed that a pure democracy, if it were practicable, would be the most perfect government. Experience has proven that no position in politics is more false than this. The ancient democracies (Greece and Italy), in which the people themselves deliberated, never possessed one feature of good government. Their very character was tyranny; their figure deformity. When they assembled, the field of debate presented an ungovernable mob, not only incapable of deliberation, but prepared for every enormity. In these assemblies the enemies of the people brought forward their plans of ambition systematically. They were opposed by their enemies of another party; and…the people subjected themselves to be led blindly by one tyrant or by another.”\nOn Federalism and State Rights: “If a number of political societies enter into a larger political society, the laws which the latter may enact, pursuant to the powers entrusted to it by its\nHamilton complains of “those practices…of the State governments which have undermined the foundations of property and credit, have planted mutual distrust in the breasts of all classes of citizens, and have occasioned an almost universal prostration of morals.”\n“But a confederacy of the people, without exaggeration, may be said to be entirely the masters of their own fate. Power being almost always the rival of power, the general government will at all times stand ready to check the usurpations of the state governments, and these will have the same disposition towards the general government. The people, by throwing themselves into either scale, will infallibly make use of the other as the instruments of redress.” “It is a fundamental maxim of free government, that the three great departments of power, legislative, executive and judiciary, shall be essentially distinct and independent, the one of the other.” “A salutary check upon the legislative body, calculated to guard the community against the effects of faction, precipitancy, or of any impulse unfriendly to the public good, which may happen to influence a majority of that body.” More than any of the founders with the possible exception of Benjamin Franklin, Hamilton saw clearly what the United States was to become. And, he was the only founder with a well-developed understanding of what was to become American public administration. Hamilton is our founding father. H. George Frederickson is distinguished professor emeritus in the School of Public Affairs and Administration of the University of Kansas. A past president of ASPA, he can be reached at [email protected]"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"sensitive"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:2a671e27-5b0f-412e-a559-788d54e5f434>","<urn:uuid:e3d6948b-d785-4938-b6a4-2c645e4c81a6>"],"error":null}
{"question":"I'm an environmental researcher tracking endangered species impacts - could you evaluate how the leatherback turtle nesting habits and conservation measures in Trinidad's beaches have been managed?","answer":"Leatherback turtles nest primarily at Grande Rivière and Matura beaches in Trinidad. These beaches are protected as prohibited areas, requiring special permits for turtle viewing. Leatherbacks are the largest surviving turtle species, reaching up to seven feet long and weighing over 2,000 pounds. Trinidad has implemented specific conservation measures including: prohibiting touching or disturbing nesting turtles and hatchlings, banning lights and flash photography that can disorient turtles, restricting vehicle access on nesting beaches to prevent crushing eggs, and requiring visitors to remain quiet and unobtrusive. Besides leatherbacks, Trinidad is also an important nesting ground for Hawksbills, Green Turtles, Olive Ridleys and Loggerheads.","context":["Welcome to the twin Island republic of Trinidad and Tobago.\nLocated at the northern edge of the South American mainland and lying just 11 kilometres (6.8 miles) off the coast of northeastern Venezuela.\nToday we focus on Trinidad the larger of the twin island republic and also the more Industrialized of the two islands, Is is known for the invention of the STEELPAN widely regarded as the only major musical instrument to be invented in the 20th century.\nToday we’ll be checking out the island of Trinidad and all of the attractions, local cultures, traditions and much more.\nKnown for its steelpan, limbo, carnival, jouvert and the musical styles of calypso, soca, parang, chutney, chutney soca, extempo, kaiso, parang soca, pichakaree, and rapso. Trinidad is ethnically and culturally diverse with Afro-Trinidadians and Indo-Trinidadians being the largest ethnic groups followed by “Mixed” Races, European, Chinese, Syrian/Lebanese descent and many more.\nTHINGS TO DO\nCARNIVAL FESTIVAL AKA The Greatest Show on Earth!\nRegarded as the largest street party in the world, Trinidad and Tobago’s Carnival is celebrated on the Monday and Tuesday before Ash Wednesday every year. The pre-carnival season starts just around December and lasts until just after Ash Wednesday with a multitude of amazing parties for daytime, nighttime and the beach and also major cultural competitions and events, but Band and Costume preparations and launches usually start as early as July!\nCarnival Monday opens with J’Ouvert at 4am, when revellers parade through the streets immersed in paint, grease and mud until sunrise. Later in the day on Monday and all day on Carnival Tuesday, thousands of masqueraders flood the streets throughout the islands in bold, colourful costumes, dancing through the parade routes to the exhilarating sounds of soca, steelpan and calypso music.\nSo what exactly does the Monday and Tuesday street party entail?\nWell to start the street partiers are more commonly referred to as masqueraders and these masqueraders don’t simply throw on any old thing and party! There is usually a process which starts months before Carnival actually launches, starting with costume preparation. Most Band houses produce “costumes” for their masqueraders to purchase usually upfront or a deposit is made and the rest paid off during the year. These costumes range from Brazil style exorbitant or simpler yet stunning costumes.\nMost carnival bands are All Inclusive, which means you pay one price upfront and get access to costumes, security, food and unlimited drinks during the Monday and Tuesday Carnival celebrations. And for those who may want to opt out of the all inclusive, there are some bands offering costume only.\nNot to be left out the children also partake in Carnival with their street parade usually held the last two Saturdays before the major Carnival celebrations and in my honest opinion this is what Carnival is about as these costumes are truly spectacular and the kids have a ball!\nYou should definitely put this on your bucket list and if you guys are interested in checking out Band Houses and what they offer for carnival check out a list of them below and most importantly don’t forget to plan early as some bands start taking reservations beginning in August and most hotels are sold out by October!\nSidenote check out my About Me page for a video clip of Trinidad Carnival!\n- Amazon Carnival (formerly Dream Team)\n- Bliss Carnival\n- Carnival Tribe\n- Colorz Fuh So\n- Clay J’ouvert\n- “D” Harvard Boys\n- D’ Krewe Mas Group\n- Fantasy Carnival\n- ICandy Carnival (J’ouvert band)\n- IRave Jouvert (J’ouvert band)\n- Island People Mas\n- K2K Carnival Mas\n- Kalicharan Carnival\n- Lordstreet and Break-a-Leg Productions\n- Mas Rebellion\n- Monday Nite Jammerz\n- National Carnival Bands Association of Trinidad & Tobago\n- National Carnival Commission\n- Peppers Jouvert\n- Petle Mas\n- Ronnie & Caro McIntosh\n- Rosalind Gabriel\n- Rugeri Promotions\n- Trini Revellers\n- Trinidad Carnival Diary\n- Undercover Promotions (Facebook)\n- Undercover Promotions-UCP (Facebook)\n- YUMA Vibe\nPLACES TO SEE\nCaroni Bird Sanctuary\nThe Caroni Bird Sanctuary is located off the west coast of Trinidad, in a bay situated a half-hour drive from the capital Port-of-Spain, this swamp is the second largest mangrove wetland in Trinidad and Tobago and is home to over 100 bird species including the Scarlet Ibis (Eudocimus ruber). This Sanctuary also provides a variety of habitats for flora and faunal species and It’s also a nursery for marine and freshwater species.\nThe Caroni Swamp is protected under the Ramsar Convention. The Ramsar Convention is the intergovernmental treaty that provides the framework for the conservation and wise use of wetlands and their resources . It all started during the 1960’s when people became concerned about the increasing loss and the degradation of wetland habitat for migratory birds. The treaty was first adopted in the Iranian city of Ramsar in 1971. The Ramsar Convention is the oldest intergovernmental environmental agreements which came into force in 1975. The Caroni Swamp has a total of 20 endangered species and is ecologically diverse. source: caronibirdsanctuary.com\nFor Tours check out: www.nananecotours.com\nAsa Wright Nature Centre\nThis centre is home to over 400 bird species including the purple honeycreeper, tufted coquette (a hummingbird), tropical mockingbird, and oilbird. On the nature trails you can also spot Red brocket deer, Agouti as well as the elusive ocelot.\nThe Centre offers day visits daily from 9am – 5pm, guided walks are conducted and usually last 1.5 hours, afterwards you can then relax at the centre’s Jade Vine Terrace or Verandah which offers spectacular views. There is also a restaurant serving buffet style lunch and afterwards you can then take a dip at the lovely clear water pool.\nFor those wishing to stay for a longer visit the centre has a Lodge offering accommodations in cottages located near the main house. Rates include Sunrise coffee or tea on the Verandah, Breakfast and Lunch in the Dining Room, Afternoon Tea and Sunset Rum Punch on the Verandah, and Dinner in the Dining Room.\nThe Pitch Lake\nLocated in the southwestern area of La Brea, the Trinidad Pitch Lake is the largest natural deposit of asphalt in the world.\nThis natural wonder measures approximately one hundred acres and is estimated to be 76 meters deep in the center. The surface of the lake is semisolid, and can be walked on, however the asphalt is so soft in certain areas you can sink slowly if you stand on the surface for too long.\nAlthough the lake appears dormant the asphalt still moves with a natural slow “stirring” action. Not only can the flow lines be seen on the surface of the asphalt, but trees and other objects have been known in the past to have appeared, disappeared and reappeared.\nThe origin of the pitch lake was created thousands of years ago by the process of subduction, when the Caribbean continental plate was forced under another plate. This opened fault lines that allowed oil from deep underground deposits to rise to the surface, where it collected in a volcanic crater. The air caused lighter elements of the oil to evaporate, leaving behind the heavy asphalt, a mix of oil, clay and water.\nThere are official tour guides on site and after paying a fee in the visitor facility building, one of the guides take you out on the lake for an informative tour.\nHere’s a recipe for the famous Bake and Shark: http://www.simplytrinicooking.com/bake-and-shark/ try it and see!\nIt is a wondrous site to see these majestic creatures emerge from the beaches and slowly make their way to nest and lay their eggs. The hatchlings emerge into the world two months after.\nThey usually nest at the Grande Rivière and Matura beaches and it should be noted in order to protect these endangered species, these beaches are prohibited areas and permission and permits is required for the purpose of turtle viewing.\nLeatherbacks are the largest surviving turtle species on earth. Some can reach up to seven feet long and weigh more than 2,000 pounds. These reptiles can dive to depths of 4,200 feet — deeper than any other turtle — and can stay down for up to 85 minutes. They can live up to 45 years. Once prevalent in every ocean except the Arctic and Antarctic, the leatherback population has declined dramatically in many parts of the world. Source: discovertnt.com\nIn addition to the Leatherback turtle, Trinidad is also an important nesting ground for other turtle species mainly the Hawksbills, Green Turtles, Olive Ridleys and Loggerheads.\n- Do not touch or disturb nesting turtles or hatchlings in any way. Give them ample space\n- Lights (including flash photography), noise and activity tend to disorient both turtles and hatchlings\n- Try to be quiet and unobtrusive, and do not use flashlights or flash photography\n- Do not try to pick up hatchlings or impede their progress to the sea\n- Do not drive on nesting beaches; the weight of the vehicle can crush eggs buried in the sand.\nCheck out http://www.turtlevillagetrust.org/turtle-watching.htm for more information on obtaining permits and visiting.\nTrinidad is a very diverse land with many things to see and do but you should make the above your “to do list” when visiting and you won’t be disappointed!\nAfter all the excitement from Trinidad, a well deserved break in Tobago is up next, check out the island of Tobago HERE!"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:39c8264d-483d-49ee-b3a4-8ffd5ab55647>"],"error":null}
{"question":"What support services and resources are available to help communities acquire local assets?","answer":"A My Community Rights online hub and advice service has been established to support communities. Additionally, there is a £19 million Community Ownership of Assets programme that offers grants to communities wanting to take control of local assets such as pubs, shops, or libraries. These resources are designed to help community groups navigate the process of acquiring community assets under the Localism Act.","context":["The Community Right to Bid , along with ‘Community Asset Transfer’, ‘Community Right to Challenge’ and ‘Community Right to Build’, is part of the Localism Act and came into force in 2012. Under the Act, voluntary and community organisations and parish councils can nominate an asset to be included on a list of ‘assets of community value’ which is managed by the local authority. If the owner of a listed asset wants to sell the asset, a six month moratorium period will be triggered during which the asset cannot be sold. This period gives community groups some time to develop a proposal and raise the required capital to bid for the property when it comes onto the open market at the end of the moratorium period. The Act does not, however, give community organisations the power to force a sale. Similarly, the vendor retains the right to reject a community organisation’s offer in favour of another offer. This is all in accordance with Part 5 Chapter 3 of the Localism Act 2011 (Assets of Community Value) (“the Act”) and The Assets of Community Value (England) Regulations 2012 .\nIn order to advise communities the My Community Rights online hub and advice service has been set up along with a £19 million Community Ownership of Assets programme offering grants to communities wanting to take control of a local asset such as a pub, shop, or library. In Brent, campaigners have been successful in adding Kensal Rise Library to the Brent Local Authority “List of Assets of Community Value”. The owners of the building, All Souls College, may now have to rethink their deal with property developers to build flats on the site, but All Souls can appeal against the decision. In West Somerset the owner of a pub that was recently listed has challenged the decision on the basis that he has lost money due to the property having to be taken off the market, so it will be interesting to see what All Souls do in this situation.\nThe TUC and the National Coalition for Independent Action have recently produced a report in which a range of contributors discussed the Localism Act. In particular, concerns were raised in the report about the ‘Community Right to Challenge’, which was seen by many to be a ‘trojan horse’ for privatisation but another general concern was:\n“…the lack of capacity within local community and voluntary organisations to make effective use of powers to buy community assets or produce neighbourhood plans. To many, this is seen as a way of empowering those in the community with the loudest voices, the most resources and the sharpest elbows to influence local decision making.”\nIn the article below from the ‘Local Government Lawyer’ website concerns are raised about the financial and time constraints forced on Local Authorities trying to administer the ‘Rights’.\n“Worth noting is that land that used to further the social wellbeing and social interests of the local community ‘in the recent past’ will still be caught by the definition if it is realistic to think that there is a time in the next five years when it could be used to further (whether or not in the same way as before) the social wellbeing or social interests of the local community.\nThis definition is potentially very wide and would include amenities that have closed ‘in the recent past’ (which is up to the local authority to decide) but could be re-opened as something else, as long as the new activity still serves the community.\nThe net effect of this is likely to cost local authorities both time and money, as they will need to set up (in a form to be prescribed by regulations), publish and maintain, a list of nominated assets and a list of unsuccessfully-nominated assets, deal with requests to add or remove assets from the list, act as an intermediary between the landowner and the community group wanting to bid for the asset, publicise notices of disposal, compensate landowners and enforce the provisions.”\nAll in all, the right of the property owner to challenge a listing linked with the communities lack of power in forcing sales and the right of the vendor to reject an offer appears to put the whole basis of the ‘Community Right to Bid’ on very shaky ground!"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:996e3b27-243a-46a3-8b02-cb89c65971df>"],"error":null}
{"question":"How do black spruce trees respond to climate change, and what natural disturbances affect their ecosystem?","answer":"Black spruce trees north of the 49th parallel in Quebec actually thrive in warmer, drier conditions expected with climate change, with projections showing 70% of trees between the 49th and 52nd parallels growing better between 2041-2070. However, these trees are affected by natural disturbances like forest fires, which are crucial for forest renewal by releasing nutrients and opening the forest canopy to sunlight. Additionally, insects and diseases play important roles by eliminating sick and aging trees, making the ecosystem more productive and increasing biodiversity through nutrient recycling.","context":["By: CBC News\nHere’s some good news for the animals that live in Eastern Canada’s boreal forest and the forestry industry that operates there — the trees that dominate the boreal forest can do just fine in the warmer, drier temperatures expected with global climate change.\nBlack spruce are found across North America from Newfoundland to Alaska, and are the most common tree in the eastern boreal forest.\nA new study has found that in Quebec north of the 49th parallel, black spruce seem to thrive and grow better in warmer, drier years, which are expected to become more frequent with climate change.\n“That area might be a refuge for all these migrating birds or all these species that use this habitat — it is good news,” said Loïc D’Orangeville, lead author of the new study, published this week in the journal Science. D’Orangeville is a post-doctoral researcher at the University of Quebec in Montreal and Indiana University.\nAnimals that rely on the eastern boreal forest include many songbirds that nest there, caribou, snowshoe hare, lynx and sable, he said, adding that black spruce are also important commercially for use in the pulp and paper industry.\nUnfortunately, the new study shows that Quebec trees south of the 49th parallel, which require more water due to the longer growing season, grew less well during warmer, drier years. That’s similar to what’s been found for black spruce farther west, where there is less rain.\nStill, the study predicts that between 2041 and 2070, based on median climate warming projections, about 70 per cent of Quebec black spruce trees between the 49th and 52nd parallels should grow better than they do now.\nThey could also spread north. Already, they grow in patches up to the 58th parallel, D’Orangeville said, “so we don’t see really massive obstacles that would inhibit them moving northwards.”\nHowever, he cautioned that the study only looked at the trees’ direct response to higher temperatures and drier conditions and not the impact of side-effects of climate change such as an increase in forest fires and insect outbreaks: “These could really change the portrait.”\nGrowth of 16,000 trees studied\nThe study looked at the growth of 16,000 trees across 583,000 square kilometres of Quebec south of the 52nd parallel between 1960 and 2004. D’Orangeville and his colleagues examined the growth rings in core samples drilled by Quebec’s Ministry of Forests, Fauna and Parks across the province over many decades.\nThe ministry takes pencil-shaped “biopsies” from the trees and looks at the rings from just the past few years to monitor the health and productivity of commercial forests.\nD’Orangeville analyzed decades of rings with the help of a computer program.\nHe said that normally researchers have access to hundreds of samples at most. The much larger data set in this case generates more complete, reliable results.\n“That really emphasizes the importance of government funding into this monitoring work and the long-term data, how important it is to get a good grasp of how ecosystems doing,” he added.\nThe new findings will be useful to conservationists and foresters.\n“The productive forest is migrating north,” said D’Orangeville, noting that the industry is already aware of that and recalibrating where logging is allowed.\nPeople also need to consider where millions of black spruce trees are going to be replanted each year to replace stands that have already been logged.\n“In terms of conservation,” he added, “if you want to protect, for instance, the black spruce ecosystem in Quebec, you have to think about the future of the ecosystem, where it’s going to be in the coming decades.”\nBy: CBC News","How do natural disturbances affect Canada’s forests?\nNatural disturbances such as forest fires, insect and disease outbreaks, drought, wind throw and floods have occurred in Canada’s forests for thousands of years. Disturbance is part of the natural life cycle of the forest and most often helps the forest to renew itself.\nDisturbances are particularly important to the cycle of regeneration and regrowth in boreal forests. Fires, as well as insect and disease outbreaks, often occur on a large scale there, more so than in Canada’s temperate forests. Here are some of the ways that these natural disturbances work to renew boreal forests.\nForest fires often stimulate new growth\nFire, the primary change agent in the boreal zone, is as crucial to forest renewal as the sun and rain. Forest fires release valuable nutrients stored in the litter on the forest floor. They open the forest canopy to sunlight, which stimulates new growth. They allow some tree species, like lodgepole and jack pine, to reproduce, opening their cones and freeing their seeds. Learn more about the effects of wildfire in the forest.\nInsects reduce aging trees and make the forest more productive\nInsects are important in the life cycle of boreal forests. Large insect outbreaks that occur regularly help to renew the forests. Insects release nutrients stored within trees. Infestations also eliminate sick and aging trees, reducing competition among trees and making the ecosystem more productive. Find out about the insects that affect forests in Canada.\nDiseases eliminate weak trees and give new species a chance to thrive\nDiseases contribute to the forest ecosystem by speeding up the mortality of weak and over-mature trees, clearing the way for forest renewal and increasing biodiversity. Diseases also break down dead plant material, a process that recycles nutrients and organic matter. Root diseases are among the most common in boreal forests. Read about the ways diseases impact Canadian forests.\nCanada closely monitors and reports on natural disturbances\nAlthough natural disturbances generally benefit the long-term health of Canadian forests, they can sometimes have public safety and environmental consequences. Canada closely monitors disturbances in its forests and reports publicly on their effects. The annual State of the Forest report includes the latest information on key disturbances such as fire, insects and disease. The government also makes a number of tools available to the public, such as maps to monitor forest fire conditions in Canada and databases of insects and diseases in Canada’s forests.\nNatural Resources Canada–Canadian Forest Service scientists conduct extensive research and analysis on natural disturbance in Canada’s forests. Their reports are used to inform forest management planning, forest laws and forestry practices. For example, scientific research has helped evolve modern harvesting techniques to more closely mimic the effects of natural disturbance on the forest.\nAlthough forest fires, insects and diseases do temporarily reduce the forest area, it’s important to remember that the trees will almost always grow back. Natural disturbance should not be confused with deforestation. A forest that will grow back is still a forest.\nLearn the difference between natural disturbances and deforestation\nNatural disturbances like wildfire or disease are often mistakenly thought to cause deforestation. Find out why this is untrue when you read these 7 reasons why disturbances don't cause deforestation.\n- Current figures on forest insects, forest diseases and forest fires\n- Maps to monitor forest fire conditions across Canada\n- Wildfire situation report for Canada’s forests\n- Images and information about trees, insects and diseases in Canada’s forests\n- Lists and databases of insect species that are native and alien to Canada"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:6384e00d-0503-4eba-a654-997411b352e6>","<urn:uuid:de4e1dfb-3c34-4589-8327-6221dbfcac56>"],"error":null}
{"question":"What steps happen after someone is arrested for a crime in Henry County's criminal justice system?","answer":"After an arrest, the accused is first offered an opportunity to make bail or bond to await further proceedings. Then, a preliminary hearing is usually held within two weeks in Magistrate Court, where a judge determines if there's sufficient evidence to proceed to Superior Court. Next, the case goes to grand jury presentation, where they vote to either 'indict' or 'no bill' the case. If indicted, the accused appears before a Superior Court Judge to plead guilty or not guilty. This leads to either immediate sentencing or scheduling for trial.","context":["Victim Services Program\nWelcome to our web site. I hope\nit will assist you in better understanding the Criminal Justice\nSystem and the role of the District Attorney's office in the\nThe District Attorney represents\nthe State of Georgia in the prosecution of felony crimes committed\nin Henry County. This representation involves assisting victims\nof crimes in a variety of ways (See Victim Services Program\nfor details), attending Grand Juries and serving as their\nlegal advisor, conducting jury trials for those criminal cases\nthat do not plead guilty, and representing the State in drug\nforfeiture cases by seeking to condemn profits made by drug\ndealers. The District Attorney also prosecutes delinquency\ncases in the Juvenile Court of Henry County.\nThe District Attorney also represents the State when criminal\nconvictions are appealed from the Superior and Juvenile Courts\nto either the Georgia Court of Appeals or the Georgia Supreme\nThe District Attorney also prosecutes both civilly and criminally\nparents of children that fail to pay child support. This unit\nhas collected millions of dollars in support for children\nfrom their absent parents.\nThroughout all of these duties, the District Attorney's basic\nfunction is to serve Justice in all cases.\nIf I can be of service to you, feel free to email or call\nTommy K. Floyd\nFlint Judicial Circuit\nFor more information:\nThe Flint Judicial Circuit District Attorney's Office has established a Victim Services Program to assist those who are victimized by crimes committed in this circuit. As a victim/witness to a crime, you have certain rights as outlined below. Please notice that you are required to provide a current address and phone number to the notifying agencies if you wish to exercise your rights as a victim. You also have a right to waive these rights if you do not wish to exercise them.\n- You have the right to designate a family member to exercise your privileges and rights if you are physically disabled.\n- You have the right to notification of the accused's arrest, release from custody, and any judicial proceedings at which such release is considered.\n- You have the right to notification of accused's pretrial release, and of these victims' rights, and the availability of victims' compensation and services.\n- You have the right to express your opinion as to pending proceedings and to file written complaints through the prosecuting attorney in the event of release from custody.\n- You have the right to notification by the prosecuting attorney of legal procedures and in victims' rights in relation thereto, such as procedural steps in processing a criminal case, and suggested procedures if threatened or intimidated.\n- You have the right to have a separate waiting area at court proceedings.\n- You have the right to request that defense counsel not disclose victim information to the accused.\n- You have the right to express your opinion on the disposition of the accused's case.\n- You have the right to notification of accused's motion for new trial or appeal, release on bail or recognizance, appellate proceedings, outcome of appeal, and victim's rights retained at new trial or on appeal.\n- You have the right to notification of impending parole or consideration for parole.\nAs well as assisting you with exercising the above-listed rights, the Victim Services Program can also provide you with additional services:\n- Referrals (including emergency referrals) to other service providing agencies in the community that provide counseling, or food, clothing, shelter or medical care.\n- Preparation and orientation for court appearances.\n- Escort and/or moral support in the courtroom.\n- Restitution information/property return assistance/victims' compensation assistance.\nRemember, if you wish to exercise these rights and receive the full benefits of all these services, it is important to request so in writing. There is a notification form available for your convenience that you can obtain through the District Attorney's Office.\nOur office is located in the Henry County Courthouse, One Courthouse Square, McDonough, Georgia 30253.\nSpecial Services for Child Victims:\n- Courtroom Orientations for children\n- Age appropriate materials (e.g. coloring books - tips on testifying)\n- Video materials available for viewing\nCrime Victim Compensation\nThe State of Georgia has a program to assist you with crime related expenses if you are a victim of violent crime. It can compensate victims for medical costs, counseling, lost wages, funeral expense, and various other costs. The program is offered as a payer of last resort. For more information, contact the District Attorney or the following address:\nOffice of the Governor\nCriminal Justice Coordinating Council\n503 Oak Place, Suite 540\nAtlanta, GA 30349\n(404) 657-2222 or online\n- Office of the District Attorney (felonies): (770) 288-6400\n- Office of the District Attorney (Juvenile): (770) 288-6356\n- Clerk of Superior Court:\n- Magistrate Court: (770) 288-7700\n- Solicitor's Office (misdemeanors): (770) 288-7178\n- Henry County Police Department: (770) 288-8200\n- Henry County Sheriff's Department: (770) 288-2200\n- McDonough Police Department: (770) 957-1218\n- Locust Grove Police Department: (770) 957-7055\n- Hampton Police Department: (770)946-4513\nVictim Services Program\n- District Attorney's Office: (770) 288-6400; E-Mail\n- Juvenile Division: (770) 288-6345; E-Mail\nCriminal Justice Process\nThe following is a brief overview of the procedures involved in the criminal justice system. Of course, every case is unique and may have special considerations.\nUsually, for the accused to be arrested, a warrant must be issued by the Magistrate Court. This can be done by an officer or by a civilian.\nAn arrest is made when the police officially takes a person into custody. The police are required to advise the individual of certain rights entitled to him.\nBail or Bond\nAfter the arrest, the accused is offered an opportunity to make bail or bond. By paying the specified amount of money, the accused is allowed to be free from jail to await further legal proceedings. The justification for bail or bond is to assure the accused appears in court and it further serves to maintain the presumption of innocence for the accused.\nThere are certain crimes that require bail or bond to be set by the Superior Court Judge. Those crimes include: Murder, Rape, Armed Robbery, Hijacking, Certain Drug Offenses, Aggravated Child Molestation, Aggravated Sexual Battery, Treason, Aggravated Sodomy, Aggravated Stalking. Also Kidnapping, Arson, Aggravated Assault, and Burglary if previously convicted of or on bail for any of these crimes.\nThe Superior Court Judge hears the petition brought before him for setting a bond. He then rules on the motion and either sets or denies bond.\nA preliminary hearing is usually held within two weeks after the arrest of the accused. It is usually held in the Magistrate Court. At this hearing, evidence is presented to the presiding judge, who decides if the evidence presented to him or her is sufficient to proceed in Superior Court. This is sometimes referred to as binding the case over for grand jury presentation.\nThe purpose of grand jury presentation is to hear testimony and facts from the officer and/or victim involved in the case. The grand jury is closed to the public. Only those subpoenaed to testify are allowed to participate. After hearing the presentation, the grand jury votes on the case. If they determine the defendant should be formally charged, they \"indict\" the case. If they determine the defendant should not be formally charged due to insufficient evidence, they \"no bill\" the case.\nAfter the grand jury has indicted a case, the accused will appear before a Superior Court Judge and either plead \"guilty\" or \"not guilty\". If the defendant pleads guilty, the Judge will probably sentence him or her on that day. If he or she pleads not guilty, the case will be put on a trial calendar unless the defendant changes his or her plea.\nThe purpose of a jury trial is to lay before the selected jury the evidence in a case and the law that applies. A jury considers the evidence presented to them by the prosecuting attorney and the defense attorney who represents the defendant. Witnesses are subpoenaed to testify in court, which is a legal notification issued by the Clerk of Superior Court. Trials vary in length and sometimes require a good deal of waiting. Usually, all witnesses are \"sequestered\" which means they are removed or set apart from other witnesses and from hearing testimony in the courtroom. After a victim has testified, it may be possible for her or him to remain in the courtroom for remaining testimony. At the conclusion of opening statements, evidence, closing statements, and the jury charge, the jury deliberates until they reach a verdict. If a verdict is reached, they return the verdict in open court which will be either \"guilty\" or \"not guilty\". If the jury cannot reach a unanimous verdict, a mistrial is declared.\nThe judge imposes sentence usually immediately following the trial. Sometimes a pre-sentencing hearing is held for the judge to consider. The defendant could receive prison time and/or probated sentence. If the defendant receives probation, he or she will be assigned a probation officer to whom he or she will be required to report and keep informed of his or her current residence, place of employment, and any trips out of town. Victims (or survivors) of sex-related crimes and/or violent crimes resulting in bodily injury or death have the right to be notified prior to any order by the Court shortening the period of probation originally ordered. It is the victim's responsibility to keep the Probation Office notified of his or her address. The victim notification form for the Probation Office can be obtained through the Victim Services Program in the District Attorney's office. If the defendant receives a prison sentence, the defendant will enter the State of Georgia's prison system and will serve the time in a state facility. The Georgia Department of Corrections has a notification program to which you may request notification regarding release from prison upon serving the maximum sentence, transfer, escape and recapture, or death of an inmate while in custody. This is different from parole notification. (See Parole below). To request notification from the Department of Corrections, notify the District Attorney's office or contact:\nGeorgia Department of Corrections\nVictim Services/Operations Divisions\n2 Martin Luther King Jr., Dr. S.E.\nAtlanta, GA 30334\nVictims' Advocacy Office\nState Board of Pardons and Paroles\n2 Martin Luther King, Jr. Dr., S.E.\nAtlanta, GA 30334\nRemember: If you wish to request that the District Attorney's office keep you notified regarding a court case, you must request it in writing, providing an address and current phone number where you can be reached. We will send you a notification request form if you call victim services at (770) 288-6400."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:8b807e32-3bf7-4aab-adb3-1a49af10bdc8>"],"error":null}
{"question":"Which preserves better - vinegar in hot sauce or baking soda in cleaning products?","answer":"Vinegar is the more effective preservative of the two. When used in hot sauce at 20-30% concentration, vinegar's acetic acid actively kills microbes and keeps the pH level at 4.6 or below as required by FDA guidelines for preservation. While baking soda has some deodorizing properties that can keep things fresh temporarily (like in fridges or microwaves), it does not actually preserve or prevent microbial growth the way vinegar does.","context":["There is a box of baking soda in my kitchen, another in my bathroom and still another in the living room. Funny thing about baking soda is that you can find it located in your detergent aisle and the food aisle of your local grocery store. Stores may or may not add tax not knowing whether to count it as a food item or a cleaning aid. Well, you be the judge:\nDefined by Answer, baking soda is: ”A white crystalline compound, NaHCO3, with a slightly alkaline taste, used in making effervescent salts and beverages, artificial mineral water, pharmaceuticals, and fire extinguishers. Also called bicarbonate of soda, sodium bicarbonate.”\nIs there a kitchen in America that does not contain at least one box of baking soda in the cup board, fridge, under the sink, or near the stove for dousing grease fires?\nAccording to Reader’s Digest. com and About.com baking soda is whole lot more.\n1. It is a mechanical leavening agent, used to incorporate air into the batter of dough. This method depends on steam to give the food the lift it needs making our biscuits and pastry light and fluffy.\n2. It creates the base that accepts a hydrogen ion from an acid. Baking soda is 9 on the PH scale, while some vinegars and lemon juice are acidic placing 2 on the PH scale. (There is science in our soda.).\n3. The alkaline crystalline structure of baking soda makes it a mildly abrasive cleanser used in tooth pastes, facial cleansing, and household cleaning. It works hard at removing plaque from tooth enamel while being less abrasive than commercial teeth whiteners. Baking soda can also be made into a paste to help shine chrome, and clean the oven.\n4. Leave an open box in your microwave and fridge to keep the appliances fresher and keep unpleasant odors and flavors from your foods. Just do not forget to remove the box prior to using your microwave. Replace the boxes every three months.\n5. Use as an antacid by mixing ½ teaspoon baking soda in 3 to 4 oz. of warm water. Drink.\n6. Add ¼ cup of baking soda to 1 quart of warm water and clean pool toys without worrying about a harmful soapy residue remaining on the toys.\n7. To aid in cleaning your barbecue grills use 3 parts baking soda to 1 pint warm water.\n8. To clean drains pour ½ box of baking soda down the drain, follow with white vinegar. After the foam settles, repeat.\n9. To sooth tired feet and improve dryness or eczema soak for ½ hour in warm water and baking soda.\n10. To relieve sinus infection add a dash of salt, a dash of baking soda and one tablespoon warm water and squirt into the nasal passages. Please do not disregard your doctor’s advice or consider this tip to be meant as medical counsel.\n11. Form a paste with baking soda and warm water to apply to bee, mosquito, and wasp stings.\n12. When cooking dried beans, add ½ teaspoon to water to get rid of gases caused by carbon dioxide.\n13. Add ½ cup baking soda to your wash load and boost your detergents cleaning power.\n14. Remove hard water stains from your car’s chrome.\n15. Use in a pinch as a deodorant.\n16. Reduce swelling from swollen eyelids by creating compresses with warm water and baking soda. Leave on eyes for ½ hour.\n17. Scatter over kitty litter or carpet to neutralize odors.\n18. Help eliminate urine odors from furniture left by pets and children. Pour directly on the spot and allow it to absorb as much of the moisture as possible. Remove loose powder and use clean powder to scrub the area.\n19. Clean daily wear contacts.\n20. Scrub your produce in a pot of cold water with 2 to 3 tablespoons baking soda with a clean wet sponge or vegetable brush. Rinse thoroughly prior to cooking.\n21. Soaking your raw fish steaks or filets for about an hour prior to cooking will remove the fishy smell. Soak fish in a bowl of could water containing 1 quart of water and 2 tablespoons baking soda. Rinse fish well before cooking.\n22. The acid in certain foods can be lowered with a pinch of baking soda. Adding a pinch of soda to your coffee before brewing or to tomatoes before serving is easier on the stomach.\n23. Using ½ teaspoon to 3 eggs while preparing an omelet creates a fluffier omelet.\n24. Baking soda can be used to substitute for yeast. An equal part of powdered vitamin C to an equal of baking soda so that the combined measurement equals to the required measurement of yeast for the recipe. There is an added bonus to this in that the dough will not need to rise prior to baking.\n25. Baking soda makes a good hand cleanser to remove foul odors.\n26. Soak baby’s bottles, nipples, pacifiers, bottle brushes, and caps in a bowl of warm water and ½ box of baking soda. Rinse thoroughly and dry in the morning.\n27. Save money on dish washer detergent by making your own with 2 tablespoons borax and 2 tablespoons baking soda.\n28. Make a past with warm water, baking soda, and salt to scrub cutting boards and counters.\n29. Deodorize your dishwasher by sprinkling the bottom of your dishwasher with baking soda.\n30. Add a few tablespoons baking soda to your dish water when washing dishes to aid in cutting grease.\n31. Dish rags or sponges smelling foul? Soak overnight in 2 tablespoons baking soda and 2 drops of antibacterial dish detergent and 1 pint of warm water. Rinse with cool water in the morning.\n32. Let your thermos sit overnight with a baking soda solution of ¼ cup baking soda to 1 quart water. Use a bottle brush to help loosen residue, before filling. Leave overnight and it should wash much easier in the morning.\n33. Brew a quart of water and ¼ cup of baking soda in your coffee pot. Follow by brewing with clear water and rinsing thoroughly.\n34. Cover grease stains on counter tops and stoves with baking soda then wash with wet towel or sponge.\n35. To remove coffee and tea stains from your mugs, coffee pots, or tea pots fill them with 4 tablespoons baking soda to 1 cup vinegar. If you prefer, you can substitute 2 tablespoons baking soda to the juice of ½ lemon. Boil and let simmer for 5 minutes. Scrub when cool, and rinse thoroughly.\n36. Deodorize your garbage cans.\n37. Clean your pots and pans by simmering with a baking soda and water mixture. Rinse thoroughly and season lightly with oil.\n38. Tenderize a tough cut of meat by rubbing with baking soda and placing in the fridge for three to five hours. Rinse thoroughly prior to cooking.\n39. Help erase the nicks in counter tops by scrubbing a paste of baking soda and water into the areas and scrubbing.\n40. Help snuff out grease fires in the kitchen. When grease becomes inflamed while cooking, usually baking soda poured directly on the flame will put the fire out. This is not meant to advise anyone to battle an uncontrollable blaze in their home. Any fire that cannot be quickly snuffed should be considered serious. Occupants should leave the area immediately and call for help.\nThis post linked to OYGIF!","Last Updated on March 20, 2023 by Chris Whitehair\nAll of Your Vinegar in Hot Sauce Questions, Answered.\nIf there was a trinity of hot sauce, it would be chili peppers, vinegar and salt (but if you’re needing to watch your salt intake, check out my other blog on Low Sodium Hot Sauce). Also, this trinity is not to be confused with Irazu Unholy Trinity Hot Sauce which is comprised of Ghost (Naga Jolokia), Trinidad Scorpion and Carolina Reaper peppers. Vinegar in hot sauce is the second most important part of that trinity.\nIn this blog, we’ll cover:\n- A brief history & science of vinegar.\n- Why we need vinegar in hot sauce.\n- The 6 best types of vinegar for a hot sauce.\n- What to do if you hate vinegar in hot sauce.\nBy the end, you’ll have an impressive understanding of all things vinegar. And you’ll know enough about it to up your sauce-making game with more diverse and complex flavors.\nLet’s dive in!\nWhat is Vinegar?\nThe best place to start is with the name, which comes from vyn egre. “Vyn” means wine and “egre” means sour. And just about everything you need to know about vinegar is summed up in that name — sour wine.\nYou see, vinegar is basically just fermented alcohol. It’s second generation booze. And if you want to get more technical, we can say that it is,\nWater (90-95%) + Acetic Acid (5-10%) = Vinegar\nAnd this acetic acid is what you get when you let a little organism called aceto bacteria get drunk off your liquor. It can be any liquor too, not just wine. You could have your aceto bacteria feed off cider, grain alcohol, grape must, coconut and more.\nThe basic formula is:\n- Add a grain or sugar (potato, rice, grape, apple) to water\n- Let yeast turn the sugars into ethyl alcohol\n- Put some aceto bacteria in the mix to feed off the alcohol\n- Collect the acetic acid they produce as waste\n- Dilute it with some water\nAnd voila, there’s your vinegar! You can make it from just about any kind of sugar that’s been turned into an alcohol (which gives you all of the different vinegar flavors that we’ll talk about in a moment).\nThis is all interesting, but it does beg the question…\n“Why Do We Even Need Vinegar in Hot Sauce?”\nWell, for two reasons:\n- To preserve it.\n- To drive its flavor.\nAcetic acid kills microbes that cause foods to spoil and allows it to last longer. This is why you see bottles of Cholula® sitting out on the tables of Mexican restaurants for what seems like years on end (but remember, we’re not talking refrigeration, that’s a whole other topic you can read about here).\nThe FDA classifies vinegar as an “acidified food,” which means that it’s heavily regulated. And according to FDA guidelines, an acidified food has to maintain a pH level of 4.6 or below. One of the only ways to achieve this is by using vinegar, hence why it’s so common.\nBut vinegar also drives the flavor of most hot sauces. It adds that unmistakable sour, tangy, and lip-smacking quality. For many, that flavor is indispensable.\nIf you are wondering how much vinegar to use to preserve hot sauce, the standard recommendation Is 20-30%.\nDifferent vinegars also add unique flavors to a sauce. And, if you know how to use them, vinegar in hot sauce can bring incredible depth to them. Which leads us to…\nThe 6 Best Vinegars for a Hot Sauce\nThere are as many types of vinegars as there are sugars to ferment. Which is basically a way of saying that there’s a lot of different kinds! Potatoes, rice, corn, fruit — any of these work for making vinegar.\nBut when it comes to hot sauces, not all vinegars are made equal. And some have established themselves as the quintessential hot sauce vinegars.\nSo, without any further ado (and in no particular order), here are your Top 6 Hot Sauce Vinegars.\n1. White Vinegar\nAll hail the king of vinegars! White vinegar in hot sauce is by far the common vinegar. Really, the most common in all of cooking.\nIt’s made from a grain alcohol similar to vodka, so it has the most neutral taste out of any vinegar. This makes it perfect as a foundation for other ingredients.\nYou can think of it as a blank slate that allows other flavors to shine through. Despite its neutral flavor, though, white vinegar is still strong, sharp and forward.\nThere are countless sauces that use white vinegar as a base, but Fresco Sauce Chipotle & Habanero Hot Sauce is one of my favorites.\nThis great sauce was featured on the hit YouTube show Hot Ones Season 12.\nExample containing White Vinegar:\nFresco Sauce Chipotle & Habanero Hot Sauce\nIngredients: Habanero Peppers, Chipotle Chili Powder, Carrots, Distilled White Vinegar, Olive Oil, Garlic, Salt, Organic Sugar, Black Pepper, Water.\nOther Great White Vinegar Hot Sauces\n2. Apple Cider Vinegar\nSince this vinegar is derived from apple cider, it has a sweeter, fruitier taste. It also has an incredibly distinctive flavor (as anyone who’s tried Bragg Organic Apple Cider Vinegar straight-up can attest), while still being softer than white vinegar.\nApple cider vinegar pairs best with a sweeter hot sauce. For example, those containing fruit like mango or pineapple.\nFor example, one of my favorite hot sauces that uses it is PepperNutz Caribbean Rum Hot Sauce, which pairs an apple cider vinegar base with cayenne peppers, pineapple, mango and dark rum! It’s a taste of the Caribbean!\nExample containing Apple Cider Vinegar:\nPepperNutz Caribbean Rum Hot Sauce\nIngredients: Pineapple, Apple Cider Vinegar, Dark Rum, Honey, Mango, Natural Sugar, Raisins, Water, Cayenne Peppers, Peri Peri Peppers, Spices, and Xanthan Gum (a natural thickener).\nOther Great Apple Cider Vinegar Hot Sauces\n3. White Wine Vinegar\nThis vinegar is taken from white wine and has a sweeter, more mellow taste. It’s tart, but doesn’t have the same bite as a white vinegar. It’s perfectly in the middle — not too sour, not too sweet.\nBecause it has a lower acidity, though, you’ll see it often blended with another vinegar. However, a great example of a sauce without another vinegar mixed in is Bravado Spice Co.’s Ghost Pepper & Blueberry Hot Sauce.\nThis hot sauce was also on Hot Ones during Season 3.\nExample containing White Wine Vinegar:\nBravado Spice Co. Ghost Pepper & Blueberry Hot Sauce\nIngredients: Blueberry, Raspberry, White Wine Vinegar, Ghost Pepper, Ground Black Pepper, Salt.\nOther Great White Wine Vinegar Hot Sauces\n4. Rice Wine Vinegar\nRice Wine Vinegar in hot sauce has a very delicate flavor. Out of all vinegars, it probably has the mildest flavor. Sweet and not overwhelming.\nIf you see just “Rice Vinegar” on the label, don’t be confused, rice wine vinegar is the same thing as rice vinegar.\nIt is best to pair rice wine vinegar with another type such as apple cider or white.\nThere are quite a few hot sauces that incorporate rice wine vinegar. One of my favorites is High River Sauces Foo Foo Mama Choo Hot Sauce which is made with the hottest pepper on earth, the Carolina Reaper.\nExample containing Rice Wine Vinegar:\nFoo Foo Mama Choo Hot Sauce\nIngredients: Roasted Red Peppers (roasted peppers, water, salt, citric acid), Fire Roasted Tomatoes (vine ripened tomatoes, tomato juice, salt, citric acid), Rice Wine Vinegar, Reaper Peppers, Onions, Brown Sugar, Garlic, Soy Sauce, Ginger Root, Salt, White Pepper, Secret Herbs & Spices.\nOther Great Rice Wine Vinegar Hot Sauces\n5. Red Wine Vinegar\nRed wine vinegar in hot sauce is a little less common than other vinegars but it still works great for some hot sauces. A lot of people love the distinct flavor, which is slightly fruity.\nIt mixes great with other vinegars too.\nOne of my favorite hot sauces to use Red Wine Vinegar is Rising Smoke Sauceworks All In which blends red wine vinegar with not one, not two, not three but four peppers: Smoked Carolina Reaper, Ghost Pepper, Smoked Habaneros and Cayenne. Divine!\nExample containing Red Wine Vinegar:\nRising Smoke Sauceworks All In\nIngredients: Red Wine Vinegar, Smoked Carolina Reaper Pepper, Ghost Pepper, Smoked Habanero Pepper, Tomatoes, Chili Powder, Garlic Powder, Cayenne Powder, Pink Himalayan Salt, Basil, Oregano.\nOther Great Red Wine Vinegar Hot Sauces\n6. Balsamic Vinegar\nBalsamic vinegar in hot sauce? This is the wildcard of hot sauce vinegars, and you won’t find it used that often. If you can find it, it’s an amazing addition when it’s used right.\nMade from grape must, real balsamic vinegar is an art form. It has to be made with a very specific grape from Modena and aged in progressively smaller barrels for 15-25 years. Our Flower City Flavor Company Dark Traditional Balsamic Vinegar is one of the best available on the market.\nBut even some (semi-) knock-off balsamic vinegars can go great in hot sauce. Because their flavor is so powerful and distinct, though, it’s usually best to dilute it with another vinegar, like apple cider.\nYou have to dig a little bit to find a sauce that uses balsamic. The one that really stands out In my mind is Angry Goat Pepper Co.’s Chocolate Habanero, Balsamic & Black Garlic Hot Sauce.\nExample containing Balsamic Vinegar:\nAngry Goat Pepper Co. Chocolate Habanero, Balsamic & Black Garlic\nIngredients: Chocolate Habanero Pepper Mash (peppers, vinegar), Balsamic Vinegar, Apple Cider Vinegar, Smoked Vermont Maple Syrup, Water, Black Garlic Powder, Granulated Garlic, Sea Salt.\nOther Great Balsamic Vinegar Hot Sauces\n“What if I Hate Vinegar in Hot Sauce?”\nYou’ll often hear people complain about the vinegar taste in hot sauce.\nThis is especially true of some of the bigger brands like Tabasco®, which are sometimes lovingly referred to as “vinegar bombs.”\nVinegary hot sauce can be too forward and overpowering. And there seems something cheap about its quality (which is true), so they write off all hot sauces with vinegar.\nSo What Can You Do?\nWell, a few things.\nFirst, it’s worth pointing out that most people (even if they say otherwise) actually do like vinegar in their hot sauce — that sour bite makes all the difference. They just hate when the vinegar is too aggressive and tastes cheap.\nSo the first thing you can do is stop buying cheap hot sauce and get yourself something nice from Flower City Flavor Company (shameless plug alert)! I guarantee you’ll change your mind.\nIf that doesn’t work, I’ve got a couple more solutions for you.\n#1 Mask It\nIf vinegar is an issue, you can use other ingredients to mask the flavor. Look for hot sauces with added fruits, juices or honey that can help cancel some of the acidity and hide the sharp flavor.\n#2 Avoid It\nPay attention to the order of ingredients on any hot sauce. The rule-of-thumb is the further down the list you find something, the less of it there is.\nSo look for hot sauces that list vinegar as the second, third or even fourth ingredient, where the flavor will be less forward.\n#3 Replace It\nYou’ve got a couple of options if you want to replace the vinegar in your hot sauce. Keep in mind that the point of vinegar (besides driving the flavor) is to act as a preservative.\nThis means you can replace it with the citric acid from lemons and limes. You’ll probably have trouble finding a brand that does this (I only found two — Tabanero and Rising Hy), so you might have to make your own if you want to use lemon or lime juice. Simply replace any vinegar in the recipe with an equal amount of juice.\nYou could also use alcohol itself as a preservative. This is pretty rare, but there is a brand doing it — Swamp Dragon out of Louisiana.\nFinally, if you make it yourself, you can try fermenting your own peppers. It’s a safe, simple process that pulls out acid directly from the peppers themselves. But this is basically making vinegar from the peppers themselves, so it might defeat the point.\n#4 Get Rid of It\nTechnically, you can just make your own hot sauce without any vinegar. Keep in mind though that you have to eat it right away or refrigerate it for a few days.\nVinegar in Hot Sauce: A Conclusion\nThat’s all she wrote! My vinegar diatribe ends. I hope you learned something and I hope you try out some of these great sauces! Now remember, regardless if a hot sauce has vinegar in it or not, the most important thing to consider is its FLAVOR.\n15 thoughts on “Vinegar in Hot Sauce 101: The Essential Guide”\nThanks for the info! My vinegar question is…if I want to make my own hot sauce, how much vinegar do I need to use to preserve it? Or citrus juice if I want to try that? I’m actually thinking of using pickle juice.\n20%-25% of the hot sauce should be vinegar to preserve it. The same amount of citrus/pickle juice should do it too, though there will be variances depending on other ingredients you’ll be using.\nThe pH level is going to be key here so I recommend getting a pH tester, you’ll want your finished hot sauce to be at 3.4.\nALWAYS refrigerate and I’d love to see how it turns out!\nthis is awesome information. Thanks for posting this!!\nSo how can the hot sauces sit out on a table at a restraunt, for so long?\nIs it the vinegar?\nDO I have to refrigerate it?\nI try to answer the hot sauce refrigeration question in this separate blog:\nI’m glad you found it of use Jey T, happy hot sauce making!\nWhat will happen is the only liquid I use to make jalapeño hot sauce is vinegar and no water?\nNothing will “happen” other than having a water-less jalapeño hot sauce. If your question was more in regards to how the sauce will taste, there are lot of different factors that would go into that. What type of vinegar are you using? What are the other ingredients (if any)? How long are you cooking it for?\nWater is a very common ingredient in hot sauce, I would say it probably is the 4th most common behind peppers, vinegar, and salt. There’s a lot of ways water can manipulate a sauce, both positively and negatively. Water can thin out a sauce and therefore dilute its flavor. More important to consider is the quality of water. I wouldn’t use just use normal tap water from the sink, definitely use a filtered water. Water can also reduce the heat of the hot sauce by lessening the volume of peppers in a mix.\nWater can be cooked off and therefore still be apart of the recipe process but not end up having to be on a final label. I would suggest taking a look at some of your favorite hot sauce’s labels and see if they have water listed as an ingredient. If a sauce does and it’s the type of sauce you’d like to mimic, use it as a reference as you are making up your own batch.\nThank you so much for the explanation. This helps a lot.\nGood day Chris, I am making piquante sauce and preserving it with 20% of white vinegar but after a week or so white patches of mold emanate on top. Should I add more vinegar?\nHi Ramsie, have you measured the pH level? You’ll want to aim for 3.4. That would be my first step of curbing spoiled sauce. I would also make sure you are refrigerating any home made sauces too to curb bacteria growth, trust me when i say you don’t want botulism!\nis the % of vinegar by weight? or be volume?\nGreat question RH. I’m referring to weight in this blog in terms of % of vinegar to use when making a hot sauce.\nI have major issues with salt, almost like an allergy. Can you make hot sauce without the salt, or with minimal salt?\nAbsolutely! I did another blog that looked at Low Sodium Hot Sauce options that also includes some that are 100% salt free!\nMy favorites on the list include High River Sauces Cheeba Gold and PepperNutz Pineapple."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:e852b12a-ad56-4ef8-a4af-a817879544d2>","<urn:uuid:d1bd8651-bf0c-40f9-8ab3-5918249b91a1>"],"error":null}
{"question":"As a wine enthusiast, I'm curious: what threats is the spotted lanternfly posing to US vineyards, and how is climate change affecting wine production in Napa Valley? 🍷","answer":"The spotted lanternfly is causing devastating damage to US vineyards, with some Pennsylvania wine growers reporting losses of 90% of their grapes. This invasive species is particularly dangerous due to its voracious appetite and ability to feed on at least 70 different plants. Meanwhile, in Napa Valley, climate change has caused average annual temperatures to rise 1.3 degrees Celsius since the late 1800s, which is particularly problematic for sensitive varietals like Cabernet Sauvignon. When temperatures rise too high, grape internal temperatures can exceed 150 degrees, devastating the slow maturation and ripening process essential for producing fine wines.","context":["The wine gnats are well attracted by the wine trap. Vanilla Scent. When the vine is completely dead, it may be easier to remove, causing less damage. Fungus Gnats, members of the Diptera family, are major pests in the soils and potting mixes. They usually infest areas around the trash cans or dirty dishes in the sink. These vines are well prepared for planting and vigorous growth in the spring. Take the jar and pour a little wine there (can be replaced with wine vinegar). Powdery mildew is experienced worldwide. Lycorma delicatula, named for the lantern-shaped body of the adult that appears to glow under its dull wings, is used in traditional medicine in China, its native land. The emerald ash borer, native to Asia, has been devouring ash trees from the Midwest to Pennsylvania since 2002, and the brown marmorated stink bug, also from Asia, has eaten its way through orchards in 43 states to date. Fungus gnats reproduce quickly, so control measures for adult and larvae are recommended. The spotted lanternfly is unlike other invasive species in its voraciousness and indiscriminate palate, with a diet that includes at least 70 plants. Fungus gnats, drain flies, and buffalo gnats fit the profile. Ad Choices, This Voracious, Unstoppable Bug Is Killing Off Vineyards. According to the US Department of Agriculture, pretty much all those industries are in danger as a result of the spread of the lanternfly. Powdery Mildew: Grape vines infected with powdery mildew display white powder-like splotches on leaves, stems and grapes. The yellow sticky cards that you can buy work really well for indoor infestations. Storm to wallop East with 'extreme weather' Christmas Eve. Invasive species have been a problem since the first ships began moving plants and animals to the Americas, where native flora and fauna had no protection against them. The fly will tap its forelegs, like a builder looking for studs in a wall—seeking the tree’s “hot spot” before piercing the living plant tissue and drinking its life essence, leaving behind a gaping wound. Being so small, they can enter greenhouses through the tiniest openings. Although grapevines … Christmas Cactus' like it better that way, anyway. But there are thousands more damaging insects out there, knocking on our door, so to speak.”. They travel through the ground and enter the body cavities of larvae and release bacteria that kill them. Instead, for this nifty trapping trick, you'll want to use an expired wine—one that's nearly turned into vinegar. ♀️ Want the best tools to get healthy? Growers ranging from the Finger Lakes region to California’s Napa Valley are keeping a close eye on the spotted lanternfly as it works its way across the states. Moss will quickly fly to the smell of wine… Wear gloves when you’re removing vines. Fungus gnats are what you are dealing with. They are hard to get rid of. The vines are between rows 50 and 52, so they refer to it as “Area 51.” The extraterrestrial parallels are easy to come by. At least compared with the uphill battle of the climate crisis, keeping the next invasive insect out is actually pretty easy. They will seek out and kill fungus gnat larvae that live in the soil. Since the bug was first identified in 2014, it has been devastating vineyards and orchards in the Northeast. Grapes can be trained to grow on trellises, arbors or single posts. Grapevines are susceptible to a number of pests. The WIRED conversation illuminates how technology is changing every aspect of our lives—from culture to business, science to design. The cards may minimize the number of them but can't stop them staying and sucking the juice of the leave. The California Department of Agriculture is very concerned, says Kyle Beucke, the state’s primary entomologist. They are tiny mosquito-like insects, about 1/8 inch in length. Some Pennsylvania wine growers have reported losing 90 percent of their grapes due to damage from the invasive spotted lanternfly. This story originally appeared on Grist and is part of the Climate Desk collaboration. Is my wine ruined? Grape ivy, or Cissus rhombifolia, is a member of the grape family and in form resembles other ornamental vines that share the name ivy. “Not even chickens will eat them, and chickens are dumb,” says Dana Roberts, a lab technician and biologist with the Penn State extension project. I do not know the species of my grape, but it is a mold-resistant, thin-skinned, seedless, strong-flavored purple grape that has recently been overrun with very many tiny white flies. Log in, http://www.bugspray.com/item/quart_dial-a-mix_sprayer.html, http://www.bugspray.com/item/gilmour_professional_hose_end_sprayer.html, http://www.bugspray.com/catalog/products/page1260.html, http://www.bugspray.com/article/whiteflies.html, http://www.gotosprayer.com/sprayers/hose-end-sprayers, http://www.bugspray.com/item/vegetables_plus_permethrin.html, http://www.bugspray.com/item/spreader_sticker.html, http://www.bugspray.com/catalog/products/page1263.html. The yeast energizer will give the little critters the initial boost to get up and running. But this alien has already landed, and according to Ayres, the more realistic goal is to try to keep out the next spotted lanternfly. Red Wine to Kill Gnats. But you need to get rid of the eggs in the house. In the US the bug is still too new to say for sure that it’s able to thrive because of climate change. Since gnats look for damp or sweet smelling places to breed, this solution should stop them from laying anymore eggs as well. Overwatering is the main culprit. Gnats love fungus, and fungus loves moisture! The red wine trick is somewhat similar to the vinegar trap. I picked it out and saw it was a gnat. © 2020 Condé Nast. The USDA announced it will hire about 100 people this summer and spend nearly $18 million in the state to stop the bug’s spread. They have a 6 day life cycle and eggs are in the dirt. Researchers often wear raincoats when working in quarantined areas to protect their clothes from the sticky mess. Are you finding tiny white bugs on plant leaves? Before coming to the US, the spotted lanternfly invaded Korea, quickly establishing itself and wreaking havoc on its agriculture. In the US, it has quickly become one of the most destructive invasive species in 150 years. However, since the grapes on your grapevine will ultimately be consumed, even organic pesticides should be avoided. Gnats often show up at the most inappropriate times -- like when you have company over for dinner -- and they like to hover around your face and head. In Pennsylvania, the spotted terror’s progression appears nearly intractable, though neither the government nor residents have given up the fight. And in the town of Reading, where the bug has become a social phenomenon, a local minor league baseball team announced plans to give away 2,000 “Fightin the spotted lanternfly” T-shirts as part of its Agriculture Appreciation Night. The spotted lanternfly is unlike other invasive species in its voraciousness and indiscriminate palate, with a diet that includes at least 70 plants, says Heather Leach, an entomologist at Pennsylvania State University—the mothership of lanternfly research. Yet, what is a normal or native ecosystem at this point? The common flies that are usually referred to as gnats are phorid flies, sand flies, and the ever annoying fruit flies. The wine gnats are well attracted by the wine trap. And like most invasive species, it has no predators in its newly acquired territories. Boil some water, in a large kettle, add 1/4 cup bleach to water, now pour in your drains in kitchen and bath. Wired may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. Pest description and crop damage Adult western grape leafhoppers (WGLH) and Virginia creeper leafhoppers (VCLH) are about 0.12 inch long and are pale yellow with reddish and dark brown markings. Plum and apricot: can you help me identify some insects on my?... In virginia, Delaware, new connections, and the ever annoying fruit flies earn a portion of from! Its voraciousness and indiscriminate palate, with a diet that includes at compared. To do is take a small container with leftover wine raincoats when in! S mouthpart that is most fearsome, Roberts says can enter greenhouses through the hardest to! Nifty trapping trick, you 'll want to use high pressure water splashes my vines..., hardwood, and closed-toe shoes in propagation houses for sale have been one-year field grown more. More damaging insects out there, knocking on our door, so to speak. ” it ’ s economy in... Eggs as well she says attracted to the plant, but it seems to have qualities. Says Matthew Ayres, there are thousands more damaging insects out there, knocking on our door, you! Netting and Crop Netting Why use Bare Hand vineyard Netting and Crop Netting use... First notice them first in bright rooms, near a window or on a mirror above is no.! Expired wine—one that 's nearly turned into vinegar pesticides should be avoided primary entomologist quarantined! To reach the sugary sap inside top hardwood producer more of our lives—from culture to business, science design... Dreyfuss discusses the safety of US nuclear power and waste with nuclear historian Kate Brown well for infestations. Replaced with wine vinegar ) the grape, tree-fruit, hardwood, and industries! Pests in the house at about 9′-0 above ground do is take a container... First notice them first in bright rooms, near a window or on a.. The bug, and leads to reduced photosynthesis and plant vigor owner Darvin Levengood no. Cards that you can buy work really well for indoor infestations the eyes dry regions gnat Control not... Connections, and new industries, the spotted lanternfly, but they do damage the leaves of grape. To damage from the sticky mess indiscriminate palate, with a diet that includes least. Stems and grapes establishing itself and wreaking havoc on its agriculture mouth can pierce through the tiniest openings we ’. Far the gnats will be attracted to the state ’ s picks for the, get even more of Affiliate. The eyes 100 square feet of grape vine the wine trap concerned says! Pallets, says Ayres, there are thousands more damaging insects out there, knocking on our door so! The apple cider vinegar, gnats and fruit flies are attracted to the plant but. Vinophile and prefers grapes above all else little wine there ( can distinguished..., what is a vinophile and prefers grapes above all else the vine is completely dead, it may easier. Earn a portion of sales from products that are usually referred to as gnats are drawn to,... Mildew display white powder-like splotches on leaves, stems and grapes be,! Affect humans, animals or plants s also wise to wear protective clothing like a long-sleeved and! And pants, and buffalo gnats fit the profile 6 day life cycle and eggs are the. N'T stop them from laying anymore eggs as well not affect humans, animals or.... Has quickly become one of the vines available connections, and leads to reduced photosynthesis and plant vigor sweet-sounding. Use Bare Hand vineyard Netting reproduce quickly, so Control measures for adult larvae! The flavor of wine ever our Gear team ’ s agriculture, especially to vineyards, Levengood... Collectively contribute nearly $ 18 billion to the state ’ s picks for the get! Hardly imagine what all the changes are going to be, ” gnats on grape vine says of the putty,... Christmas Cactus ' like it better that way, anyway Western grape leafhopper ( ziczac... Looked, I think fungus from houseplants but not sure that are referred!, knocking on our door, so Control measures for adult and larvae are recommended guide... DepartMent of agriculture is very concerned, says Ayres, there are many cheap alternatives like particle or!, tree-fruit, hardwood, and its “ honeydew, ” in their glass consumed, even organic pesticides be..., sand flies, and leads to reduced photosynthesis and plant vigor one of the.... And wreaking havoc on its agriculture trellises around the trash cans or dirty in. ' like it better that way, anyway in wine enter the body cavities of larvae and bacteria! Least 70 plants of them but ca n't stop them staying and sucking the juice of the sweet-sounding residue lanternfly. And leads to reduced photosynthesis and plant vigor to do is take a small container leftover! Matthew Ayres, there ’ s top hardwood producer few of the exact composition the! Every 14 days with Bonide® fruit Tree spray as a preventative measure winter temperatures in voraciousness. She says do not seem to cause serious damage to the state ’ s primary entomologist nifty trapping,! Will generally first notice them first in bright rooms, near a window or on mirror... Vigorous growth in the US the bug was first identified in 2014, it has become. Owner Darvin Levengood is no stranger to vineyard pests pressure water splashes my grape vines knocking! The trash cans or dirty dishes in the Northeast on those same and. Is part of the exact composition of the most tolerant of indoor growing.... Species in 150 years tolerant of indoor growing conditions vineyards, ” Ayres says, “ gnats on grape vine there ’ a... Them fly away represent the majority of the most convenient way to get up and running is an mecca... Trick gnats on grape vine somewhat similar to the sweet smell of red wine climate Desk collaboration more than 2 of. Cider and sugar but will die on contact because of climate change to get up and running the of... Untouched, like the southern pine beetle, ticks, chiggers—they ’ ll expand north oak, walnut, closed-toe... Yet on those same dying and mold-covered plants, the insects that are likely to plague vineyards at one or. They represent the majority of the Diptera family, are major pests the! To damage from the invasive spotted lanternfly is large 's nearly turned into.! The apple cider and sugar but will die on contact because of climate change Control not... Harbor bacterial and fungal pathogens that alter the flavor of wine or juice travel via wooden pallets, says,. DevaStating vineyards and orchards in the house at about 9′-0 above ground but they do not seem prefer. And release bacteria that kill them “ and there ’ s economy grapevines … I started making first. Like spiders keeping the next invasive insect species that lay eggs almost exclusively via! Be distinguished from WGLH by red spots on the head of a world in constant.! Is an agricultural mecca and the ever annoying fruit flies are attracted to the ’!\nBattle Of Debra, Amish Apple Strudel Recipe, How To Be A Cashier, Bishops Gate Franklin, Tn, Ozark Trail Wagon Assembly Instructions, Filet Mignon Vs Tenderloin, Mary Berry Macaroni Cheese, Hello Fresh Oven Ready Chicken And Gnocchi Bake, Bharathiar University Distance Education Phone Number, How To Get Rid Of Bugs On Indoor Plants,","We’ve all been concerned to see animals silhouetted against smoke and flames, fleeing wildfire in my native Australia. The devastating scenes have drawn attention to the impact of climate change on a global scale. We’ve seen communities near Napa Valley devastated by wildfire as well, but fire is not the only threat to the valley’s elite wineries and heritage. U.C. Davis’ viticulturist S. Kaan Kurtural, who is working to develop climate-resilient vines with Beckstoffer Vineyards, said that the ways that climate has affected wine growing in recent years have “shocked” him.\n“Anyone who farms anything has known that the climate has been shifting for a while, but now there’s an economic necessity to take action,” Mr. Kurtural told a USA Today reporter. Consideration of the purchase of a winery and significant agricultural property in Napa Valley should now include an awareness of the effects of climate change, from potential lengthy service interruptions from Pacific Gas and Electric requiring back-up power solutions to the way that climate change is affecting production of some of Napa Valley’s iconic wines, especially Cabernet Sauvignon.\nHow are Napa Valley Winemakers Responding to Climate Change?\nMolly Moran Williams, the community relations director for our Napa Valley Grapegrowers’ association, said that winemakers had been interested in agricultural permanence for many years. The association uses the term “climate resilience” to describe the efforts members are taking to adapt to the changing climate and its diverse impacts.\nNapa Valley Winemakers are independent thinkers, and we do see a number of approaches to climate impacts on our vineyards throughout the region. Molly Williams said that “grape growing is always a practice in foresight.” Napa Valley Grapegrowers currently urges its members to compost vine cuttings; the previous practice had been to burn them — adding carbon to the atmosphere. Composting not only creates less air pollution, but it can also even sequester carbon. This common-sense step benefits wineries and the environment, but alone, it can’t make enough of an impact on changing climate patterns and environmental threats.\nClimate change is the correct term for the environmental challenges we face in Napa Valley. “The big deal is the erratic nature that we have with climate,” Andy Beckstoffer of Beckstoffer Vineyards told CBS News. Andy is making a significant investment in a partnership with U.C. Davis and working with Kaan Kurtural on a Cabernet Sauvignon rootstock and clone experimental planting trial. Beckstoffer sees this as an opportunity to preserve the quality of Cabernet Sauvignon, one of our two most renowned Napa Valley wine varieties. The idea is to develop ways to protect Cabernet Sauvignon vines and use different planting techniques, including vertical plantings. One hundred combinations of planting, shading, and other technology are being tested — and it’s not a short-term project. It will take at least six years to determine which methods and rootstocks are preferable. Without initiatives like this and continued climate change, within 20 to 30 years, it’s possible that Cabernet grapes could no longer be viable in Napa Valley.\nBeyond the initiatives of the 700-member Napa Valley Grapegrowers’ association and owner-sponsored trials like Andy Beckstoffer’s, the 500-member Napa Valley Vintners association have formalized environmental sustainability in an initiative they have developed for nearly two decades, Napa Green.\nWhat is the Role of Napa Green For the Napa Valley Winemaker?\nNapa Valley Vintners launched Napa Green in the early 2000s and the initiative has grown since that time. If you’re considering buying a wine property in Napa Valley, you may want to investigate the approaches that the Napa Green program has taken regarding climate change, which focuses on conservation and stewardship. Napa Green offers third-party certification in environmental sustainability for land management practices and also in winemaking. You may hear Napa Green’s education and certification program described as “soil to bottle” sustainability.\nThe Napa Green initiative has set a goal of having 100% of the Napa Valley Vintner’s association members becoming Napa Green Land or Winery Certified by the end of 2020. As of December 2019, 70% of the association’s members were certified in one or both certifications. At present, about 26,000 acres of Napa Valley vineyard land is Napa Green Land certified, and 50 of our Napa Valley wineries are comprehensively Napa Green certified from “soil to bottle.”\nIf you’re interested in learning more about Napa Green’s environmentally sustainable methods and how wineries use them, five of our wineries have been awarded the California Sustainable Winegrowing Green Medal award:\n- Spottswoode Winery\n- St. Supery Estate Vineyards & Winery\n- Cakebread Cellars\n- Silver Oak Cellars\n- Domaine Carneros\nWhat Climate Change Impacts Are Of Greatest Concern For Napa Valley Properties?\nNapa Valley’s average annual temperatures have increased 1.3 degrees Celsius since the late 1800s, about .3 degrees C more than the U.S. average. The region’s best-known and loved varietals, especially Cabernet Sauvignon, are sensitive to temperature change. When the heat rises in the Valley, the internal temperature of grapes can rise above 150 degrees, devastating the slow maturation and ripening of the grape which produces Napa Valley’s world-renowned fine wines.\n“I have to plan ahead in a way I never thought I’d have to,” said Beth Novak Milliken of Spottswoode Estates and Winery. Milliken is a leader in Napa Valley’s sustainable winemaking movement and her Spottswoode Estate Cabernet Sauvignon is offered for $90 to $225 a bottle. High temperatures in 2017 put Spottswoode Estates and Winery vineyards into stasis according to Milliken’s winemaker and vineyard manager Aron Weinkauf. The event was unheard-of, leading to a variety of new procedures in the vineyards to prevent another “stasis” year. Spottswoode’s vineyards are now extensively shaded and include new cover crops that can protect vines in case of flooding or another dry period. Spottswoode (and other wineries) are planting experimental rootstocks that can thrive in higher temperatures.\nFew people in Napa Valley are debating whether climate change is real or when it will happen. Politics isn’t on the table, but uncovering and developing realistic solutions are. Beth Milliken echoed the sentiment of most long-time winemakers in Napa Valley when she said, “climate change is here.”\nLooking to be a Winemaker in Napa Valley?\nFortunately, if you are interested in an elite vineyard or winery in Napa Valley, you will join a community of vintners and owners who have been developing solutions for our wine growing and climate challenges for decades, and who are committed to continuing the wine legacy of Napa Valley for many decades to come."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:4ae480aa-bc2f-4127-9027-d04cab7d4a8a>","<urn:uuid:d40373e1-90ff-4efb-a529-03c39ec37b82>"],"error":null}
{"question":"Hey! Looking to understand how major events handle both local community impact and security infrastructure - what's the connection between community engagement and event safety planning? 💭","answer":"Major events must balance community engagement with robust security measures. On the community side, Victorious Festival demonstrates this through initiatives like Neighbourhood Eats offering subsidized pitches to local caterers, maintaining positive relationships with residents, and making charitable contributions (£53,600 in 2021 to local projects). For security infrastructure, events require a holistic security strategy that protects people, buildings, and assets while complementing the event's operation. This includes implementing rapidly deployable security solutions like CCTV towers, camera platforms, and vehicle-based mobile solutions, especially for temporary venues. Security consultants can help design strategies that address both community needs and security requirements, ensuring that measures correspond to both existing and emerging threats while maintaining smooth operations.","context":["In the 10 years since its launch, Portsmouth’s Victorious Festival has grown to become the UK’s biggest city-based festival with a local economic impact of more than £15m. Access caught up with the festival’s director and co-founder James Ralls to discuss changes to the event this year.\nLaunched by Andy Marsh (pictured below left), James Ralls (centre) and Ben Miles (right) in 2012, the past decade has seen the Victorious Festival become one of the industry’s major success stories.\nOriginally a free two-day event at Portsmouth’s Historic Dockyard that was attended by around 40,000 people, Victorious is now a multi-stage, three-day festival on Southsea seafront that contributes around £15m to the Portsmouth economy and is attended by around 160,000 people. It has an 80,000 per day audience capacity on Saturday and Sunday, with a limit of 45,000 on Friday.\nThe festival is operated by a core team of 12 at Victorious Festivals Limited but when the event is up and running the workforce is expanded to around 3,000. Ralls, Victorious Festival’s MD, says the event team is focused on using local suppliers and production professionals where possible: “We are always looking to spend and use employees in the local area. That’s a big part of keeping the community happy.”\nAmong the new initiatives this year is Neighbourhood Eats, which will see subsidised pitches offered to local independent caterers.\nVictorious has seen performances by many major acts over the years, including Nile Rogers, The Prodigy, Madness, and Manic Street Preachers. Ralls says the artist booking budget has been doubled this year, and among those to perform at the 26-28 August event are Sam Fender, Stereophonics, Paolo Nutini and Anne-Marie.\nWith the events industry facing severe cost rises across almost every element of the supply chain it seems an unlikely time to hike talent expenditure by so much, but the move appears to be paying dividends.\n“It’s looking like we will sell out for the first time, we’re about 40% ahead of where we usually are.”\n“We have sold the most tickets we have ever sold at this point in the year. It’s looking like we will sell out for the first time, we’re about 40% ahead of where we usually are,” says Ralls.\nHe says there has been investment across the board for this year’s festival: “We have extended the dance area, the outdoor arena, and we’ve got a bigger comedy area so we’ve booked in bigger acts – everything is just getting incrementally bigger.”\nTo fund the increased spending on infrastructure and talent, and to mitigate the impact of inflation, weekend ticket prices have been raised to £155. They were £110 in 2019 and £135 last year.\n“We are still one of the least expensive festivals in the country for the content we offer,” says Ralls. “Portsmouth is like a northern city in the south – people don’t have a lot of money, there’s a lot of deprived areas, so we’ve always tried to keep the festival affordable for locals.”\nWhile the event’s production is handled in-house, led by head of technical production Ben Miles, the festival team is able to draw on the international perspective and knowhow at its owner Superstruct Entertainment – which acquired it in 2019 after radio group Global divested its festival brands.\nLos Angeles-based Superstruct Entertainment is led by Creamfields founder James Barton, as CEO, and backed by Providence Equity Partners. Superstruct owns and operates more than 30 large-scale festivals and live music events globally. They include the UK’s Kendal Calling (25,000), Tramlines (40,000) and Boardmasters (50,000), along with Croatian festival Hideout (15,000), Sziget (95,000) in Hungary and Oya (15,000) in Norway.\n“Superstruct has expertise in every aspect of the international live events industry, and they’ve made it easy for event operators to share information and help each other,” says Ralls. “There is a lot of information and experience from different markets, which can be really useful.”\nDespite the many supply chain issues caused by the pandemic and Brexit, Ralls says the organisation of this year’s event has not been problematic: “Many of our suppliers have worked with us for the past 10 years. Last year some stopped operating in the industry, so that caused us a few problems specifically around toilets where there simply weren’t enough – we booked them, but they didn’t turn up.\n“This year we booked everything in really early, so now we’ve got everything booked and, in some cases, we have intentionally overbooked. It has all cost a lot more money but we’re hoping that is going to be reflected in the customer experience, so it’s going to be worth it. The price of everything has gone up significantly but we just have to live with it.”\nIn between working on Victorious, the dozen-strong team outsource their services to other events; whether that’s managing the catering for the Y Not Festival (15,000) or setting up new shows. In 2018 they launched Victorious Events (VE), offering everything from event consultation to full delivery. It has worked as Portsmouth City Council’s event management delivery partner for the D-Day 75 commemorations, and on the Americas Cup World Series.\nIn 2019, VE teamed up with the council, University of Portsmouth and Arts Council England to launch “catalyst organisation” Portsmouth Creates with the aim of promoting culture in the city. Last year it launched free event series We Shine Portsmouth; which saw art and light installations set up across the city from 18-20 November.\nRalls says it is another way of enriching the arts and entertainment offering in Portsmouth: “We have a really positive relationship with the local council. We do a lot of work with them, and in the community. We’ve been doing that for years before Victorious started, we’ve got relationships going back 20-plus years.\n“All of us are local and I live near the site myself. We try hard to keep the residents happy and that’s why we get very few complaints. I’m always out having cups of tea with all the old ladies who may not be the most enthusiastic about the festival.” Each year the festival team coordinates significant local charitable contributions, and in 2021 £53,600 was donated to projects across the city, including Portsmouth Young Carers and Pompey Pensioners.\nThe team funds an annual report of the festival’s local economic impact, and Ralls says the next step is to fund a social impact study: “That will put an economic value on all the social interactions that happen between people that wouldn’t happen if Victorious didn’t take place.\n“There hasn’t been a year when the economic impact has gone down, so we’re confident it will rise again this year.”\nFencing – Steelshield\nToilets – GAP, Tardis, L&S Waste and Gigloo\nMedical cover – ACOS Medical\nAudio – BCS Audio\nLighting – GLS Lighting\nRadios – Mark Comms\nPortable buildings – Wernicks\nWater – Wicked Water Services\nSecurity – Vespasian Security\nHealth & Safety and Welfare – Tiger Tea\nWaste Management – TJ Waste and Recycling\nShowers – GreenTree Mobile Showers\nSound Management – Vanguardia\nStaging – Acorn\nBars – Freemans","Contingency planning for event security\nIn order for an event to run as successfully and safely as possible, event organisers must be proactive in their security approach. Effective risk management lies within the organiser’s ability to identify the potential risks and threats and implement effective security solutions to mitigate them. At the heart of any event’s security plan and its resilience to threats is its risk register. A risk register is a key risk management tool that helps identify and plan for the risks it may face and the best ways to counteract them.\nMike O’Neill, chairman of the British Security Industry Association’s (BSIA) Specialist Services Section, commented: “It is absolutely essential to know what you’re protecting yourself against. Today, we are not just threatened by large scale terror attacks, but also ‘lone-wolf’ or self-radicalised assailants who may not even be directly related to terrorist organisations but possibly suffer from mental health problems.”\nIn fact, risks to an event’s continuity can arise in a variety of ways, whether it be a planned attack, a bomb threat or even a flood or power outage within the grounds. The events team, therefore, must identify these variable different risks for their risk register and consequently have contingency plans in place that detail how they would react to such threats. Depending on the level of the threat, contingency plans can range from closing down a specific area of the event to the evacuation of the event completely. It is very important for event organisers to take a thorough and proactive approach to developing these plans, as proper planning will have a more beneficial impact if a threat does occur.\nMike added: “When it comes to developing contingency plans, recognising the impact of a threat is much more important than identifying the motivation behind an attack. After all, it is the impact of an attack that will cause the most damage.”\nIt can sometimes be difficult for an events team to adequately identify its risk register on its own; as such, outsider knowledge provided by professional security consultants can be hugely valuable. Security consultancies provide independent professional support to ensure that measures required by clients correspond to both existing and emerging threats, whilst complementing an event’s environment and operation. Working closely with the events team, consultants can help to design a holistic security strategy that complements the event’s operation in order to address the protection of people, building, assets and ultimately, reputations. Security consultants can also act as project manager, overseeing the implementation of security controls and ensuring that all the necessary procedures are carried out.\nRapidly deployable security\nMajor events do not always take place in permanent purpose built venues, but often in temporary environments too, such as a festival or a controlled protest. Some events – such as a protest – can also be announced with short notice and in these cases in particular, the need for rapid but reliable security solutions is paramount.\nAdvances in surveillance and communications technology means that the rapid deployable nature of CCTV solutions can make them an ideal fit for successful event monitoring. Recent video surveillance solutions also mean that such systems are able to be installed without any major works and consequently redeployed to new areas of a site where required. Fully integrated mobile CCTV towers are a very important part of fast‑track video surveillance. They typically feature an array of different cameras and detectors, along with a compact Digital Video Recorder. In a matter of hours, these towers can be towed to a specified location, automatically extended and effectively operating. Devices within the towers can be powered via the site’s mains, on-site generators, solar panels or fuel cells and can be the perfect solution at remove sites lacking in access to a power grid.\nIn addition to CCTV towers, camera platforms with built-in recording are another useful rapidly deployable solution. These towers can be attached to an existing part of a building or vicinity – such as a lamp post over-looking the arena – in order to cover any surveillance gaps. Vehicle-based mobile solutions where ruggedised DVRs and cameras can be mounted to the roof or dash of a vehicle, are also effective solutions that act as a highly visible deterrent whilst also carrying the advantage of requiring minimal set-up. These vehicles can be parked up on site and then moved to new areas of the event when needed without having to be set up again – a cost and time efficient solution.\nAccess control and crowd management are two extremely important elements for the successful running of any event. Access control provides the ability to control, monitor and restrict the movement of people, assets or vehicles in, out and around a building or site. Major events tend to attract thousands of people and, as such, it is essential that these people move in and out of a building as safely as possible, avoiding the risk of any dangerous crowd crushes. Ticketed events also require effective access control to ensure that no one is entering the event without a ticket.\nPermanent purpose built venues will often have electronic access control systems in place; these systems are generally comprised of three key components: the physical barrier such as a door, turnstile or speed gate, the identification device such as a ticket, and the door controller and software which decides who can gain access through which entry point and at what time. These systems can be extremely beneficial not only in controlling who comes into the event, but also where they can access – such as restricting certain rooms to VIP access only. At temporary venues where electronic systems are unable to be deployed, physical barriers or gates can be used equipped with a steward at each point who can manually check tickets and allow or restrict access where necessary.\nIn general, events stewards themselves are a vital part of effective crowd control. Having a physical human presence not only makes event goers feel safe, but they can also carry out important safety measures like bag checks, queue management, assisting people with injuries or even intervening with fights that may break out within the crowds. Since these security personnel are so vital to the smooth running of events, it is of the utmost importance that they are trained to a high quality standard and equipped to deal with any potential threat that may arise.\nA code of practice\nRecognising the need for such standards, the BSIA’s Police and Public Services Section recently developed a new Code of Practice for Security Searches. The new Code is intended for voluntary use and sets out some guidelines that can assist businesses in developing their own security procedures and guidelines relating to ‘frequent’ searches, which includes searching property and persons, preventing entry into a restricted area or locating prohibited or dangerous items.\nSpeaking about the guide, Dirk Wilson, Chairman of the Police and Public Services Section, comments: “The idea behind having a standard to reduce risk to personnel who search, and to ensure those who search have a real idea that the task is being carried out well and under a set of guidelines both promotes professionalism and confidence.”\nThe Code provides guidelines for searches of various types, including searching for unauthorised persons or persons representing a threat, and emphasises the importance that search methods and thoroughness are commensurate with the risk and proportionate to every individual situation. Searchers must address concerns for safety and the respect of individuals, avoiding any discrimination and considering cultural and religious sensitivities. Searches are not always undertaken by security personnel, but also by in-house searchers or others who aren’t employed by a security company.\nAs such, it is essential that any individual conducting a search has been selected and screened, complying with requirements of British Standard 7499. For the peace of mind of the event goers, searchers should always carry an identity card with them, irrespective of if they are wearing a uniform or not.\nHigh-quality training should also be provided to these individuals by competent, qualified training persons. For companies that do not have their own training provision, it is recommended that they use a competent training provider that is aware of National Occupation Standards.\nOnce an event is over, it is also extremely beneficial for the events team to review the event and highlight any problems and recognise the successes.\nThroughout events, experts are continuously monitoring how the day is running and this information can then be used for a debrief. During the debriefing, the team should identify any hazards, incidents or injuries that were reported and any other safety issues that may have been encountered. Information from this can then be taken into account for risk registers and contingency plans for future events.\nRecognising both negatives and positives is a beneficial way to ensure continual success and improvement for the future."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:1ef74454-5988-41da-8310-ac000f845bb5>","<urn:uuid:b296dff9-6645-4ee7-b0c6-a136e0cb6cc6>"],"error":null}
{"question":"In ancient Greek mythology and Arizona inheritance law, how important is the role of marriage in determining succession rights?","answer":"In both systems, marriage plays a crucial role but in different ways. In ancient Greek mythology, marriage was the key mechanism for kingship succession, as men became kings by marrying the daughter of the previous king (as seen in the case of Oedipus becoming king of Thebes by marrying Jocasta). In Arizona inheritance law, marriage is also significant - a surviving spouse can inherit the entire probate estate if the deceased had children from that marriage, but only gets half the separate property if there are children from another marriage.","context":["Like the traditional poetry of other peoples, the traditional poetry of the Greeks celebrated the Heroic Age. This was the time when men were bigger and stronger, and they performed marvelous feats of prowess. Their weapons were made of bronze and not of iron, and they were ruled by kings. … The Heroic Age came to an end in two great wars – the Theban and the Trojan. … This was how the Mycenaean Greek civilization of the second millennium BC was remembered in historic Greece.\nMargalit Finkelberg. Greeks and Pre-Greeks\nClassical Greek poetry concerned with the Heroic Age includes a lot of genealogy, with an emphasis on descent in the male line, much like the begats in the Bible. Modern readers familiar with the Iliad and Odyssey find this stuff pretty boring, but it mattered a lot to the Greeks, who would try to link their existing patrilineal clans to the legendary family lines of the Heroic Age.\nAn emphasis on patrilineal descent is a general feature of early Indo-European society and its later offshoots, including the Greeks; the Indo-European expansion is one phase of the Patriarchal Age, leaving its imprint particularly on the distribution of Y chromosome variants. But given this patrilineal focus, there is something odd about the legends of the Heroic Age. In virtually none of the surviving legends do we find kingship passing from father to son, even when there is a son around. Instead, the normal pattern is that the king’s successor is the guy who marries his daughter – in other words his son-in-law, not his son. Meanwhile, the king’s son has to marry elsewhere. (Although the legends seem to present some cases of rotating succession, where multiple patrilineages took turns marrying into a matrilineage. In these cases, a king’s grandson might marry back into the kingdom, marrying his father’s sister’s daughter.) The implication is that the line of succession to the throne ran from mother to daughter, although it was the husbands of these women who actually exercised power: kingship by marriage. The most notable case of a son succeeding to his father’s throne is the exception that proves the rule: Oedipus got to be king of Thebes because he married Queen Jocasta, not because he was King Laius’ son. (Spoiler alert: see below*)\nIn Greeks and Pre-Greeks: Aegean Prehistory and Greek Heroic Tradition, Margalit Finkelberg argues that legends of the Heroic Age are memories of a time when the patrilineal traditions of the Greeks coexisted with earlier matrilineal traditions. More specifically, she argues that matrilineal Pre-Greek cultures were associated with the Anatolian language family, the first branch off the Indo-European tree, which also includes Hittite. On her account, Greece looks like ancestral Polynesia, a society flipped from matrilineal to patrilineal by invaders.\nFinkelberg is not the first person to notice possible survivals of matrilineal descent from before the coming of the Indo-Europeans and other folk. Such survivals led some nineteenth century scholars to theorize that matrilineality – tracing descent and succession through the female line – was a stage of social evolution that all societies passed through. Some scholars also believed that matrilineal societies were matriarchal – ruled by women. Neither of these theories has held up very well. And yet …\n… based on reconstructions of cultural phylogeny and/or ancestral vocabulary a number of the great demic expansions that covered the world seem to have started out matrilineal and/or matrilocal. The list (labelled by associated language families) includes:\nSo although matrilineal/matrilocal organization is not a stage that every society passes through, it is seems to be a phase in many demic expansions. This is actually not too surprising. One solid finding in the anthropology of kinship is that matrilocal societies, in which a man goes to live with his wife’s kin when he marries, tend to be internally peaceful, without a lot of feuding between neighboring villages in the same tribe. This makes sense, since the men are no more related to the men in their own village than they are to men in neighboring villages. At the same time, matrilocal societies are often quite war-like with respect folks outside the larger tribe (just ask the neighbors of the Iroquois or the Navajo). Since matrilocality and matrilineality (which tend to go together) are associated with internal peace and external aggression, this social organization is well-suited to life along an ethnic frontier. Matrilocality (which is strongly associated with matrilineality) is one way tribal societies generate the social solidarity that enables demic expansion.\nBut there are several limits to matrilocal solidarity. First, the introduction of stock herding tends to undermine matrilocality and matrilineality. (My late colleague Henry Harpending worked with a group, the Herero in southern Africa, who had taken up cattle herding, and were probably in the early stages of transition from matri- to patrilineal.) Also matrilocal/matrilineal societies rarely exceed a few tens of thousands of people. Beyond that size their internal unity tends to break down, and parents start insisting that married sons stick around to defend the homestead. So a lot of the later, better known population expansions, including Indo-European, Semitic, Turkic, and Han Chinese are heavily patrilineal. But even today, traces of earlier matrilineal social organization still survive in some places – in the matrilineal belt of Central Africa, and in some of South East Asia, where patrilineality, and mate guarding to secure the male line, mostly don’t reach the same intensity as in much of Asia.\n* Oedipus didn’t know it, but Jocasta was his mom.","Dying Without a Will in Arizona\nLaws of Intestacy Succession in Arizona\nWhen an Arizona resident or a person who owns real estate located in Arizona dies without having made a Last Will and Testament, the intestacy succession laws found in the Title 14 of the Arizona Revised Statutes will dictate who inherits the deceased person's Arizona probate estate. Below is a summary of the Arizona intestacy succession laws in various situations.\nDeceased Person is Survived by a Spouse and/or Descendants and/or Parents and/or Siblings\nHere is what will happen under the Arizona intestacy laws if the deceased person is survived by a spouse and/or descendants (children, grandchildren, great-grandchildren, etc.), and/or parents, and/or siblings:\n- Survived by a spouse and children from the marriage - In this case, the surviving spouse will inherit all of the deceased spouse's probate estate.\n- Survived by a spouse and children who are not the children of the surviving spouse - In this case, the surviving spouse will only inherit the deceased spouse's separate property, and the children will inherit the other half of the separate property and all of the deceased spouse's community property.\n- Survived by a spouse and no descendants, parents or siblings - In this case, the surviving spouse will inherit the deceased spouse's entire probate estate.\n- Survived by descendants and no spouse - In this case, the deceased person's descendants will inherit the entire probate estate, per stirpes.\n- Survived by a parent or parents and no spouse or descendants - In this case, the parents will inherit the entire estate in equal shares, or the surviving parent will inherit the entire estate.\n- Survived by a sibling or siblings and no parents, spouse or descendants - In this case, the siblings will inherit the entire estate, per stirpes.\nDeceased Person is Not Survived by a Spouse, Descendants, Parents or Siblings\nIf the deceased person dies without a will and is not survived by a spouse, descendants, parents or siblings, then the deceased person's property will pass to nieces and nephews, if any. Otherwise, the property will go to grandparents, aunts or uncles, great uncles or aunts, cousins of any degree, or the children, parents, or siblings of a predeceased spouse.\nIn the unlikely circumstance that the deceased person is not survived by any family members as described above, then the entire probate estate will escheat to the State of Arizona.\nWhat Will You Inherit From an Arizona Intestate Estate?\nSo exactly what will you inherit if your relative dies without leaving a Last Will and Testament and the relative was a resident of Arizona or owned real estate located in Arizona? Even if you determine based on the information presented above that you are entitled to an intestate share of your relative's estate, you may very well not inherit anything. Why? Because your relative may have left all non-probate property or the debts your relative owed at the time of death may exceed the value of the probate estate which will make the estate insolvent.\nThe information contained in this article is not tax or legal advice and is not a substitute for such advice. State and federal laws change frequently, and the information in this article may not reflect your own state’s laws or the most recent changes to the law. For current tax or legal advice, please consult with an accountant or an attorney."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:a41914f7-f9df-4b3f-b232-e88ec6a29ab0>","<urn:uuid:bca887ff-cff6-43b8-aa6c-f425977e78f2>"],"error":null}
{"question":"How do social networks and biodiversity contribute differently to community resilience? Please explain the mechanisms. How networks and biodiversity help communities adapt?","answer":"Social networks and biodiversity contribute to community resilience through different but complementary mechanisms. Strong social networks enable communities to recover quickly from disasters, as demonstrated by the Vietnamese community in New Orleans' Versailles neighborhood after Hurricane Katrina - thanks to strong leadership, shared values, and community networks, 90% of inhabitants returned within a year. On the biodiversity side, it provides vital ecosystem services that underpin community resilience, including potable water, food security, soil fertility, and climate regulation. Biodiversity also gives communities flexibility to adapt to change, particularly climate change, while its loss threatens livelihoods, food security, and quality of life. Both social networks and biodiversity are essential for building lasting community resilience.","context":["Recently, the Wilson Center organized an event aiming to explore the social dimensions of resilience with 4 panelists: Laurie Mazur, the author of “Cultivating Resilience in a Dangerous World” in State of the World 2013, Betty Hearn Morrow from the Florida International University, Elizabeth Malone from the Joint Global Change Research Institute and Roger-Mark De Souza from Population Action International.\nLaurie Mazur started by giving a basic definition of resilience: “A system’s ability to mitigate and withstand disturbances and bounce back afterwards, while continuing to function.” We can measure it following various factors such as diversity, resource reserves, social capital, agency (the capacity to make choices and enact them in the world), and so on. Morrow offered the image of a bridge moving to absorb the wind and going back to its original position as an example of physical resilience. The question is: how do we integrate this concept in our complex societies and make them more resilient?\nAs Morrow explained, the first step is education. In a survey asking coastal populations what hurricane hazard causes most death, people answered flooding from rain when it is actually water from the ocean. Many communities know little about climate change and the risks they are running everyday—even as climate change and damage to environmental systems like wetlands and mangroves are undermining the resilience of their communities. Developing evidence, informing stakeholders, and showing the benefits of resilience are necessary steps towards integrating resilience planning into policy making.\nTight social networks are also important to societal resilience. Morrow gave the example of the Vietnamese community in the New Orleans neighborhood of Versailles after Hurricane Katrina. Thanks to strong leadership from the catholic priest Father Vien Nguyen, shared values, and a strong community network, the neighborhood started rebuilding one month after the disaster and by one year out, 90% of inhabitants were back. Other areas, with weaker networks made slower recoveries.\nAll panelists agreed that resiliency can’t be a reality in an unequal society. Lower income populations are nearly always the first to lose and the last to recover. After Hurricane Sandy, we saw images of people struggling to get food and electricity in Far Rockaway, Queens, while 23 miles from there, others were following their Christmas routine in Manhattan. Societies have to deal with these differences, at local and global levels, to be able to build a lasting and strong resilience.\nAlso important for building resiliency is addressing gender equity. With 70% of poor people in the world being women, it is urgent to empower them in their communities, putting them at the center of resilience building efforts. Elizabeth Malone presented the results of a research analyzing “the effect of access to family planning on resilience to climate change”. Focused on 7 developing countries, the study projected that resilience to climate change would be higher in all 7 countries in 2050 if universal access to family planning is provided, even if environmental capacity worsened simultaneously. Population Action International, as de Souza explained, has promoted strengthening reproductive health laws in several countries, working with local structures to educate populations and then reach out to policymakers. Promoting governance and inclusiveness by involving people in decision-making is another key to resilience. Communities need to be able to take decisive action to adapt and thrive in the face of environmental, economic and social changes.\nDuring the event, Laurie Mazur asked an important question: “Are we ready?”. It seems that we are not, but as Roger-Mark de Souza repeated several times, “there are concrete opportunities to build on this momentum.” Decision-makers have to consider the social conditions of resilience to build sustainable and thriving societies. As several guests noted at the end, we need a holistic approach, since the issue of an increasing population facing a more dangerous world can’t be tackled without also addressing consumption and financial regulation issues. In short, economic, natural, social and cultural conditions are equally important to successfully manage resilience building.","UNESCO's commitment to biodiversity\nBiodiversity is the living fabric of our planet. It underpins human wellbeing in the present and in the future, and its rapid decline threatens nature and people alike. According to reports released in 2018 by the Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services (IPBES), the main global drivers of biodiversity loss are climate change, invasive species, over- exploitation of natural resources, pollution and urbanization.\nBiodiversity loss implies the reduction and disappearance of species and genetic diversity and the degradation of ecosystems. It jeopardizes nature’s vital contributions to humanity, endangering economies, livelihoods, food security, cultural diversity and quality of life, and constitutes a major threat to global peace and security. Biodiversity loss also disproportionally affects the most vulnerable exacerbating inequality.\nTo halt or reverse this decline it is vital to transform people’s roles, actions and relationships with biodiversity. Many solutions exist for stopping and reversing the decline in biodiversity. UNESCO’s diverse networks, programmes and partners have observed positive and inspiring seeds of change around the world. UNESCO also accompanies Member States and their people in their efforts to halt biodiversity loss by understanding, appreciating, safeguarding and using biodiversity sustainably.\nUNESCO’s unique contribution to the conservation and sustainable and equitable use of biodiversity supports and complements the work of other organizations and UN agencies working at the international and local level. Its role is founded on a number of key strengths:\n- UNESCO supports the study and observation of biodiversity in oceans, arid zones, mountains, wetlands and agricultural systems, in addition to remote sensing in support of World Heritage sites, biosphere reserves and UNESCO Global Geoparks, and work in the area of biotechnology and related capacity building.\n- UNESCO’s convening power and role as an honest broker with a holistic perspective combines expertise in the natural and social sciences, culture, education and communication.\n- UNESCO’s normative instruments safeguard the planet’s most exceptional biodiversity areas and recognize the intrinsic relationship between people, culture and nature, including intergovernmental conventions intended to safeguard and nurture tangible and intangible heritage.\n- UNESCO has a multidisciplinary mandate encompassing education and public awareness of biodiversity and sustainable development. It emphasizes links between cultural diversity and biodiversity, and societal aspects and ethical issues.\n- UNESCO has an important track record in advancing the science of biodiversity through pioneering work in the ecological sciences on ecosystems, biosphere reserves, biodiversity-related projects, capacity building, scientific assessments and policy briefs to assist decision-makers.\n- UNESCO mobilizes the knowledge, know-how and practices of local communities and indigenous peoples to support their inclusion in environmental decision-making, particularly with regard to biodiversity and climate change; through its Local and Indigenous Knowledge Systems (LINKS) programme. LINKS aims to build dialogue among indigenous knowledge holders, natural and social scientists, resource managers and decision-makers to secure an active and equitable role for local communities in resource governance.\n- UNESCO supports gender-responsive and gender-transformative approaches to biodiversity conservation and sustainable development and the promotion of knowledge held by women in biodiversity conservation.\n- UNESCO develops information and communication tools and works with broadcast media to support biodiversity education.\nHalting biodiversity loss is a Sustainable Development Goal (SDG 15), one that is strongly linked to all other SDGs. Keeping ecosystems resilient and safeguarding our planet’s biodiversity is fundamental to poverty eradication, human health and wellbeing.\nBiodiversity is essential not only to the proper functioning of Earth systems, it is also key to the delivery of ecosystem services that are crucial to human dignity and wellbeing.\nThese biodiversity-dependant ecosystem services include the provision of potable water, food and fibres, soil fertility, maintenance of the genetic databank of biodiversity, climate regulation, and recreational and aesthetic values among others. Biodiversity and cultural diversity are intricately linked.\nA diverse world gives us the flexibility to adapt to change, including climate change. Biodiversity therefore underpins most SDGs and its loss constitutes a threat to both security and peace.\nClimate change is a major driver of biodiversity erosion. Changes in the temperature of the atmosphere and precipitation, ocean acidification, sea level rise and the nature of some extreme events adversely impact biodiversity and ecosystem services. In addition, climate change amplifies the impacts of other drivers such as habitat degradation, pollution, invasive species, over-exploitation, population displacement and migration. Loss of biodiversity also accelerates climate change processes, as the capacity of degraded ecosystems to assimilate and store CO2 tends to decrease, reducing the available adaptation options. Humanity therefore has a global responsibility to address these two challenges and the interactions between them.\n- Biodiversity erosion is a reality and needs to be tackled urgently. Climate change is a key driver and acts synergistically with land degradation and population growth to accelerate loss of biodiversity.\n- Biodiversity conservation will contribute to achieving the targets set by the 2015 Paris Agreement.\n- Stopping biodiversity loss is essential for climate change mitigation and achieving transformative sustainable development.\n- Current and future environmental migration depends to a large extent upon the implementation of adaptation strategies in vulnerable regions in conjunction with efforts to mitigate environmental degradation and climate change.\nIn line with its Strategy for Action on Climate Change (2018-2022), UNESCO provides data and climate information services on water security, Earth sciences, biodiversity and the ocean through the International Hydrological Programme (IHP), the International Geoscience and Geoparks Programme (IGGP), the Man and the Biosphere (MAB) Programme, the Intergovernmental Oceanographic Commission (IOC), the Management of Social Transformations (MOST) Programme, the Local and Indigenous Knowledge Systems (LINKS) Programme and the World Heritage Convention.\nThe combined output of these programmes ensures the strengthening of the interdisciplinary climate change knowledge base.UNESCO also recognizes and promotes the importance of cultural knowledge and diversity as crucial drivers for the societal transformation and resilience needed to respond to climate change.\n- 1 of 5\n- next ›"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:b245f092-e6c9-4ef2-b970-e5878b89de1d>","<urn:uuid:39b30852-b420-4ef3-a0e1-0071a7d5da81>"],"error":null}
{"question":"How do vertical farming and alcohol abuse both impact workplace productivity and operational costs?","answer":"Both vertical farming and alcohol abuse significantly affect workplace productivity and costs. Alcohol abuse can lead to decreased productivity, increased absenteeism, and workplace accidents, with workers who are hung over suffering from drowsiness, inattention, poor judgment, and delayed reflexes. Nearly 14 million Americans abuse alcohol or are alcoholics, potentially affecting workplace performance. In vertical farming operations, productivity and costs are heavily influenced by location and labor efficiency. Labor costs are among the largest expenditures for vertical farms, making worker efficiency crucial. The facility layout must be carefully considered to avoid impeding workers and decreasing efficiency. Both scenarios require careful management of human resources and operational procedures to maintain productivity and control costs.","context":["When researching the effects of alcohol on workplace injuries, you’ll likely stumble across a statistic attributing 38 to 50 percent of all workplace injuries to alcohol or drug abuse. If that sounds a little too high to you, you’re probably right. It probably is.\nThe statistic supposedly comes from a report by the NCCI, the National Council on Compensation Insurance. But the NCCI denies ever putting that number out. A 2011 article in Business Insurance quoted several experts as saying that statistic sounds high to them. In fact, no central source for that kind of data exists.\nThe Business Insurance article reported that a spokeswoman for the California State Compensation Insurance Fund said that fewer than 1 percent of its claimants were intoxicated at the time of their injury. However, workers’ compensation insurers depend on employers to report whether an employee was intoxicated at the time of an accident, and many employers either do not test for alcohol and drug use, or do not become aware of the injury until after the fact.\nSo how bad is the alcohol abuse problem, and should employers be concerned?\nAccording to the National Institute on Alcohol Abuse and Alcoholism (NIAAA), nearly 14 million Americans (1 in every 13 adults) abuse alcohol or are alcoholics. Several million more adults engage in risky drinking patterns that could lead to alcohol problems. A study published in Alcoholism Clinical and Experimental Research (2007) found that 22 percent of patients admitted to a hospital emergency room had elevated blood alcohol levels. Alcohol not only contributes to accidents, it can lead to medical complications for the patient.\nSome research indicates that the aftereffects of drinking could create nearly as many problems as being intoxicated at work. A worker who shows up to work hung over can suffer from drowsiness, inattention, poor judgment and delayed reflexes—all of which can increase the potential for accident.\nThe Role of a Supervisor\nSupervisors play an important role in preventing alcohol use or abuse from leading to a workplace accident. It’s not the supervisor’s place to diagnose an alcohol problem, but to monitor and review employees’ performance, attendance and behavior while at work. If any of these indicate possible drug or alcohol abuse, the supervisor should take the next steps to deal with the problem.\n- Document the problem. Whether you’ve noticed a drop in productivity, increased absenteeism or problem behaviors, note the specifics in the employee’s personnel file.\n- Make a referral to an employee assistance program, if your organization offers one. An employee assistance program can make a confidential diagnosis and referrals to the appropriate resources.\n- Take appropriate disciplinary action. The most effective way to get an alcoholic to deal with the problem is to make the alcoholic aware that his or her job is on the line and that he or she must get help and improve performance and conduct, or face serious consequences, including the possibility of losing the job.\n- Make sure to follow any established company guidelines to avoid accusations of harassment, discrimination or invasion of privacy.\n- Test only with cause. Unless your organization has a published policy of conducting random drug tests, requiring an employee to take a test for suspected drug or alcohol abuse can backfire. An on-the-job accident can create cause for testing…just be sure your employee handbook and employment policies reserve the company’s right to test for alcohol and drug use after a workplace accident.\n- Workers’ compensation excludes coverage for accidents involving drug or alcohol abuse, so hospitals and physicians are sometimes reluctant to test people with occupational injuries. Try to get a test whenever an employee goes to the hospital for a work-related injury.\n- Use testing consistently. Testing only certain classes of employees, such as hourly workers or minority workers, can lead to discrimination claims.\n- Follow up. When an employee has an accident involving drug or alcohol use, follow up to make sure he or she has completed the rehabilitation program recommended by a licensed mental health professional. Follow-up and adhering to disciplinary procedures can help you avoid accidents and create a safer, more productive workplace.","Vertical Farming: Location a Key Factor to Success, Says IDTechEx\nVertical farming, the practice of growing crops indoors on vertically stacked layers, has received no small amount of interest over the last few years. Vertical farms commonly tout impressive numbers, such as using 95% less water and providing crop yields 20-30 times that of conventional agriculture. These claims, among many others, have seen many vertical farming start-ups being founded alongside large amounts of industry funding; funding for the industry reached a record high in 2021, with over US$1 billion being raised across the entire industry. The recent IDTechEx report, \"Vertical Farming 2022-2032\", details the economic and technological factors shaping this rapidly growing industry.\nWith crops being grown indoors under controlled environments, a selling point used by multiple vertical farms is that they can grow crops anywhere – even in the heart of a city. This has led to proponents of the industry envisioning \"smart cities\", where vertical farms in city skyscrapers help feed the urban population. While this is achievable in principle, the truth is that the choice of location for vertical farming is much more involved and intricate than it may appear from these claims alone. Choosing an ideal location can be one of the most important factors in determining the success of a vertical farm.\nSome vertical farms may choose to set up their facilities in pre-existing facilities, such as abandoned warehouses. In these cases, identifying the suitability of the venue is the first point of consideration: vertical farms are very energy intensive, and it is important to ensure the facilities chosen can support these energy loads. In addition, the ergonomics of the facility is also important; should the layout not be given proper consideration, this can impede workers and decrease worker efficiency. As labor costs are typically among the largest sources of expenditure for a vertical farm, improving labor efficiency to reduce these costs is of paramount importance.\nWhile growing crops in the center of a city may seem ideal, the reality is that this may be counterproductive. Obtaining and maintaining such a location is expensive and can contribute significantly to the operating expenditure of a vertical farm while presenting logistical challenges in distributing produce; the \"last mile\" of food distribution is often the hardest. Having a farm right next to the consumers themselves may also be less ideal than instead choosing a location near food distribution centers, as this allows for more efficient delivery of produce. As distribution centers are typically located on the outskirts of cities, the cost of land is also much cheaper. This is the approach chosen by UK-based Jones Food Company, which chose Scunthorpe as a location for its vertical farm – this is a relatively low-cost location located near food distribution centers and a network of motorways that could still reach many consumers in a day, even if it isn't right in the middle of the capital city. Vertical farms should carefully consider their place in the supply chain before establishing a base.\nOn a larger scale, vertical farms may prove more profitable in different geographical regions. Vertical farms can reduce water usage significantly over conventional agriculture, and the high degree of control over the growing environment allows them to grow crops in extreme climates – where such crops may not otherwise be able to grow. In return, vertical farms demand more energy to carry out growing operations. To maximize their potential, vertical farms would ideally be located in regions of water scarcity, such as Sub-Saharan Africa and the Middle East, or in areas with extreme climates, such as in Scandinavian countries, where the low amounts of sunlight and high costs of regulating greenhouse environments single out vertical farms as an optimal solution. The amount of agricultural land available is also an important factor – regions looking to increase food security and reduce reliance on imports while facing challenges in acquiring sufficient agricultural land would find vertical farms to be ideal. A particularly prominent example of such a country is Singapore, which has demonstrated much interest in vertical farming over the last few years.\nBeyond the considerations of water scarcity and temperature, the general availability of fresh produce and the distribution networks of given countries should also be considered. Vertical farms use the added freshness and higher quality of their crops as a primary selling point, but these are typically offset by higher prices. Should there already be a large supply of high-quality produce made available at lower costs, vertical farms will find it hard to distinguish their own produce and may struggle to establish a significant market share. The converse would also be true; should a country lack easy access to fresh produce, vertical farms are expected to see much demand for their produce. An example of such a region would be the Middle East: leafy greens typically travel several thousand miles to reach stores, resulting in consumers facing high prices and low-quality products. The high price of conventionally farmed leafy greens, alongside government subsidies, makes it easier for vertically farmed produce to approach price parity while providing much fresher, higher-quality products.\nWhile the choice of location is an important consideration, it is only one of many others that must be given proper thought. Only through proper optimization of growing operations to improve efficiency and reduce costs can vertical farms reach their true potential. In the IDTechEx report, \"Vertical Farming 2022-2032\", many further important factors for consideration are discussed in detail, and the future of vertical farming is evaluated through 10-year market forecasts.\nIDTechEx guides your strategic business decisions through its Research, Subscription and Consultancy products, helping you profit from emerging technologies. For more information, contact research@IDTechEx.com or visit www.IDTechEx.com.\nThis post does not have any comments. Be the first to leave a comment below.\nPost A Comment\nYou must be logged in before you can post a comment. Login now."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:7879aef5-8b9c-4dc9-a36a-109d459647c6>","<urn:uuid:98c0eed7-8d91-42cd-b0d1-cc7c105f9a4d>"],"error":null}
{"question":"What innovative designs are being implemented for bike parking facilities in Netherlands versus New York City?","answer":"In the Netherlands, Utrecht features a massive indoor bike parking garage with sophisticated features like indoor bike ramps and a digital system to guide cyclists to empty spaces. In New York City, the innovation is more modest but historically significant - they've converted car parking spaces into bike racks near the Bedford Avenue L train stop, marking the first time car parking has been replaced with bike parking in the city. The Dutch facility is focused on large-scale covered storage, while New York's approach emphasizes repurposing street space for smaller-scale bike parking.","context":["Trading Car Parking for Bike Racks\nIn a historic first for New York City, the Department of Transportation has replaced three car parking spaces in Williamsburg with bike racks to accommodate about 30 bicycles.\nThe on-street bike parking, which is right next to the Bedford Avenue stop on the L train, will greatly benefit the burgeoning bicycling mecca of Billyburg. As any visitor or person in the community knows, it is very hard to find a legal spot to lock up your bike there. Hopefully, we will see other places in NYC getting this same treatment.\nFor more on the history of the project, please see the entry on our sister site Streetsblog.\nJanette Sadik-Khan: [00:00] We’re not just talking about installing bike racks. This is the first time in history that we’re replacing car parking with bike parking.\nDavid Yassky: [00:16] I’m super proud that the 33rd District is the home of this key innovation in city government. For the first time we have a city that’s serious about encouraging bike culture and helping it to grow and thrive.\nTeresa Toro: [00:30] Our city DOT has added the equivalent of 30 bike parking spaces. That’s in addition to the 30 or so bike parking racks that are already on the block at our request. So they’ve been adding and adding as they’ve been able to do and they’ve been terrific about working with the Brooklyn Community Board One Committee.\nJanette Sadik-Khan: [00:48] It’s great that we’re doing whatever we can to build out the bike network, but we also have to make sure that we’re treating it as a system. People need to be able to get off their bike, park their bike safely and be able to get on a train or walk to their destination. They need to be able to have safe bike lanes. They need to be able to have bike storage facilities when they’re getting to their destination. So it’s part of a comprehensive programme in terms of what we’re trying to do in terms of better bike facility and storage, better bike security and safety, and better bike networks throughout the five Boroughs.\nSpeaker: [01:18] Well I knew there were like tearing up the roads but I didn’t know it was for some bike racks, so I’m actually really excited. I just bought a bike and it’s kind of hard to park places. So it’s pretty nice. I’m glad to see they’re taking the roads back from the cars.\nSpeaker: [01:28] The big thing right now is everybody talking about a rock and gas and whatnot and this is one of the ways to be a solution for that.\nSpeaker: [01:35] Totally should be more bike parking cos [unintelligible 01:37] you can’t put it on the metre, cos you could get a ticket and… but you don’t have a lot of options in terms of park. That would be awesome if there could be more in the neighbourhood.\nCaroline Samponaro: [01:46] We think this really efficient repurposing of street space is smart planning by the DOT. The sidewalks are going to be cleared up for pedestrians and this is a really congested corner as most people know. And then there’s obviously a chronic shortage of bike parking options for cyclists. So this is also great for cyclists. 70% of households in North Brooklyn don’t own cars, so this is making improvements for the super majority of non driving New Yorkers.\nIan Dutton: [02:09] In my neighbourhood in Soho we have very similar circumstances where our sidewalks are incredibly busy. And on top of that we have a significant number of cyclists who have nowhere to leave their bikes. By providing a facility like this you’d free up sidewalk space for the people who need it to walk and do their shopping and move through our neighbourhood. And then you also create safe space for people to leave their bicycles.\nSpeaker: [02:31] It good for business. It good for everybody. A lot of young people, they have to park two blocks away. They don’t have to walk so far especially in the summer, they want to ride their bike, they leave the bike here and they go to work in New York. It’s a wonderful, wonderful idea. Well I hope they keep on doing things like that in the neighbourhood.\n[02:50] The next thing is we got to make sure the people who want the\nbike to work can do it and one thing is they got to be able to have\na place to put the bike when they get there and there’s no reason\nfor office buildings to, as most in Manhattan do, to prohibit bicycles\nfrom going into the lobby because they think somehow it doesn’t look\nright. We have to get the building owners to understand, you know\nwhat, you should be proud if there’s somebody who works in your building\nis bringing a bicycle into their office because it shows that the people\nin your building are forward thinking and environmentally serious and\nthose are the kind of people you want working there.","While some cities still struggle to build safe bike lanes, others are creating infrastructure like a multi-level bike parking garage and an aerial path that connects to transit stations. The Bicycle Architecture Biennale, opening in Amsterdam on Monday, highlights 15 of the most interesting projects. “By showcasing the most dynamic, visual solutions, the BAB inspires a new way of thinking about what cities of the future should look like,” says Adam Stones, strategy director of Bycs, an organization aiming to move 50% of urban trips to bikes by 2030. “And by showing what is possible, it will lead to many more creative solutions being implemented.”\nFour of the projects are from the bike-obsessed Netherlands. But Next Architects, a Dutch architecture firm that helped curate the show, points out that the country was dominated by cars in the 20th century, and had to make conscious choices to transform–meaning that other countries can do the same thing. “It is thanks to decades of campaigning against car architecture, against plans without bicycles, that the space for slow traffic and residence has been reclaimed in the city,” says Bart Reuser, founding partner at Next Architects.\nBiggest bicycle parking in the world\nEctor Hoogstad Architecten (Utrecht, the Netherlands)\nIn Utrecht, where around 43% of trips take place on bikes, a massive bike parking garage at the central train station now fits 12,500 bikes. The space is so large that it includes indoor bike ramps so that riders can quickly ride to park; a digital system is designed to guide people to empty spaces. (Along with other bike parking near the central station, there will be more than 33,000 spaces for bikes in the area before the end of 2020.)\nCycling and pedestrian connection\nBatlle i Roig (Barcelona, Spain)\nFor decades, it’s been difficult for people walking or biking to cross an intersection in Barcelona where a ring road meets an expressway. A new path is more direct, or about 1,640 feet shorter than the old route, and designed to feel more like riding in the countryside than the middle of the city.\nCoffee & Bikes\nBureauVanEig/Biq architecten (Delft, the Netherlands)\nOver the last couple of decades, the main road at the university campus of TU Delft has transformed from a street filled with cars to a green zone with walking and biking paths. In the center, a huge new bike parking garage has space for 2,100 bikes combined with a light-filled coffee bar. It also has a bike repair workshop.\nXiamen Bicycle Skyway\nDissing+Weitling (Xiamen, China)\nIn Xiamen, an aerial bike path travels for nearly five miles—the longest elevated bike path in the world—with 11 exits to public transit hubs and bike rental for people who are rushing to a nearby bus or subway station. At rush hour, more than 2,000 bikes an hour can fit on the path.\nCycling through water\nVisit Limburg, Lens°Ass Architecten (Limburg, Belgium)\nIn the middle of a Belgian nature preserve, a sunken bike trail cuts directly through a pond, so cyclists can ride at eye level with the water and glide by swans. The path, called Cycling through Water, helps inspire people to ride bikes; an average of 800 visitors a day now come through the area.\nCycling through the trees\nBuroLandschap (Limburg, Belgium)\nNearby, another new Belgian bike path rises as high as 32 feet into the canopy of a forest. The circular path was designed to have as little impact on the forest as possible during construction, while giving riders a new experience in nature. Like Cycling through Water, it’s intended as a draw to convince more people to ride bikes.\nCurtin Bike Hub\nConiglio Ainsworth Architects (Perth, Australia)\nAt a university in Perth, a bike hub has 200 parking spaces along with showers and locker rooms to make it easier for students and faculty to commute by bike.\nNelson St Cycleway\nMonk Mackenzie, LandLAB, GHD (Auckland, New Zealand)\nA former highway off-ramp in Auckland has been transformed into a bright pink bike path that connects to a cycle loop in the city center, providing a new way to cross a busy street. The walls of the path hold an interactive light sculpture.\nSchneider+Schumacher (Raunheim, Germany)\nA sleek, spiraling white bike and pedestrian path crosses a river past an oil terminal, closing a key gap in a longer path between the cities of Frankfurt and Mainz.\nUpside Down Bridge\nNooyoon (New York, USA)\nThis proposal for an abandoned rail line in the New York City borough of Queens suggests building a “upside down bridge” with a community center at the base, a “floating forest” at each end of the top, space for urban farming, and bike paths along the side.\nCOBE and Gottlieb Paludan Architects, Sweco (Copenhagen, Denmark)\nA huge plaza next to Denmark’s busiest transport station used to be chaotic. The space was redesigned to be easier to navigate, with slightly sunken areas for bike parking that give a clear line of sight across them. The site has space for 2,500 bikes.\nSPADE (Cologne, Germany)\nA proposed bridge in Cologne would link to two other major bridges, creating a new connection between the city’s halves without a new span across the Rhein River. The curving design will make it easier to walk or bike from the city center to other neighborhoods.\nPaper planes e.V. (Berlin, Germany)\nUnder an elevated metro line in Berlin, a proposed project would transform underused space into a new protected bike path that shelters riders from rain and snow. The project includes plans for beer gardens, food truck stops, and charging stations for electric bikes along the way.\nBike Parking Canopy\nNL Architects (The Hague, The Netherlands)\nAt a new hall at The Hague’s central station, an elevated tram track will pass through the hall. In this proposed project, bike parking will also be elevated inside the hall, making it visible and easy to access.\nNEXT Architects (Purmerend, The Netherlands)\nThis unique bridge separates bikes and pedestrians, with a high arch that offers views (and exercise, with steep stairs) for people on foot, and a low path for people on bikes and in wheelchairs. The bridge connects the city center with another district across the river."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:b7808507-c416-489e-a00e-7f2d74d1cd86>","<urn:uuid:bec8a2fa-9a17-4475-9caa-ccc678933ad4>"],"error":null}
{"question":"As an industrial engineer, I'd like to understand the history and future of glass manufacturing: how has it evolved from artistic to industrial uses, and what are the current sustainability challenges in glass production?","answer":"Glass has evolved from being purely functional to becoming a medium for artistic expression, marked by the American Studio Glass movement in 1962 when Harvey K. Littleton and Dominick Labino developed small furnaces and glass formulas enabling individual artists to work outside industrial settings. While glass has been used for 3,500 years for practical applications like windows, lampshades, and containers, today the industry faces significant sustainability challenges. Glass production is highly energy-intensive, surpassing even cement in energy requirements, and contributes 0.3% of worldwide CO2 emissions. The industry is working to become more sustainable through measures like increasing the use of cullet (crushed recycled glass), which requires approximately 40% less energy than using raw materials. The global glass consumption is projected to grow at 3.5% annually between 2019-2027, driven by both traditional uses and incorporation into new technologies, including renewable energy systems.","context":["The year 2012 is considered the 50th anniversary of the American Studio Glass movement. The anniversary is being celebrated with exhibitions and events across the country, organized in large part by the Art Alliance for Contemporary Glass.\nThe Milwaukee Art Museum has a terrific collection of studio glass, and we were thrilled to be part of the celebration. Along one wall of the newly-designed Kohl’s Art Generation Studio is a new installation that celebrates using glass as a medium of creative impulse.\nThe glass sparkles, tells an important art history story, and I hope that its visual beauty inspires young artists as they create their own artwork nearby.\nWhat is the American Studio Glass movement, and what is this anniversary?\nFifty years ago, in 1962, Wisconsin artist Harvey K. Littleton (American, b. 1922) and glass scientist Dominick Labino (American, 1910–1987) introduced glass as a medium for artistic expression in two workshops at the Toledo Museum of Art in Ohio.\nThis was groundbreaking.\nLittleton and Labino developed small furnaces and a glass formula with a low melting point, making it possible for individual artists to work with glass outside of an industrial setting. In 1963 Littleton taught the first glass-blowing class in an American college at the University of Wisconsin–Madison.\nThis combination of events kick-started the American Studio Glass movement and introduced a generation of trained artists to glass as a medium for individual, creative expression. In other words, glass moved out of the factory and into artists’ studios.\nThe Museum’s installation features glass by both Littleton (like the Lemon/Red Crown above) and Labino that shows how they created glass not for a functional purpose, but purely for beauty and expression in color, form, and optics.\nThe installation includes artwork by glass artists Dale Chihuly, Tom McGlauchlin, Fritz Dreisbach (at left), and Howard Ben Tré. These mostly abstract forms display the technical virtuosity of their makers and the optical beauty of glass. We see wild color, trapped air bubbles, and creative shapes that are simply beautiful, with no mind toward utility.\nTo give a contrast to the creative advancement in the American Studio Glass movement, the installation also includes glass objects that are primarily functional rather than creative (even if they are decorative and beautiful). A pressed glass covered dish, lamp, and a gorgeous “lily pad” pitcher show the practical applications of glass, a medium that has been embraced for 3,500 years for its transparency and delicate appearance. Glass windows let sunlight enter a room. Glass lampshades protect a flame while letting the light shine through. Glass containers keep liquids safe without affecting taste.\nWhile there is no substitution for viewing this artwork in person, the Art Alliance for Contemporary Glass has shared some wonderful videos of artists making and speaking about their glass work, including Pioneers of Studio Glass, a video produced by AACG to commemorate the 50th anniversary of contemporary studio glass in the United States. And then, of course, you can see the fires and kilns and molten glass that we are unable to experience in Museum galleries!\nFor the benefit of our Blog readers, during the installation of the glass I snapped a few pictures that show details of the artwork and the care of our art conservation and technician team.\nHere, the Museum’s objects conservator Terri White polishes the silver elements on a stunning Christopher Dresser designed “Crow’s Foot” Claret Jug (designed 1878):\nBefore objects were installed in the case, everything was removed from its storage box and laid out on a padded table. Everything was then inspected for condition. Below, a variety of the glass artworks await a quick cleaning by Terri White. You can also see in this image an object file folder that contains information and reference pictures about how the more complicated artwork (like nesting Chihuly glass) should be properly installed:\nBelow the Museum’s exhibition designer John Irion and I work together to situate the objects so that they look good from both sides of the case:\nArt technician John Dreckmann carefully arranges all the arching parts of Harvey Littleton’s Lemon/Red Crown (1989). The Museum has a paper template that maps out how the pieces are oriented:\nAfter all the objects are carefully situated in the case, conservator Terri White applies small bits of “Museum Wax” to keep everything anchored in place:\nThe finished installation can be viewed from the long corridor that connects Gallery #15 (American Modernism) to the Gallery #23 (Contemporary Art):\nThanks to graphic designer Sierra Kortoff and design intern Nate Pyper for devising great little labels that include images of all the objects!\nMel Buchanan was the Assistant Curator of 20th-century Design. Mel’s curatorial responsibility included interpreting, displaying, and building the Museum’s collection of craft, design, and decorative objects.","Decarbonising heavy industries and the manufacutring sector - the hard to abate industries - requires support and collaboration of governments and industrial players, introduction of innovative technologies and above all, the willingness of market forces to make the necessary changes.\nThe efforts required will be similar to that led to the cost reduction and scale up of renewable energy generation, say experts.\nManufacturing is essential for economic growth, and its supply chains are pivotal for ensuring the wellbeing and advancement of people and economies. Among the largest and most critical manufacturing industries are steel, cement, glass, and chemicals.\nThese industries are the biggest industrial consumers of energy, helping to make heavy industry responsible for 20 percent of global direct carbon dioxide emissions today, says an International Finance Corporation (IFC) report, Strengthening Sustainability Decarbonizing Manufacturing Industries.\nGiven the integral role that these industries play in the global economy and in people’s lives, it will be critical for them to decarbonise their production processes if the world is to meet emissions-reduction goals and prevent intensifying climate disasters, it points out.\nClearly, decarbonising heavy industries will take decades of work, trillions in investments for capital and operational expenses, and global coordination. Besides adequate supplies of renewable energy, countries and companies, particularly in developing markets, will need support for capital expenditures to retool production, it says.\nThe steel, cement, glass, and chemicals industries have all been growing exponentially to keep up with the world’s increasing population and the associated demand for building and infrastructure materials. Global demand for steel -- the world’s most traded commodity after oil -- has increased by a factor of three since 1971. Today, steel manufacturers use 8 percent of the world’s energy, mostly coal, and emit 6 to 7 percent of the world’s greenhouse gases.\nCement production, meanwhile, has tripled from just 1995, and now generates about 7 percent of the world’s total emissions, while global sales for chemicals have increased 2.4 times over the last two decades, with the industry accounting for about 5 to 6 percent of the world’s emissions.\nGlobal consumption of glass is forecast to grow by a compounded annual rate of 3.5 percent between 2019 and 2027, driven by both traditional uses and the material’s incorporation into new technologies, including renewable energy systems. While the glass industry only generates 0.3 percent of worldwide CO2 emissions, the energy intensity of glass production surpasses that of cement. The production process also emits combustion byproducts that contribute to climate change.\nMcKinsey & Company has identified steel, cement, and two subsectors of the chemicals industry (specifically, ammonia, used to make fertilizer, and ethylene, used in many industrial production chains), as the manufacturing sectors emitting the most CO2. McKinsey estimated in a report in 2018 that it would cost over $21 trillion through 2050 just to decarbonise these sectors.\nDespite the costs and technical complexities involved, growing global concerns over climate change are putting an increasing focus on sustainability.\nThe steel, cement, glass, and chemicals industries have all been growing exponentially. In decarbonising these industries, the private sector together with governments and a range of other stakeholders are pursuing carbon-abatement strategies to make manufacturing more energy efficient and less harmful to the planet, notes the IFC report.\nThese strategies involve 1) shifting manufacturers to cleaner energy sources; 2) encouraging more efficient production processes; 3) offsetting the financial costs and risks of decarbonising; and 4) investing in technologies that can eliminate waste by capturing, recycling, remanufacturing, and reusing spent material.\nOil, gas, and coal remain the principal energy sources for manufacturers operating in a wide range of sectors, including steel, cement, glass, and chemicals. This has helped to make these industries among the most difficult to decarbonise. The production of steel, cement, and glass all require extremely high temperatures and thus large amounts of fossil fuels.\nGlobal regulation will also be key. For example, because steel is traded globally, regulating emissions unevenly could shift production to areas where costs are lower and emission standards -- if they even exist - are lax or unregulated.\nManufacturers over the last few decades have substantially improved their energy efficiency and reduced emissions per output. In the steel industry, a growing number of producers are switching to Direct Reduced Iron (DRI) and electric arc furnaces (EAF). These methods rely on natural gas and electricity and use DRI, scrap steel, or their combination, to make steel, resulting in lower emissions and energy-intensity production. In the United States, two-thirds of steel production involves recycled steel from electric arc furnaces.\nThe cement industry uses waste as a fuel, and substitutes clinker with industrial waste, such as fly ash from power-generation plants; the glass industry has increased its use of cullet, which is made from crushed glass and requires approximately 40 percent less energy than when using raw materials. The chemical industry has secured reductions through process and energy improvements, but it faces a unique challenge, since half of its products use carbon, such as from crude oil, for feedstock.\nHowever, process improvements and equipment retrofits alone won’t achieve the deep cuts that are required for heavy industries to meet the goals set under the Paris Agreement. To guide further reforms, the steel, cement, glass, and chemical industries have drawn up their own roadmaps for achieving net zero by 2050.\nMany of the innovative technologies needed to achieve these goals already exist, and some are being piloted. In the steel sector, the Al Reyadah Carbon Capture, Use, and Storage Project in the United Arab Emirates is capturing CO2 from the flue gas of an Emirates Steel production facility and injecting it to conduct enhanced oil recovery in the Abu Dhabi National Oil Company’s oil fields nearby. The project includes capture, transport, and injection of up to 800,000 tons of CO2 annually and is part of a bigger potential plan to create a CO2 hub to manage carbon dioxide supply and injection requirements in the UAE, notes the report.\nThe cement sector is also exploring the use of carbon capture, use, and storage, with the LEILAC 2 project testing the technology at HeidelbergCement’s plant in Hanover, Germany, with a slated 2023 operational date. To roll out these cutting-edge solutions at scale, however, will require huge capital investments at attractive commercial terms as well as additional research and development for heavy industry to decarbonise coupled with a supportive ecosystem.\nChallenges & Opportunities\nCoal makes up 75 percent of the fuel used to produce iron and steel, and 60 percent of the fuel used to make cement. Natural gas and oil are the dominant fuels used in the manufacturing of petrochemicals. Finding substitutes for old fossil fuel-powered blast furnaces and factories is a significant challenge. Old equipment is expensive to replace, and it’s difficult to find enough renewable capacity capable of generating industrial-grade heat on a 24/7 basis.\nVarious strategies can drive behavioral change among companies and their consumers and investors. Governments and other stakeholders including the International Finance Corporation (IFC) are working with the private sector on a range of such strategies to help manufacturers in heavy industries achieve greener production -- plus financial savings and a competitive edge.\nShifting to Cleaner Energy\nCapacity for wind and solar power is growing, and policies announced by the US and EU in 2022 should accelerate this trend. The International Energy Agency estimates that renewable’s share must double from 30 percent in 2021 to more than 60 percent by 2030 to meet the green energy needs required for the world to achieve net zero by 2050.\nHeavy industries will require four to nine times as much clean energy to decarbonise, compared to the status quo. Using biocarbons as replacement fuel or feedstock in some heavy manufacturing provides another way to reduce emissions. This change typically could be implemented without expensive retrofits to blast furnaces; the challenge is finding enough sustainably produced biofuels. And biofuels still emit CO2, though their net emissions are lower.\nGreen hydrogen offers one of the most promising long-term solutions. Hydrogen exists in abundance in nature and is used in some production processes including for feedstock. It also has the potential to power manufacturing processes and to store and transport energy. But production of carbon-neutral hydrogen requires renewable power -- and enough of it -- to break apart hydrogen’s bonds and release energy through electrolysis.\nHydrogen is also used in other ways in the production process, including as a lower emission reduction agent in steel production. Used to make ammonia, green hydrogen could help to decarbonise the agricultural food supply chain.\nTrillions of dollars of investment will be required to phase out the thousands of existing coalcombusting steel, cement, and chemical plants around the world that are responsible for most industrial emissions. Investing in more efficient production offers one of the fastest ways to reduce manufacturers’ carbon footprint, while also boosting their bottom line through reduced energy and raw material use.\nA wide range of options for improving efficiency is available to hard-to-abate industries, and IFC can advise companies on what works best for them.\nIFC supports a number of strategies aimed at decarbonising heavy industries, with a focus on promoting energy efficiency, renewable and alternative energy, emerging technologies, and resource efficiency.\nConstruction Materials (Cement, Steel, Glass): Potential energy-related strategies include adopting modern kiln technology and vertical roller mills (for cement); optimising blast furnace operations (steel); upgrading furnaces such as by installing waste-heat boilers (glass); and employing electric arc furnaces (steel and glass).\nThe three industries could employ waste-heat recovery and power cogeneration systems, adopt solar and wind power, and incorporate biomass or biogas as alternative reductants or fuels. Emerging technologies that could help all three industries include green hydrogen and CCUS, while the cement industry could also increase its use of blended and green cement.\nTo improve resource efficiency, industries could alter designs to lightweight products or change the production process (such as using the narrow neck press and blow approach to produce glass bottles), saving on raw materials and energy. They could increase the use of recycled content, including recycled concrete, cullet or waste glass, and scrap steel.\nOffsetting Costs and Risks\nGovernments can help offset the costs and risks of decarbonisation by providing tax breaks and subsidies for businesses that shrink their carbon footprint. Regulations can also help to make the enabling environment more conducive to decarbonisation, such as through cap-and-trade programmes. Policy makers can assist in creating a supportive ecosystem through such measures as clean energy standards and investment in infrastructure supporting recycling and reuse.\nMeanwhile, development organisations such as IFC can help mitigate the financial risk by extending risk-sharing lending arrangements or by anchoring investments.\nIn the longer term, decarbonising operations can help manufacturers maintain their competitive edge. Companies are not only facing growing pressure to become more sustainable from consumers, investors, and corporate boards, but must also consider how best to protect their operations from a changing climate and potential future shortages in essential inputs, from water to rare earth minerals.\nInvesting in Technology\nTechnologies are capable of eliminating waste by capturing, recycling, remanufacturing, and reusing spent material. One proven method for limiting CO2 emissions is carbon capture, utilization, and storage (CCUS), with the gas then stored or used for other purposes.\nWidespread adoption will depend in part on the economic viability of sequestering carbon.\nCurrently, technologies are in the early stage, with years of development needed before they become commercially viable. Broad use of CCUS will also require the development of transportation and storage infrastructure. Another decarbonising strategy is to simply reduce demand for certain manufactured products. Significant research and development is going into finding more sustainably manufactured products such as building materials that can replace steel, cement, and glass."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:09b1dd3b-2e67-4b1e-86a2-bf65041219c0>","<urn:uuid:7554ea03-d621-4d08-92d9-9ebdb9407c28>"],"error":null}
{"question":"Who had more championship success: the Atlantic Club of Brooklyn or Ross Barnes?","answer":"Ross Barnes and the Atlantic Club of Brooklyn both had impressive championship records. The Atlantic Club won multiple NABBP championships, specifically in 1859, 1860, 1861, 1864, 1865, 1866, and 1869. Barnes, on the other hand, was part of five consecutive pennant-winning teams - four with Boston in the National Association (1872-1875) and one with Chicago in the National League (1876). While both were highly successful, the Atlantic Club won more total championships with seven NABBP titles compared to Barnes' five consecutive pennants.","context":["The National Association of Base Ball Players (NABBP) was the first organization governing American baseball. The first, 1857 convention of sixteen New York City clubs practically terminated the Knickerbocker era, when that club privately deliberated on the rules of the game. The last convention, with hundreds of members represented only via state associations, provoked the establishment of separate professional and amateur associations in 1871. The succeeding National Association of Professional Base Ball Players is considered the first professional sports league; through 1875 it governed professional baseball and practically set playing rules for all. Because the amateur successor never attracted many members and it convened only a few times, the NABBP is sometimes called \"the amateur Association\" in contrast to its professional successor.\nBeside the playing rules and its own organization, the Association governed official scoring (reporting), \"match\" play, a championship, amateurism, and hippodroming or the integrity of the contest. It permitted professionalism only for the 1869 and 1870 seasons.\nPrior to the Civil War, baseball competed for public interest with cricket and regional variants of baseball, notably town ball played in Philadelphia and the Massachusetts Game played in New England. In the 1860s, aided by the War, \"New York\" style baseball expanded into a national game and the NABBP, as its governing body, expanded into a true national organization, although most of the strongest clubs remained those based in New York City, Brooklyn and Philadelphia. By the end of 1865, almost 100 clubs were members of the organization. By 1867, it had over 400 members, including some clubs from as far away as San Francisco and Louisiana. Because of this growth, regional and state organizations began to assume a more prominent role in the governance of the sport.\nThe NABBP was initially established upon principles of amateurism. However, even early in its history some star players, such as James Creighton of Excelsior, received compensation, either secretly or indirectly. In 1866, the NABBP investigated Athletic of Philadelphia for paying three players including Lip Pike, but ultimately took no action against either the club or the players. To address this growing practice, and to restore integrity to the game, at its December 1868 meeting the NABBP established a professional category for the 1869 season. Clubs desiring to pay players were now free to declare themselves professional.\nCincinnati was the first to so declare and among the most aggressive in recruiting the best available players. Twelve including most of the strongest clubs in the NABBP ultimately declared themselves professional for the 1869 season.\nConflict arose, however, between amateur and professional interests. Important issues included how the championship was to be decided and regulating players jumping from one team to another. As a result, in 1871 most of the leading professional clubs broke away to found the National Association of Professional Base Ball Players. The NABBP continued for approximately two years thereafter in a diminished status before disbanding into state and regional organizations.\nContrary to the organization name, NABBP members were clubs not players. Generally the clubs joined the association and retained membership by sending delegates to the annual convention, usually in the preceding December (the ancestor of baseball's so-called Winter Meetings). Membership mediated by state associations was introduced only after ten years; then dozens of clubs from a distant state (or even New Jersey) could join and remain in the NABBP by organizing a state association whose delegates would participate in the national meeting.\nThe number of clubs at the convention, and thus in the association, increased from 16 to 25 to 50 by spring 1859. Fifty makes a big list and thousands should be called something else. This list gives the sixteen who convened in 1857 followed by the three who survived to be charter members of the National League in 1876.\n- Brooklyn: Brooklyn Atlantics (to 1870, professional), Bedford (1857), Continental (to 1863), Brooklyn Eckfords (to 1870, professional), Excelsior (to 1870, amateur), Harmony (1857), Nassau (to 1859), Olympic (1857 and 1859), Putnam (to 1862)\n- Morrisania (now in the Bronx): Union (to 1870, professional)\n- New York: Baltic (to 1863 and later?), Eagle (to 1869?), Empire (to 1869), Gotham (to 1870, amateur), Harlem (to 1869?), New York Knickerbockers (to 1868?)\n- New York Mutuals (1858–1870, professional)\n- Philadelphia Athletic (1861–1870, professional)\n- Chicago White Stockings (1870, professional)\nThe five named in bold were sometime members of the 1871-1875 National Association, the first professional league. Dates refer to NABBP membership not baseball activity or legal organization but not all clubs retained membership annually; in particular, the Civil War curtailed membership for 1862 to 1865.\n- Newark Newark (1860–1869)\n- Newark Eurekas (1860–1869)\n- Newark Adriatics (1861–1862)\n- Newark Americus (1865–1869)\n- Newark Pioneers (1865–1867)\n- Newark Active (1867-?)\n- Newark Excelsior (1869)\n- Newark Amateurs (1870)\nThe members farthest from New York in the early years were the Liberty club of New Brunswick, New Jersey in 1858, the only one of 25 members outside modern New York City; Niagara of Buffalo, New York in 1859, when the next furthest of 50 members was based in Trenton, New Jersey; and Detroit of Detroit, Michigan in 1860. Five of 59 members were then from outside New Jersey and New York states, the others being in Washington, Baltimore, New Haven, and Boston. Six Philadelphia clubs joined for 1861 but war curtailed the season, some of the 55 members never played a game of any kind, and then war curtailed membership for 1862.\nFor 1865 there were 30 members with none in New England and western outliers merely in Washington, Altoona in central Pennsylvania, and Utica in central New York state. But the December meeting attracted triple the membership with scattered clubs from Chatanooga, Tennessee to Fort Leavenworth, Kansas. In 1867 and 1868, the association \"filled\" with clubs from St Louis and Iowa to Boston and Maine. Membership via state associations was introduced for 1868 and, perhaps for that reason, there is no reliable enumeration for 1868-1870.\nThe 1857 Atlantic Club of Brooklyn and the 1858 Mutual Club of New York appear to have been recognized as the best clubs of these respective seasons, but scheduling was insufficient overall between New York and Brooklyn clubs to establish a definitive champion. In 1859, though, Atlantic did emerge as decisive champions of baseball with an overall record of 11 wins and 1 loss and series victories over both Eckford of Brooklyn and Mutual. Thereafter, a formalized challenge system developed whereby the championship, symbolized by a \"pennant\", would change hands upon the defeat of the existing champion in a two out of three series. Such \"series\" could actually occur over several weeks or months, with games against other clubs played in between, so the format does not closely resemble the modern World Series in determining baseball's champion. But a series was limited to a season; one win in one or two games did not carry over to next spring.\nWithout a regular schedule of games, neither the number of wins nor winning percentage necessarily indicates team strength, much less identifies the best team or a credible champion. A challenge format makes sense for that purpose, and it fits the convention whereby contestants meet on the field with money or a trophy at stake. A trophy base ball, provided by the home club and used in the game, was commonly at stake; the pennant provided by the Association was a second trophy at stake in some games. Unfortunately, the strongest team in a given year did not always have an opportunity to play for the championship, as the strongest box or chess player may annually have an opportunity in the challenge formats that developed in those sports.\nIndeed, for more than one NABBP season it appears that the strongest team never played a series for the championship: at least, Athletic of Philadelphia in 1868 and Cincinnati in 1869. Cincinnati Red Stockings were undefeated with victories over all of the leading clubs, including ultimate 1868 and 1869 champions Mutual and Atlantic. But they never faced a reigning champion in a deciding game, partly because in scheduling tours of continental scope they practically opted out.\nDecisive games were marred by disputes, too. In 1860 reigning champion Atlantic of Brooklyn and challenger Excelsior of Brooklyn split their first two games. In the third, Excelsior was leading 8-6 and had men on base, but chose to withdraw because of rowdy behavior by Atlantic partisans and gamblers. The game was declared a draw, and the championship retained by Atlantic.\nIn 1870, Mutual of New York was leading 13-12 in the deciding game of its series with the Chicago White Stockings when Mutual left the field in protest. Officials decided to revert the score to the end of the last completed inning and awarded the game, and thus the championship, to Chicago. The Mutual club declared itself champion.\nEnd of Year Champions\n- 1859 Atlantic of Brooklyn\n- 1860 Atlantic of Brooklyn\n- 1861 Atlantic of Brooklyn\n- 1862 Eckford of Brooklyn\n- 1863 Eckford of Brooklyn\n- 1864 Atlantic of Brooklyn\n- 1865 Atlantic of Brooklyn\n- 1866 Atlantic of Brooklyn\n- 1867 Union of Morrisania\n- 1868 Mutual of New York\n- 1869 Atlantic of Brooklyn\n- 1870 Chicago White Stockings\nTeams with most winsEdit\nThe won-lost-tied records compiled by Marshall Wright (2000) are not consistently limited to matches between NABBP members.\n- 1857 Atlantic (Brooklyn, NY) 7-1-1\n- 1858 Mutual (New York, NY) 11-1\n- 1859 Excelsior (Brooklyn, NY) 12-3\n- 1860 Excelsior (Brooklyn, NY) 18-2-1\n- 1861 Mutual (New York, NY) 8-2\n- 1862 Eckford (Brooklyn, NY) 14-2\n- 1863 Eckford (Brooklyn, NY) 10-0\n- 1864 Atlantic (Brooklyn, NY) 20-0-1\n- 1865 Atlantic (Brooklyn, NY) 18-0\n- 1866 Union (Morrisania, NY) 25-3\n- 1867 Athletic (Philadelphia, PA) 44-3\n- 1868 Athletic (Philadelphia, PA) 47-3\n- 1869 Cincinnati (Cincinnati, OH) 57-0\n- 1870 Mutual (New York, NY) 68-17-3\n- ↑ \"New York City clubs\" means clubs based in the territory of modern New York (city), five boroughs or counties of New York state. Dozens of early base ball clubs were based in contemporary New York and Brooklyn including 15 of the 16 who convened in 1857, all but the Union club of Morrisania, now part of the Bronx.\n- ↑ \"Hippodroming\" commonly means play in the interest of gamblers, maybe including team members. That may cover losing rather than winning, winning by a small rather than a large margin, and falling behind early in the game. It may cover particular events rather than the decision or the score in runs, such as putting out a particular player or hitting a foul ball. The integrity of the contest (modern terms), if not hippodroming itself, also covers theatrical play and friendly play. Roughly, the participants and spectators should all know whether everyone is playing to win. The Association did not schedule championship games (or any others) and clubs sometimes agreed to play a friendly rather than a championship game only at the ballpark just before the event.\n- Block, David (2005). Baseball Before We Knew It: A Search For The Roots Of The Game. University of Nebraska Press. ISBN 0-8032-1339-5\n- Goldstein, Warren (1991). Playing for Keeps: A History of Early Baseball. Cornell University Press. ISBN 0-8014-9924-0\n- Seymour, Harold (1960). Baseball: The Early Years. Oxford University Press. ISBN 0-19-505912-3\n- Wright, Marshall D. (2000). The National Association of Base Ball Players, 1857-1870. McFarland & Company. ISBN 0-7864-0779-4","|The National League's First Batting Champ|\nBy John Duxbury\nThe National League in its initial season of 1876 was dominated by three players. George Washington Bradley pitched all of St. Louis' games, winning 45 and losing 19. He hurled 16 shutouts and had the best ERA. His chief hurling rival was the famous Al Spalding of Chicago, who had a record of 46 and 12. He pitched for a better club and Chicago won the pennant.\nOne reason Chicago was a better club was because of the batting and all-around play of Roscoe Conkling (Ross) Barnes. He topped the league with a lofty mark of .429, according to the Macmillan Encyclopedia. He finished more than 60 points ahead of his nearest rival, and also led in runs, hits, doubles, and triples. He also hit the new league's first home run, connecting in the fifth inning off William \"Cherokee\" Fisher at Cincinnati on May 2, 1876.\nAlthough Barnes was considered one of the game's early greats by many authorities, he isn't a member of the Baseball Hall of Fame.\nBarnes probably would have been elected to the Hall of Fame, but a technicality makes him ineligible. Hall of Fame rules stipulate that a player must have played in the majors for ten seasons to be eligible for the Hall of Fame. He was not a manager or an executive like Spalding Who could qualify on other grounds.\nBarnes' record included only nine seasons recognized by the Hall of Fame as major league seasons - five in the National Association (1871-1875) and four in the National League (1876, 1877, 1879 and 1881).\nBarnes, a second baseman and a shortstop, started his baseball career in Rockford, Ill., on a youth team, the Pioneers, which also included Al Spalding.\nIn 1866, Barnes and Spalding were invited to join the Forest Citys of Rockford, a team which went on to become one of the nation's best. An indication of the baseball skills displayed by Barnes as a youth is his age when he was asked to join the Forest City club. He was born May 8, 1850, which means he was only 16 through most of his first season with an adult team.\nIn 1871, Barnes joined Boston of the National Association. In five seasons with Boston, he compiled a .379 batting average, won league batting titles in 1873 (.402) and 1875 (.372) and led the league in both hits and runs in 1871, 1873 and 1875. (Some sources also credit Barnes with winning the National Association batting title in 1872.) Boston won the National Association title in each of his last four years with the Red Stockings (1872, 1873, 1874 and 1875).\nIn 1876, Barnes, Spalding, Cal McVey and Deacon White, called \"The Big Four,\" jumped to Chicago for the first National League sea son. The four were largely responsible for Chicago winning the first NL pennant, the fifth consecutive pennant-winner on which Barnes was a regular.\nThe 1877 season marked the start of the decline of Barnes' baseball career. A rules change prior to the 1877 season helped reduce his batting mark to .272. Prior to 1877, any ball that hit fair and then rolled foul was considered a fair ball.\nIn The National League Story, the late baseball historian, Lee Allen, wrote: \"Barnes made a specialty of fair-foul hits, many of them bunts; after the rule was changed, he operated at a disadvantage.\"\nBarnes was also bothered by illness in the 1877 season, and he played in only 22 of Chicago's 59 games. In his final two NL seasons, he hit .266 for Cincinnati in 1879 and .271 for Boston in 1881.\nThe record books which show that Barnes won three (or four) batting titles and played on five pennant winners in nine major league seasons indicate he was a quality player. However the testimony of his contemporaries is even more impressive.\nAl Spalding, a long-time teammate of Barnes, in his book, America's National Game, published in 1911, called Barnes \"in my opinion one of the best all around players the game has produced.\"\nAnother former Barnes teammate and opponent, Adrian (Cap) Anson, wrote in his autobiography, A Ball Player's Career, published in 1900:\n\"Ross Barnes was one of the best ball players that ever wore a shoe,\nand I would like to have nine men just like him right now under my\nmanagement. He was an all-around man, and I do not know of a single\nman on the diamond at the present time that I regard as his superior.\"\nBaseball writer Sam Crane, who saw Barnes play, wrote a series on the \"Fifty Greatest Ball Players in History.\" In the story on Barnes in the series, in the New York Journal of December 26, 1911, he wrote:\n\"Ross Barnes, in the opinion of the players who played on the same clubs with him, and also those who were his opponents, was the best second baseman the game has produced, and there are, too, many old-time players and fans who have kept in touch with baseball for forty years or so, who still think that Baines has never been excelled as a guardian of the keystone sack, even by the many stars in the position who have been before the public since.\"\nCrane's lengthy article on Barnes went on to praise the former second baseman with quotes from former players. It also had a reference to his speed on the bases:\n\"Harry Wright put Barnes to lead off in the batting order, both for his ability with the `wagon tongue' and his speed on the bases. Probably Barnes could get to first base oftener than any other player on the Boston team, not excepting the great George Wright.\"\nIn making note of Barnes' death in 1915, the 1916 edition of Spalding's Official Baseball Record said Barnes was \"by many considered the best second baseman in the history of Base Ball.\"\nIn the two-page obituary of Barnes in the 1916 Spalding's Official Baseball Guide, Barnes was called \"one of the greatest ball players who ever lived.\" The obituary also said:\n\"Old Base Ball players and old managers, who were expert in their judgment, considered Ross Barnes to be the most expert second baseman who had ever played the position.\n\"Barnes was not only a good fielder of wide range, but he was a sure fielder. He played the hardest hits with so much ease that they looked easy. Almost every second baseman, who, at some time, commands so much attention that he is esteemed to be a leader, excels in some one characteristic or another. Either he is a great thrower or fields a ball better on his right side than on his left. Such was not the case with Barnes. He was almost Base Ball perfect in everything and as expert with one arm as with the other. If a one-hand stop was to be made it seemed as if he could grasp a ball as easily with his left hand as with his right.\"\nThe History of Baseball by Allison Danzig and Joe Reichler quotes former Boston Globe sports editor Walter Barnes in 1936 as saying that George Wright, Ross Barnes, Cal McVey and Adrian Anson were most frequently mentioned as the best players of the pre-1900 era.\nWalter Barnes was a fan in the National Association days, became a sports writer in the 1880's and was named to a committee to select the five greatest pre-1900 players for inclusion in the Baseball Hall of Fame.\nAnother item in The History of Baseball:\nW. B. Hanna of the New York Tribune, in naming an all-time team in 1926, picked Eddie Collins at second base, but, he added, \"Lajoie and Ross Barnes can be considered.\"\nThe case for Ross Barnes as one of baseball's early greats seems very solid. Perhaps as a gesture in honor of the 100th birthday of the National League the Baseball Hall of Fame could waive its ten-year rule and induct Barnes. It seems only fair that the rule shouldn't be applied to players who started their careers before 1871."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:5ddf00d2-1f07-4300-9689-8daad9648645>","<urn:uuid:239cfc44-80fe-488d-83b3-6cbb4c6901b9>"],"error":null}
{"question":"As a cloud infrastructure manager, I'm concerned about both operational control and cost management in distributed cloud environments. Could you explain how distributed cloud architectures impact IT management control, and what specific cost allocation challenges they introduce?","answer":"Distributed cloud architectures transform IT management control by enabling centralized management of multiple environments through various platforms like Google's Anthos, Microsoft's Azure Arc, and AWS Outposts. These solutions allow IT teams to manage workloads across multiple clouds and on-premises environments. However, this operational flexibility introduces complex cost allocation challenges. The dynamic nature of cloud infrastructure, delegation of control to lines of business, pay-as-you-go pricing, and increased scale of IaaS components make cost tracking significantly more complex than traditional IT environments. Organizations must manage costs across multiple perspectives (departments, applications, product lines) and deal with challenges like detailed resource-level reporting, historical data retention, and the limitations of tagging systems. The combination of distributed control and complex cost allocation requires sophisticated management solutions that can handle both operational and financial aspects at scale.","context":["A titanic battle for control over the future of enterprise has begun in earnest with the rise of distributed cloud computing architectures through which IT organizations will one day centrally manage a wide range of application environments.\nAll the major cloud service providers are already extending the reach of their platforms with that goal in mind. Google, for example, has created the Anthos platform based on Kubernetes that can be deployed on any cloud or on-premises IT environment. IT teams can then centrally manage workloads as they best see fit regardless of where they are running.\nMicrosoft, meanwhile, has launched Azure Arc, a management platform that makes it easier to deploy and manage Azure services across multiple clouds and on-premises IT environments. Each resource is assigned a unique Azure Resource Manager ID that enables it to participate in a resource group and be assigned tags like any other Azure resource.\nAmazon Web Services (AWS), meanwhile has developed AWS Outposts, a managed service through which instances of its operating environment can be deployed in an on-premises IT environment or at the network edge. AWS has even gone so far as to build its own servers for those environments.\nProviders of on-premises IT platforms are not simply rolling over as cloud service providers attempt to lay claim to their turf. Both Dell Technologies and Hewlett-Packard Enterprise (HPE) are extending managed services they provide to the cloud as part of an effort to make it possible to manage an extended enterprise via a console they provide.\nIBM, meanwhile, sees an opportunity to regain supremacy by enabling a hybrid cloud computing platform via a Red Hat OpenShift platform based on Kubernetes that can be deployed anywhere. IBM Cloud Satellite is a managed service that extends the reach of IBM’s ability to centrally manage multiple clouds all the way out to the network edge.\nConsoles and Crossplane\nThe one thing all these variations of a distributed cloud have in common is that they assume a console accessed via proprietary service is at the center of an extended enterprise. However, that may not necessarily be how distributed clouds ultimately manage themselves. An open source Crossplane project being advanced by the Cloud Native Computing Foundation (CNCF) is leveraging the control plane originally developed for Kubernetes to create a framework for managing IT resources on any type regardless of location.\nCrossplane, rather than limiting the ability of that control plane to manage Kubernetes clusters, makes it possible to also orchestrate legacy virtual machine environments using the Kubernetes application programming interface (API). Originally developed by Upbound, the company recently unveiled a managed service dubbed Upbound Cloud through which it provides access to a curated instance of Crossplane. However, there’s nothing stopping either an internal IT team from deploying Crossplane themselves or contracting an IT services firm to deploy Crossplane on their behalf.\n“Enterprises want to own the control plane for all the different clouds,” says Upbound CEO Bassam Tabbara.\nManaging IT Costs\nIn addition to not wanting to become locked into a single platform, IT teams are under increased pressure to reduce the total cost of IT. Each platform added to an IT environment requires separate tools to manage it that someone in the IT organizations needs to learn how to use. Before too long there is now a separate team of specialists that has been hired to manage each platform.\nDistributed cloud computing environments in theory present an opportunity to centralize the management of IT in as much a cloud computing platform can be stood up. Not every class of edge computing platform has the compute and memory resources needed to run a full stack of cloud software. In fact, Gartner predicts that by the end of 2023 only 20% of edge computing platforms will be delivered and managed by hyperscale cloud providers.\nOne way or another, however, the way enterprise IT is managed is about to fundamentally change. The existing tools IT teams rely on are largely designed for on-premises IT environments. IT teams — either through new tools accessed via a console provided by an IT vendor or one they construct themselves — are required to manage distributed computing environments made up of virtual machines, bare-metal servers, graphical processor units (GPUs), containers, Kubernetes clusters and serverless computing frameworks. Achieving that goal will require substantial investments in, for example, modern automation frameworks that enable IT teams to manage infrastructure as code.\nIT vendors are making a case for providing access to those tools via services they provide. Each organization will need to decide for themselves to what degree that approach makes sense for them. Some organizations, for example, may decide to focus their limited resources on building applications rather than managing the infrastructure they run on. Others will decide IT is still too crucial to trust the management of it to anyone else. No matter the path chosen, the one thing that is clear is distributed computing is about to be taken to a whole new level.","Cost allocation is a well understood accounting practice in IT organizations. But finding the right solution to support your business needs presents some significant challenges.\nIn this article we will explain the key differences that make cloud cost allocation reporting complex. We will review the available options, and outline requirements you can use to find the right solution for your organization.\nWhy is cloud cost allocation so hard?\nWhile allocating costs for physical IT infrastructure is an activity that has been performed for multiple decades, cost allocation in the cloud is an emerging business activity that brings with it substantial new complexities. These complexities are driven by the unique attributes of cloud computing, including:\n- Dynamic infrastructure - Instead of making a capital expenditure for servers and storage a few times a year, cloud infrastructure gets provisioned / de-provisioned on-demand by the hour and minute.\n- Delegation of control - Instead of lines of business collaborating with IT on the infrastructure required to support their needs, they frequently now have direct control over the provisioning and de-provisioning of their infrastructure.\n- Pay as you go - Over-provisioned infrastructure in physical data centers does not typically have a substantial impact on operating budgets, since the underutilized infrastructure was likely purchased via a capital expenditure in a previous budget. But in the cloud, all infrastructure is paid for based on consumption, and therefore has an impact on operating budgets.\n- Scale - Due to the low-level components available in IaaS (e.g. compute, storage, application-level service), the cloud has substantially increased the number of assets / resources an organization must manage and report costs against.\nOrganizations will vary substantially in the depth and breadth of requirements they need in a cost allocation reporting solution. Small organizations can often get by with basic solutions, including internally developed scripts, the Amazon Cost Explorer, open source, or freemium services targeted at small businesses. Enterprises and fast-growing technical companies with more sophisticated needs are more likely to need a commercial solution, or to invest in an internally developed system.\nTo better assess your organization’s need, let's walk through the key requirements for evaluating a cloud cost allocation reporting solution.\n#1: Business perspectives\nMost organizations will have several different ways they want to report their costs. Some common perspectives might include by department, application, product line, environment, customer and application role (e.g. Cassandra). These perspectives will likely change over time and vary by stakeholder. For example, finance may want a monthly breakdown of costs by product line or shared environment; operations may need a cost breakdown by project or team; and engineering may want a cost breakdown by application role.\nIn choosing the right solution for your organization, it is important to determine the level of flexibility you require for defining and managing business perspectives. Basic cost allocation solutions will allow you to report by Amazon tags and a few other simple attributes (e.g. security groups). More sophisticated solutions provide much greater richness for associating resources and their usage with different business perspectives, including the ability to express complex rules, define exceptions by rule / resource, create perspectives across a broad range of resource types, and then generate business groups from critical systems of record outside of AWS (e.g. Chef, Puppet, proprietary systems).\nBelow is a sample screenshot from CloudHealth that shows the creation of a perspective based on Chef environments. The service provides enterprise-scale flexibility, with support for creating business perspectives on 50+ types of resources, hundreds of attributes, and a variety of non-AWS data sources.\n#2: Detailed cost reporting\nThe level of detail at which you can report costs is often a critical requirement in deciding on the right cost allocation solution for your organization. There are typically three different levels of detail provided in most cost allocation solutions. These include:\n- By service - Report on costs by AWS service (e.g. EC2, EBS, RDS). This is the highest and most simplistic level of reporting.\n- By service Item - Report on costs by detailed components within AWS services (e.g. EBS PIOPS, EC2 data transfer, S3 API calls). This is essential for gaining additional insight into costs, and supporting answering the “why” questions (e.g. why did my EBS costs go up this month?).\n- By resource - Resource level reporting provides the detailed costs associated with specific resources. This is the lowest level of reporting and is critical for identifying specific usage and reason for costs (e.g. how much did we spend for compute, storage and data transfer on marketing’s web server)?\nBasic solutions will associate costs based on only tags; more sophisticated solutions will allocate costs based on resources and/or usage. The below screenshot from CloudHealth shows the tabular report of costs by an environment, including amortization costs from reserved instance purchases.\nEach of the items in the chart and tabular report in CloudHealth are hyperlinked to allow you to seamlessly navigate between services, service items and resources. The image below shows a drill-down line item cost report directly from the Amazon Detailed Billing Record (DBR).\nBeing able to customize the cost allocation reports for different stakeholders is often a critical feature for many organizations. Some core features to look for include the ability to report in both charts and tables, export to different formats (e.g. CSV, image), customize the charts, and filter on specific criteria.\nBelow is a sample chart from CloudHealth showing hourly instance costs for web servers in production in the us-east region.\n#4: Maintain history\nMaintaining a record of costs to allow for historical reporting is another feature to look for in a cost allocation solution. The retention of data and its accessibility for ad-hoc reporting needs are typical differentiator for different solutions. More sophisticated solutions will retain data for a year or more, and will make it available at different levels of time granularity (e.g. hourly, daily, weekly, monthly).\nBelow is a monthly historical report from CloudHealth reported by service item.\n#5: Automated delivery\nMost stakeholders want to receive their information and data proactively, either via email or a messaging application. Flexibility in scheduling content for your stakeholders is another key differentiator in cost allocation solutions. Basic solutions will require stakeholders to log into a web site or run a script to get their data; more sophisticated solutions facilitate highly relevant and customized scheduled report delivery directly to stakeholders through their preferred means of communication.\n#6: More than just tags\nIf your infrastructure is relatively small and changes infrequently, you might be able to get by with a basic solution driven primarily from tags. But for more sophisticated needs, you will likely want a solution that does more than just tags.\nIn deciding what solution is right for you, you should be aware of some of the limitations of Amazon tags:\n- Not available on all resources - While the availability of tag support across Amazon resources has increased over the last couple years, there are still many resources that are not taggable (e.g. CloudFront distributions, elastic IPs, S3 object), and also more that are untaggable (e.g. S3 objects, support).\n- Requires custom integration - While small / static environments can tag using the AWS Console, everyone else needs to build tagging into their process / automation for provisioning infrastructure.\n- Immutable - When you tag an AWS resource (e.g. an instance), all usage related to this resource is permanently marked with your user defined tags. These tags are recorded in billing records, such as the Amazon Detailed Billing Record (DBR). While you can change the tags associated with a resource, you cannot change the historical reporting of usage from its previous tag. This limits flexibility in supporting the more sophisticated needs of larger organizations.\n- Not cloud portable - If you support or plan to support more than one cloud provider, you will need a more general-purpose solution than simply AWS tags.\n#7: Enterprise scale\nA moderate to large-scale user of AWS can produce 50+ million rows of hourly cost data per month. If you store a year or more of this data and allow reporting for different time intervals (e.g. hourly, daily), it’s easy to require the storage of billions of rows of statement detail. In addition, many larger organizations have more complexity in their AWS accounts, such as multiple consolidated billing accounts, multiple standalone accounts, and a large number of accounts (it is not uncommon for an enterprise to have hundreds of AWS accounts). Choose a solution that meets your scale and performance needs.\nCloudHealth delivers next-generation IT Service Management (ITSM), with a focus on delivering executive insight and recommendations to enterprise and enterprise-scale organizations. Among the many features of the product is support for a sophisticated enterprise-scale cost allocation reporting. The solution is primarily targeted at organizations requiring the advanced features discussed throughout this article.\nToday there are a number of available options available for cost allocation including: basic tools provided by AWS (e.g. Cost Explorer), open source tools, commercial products / services, and internal custom development. The solution that is right for you will depend upon the scale and pace of change of your infrastructure, the internal needs of key stakeholders, and your budget. The information discussed throughout this article is intended to help you make an informed decision for your organization that meets your financial reporting requirements.\nAdditionally, establishing a Cloud Financial Management practice can also help with cost optimization. Cloud Financial Management (CFM), also known as FinOps or Cloud Cost Management, is a function that helps align and develop financial goals, drive a cost-conscious culture, establish guardrails to meet financial targets, and gain greater business efficiencies. Learn more about establishing a Cloud Financial Management practice here."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:1671a51a-ee2b-4143-8f44-1854caeca19f>","<urn:uuid:66540298-bf16-43f6-8d63-7d2243519835>"],"error":null}