{"question":"What's the main difference between corporate governance principles and design principles when it comes to their applicability and context-specificity?","answer":"Corporate governance principles are unique to each company's situation and circumstances, with no universal definition as they need to be applied to each company's specific context. In contrast, design principles are generic in nature and are not generally placed in context - they only become context-specific when additional context is added, at which point they become design guidelines.","context":["This method is congruent with Fraenkel and Wallen (2001) who note, \"Researchers usually dig into the literature to find out what has already been written about the topic they are interested in investigating. Both the opinions of experts in the field and other research studies are of interest. Such reading is referred to as a review of the literature\" (p. 48). A critical review of the literature can also provide other benefits as well. For example, Wood and Ellis (2003) identified the following as important outcomes of a well conducted literature review: In fact, this was one of the few areas where there was a consensus about the importance of good corporate governance practices. The research also showed that while there is no universal definition of corporate governance, the main thrust of the concept relates to how companies are controlled, with the specific definition being applied to each company's unique situation and circumstances. Finally, the research showed that although the issue of corporate governance has received an increasing amount of attention in recent years, particularly following the corporate scandals as exemplified by Enron et al., there remains a dearth of timely and relevant studies concerning the need for good corporate governance practices in small- to medium-sized enterprises, making this study a valuable contribution to the existing body of knowledge.\n1. It helps describe a topic of interest and refine either research questions or directions in which to look;\n2. It presents a clear description and evaluation of the theories and concepts that have informed research into the topic of interest;\n3. It clarifies the relationship to previous research and highlights where new research may contribute by identifying research possibilities which have been overlooked so far in the literature;\n4. It provides insights into the topic of interest that are both methodological and substantive;\n5. It demonstrates powers of critical analysis by, for instance, exposing taken for granted assumptions underpinning previous research and identifying the possibilities of replacing them with alternative assumptions;\n6. It justifies any new research through a coherent critique of what has gone before and demonstrates why new research is both timely and important.\nThe primary data needed for the proposed study will be collected using an online custom survey instrument to be posted on a premium online survey service such as Zoomerang, SurveyMonkey or SurveyGizmo. The questions for the custom survey instrument will be based on the primary themes that emerge from the review of the relevant literature following the guidance provided by Proctor and Vu (2005). Face validity of the survey instrument will be achieved following the guidance provided by Neuman (2003) for this purpose. The survey instrument will consist of three sections:\n1. Section one will consist of a series of yes/no, fill-in-the-blank and multiple choice questions to develop relevant demographic data and professional experience information.\n2. Section two will consist of a series of five-level Likert-scaled questions ranged \"strongly agree\" to \"strongly disagree,\" with a \"no opinion/not application\" option offered.\n3. Section three will consist of an open-ended comment segment that will encourage respondents to include any additional thoughts, insights, empirical observations and experiences concerning good corporate governance practices in the small- to medium-sized enterprise.\nThe data that results from the secondary and primary research will be analyzed as described below.\nData analysis methods\nThe secondary data will be analyzed by identifying recurring themes, salient points, major issues and other areas of interest and synthesizing these findings with the results of the primary data analysis. The primary data will be analyzed using SPSS Version 11.0 for Windows (Student Version) to develop frequencies, standard deviations and means for each of the custom survey question responses. These results will be presented in tabular and graphic form and summarized and interpreted in a narrative fashion.\nMechanisms to assure the quality of the study\nAll respondents to the online survey will remain anonymous but will still be consented prior to the commencement of the survey administration using the informed consent form shown at Appendix a which is specifically designed for online surveys. Notwithstanding the anonymity of the respondents, all survey data will remain password-protected in the researcher's personal computer, maintained for a period a 10 years and then destroyed. Researcher bias represented a potential limitation, but the use of both secondary and primary data will help to improve the trustworthiness of the research findings and every effort will be made to interpret the findings objectively.\nA tentative timetable for completion of the study proposed herein is shown in Table 1 below.\nTIME (MONTHS) (2011)\nPhotocopy info from non-bibliographic sources\nSubmission of thesis proposal\nFine tune research question and methodology\nWriting up of thesis\nRevision, editing and submission\nAnastas, J.W. (1999). Research design for social work and the human services. New York:\nDennis, C., & Harris, L. (2002). Marketing the e-business. London: Routledge.\nDetomasi, D. (2002). International institutions and the case for corporate governance: Toward a distributive governance framework? Global Governance, 8(4), 421-422.\nFraenkel, J.R. & Wallen, N.E. (2001). Educational research: A guide to the process. Mahwah,\nNJ: Lawrence Erlbaum Associates.\nThe irresistible case for corporate governance. (2005, September). The World Bank. Retrieved http://www.ifc.org/ifcext/corporategovernance.nsf/AttachmentsByTitle/The_\nNeuman, W.L. (2003). Social research methods: Qualitative and quantitative approaches, 5th ed. New York: Allyn & Bacon.\nO'Sullivan, M. (2001). Contests for corporate control: Corporate governance and economic performance in the United States and Germany. Oxford: Oxford University Press.\nProctor, R.W. & Vu, K.P. (2005). Handbook of human factors in Web design. Mahwah, NJ:\nLawrence Erlbaum Associates.\nRamirez, S.A. (2007). The end of corporate governance law: Optimizing regulatory structures for a race to the top. Yale Journal on Regulation, 24(2), 313-314.\nRose, P. (2007). The corporate governance industry. Journal of Corporation Law, 32(4), 887-\nShu-Acquaye, F. (2007). Corporate governance issues: United States and the European Union.\nHouston Journal of International Law, 29(3), 583-584.\nWood, G.D. & Ellis, R.C. (2003). Risk management practices of leading UK cost consultants. Engineering, Construction and Architectural Management, 10(4), 254-62.\nProforma Electronic Informed Consent Form\nYou are invited to take part in a research study of corporate governance in small- to medium-sized enterprises. You were chosen for the study because you satisfied the inclusion criteria of the study (i.e., more than 10 years of executive-level experience and agree to participate) This form is part of a process called \"informed consent\" to allow you to understand this study before deciding whether to take part.\nThis study is being conducted by a researcher named [insert], who is a doctoral/master's student at [insert] University.\nThe purpose of this study is to develop a comprehensive assessment of the importance of corporate governance to the success of a small- to medium-sized enterprise.\nIf you agree to be in this study, you will be asked to complete an online survey in which you will remain completely anonymous.\nVoluntary Nature of the Study:\nYour participation in this study is voluntary. This means that everyone will respect your decision of whether or not you want to be in the study. No one at Insert all relevant institutions or agencies will treat you differently if you decide not to be in the study. If you decide to join the study now, you can still change your mind during the study. If you feel stressed during the study you may stop at any time. You may skip any questions that you feel are too personal.\nRisks and Benefits of Being in the Study:\nThere are no perceived or discernible risks associated with completing the survey instrument, but the results of the study could potentially be enormously valuable for executives of small- to medium-sized enterprises.\nNo monetary compensation is offered for participation in the research project; however, all respondents can obtain a copy of the completed research study by contacting the researcher at email address [insert].\nAny information you provide will be kept Insert either the word confidential or anonymous (note that while anonymity is preferred, it only applies in studies in which no one, not even you as the researcher knows who participated, i.e. A survey with consent implied through completion of that survey). The researcher will not use your information for any purposes outside of this research project. Also, the researcher will not include your name or anything else that could identify you in any reports of…\nIn fact, this was one of the few areas where there was a consensus about the importance of good corporate governance practices. The research also showed that while there is no universal definition of corporate governance, the main thrust of the concept relates to how companies are controlled, with the specific definition being applied to each company's unique situation and circumstances. Finally, the research showed that although the issue of corporate governance has received an increasing amount of attention in recent years, particularly following the corporate scandals as exemplified by Enron et al., there remains a dearth of timely and relevant studies concerning the need for good corporate governance practices in small- to medium-sized enterprises, making this study a valuable contribution to the existing body of knowledge.\nCorporate Governance: A review of Literature What is Corporate Governance? Principles of Corporate Governance Theoretical foundations of corporate governance Agency theory Stewardship theory Stakeholder theory Post-Enron theories Corporate Governance: The changing trends Recent developments on regulatory front and research Corporate Governance: Relationship with market indicators Venture Capital Model: Impact on Corporate Governance Appendix I- Examples of Corporate Governing bodies This paper is a review of pertinent literature on corporate governance. Corporate governance addresses the control issues created due to the separation of ownership\nCorporate Governance Sustainability During the last several years, the issue of corporate governance has been increasingly brought to the forefront. This is because the financial crisis exposed the weaknesses of the current system by: failing to protect the interests of stakeholders. In response to these challenges, various reports have been reexamined. One of the most notable is the King Report of 2002. It identified several different criteria that can be used\nIt should not be treated as a separate exercise undertaken to meet regulatory requirements.\" (ICA, 29) Here is expressed a philosophical impetus that drives the focus of this research, that such compliance which will generally concern matters such as corporate accounting, the practice of internal oversight and the practice of financial transaction must be considered inextricable from other aspects of practical, procedural and legal operation in terms of its\n(Millstein, 2005) Since United States and Australia are countries which are already considered to be globally competitive that has attained its almost perfect status in the world market, developing countries are basically taking into account every step that they make for which they might soon adapt to attain the same position in the global context. Therefore, studying both countries' corporate governance is necessary in order for other developing countries to\nCorporate Governance Two different, yet related corporate governance definitions have been presented in this paper (Mallin, 2006: 3). Sometimes they cause confusions and controversy and ultimately affect the implementation of tightening of governance (Windsor, 2009). The 1992 Cadbury Report, which presented the major proposals for tightening governance, described governance as the system through which firms are managed, regulated and supervised (Cadbury, 1992: 15). The fundamental agency idea emphasizes that corporate governance has\nCorporate Governance of Commonwealth Bank: Australia's Commonwealth bank is a multinational bank with operations across the United States, United Kingdom, Asia, Fiji, and New Zealand. The bank provides various financial services including superannuation, broking services, investment, retail, business and institutional banking, and insurance. The financial institution is currently regarded as the country's second largest organization listed on the Australian Securities Exchange. Together with National Australia Bank, ANZ, and Westpac, Commonwealth bank","For all the #edumooc'ers out there, I apologize that most of the references in this piece are of academic nature, and therefore are not in the public domain. Below are key excerpts from a synthesis paper I wrote about design research. I see now that the methodology that I propose would also easily apply to the development of online learning – in fact, I actually use this methodology somewhat informally as I design and re-design various iterations of one of the online courses that I teach.\nIf you find this useful, or plan to use this methodology, please leave me a comment. Thanks.\nA Design Research Methodology for Online Learning Course Design\nWang and Hannafin define design-base research as “a systematic but flexible methodology aimed to improve educational practices through iterative analysis, design, development, and implementation, based on collaboration among researchers and practitioners in real-world settings, and leading to contextually-sensitive design principles and theories [underline added]” (2005, p. 6).\nDesign principles are \"aims and goals guiding design decisions that occur during the development life cycle\" (Mariage, Vamderdonckt, & Pribeau, 2005, p.689). Design principles are generic and are not generally places in context. When context is added to a design principle, it becomes a design guideline.\nDesign research is pragmatic: it provides a solution to a real-world educational problem (such as teaching terminology) and adds to educational theory in the form of design principles that can be used by educational practitioners (Brown, 1992, p. 143; Collins, 1992, p. 15). Depending on the context in which it is being used, design research may also be known as design studies, design experiments, development/developmental research, formative research, formative evaluation, or engineering research (van den Akker, Gravemeijer, McKenney, & Nieveen, 2006, p. 4). Since design research is intended to both solve a real world problem and to develop re-usable design principles, it is well suited to help develop design theories for mobile learning.\nThere are many approaches to design research – all of which begin with a theory gathering or literature review phase and end with a reflection on both the design solution and the design research process. The middle part of the process – the iterative cycles of analysis, design, development, and implementation – very among the different approaches.\nMost online learning projects involve both instructional designers and software developers; therefore, a design research approach to online learning should take into account the process used by these practitioners. Specifically, an ADDIE-based instructional design approach and an Agile-based software development approach.\nFor online learning (and mobile learning), I recommend a simplified four-phased design research approach that draws on the characteristics of the design research approaches presented in research (Ma and Harmon, 2009;Middleton, Gorard, Taylor, and Bannan-Ritland, 2008; Gravemeijer and Cobb, 2006) with instructional design methodologies and the agile software development method. I call this approach ASER (analyze, strategize, experiment, reflect). As illustrated below, the ASER process has four phases: 1) analyze real-world problem, 2) strategize design experiment, 3) conduct context specific design experiment, and 4) reflect on entire project.\nIn the analyze phase the researcher performs a detailed analysis of a real-world problem. When analyzing the problem, the researcher ensures that scope of the problem is general enough to warrant design research, and that the problem is indeed a design problem. This phase requires crafting a research question.\nThe strategize phase requires the development of strategies to support the design research project. The researcher performs detailed literature reviews and chooses or develops frameworks based upon current theories. The researcher defines the strategies for the experiment phase, including identifying research methods and data collection methods, and identifying specific goals for each experiment cycle. In the strategy, the researcher defines the specific boundaries for the beginning and ending of cycles and the project as a whole. These boundaries provide the necessary scope for the additional team members (instructional designers and software developers). For example, the researcher may define the means of delivering the content to the devices not within the scope of the project, but the coding of the content itself within scope. In addition, the researcher defines the scope of each iteration small enough to permit multiple iterations of the experiment phase.\nDuring the strategize phase, additional team members perform their analysis. Instructional designers perform the analysis phase of ADDIE. Software developers perform the initial planning and architecture design portion of their process. The frameworks defined by the researcher are used as input to the instructional designers and the software developers and for their analysis.\nThe experiment phase is the iterative phase in the ASER approach, clearly illustrated by the circular arrows in the diagram. The research team uses iterative cycles of design, develop, instructional experiment, and evaluate, with the evaluate step providing input to the next design stage and the first iteration acting as the feasibility test for the project. The four cycles align directly with the design, develop, implement, and evaluate phases in ADDIE. The iterative development and testing phases of the agile software development method also align. Each iteration has a specific goal, defined in the research design strategy, and there is specific software and instructional material developed to support that goal.\nReflect is the final phase of the project. In this phase, all data collected throughout the iterative cycles is analyzed as a whole. The researcher seeks to extract design principles based upon the results of the design experiments. The software development team completes the final phases of their process, seeking to commercialize the results of their development. In addition to the analysis of the research results, an evaluation of the overall research process is performed and learnings are shared.\nBrown, A. L. (1992). Design experiments: Theoretical and methodological challenges in creating complex interventions in classroom settings. The Journal of the Learning Sciences, 2(2), 141-178. doi:10.1207/s15327809jls0202_2\nCollins, A. (1992). Towards a design science of education. In E. Scalon & T. O'Shea (Eds.), New Directions in Educational Technology (pp. 15-22). Berlin, Germany: Springer-Verlag.\nGravemeijer, K., & Cobb, P. (2006). Design research from a learning design perspective. In J. van den Akker, K. gravemeijer, S. McKenney, & N. Nieveen (Eds.), Educational Design Research (pp. 17-51). Abingdon, UK: Routledge. doi:http://www.routledge.com/\nMa, Y., & Harmon, S. W. (2009). A case study of design-based research for creating a vision prototype of a technology-based innovative learning environment. Journal of Interactive Learning Research, 20(1), 75-93. doi:http://www.aace.org/\nMiddleton, J., Gorard, S., Taylor, C., & Bannan-Ritland, B. (2008). The \"Compleat\" Design Experiment. In A. E. Kelly, R. A. Lesh, & J. Y. Baek (Eds.), Handbook of design research methods in education (pp. 21 – 46). New York: Routledge, Taylor & Francis.\nMariage, C., Vamderdonckt, J., & Pribeanu, C. (2005). State of the art of web usability guidelines. In R. W. Proctor & K.-P. L. Vu (Eds.), Handbook of human factors in web design (pp. 688 – 700). Mahwah, NJ: Lawrence Erlbaum Associates.\nvan den Akker, J., Gravemeijer, K., McKenney, S., & Nieveen, N. (2006). Introducing educational design research. In J. van den Akker, K. Gravemeijer, S. McKenney, & N. Nieveen (Eds.), Educational Design Research (pp. 3-13). Abingdon, UK: Routledge. doi:http://www.routledge.com/\nWang, F., & Hannafin, M. J. (2005). Design-based research and technology-enhanced learning environments. Educational Technology Research and Development, 53(4), 5-23. doi:10.1007/BF02504682"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:7cfb0c65-e079-4324-b8a1-c569c28c2b25>","<urn:uuid:d5f85b87-d8c8-484d-95be-788119d83dc1>"],"error":null}
{"question":"请问如何形成南极冰架底部的'倒置河流'？这个过程是怎样的？🤔","answer":"These 'upside-down rivers' form as buoyant plumes of warm and fresh water rise and flow along the underside of an ice shelf. These warm water plumes carve channels into the base of the ice shelf, which can extend for tens of miles and reach depths of up to 800 feet. When such a channel is carved into the ice shelf's base, the top surface of the ice shelf sags, creating a visible depression or 'wrinkle' in the otherwise smooth ice surface.","context":["by Staff Writers\nBoulder CO (SPX) Mar 17, 2016\n\"Upside-down rivers\" of warm ocean water threaten the stability of floating ice shelves in Antarctica, according to a new study led by researchers at the University of Colorado Boulder's National Snow and Ice Data Center published in Nature Geoscience. The study highlights how parts of Antarctica's ice sheet may be weakening due to contact with warm ocean water.\n\"We found that warm ocean water is carving these 'upside-down rivers,' or basal channels, into the undersides of ice shelves all around the Antarctic continent. In at least some cases these channels weaken the ice shelves, making them more vulnerable to disintegration,\" said Karen Alley, a Ph.D. student in CU-Boulder's Department of Geological Sciences and lead author of an analysis published in Nature Geoscience.\nIce shelves are thick floating plates of ice that have flowed off the Antarctic continent and spread out onto the ocean. As ice shelves flow out to sea, they push against islands, peninsulas, and bedrock bumps known as \"pinning points.\" Contact with these features slows the flow of grounded ice off the continent.\nWhile ice shelves take thousands of years to grow, previous work has shown that they can disintegrate in a matter of weeks. If more ice shelves disintegrate in the future, loss of contact with pinning points will allow ice to flow more rapidly into the ocean, increasing the rate of sea level rise.\n\"Ice shelves are really vulnerable parts of the ice sheet, because climate change hits them from above and below,\" said NSIDC scientist and study co-author Ted Scambos. \"They are really important in braking the ice flow to the ocean.\"\nThe features form as buoyant plumes of warm and fresh water rise and flow along the underside of an ice shelf, carving channels much like upside-down rivers. The channels can be tens of miles long, and up to 800 feet \"deep.\"\nWhen a channel is carved into the base of an ice shelf, the top of the ice shelf sags, leaving a visible depression, or \"wrinkle\", in the relatively smooth ice surface. Alley and her colleagues mapped the locations of these wrinkles all around the Antarctic continent using satellite imagery, as well as radar data that images the channels through the ice, mapping the shape of the ice-ocean boundary.\nThe team also used satellite laser altimetry, which measures the height of an ice shelf surface with high accuracy, to document how quickly some of the channels were growing. The data show that growing channels on the rapidly melting Getz Ice Shelf in West Antarctica can bore into the ice shelf base at rates of approximately 10 meters (33 feet) each year.\nThe mapping shows that basal channels have a tendency to form along the edges of islands and peninsulas, which are already weak areas on ice shelves. The team observed two locations where ice shelves are fracturing along basal channels, clear evidence that basal channel presence can weaken ice shelves to the point of breaking in vulnerable areas.\nIce shelves are thick floating plates of ice that have flowed off the continent and out onto the ocean. As ice shelves flow out to sea, they push against islands, peninsulas, and bedrock bumps known as \"pinning points\".\nContact with these features slows the ice flowing off the continent. If ice shelves disintegrate in the future, loss of contact with pinning points will allow ice to flow more rapidly into the ocean, increasing rates of sea level rise.\nWhile no ice shelves have completely disintegrated due to carving by basal channels, the study points to the need for more observation and study of the features, said co-author... \"It's feasible that increasing ocean temperatures around Antarctica could continue to erode ice shelves from below.\"\nThe study, \"Impacts of warm water on Antarctic ice shelf stability through basal channel formation,\" was led by University of Colorado Boulder Ph.D. student Karen Alley, who worked with coauthors Ted Scambos of NSIDC and Matthew Siegfried and Helen Fricker of Scripps Institute of Oceanography. Their work was funded in part by NASA and the U.S. Geological Survey.\nUniversity of Colorado at Boulder\nBeyond the Ice Age\n|The content herein, unless otherwise known to be public domain, are Copyright 1995-2016 - Space Media Network. All websites are published in Australia and are solely subject to Australian law and governed by Fair Use principals for news reporting and research purposes. AFP, UPI and IANS news wire stories are copyright Agence France-Presse, United Press International and Indo-Asia News Service. ESA news reports are copyright European Space Agency. All NASA sourced material is public domain. Additional copyrights may apply in whole or part to other bona fide parties. Advertising does not imply endorsement, agreement or approval of any opinions, statements or information provided by Space Media Network on any Web page published or hosted by Space Media Network. Privacy Statement All images and articles appearing on Space Media Network have been edited or digitally altered in some way. Any requests to remove copyright material will be acted upon in a timely and appropriate manner. Any attempt to extort money from Space Media Network will be ignored and reported to Australian Law Enforcement Agencies as a potential case of financial fraud involving the use of a telephonic carriage device or postal service.|"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:433a1005-c403-46d4-968e-fa30f1c1a472>"],"error":null}
{"question":"Which offers better protection against periodontal disease in dental restorations: Captek Nano's gold substrate or CEREC's IPS e.max lithium disilicate material?","answer":"Captek Nano's high-purity gold substrate (83%) has been clinically proven to reduce harmful bacteria and plaque surrounding restored teeth, providing protection against periodontal disease. While IPS e.max lithium disilicate offers excellent durability and esthetic properties, the documents don't mention any specific periodontal disease protection benefits for this material.","context":["June 2012, Volume 8, Issue 6\nPublished by AEGIS Communications\nA Practical Esthetic Solution to Challenging Clinical Situations\nComposite metal structure and composition of the coping provide esthetics that rival all-ceramics, high strength factors, and protect against periodontal disease.\nIn this rapidly changing world of new technologies and materials, established tried-and-true systems are often overlooked, as many believe options that are not considered “cutting edge” may be outdated or inferior. This attitude could not be further from the truth and can often lead practitioners past the best solution for the restorative challenge being faced. With the tremendous number of restorative materials and systems available today, it is important to try to understand each material’s strengths and weaknesses in order to confidently make educated decisions as to the best material choices for any given restorative challenge.\nCaptek™ (Argen Corporation, www.captek.com) is a very unique substrate for porcelain-fused-to-metal (PFM) restorations that offers great benefits in esthetics, versatility, strength, and health. The Captek technology is, by definition, a “metal composite” where high-purity gold is reinforced with an internal skeleton of uniquely prepared hard particles of platinum/palladium. First introduced in the literature in 1995,1 Captek has undergone a continual and dramatic evolution, resulting most recently in the development of the higher-strength, super-thin Captek Nano line of materials.2 By using nanoparticle technology and manufacturing, the density of the reinforcing particles is increased over 100% from the original Captek. The engineering of the Captek Nano yields increased physical properties in thinner dimensions with slightly reduced gold content. This same advanced nanotechnology has also resulted in improved companion products that achieve a more powerful porcelain bond, are user friendly for the laboratory to build collars and coping support structures, and provide high fracture resistance.3 The Captek Nano system is also indicated for longer-span bridges that include up to two consecutive pontics and implant-supported crowns and bridges.\nBecause of its unique structure and composition, Captek Nano is able to provide a super-thin (0.20 mm) high gold substrate (83%) that does not oxidize,4 lose its bright gold appearance, or create darkness at the margin. Additionally, the high-purity gold—when supported internally with the unique particle structure—is clinically proven to reduce harmful bacteria and plaque surrounding restored teeth.5 With all of these attributes, it is possible to achieve esthetics that rival all-ceramics, achieve high strength factors, enable clinicians to choose their preferred margin preparation6—traditionally cement or bond—and provide a restoration that encourages health with high protective potential from caries and/or periodontal disease.\nEven though some might be aware of the esthetic potential that Captek offers, in esthetic situations, dentists often still default to all-ceramics first. Transparent all-ceramics do offer high esthetic potential, but they are contraindicated in situations where the underlying tooth structure is not ideal, as often is the case for non-vital or discolored teeth.7 This can present quite a dilemma when an otherwise straightforward all-ceramic esthetic case is complicated when one or more teeth are dark, missing, or compromised—requiring bridgework—or extra protection is necessary due to intrasulcular margin position and periodontal or other systemic health concerns.8 Perhaps there is just a need for extra strength due to high-risk occlusion or posterior restorations. As demonstrated in the two cases presented, Captek Nano was a successful restorative option and offered an esthetic and functional solution to the clinical challenges.\nCase 1—Management of Dark Preparations\nIn this case, patient was very dissatisfied with the pre-existing pressed ceramic crowns on the two centrals as well as the composite veneer on right lateral, and also wished to lengthen the left lateral. The case was originally prescribed for full-coverage lithium-disilicate crowns on the centrals with thin lithium-disilicate veneers (e.max®, Ivoclar Vivadent, www.ivoclarvivadent.com) on the two laterals (Figure 1). The obvious challenge was not just the dark preparations on the centrals, but the fact that they were two different colors (Figure 2). In addition, the roots were different in width, creating a contour/shape challenge. The situation was further complicated by the fact that the laterals were minimally prepared facially for thin veneers, while the centrals would be thicker crowns.\nIt is commonly thought that the solution to a dark substrate is to simply prepare more aggressively, creating more room to mask the darkness. This approach can certainly help, but it is not a total solution because the underlying color—which can also change over time—can still show through, even with aggressive preparation. This situation is depicted in the second case. When the decision is made to restore with a more opaque ceramic material, the challenge then becomes how to control the ceramic layering so as to re-establish the vitality of the crown and create a natural value and appearance of translucency. So, on the one hand, metal-free restorations can easily be too transparent, resulting in a gray or low-value appearance, while on the other hand, it is very common—especially in the cervical margin area—for the more opaque zirconia products to look overly bright and lacking in vitality.9\nIn the situation shown, after consultation with the doctor about the esthetic challenges, it was decided to approach this as a combination case, with the two centrals being produced with Captek Nano and the laterals with pressed ceramic veneers (Figure 3). The clinician was initially skeptical that a PFM could blend esthetically with all-ceramic veneers in the anterior region. After hearing that Captek can block out underlying colors, yet still provide a clean, bright, and controllable canvas for creating the natural chroma and value,10 he agreed. In the author’s experience, Captek allows the ceramist to see in the laboratory the final crown shade that will closely represent the shade in the oral environment. Thus, for the author/ceramist, the Captek substructure made the matching process and the clinical outcome more predictable.\nPrior to fabrication of the veneers, care was taken to produce accurate-colored stump dies (IPS Natural Die Material, Ivoclar Vivadent) for the lateral incisors. The veneers were produced first, placed on the stump dies, then the Captek crowns were layered to match (Figure 4). The final case inserted in the mouth is shown in Figure 5. All goals in regards to eliminating the influence of the underlying tooth structure, maintenance of proper contours, blend-in at the gingival, and the esthetic match of full-contour metal-based restorations to pressed porcelain veneers were achieved.\nIt is important to note that the crowns did not have porcelain margins, but rather metal to the edge. Porcelain margins—while recognized as the most esthetic option on PFM or zirconia substructures in ideal situations—can be highly problematic if used on dark teeth. The darkness can be pulled right through the margin and broadcast into the body of the crown and reflect poorly in the tissue. This situation is depicted in the following case.\nCase 2—Management of Translucency at the Margin\nIn this case, a Captek crown was prescribed for the patient’s left central due to an awareness of the issue the dark preparation created (Figure 6). A porcelain margin was planned in an effort to achieve the best possible esthetics. A very deep shoulder was prepared to provide for a thicker porcelain margin to help mask out the darkness. Figure 7 shows the insertion of that crown. Even with a large shoulder preparation, the low value from the preparation was pulled right through the ceramic porcelain margin and into the tissue, even though there was additional room for ceramics. The low value at the gum line created a completely unacceptable result. The crown was re-made, this time with thin Captek Nano metal to the margin to block out the darkness. Figure 8 shows the insertion of the second crown. In this case, eliminating the porcelain margin made a dramatic difference in the esthetic clinical outcome. Because the Captek Nano material is so thin, does not oxidize, and therefore requires very little opaque to mask, no sign of darkness or excessive opacity is visible at the margin.\nThese cases show how Captek Nano can provide a common-sense solution to difficult clinical situations. With high-strength factors, an ultra-thin coping, the bright gold color, elimination of oxides/corrosion, and minimization of harmful bacterial plaque, Captek Nano offers a predictable restorative option in the quest to provide long-term esthetic results.\nThe author would like to thank Dr. Thomas Hedstrom of Worcester, Massachusetts, and Dr. Roger Dunphy of Ft. Meyers, Florida, for their dentistry, photography, and contributions to cases one and two respectively. Thanks are also due to the Argen Corporation in San Diego, California, for assistance and contributions toward this article.\n1. Shoher I, Whiteman A. Captek: a new capillary casting technology for ceramometal restorations . Quintessence Dental Technol. 1995;18:9-20.\n2. McArdle B. Clinical indications for a composite-metal PFM restoration . Cosmetic Dentistry (US Edition). 2011;1(January 20):16-20.\n3. Test of Captek ceramic‐metal composite bond. Faenza, Italy: ENEA Research Center, 2010. [Giancarlo Garotti, restorations fabricated by Dentalprotesi srl Laboratory of Mr. Godeas, Conegliano, Veneto, Italy].\n4. Geis-Gerstorfer J. Static Immersion and Electrochemical Polarization Corrosion Tests on Captek. Department of Prosthodontics, Dental School, University of Tubingen, 1997.\n5. Goodson JM, Shoher I, Imber S, et al. Reduced dental plaque accumulation on composite gold alloy margins . J Periodontal Res. 2001;36(4):252-259.\n6. Lowe RA. Periodontal compatibility of intracrevicular Captek restorative margins: A case report . Contemporary Esthetics and Restorative Practice. 2004;8(10).\n7. Dudney T. The challenge of restoring teeth with darkness in the gingival third . Inside Dentistry. 2007;3(8):66-68.\n8. Gottehrer NR. The periodontal crown: creating healthy tissue . Dent Today. 2009;28(5):121-123.\n9. Lowe RA. Comparison of Captek Nano EZ vs. porcelain to zirconia all ceramic crowns in the aesthetic zone: a case report . Oral Health. 2012\n10. Nathanson D, Nagai S, Po S, et al. Preliminary evaluation of the effect of crown on gingival color. Presented at the IADR Meeting March 1-13, 2004; Honolulu, Hawaii. Abstract 1478.\nAbout the Author\nAl Fillastre, BS, CDT","Retrofitting a Crown Supporting a Removable Partial Denture Using “Biogeneric Copy” to Replicate Tooth’s Preoperative Condition\nDhaval Patel, DDS\nWhen a crown that supports a removable partial denture (RPD) needs to be replaced, patients often balk at having to wait several weeks for laboratory production to be completed before receiving the new restoration. Moreover, the fit of the lab-produced unit may not always be satisfactory. CEREC® CAD/CAM technology provides a design method known as Biogenetic Copy, which allows a clinician to replicate the preexisting size, shape, and form of a tooth chairside. As this case report demonstrates, using this method to retrofit a crown under an existing RPD prosthesis can result in a predictable, accurate, durable, and esthetic same-day restorative solution.\nComputer-aided design/computer-aided manufacturing (CAD/CAM) technology has brought significant benefit to the dental industry.1,2 It not only enables clinicians to deliver same-day restorations, but also allows them to “think outside the box” and perform procedures that in the past were extremely rare in dentistry. One such application is manufacturing a crown on a tooth that supports a removable partial denture (RPD).\nIt is quite common for dental patients to have partial dentures. When one of the teeth that is supporting the RPD needs a crown, it is often difficult for the dentist to convince the patient to have the RPD sent out to a laboratory for 2 to 3 weeks along with the final impression. Patients simply don’t want to be without their partial denture for that length of time. Additionally, there is no guarantee that the fit of the lab-made crown supporting the RPD will be precise. As many dentists can attest, the fit can be “hit or miss.” There may be instances when the partial denture does not adequately fit around the newly produced crown, requiring the patient to have to get a new RPD and causing significant distress and frustration.\nA solution to this type of situation involves CEREC® (Sirona Dental, www.sirona.com) CAD/CAM technology. CEREC software provides a design method known as Biogeneric Copy, a technique with which the clinician can produce an exact replica of the preexisting size, shape, and form of the tooth to be restored. This technique is demonstrated in the following case report.\nA 68-year-old female patient presented with the chief complaint of sensitivity to cold and sweets on the upper right side of her dentition. Tooth No. 4 had an existing amalgam restoration with a mesial marginal ridge fracture (Figure 1). Radiographic evaluation was within normal limits. It was determined that this tooth needed a crown due to the fracture, recurrent decay, and the fact that it was supporting the removable partial denture. The RPD had a rest seat on the distal aspect of tooth No. 4 and two clasps on the buccal and lingual aspects of the same tooth (Figure 2 and Figure 3).\nPrior to using CEREC technology, the author found that there were two major drawbacks to performing this procedure. First, patients were typically very reluctant to part with their partial denture for a 2- to 3-week period; they found it difficult to function without it, especially if the RPD involved anterior teeth. Second, the fit of the final restoration to the RPD was almost always problematic.\nIn the present case, the author was able to confidently tell the patient that he could make her crown that same day with, in his opinion and based on his experience, a material that was strong enough to support the partial denture and a fit that would rival what the laboratory could produce. After having options explained to her, which also took into consideration her desire for a limited timeframe for completion, the patient agreed to receive a CAD/CAM-generated that would be fabricated in the clinician’s office immediately using CEREC Omnicam (Sirona).\nTooth No. 4 was prepared for a full-coverage crown. It is important to note that care should be taken to remove enough tooth structure in all areas of the tooth to allow adequate thickness of material for the new crown. If not enough tooth structure is removed, the software will give a minimal thickness warning, and adding any more material to what was copied could lead to adjustments that may result in an improper fit of the RPD around the restoration. This would defeat the purpose of this design method.\nAfter completing the preparation, the RPD was placed back in the patient’s mouth to check the reduction and make sure there was enough room for the crown (IPS e.max®, Ivoclar Vivadent, www.ivoclarvivadent.com) (Figure 4).\nScanning and Designing Process\nFor this case, making a copy of the existing tooth (ie, via Biogeneric Copy) was chosen as the design method. Biogenetic Copy is one of the fabrication modes of CEREC Omnicam software. It allows the operator to duplicate exactly the morphology and contours of an existing tooth or restoration, including rests, by having the computer overlay the “before” and “prep” pictures of any tooth in the mouth.\nPrior to tooth No. 4 being prepared for a crown, a scan of the tooth was taken along with the anterior teeth and placed in the folder called “Biogeneric Copy Upper.” After the tooth preparation was performed, tooth No. 4 was scanned again along with the anterior teeth and the scan placed in the folder called “Upper Arch.”\nAfter margination and setting the insertion axis is done, the software brings the user to the step of the copy line. This step involves drawing a copy line around the tooth structure that is desired in the final restoration (Figure 5). In this case there was a rest seat on the distal aspect and Akers clasps on the buccal and palatal, so it was imperative that all of those surfaces were copied completely. The copy line was drawn accordingly, and all of these surfaces were copied (Figure 6). When the software proposes the final restoration, one can see how it reproduces everything inside the copy line to provide the clinician a restoration that is an exact replica of the preexisting tooth (Figure 7). At this time the clinician should resist the urge to change anything on the surfaces that will be in contact with any rests or clasps, as doing so could lead to adjustments and the RPD subsequently not fitting around the new restoration.\nIPS e.max LT shade A2 was chosen to mill the crown.3 IPS e.max lithium-disilicate restorations offer excellent durability, featuring 360 MPa to 400 MPa of flexural strength.4,5 When fabricated to full contour, the monolithic structure is the most robust ceramic milled system tested to date.6,7 According to the manufacturer, the opalescence, translucency, and light diffusion properties of IPS e.max lithium disilicate were all designed to replicate natural tooth structure for beauty and undetectable restorations.8\nMilling and Try-in\nUsing the CEREC inLab MC XL CAD/CAM milling machine (Sirona), it took approximately 6 minutes for the restoration to be milled. The sprue was removed and the restoration was tried in. Once the fit and occlusion were verified, the RPD was inserted to ensure proper fit around the new restoration. As can be seen in Figure 8 and Figure 9, the RPD fit the restoration in a manner that was identical to the way it fit the original tooth. After insertion, the restoration was finished and polished. At this point, it was in the blue stage and required a crystallization process to stain and glaze.\nStaining, Glazing, and Cementation\nIn this case, it was noted during the planning stage that there was a definite change in chroma from the gingival to the incisal edge. The value shade of tooth No. 4 was A2 so this shade was selected. However, the gingival third was closer to A3; therefore, this third was stained with a darker A3 to achieve the gradation in color from the gingival third to the cuspal third.\nBefore bonding, the intaglio of the crown was etched with 4.5% hydrofluoric acid-etch for 20 seconds. The enamel at the margin was selectively etched for 15 seconds, washed, and dried. An adhesive resin dental cement (NX3 Nexus™, Kerr Dental, www.kerrdental.com) along with a self-etch, light-cure adhesive bonding system (OptiBond™ XTR, Kerr Dental) were used to cement the restoration. When the cement reached gel stage, the restoration was tack-cured for 2 seconds and excess cement was removed with an explorer. All surfaces were then light-cured for 20 seconds each. The proximal surfaces were flossed and any remaining cement was removed. Occlusion was checked and the margins were polished.\nThe RPD was then inserted, and it fit the same way as it fit around the original tooth and at the blue-stage try-in (Figure 10 and Figure 11). This fit was achieved without any adjustments on the milled restoration and was possible because of the Biogeneric Copy design method, which precisely duplicated the preoperative condition of the tooth.\nDiscussion and Conclusion\nThe CEREC Biogeneric Copy design method allows the clinician to achieve an exact copy of the preoperative condition of a tooth. An effective application for this design method is to use it to duplicate a tooth underneath a removable partial denture. In the author’s experience, patients have always been pleased to receive this kind of service and, as a result, have often become a good source of referrals for the practice. Retrofitting a crown under an existing removable partial denture prosthesis using chairside CEREC CAD/CAM technology has been shown to be predictable, accurate, durable, and esthetic.9-11 Being able to achieve this “same-day” with the CEREC Omnicam scanning process can be a pleasurable experience for the practitioner while, more importantly, serving the needs and wants of patients.\nThe author had no disclosures to report.\nAbout the Author\nDhaval Patel, DDS\nFaculty Member for Anterior and Posterior CEREC® CAD/CAM, and Advisory Board Member, PDS Institute, Irvine, California; Private Practice, Roseville, California\n1. Poticny DJ, Klim J. CAD/CAM in-office technology: innovations after 25 years for predictable, esthetic outcomes. J Am Dent Assoc. 2010;141 suppl 2:5S-9S.\n2. Shenoy A, Shenoy N. Dental ceramics: An update. J Conserv Dent. 2010;13(4):195-203.\n3. McLaren EA, Chang Y. The 3D communication of shade: visual shade taking and the use of computerized shade-taking technology. Inside Dentistry. 2006;2(1):92-93.\n4. Leung BT, Tsoi JK, Matinlinna JP, Pow EH. Comparison of mechanical properties of three machinable ceramics with an experimental fluorophlogopite glass ceramic. J Prosthet Dent. 2015;114(3):440-446.\n5. Giordano R. Materials for chairside CAD/CAM-produced restorations. J Am Dent Assoc. 2006;137 suppl:14S-21S.\n6. Guess PC, Vagkopoulou T, Zhang Y. Marginal and internal fit of heat pressed versus CAD/CAM fabricated all-ceramic onlays after exposure to thermo-mechanical fatigue. J Dent. 2014;42 (2):199-209.\n7. Lin WS, Ercoli C, Feng C, Morton D. The effect of core material, veneering porcelain, and fabrication technique on the biaxial flexural strength and weibull analysis of selected dental ceramics. J Prosthodont. 2012;21(5):353-362.\n8. IPS e.max® Lithium Disilicate. Ivoclar Vivadent website. http://www.ivoclarvivadent.us/emaxchangeseverything/lithium-disilicate/index.php. Accessed November 23, 2015.\n9. Helvey GA. Retro-fitting an existing crown adjacent to a removable partial denture in a single visit. Inside Dentistry. 2009;5(3):34-41.\n10. Marchack BW, Chen LB, Marchack CB, Futatsuki Y. Fabrication of an all-ceramic abutment crown under an existing removable partial denture using CAD/CAM technology. J Prosthet Dent. 2007;98(6):478-482.\n11. Schoenbeck P. Retro-fitting a CEREC crown to a removable partial denture. Dent Today. 2008;27(3):110,112-113."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:92fad212-db0a-4e1e-b84c-67c24454caf4>","<urn:uuid:cd721822-c88a-4415-8fbc-3afd0fb28203>"],"error":null}
{"question":"What are the key differences between the PW610F-A engine's compressor and the X3.3G engine's cylinder components in terms of their basic structure?","answer":"The PW610F-A engine uses a two-stage compressor that is designed to be compact and efficient with a low parts count, while the X3.3G engine uses a cylinder block and head system. The cylinder block serves as the main bottom end structure made of iron or aluminum where the air-fuel mixture is compressed, while the cylinder head is a flat plate of metal bolted to the top containing rocker arm and push rod components to transfer rotational mechanics from the crankshaft to operate the valves.","context":["Eclipse Aviation Selected Pratt & Whitney Canada to be the Eclipse 500 Engine provider on February 19, 2003. Pratt & Whitney Canada created the PW610F-A engine, a PW600 Series engine, to be the Eclipse 500 engine. On May 5, 2004 Pratt & Whitney Canada completed the first run of the PW610F engine and completed it's first flight on board Pratt & Whitney Canada's Boeing 720 flying test bed on December 20, 2004. The Pratt and Whitney Canada PW610F became certified by Transport Canada and the FAA on July 27, 2006. The official name for the Eclipse 500 Engine is the Pratt & Whitney Canada PW610F-A engine. The PW610F-A is capable of producing 950 pounds of thrust (lbf). The PW610F was originally rated at 900 pounds of thrust, however Pratt & Whitney Canada created an updated version (PW610F-A) of the PW610F that produces more thrust. Just like the other PW600 series engines, the PW610F-A is made with half the parts of a conventional turbofan engine.\nTwo Pratt & Whitney Canada PW610F-A engines are mounted at the back of the Eclipse 500 very light jet. The Eclipse 500 engine is FADEC Controlled (Full-Authority Digital Engine Control), allowing for a lighter workload on the pilot flying the Eclipse 500. Also the PW610F-A has an automatic power reserve that allows for increased power, if one of the engines accouters a problem.\nAbove Pratt & Whitney Canada PW610F-A Engine photo by Pratt & Whitney Canada, Copyright PWC. Second Eclipse 500 Engine Photo by hyku on Flickr. Second photo (only) released under a Creative Commons License.\nEclipse 500 Engine Pratt & Whitney Canada PW610F-A Specifications:\nPW610F-A Engine Dimensions (Eclipse 500 Engine Dimensions):\n- Diameter: 14 inches.\n- Length: 46 inches.\nEclipse 500 Engine Thrust:\n- Maximum Takeoff 950 pounds of force/thrust (lbf) for Maximum Takeoff.\n- Normal Takeoff: 950 lbf\n- Maximum Continuous: 850 lbf\nEngine Speed Limitations:\n- Max steady state low rotor (N1): 22,542 RPM (102%)\n- Max steady state high rotor (N2): 48,000 RPM (100%)\n- Transient (20 sec.) low rotor (N1): 22,763 RPM (103%)\n- Transient (20 sec.) high rotor (N2): 48,960 RPM (102%)\n- Maximum Takeoff: 1463 ºF or 795 ºC\n- Normal Takeoff: 1463 ºF or 795 ºC\n- Maximum Continuous: 1463 ºF or 795 ºC\n- Transient (20 seconds): 1490 ºF or 810 ºC\n- Starting: 1562 ºF or 850 ºC\nOil Inlet Temperature:\n- Maximum: 265 ºF or 130 ºC\n- Minimum: -40 ºF or -40 ºC (this temperature is listed on the type certificate, unsure if both are supposed to be 40 degrees.\n- Transient maximum (90 sec.): 275 ºF or 135 ºC\n- Min. at ground idle & flight idle: 15 psig\n- Normal minimum above idle: 100 psig\n- Maximum: 160 psig\n- Transient (20 seconds): 225 psig\nOil Tank Capacity:\n- Total Capacity: 6.13 Liters, 1.345 Imperial gallons or 1.620 U.S. Gallons\n- Usable capacity: 1.09 Liters, 0.239 Imperial gallons or 0.287 U.S. Gallons\nMaximum external bleed air available is 9.5 PPM at Sea Level decreasing to 7.3 PPM at 41,000 feet.\nFuel: Jet A\n- Advanced shock management design\n- High efficiency and flow\nPW610F-A Two-stage compressor\n- Compact, efficient, low parts count\nPW610F-A Reverse-flow combustor\n- Low emissions, high durability\nPW610F-A Single-stage high pressure turbine\n- Latest technology\n- Low parts count for low maintenance cost and fast turnaround time\nPW610F-A Single-stage low pressure turbine\n- Free turbine, shrouded blades\n- High efficiency mixer for low fuel consumption and low noise\n- Based on P&WC proven designs\nPW610F-A FADEC (Full Authority Digital Engine Control):\n- Dual channel redundancy\n- Ease of operation, reduced workload\n- Intelligent health monitoring and diagnostics\n- Designed for efficient integration with aircraft electronics\nAbove information is derived from Pratt & Whitney Canada information, their press releases and FAA data on the engine.\nThe Eclipse 500 Engine is also called the EA-500 Engine and the EA50 Engine.","TECHNICAL SPECIFICATIONS ENGINE MODEL For genset Models Engine Type No. Of Cylinder Compression Ratio Firing Order Cycle of operation Combustion system Fuel pump Governing Cooling X3.3 GI, X3.3G2 C33D5,C38D5 C30D6,C35D6 INLINE 4 18.5:2 1-3-4-2 Four Stroke Direct Injection BOSCH IN-LINE Mechanical Water cooled\nEngine An engine is motor which converts chemical energy into mechanical energy\nVarious Parts of Engine Crankshaft Crankcase Crank Pin Camshaft Spark plug Fuel pump Cylinder Block Cylinder Head Inlet valve & Exhaust valve Piston Piston Rings Connecting Rod Gudgeon Pin\nCylinder Block The cylinder block, also called as engine block is the main bottom end structure. Usually it is made up of iron or aluminum. Function: In the bore of the cylinder the fresh charge of air-fuel mixture is ignited,compressed by piston.\nCylinder Head The cylinder head is flat plate of metal bolted to the top of cylinder block with head gasket in between;Top of head contains rocker arm & push rod to transfer rotational mechanic from the crankshaft to linear mechanic to operate the valves. It is the key to performance of the internal combustion chamber.\nInlet valve & Exhaust valve Inlet valve:Its function is to intake the fresh air-fuel mixture into the cylinder. Exhaust valve:Its function is to exhaust is the burnt gases by the force of piston.\nPiston Piston is connected to the crankshaft through the connecting rod,when piston moves downward sucks fresh air-fuel mixture in suction stroke & ignited inside the cylinder due to this high temperature and pressure generated,thus expanded gas force down to piston.\nPiston Rings A piston ring is an open ended ring that fits into a groove or outer diameter of the cylinder. Piston rings have three major functions which are to seal the expansion chamber,support heat transfer & finally,regulate the engine oil consumption.\nConnecting Rod & Gudgeon Pin A small end of connecting rod is connected to the piston and other end is connected to the crankshaft. Its function is to transmit the reciprocating motion of piston to the to the rotary motion of crankshaft. Gudgeon pin is used to connect the piston & connecting rod.\nCrankshaft Crankshaft is the part of an engine which translates the reciprocating linear motion of piston into rotation. To convert the reciprocating motion into rotation,the crankshaft has “crank pin”,it typically connects to flywheel,to reduce the pulsation characteristics four stroke cycle.\nCamshaft Camshaft is a part which is used in piston engine to operate valves. It consists of cylindrical rod with cams. The camshaft were invented in Iraq (Mesopotamia), described by Al-Jazari in 1206.The relationship between camshaft rotation & crankshaft rotation is of critical importance.\nTurbocharger An exhaust driven air compressor Impeller on the left Turbine on the right Connecting shaft, free floating bearings, oil lubricated center housing\nAftercooling Heat exchanger for inlet air Series of metal tubes through which hot inlet air flows Heat from the air flowing from the tubes is absorbed through the tube walls and carried away 2 types Air to air (ATAAC) Jacket water (JWAC)\nWater Pump Flow of the coolant begins at the water pump Water pumps are gear or belt driven Water pump seals Separates engine oil from coolant\nOIL COOLER Engine coolant flows from the water pump directly into the oil cooler Oil carries heat away from critical engine parts Heat is transferred from the oil to the engine coolant\nTypes of fuel system PT = PRESSURE TIME IFSM =INTIGRATED FUEL SYSTEM MODULE CRS= COMMON RAIL SYSTEM MCRS= MODULAR COMMON RAIL SYSTEM CAPS=COMMON ACCUMOLATED PUMPING SYSTEM HPI=HIGH PRESSURE INJECTION SYSTEM ININE= INJECTION ROTARY= INJECTION\nCommon Engine Terms >Bore >Stroke >Compression Ratio >Displacement >Horsepower\nBore Size >The diameter of the cylinder >Measured in inches or millimeters\nStroke >How far the piston moves from TDC to BDC >Equal to twice the crank radius\nCompression Ratio > Ratio between the cylinder volume with the piston at BDC and the volume with the piston at TDC Compression ratio of our engines are approximately a 16:1 (non-ACERT) and 18:1 (ACERT)\nDisplacement Engine size is expressed in liters or cubic inches Displacement =X Stroke X No. of Cyls. (3.14 X B 2 ) 4\nHorsepower Horsepower is the rate of doing work (how quickly a force is applied through a distance) Horsepower can be expressed in pound feet per second 1 horsepower = 550 lb/ft per second = 33,000 lb/ft per minute"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:df6af86e-8a99-417c-9265-6ff353c2eb94>","<urn:uuid:d177a61c-b4f6-4db5-ac7a-a4df23b0e670>"],"error":null}
{"question":"Could you compare the depth of Great Slave Lake with Tsho Rolpa glacial lake in terms of their elevation and monitoring challenges?","answer":"Great Slave Lake in Canada's Northwest territories is the deepest lake in North America at over 2,000 feet deep. In contrast, Tsho Rolpa glacial lake in Nepal is located at a much higher elevation of 4,550 meters above sea level. While Great Slave Lake's remoteness makes it largely untouched by progress, Tsho Rolpa presents unique monitoring challenges due to its location in remote high mountains. To address this, researchers use a combination of remote-sensing data and field validation to monitor its expansion and stability, as direct access for comprehensive field-based monitoring is difficult.","context":["Why monitor glacial lakes?\nOf the 3,624 glacial lakes in the Koshi, Karnali, and Gandaki basins, our 2020 inventory identified 47 as potentially dangerous or at of risk of outburst flooding. In the Koshi basin alone, there are 42 potentially dangerous glacial lakes – 22 in China and 18 in Nepal.\nThe 26 recorded glacial lake outburst floods in Nepal have been devastating, claiming lives and destroying critical infrastructure such as roads and hydropower plants. Worryingly, these incidents are now increasing in frequency as the rise in global temperatures accelerates the melting of glaciers. Long-term, continuous monitoring of potentially dangerous glacial lakes is therefore critical. However, such lakes are often located in remote high mountains, not easily accessible for comprehensive field-based monitoring.\nWeACT research on Tsho Rolpa glacial lake\nUnder the Web-Based Natural Dam-Burst Flood Hazard Assessment and ForeCasting SysTem (WeACT) project, a team from four institutions – ICIMOD, Loughborough University, Newcastle University, and Tribhuvan University – adopted a new approach for their study that combines remote-sensing data with field validation to remotely monitor the expansion of Tsho Rolpa glacial lake, a potentially dangerous glacial lake in the Koshi basin. Data generated by remote sensing showed that the lake is expanding towards Takarding Glacier, and this was validated by an expedition team which observed the glacier ice calving into the lake. This new approach could be adopted to monitor lakes across basins.\nWhy Tsho Rolpa?\nTsho Rolpa glacial lake is located at 4,550 masl in the Rolwaling Valley, Dolakha District, central Nepal. One of the advantages of studying Tsho Rolpa is the availability of data on the lake’s evolution. Researchers began studying the lake in the early 1990s, when the lake’s high flood risk was identified. The lake’s water level was lowered in the past to reduce the risk, but the lake is now expanding, and islands that were visible near the end moraine dam are shrinking. The WeACT research team observed continuous rock fall and landslides from the lake’s side walls, ice in the lateral and end moraine melting, and glacier melt from the side valley feeding into the lake. All these developments add more stress to the lake’s stability, and the risk of a moraine dam breach is potentially high.\nRemote sensing coupled with field-based validation\nThe WeACT research team used satellite images with a high spatial and temporal resolution to study Tsho Rolpa’s boundary variations for the summer of 2019. The researchers used Copernicus Sentinel multispectral imagery to extract more accurate lake boundaries at a 10-m spatial resolution. Preliminary results estimated the lake’s boundary changes and the glacier terminus horizontal position through time. The team validated the results through unmanned aerial vehicle-based photogrammetry, with information from the field-based ground control point using a differential global positioning system device. The team also compared their observations with previous estimations to find that the lake has been gradually expanding.\nFor Tsho Rolpa, the WeACT team’s approach allowed the observation of monthly and annual boundary change rates beyond 2019 (starting from when the lake was first investigated in the early 1990s) using other data sources besides Sentinel imagery. This approach of using remote-sensing time series to monitor glacial lake evolution has the potential to improve glacial lake analysis in general. This research primarily enables stakeholders at the local, provincial, and national levels to understand changing GLOF risks and integrate the knowledge into their disaster management plans.","Canada is a country with more than her fair share of lakes. In reality, eight percent of the country’s landmass is covered by the fresh water bodies. That’s a fact which puts Canada in prime position on the list of countries with the most surface area covered by lakes.\nLakes are beautiful and just as environmentally important as oceans, yet they remain pretty much uninvestigated. Yes, data is available on how big they are, what their depth is and there’s plenty of information on estimations of their volume. We know they play an important part in the hydrologic cycle, but what exactly lies beneath the waters is pretty much a mystery. The world takes lakes for granted. We shouldn’t. Lakes are amazing.\nIf you really want to see lakes in all their true natural glory, Canada should be your number one place to visit. Check out the most incredible fifteen here and you’ll start to wonder why you haven’t been there sooner.\n15. Wedgemount Lake\nWedgemount Lake nestles just below Wedge Mountain in the Garibaldi Mountain Range in British Columbia, Canada. It’s encompassed by two glaciers, the Wedgemount and the Armchair. At its deepest point it’s estimated to be around sixty metres deep and five at its shallowest. The lake can only be reached after a steep, seven-kilometre climb which you’ll need some good boots for and the right equipment. Don’t plan on catching your dinner while you’re up there. Recent studies have shown the lake to have no fish life.\nWhy Go? The incredible turquoise waters of Wedgemount Lake are surrounded by some of the most stunning scenery you’ll ever see. It’s comparable with a glacial moonscape. Because of its geographical position the night skies are light pollution free which makes it a great place for overnight star spotting.\nMap Location: Lake Wedgemount\n14. Lake Superior\nIf you’re planning on visiting Lake Superior, don’t think you’ll be able to take a leisurely stroll all the way around its shores. Lake Superior, with a surface area of almost thirty-two thousand square miles, is as big as some countries. It spreads its watery reach from Ontario in the north of Canada, over the border and through several American states.\nWhen they named it, they named it right, because it really is superior in many ways. Not only is it the largest of the Great Lakes, it’s also the largest freshwater lake in the world. Surprisingly enough, it only comes in third where the volume of water it holds is concerned. You’ll need some good muscles if you’re considering rowing across it though. It measures a staggering one hundred and sixty plus miles at its widest point. Now that’s some lake.\nWhy Go? While you might not be able to walk around Lake Superior, you can drive around it. It’s a one thousand two hundred mile road trip of a lifetime through national parks with amazing canyons, cliffs, and waterfalls. A definite must do.\nMap Location: Lake Superior\n13. Berg Lake\nBerg Lake lies just underneath the highest peak in the Rockies, Mount Robson, which is in the Canadian province of British Columbia. It’s tucked away out of sight at an altitude of just under five and a half thousand feet. The only way to reach it is by hiking through the wilds of Mount Robson Provincial Park. Is it worth the effort? Definitely. The azure waters of Berg Lake are backed by impressive mountains and bordered by pine forests. The landscape and light are a photographers dream.\nWhy Go? Berg Lake is a glacial lake fed by the Berg Glacier. As it is constantly moving, chunks frequently drop off the glacier and into the lake waters to float there like mini icebergs. To get to Berg Lake you need to pass through the incredible Valley of a Thousand Waterfalls which, on its own, is reason enough for making the trip.\nMap Location: Berg Lake\n12. Lake Ontario\nLake Ontario, in the Canadian province of Ontario, is bordered not just by Canada, but by the US state of New York too. It would be easy to compare Lake Ontario to one big faucet as the lake provides drinking water to over nine million people. That’s a lot of water coming out of the smallest of the Great Lakes every day. It might be diminutive, but what it lacks in superficial square footage it makes up for in depth. Being over eight hundred feet at its deepest point means it holds more water than lakes which are bigger in size. An unusual fact which makes it the fourteenth largest lake in the world.\nWhy Go? Lake Ontario is rimmed with beautiful beaches and cliffs. It’s the perfect place for practicing water sports of every kind. From windsurfing, kayaking and paddle boarding. The bonus? If you fall off you don’t have to worry about swallowing the water, it’s fresh not salt. While you’re there, keep your eyes peeled and see if you can spot Lake Ontario’s monster of the deep, Ogopogo.\nMap Location: Lake Ontario\n11. Maligne Lake\nMaligne Lake is a stunning fourteen mile-long stretch of bright blue water at the base of the Maligne Mountains. Part of the Jasper National Park in Alberta, Canada, its glacial waters are on average just over a hundred feet deep in most parts, but in some points plunge down as far as three hundred. It’s forty-five miles of shoreline is bordered with pine forests. It’s also world renowned for the tiny, but much-photographed islet called Spirit Island.\nWhy Go? From on the waters of Lake Maligne it’s actually possible to see all three of the different glaciers which feed the lake. It’s also a great place for sport fishing, with the main catch being rainbow trout, and kayaking and canoeing. So if you have a pioneering spirit, Lake Maligne should be on your bucket list, but keep an eye out for bears, wolves, and caribou.\nMap Location: Maligne Lake\n10. Spotted Lake\nSpotted Lake, in the Similkameen Valley in British Columbia, when full of water isn’t that much to look at. It’s also probably the smallest patch of water to be labeled lake too. It’s just under half a mile long and less than a quarter of a mile wide. Makes you wonder what all the fuss is about, doesn’t it? But when Spotted Lake dries out in the summer months, it becomes one of those weird and wonderful creations of Mother Nature that are just absolutely amazing. The lake’s waters have an exceptionally high mineral content and as they evaporate, they leave behind a strange lunar-like surface full of crystallized pathways and pools.\nWhy go? Spotted Lake was revered as a sacred site by the local indigenous tribes who realized it had amazing medicinal and therapeutic qualities. It also magically changes color as the season progresses and the water evaporation increases. It really is one of those bizarre things which just has to be seen to be believed.\nMap Location: Spotted Lake\n9. Abraham Lake\nAlthough Abraham Lake, in Alberta, Canada, is called a lake it is, in fact, a man-made reservoir. The twenty mile long stretch of water was created with the construction of the Bighorn Dam in the early nineteen seventies. It’s quite narrow measuring just over two miles at its widest point and with a surface area of around twenty-one square miles it doesn’t show up on any list of the world’s largest lakes. Abraham Lake has become famous for creating its own kind of magic.\nWhy go? During the harsh Canadian winter, Abraham Lake freezes over and as the ice forms it traps bubbles rising from the depths inside it. These frozen bubbles are a freak of nature caused by bacteria rotting the underwater vegetation. Getting to Abraham Lake to photograph the bubbles should be on every adventurous photographer’s list of must do’s.\nMap Location: Abraham Lake\n8. Great Slave Lake\nThe Great Slave Lake, in Canada’s Northwest territories, is ranked as the tenth largest lake in the world. What really sets it apart from other lakes though is its depth. At just over two thousand feet in some parts, it’s the deepest in North America. It’s not a lake you can explore in one day either as it measures an incredible ten and a half thousand square miles, is almost three hundred miles long and its width is over a hundred and twenty miles at the widest point. Yes, it is enormous.\nWhy go? The Great Slave Lake’s remoteness means it’s a part of the world which is pretty much untouched by progress. It really is an unspoilt wilderness which is perfect for kayaking and fishing. Parts of the lake can be frozen over for up to eight months of the year and are cut off from civilization, so be careful when you go or you could be there for much longer than expected.\nMap Location: Great Slave Lake\n7. Lake Minnewanka\nLake Minnewanka, tucked away in the mountains near the town of Banff in the Banff National Park, is thirteen miles long which makes it the second longest mountain lake in Canada. It’s surrounded by stunning snow-capped mountains and its chilling, glacial blue waters can reach depths of up to five hundred feet. The lake’s volume has also been increased over the years, with water levels rising almost a hundred feet, after dams were built to provide hydro-power to Banff. What’s so special about it?\nWhy go? After the dams were built and Lake Minnewanka’s water levels rose so dramatically, they flooded a small village, Minnewanka Landing, which was on the shoreline. Now completely submerged, it’s become an amazing scuba diving site with a whole abandoned ghost village to explore underwater. If you’re there in the winter, there’s also a chance to go ice diving if you can handle the cold.\nMap Location: Lake Minnewanka\n6. Waterton Lake\nWaterton Lake is a lake with dual nationality. It is located partly in Canada, near Alberta and partly in the US, near Montana. Although it’s split into two distinct parts, upper and lower, it’s joined by the Bosporus channel so is classed as one lake rather than two. Waterton Lake, at an altitude of over four thousand feet and with a surface area of approximately five square miles, is surrounded by national park lands renowned for their biodiversity. Its waters have an average depth of around two hundred and fifty feet, but this can change to almost five hundred feet in some places. That’s pretty deep.\nWhy go? Waterton Lake is situated in the Waterton Lakes National Park. It’s an environment so uniquely special it’s been classed as a UNESCO World Heritage Site, an International Peace Park, and a Biosphere Reserve. It’s the perfect place to really get back to nature by hiking some of the park’s amazing trails. Though if you do go, make sure you’re bear aware.\nMap Location: Waterton Lake\n5. Peyto Lake\nPeyto Lake is another of those stretches of water which will take you by surprise at the startling azure blue color of its waters. Located high up in the Canadian Rockies at an altitude of over six thousand feet, it is incorporated in the boundaries of the Banff National Park. It’s a small, but easily accessed glacial lake which measures just under two miles at its longest point, only half a mile at its widest and has a surface area of two square miles. As far as Canadian lakes go, it’s quite petit.\nWhy go? Even though Peyto Lake is up in the mountains, it’s is relatively easy to get to. Which is great if you’re not the backpacking, trailblazing, hiking type. It means you don’t have to miss out. Peyto Lake can be reached by driving through the Banff National Park on highway 93 or the Icefields Parkway to call it by its other name. Don’t feel guilty for not hiking, the photographs you take will be just as stunningly impressive as if you’d walked.\nMap Location: Peyto Lake\n4. Emerald Lake\nEmerald Lake can be found in the Yoho National Park which is in British Columbia, Canada. The lake really lives up to its name by being a stunning emerald green in color when it’s in its liquid form. High up at an altitude of over four thousand feet, Emerald Lake can remain frozen for periods as long as seven months of the year so don’t plan on going before at least July. It may be the largest lake in Yoho National Park, but its shoreline only measures just over three miles long and is completely circumvented by a hiking trail which takes around one and a half hours to fully complete.\nWhy go? Emerald Lake is in a quiet and very secluded spot but is easy to get to with a vehicle. It’s a great place for observing eagles and ospreys in their natural habitat while hiking the trail. You can also canoe across the beautiful green and tranquil waters and get a feel of how it might have been for the original indigenous inhabitants of the area.\nMap Location: Emerald Lake\n3. Garibaldi Lake\nGaribaldi Lake is a large stretch of water geographically located in British Columbia, Canada between the townships of Whistler and Squamish. Its surface area spreads for an amazing two thousand five hundred acres through the Garibaldi Provincial Park, which is a lot of lake. It has an average depth of just under four hundred feet which can plummet down as far as almost nine hundred feet in places. Garibaldi Lake can only be reached by hiking the Garibaldi Lake Trail which is around five and a half miles long.\nWhy go? The turquoise waters of Lake Garibaldi are so crystalline, the surface acts like a mirror and reflects super clear images of the surrounding landscapes. Great for photography. If you’re into winter sports like snowshoeing and backcountry skiing then this is a place you really should be aiming to visit.\nMap Location: Garibaldi Lake\n2. Lake Louise\nLake Louise is a glacial lake fed by the Lefroy Glacier and can be found in the Banff National Park, Alberta, Canada. It’s a small, but stunning lake which measures just over a mile in length, a third of a mile in width and has only a third of a square mile of surface area. With a maximum depth of around two hundred and thirty feet, it’s almost as deep as it is wide. Its close proximity to the small town of Lake Louise has made it a popular tourist attraction.\nWhy go? This is the ideal Canadian lake to visit if you’re unsure of being too far away from civilization. Spend the day wandering around the wilderness of Lake Louise’s shores, enjoy some horse riding through the forests or even rock climbing if you’ve got a head for heights. Then, rather than roughing it at a campsite, spend the night at the Château Lake Louise, the huge and very luxurious hotel built right by the water’s edge. No-one said you couldn’t visit Canadian lakes in style, did they?\nMap Location: Lake Louise\n1. Moraine Lake\nMoraine Lake nestles in a landscape which looks like the perfect picture postcard image. Pine forests, symmetrical mountain peaks and the lake’s ice blue waters shimmering between them. This impeccable stretch of glacial water is to be found in the Banff National Park, near the township of Lake Louise, in Alberta, Canada. Moraine Lake covers an area of around one hundred and twenty acres in the Valley of Ten Peaks and reaches almost fifty foot in depth in places.\nWhy go? Moraine Lake is one of the most photographed spots in all of Canada. It’s been replicated on everything from paper money to video games and even used as log-in screens for major technology companies. You’ve probably seen it digitally reproduced, so why not go and see the real thing? Believe it, it’s even better live, so make sure you don’t miss out by not going to see it.\nMap Location: Moraine Lake"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:9f9dcb5f-ffe2-466d-8411-d34e296a9393>","<urn:uuid:42847a9a-736c-4b8a-af6d-7fbf0ecc364b>"],"error":null}
{"question":"How should I clean and maintain aluminum outdoor furniture to keep it looking new?","answer":"To maintain aluminum outdoor furniture, clean it with soapy water and apply a coat of car polish to keep it looking as good as new. Aluminum furniture is corrosion resistant and can survive outside for extended periods. However, if you have less expensive folding chairs, they should be stored during bad weather. The higher-end, heavier-grade pieces can be left outside.","context":["Required Material For Outdoor Furniture\nOutdoor furniture is manufactured out of a number of natural and created materials. Most buyers want for outdoor pvc furniture that was made to last, looks new and fresh for years to come, stays attractive despite connection with the elements, and is easy to keep. Some materials are better than others, and several withstand connection with the elements better. To help make the best purchasing decision when buying outdoor or outdoor furniture, one should browse the characteristics of each kind of materials, paying close give attention to the experts and negative areas of every. Some could become more resilient to rainwater or wind flow while some can keep going a lot longer in ambiance or sunlight.\nYou will need to consider factors like available inside space for also storing, maneuverability and weight, the amount of maintenance required to keep carefully the furniture looking good carefully, and the looks one wants for the deck when choosing materials for your garden furniture. You can purchase outdoor furniture from furniture or home stores or online.\nMaterials within the Produce of OUTDOOR FURNITURE\nThe four main types of materials within the creation of outdoor furniture include plastic, wood, wicker, and materials.\nThe plastic-type material is the cheapest usually listed option. Plastic furniture highly is lightweight, can be created from recycled materials, and chairs can be stacked for storage. Also clear plastic is definitely not the best-looking option and may not exactly previous as long as other materials if one will buy flimsy furniture. More strong clear plastic furniture can be obtained that is weather durable and resistant. You will need to store plastic material inside to avoid pitting and fading, although top quality portions tend to go without demonstrating wear much longer. Maybe it’s cleaned with normal soapy water and a scrubbing clean (if needed), making it easy to look and keep maintaining after. Vinyl can be molded, molded, and shaped into nearly any design, such that it is a superb choice for those who want various things.\nPatio furniture comes into play a variety of lumber types you may use if you might just like a warmer, more each day and natural look. Popular lumber types include teak, pine, cedar, eucalyptus, and redwood. Hardwoods have a tendency to be durable and long-lasting, with teak, jarrah, and shore resilient up to 50 years, and redwood and role suffered up to 25 years. Coping with timber with special natural sealants and natural oils increase its lifespan significantly.\nSoft woods like cedar and pressure looked after pine, although significantly less durable as hardwoods, do earlier for years outside the house. Pressure healed pine is looked after to resist rot and standard water and will keep on up to two decades. However, unattended pine has the low degree of the amount of resistance to rot which is preferred which it is layered or closed down and stored indoors during winter weather. Another plus side to wood is the fact it doesn’t support the sun’s comfort like vinyl fabric and metallic do.\nWicker can be natural or fabricated and an outdoor patio area an inviting or rustic look. This woven wood is durable but lightweight. Wicker furniture can created from cane, rattan, bamboo, or a lot of other materials. Outdoor models are usually created from synthetics to be able to increase weather level of resistance and durability. Wicker furniture can be bulky and expensive, the utilization of synthetics has led to lower costs, however. Weather-resistant wicker can be hosed off and was made to last outdoors. Some deals include up to 20-12 calendar months assurance.\nTerrace and outdoor furniture is made out of some metals, each which consists of own weaknesses and abilities.\nWrought hair straightening iron shows up best in a simple or formal environment. It is a good, durable material, and furniture designs range between traditional to contemporary. It is rather heavy and cannot word of mouth of advice over or blow away easily, such that it is an excellent choice for the windy environment. This type of metallic will demand some treatment to avoid increase and corrosion degree of the amount of resistance. Maybe it’s colored to both create a different turn to improve its level of resistance to corrosion also. Some negatives of hair straightening iron furniture include iron’s propensity to heat and lose when kept in sunlight. It could be cold in cooler times even. Without cushions, iron is not the most well-liked choice, and using pads with wrought hair straightening iron furniture solves the nagging problems due to chilly and heat. Better quality fabrics should outdoors be used, and cushions should be located away after use. Wrought hair straightening iron furniture can be staying year-round out-of-doors, provided it properly is taken care of.\nMetallic shall not corrosion fade or, whether it’s been split with a powder-coat end especially. This metallic is employed in modern, streamlined designs. It requires less maintenance than material or wrought hair straightening iron which is significantly lighter and easier to move. Also, it remains cooler in natural light. Aluminum patio sets can be cleaned with soapy water, and making use of a level of car polish shall keep the light weight aluminum look as effectual as new. Unfortunately, this is an even more expensive material and high-end sets can be pricey. However, the material is corrosion repellent and could survive outside the house for lengthened times. One will quickly realize less costly foldable seats for an inexpensive car seat solution, but these should be stored during bad weather. Costlier, heavier-grade parts can be still left outside still."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:8a26865b-b15e-4930-96e6-16b6e7a67bb2>"],"error":null}
{"question":"Which costs more over time: maintaining parking garages regularly or letting them deteriorate? What does MIT research suggest about maintenance costs in infrastructure?","answer":"Regular maintenance is significantly more cost-effective than allowing deterioration. According to the Pennsylvania parking garage case studies, repairs for lightly-maintained garages cost two to four times more than well-maintained ones on an inflation-adjusted basis. This aligns with MIT CSHub's research showing that hazard-induced maintenance costs can be significant over a building's lifetime and can exceed the initial building cost. Their studies demonstrate that investing in more hazard-resistant and well-maintained construction is very cost-effective in certain locations.","context":["The risk of hazards like natural disasters and extreme heat is underestimated. Stronger construction to mitigate it is undervalued.\nMIT CSHub studies how cities can be made more resilient to hazards through investment in stronger, cooler construction.\nOur research integrates neighborhood texture, the density and configuration of buildings in an area, into hazard risk and loss analysis to reveal the value of stronger construction, identify areas and groups most at financial risk, and understand the greenhouse gas emissions of less strong construction. Additionally, our investigation of cool pavements has shown how they cool cities and the climate.\nTo provide a comprehensive picture of the economic vulnerability of structures in a specific community when subject to different hazards, CSHub focuses on the vulnerability assessment of buildings considering the neighborhood texture-driven pressure amplification and related costs of repair and recovery. The outcome of this research will serve the community as a tool to quantify and visualize the vulnerability of their neighborhood considering the construction method and local climate conditions.\nIn this project, inspired by molecular modeling and based on the structure types and components for several hazards, building-specific fragility curves will be developed. In addition to the variety of hazards, the performance of building components such as windows, siding, doors, and roofs will be added to the modeling portfolio through a combination of analysis and validation data. The result outputs will demonstrate how the fragility curves can enable a performance-based approach to resilience rating systems. The outcome of this research will be used in conjunction with other hazard resistance tools and life cycle economic and environmental analysis tools in support of performance-based resilience ratings.\nIn order to forecast fluvial and pluvial flooding risks, CSHub will develop a framework that incorporates above-ground city textures while detecting the flow of flooding on the surface. The outcome of this project is targeted to support rapid assessments of current infrastructure to the risks of climate variability, and climate change, as well as urban and suburban land use change. The tool will also be beneficial to agencies that are currently assessing the cost of climate change adaptation on urban infrastructure.\nThe Alkali-Silica Reaction (ASR) causes expansion and cracking in concrete. This can result in structural problems in concrete infrastructure that can limit the infrastructure's service life and also generate high maintenance costs. CSHub research seeks to better understand the reaction and its mechanisms, which is key to determining solutions that will prolong the life of concrete infrastructure.\n- Investigating a Big Dam Concrete Problem (MIT News, September 2017)\nSimulating the Formation of ASR Gels (April 2019)\n- Atomistic Modeling of ASR Gel (August 2017)\n- Bottom-up Modeling of ASR in Concrete (March 2016)\n- Dupuis, R; Béland, L.K. & Pellenq, R. Molecular simulation of silica gels: Formation, dilution, and drying, Physical Review Materials, Volume 3, 7, 2019.\n- Dufresne, A., Arayro, J., Zhou, T., Ioannidou, I., Ulm, F.J., Pellenq, R., & Béland L. K. Atomistic and mesoscale simulation of sodium and potassium adsorption in cement paste, The Journal of Chemical Physics, Volume 149, 70, 2018.\nCreep, the gradual structural deformation in concrete under a load, it is known to impact on the durability of concrete structures. CSHub researchers are working to better understand what causes creep starting at the nanoscale.\n- Riddle of cement's structure is finally solved (February 2016)\n- International Conference on Creep, Shrinkage and Durability Mechanics of Concrete and Concrete Structures(2013)\n- Toward Understanding Cement Paste Creep (January 2017)\n- Holding It Together - C-S-H Cohesion (December 2011)\n- Predicting CSH Aging (March 2013)\nCao, P., Short, M.P., and Yip, S. \"Understanding the mechanisms of amorphous creep through molecular simulation,\" PNAS, December 26, 2017, vol. 114 no. 52.\nBauchy, M., Masoero, E., Ulm, F.-J., & Pellenq, R. Creep of Bulk C-S-H: Insights from Molecular Dynamics Simulations, in C. Hellmich, B. Pichler, J. Kollegger (eds.), CONCREEP 10: Mechanics and Physics of Creep, Shrinkage, and Durability of Concrete and Concrete Structures, ASCE, 2015\nMasoero E., Bauchy, M., Del Gado, E., Manzano, H., Pellenq, R. M, Ulm, F.-J., & Yip, S. Kinetic Simulations of Cement Creep: Mechanisms from Shear Deformations of Glasses, C. Hellmich, B. Pichler, J. Kollegger (eds.), CONCREEP 10 : Mechanics and Physics of Creep, Shrinkage, and Durability of Concrete and Concrete Structures, ASCE, 2015\nShort, M. and Yip, S., \"Multiscale materials modelling at the mesoscale,\" Nature Materials, Volume 12, September 2013.\nVandamme, M.; Ulm, F.J., \"Nanoindentation investigation of creep properties of calcium silicate hydrates,\" Cement and Concrete Research, Volume 52, Pages 38-52, 2013\nIn hazard-prone areas, hazard-induced maintenance costs can be significant over the lifetime of a building. In fact, the costs of hazard-related repairs can exceed the initial building cost. Our team has developed a building life cycle cost analysis (LCCA) approach that incorporates operational costs associated with energy consumption and repairs due to damage from hazards. Our case studies have demonstrated that investing in more hazard-resistant residential construction in certain locations is very cost-effective.\n- MIT Climate Portal: Climate-Resilient Infrastructure (September 2021)\n- MIT News: Mitigating hazards with vulnerability in mind (September 2021)\n- The Hill: Climate Resilience is the New Sustainability (May 2021)\n- Building to Better Weather the Storm (MIT News, June 2017)\n- Build disaster-proof homes before storms strike, not afterward (The Conversation, August 2016)\n- New approach calcuates benefits of building hazard-resitant structures (MIT News, December 2016)\nFact Sheet: Resilient Buildings (May 2020)\nTopic Summary: City Texture and Urban Resilience (March 2020)\nInformation Sheet: Building Resilience (May 2018)\n- Building Life Cycle Cost Analysis: Life Cycle Costs of Hazard Resistant Buildings (February 2017)\nPrecipitation Flooding in Urban Environments (March 2021)\nCreating Customized Fragility Curves for Resilient Building (November 2018)\n- Prioritizing Resilient Retrofits (February 2018)\n- Planning More Resilient Cities (March 2017)\n- A Break-Even Hazard Mitigation Metric (July 2016)\n- Quantifying Hazard Life-Cycle Cost (August 2014)\n- Hazard Mitigation Assessment Methodologies (August 2013)\n- Quantitative Assessment of Resilience in Residential Building Envelope Systems (March 2013)\n- Keremides, Konstantinos; Qomi, Mohammad Javad Abdolhosseini; Pellenq, Roland J. M.; and Ulm, Franz-Josef. “Potential-of-Mean-Force Approach for Molecular Dynamics–Based Resilience Assessment of Structures” Journal of Engineering Mechanics, Volume 144, Issue 8 (2018)\n- Noori, M., Miller, R., Kirchain, R., Gregory, J., \"How much should be invested in hazard mitigation? Development of a streamlined hazard mitigation cost assessment framework,\" International Journal of Disaster Risk Reduction (2018)\n- Noshadravan, A.; Miller, T.R.; and Gregory, J. \"A Lifecycle Cost Analysis of Residential Buildings Including Natural Hazard Risk\" Journal of Construction and Engineering Management (2007).\nLife cycle assessment (LCA) considers all life-cycle phases from initial construction to demolition. For pavements, this includes the operation, maintenance, and end of life phases, and factors such as traffic delay, lighting demand, and future maintenance. CSHub models quantify environmental impacts across a pavement’s life cycle from manufacturing to disposal and offer detailed analyses of the use phase.\nMitigating Climate Change with Reflective Pavements (November 2020)\nContext Dependent Pavement Life Cycle Analysis (July 2019)\nLife Cycle Thinking: Pavements (March 2018)\n- Life Cycle Carbon Uptake of the United States Pavement Network (January 2021)\n- Impact of Use Phase in Pavement Life Cycle Assessment: A Case Study of Alternative Designs in Different Contexts (April 2014)\n- Key Drivers of Uncertainty in Pavement LCA (November 2012)\n- Comparative Pavement LCAs With Uncertainty (June 2012)\n- Network, Pavements and Fuel Consumption (April 2012)\n- Adopting a Life Cycle Perspective (April 2011)\n- Designing for Sustainable Pavements (March 2011)\n- Gregory, J., AzariJafari, H., Vahidi, E., Guo, F., Ulm, F.J., Kirchain, R. \"The role of concrete in life cycle greenhouse gas emissions of US buildings and pavements.\" PNAS. September 14, 2021 118 (37).\n- Guo, F., AzariJafari, H., Gregory, J., Kirchain, R. \"Environmental and economic evaluations of treatment strategies for pavement network performance-based planning\", Transportation Research D: Transport and Environment. Volume 99, October 2021, 103016\n- AzariJafari, H., Guest, G., Kirchain, R., Gregory, J., Amor, B. \"Towards comparable environmental product declarations of construction materials: Insights from a probabilistic comparative LCA approach\", Building and Environment, 190: 2021, 107542. 2021.\n- Xin Xu, Mehdi Akbarian, Jeremy Gregory, Randolph Kirchain, \"Role of the use phase and pavement-vehicle interaction in comparative pavement life cycle assessment as a function of context\", Journal of Cleaner Production, 2019.\n- M. Akabarian, F. Ulm, X. Xu, R. Kirchain, J. Gregory, A. Louhghalam, J. Mack, “Overview of pavement life cycle assessment use phase research at the MIT Concrete Sustainability Hub”, ASCE T&DI International Airfield and Highway Pavements Conference, Chicago, IL, July 21-24, 2019.\nXu, X., Gregory, J., & Kirchain, R. \"Role of the Use Phase and Pavement-Vehicle Interaction in Comparative Pavement Life Cycle Assessment,\" Proceedings of the Transportation Research Board 97th Annual Meeting, 2018.\nKirchain, R., Gregory, J., Olivetti, E. \"Environmental life-cycle assessment.\" Nature Materials, 16 693–697 (2017)\n- J. Gregory, A. Noshadravan, O. Swei, X. Xu, R. Kirchain, “The importance of incorporating uncertainty into pavement life cycle cost and environmental impact analyses,” Proceedings of the Pavement Life-Cycle Assessment Symposium 2017, Champaign, IL, April 12-13, 2017\n- Gregory, J., Noshadravan, A., Olivetti, E.A., Kirchain, R., \"A Methodology for Robust Comparative Life Cycle Assessments Incorporating Uncertainty.\" Environmental Science & Technology, Vol. 50: Issue. 12: Pages. 6397-6405.\n- Louhghalam A., Akbarian, M., Ulm F-J. \"Carbon management of infrastructure performance: Integrated big data analytics and pavement-vehicle-interactions\". Journal of Cleaner Production. Volume 142, Part 2, 20 January 2017, Pages 956-964. 2016\n- Xu, X., Wildnauer, M., Gregory, J., & Kirchain, R. \"Accounting for Variation in Life Cycle Inventories: The Case of Portland Cement Production in the U.S.\", R.E. Kirchain et al. (Eds), REWAS 2016: Towards Materials Resource Sustainability, Springer AG.\n- J. Mack, J. Gregory, R. Kirchain, “Accounting for Rehabilitation Activity Uncertainty in a Pavement Life Cycle Assessment using Probability and Decision Tree Analysis,” Proceedings of the International Concrete Sustainability Conference, Miami, FL, May 11-13, 2015.\n- Xu, X., Gregory J., Kirchain R., \"Role of the Use Phase and Pavement-Vehicle Interaction in Comparative Pavement Life Cycle Assessment\" Transportation Research Board 94th Annual Meeting. No. 15-4011. 2015.\n- Noshadravan A., Xu X., Gregory J., Kirchain R., “Uncertainty management in comparative life-cycle assessment of pavements”, Proceedings of the 12th International Symposium on Concrete Roads, Prague, Czech Republic, September 23-26, 2014.\n- Xu X., Noshadravan A., J. Gregory, R. Kirchain, “Scenario analysis of comparative pavement life cycle assessment using a probabilistic approach,” Proceedings of the International Symposium on Pavement LCA, Davis, CA, October 14-16, 2014.\n- J. Mack, X. Xu, J. Gregory, R. Kirchain, “Developing robust rehabilitation scenario profiles for life cycle assessment using decision tree analysis,” Proceedings of the International Symposium on Pavement LCA, Davis, CA, October 14-16, 2014.\n- Santero N., Loijos A., Ochsendorf J., \"Greenhouse Gas Emissions Reduction Opportunities for Concrete Pavements,\" Journal of Industrial Ecology, Volume 17, Issue 6, Pages 859–868, 2013\n- Loijos A., Santero N., Ochsendorf J. \"Life cycle climate impacts of the US concrete pavement network.\" Resources, Conservation and Recycling. Volume 72, March 2013, Pages 76-83, 2013.\n- Noshadravan A., Wildnauer M., Gregory J., Kirchain R., \"Comparative Pavement Life Cycle Assessment with Parameter Uncertainty,\" Transportation Research Part D, 25, Pages 135-138, 2013\n- Akbarian M., Moeini-Ardakani S.S., Ulm F.-J., Nazzal M., \"Mechanistic Approach to Pavement-Vehicle Interaction and Its Impact on Life-Cycle Assessment,\" Transportation Research Record: Journal of the Transportation Research Board, No. 2306, Pages 171-179, 2012\n- Mack J., Ulm F.-J., Gregory J., Kirchain R., Akbarian M., Swei O., Wildnauer M., \"Designing Sustainable Concrete Pavements using the Pavement-ME Mechanistic Empirical Pavement Design and Life Cycle Analysis,\" International Conference on Long-Life Concrete Pavement, 2012\n- Loijos A., Akbarian M., Sahni S., Ochsendorf J., \"Sensitivity Analysis of the Life Cycle Environmental Performance of Asphalt and Concrete Pavements,\" Concrete Sustainability Conference, 2010\nA life cycle cost analysis (LCCA) is an analysis methodology that enables engineers, designers, and decision-makers to better understand the economic impacts of infrastructure decisions over time along with the opportunities that exist to reduce impacts. CSHub pavements LCCA research considers life cycle, context, and future, and also incorporates risk.\n- Paving ahead (MIT News, April 2019)\n- Life Cycle Thinking: Pavements (March 2018)\n- Measuring the Impact of Competition on Paving Material Prices (November 2017)\n- Pavement Life Cycle Cost Assessment: Price Projection Modeling (April 2016)\nThe influence of analysis period on pavement network performance (November 2017)\n- Estimating The Impact Of Competition (February 2016)\n- Developing a Network-Level Pavement Management Model (November 2015)\n- Material-Specific Price Projections: Implementation (September 2014)\n- LCCA of Pavements: Scenario Analysis (February 2014)\n- Initial Cost Uncertainty in LCCA (May 2013)\nGuo, F., AzariJafari, H., Gregory, J., Kirchain, R. \"Environmental and economic evaluations of treatment strategies for pavement network performance-based planning\", Transportation Research D: Transport and Environment. Volume 99, October 2021, 103016\nO. Swei, M. Akabarian, J. Gregory, R. Kirchain, J. Mack, “A review of pavement economic studies at the MIT Concrete Sustainability Hub”, ASCE T&DI International Airfield and Highway Pavements Conference, Chicago, IL, July 21-24, 2019.\nOmar, S., Gregory, J., & Kirchain, R. (2018). Does Pavement Degradation Follow a Random Walk with Drift? Evidence from Variance Ratio Tests for Pavement Roughness, Journal of Infrastructure Systems, Vol 24, no.4, 2018.\n- Swei, O., Gregory, J., Kirchain, R., Construction cost estimation: A parametric approach for better estimates of expected cost and variation. Transportation Research Part B: Methodological. Volume 101, July 2017, Pages 295–305\n- M. Akbarian, O. Swei, and J. Gregory, Probabilistic Characterization of Life-Cycle Agency and User Costs: Case Study of Minnesota, Transportation Research Record: Journal of the Transportation Research Board, No. 2639, 2017, pp. 93–101. 2017\n- Swei, O., Gregory, J., and Kirchain, R. Probabilistic Approach for Long-Run Price Projections: Case Study of Concrete and Asphalt. Journal of Construction Engineering and Management. 2016.\n- Swei, O. Probabilistic Life-Cycle Cost Analysis of Pavements: Drivers of Variation and Implications of Context,Transportation Research Record: Journal of the Transportation Research Board, No. 2523. Pages 47–55. 2016.\n- Swei O., Gregory J., Kirchain R., Pavement Management Systems: Opportunities to Improve the Current Frameworks Transportation Research Board 95th Annual Meeting, No. 16-2940. 2016.","Some parking facility owners and operators believe that as long as their structures continue to serve the public, few maintenance-related tasks need to be performed. Nothing could be further from the truth—facility maintenance is downright essential. One of the most important things an owner or operator can do to extend the life of a parking structure is formulate and implement a proper maintenance plan.\nCase studies of three different parking garages in Pennsylvania clearly demonstrate that ongoing maintenance programs minimize repair costs. In fact, well-maintained garages have significantly lower annualized repair costs, while repairs for lightly-maintained garages cost operators and owners two to four times as much (on an inflation-adjusted basis).\nAll three Pennsylvania garages investigated were built in the early 1970s. They were all designed by the same design firm and all experienced similar weathering. The primary difference between the three garages was the extent of known maintenance. To easily identify the facilities, they will be referred to by their geographic location within the state: Eastern, Central, and Western.\nThe three garages feature the same structural systems: cast-in-place lightweight concrete, one-way slab and beam floor systems reinforced with unbonded post-tensioned (P/T) tendons. The garages share the following characteristics:\nThe lightweight concrete has poor freeze-thaw durability, which is partially offset by significant floor drainage slopes throughout most floor areas. Where drainage slopes are minimal, the slabs exhibited significant freeze-thaw damage.\nThe P/T tendons are 7-strand wire protected by plastic sheathing with minimal concrete cover (less than 3/16 of an inch). This was between the driving surface and the tendons where they crossed above beams. This thin concrete layer wore through in a number of locations, leaving the tendons vulnerable after the plastic sheathing also wore through. At locations where the sheathing had worn away, the tendons corroded and then broke.\nPerimeter walls consist of either concrete or clay hollow cell block similar to—but only half the height of—common concrete block (CMU). In the Eastern and Central garages, every other cell was grouted solid, while in the Western garage, all cells were grouted solid. The Eastern and Central garages sustained significant damage from having water trapped in the un-grouted (empty) cells. This was from water slowly saturating the concrete and tendons beneath it.\nThe Western garage had supplementary slab rebar to provide a safety mechanism for tendon failure. When these rebars corroded, they became a significant deterioration mechanism as well.\nCondition on Investigation\nConstructed in 1973, the Eastern garage is a 420-space, five-level facility. The garage’s maintenance history was unknown, but appeared to consist of light maintenance (primarily repairing exposed broken slab tendons and installing weep holes into perimeter masonry walls to alleviate water storage within the ungrounded cells). During the investigation, the garage’s critical issues were extensive perimeter wall and slab edge deterioration on the upper two levels (due to water saturation from the perimeter walls’ ungrouted cells), localized slab P/T tendon breakage above beams, chloride-contaminated concrete, and brittle joint sealants.\nConstructed in 1972, the Western parking garage is a 300-space, four-level facility. The maintenance history was unknown, but appeared to consist of light maintenance (primarily removing loose concrete and patching of spalls). This garage received a unique vertical expansion down into the soil beneath a portion of the facility (to make room for a 10,000-square-foot bus/train waiting area). During this project, a traffic-bearing, waterproofing membrane was installed above the waiting area and joint sealants were replaced. During the investigation, the garage’s critical issues consisted of extensive slab freeze-thaw damage at roof-level flat areas, freeze-thaw damage to numerous beam and slab edges, localized slab P/T tendon breakage above beams, extensive rebar corrosion and concrete spalling over the top of beams, chloride contaminated concrete, brittle joint sealants, and a worn-out membrane.\nConstructed in 1973, the Central garage is a 490-space, five-level facility. This garage was judged to be in fair condition, except for a 5,500-square-foot portion of the roof level where minimal floor drainage exhibited a significant number of broken slab P/T tendons. The known maintenance history consisted of two sets of structural and waterproofing repairs, as well as architectural renovations (the original perimeter wall was replaced with a brick-faced concrete wall). During the investigation, the garage’s critical issues were the extensive P/T tendon damage at flat areas of the roof level, moderate slab edge deterioration due to water leakage through the original perimeter wall and then through the brick façade, chloride contaminated concrete, and brittle joint sealants.\nStructural Repair Options\nDetailed here are the structural repair options along with costs and lifespans for the garages. Excluded are non-structural costs included in the final repair options’ costs. These, while real, varied greatly by client preference and constraints. These non-structural costs included lost revenue; construction management fees; design fees and contingencies; and lighting, elevator, parking equipment, and occupied space upgrades. Structural repair option costs include structural repairs and waterproofing to protect the structural repairs. Unless specifically noted, all repair options were designed to allow for another life extension at the end of the proposed repair (See Figure 1 for details).\nThe Eastern garage had several proposed repair options: one-year life extension at $139,000; five-to-10-year life extension at $1,223,000; 20-to-30-year life extension at $2,216,000; and replacement with a new garage with a 45-year-plus lifespan at $6,506,000.\nThe Western garage had these proposed repair options: three-to-five-year life extension at $889,000; seven-to-12-year life extension at $1,262,000; and 15-to-25-year life extension at $1,855,000. No replacement option was desired based on the anticipated lack of future additional parking demand and the resulting inability to recoup the large costs of a new facility.\nThe Central garage had these proposed repair options: three-to-seven-year life extension at $253,000 (this option required demolition shortly past year 10); five-to-10-year life extension at $684,000; 12-to-15-year life extension at $882,000; 14-to-19-year life extension at $898,000; 15-to-20-year life extension at $1,624,000; and replacement with a new garage with a 45-year-plus lifespan at $4,788,000.\nThe repair options presented different challenges to each garage owner. Owners typically look at monetary factors such as total cost, length of life extensions, and the remaining durations of outstanding bonds, as well as non-monetary considerations that include the political environment and anticipated future parking demand. Newer parking garages often have significant annual bond payments as compared to revenues, while older garages with small or no annual bond payments provide strong cash flow to subsidize other newer garages or the entire parking system. New parking garages rarely provide significant positive cash flow because they compete with much cheaper on-street parking (which is generally paid for with either gasoline excise or property taxes) and are provided as a public service with no intent of generating significant positive cash flow.\nIt’s recommended to owners that when analyzing monetary factors, one should look primarily at the annualized cost effectiveness—or the ace—which is defined as cost-per-space per year (total cost divided by number of spaces divided by the mid-point between the anticipated lower and upper repair life spans).\nOwners are also urged to look at total cost. The ace highlights the relative cost effectiveness of each option, while the total cost highlights total funding needs. Total cost often influences the political consequences of requesting funding and interacts with the anticipated likelihood of future parking demand and the current political will to fund anticipated future parking supply.\nThe Eastern garage had four options presented, with a 20- to 30-year life extension being the most cost-effective. The facility’s owner decided that additional parking demand was necessary for community growth. A demolish-and-rebuild solution was chosen: Minimal garage repairs were made to maintain safety until the facility was demolished and a new 680-space, seven-level garage was built with a construction cost of approximately $12.1 million.\nThe Western garage had three options, with a 15- to 25-year life extension being the most cost-effective. The owner chose the life extension based on its cost effectiveness and a low anticipation for future parking demand increase. The owner then proceeded with small repairs until funds became available to repair the garage in three phases. Construction costs totaled just less than $2 million.\nThe Central garage had six options presented, with a 14- to 18-year life extension being the most cost-effective. The owner chose the life extension based on its cost effectiveness, as future parking demand—while anticipated to increase—was uncertain as to the rate of growth and there was time before a new facility was needed. The garage was repaired in one phase with a construction cost totaling $1.5 million. A new 525-space, six-level garage with 20,000 square feet of retail was built several blocks away. The construction cost was $11.1 million.\nDue to the effects of inflation on pricing, the U.S. Department of Labor’s Bureau of Labor Statistics numbers were used to translate the ace pricing from each investigation into October 2012, prices. Figure 1 compares repair options with the translated ace pricing.\nFigure 2 shows the translated ace costs versus option lifespan for all three garages.\nThe following conclusions can be inferred from the table and graph:\n- The garage with the known comprehensive maintenance history had the most economical ace. The garages with apparent little maintenance history had ace that was typically two to five times as expensive for similar lifespans as the comprehensively maintained garage.\n- Shorter term repairs typically have smaller total costs but also are less cost-effective (have higher aces) in extending the lifespan of a facility.\nThere is typically an optimum repair scenario that extends the lifespan most cost-effectively.\n- New garages are typically not the most cost-effective way to continue to provide structured parking supply, but it is difficult to accurately compare costs. It’s particularly difficult to project maintenance costs throughout a new garage’s lifespan, as this will significantly change the ace for the option. There is also difficulty in direct comparison because new garages often have non-mandatory items (such as faster elevators, surveillance equipment, emergency power systems, and better durability resistance) and mandatory items (more robust earthquake resistance) that simply did not exist when these garages were built. Other non-monetary issues that may be considered important are that new garages may be politically more acceptable than repairs, because old, repaired garages often appear similar to the general public when compared to their pre-repair appearance; newer features can be added; and few people may notice the increase in annual bond payments.\nAn interesting note is that the parking efficiency—the square feet per car—(which is set at the time of construction) affects maintenance costs. The Western garage has about 12 percent more square feet per car. Since every square foot must be maintained and repaired, the facility’s costs are 12 percent higher due to is configuration based on “per space” repairs.\nThe Importance of Maintenance Plans\nParking facilities differ from most buildings because, like bridges, they are subject to weathering, large thermal cycles, and de-icing salts. To counteract these factors and cost-effectively prolong their lifespan, a carefully planned and monitored maintenance plan will minimize the total cost of ownership.\nGregory J. Neiderer, PE, is mid-Atlantic department head at Walker Restoration Consultants. He can be reached at email@example.com."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:4d9c3926-3b2b-451b-88ae-a73713ce5ed1>","<urn:uuid:9b6133db-3eb6-42b4-8561-25228921c1ab>"],"error":null}
{"question":"How do bone cement and UFG titanium implants compare in terms of their composition additives and their respective purposes?","answer":"Bone cement and UFG titanium implants use different types of additives for distinct purposes. Bone cement includes various additives such as radiopacifiers (zirconium dioxide or barium sulfate) for X-ray opacity, initiators and activators for controlling polymerization, sometimes softeners and emulsifiers, and antibiotics for infection prevention. In contrast, UFG titanium specifically avoids additives like aluminum and vanadium (which are commonly used in traditional titanium alloys for strength) while achieving superior strength through its nanometer-sized grain structure, making it a purer implant material that doesn't require additional chemical components.","context":["Methyl methacrylate (MMA) is the elemental portion of bone cements. to take advantage of it, a dough is ready from the liquid and powder via blending correct prior to software, that is regularly performed through the working workforce. in the course of its operating section the dough is then inserted into the tissue the place polymerization is done. hence, the ultimate implant polymethyl methacrylate (PMMA) is simply created on the implantation web site. along with methyl methacrylate, bone cements occasionally comprise different methacrylates, similar to butyl methacrylate. to accomplish X-ray opacity, radiopacifiers (zirconium dioxide or barium sulfate) are extra to the powder. either the liquid and powder parts include ingredients (initiator and activator) that release polymerization and keep watch over the set ting while combined jointly. furthermore, softener and emulsifiers are a few occasions used. The addition of antibiotics to the powder part so that it will hinder or deal with infections has turn into specially very important. advertisement bone cements fluctuate in composition and the process curing. a few are designed for top and others for low viscosity. the way in which the person handles and applies the cement continually crucially impacts the standard of the implant. it's because transparent and accomplished information regarding the cements will be on hand to teach the person how the entire suitable elements paintings it's going to even be attainable jointly and the way they rely on one another.\nRead or Download Bone Cements: Up-to-Date Comparison of Physical and Chemical Properties of Commercial Materials PDF\nBest Orthopedics books\nJurch’s scientific therapeutic massage is designed to stipulate the foundations and foundational knowing of assessing and treating orthopedic harm or disorder via therapeutic massage remedy. The textual content follows an anatomic sector strategy, protecting floor anatomy and muscle tissues sooner than offering a entire assessment of the main frequently proposing orthopedic dysfunctions or stipulations.\nPlastic and Reconstructive surgical procedure has been designed to supply succinct details to plastic surgeons of all degrees of expertise and trainees in accomplice specialties. The format is modern with the concise details specified by a readable sort. There are descriptions of vital operations and methods with area so as to add the reader's personal notes.\nThe prevalence of pressure fractures of the reduce extremities in the course of U. S. army easy education is considerably larger between lady army recruits than between male recruits. the superiority of this damage has a marked impression at the overall healthiness of carrier group of workers and imposes an important monetary burden at the army by means of delaying final touch of the educational of latest recruits.\nAdapted for trendy busy clinician, medical activities drugs offers hands-on info for the administration of either leisure and aggressive athletes. Over one thousand full-color medical illustrations plus a wealth of precis packing containers make it easier to receive key details fast, whereas authoritative textual content written through tested and rising gurus offers cutting-edge information on overcoming any problem within the strong point.\nExtra info for Bone Cements: Up-to-Date Comparison of Physical and Chemical Properties of Commercial Materials","November 6, 2013\nby Americo Fernandes, DMD\nUltra Fine Grain (UFG) titanium is a new improved form of the old classic Commercially Pure (CP) implantable titanium we as dentists are familiar with. It is produced through a process known as Severe Plastic Deformation. This novel patented process, positively impacts the structural strength of titanium by reducing the grain dimensions to nanometer size. As a result of this new process, physical failure of UFG titanium dental implants are expected to decline when compared to CP titanium dental implants used today. Bone cell colonization studies reveal another benefit when compared to CP titanium, higher bone cell numbers per unit area. This improvement in cell colonization can positively impact the healing process. This article describes two years of clinical observations of Ultra Fine Grain titanium, utilized for the very first time as a dental implant material in North America.\nUFG titanium was developed through a joint research effort of American and Russian scientists at Los Alamos National Laboratories and UFA Aeronautical University in Russia.1 By processing traditional Commercially Pure titanium (CP titanium) through a novel patented process known as Severe Plastic Deformation, a new UFG titanium is created.2 The effects of this process on CP titanium result in a new UFG titanium, comprising of desirable nanometer sized grains of titanium. The UFG titanium is chemically the same as CP titanium but is physically different due to the much smaller grain size. This new titanium is inherently much stronger when compared to its traditional predecessor, CP titanium because of the smaller grain size. UFG titanium’s superior properties come from the remarkable gain in strength without increasing undesirable brittleness.3 Subsequent bone cell studies have also shown that bone cells show greater numbers of colonies on the UFG titanium surface when compared to traditional CP titanium, resulting in an attachment increase between bone and implant surface.4 Bone cells attach to boundaries between titanium grains. Since UFG titanium has more boundaries between the smaller grains compared to CP titanium, an increase in bone cell colonization is expected on the UFG titanium surface. This unique characteristic appears to allow the loading of UFG dental implants into function earlier because of the greater number of bone cells. Because of UFG titanium’s superior strength, failures as a result of breakage should also decrease.5 The increase in strength is especially important when using smaller implants such as the very popular one piece minis. Some small diameter dental implants are made from titanium alloy metal in order to overcome implant breakage issues. Titanium alloy dental implants use Aluminum and Vanadium to gain an increase in physical strength. Some clinicians, if given the option, would prefer to not use implantable metals made with Aluminum and Vanadium for variety of reasons not discussed in this paper. UFG titanium does not incorporate Aluminum or Vanadium which is a definite benefit for these clinicians.\nDISCUSSION & RESULTS\nDuring the last two years, I have placed 65 UFG dental implants in a variety of locations in the mouth. I used these new implants to restore single to multiple missing teeth with traditional fixed prosthesis. During this two year period, UFG titanium dental implants and CP titanium dental implants were compared according to their unique clinical performance. I have been using traditional CP titanium dental implants for approximately 20 years and during this time, I have learned a lot about their familiar clinical performance characteristics. From my personal experiences with CP titanium dental implants, I was well prepared to sort out clinical differences between these two types of dental implants. These new UFG dental implants have been manufactured and prepared to the same exact dimensions and designs of CP titanium dental implants that I have been using for the last 20 years. Both UFG and CP titanium dental implants were manufactured by BASIC Dental Implant Systems, Inc., Albuquerque, New Mexico. Based on my clinical experience, dental implants are ready to restore when they meet the following criteria; 1) Lack of infection around the implant 2) The ability of bone to resist clockwise torque force of the implant to 40 Ncm. 3) Intimate bone to implant body surface contact as seen through traditional Periapical Radiographic examination. Depending on the patient and type of bone, an implant can be ready to restore using CP titanium within two to four months. This protocol has been a standard practice in my clinic for many years. Research has shown that a greater number of bone cells tend to colonize UFG titanium surfaces when compared to CP titanium surfaces. Because of these earlier findings, I wanted to know whether it is possible to restore UFG dental implants earlier, compared to the traditional CP dental implants I have been using for many years. An evaluation period of one to two months was chosen to assess UFG titanium implants for restoration loading instead of the typical period of two to four months for classical CP titanium implants.6 All of the patients treated with UFG titanium dental implants returned at 1 to 1.5 months from the time of surgical placement. At recall, it was quite evident that these UFG titanium dental implants are able to meet restoration criteria significantly earlier when compared to traditional CP titanium dental implants. Periapical radiographs of these novel implants generally show a greater degree of bone maturity at the implant surface when comparing to CP dental implants. Radiographic examinations of UFG dental implants typically show greater bone density at the implant body surface, which generally means more bone on the implant’s surface. The increase in bone cell colonization on UFG dental implants was expected because of the earlier research findings and my findings confirm this earlier research. UFG titanium dental implants have proven that they can indeed be loaded earlier compared to CP titanium dental implants. In my experience, torquing CP titanium dental implants to 40 Ncm, at 1 to 1.5 month periods usually results in movement of some implants, requiring additional time for adequate healing, necessary to meet criteria for restoration. Without exception, all 65 UFG dental implants were more resistant to torque forces at recall appointments much earlier compared to CP titanium dental implants. Breakage of dental implants has never been an issue to worry about when utilizing CP dental implants; therefore I have found no difference here. I have encountered very few broken dental implants in my practice during the past 20 years and I cannot report on the clinical benefits to me of UFG titanium dental implants as result of its increased strength properties. My experience utilizing so-called minimal diameter dental implants is only beginning and as such, the strength of these dental implants will most likely play an important role as I increase the use of these implants clinically. My preference is to avoid implanting dental titanium, which incorporates Aluminum and Vanadium to add strength at the expense of biological issues. A nice benefit of UFG titanium is that it significantly surpasses the strength properties of both CP and Alloyed titanium without Aluminum and Vanadium.7 To date, all UFG dental implants are in function and are recalled at six to 12 month intervals. UFG titanium dental implants have also been provided to other dentists in the USA, Taiwan, China and Russia. These clinicians report clinical observations similar to those described in this paper.\nUFG titanium dental implants offer two significant benefits when compared to traditional\nCP and Alloy titanium based dental implants. These two benefits are greater strength, without the Aluminum and Vanadium, and improved healing capability. From a clinician’s perspective, these benefits hold the promise of treating our patients faster with functioning dental implants that are less likely to break under function. This is very desirable to all dentists and patients. From my clinical observations to date, it can be said that traditional CP titanium and Alloy based dental implants can be replaced as the material of choice by UFG titanium. OH\nDr. Americo Fernandes graduated from the University of Manitoba in 1984.\nHe obtains a Private Practice with emphasis on Implant Dentistry, Winnipeg. Placing and restoring dental implants for over 25 years. President, BASIC Dental Implant Systems, Inc.\n1,2,3. Microstructures and Properties of Ultrafine-Grained Pure Titanium. Vladimir V. Stolyarov1; Yuntian T. Zhu2; Terry C. Lowe3; Ruslan Z. Valiev, Journal of Nanoscience and Nanotechnology, June 1, 2001\n4. Accelerated growth of preoblastic cells on ultrafine grain titanium, Y. Estrin, C. Kasper,S. Dietrichs and R. Lapovok. Journal of Biomedical Materials Research, 2008.\n5. Comparison of Mechanical properties of medical grade titanium. Terry Lowe, Accepted for Publication, fall 2012.\n6. Increased osteoblast adhesion on nanophase metals: Ti, Ti6AL4, and CoCrMo. Thomas J. Webster, Jeremiah U. Ejiofor, Biomaterials 25, 2004, 4731-4739.\n7. Progress in material science. M. geetha, A.K. Singh, R. Asokamani, A.K. Gogia. Elsevier Volume 54, Issue 3, May 2009, Pages 397-425"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:7f10888e-545d-46a8-a4ea-364c7303cf9f>","<urn:uuid:b1272181-1b8f-4d00-b743-714f28c2ea72>"],"error":null}
{"question":"What role do cats play in affecting bird populations both in urban areas and on islands, and how can their impact be monitored?","answer":"Feral cats are significant predators of birds, hunting both for food and recreation. In island ecosystems, they are particularly destructive to ground-nesting birds that haven't evolved defenses against these agile hunters. In urban areas like Boundary Brook, bird populations are monitored through citizen science initiatives using tools like iRecord, where visitors can report sightings and help track biodiversity. To protect birds, it's recommended to keep cats indoors and ensure they are spayed/neutered to prevent feral cat proliferation. This monitoring and management is crucial for protecting both common birds like tits and robins, as well as rarer species.","context":["Are you looking for ways to add interest to your lockdown outdoor exercise this winter? Were you inspired by the RSPB’s Big Garden Birdwatch last weekend?\nIf so, Boundary Brook is a great place to practise your bird-spotting skills. Read on to find out our rarer recent visitors, top spotting tips for birds at Boundary Brook at this time of year, and how to get help identifying birds from our resident ornithologist Nick Boyd.\nWinter is one of the most rewarding times for bird-spotting, as the trees’ bare branches help make birds much more visible than at other times of the year. Birds are busy looking for food through the colder months, and later in the season, singing for mates and scouting for nesting sites. It’s also a great opportunity to spot rarer winter visitors that migrate to the UK from Scandinavia and further afield.\nIf you haven’t done so yet, it’s not too late to put up a bird box – but be sure to clean out last year’s boxes with boiling water to remove any parasites that could harm the chicks first. If you have any boxes that you no longer use and want to donate for us to position at Boundary Brook, please get in touch.\nHelp us provide a safe home for our resident tawny owls\nWe’ve been busy preparing the site for the imminent nesting season, and have put up boxes around the site for sparrows, tits, and – most notably – tawny owls! We’re excited by several reports of tawny owls in and around the site from our neighbours in Howard Street recently, and whilst Boundary Brook is not (yet) blessed with acres of mature woodland trees, we’ve scouted out a Scots Pine that offers sufficient support for a tawny owl nest box and the horizontal branches that the chicks need to explore their surroundings and test their wings before fledging. It may be another few years until the o-wls find the woods developed enough to call home. In the meantime, we’ll be keeping our fingers crossed!\nIf you spot the large nest box alongside the butterfly glade on the Howard Street side of the site, be aware that brooding tawny owls are sensitive to disturbance, and can be aggressive, so please resist the urge to be too inquisitive.\nTawny owls are very well camouflaged in their woodland setting, so the best way to identify them is usually by the characteristic wavering ‘hoohoo’ hoot – this is the call of males looking to attract a mate, heard at dusk or after dark. The female call is a sharp ‘ke-wick’.\nOther birds of prey seen at Boundary Brook include the ubiquitous (but equally lovely) red kites soaring overhead, and also landing onsite, kestrels hovering by the allotment boundary looking for prey, and a visiting sparrowhawk – like this beautiful adult male spotted just a few days ago surveying its territory at Boundary Brook – thanks to OUWG Chair Helen for the excellent photo!\nTop tips on what to look out for at Boundary Brook this winter\nIf you keep a keen eye out onsite at the moment, in addition to the easily spotted tits, robins, blackbirds and wood pigeon, you’re more than likely to spot flocks of goldfinch feasting on the seed heads of our many teasels around the Park. The striking red, black, and white face markings and flash of gold on the wing make these birds one of the most eye-catching and easy to identify finches – a real treat. Speaking of which, teasels are an excellent winter food source for finches and other birds, and make an impressive silhouette on frosty days when little else is growing in the garden, so it’s a great idea to plant some if you have a garden to encourage birdlife at home. Greenfinch are also starting to come into song again – have a listen to their distinctive buzzy-sounding song to help you ID them.\nRedwing can also be seen in abundance at Boundary Brook at this time of year – look out for a thrush-like bird with distinctive orange-red side markings beneath the wings and a striking pale eyebrow and ‘moustache’ stripes on the face. With resident Song Thrush populations in serious decline, the redwing is a welcome addition to the thrushes at Boundary Brook. Millions of this sociable winter visitor arrive from Scandinavia each winter and stay until April – at the moment, they’re easiest to find feeding on ivy berries or lingering hawthorn berries.\nWoodpeckers also visit Boundary Brook – green woodpeckers love eating ants so are often seen on the ground, hoovering up their favourite insects. Keep a look out around the meadow where they have been seen most recently.\nGreater spotted woodpeckers have been spotted – and heard! – on the more mature trees at the Nature Park recently too. These piebald favourites will be starting to engage in their telltale loud drumming on tree trunks instead of singing to claim territory and attract mates, so keep an ear out for the unmistakeable rat-a-tat-tat next time you visit. Both males and females engage in this behaviour, but if you’re lucky enough to spot one, they can easily be told apart, as the male has a red patch on the back of his head, whereas the female’s head is black and white.\nOne or our more exotic visitors are the bright green Ring-necked parakeets that escaped captivity to become our only naturalised parrot. They have a red beak and a pink and black ring around the face and neck, and can be noisy, so keep your eyes and ears peeled. Numbers of these non-native species are spreading fast in Oxford and elsewhere, and it’s thought that they could have negative impacts on woodpeckers and other native species, so it’s important that we monitor their numbers closely.\nGoldcrest, along with the firecrest, is the UK’s smallest bird, so you’ll need an eagle-eye to spot them, but they are to be found flitting around the conifer trees at Boundary Brook. Their dull greyish-green plumage and pale belly are not particularly distinctive – it’s the Mohican-like flash of a narrow black and yellow stripe on their heads that’s the best sign of this fabulously rewarding little species. Time to invest in a good pair of binoculars!\nFor the more serious twitchers (we know you’re out there!), there will be spotters’ badges awarded for all who spot the rarer and more elusive Siskin that we’ve seen enjoying the cone seeds high up in the top of the alder trees near the kidney pond over the winter. Males are easier to identify with their bright yellow breast and cheeks, and a black cap, while females are a drabber pale yellow.\nRedpoll have also been seen around the birches bordering the butterfly glade and allotments at the far end of the North Wood side of the site. These small brown and white finches can be identified by their small red forehead patch, black feathering around a yellow bill, and two white wingbars. Males have a pale red vest on the chest and upper flanks. Only a few hundred redpoll are recorded each year in the UK, so its important that we keep track of the population at Boundary Brook.\nBecome a citizen scientist and help us protect birds at Boundary Brook\nYou’ve probably noticed the whiteboard by the shed at the entrance to the Park where visitors can record their wildlife sightings onsite. This is a great way to let us know some of the rarer wildlife you’ve seen and help us keep track of the site’s biodiversity – but it’s not so easy to capture all that invaluable data that our members record …\n… Which is why OUWG is moving into the 21st century and launching Boundary Brook Nature Park on iRecord, the Biological Records Centre’s (BRC) online tool for recording wildlife! You can share your sightings of birds and other wildlife through the iRecord website, and the iRecord App let’s you record what you see while you’re onsite. You can upload photos, and experts will review and validate any sightings you’re unsure of.\nWhy use iRecord?\nBy sharing records in one place, you can be a citizen scientist, contributing to evidence-based decisions about how to develop and manage Boundary Brook. This will help with future fundraising and other efforts to secure the Park’s long-term future, and the results will also efforts feed into county-wide efforts to maximize biodiversity and wildlife conservation.\nHow do I use iRecord?\nDownload the iRecord App, register, and start adding records with the ‘+’ button, and entering the Location as ‘Boundary Brook Nature Park’. You can enter multiple records to the same location by pressing and holding the ‘+’ button and choosing General Survey to record your sightings. Video guides to downloading and using iRecord are on the TVERC website, and there’s a getting started guide.\nIf you don’t have a smart phone, please do continue to write your sightings and the date on the whiteboard onsite and we’ll add those to iRecord too.\nOur resident ornithologist Nick Boyd has been helping us spot and identify these rarer species, and is happy to help with bird identification if you’re not sure of what you’ve seen. If you snap a photo or record some audio of birdsong and email it to us, Nick will more than likely be able to pinpoint your bird, or you can just send in a description and he’ll let you know what the likely species suspects are.\nIn our bird surveys this winter, we’ve currently confirmed 29 species visiting the site since last year – take a look at the list below:\n|Common name (English)||Scientific name (Latin)|\n|Red kite||Milvus milvus|\n|Wood pigeon||Columba palumbus|\n|Collared dove||Streptopelia decaocto|\n|Tawny owl||Strix aluco|\n|Green woodpecker||Picus viridis|\n|Great spotted woodpecker||Dendrocopos major|\n|Carrion crow||Corvus (cornix) corone|\n|Blue tit||Cyanistes caeruleus|\n|Great tit||Parus major|\n|House martin||Delichon urbicum|\n|Long-tailed tit||Aegithalos caudatus|\n|Song thrush||Turdus philomelos|\n|House sparrow||Passer domesticus|\n|(Lesser) Redpoll||Acanthis cabaret|\nIt’s an impressive indication of the diversity of species benefiting from Boundary Brook, but we expect there are another 10-15 species that we should be able to identify onsite over the next year.\nIf you spot a bird onsite that’s not on the above list (birds flying over the site can’t be counted, unfortunately!), please do help us reach our target of 40+ confirmed species by letting us know – ideally with a photo for Nick to verify the sighting.\nNick has drawn up a target list of species that are likely to visit the kind of habitat that Boundary Brook offers below, so keep in mind these likely suspects the next time you visit:\n- Fieldfare – listen for their “chuh-chuh-chuck” call\n- Starling – common enough to surely visit the site, but no confirmed sightings recently – check treetops, or for feeding birds on the Hay Meadow\n- Jackdaw – commonly heard flying over; check treetops\n- Pied wagtail – probably pops into the Hay Meadow to feed sporadically\n- Jay – look out for the bright white rump above a black tail as it flies off and listen out for this harsh screeching\n- Treecreeper – climbing tree trunks; might be joining mixed tit/goldcrest flocks passing through\n- Feral pigeon (rock dove) – obviously not a native (or popular!) species to Oxfordshire but very much a part of our wild ecosystem now. [NB if you see a largish grey pigeon without woodpigeon’s big white neck patch it could be feral pigeon, stock dove, or a young wood pigeon, ideally get a photo]\nSo please do make Boundary Brook part of your regular lockdown exercise, keep your eyes to the skies and ears peeled, and take part in some invaluable citizen science with iRecord in the process.","From remote islands to our own backyards, invasive species threaten native plants and wildlife. These are 10 of the most unwanted and threatening invasive species throughout the world.\n1. Yellow Crazy Ants\nYellow Crazy Ants, believed to be native to West Africa, have been dispersed by human transportation systems to remote islands around the world, where their unique adaptations put native species at risk. The Yellow Crazy Ant does not bite or sting, but instead secretes formic acid to subdue its prey. On Christmas Island in the Indian Ocean, Yellow Crazy Ants have created supercolonies and decimated the native Red Land Crab population. Researchers are concerned that endangered species such as the Abbott’s Booby (Sula abbotti) could be at risk of extinction on the island if the Crazy Ant population persists.\n2. Brown Tree Snakes\nThe Brown Tree Snake was introduced to Guam shortly after World War II and since then has drastically altered the island ecosystem. Predation by this invasive snake has led to the local extinction of native lizards and six forest birds. Researchers are also concerned about cascading ecological effects leading to a decline in native plant species.\n3. Feral Cats\nThe domestication of cats has dispersed felines around the world. Those that do not become pets end up in ecosystems where they interact with species that did not evolve to defend against these agile hunters. Feral cats are known to hunt not only for food but also for fun, which poses a problem for island birds and other native species that have evolved to nest on the ground. Feral cats also do considerable damage in our own backyards. Keeping your pets inside is the only way to ensure they will not harm or kill native wildlife. For cats that are allowed outdoors, spaying and neutering are strongly encouraged to prevent proliferation of feral cats in the wild.\n4. House Mice\nSmall and seemingly inconsequential at first glance, house mice are one of the greatest threats to island species around the world. Midway Atoll, an island chain in the Southwest Pacific, is home to one of the largest breeding colonies of Albatross in the world, but house mice threaten these species. Predation on eggs, chicks, and even adults has led to drastic declines in Black-footed Albatross and Short-tailed Albatross. The House Mouse is quick to adapt to new surroundings and environments, which makes it particularly adept as an introduced species and often leads to invasion.\nRats are known for their ability to swim ashore to islands from ships, and when they’re not swimming onto shore, they’re simply walking onto the gangway and entering an ecosystem never designed to accommodate the voracious predator. The species is well known for its incredible adaptability and resourcefulness. On islands, invasive rats can and do lead to the catastrophic decline of native seabirds and other island wildlife.\nLionfish are native to the South Pacific and Indian Oceans, but with their introduction into the waters of the Southeastern United States in the mid-1980s they have become one of the most harmful aquatic invasive species. Popular in the pet trade, they are found in home aquariums throughout the world. Release into the wild has had disastrous consequences for native marine species. Lionfish are known to eat over 50 different species of fish, including economically and ecologically important species. Now conservation efforts are under way and people are encouraged to fish and eat the species to suppress the invasive population.\nMacaques are invasive on islands throughout Puerto Rico where wild, feral populations pose a threat to human health, livelihoods, and native species. Wild Macaques are known carriers of the Herpes B Virus and estimates suggest 70% of wild individuals carry the virus and have the potential for human transfer.\n8. Cane Toads\nOften intentionally introduced as a biological control agent, Cane Toads have become one of the most damaging invasive species in the world. Their toxic secretions make them unappealing to most predators and their rapid reproduction allows them to over-populate and out-compete native amphibians.\nGoats are quick to adapt to new environments and can devour vegetation at alarming rates. When they make their way to sensitive ecosystems, they can easily alter plant communities and create niche space for hardier invasive plants to proliferate in. On islands, feral goats pose a particular threat to specially adapted native vegetation as well as other native herbivores that rely on this vegetation for food. In the case of Redonda island, invasive feral goats depleted all vegetation and began to starve as a result.\nMongoose were often introduced on islands as a biological control to mitigate the effects of invasive predators such as rats and snakes. Ultimately, this tactic proved disastrous. Mongoose have wiped out several species on islands around the world. Mongoose are also known carriers of human and animal diseases such as rabies.\n- The Invasive Rose-ringed Parakeet – a Threat from Hawai’i to Spain - May 24, 2018\n- Birds and Insects Perking up on Antipodes Island after Restoration Project - May 24, 2018\n- Biodiversity: What is it and Why Does it Matter? - May 17, 2018\n- Palmyra Atoll – A Hope Spot for the World’s Oceans - April 27, 2018\n- Scientists Study Vocalizations of Thriving, Wild ‘Alalā - April 20, 2018\n- Conservation and the Future of Kaho’olawe - March 28, 2018\n- The Restoration of Kaho’olawe - March 23, 2018\n- Cultural Connections of Kaho’olawe - March 22, 2018\n- Sailor’s Hat – A Mark of Destruction on Kaho’olawe - March 16, 2018\n- The Danger of Kaho’olawe - March 13, 2018"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:1ee5fe8d-fb26-4a47-a4be-4c4e84fcd4c7>","<urn:uuid:36f6cdac-221a-49ce-80c6-914304709d1e>"],"error":null}
{"question":"What's the link between screen time and stress in teens, and how much time do they actually spend on screens these days?","answer":"Current estimates show that 8-18 year-olds spend more than 7 hours using screens daily, with US teens specifically using media for up to 9 hours a day. About 94% of teens with mobile devices are online daily, with many online constantly. Regarding stress, 54% of teens are reported to be stressed according to parents, with 58% of teens turning to screens for stress relief. However, screen use can actually contribute to stress through various mechanisms like cyberbullying (affecting 23% of teens, especially girls), 'Facebook depression', and sleep disruption from late-night screen use.","context":["New tools, old rules: limit screen-based recreational media at home\nAmerican Heart Association Scientific Advisory\n- Screen time from computers, phones, tablet computers, video games, TV and other screen-based devices is associated with increased sedentary behavior in children and teens. Sedentary behaviors contribute to overweight and obesity.\n- TV viewing has decreased among young people, but overall screen media consumption has increased substantially in this age group.\nEmbargoed until 4 a.m. CT / 5 a.m. ET Mon., Aug. 6. 2018\nDALLAS, Aug. 6, 2018 — Screen time from computers, phones, tablet computers, video games, TV and other screen-based devices is associated with an increased amount of sedentary behavior in children and teens, according to a new scientific statement released by the American Heart Association and published in its journal Circulation.\nSedentary behaviors include sitting, reclining or laying down while awake -- activities which exert little physical energy – and contribute to overweight and obesity in children and teens.\nAmerican Heart Association scientific statements are developed by a panel of experts who review existing scientific literature and evidence to provide an overview of a topic related to cardiovascular disease or stroke. In this review, the writing group found that the available scientific literature is based almost entirely on self-reported screen time, with very few breaking down the type of device or the context in which it is used, which means that the studies are not designed to prove cause and effect.\nThe writing group determined that over the last twenty years, TV viewing by children and adolescents has declined but the recreational use of other screen-based devices, such as smart phones, tablet computers and others has resulted in a net increase in screen time overall. Current estimates are that 8- to 18-year-olds spend more than 7 hours using screens daily.\n“Still, the available evidence is not encouraging: overall screen time seems to be increasing -- if portable devices are allowing for more mobility, this has not reduced overall sedentary time nor risk of obesity,” according to Tracie A. Barnett, Ph.D., a researcher at the INRS-Institut Armand Frappier and Sainte-Justine University Hospital Research Center, in Montreal, Canada, and the chair of the writing group.\n“Although the mechanisms linking screen time to obesity are not entirely clear, there are real concerns that screens influence eating behaviors, possibly because children ‘tune out’ and don’t notice when they are full when eating in front of a screen. There is also evidence that screens are disrupting sleep quality, which can also increase the risk of obesity,” Barnett said.\nThe message to parents and children is to take steps to limit screen time. “We want to reinforce the American Heart Association’s long-standing recommendation for children and teens to get no more than 1-2 hours of recreational screen time daily. Given that most youth already far exceed these limits, it is especially important for parents to be vigilant about their child’s screen time, including phones.” Barnett said.\nRecommended interventions to minimize screen time emphasize the importance of involving parents. Parents can help their children reduce screen time by setting a good example with their own screen use and by establishing screen time regulations.\n“Ideally, screen-based devices should not be in bedrooms, especially because some studies have found that having screen-based devices in the bedroom can affect sleep. Maximize face-to-face interactions and time outdoors,” Barnett said. “In essence: Sit less; play more.”\nAccording to Barnett, more research is needed because the patterns of screen-based media use and their long-term effects on children and teens are not yet known. In addition, the authors report that not much is known about how to help youth be less sedentary and the appeal of screens is making this an even greater challenge. Future research should focus on how to achieve greater balance. Detailed information on the overall impact of today’s sedentary pursuits – especially with respect to screen-based devices – is needed, Barnett said.\nCo-authors are Aaron S. Kelly, Ph.D.; Deborah R. Young, Ph.D.; Cynthia K. Perry, Ph.D.; Charlotte A. Pratt, Ph.D., M.S., R.D.; Nicholas Edwards, M.D., M.P.H.; Goutham Rao, M.D.; and Miram Vos, M.D. M.S.P.H. Author disclosures are on the manuscript.\n- Available multimedia located on the right column of the release link: https://newsroom.heart.org/news/new-tools-old-rules-limit-screen-based-recreational-media-at-home?preview=87a5e3aab8bce40e6d75402c589eac9b\n- After Aug. 6, 2018, view the manuscript online.\n- Healthy Kids\n- Follow AHA/ASA news on Twitter @HeartNews\nThe American Heart Association/American Stroke Association receives funding mostly from individuals. Foundations and corporations donate as well, and fund specific programs and events. Strict policies are enforced to prevent these relationships from influencing the association’s science content. Financial information for the American Heart Association, including a list of contributions from pharmaceutical and device manufacturers and health insurance providers are available at www.heart.org/corporatefunding.\nAbout the American Heart Association\nThe American Heart Association is devoted to saving people from heart disease and stroke – the two leading causes of death in the world. We team with millions of volunteers to fund innovative research, fight for stronger public health policies, and provide lifesaving tools and information to prevent and treat these diseases. The Dallas-based association is the nation’s oldest and largest voluntary organization dedicated to fighting heart disease and stroke. To learn more or to get involved, call 1-800-AHA-USA1, visit heart.org or call any of our offices around the country. Follow us on Facebook and Twitter.\nFor Media Inquiries: 214-706-1173\nDarcy Spitz: 212-878-5940; Darcy.Spitz@heart.org\nFor Public Inquiries: 1-800-AHA-USA1 (242-8721)","Hansa Bhargava MD FAAP\nStaff Physician, Children's Healthcare of Atlanta\nMedical Editor, WebMD\nPediatricians are seeing more and more teens suffering from stress. Whether they are complaining of it or having somatic symptoms such as headaches and stomach aches, it seems that stress and anxiety are on the rise. We know that over scheduling, homework, and the pressures of getting into college can contribute to this. But can media also affect it? Is screen time and media a stressor or a remedy for stress?\nIn a recent WebMD survey published in their Teens and Stress report, 54% of teens were stressed according to parents. Interestingly, 40% of parents turned to the screen for family stress relief while 58% of teens did. Social media and texting was used as stress relief by almost half the teens. This is on the heels of the Common Sense Media survey reporting that US teens were using media for 9 hours a day. Other recent reports have shown that 94% of teens with mobile devices are online daily with many online constantly.\nSo it seems that stress is on the rise and media use is on the rise. Although there may not be a direct relationship, some real issues impact stress and anxiety. Consider this: 23 % of teens report cyberbullying, especially girls. There have been reports of “Facebook depression” and loneliness, as kids who aren’t in social media conversations may feel left out. Other negative consequences can also have an impact: many teens are in front of a screen late at night or ‘sleep text’, both of which can contribute to lack of sleep, which in turn can decrease focus and potentially cause irritability and depression. And last but certainly not least, what about the time media consumes?\nTime spent on media is time often not spent communicating with family. Lately, when I’ve gone into a restaurant, I’ve observed that as soon as a family sits down, everyone pulls out a mobile device. No one is really talking. So even the short amount of time not doing homework, playing soccer, or at school is being compromised. Psychologists, community leaders and experts have long reported that family time can contribute to less depression, less anxiety, better academic performance and generally happier kids. But what if that family time is on media??\nAs the AAP reviews our screen time recommendations, I feel that we, as pediatricians should continue to advise parents about basic principles.\nParents need to lay down some parameters about when and how media is used. Media is a centerpiece of teens’ lives and is not going away, but just as we don’t give our kids a set of keys to our car and say “just drive”, we need to enforce appropriate media use. And good modeling is also critical: parents need to put down their mobile devices and simply communicate with their kids. Old fashioned parenting and just talking to your kids can build the foundation to a less stressful childhood and hopefully a happier life."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:4da89069-c646-4037-9659-d799799f22db>","<urn:uuid:9ee5a44c-ac0e-4471-bc2a-f3b31e423c46>"],"error":null}
{"question":"Which musical instruments did William Grant Still learn to play by himself? Amazing!","answer":"William Grant Still taught himself to play the clarinet, saxophone, oboe, bass, cello and viola. He also learned to play the violin through formal training, which he began at age 15.","context":["performed by Neeme Järvi and the Detroit Symphony Orchestra\n(cover image by Kent Henderson)\nGeorge Gershwin won’t make it into the series, he has plenty of fame already. For a genius jazzy symphony, here’s something you should give an ear to.\nLater to be known as “the dean of African-American composers,” William Grant Still was born on May 11, 1895 in Woodville, Mississippi. Both his parents were teachers, but his father also worked as a bandleader and was part owner in a grocery store. He passed away when his son was only three months old.\nAs a result, Mrs. Still moved from Mississippi to Little Rock, Arkansas. She continued teaching there, and remarried. Her new husband, Charles B. Shepperson, nurtured the young boy’s interest in music by taking him to operettas and buying him records.\nStill grew up in Little Rock, and it was here that he began his formal musical training, beginning with the violin at age 15. In addition, he taught himself to play the clarinet, saxophone, oboe, bass, cello and viola. Ambitious young man for sure.\nHe actually began his studies in medicine, pursuing a degree at Wilberforce in Ohio, but eventually decided to focus on music. He earned a scholarship to Oberlin, where he studied with people like George Whitfield Chadwick, and later with Edgard Varèse, of all people.\nInstead of talking about his career path, I’d like even more to talk about the remarkable number of firsts that Still racked up in his career, either as an American composer, an African American conductor, or any combination of those.\nIn 1936, he was the first African American to conduct a major American orchestra, taking the podium with the L. A. Philharmonic. In 1955, he was the first African American conductor to lead an orchestra in the Deep South, with the New Orleans Philharmonic. His works were performed not only in America, but also by such renowned institutions as the Berlin Philharmonic, London Symphony, and the Tokyo Philharmonic. He was also the first American composer to have an opera produced by the New York City Opera. His first symphony was the first work by an African American composer to be performed by a leading orchestra, and “until the 1950s,” says Wikipedia, was “the most widely performed symphony composed by an American,” citing a biography of the composer by Dr. Edith Borroff. He was also the first African American to have an opera performed on national television.\nWow. (On a side note, as this article mentions, the first African-American conductor ever to conduct the Berlin Philharmonic was Rudolph Dunbar, who did so in 1945 with a performance of Still’s first symphony, the first performance of the work in that city, likely in the whole country. It may also have been the European premiere, but I can’ be sure.\nEach of the four movements has poems from poet Paul Laurence Dunbar and subtitles from the composer given to it, and I won’t reproduce them here. They can be found in this section of the Wikipedia article.\nThe symphony begins unmistakably jazz-like. After a few long notes, maybe reminding us of Dvorak, the background color afforded by the orchestra when they enter sets the music awash in shades of jazzy blues. As if we hadn’t already gotten the message, a muted trumpet picks up this bluesy melody, and the symphony is underway. It’s sensual and rich and irresistible. Not only does Still know how to write a blues progression and sumptuous harmonies, he also has an impeccable feel for orchestration and texture.\nAside from this perfectly iconic blues sound, which Still handles easily as well as his fellow jazzy countryman Gershwin, there’s also a sense of longing in the first movement in certain passages, and the subtitle for this movement was indeed ‘Longing.’ The development is enticing and really goes somewhere, but comes back around for a cool, smooth close.\nThe second movement, marked adagio, feels rather like a continuation of some of the softer, richer passages of the first movement, that ‘languishing in the summer heat on a night in the South’ kind of sound. It’s also maybe a little bit like film music, in that it seems almost background, building a large, warm backdrop for a few brief solo passages, from double reed, a brief solo violin, clarinet. It’s clearly related to the first movement, and only after some of these more intimate utterances does the whole orchestra give us a few phrases. It’s overall the least convincing of the four movements, still nice, but feels more like echoes of the first movement, leading us into the ‘animato’ third movement.\nAfter the lush languor of the second, the instant change of atmosphere is welcome. It’s not a scherzo, but has bounce, and crunch, and some very satisfying roars from brass, almost parade-like in places. It’s the shortest of this symphony, at only about three minutes. It doesn’t go wild, but reaches the kind of conclusion that an average listener may mistakenly think is the place we should start clapping. But it isn’t.\nThe finale is the longest movement of the work, and opens with a sweeping, epic gesture that sets an entirely different, serious mood for what we’ve heard. It’s a big tune, but more than just pretty harmonies; this seems to carry some (more) weight. Flute lightens the mood, recalling material from the first movement, but I do feel almost as if we were kind of drawn into this work, seduced even, by the first three movements, and only now does the real heart of the piece come through. It’s a bit darker; there’s more tension, and Still marked this movement ‘lento, con risoluzione,’ with resoluteness (?), and we can hear it.\nBut it doesn’t go out on a melancholy note. The final section (coda?) of this movement, rounding out the symphony, is lively, colorful, and masterfully handled, up to the triumphant, quite epic ending. Still gives us an apparently straightforward symphony, something very easy to listen to, but it continues to show layer after layer of harmony and color, all the way up to its surprisingly stern ending.\nThere’s an Americanness about this symphony that stems unmistakably from the sounds of jazz and imagery of early 20th century America, something refreshingly devoid of references to war. Even with its more melancholy moments, there’s an overall welcoming sense of carefreeness to this symphony, a traditional, legitimate four-movement form, but also sumptuously melodic and easy to listen to.\nThis is just one example of American composers drawing from their surroundings, as we saw last week with Charles Ives and his folk tunes, or Amy Beach drawing from her (not really American) heritage with the Gaelic symphony. Jazz is a big part of American music, and was especially so in the ’30s. We’ll continue to see this drawing from different aspects of American identity, but Still’s symphony is undeniably the jazziest in our lineup. I’ve purchased his other four symphonies, although I hear that this might be his best. We’ll see.\nDo stay tuned for much more American music, and thank you for reading."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:20d437d9-b0e6-43e3-a9e8-8554d7855b7e>"],"error":null}
{"question":"What are the power reserve specifications of the Audemars Piguet Royal Oak Offshore Grand Prix compared to the Jacob & Co. Astronomia Solar Planet?","answer":"The Audemars Piguet Royal Oak Offshore Grand Prix features up to 60-hour power reserve, while the Jacob & Co. Astronomia Solar Planet has a shorter power reserve of 48 hours.","context":["Audemars Piguet have today revealed the latest additions to the iconic Royal Oak Offshore series at the SIHH Geneva. The Royal Oak Offshore Grand Prix Collection represents the manufacture's dexterity in working with forged carbon and ceramic as base material for the watches, and the collection comprises three limited edition models which offer an all-carbon option (1750 pieces) as well as variations with rose gold (650) and platinum (75) detail. Forged carbon is exclusively used by Audemars Piguet and it is they who have developed all aspects of working with the material, from the manufacturing procedures through to the tooling required. The resulting pieces are therefore very light, extremely durable and, in keeping the Royal Oak Offshore family philosophy, distinctive watches.\nEach model in the Grand Prix Collection features details unique to this edition and all draw their styling from various elements otherwise associated with Grand Prix race cars, but across the collection you will find references to air intakes, ventilated brake discs, gear ratios, instumentation, wheel rims and even aerodynamic cues. This detailing makes the collection a little different in that it offers the collector more than a revision of existing case/crown/pusher and dial combinations, with many features not seen on any other Royal Oak Offshore model.\nAs is the expectation from Audemars Piguet, the degree of finishing and attention to the most miniscule detail on these watches is truly incredible - and will no doubt help the manufacture account for the as yet unannounced prices.\nPowered by the tried and tested 3126/3840 selfwinding chronograph movement and housed in a 44mm case, the Audemars Piguet Royal Oak Offshore Grand Prix Collection is sure to become a talking point on the watch forums in the coming days, weeks and months.\nForged carbon case, forged carbon and black ceramic bezel, blackened titanium crown, black ceramic and titanium pushpieces, titanium pushpiece guards, titanium exhibition case-back fitted with a sapphire crystal.\nLimited edition of 1750\n18-carat pink gold case, forged carbon and black ceramic bezel, pink gold crown, black ceramic and pink gold pushpieces, carbon pushpiece guards, pink gold exhibition case-back fitted with a sapphire crystal.\nLimited edition of 650\n950 platinum, forged carbon and black ceramic bezel, white gold crown, black ceramic and white gold pushpieces, carbon pushpiece guards, platinum exhibition case-back fitted with a sapphire crystal.\nLimited edition of 75\nTechnical specification (Courtesy of Audemars Piguet):\nMovement Calibre: 3126/3840 selfwinding Total diameter: 29.94 mm (131/4 lignes) Casing diameter: 26 mm Thickness: 7.16 mm 59 jewels 365 parts Up to 60-hour power reserve Cadence of the balance: 21,600 vibrations per hour Variable-inertia balance with eight inertia-blocks and flat balance-spring Geneva-type mobile balance-spring stud-holder Three-position winding crown Finishing: all parts meticulously decorated; mainplate circular-grained; bridges rhodium-plated, chamfered, snailed and adorned with a Côtes de Genève motif. Diamond-polished jewel sinks; wheels featuring chamfered arms and diamond-polished sinks, chamfered screw slots 22-carat gold oscillating weight partially blackened and decorated with two scoops Cases Diameter: 44 mm Thickness: 15.65 mm Case-back engraved with the inscription Royal Oak Offshore Grand Prix – Limited Edition Water resistance: 100 m\nDials Black with central red negative-printed exclusive “Méga Tapisserie” motif in eloxed aluminium, anthracite small seconds counter (at 12 o’clock), silvered and yellow 30-minute counter (at 9 o‘clock), silvered and black 12-hour counter (at 6 o’clock), yellow eloxed aluminium flange\nAnthracite with central black negative-printed exclusive “Méga Tapisserie” motif in eloxed aluminium, anthracite small seconds counter (at 12 o’clock), silvered and yellow 30-minute counter (at 9 o‘clock), silvered and black 12-hour counter (at 6 o’clock), black eloxed aluminium flange\nBlack with central blue negative-printed exclusive “Méga Tapisserie” motif in eloxed aluminium, anthracite small seconds counter (at 12 o’clock), black and red 30-minute counter (at 9 o‘clock), silvered and black 12-hour counter (at 6 o’clock), silvered aluminium flange\nWhite gold hour-markers with luminescent coating\nOpenworked and luminescent hour and minute hands in white or pink gold Straps Black calfskin and alcantara, hand-sewn with alcantara inserts and edges, pin buckle in beadblasted titanium, or 18-carat pink gold or 950 platinum. Functions Hours and minutes Small seconds Chronograph with central seconds hand, 30-minute and 12-hour counters Flange with tachometric scale Date","After 2 years of development, Jacob & Co. launched the astronomer solar energy at Baselworld, which features the eight planets of the solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus and Neptune.\nJacob & Co. pushed the experience of astronomy into the 44.5mm case: Astronomia Solar, the 34.55mm diameter movement and 439 components move in constant bidirectional rotation and represent the solar system, further enhancing the realism of celestial bodies.\nThe first arm supports the hour and minute hands made of sapphire, which rotates counterclockwise to ensure that the 12 o’clock is always in the correct position, regardless of where the sub-dial is, thanks to the patented differential system.\nThe second arm holds two shafts (10 minutes / 60 seconds) gravity flying tourbillon, and its cage is decorated with the Jacob & Co. logo.\nThe third hand holds a hand-shaped globe engraved with the earth, which rotates on its own axis in 60 seconds, and completes a complete rotation of the dial in 10 minutes.\nThe two-way movement rotates in a clockwise direction, and it takes only ten minutes to complete a full 360-degree rotation. The Tanglin base rotates in the opposite direction at exactly the same speed, thus forming an accelerated, stylized view of the solar system.\nThe idea behind the Jacob & Co. Astronomy series has always been to highlight the position of the earth in the solar system in an interesting environment suitable for gem setting. Create a zero-gravity effect. After all, this is the basis of our time concept. In astronomical solar energy, all eight planets in the solar system occupy a place on the dial for the first time, and the sun is centered in the form of a 1.5 carat citrine with unmistakable JacobCut® and its 288 facets.\nThe hand-engraved globe rotates on its own axis every 60 seconds and completes a complete rotation of the dial within 10 minutes. As part of the assembly, the case also houses an auxiliary hour and minute dial and a one-minute flying tourbillon.\nThe new internal movement makes possible a reduced case size, new functions and faster rotation speed. The manual winding Jacob & Co. movement JCAM19 has a beating frequency of 4 Hz (28,800 vibrations per hour), which is faster than any other astronomical model.\nAlthough the diameter is small, only 34.55mm, it actually contains 447 components, excluding gems and semi-precious stones, which is more than other astronomical models.\nThe new astronomical solar energy continues the astronomical tradition of abstract descriptions of the universe, combining high-end Swiss watchmaking with Jacob Arable’s sourcing skills and his innovation in cutting the best gemstones, literally and vividly Expanded the horizon. fake watches perfect\nTECHNICAL SPECIFICATIONS Collection:\nModel: ASTRONOMIA SOLAR Planet Gravitational Tourbillon\nCase Diameter: 44.5mm\nMaterial: 18-carat rose gold\nCase back: 18-carat rose gold\nCase middle: single-piece sapphire crystal\nBows: Winding and time-setting via two 18-carat rose gold bows\nCrystal: Unique domed sapphire with double anti-reflective treatment\nWater resistance: 30 metres Movement Exclusive Manufacture\nCaliber: Jacob & Co. in-house manually-wound calibre JCAM19\nDiameter: 34.55mm Height: 16.50mm (11.70mm excluding garnet)\nComponents: 447 excluding the precious stones Power Reserve: 48 hours Frequency: 28,800 v/h (4 Hz)\nHours and minutes on subsidiary dial\n60-seconds flying tourbillon bi-axial\n60-seconds rotating Earth\nBi-directional movement rotating clockwise 360 degrees in 10 minutes while the aventurine base rotates counter-clockwise 360 degrees in 10 minutes Dial and hands\nDial: Sapphire crystal with rose-gold metallization Hands: Gun Blue Strap and clasp\nStrap: Crocodile leather Buckle: 18-carat rose gold folding clasp"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:cca1bf2f-2f44-43b6-85e6-a5c59049dea1>","<urn:uuid:7661edac-8862-4054-8f19-2b1b8458984b>"],"error":null}
{"question":"Hello! Between the Cronut™ pastry and mille feuille, which one needs more butter in recipe? Please give amounts for compare.","answer":"The Cronut™ pastry requires a total of 26 tablespoons (363 grams) of butter - 8 tablespoons in the dough and 18 tablespoons in the butter block. The mille feuille's rough puff pastry uses a total of 250 grams of butter - 50g cubed butter mixed into the dough and 200g grated frozen butter added during folding. Therefore, the Cronut™ pastry requires more butter, using approximately 113 grams more than the mille feuille pastry.","context":["I love making this recipe . . . because—what can I say?—it changed the world. This is a version designed for the home cook.\nSkill Level Advanced\nTime 1 hour two days before; 1 hour one day before; 2 hours the day of\nYield 12 At-Home CronutTM pastries\nGanache of your choice 1 batch 1 batch\n(pages 205 to 207)\nFlavoured sugar of your choice\nGlaze of your choice (page 208)\nAt-home CronutTM pastry Dough\nStrong flour 3¾ cups, plus 525 grams, plus\nmore as needed\nKosher salt 1 tablespoon + 6 grams\nGranulated sugar ¼ cup + 64 grams\nInstant yeast (preferably SAF 1 tablespoon + 11 grams\nGold Label)* 1½ teaspoons\nWater, cold 1 cup + 250 grams\nEgg white (large) 1 each 1 each (30 grams)\nUnsalted butter (84% butterfat), 8 tablespoons 112 grams\nPouring cream (35% milk fat) 1 tablespoon 15 grams\nCooking oil spray as needed as needed\nUnsalted butter (84% butterfat), 18 tablespoons 251 grams\nGrapeseed oil as needed as needed\nGlaze of your choice (page 208) as needed as needed\nDecorating sugar of your choice as needed as needed\nTwo Days Before\nPrepare one of the ganache recipes on pages 205 to 207 and refrigerate until needed.\nMake at-home Cronut™ pastry Dough\nCombine the strong flour, salt, sugar, yeast, water, egg whites, butter and cream in a stand mixer fitted with a dough hook. Mix until just combined, about 3 minutes. When finished the dough will be rough and have very little gluten development.\nLightly grease a medium bowl with cooking oil spray. Transfer the dough to the bowl. Cover with plastic wrap pressed directly on the surface of the dough, to prevent a skin from forming. Proof the dough in a warm spot until doubled in size, 2 to 3 hours.\nRemove the plastic wrap and punch down the dough by folding the edges into the centre, releasing as much of the gas as possible. On a piece of baking paper, shape into a 10-inch (25 cm) square. Transfer to a baking tray, still on the baking paper, and cover with plastic wrap. Refrigerate overnight.\nMake Butter Block\nDraw a 7-inch (18 cm) square on a piece of baking paper with a pencil. Flip the paper over so that the butter won’t come in contact with the pencil marks. Place the butter in the centre of the square and spread it evenly with an offset spatula to fill the square. Refrigerate overnight.\nOne Day Before\nRemove the butter from the refrigerator. It should still be soft enough to bend slightly without cracking. If it is still too firm, lightly beat it with a rolling pin on a lightly floured work surface until it becomes pliable. Make sure to press the butter back to its original 7-inch (18 cm) square after working it.\nRemove the dough from the refrigerator, making sure it is very cold throughout. Place the dough on a floured work surface. Using the rolling pin, roll out the dough to a 10-inch (25.5 cm) square about 1 inch (2.5 cm) thick.\nArrange the butter block in the centre of the dough so it looks like a diamond in the centre of the square (rotated 45 degrees, with the corners of the butter block facing the centre of the dough sides). Pull the corners of the dough up and over to the centre of the butter block. Pinch the seams of dough together to seal the butter inside. You should have a square slightly larger than the butter block.\nVery lightly dust the work surface with flour to ensure the dough doesn’t stick. With a rolling pin, using steady, even pressure, roll out the dough from the centre. When finished, you should have a 20-inch (50 cm) square about ¼ inch (6 mm) thick.*\nFold the dough in half horizontally, making sure to line up the edges so you are left with a rectangle. Then fold the dough vertically. You should have a 10-inch (25.5 cm) square of dough with 4 layers. Wrap tightly in plastic wrap and refrigerate for 1 hour.\nRepeat steps 3 and 4. Cover tightly with plastic wrap and refrigerate overnight.\nThe Day of\nOn a lightly floured work surface, roll out the dough to a 15-inch (40 cm) square about ½ inch (1.3 cm) thick. Transfer the dough to a half baking tray, cover with plastic wrap, and refrigerate for 1 hour to relax.\nUsing a 3½-inch (9 cm) ring cutter, cut 12 rounds. Cut out the centre of each round with a 1-inch (2.5 cm) ring cutter to create the doughnut shape.\nLine a baking tray with baling paper and lightly dust the paper with flour. Place the At-Home CronutTM pastries on the tray, spacing them about 3 inches (8 cm) apart. Lightly spray a piece of plastic wrap with cooking oil spray and lay it on top of the pastries. Proof in a warm spot until tripled in size, about 2 hours.±\nHeat the grapeseed oil in a large saucepan until it reaches 350°F (175°C). Use a deep-frying thermometer to verify the oil is at the right temperature.‡ Line a platter with several layers of paper towels for draining.\nGently place 3 or 4 of them at a time into the hot oil. Fry for about 90 seconds on each side, flipping once, until golden brown. Remove from the oil with a slotted spoon and drain on the paper towels.\nCheck that the oil is at the right temperature. If not, let it heat up again before frying the next batch. Continue until all of them are fried.\nLet cool completely before filling.\nPrepare the glaze on page 208 that corresponds to your choice of ganache.\nMake flavoured Sugar\nPrepare the decorating sugar on page 208 that corresponds to your choice of ganache.\nTransfer the ganache to a stand mixer fitted with a whisk. Whip on high speed until the ganache holds a stiff peak. (If using the Champagne-chocolate ganache, simply whisk it until smooth. It will be quite thick already.)\nCut the tip of a piping bag to snugly fit the Bismarck tip. Using a rubber spatula, place 2 large scoops of ganache in a piping bag so that it is one-third full. Push the ganache down toward the tip of the bag.\nPlace the decorating sugar that corresponds to your choice of ganache and glaze in a bowl.\nArrange each At-Home CronutTM pastry so that the flatter side is facing up. Inject the ganache through the top of the pastry in four different spots, evenly spaced. As you pipe the ganache, you should feel the pastry getting heavier in your hand.\nPlace the pastry on its side. Roll in the corresponding sugar, coating the outside edges.\nIf the glaze has cooled, microwave it for a few seconds to warm until soft. Cut the tip of a piping bag to snugly fit a #803 plain tip. Using a rubber spatula, transfer the glaze to the bag. Push the glaze down toward the tip of the bag.\nPipe a ring of glaze around the top of each At-Home Cronut pastry, making sure to cover all the holes created from the filling. Keep in mind that the glaze will continue to spread slightly as it cools. Let the glaze set for about 15 minutes before serving.\nServing Instructions Because the At-Home CronutTM pastry is cream-filled, it must be served at room temperature.\nStorage Instructions Consume within 8 hours of frying. Leftover ganache can be stored in a closed airtight container in the refrigerator for 2 days. Leftover flavoured sugar can keep in a closed airtight container for weeks and can be used to macerate fruits or sweeten drinks.\n* Instant yeast is often used for doughs with higher sugar content, because this yeast needs less water to react and sugar tends to pull water from dough. You can substitute the same quantity of active dry yeast, but may get a denser final product.\n* This is not the typical lamination technique and is unique to this recipe.\nWhen rolling out dough, you want to use as little flour as possible. The more flour you incorporate into the dough, the tougher it will be to roll out, and when you fry the At-Home Cronut™ pastries they will flake apart.\n± It’s best to proof At-Home Cronut pastries in a warm, humid place. But if the proofing area is too warm, the butter will melt, so do not place the pastries on top of the oven or near another direct source of heat.\n‡ The temperature of the oil is very important to the frying process. If it is too low, the pastries will be greasy; too high, the inside will be undercooked while the outside is burnt.\nYield Ganache for 12 At-Home CronutTM pastries\nWater 2 tablespoons 26 grams\nChampagne ¼ cup + 2 tablespoons 102 grams\nUnsweetened cocoa powder 1½ tablespoons 9 grams\nPouring cream (35% milk fat) ½ cup 115 grams\nEgg yolks (large) 3 each 3 each (60 grams)\nGranulated sugar 3 tablespoons 38 grams\nDark chocolate (66% cocoa 1 cup + 1 tablespoon 165 grams\ncontent), finely chopped\nCombine the water, 2 tablespoons (26 grams) of the Champagne and the cocoa powder in a small bowl. Mix to a smooth paste.\nCombine the cream and the remaining ¼ cup (76 grams) Champagne in a small saucepan and bring to a boil over medium heat. Remove from the heat.\nWhisk the egg yolks and granulated sugar together in a small bowl. Stream one-third of the hot cream mixture into the egg yolks, whisking constantly until fully blended, to temper them. Whisk the tempered yolks into the remaining hot cream. Return the saucepan to medium heat.\nKeep whisking! Continue to cook the custard over medium heat until it reaches 185°F (85°C). The custard will turn pale yellow and thicken so that it coats the back of a spoon. Remove from the heat and whisk in the cocoa powder paste until fully incorporated.\nPlace the chocolate in a medium heatproof bowl. Strain the custard through a small sieve over the chocolate. Let stand for 30 seconds.\nWhisk the chocolate and custard until smooth. When finished, the ganache will have the consistency of yoghurt. Reserve ¼ cup (50 grams) for the glaze. Cover with plastic wrap pressed directly onto the surface of the ganache, to prevent a skin from forming. Refrigerate overnight to set.\nRecipe and image from Secret Recipes by Dominique Ansel (Murdoch Books) $49.99 available now in all good bookstores and online.","18 Sep Raspberry Mille Feuille with Yoghurt Mousse\nMille feuille literally means “a thousand leaves” and refers to all the paper-thin layers formed by the puff pastry in this classic French dessert. Although it may look intimidating, a mille feuille is actually not difficult to make. Nine times out of ten I will use shop-bought puff pastry, but when I have a bit of time on my hands, I find making my own really rewarding! So I have included both options here for you.\nRough puff pastry is very similar to puff pastry in flavour and texture, but instead of using slabs of butter when folding, grated butter is used which makes the process a lot easier. It may seem counter-intuitive to weigh the pastry down when baking, but this keeps the pastry rectangles nice and thin whilst still being deliciously crispy with plenty of layers. Traditionally, a mille feuille will have a filling of creme patisserie, but I have made a light yoghurt mousse using Nutriday Double Cream Plain Yoghurt. Using yoghurt means the mousse is still creamy and decadent, but not as rich or sweet as a traditional filling. Not only does this dessert look absolutely stunning, but the contrast of the crispy pastry layers, creamy mousse and tart raspberries is simply heaven in every bite!\nNOTE: You can also serve 1 large mille feuille by dividing your pastry into 3 large rectangles of 30 x 10cm.\nFor the rough puff pastry:\n350g flour (2½ cups)\n5ml salt (1 tsp)\n50g unsalted butter, chilled and cubed\n150ml iced water (½ cup)\n5ml lemon juice (1 tsp)\n200g unsalted butter, grated and frozen (divided)\n(OR 600g ready-made puff pastry, defrosted)\nFor the yoghurt mousse:\n250ml Nutriday Double Cream Plain Yoghurt (1 cup)\n150g white chocolate, roughly chopped\n5ml powdered gelatine (1 tsp)\n30ml water (2 tbsp)\n250ml whipping cream (1 cup)\n200g fresh raspberries\n30ml icing sugar (2 tbsp)\na few springs of mint\n- To make the pastry, add the flour to a large bowl together with the salt. Add the 50g of cubed butter and use your fingertips to rub it into the flour until you have a breadcrumb texture.\n- Stir the lemon juice into the iced water and add gradually to the flour mixture, using a butter knife to mix. Add only enough water for the dough to come together and do not overwork the mixture. Cover with clingfilm and refrigerate for 1 hour.\n- On a lightly floured surface, roll the dough out into a rectangle shape, about 30cm x 15cm. Add half of the grated, frozen butter (100g) to the lower two-thirds of the rectangle. Fold the top third down and then the bottom third up over it (like folding a letter). Turn the dough once to the right (90 degrees) so that the shortest side of the rectangle is now closest to you.\n- Roll the dough out to 30cm x 15cm rectangle again. Add the remaining 100g of grated, frozen butter to the lower two-thirds. Repeat the folding as before: fold the top third of the dough down, then the bottom third up. Turn the dough once to the right. You have now completed two “turns”. If the dough is getting warm you may need to refrigerate it for 30 minutes before continuing.\n- Again roll the dough into a rectangle and repeat the folding as before (this time without adding any butter). Turn the dough once to the right and repeat the rolling and folding so that you have completed four “turns” – two with butter and two without. Refrigerate the dough for at least 4 hours or overnight (max 3 days or freeze for up to 2 months) before using.\n- To make the yoghurt mousse, place the white chocolate into a large bowl and add half the yoghurt. Melt the mixture gently (either over a pan of simmering water or at 20-second intervals in the microwave). Stir until completely smooth.\n- Sprinkle the gelatine over the water in a small bowl and leave to bloom for 5 minutes. Gently melt the mixture by dipping in a hot water bath or by heating for 5-10 seconds in the microwave. Don’t allow it to boil. Stir the gelatine into the still-warm melted chocolate and stir until smooth. Set aside to cool for 10 minutes.\n- Whip the cream until you have soft peaks and gently fold into the chocolate along with the remaining yoghurt. Once there are no more streaks cover the mixture with clingfilm and chill for at least 2 hours. Place into a piping bag fitted with a plain round nozzle.\n- Preheat the oven to 200°C. Divide the pastry in half. Roll the first block into a 30 x 15cm rectangle on a lightly floured surface. Cut into 9 equal rectangles, each 10cm x 5 cm (try not to drag your knife through the pastry, but rather press down firmly to cut). Transfer to a lined baking tray and dock each rectangle a few times with a fork. Cover with another sheet of baking paper and a second baking tray (this is to weigh the pastry down so that it doesn’t puff up too much). Bake for 20 minutes, then remove the top baking tray and bake for a further 5 -7 minutes until golden brown. Cool for 5 minutes on the tray then cool completely on a wire cooling rack. Repeat with the second block of dough so that you have 18 rectangles in total.\n- To assemble the mille feuille, pipe two rows of yoghurt mousse kisses onto 12 of the rectangles. Stack two on top of each other and top with a third, plain rectangle of pastry. Top each mille feuille with raspberries, dust with icing sugar and garnish with mint. Best served within a few hours of assembling."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:40085bdb-05bd-48af-b8e5-67fa31fe785b>","<urn:uuid:44557f1b-8ee6-4ee3-a793-e66852c8ad6d>"],"error":null}
{"question":"¿Cuál es la diferencia principal entre cómo Reform Judaism y United Methodism implementan sus mandatos religiosos?","answer":"The key difference lies in their organizational structure for implementing religious mandates. Reform Judaism operates through the Commission on Social Action (CSA), which provides guidance on applying Jewish values to public affairs, with policy set democratically by delegates from over 900 member congregations during the Union for Reform Judaism's Biennial General Assembly. United Methodism, in contrast, implements its religious mandates through a theological framework centered on different types of grace (prevenient, justifying, and sanctifying), focusing on individual spiritual transformation that leads to service and mission work.","context":["For over 100 years, WRJ has annually published the Art Calendar to showcase Jewish artists and to give them a larger and more knowledgeable audience.\nWHY ADVOCACY IS CENTRAL TO REFORM JUDAISM:\nBY: MARLA FELDMAN\n“Reform Jews are committed to social justice. Even as Reform Jews embrace ritual, prayer, and ceremony more than ever, we continue to see social justice as the jewel in the Reform Jewish crown. Like the prophets, we never forget that God is concerned about the everyday and that the blights of society take precedence over the mysteries of heaven. A Reform synagogue that does not alleviate the anguish of the suffering is a contradiction in terms.” -- Rabbi Eric Yoffie, speech to the UAHC Executive Committee, February 1998\nIt has become axiomatic that to be a Jew is to care about the world around us. To be a Reform Jew is to hear the voice of the prophets in our head; to be engaged in the ongoing work of tikkun olam; to strive to improve the world in which we live.\nThe passion for social justice is reflected in the ancient words of our prophets and sages and in the declarations of our Movement’s leaders throughout its history. The ancient command “Tzedek, Tzedek Tirdof! Justice, justice shall you seek!” constantly reverberates in our ears. It has become deeply embedded in the Reform Jewish psyche. This charge has led to a long and proud tradition of political activism by the Reform Movement.\nThe idea that people of faith have a mandate to bring their values into the public arena is not unique to the Reform Movement. There is a long tradition of faith groups “speaking truth to power” and advocating for social change, and every major religious organization in American life participates in this civic exercise. Religious voices have been central in the major social justice movements throughout our nation’s history, from the abolitionist movement to those involved with desegregation and civil rights. In the international arena as well, faith groups have led the way in advocating for nuclear disarmament, international aid and human rights around the world.\nThis is not an easy time to stand up to be counted. We are challenged by an overwhelming number of issues, each one central to our understanding of the prophetic message of our faith and critical to creating the kind of society we wish to bequeath to those who follow us. And not only are we overwhelmed by the sheer scope of the issues that are before us, but we are confronted by those who claim to speak in the name of faith, but who offer a different version of what God expects of us; those who proclaim themselves the upholders of family values yet who do not value individual rights or personal autonomy, and who have little respect for the Constitutional principles that have allowed religion to thrive in this country unfettered by government coercion or corruption.\nOurs is a different message. We proclaim that maintaining a strong safety net for those who are most vulnerable is the modern manifestation of our obligation to “leave the corners of our fields for the poor and needy.” We believe that supporting public schools so that every child in America has access to a free and appropriate education and that paying workers enough to support themselves without having to choose between shelter and food, medication or heat, are family values. If we don’t bring these progressive religious values into the public arena with us, we will abandon the public square to those offering a different view of religion and values.\nHOW DO WE IMPLEMENT THIS MANDATE TO PURSUE JUSTICE WITHIN THE REFORM MOVEMENT?\nThe Commission on Social Action (CSA) of Reform Judaism provides guidance to the Movement as it wrestles with the challenge of applying our progressive Jewish values to the public affairs agenda. The CSA is a joint commission of the Central Conference of American Rabbis and the Union for Reform Judaism, and is comprised of representatives of all the affiliates of Reform Judaism throughout North America. It oversees the work of Reform Judaism's Religious Action Center of Reform Judaism (RAC) in Washington, D.C. which pursues social justice and religious liberty by mobilizing the American Jewish community and serving as its advocate in the capital of the United States.\nUltimately it is the members of Reform congregations who set the policy for the Movement. During the Union for Reform Judaism’s Biennial General Assembly, delegates from the over 900 member congregations consider and vote on resolutions that reflect the consensus positions of our membership. This democratic process and the commitment of the Reform Movement to speak out on issues of concern is as old as the Movement itself, and is evidenced by the hundreds of resolutions adopted since its inception.\nGo to www.urj.org/docs/reso to search the database of resolutions. Click here to view the social justice statements in the major platforms of the Central Conference of American Rabbis since 1875.\nARE INDIVIDUALS BOUND BY THE POLICY OF THE REFORM MOVEMENT?\nThe resolutions adopted by the Union for Reform Judaism neither bind the members of individual congregations, nor do they presume to speak for all. Joining a Reform congregation does not mean one subscribes to a particular political perspective. In any group, there will be divergent opinions, and policymakers understand that when religious bodies take positions, there may very well be individuals in the group who disagree with the stated position.\nYet, our diversity need not deter us from fulfilling our prophetic mandate. Reform Judaism stands for certain principles, and those who join our congregations take pride in our long history of “speaking truth to power.” Just as most members know that a hallmark of Reform Judaism is an openness to the “other” – whether lesbian or gay, interfaith families, or those with special needs -- they should also know that there will be a strong social action component – mitzvah days, collection drives, social justice sermons, and education about current issues of concern. And it should be expected that through our congregations we will make a collective effort to bring our progressive, Reform Jewish values to bear in the community at large. We will be engaged on issues of local, national and global concern; we will participate in interfaith coalitions and activities; we will speak out on behalf of the vulnerable; and we will seek justice for all. This is who we are.","Our Common Heritage as Christians\nAs United Methodists, we share a common heritage of faith with Christians of every age and nation. This heritage is grounded in the Biblical witness to Jesus Christ as Savior and Lord, which is the source and measure of all valid Christian teaching.\nWith Christians of other denominations, we confess belief in the triune God-Father, Son, and Holy Spirit. At the heart of the gospel of salvation is God’s incarnation in Jesus of Nazareth. Scripture witnesses to the redeeming love of God in Jesus’ life and teachings, his atoning death, his resurrection, his sovereign presence in history, his triumph over the powers of evil and death, and his promised return. Because God truly loves us in spite of our willful sin, God judges us, summons us to repentance, pardons us, receives us by that grace given to us in Jesus Christ, and gives us hope of life eternal. Through faith in Jesus Christ, we are forgiven, reconciled to God, and transformed as people of the new covenant.\nWe United Methodists understand ourselves to be part of Christ’s universal church. We are incorporated into this world-wide community of faith by Baptism, receiving the promise of the Holy Spirit that re-creates and transforms us. Through the regular celebration of Holy Communion, we participate in the risen presence of Jesus Christ and are thereby nourished for faithful discipleship.\nOur Distinctive Heritage as United Methodists\nJohn Wesley (1703-1791), founder of the Methodist movement, combined belief in grace, justification, assurance, and sanctification in a powerful manner to create distinctive emphases for living the full Christian life. The underlying energy of our Wesleyan theological heritage stems from an emphasis upon “practical divinity,” the implementation of genuine Christianity in the lives of believers.\nGrace pervades our understanding of Christian faith and life. By grace we mean the undeserved, unmerited, and loving action of God in human existence through the ever-present Holy Spirit.\nPrevenient Grace – We acknowledge God’s Prevenient grace, the divine love that surrounds all humanity and precedes any and all of our conscious impulses. This grace prompts our first wish to please God, our first glimmer of understanding concerning God’s will, and our first hint of conviction of having sinned against God.\nGod’s grace also awakens in us an earnest longing for deliverance from sin and death, and moves us toward repentance and faith.\nJustifying Grace – We believe God reaches out to the repentant believer with accepting and pardoning love.\nIn justification we are, through faith, forgiven our sin and restored to God’s favor. This righting of relationships by God through Christ calls forth our faith and trust as we experience regeneration, by which we are made new creatures in Christ. Our Wesleyan theology also embraces the scriptural promise that we can expect to receive assurance of our salvation as the Spirit “bears witness with our spirit that we are children of God.”\nSanctifying Grace – We hold that the wonder of God’s acceptance and pardon does not end God’s saving work, which continues to nurture our growth in grace. Through the power of the Holy Spirit, we are enabled to increase in the knowledge and love of God and in love for our neighbor.\nNew birth is the first step in this process of sanctification. Sanctifying grace draws us toward the gift of Christian perfection, which Wesley described as a heart “habitually filled with the love of God and neighbor.”\nFaith and Good Works – We see God’s grace and human activity working together in the relationship of faith and good works. God’s grace calls forth human response and discipline. While faith is the only response essential for salvation, Wesley believed that salvation evidences itself in works of piety and mercy.\nMission and Service – We insist that personal salvation always involves Christian mission and service to the world. By joining heart and hand, we assert that personal religion, evangelical witness, and Christian social action are reciprocal and mutually reinforcing."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:490bda27-fd3a-4b34-8c3d-64b4df68a5b9>","<urn:uuid:35dca6e5-40e2-49c7-a978-085c4f4b1dd0>"],"error":null}
{"question":"How do Islamic and Vedic traditions compare in their views on the purifying aspects of spiritual practices involving food and heat?","answer":"Both traditions recognize heat and food-related practices as means of spiritual purification, but approach them differently. In Islamic tradition, proper eating is seen as part of religious devotion, with specific guidelines like performing wudu (ablution) before meals to remove poverty and after meals to remove minor sins. The Prophet advised moderation, stating one should fill only a third of the stomach with food, a third with drink, and leave a third for breathing. In Vedic tradition, the concept of agni (fire) is central to purification, with proper digestion (regulated by different types of agni) being key to physical and spiritual health. The Vedic concept of tapas refers to the transformative heat generated through spiritual practices that leads to higher consciousness and purification of body and mind.","context":["First Khutbah – Main Points\nإن الأكل من الدين\n“Eating is part of religion.” [from the Companions – RAH]\nلا طريق إلى الوصول للقاء الله إلا بالعلم والعمل\n“There is no path to the meeting with God except by knowledge and deeds.” [advice from al-Ghazali]\nولا تمكن المواظبة عليهما إلا بسلامة البدن\n“And there can be no devotion to it [knowledge and deeds] except with a sound body” [advice from al-Ghazali\nكلوا من الطيبات واعملوا صالحا\n“Eat from that which is good and perform righteous acts.” [Q: ‘A’raf (7):100]\nإن الرجل ليؤجر حتى في اللقمة يرفعها إلى فيه وإلى في امرأته\nThe Prophet [s] said: “A man is rewarded even for the morsel of food he raises to his mouth and to the mouth of his wife.” [related in Bukhari]\nالوضوء قبل الطعام ينفي الفقر وبعده ينفي اللمم, ينفي الفقر قبل الطعام وبعده\nThe Prophet [s] said: “Wudu’ [ablution] before eating removes poverty and performing it afterwards removes minor sins.” [related in Abu Dawud and at-Tirmidhi]\nEating is a barometer of sorts for the believer. It gives us an indication of where our nafs is at:\nوأما من خاف مقام ربه ونهى النفس عن الهوى فإن الجنة هى المأوى\n“And as for the one who fears the Station of his Lord and forbade his nafs [lower self] and its appetites, the Garden will be his refuge.” [Q: an-Nazi’at (79):40-41]\nBut not only is a it a meter for ourselves, but also for our society. And it’s here that I want to address this notion of “quietism” that we see in the Muslim community today. I will touch on this in the second half of the khutbah.\nSecond Khutbah Points\nيأيها الناس كلوا مما في الأرض حلالا طيبا ولا تتبعوا خطوات الشيطان إنه لكم عدو مبين\nيأيها الذين ءامنوا كلوا من طيبات ما رزقناكم واشكروا لله إن كنتم إياه تعبدون\n“O’ Mankind! Eat of what is good and lawful and do not follow Shaytan! He is an outright enemy.”\nAllah addresses mankind and the Muslims all in the same passage.\nما ملأ آدمي وعاء شرا من بطنه حسب ابن آدم لقيمات يقمن صلبه فإن لم يفعل فثلث طعام وثلث شراب وثلث للنفس\nThe Prophet [s] said: “No human being has ever filled a container worse than his own stomach. The son of Adam needs no more than mere morsels to sustain him; doing so, he should consider that a third of his stomach is for food, a third for drink, and a third for his soul/for breathing.” [related in at-Tirmidhi]\nThere are so many eating related disorders in this society: diabetes, heart disease, cancer. Many of the behavioral disorders we see in children and in adults also can be traced and linked with food.\nI want to address and appropriate a word that has been previously associated with piety: quietism. Some traditions see quietism as a means of quieting oneself to the world so that one may hear God. But there is another form of quietism, one that is silent in the fact of that which it knows is not good. We claim to be people of the Truth and yet we have a tendency to retreat to ourselves. But God commanded the Prophet Muḥammad [s] to “go forth and proclaim the blessing and favor of your Lord!” [Q 93: 11].\nListen/download the khutbah here: [audio:http://www.marcmanley.com/media/mp3s/importance_of_food.mp3|titles=The Importance of Food and What Lies Beyond It|artists=Marc Manley]","Tapas and Agni: Transformative heat\nby Jim Kulackoski\nAccording to the ancient Vedic sciences of India, the entire universe is in a constant state of flux or action. This perpetual state of transformation is what makes existence possible, for when something ceases to evolve, it ultimately ceases to be – in a more familiar contemporary ideology: “If you are not growing, you are dying.” The Vedic ideas of agni and tapas are interrelated in this cosmic evolution.\nIn the Vedic interpretation, tapas in an intense drive or “burning desire” towards accomplishing something. It is an intense persistence or devotion to an idea that allows one to carry it out to completion. As one encounters a number of obstacles on the path to completing any task, they must ultimately transcend those obstacles in order to complete that task, leaving them a different person. In Tantric philosophy, tapas has another meaning: the internal heat generated during certain yogic practices. This heat is the result of the conversion of the body’s fundamental essence (ojas) into a refined form of prana, bio-energy used in the development of soma, a higher state of consciousness brought about by physiological integration. In both definitions, tapas is the catalyst for transformation.\nThe principle of transformation that occurs due to the “friction” created from the persistence of tapas is called agni. Because transformation is a necessary component in existence, agni is one of the most important devatas, or laws of nature.\nAgni is an accelerated state of energy, the result of which is heat, and thus, agni and tapas are both associated with the idea of heat.\nSacred Fire: Purifying the spirit\nby Paul Tootalian\nFire. by scientific definition, fire is a process of rapid oxidation that releases heat, light and energy. But with a makeup far more mysterious, fire is at the same time a wild force of nature, an element untamed. Why do so many religions and spiritual paths depict fire as a divine spirit enveloping us? Part spirit, part dancing deity, alive and breathing, fire symbolizes the sun, resurrection and transformation in action.\nInner fires invoke the archetypal reality of purification of the human spirit, an image that opens us up to deeper dimensions. Outer fires reflect this passion as they light the spiritual path, from the wildness fire pits of Native American ceremonies and flaming Shinto altars, to Christian shrines aglow in candlelight. In Plato’s ancient Allegory of the Cave, prisoners are chained in a cave, riveted by the flickering shadows of objects projected on the cave wall in the light of a fire. Misguided, the prisoners believe the shadows to be real, however, the fire itself represents reality’s true form.\nThis is the power of Hinduism’s agni, primordial fire, God aflame. “As a lamp in a windless place does not waver,” is how the Bhagavad Gita describes the focused, purified mind. India’s sacred text goes on to praise fire in the light of glorifying spiritual masters, who, “with the torchlight of knowledge,” opened eyes blinded by the darkness of ignorance. This is the sacredness of fire.\nTapas and the Fire Element\nby Monica Yearwood\nAyurveda, the ancient system of natural healing, regards fire as a central life-giving source. Fire and its variants, light and heat, are used to describe internal processes within the body such as digestion and metabolism as well as mental acuity and emotional tendencies. We also generate fire and heat through spiritual discipline that benefits our intuition and connects us with the divine.\nFire sustains the entire planet, as the manifestation of the sun. Light, a byproduct of fire, illuminates our path and enables us to see. The sun, a primary source of fire for the entire universe and its inhabitants, dictates the daily practices that make up ayurvedic lifestyle, called dinacharya. Ayurveda teaches that practices such as waking up with the sunrise and eating our largest meal at midday, when the sun is at its strongest, offer numerous health benefits.\nAyurveda teaches that a sacred window opens just at sunrise and sunset each day, a time that supports deeper introspective practices such as meditation and yoga.\nMeditation and yoga burn away karma and enhance the fire of intellect. Surya namaskar, often translated as “sun salutations,” is a specific set of yoga postures dedicated to the sun. This series strengthens the body, but also burns away toxins in the body and purifies the mind with its heat. Many of the physical practices in yoga are used to burn away impurities in the mind, blockages in the energetic channels and obstructions in the physical body.\nAyurveda sees the human body as a small microcosm of the universal body, thus the sun and its byproducts, including light and heat, can be found within our physiology. Ayurveda recognizes agni (fire) in the physical body as a primary facilitator of health.\nAyurvedic practitioners assess the function of agni in their clients through the assessment of the doshas. Vata types, who tend toward variability, need to maintain constant agni. These types are advised to adopt regularity in their eating and sleeping times. Pitta types, who tend toward excess agni, need to implement a cooling diet and herbs to protect themselves from a variety of heat-related disorders. Kapha types, who tend toward low agni, need to constantly stoke their internal fire with pungeant spices and regular fasting.\nEach tissue in the body has a corresponding agni that regulates its proper metabolism. The jatharagni is the central, digestive fire in the body. Ayurveda describes four types of agni that regulate our digestion:\n- visham (variable) agni, most common in vata types;\n- tikshna (high) agni, most common in pitta types;\n- manda (slow) agni, most common in kapha types;\n- and sama (balanced) agni.\nAppetite can assess the function of our digestive agni. If we are constantly hungry and seldom satisfied, our agni is tikshna. If we have lost interest in food, our agni is manda. If we continually lose and gain our appetite, our agni is potentially visham.\nAyurvedic practitioners teach breathing practices to help regulate prana (the life force), which in turn regulates the fires in the physical body. Some breathing practices can increase agni, burn away blockages and stimulate digestion. Other practices can reduce agni if it is too high, or regulate agni if it is inconsistent. If one’s breathing is complete, deep and unobstructed, it is a good sign that agni is functioning properly.\nTejas is the fire of the intellect, and the essence of pitta dosha. It enables correct perception, clarity and illumination, and is cultivated by spiritual study an concentration exercises. The yogic practice of trataka, for example, involves staring at a candle flame. By resisting the urge to blink, the body eventually produces special tears that wash the eyes, purify the perceptual senses and develop tejas.\nWe can assess the propensity of our tejas by observing the clarity with which we approach our activities. Tejas bestows confidence, faith and trust in our choices. It illuminates our path and allows us to correctly perceive impending obstacles. If the mind is marred with confusion, self-doubt and apprehension, most likely tejas has been dimmed.\nTapas is the heat produced from spiritual efforts. It is generated by our willpower, self-challenge and endurance. In a Vedic mythic story about the goddess Parvati and the god Shiva, Parvati falls in love with Shiva but is initially rejected by him. In her determination, she dedicates herself to spiritual austerities. She performs all the traditional mortifications, such as sitting in the flour fires in the middle of summer and standing on one leg for years. Parvati eventually exceeds all of the great sages in her efforts and generates so much tapas that the gods begin to get uncomfortable by her power. The gods beg Shiva to grant Parvati’s wish to be with him to get her to stop. The teaching of the story is that by generating tapas we are granted spiritual boons.\nIn spite of all of these positive connotations of fire, if uncontrolled, it can destroy. Excess fire, mostly related to pitta dosha, can burn the body and cause disease. Symptoms of heat such as skin inflammations, acne, liver toxicity and loose bowel movements are symptoms of excess pitta.\nUnlike tejas, which creates illumination and clear perception, pitta dosha intensifies criticism, anger and desire to control. In general, pitta types are most susceptible toward these imbalances, which can be remedies by Ayurvedic lifestyle programs. Damaging inner fires can be reduced through a cooling and drying diet. Bitter leafy greens such as Swiss chard and kale reduce pitta’s oily and hot qualities. Coriander seed, chamomile and aloe can be taken internally if pitta is provoking digestive heat. Turmeric can assist with calming the irritability and control of a pitta-type liver.\nThe heat, humidity and longer periods of light in summer provoke pitta dosha and expose all types to excess pitta. The earth provides the antidote by offering an array of cooling fruits and vegetables. A higher carbohydrate diet from fruits provides the energy required for heightened physical activity. Swimming, sitting in the shade and avoiding outdoor exercise in the strong, midday sun can help everyone stay in balance.\nTepid Tapas: Finding the heat without getting burned\nby Trayci Handelman\nFor years I over-chaturanga’d. “Over,” as in over the limit in how many a yogi should do in a class, a day, a month; over the limit that a mortal shoulder could take. “Over,” as in overused until the rips that I had created in my shoulder had to be sewn and screwed into my rotator cuff with metal anchors. Now I am conservative with the chaturanga and realize I have tendencies to over-chaturanga in other ways.\nTapas (Sanskrit for “heat”) is the third niyama, or spiritual observance, in the Yoga Sutras. It refers to the “burning off” of negative energies in order to follow a true path of spiritual devotion. Within our society the mere mention of fire, burn or heat tends to lead to thoughts of the extreme and excess – the idea that more must be better. For yogis, this can mean hotter classes, more workshops, more studios, harder arm balances, crazier sequences. Why do we push ourselves to excess, instead of finding a place of comfort before the burnout?\n“Too much of everything is just enough” comes to mind, a lyric from a Grateful Dead song. We have been programmed to want more, bigger, stronger, hotter. Yet any niyama should be considered within the context of all five of these concepts. The interesting part about the niyamas is that they intertwine, lean on each other, even reference each other, in very subtle ways. Santosha, another niyama, means contentment, to be satisfied and grateful that what you have is enough. Svadhyaya speaks of self-study, specifically pertaining to gaining more knowledge to deepen the understanding of the self.\nIn the Yoga Sutras, the true meaning of discipline and purification is for the greater purpose of contentment and spiritual growth/devotion. Can we use these niyamas without burning out or overdosing on the notions? This answer, like most answers in all areas of yoga – spiritual, physical, emotional – is found within ourselves.\nFind the tapas – the thing that lights you up from the inside. Tap into it. Follow it, trust it, commit to it. If it starts to burn you, or worse – starts to fade you or weaken you – pause. Breathe and reflect. Is it too much, too soon, too intense? Only you will know. Follow that inner fire, the internal tapas, and more than likely you will never get burned. This is actually referred to as Mati, one of the 10 original niyamas, developing a cognitive, spiritual will. Yoga is about self-acceptance, not self-improvement. If we can keep focusing in, rather than seeking out, the answers should never be farther than the corners of our mat.\nTapas Tunes: Songs that sing of summer\n- Orange Sky, Alexi Murdoch\n- Southern Sun, Boy & Bear\n- Summer Breeze, Seals & Crofts\n- Hard Sun, Eddie Vedder\n- Sunshine (Go Away Today), Jonathan Edwards\n- Rain in the Summertime, The Alarm\n- Fired Up!, Funky Green Dogs\n- Blinded by the Light, Manfred Mann’s Earth Band\n- Sun Light, MC Yogi\n- Burn it in the Fire, Wade Morissette\n- The Sound of Sunshine, Michael Franti & Spearhead\n- The Boys of Summer, Don Henley\n- She’s a Rainbow, The Rolling Stones\n- Desert Rose, Sting\n- Follow the Sun, Xavier Rudd\n- Hearts on Fire, Passenger\n- Long Time Sun, Girish\n- Soak Up The Sun, Sheryl Crow\n- Over the Rainbow, Israel Kamakawiwo’ole"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:c53dad7b-6a3f-46e5-b04f-34ff20b871f2>","<urn:uuid:37b593bb-721c-4f94-acc4-02563ed970ff>"],"error":null}
{"question":"Could you explain what happened at the Saint Hugh of Lincoln Church incident in Huntington Station on May 28, 2022? What were the specific charges filed?","answer":"On May 28, 2022, an individual damaged several windows and doors at St. Hugh of Lincoln Church located at 21 E. 9th St. in Huntington Station. The perpetrator was arrested and charged with three specific offenses: 1) Aggravated harassment first degree, 2) Criminal mischief third degree, and 3) Disruption or disturbance of a religious service, funeral, or burial.","context":["|JULY 2022 NEWSLETTER\nThe Huntington Anti-Bias Task Force (HABTF) is a non-partisan group formed by the Town\nof Huntington in conjunction with the Suffolk County Anti-Bias Task Force. It is made\nup of concerned clergy, community representatives and lay persons who work together to\naddress the issue of intolerance, prejudice, discrimination and racism in any segment\nof our Town.\nWe've been holding public monthly since January 2019 and have accomplished quite a lot.\nUpcoming meetings are 1 PM Wed August 24 and Sept 28 (4th Wed).\nFor more information about HABTF, click\nSend suspected bias incidents to:\nTown of Huntington Anti-Bias Task Force\nDepartment of Human Services (Room 203)\nAttn: Carmen Kasper, Director\n423 Park Ave, Huntington, NY 11743\nAlso contact SCPD Hate Crimes Unit at 631-852-6323\nClick here to read HABTF May 2022 Newsletter\nClick here to read HABTF Jan 2021 Newsletter\nTable of Contents\n-- 2nd Precinct SCPD Report\n-- ADL: Hate in New York State\n-- Huntington Anti-Bias Concert\n-- Huntington Family Pride Picnic\n-- June 2022 HABTF Meeting Summary\n-- Town of Huntington News\n2nd Precinct SCPD Report\nBy Inspector William Scrima\nSince the last newsletter, there were three significant incidents in the Second Precinct that were\nreported to have elements of bias:\n- On 5/28/22, a male damaged several windows and doors at St. Hugh of Lincoln Church 21 E. 9th St.\nHuntington Station. He was arrested and charged with Aggravated harassment first degree, Criminal\nmischief third degree, and disruption or disturbance of a religious service, funeral, burial or\n- On 5/30/22, a swastika was discovered to have been drawn on the windshield of a vehicle on Berrywood Dr.\nin Huntington Station. Hate Crimes is investigating.\n- On 6/26/22 at 10:04 am a Lee Zeldin campaign sign located at West Pulaski Road and Oakwood Road in Huntington\nStation was discovered to have been painted with a swastika, \"187,\" and the word \"Gambino\". Hate Crimes Unit\narrested a Huntington man. He was charged with Aggravated Harassment 1st Degree, a hate crime, and Criminal\nMischief 4th Degree.\n5 PM Tues Aug 2 National Night Out at Manor Field Park\nClick here to check out 2nd Precinct News on Twitter\nClick here for the 2nd Precinct Community Meeting Schedule\nFor more information, please visit the 2nd Precinct department\nWebsite at www.suffolkpd.org.\nHate in Empire State: Extremism & Antisemitism\nin New York (2020-2021)\nThis report examines extremist and antisemitic trends and incidents across New York\nstate during the two-year time period from January 1, 2020 to December 31, 2021, and\nprovides recommendations for combatting these threats. The ADL Center on Extremism (COE)\nand the Community Security Initiative (CSI), a project of UJA-Federation of NY and\nJCRC-NY, jointly researched and authored the report.\nThe last two years have seen a significant proliferation of hate incidents both\nnationwide and in New York State. These incidents have been rooted, in part, in\nwidespread campaigns of disinformation and conspiracy theories, some of which have\nanimated extremists and fueled antisemitism, resulting in unrest and violence, from\nthe January 6, 2021 insurrection in Washington, D.C. to white supremacist activism\nto a spike in hate crimes and rising antisemitism.\nClick here to read more > >\nHuntington Anti-Bias Concert\nby Kevin Thorbourne\nOn Aug 20, 2022, please join us for a FREE concert to raise awareness of bias and support inclusivity\nin our town. The Huntington Anti-Bias Concert will feature some of the best talent\nfrom each of the 9 Town of Huntington High Schools and will also involve your favorite\nlocal businesses! Join us at Hecksher Park from 1PM to 4 PM to watch\nour community come together and watch our most talented students put on a show that\nwill be the talk of the town! There will be raffles, snacks and more!\nThe Tri Community and Youth Agency (Tri CYA) is the main manager of this event.\nIt is a private, not-for-profit community-based\nagency dedicated to supporting the growth and development of youth and their families in\nthe communities of Huntington, South Huntington and Cold Spring Harbor.\nFor more than 40 years, they have provided a broad range of educational,\nrecreational, social, cultural, athletic, counseling and advocacy programs.\nTo see photos from last year's concert, click https://photos.app.goo.gl/ZhdHdmuTc8pMJYBz7\nHuntington Family Pride Picnic\nby David Pinkowitz\nA Huntington couple held a family pride picnic on June 26 at Mill Dam Park, designed to celebrate LGBTQ+ families.\nEric and Jim Rubin Perez worked on the picnic for months, with help from the office of Town Councilwoman\nJoan Cergol, the Unitarian Universalist Fellowship of Huntington and Be the Rainbow, an organization in Port Jefferson.\nThe picnic idea grew out of informal brunches with other families in the area.\n“We have lived in the community for about 15 years, and one of the things that brought us to this community was\nthat Huntington had the pride parade,” Eric Rubin Perez said.\n“The goal of the family pride picnic is to bring pride back to Huntington and we’ve created an event meant\nto be a family celebration,” Jim Rubin Perez said. “We’re excited to celebrate pride in the place it all started.”\nHuntington hosted the Long Island Pride Festival starting in the 1990s.\nTo see some photos of the picnic, click https://photos.app.goo.gl/5qPvYPuym9za45ih7\nJune HABTF Meeting Summary\nby Rabbi Lina Zerbarini\nHABTF Meeting Minutes Jun 22, 2022 Zoom 1pm\nClick here to read more > >\n- Meeting was called to order at 1 pm\n- Approval of Minutes from May, 25, 2022\n- Carmen’s Bias Report -- No reports were made.\n- Town of Huntington Scholarships $2500 each – submit application – with GPA and\nplans for their future. 250 word essay. 31 Applicants, 6 awardees. Final year of\nscholarship, because the contract is over with the sponsoring organization. A suggestion\nwas made to seek further funds – this needs a “champion” – someone to organize it.\nHelen, Roxane, and Bette Schneiderman will help with this. This project is added to the\nnew Project Management tool to keep track of it.\n- Upcoming Events:\nFirst Annual Huntington Family Pride Picnic - Sunday, June 26, 1 - 4 pm@Mill Dam Park.\nOrganized by Eric and Jim Rubin-Perez. There will be games for kids. HABTF will be there with a table.\nNational Night Out - August 2, 4 pm - dark\nHuntington’s 11th Annual Anne Frank\nMemorial Garden Ceremony\nby Carmen Kasper\nHuntington Town Supervisor Ed Smyth hosted the Town of Huntington’s 11th Annual Anne Frank Memorial Garden\nCeremony on Wednesday, June 22, at 4:30 PM at Town Hall (rain forced a change from the Anne Frank Memorial\nGarden at Arboretum Park in Melville).\nThe Anne Frank Memorial Garden symbolically captures the journey of Anne Frank’s life. It features a circular\npathway that surrounds a garden, which leads to the sculpture of a young girl’s dress. The Memorial Garden\nserves as tribute to Anne’s legacy of wisdom and genuine belief in the goodness of mankind and human nature,\ndespite the ugliness of war and discrimination.\nProgram participants included Rabbi Beth Klafter of Temple Beth David in Commack, Rabbi Yakov Saacks of\nThe Chai Center in Dix Hills, musical selections by Hazzan (Cantor) Steven Walvick of the East Northport\nJewish Center; and remarks from guest speaker Gail Sheryn Kastenholz, a Huntington Station resident, Second\nGeneration Survivor and Holocaust education advocate. Attendees of the Anne Frank Memorial Garden anniversary celebration\nwere offered light refreshments, donated by Suffolk County Legislator Manuel Esteban.\nClick here to watch the\nvideo of the event"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:a8417c78-0b97-4f43-95b6-6ae61b8d030b>"],"error":null}
{"question":"How do focal and generalized seizures differ in terms of brain involvement and patient awareness, and what are their genetic implications?","answer":"Focal and generalized seizures differ fundamentally in their brain involvement and awareness patterns. Focal seizures affect a restricted area of the brain and patients may retain awareness, meaning if they remember the seizure, it must have been focal. In contrast, generalized seizures involve the entire brain, with patients always losing awareness and having no memory of the event. Regarding genetic implications, while focal seizures may be linked to structural lesions, especially if warnings are consistent, generalized seizures often have genetic components. Several genes have been identified in absence epilepsy, including mutations in CACNA1H, GABRA1, GABRB3, and GABRG2, which are involved in neuronal activity and membrane function.","context":["by Harry Ingledew (Newcastle Medical Student)\nwith the occasional interruption from me\nWhat are seizures? – an Archie intro\nPut simply, and I am a simple person, a seizure is an electrical surge in the cortex – or at least that is one way to look at it. Basically, if I strap EEG leads onto your head, there will be a screen full of electrical squiggles (see below). Usually, they are all over the place and you have to have a different sort of degree, and a better quality EEG than mine, to make sense of them.\nI used to think the seizure was a chaos of activity but, actually, if you look at the tracing above, it is sort of the opposite. It’s almost as if suddenly, the complexity of cortical impulses, with all their nano-nuances, has been replaced by a rhythmical, coordinated electrical march across the brain. Little wonder that, when this happens, people behave oddly.\nTurns out, we function best when our brains are all over the place!\nWatch these two videos that illustrate how order can erupt from chaos. The first still perplexes me but I try to imagine, as the nails in the box line up, the same thing happening to some folk in the build up to a seizure.\nThe second is 2 of my kids on the swing. I should really have anchored it a bit better! When they swing out of phase, all is fine. When they swing in phase, it’s like the frame is about to tear out of the ground.\nSo, the deal is that there are loads of reasons for people to have seizures, and there are loads of different types of seizures. It can get pretty confusing if you are not careful. At it’s core, however, the concept if simple.\nThe next step is getting a handle on the different types of seizures that you might meet in your career as a doctor.\nTypes of seizure (over to you Harry)\nRight, so now we all know how to differentiate between a seizure, syncope, or non-epileptic attack (at least in theory), we can delve deeper into the types of seizure that patients can present with.\nThere are 2 main categories into which seizures can fall: focal and generalised.\nFocal seizures occur due to abnormal electrical activity that is restricted to a certain area of the brain – this can be a small area of cortex or extend to encompass much larger areas. By definition, it never involves the whole of the cortex, however.\nFocal seizures are subdivided into those in which the person does and does not retain awareness (as opposed to generalised seizures in which patients always lose awareness). Therefore, if a patient has any memory of their seizure it must have been, at least initially, focal.\nthis is a really crucial point and often glossed over. if you ask the right questions of your patient, and the witness, you can often not just diagnose the seizure but also whether it has a focal onset.\nFocal seizures in which the patient experiences a consistent, stereotyped warning each time may be due to a structural lesion. It is therefore useful to understand how focal seizures in each of the lobes present, as it can help to locate a lesion before even seeing a scan.\nConversely, if the warning changes with each seizure, it becomes less likely that a structural lesion is the source of the problem.\nFocal seizures can present with a myriad of weirdness; the type of weirdness depends on the area of the brain in which the electrical activity is occurring.\n- Frontal – the frontal lobe is tasked with a wide array of functions including being home to the motor centres and the control of behaviour and personality. Seizures in this area therefore include motor phenomena and changes in behaviour.\n- Parietal – the parietal lobe is mostly concerned with understanding sensory input; therefore, parietal lobe seizures may include feelings of warmth / tingling down one side of the body.\n- Occipital – seizures with a visual onset, often explosions of light or colours. Like a migraine aura but much shorter and more dramatic.\n- Temporal – seizures of the temporal lobes present with lots of very strange behaviour called automatisms which include actions such as lip-smacking, chewing, and blinking. As the temporal lobe is involved in memory, strange phenomena such as déjà vu (the feeling of having already experienced the current situation) and jamais vu (a feeling that the situation is very unfamiliar) may also occur.\nFocal seizures often remain focal, but can progress and become generalised.\nYou can see an example of a focal seizure in the lecture I mentioned at the top of the page.\nGeneralised seizures occur due to abnormal electrical activity that engulfs the entire brain, and is not restricted to a single hemisphere. Patients typically do not receive any warning of an incoming generalised seizure and, after the event, they will have no memory of what occurred (other than feeling terrible).\nThere are many types of generalised seizure, but there are 2 key types to learn:\nAbsence – previously called “petit mal”, and often still referred to as this by patients. When was the last time you found yourself daydreaming? When we daydream, which for most people occurs every day, we are often described as being “absent”. This is very different however, from an absence.\nAn absence is a type of generalised seizure in which the patient suffers a brief loss of awareness. Absence seizures almost always begin in childhood and the classic story is of a child who will completely stop talking in a conversation, stare blankly for 5-10 seconds and then “3, 2, 1, they’re back in the room”, continuing where they left off with no awareness that they just had a seizure.\nHave a look at these two videos. They show how brief the attacks can be. Hyperventilation can bring them on and this is often used during EEG recordings to increase the diagnostic yield.\nGeneralised tonic-clonic (grand mal) – This is what most people think of when they think of a seizure. But what does it actually mean? Well, lets break the name down. As we said earlier, “generalised” means the entire brain is affected, the patient gets no warning, and no memory after the event. First there is a “tonic” phase in which the person will go completely stiff and fall to the ground. Then comes the “clonic” phase, in which all 4 limbs will begin to convulse violently, often resulting in injury to themselves and people around them.\nIf you see one of these as a doctor, try to make sure that you describe it in as much detail as possible. It's really annoying if people just write \"GTC x1\" in the notes. Far better to say \"patient sent stiff, arched neck and back, let out a tight cry, arms extended, legs extended, stiff for 30 seconds, not responding, then jerking of arms and legs, blue lips, low sats, then cessation over 60 secs, gradual recovery over 5-10 minutes but confused and agitated\". The second description helps me in the next day, and possibly forever more!\nHere is a good example of a generalised tonic-clonic seizure. Notice all the different phases of the attack (and how calm the nurses are – no need for a crash call!). The head turn might suggest a focal onset, just for the record, but with very rapid generalisation.\nIt is possible to make it a tonne more complicated, and there is an relentless desire to keep reclassifying things, seemingly just when everyone had got the hang of the last classification.\nCurrently, this is the \"official\" International League Against Epilepsy classification (2017). Bet they reclassify it again soon, just to keep us on our toes.\n|Focal seizures affect one part of the brain, generalised affect both hemispheres|\n|If they get a warning or have a memory it is focal|\n|Focal seizures may be due to a structural lesion, particularly if the warning is consistent|\n|The symptoms of a focal seizure help to locate the problem|\n|Being absent is different from an absence seizure|\nEpilepsy – what is it?\nSo, we have spoken a lot about the types of seizure people can have, but we haven’t actually mentioned epilepsy at all. This is because simply having a seizure doesn’t necessarily mean it is epilepsy. Epilepsy is the tendency to have recurrent seizures.\nEpilepsy is very common, affecting around 600,000 people in the United Kingdom.\nEpilepsy can occur for a vast array of reasons, but the exact cause is not found in many. Underlying brain diseases that can result in epilepsy include:\n- a genetic predisposition\n- brain injury – stroke, trauma, bleed, AVM\n- developmental abnormalities\nOlder age at onset of epilepsy increases the likelihood that the cause is a structural lesion. These patients will receive a CT or MRI scan to rule this out – preferably an MRI in this day and age.\nThere are many types of primary epilepsy syndrome but, unless you’re a consultant neurologist (in which case you wouldn’t need me to explain any of this to you), there is no reason for you to learn them all. There is one, however, that is worth learning a little bit about – Juvenile Myoclonic Epilepsy (JME).\nthis is because within JME are lessons for how to approach the history, examination and investigation of all patients with epilepsy\n- Onset is in adolescence (<30 years of age)\n- Everyone with JME has myoclonic jerks (rapid, short-lived, uncontrolled movements), particularly when tired, typically when first awaking in the morning. They often report dropping their breakfast or spilling their tea soon after waking up. This is different from the physiological twitches and jerks many of us experience as we drift off to sleep, so please don’t go self-diagnosing with JME.\n- Generalised tonic-clonic seizures are also common in JME\n- Patients with JME often also have absence seizures\n- JME can be diagnosed via an EEG as it has a very classical trace (more about this later)\nThe diagnosis that a blackout event is a seizure, rather than syncope, is often a clinical decision. A history of recurrent seizures is therefore indicative of epilepsy. It is important, however, to try and establish the cause of the epilepsy to rule out any serious, underling brain disease.\nDespite the array of complex, often unnecessary, neurological tests that are often all too tempting to order straight away, when a patient presents with any kind of blackout the most important first test that should always be done is an ECG, to check for common cardiac problems that cause blackouts. A full cardiac assessment, including a 24-hour ECG trace and an echo may also be necessary.\nScans of the brain such as CT and MRI can be used to look for structural problems in the brain that may be causing the seizures. A consistent warning indicates the seizure is focal, meaning there is a focus, therefore potentially a lesion that could be identified on a scan.\nTo use one of Dr Archibald’s favourite phrases, an EEG (Electroencephalogram) “is as useful as a chocolate teapot” in most situations.\nIf a patient has presented with what clinically sounds like a frontal lobe seizure, and an MRI is done showing a tumour in the frontal lobe, an EEG isn’t going to add anything useful to the scenario.\nThere are, however, times when an EEG is useful. Some primary epilepsy syndromes, such as JME, have classic EEG signatures. As a rule, the younger the patient, the more likely the EEG will help.\nThere is an endless list of potential treatments and medications for epilepsy and understanding them all would be incredibly complicated – so don’t bother!\nThe good news is that for many patients with epilepsy, a single drug can stop their attacks. It can get much more difficult after that, but there are reasons for optimism when starting out, particularly if investigations are reassuring (no structural cause on MRI).\nMany anti-epileptic medications have side-effects, including confusion, headache, tremors and weight gain. As well as these some are teratogenic, causing foetal malformation if taken in pregnancy. Medications like sodium valproate should be avoided in all women of childbearing in age, because of this, and there is a concerted effort to ensure this is the case in the UK.\nThere is, however, a nice simple rule that will help you choose the right medication for your patient, if you find yourself in the rare situation of needing to start a patient on anti-epileptic medication as a junior doctor.\n“If it doesn’t begin with L, then don’t prescribe it”\nLamotrigine and Levetiracetam (commonly called Keppra) tend to be best tolerated and are often effective for both focal and generalised seizures – they are great all-rounders. They are not without their own problems, of course, but this is a decent rule of thumb.\nThe management of epilepsy during pregnancy is a balancing act. Too much medication increases the risk of foetal malformations, but reducing the medication too far increases the risk of having seizures, which in-turn can also cause damage to both mother and foetus.\nit is beyond the scope of this article to cover a definitive guide to epilepsy management, and better brains than mine are required. I will put some links that you might find helpful at the bottom.\nStatus epilepticus (SE) is a medical emergency in which a seizure lasts more than 5 minutes, or there is incomplete recovery between subsequent seizures. Previously, SE was defined as a seizure lasting more than 30 minutes, but this was changed in order to ensure earlier treatment. The earlier you can intervene the better – seizures beget seizures so letting them run too long means they are harder to stop, and have worse effects on the brain itself.\nSE either occurs due to pre-existing brain disease or a new change in the brain. It is therefore vital to find the underlying cause in a patient without a diagnosis that could explain the SE.\nPrompt management with a benzodiazepine, such as IV lorazepam is vital, preferably as soon as SE is suspected. Buccal midazolam is often given pre-hospital by paramedics. If benzos fail to control the seizure, IV phenytoin should be used but, hopefully, senior help has arrived by then and as a junior doctor you shouldn’t need to give this. Often, if the phenytoin doesn’t work then your patient is on their way to ICU.\ndon't fiddle about with crappy little doses of iv medication in status. if you are gonna load, LOAD! As a rule of thumb, most adults with decent kidneys and livers will need around 1.5g of iv something (phenytoin, valproate, levetiracetam). It doesn't really matter what (as long as it's not iv bleach, Donald)\nThis link to the NICE guidelines isn’t pretty, but it does cover the standard approach in the UK.\nThe SIGN guidelines are often a bit more readable. This link will take you there.\nSudden unexpected death in epilepsy (SUDEP)\nIf well managed, most people with epilepsy will have a normal life expectancy. Sometimes, however, a person with epilepsy may die during or soon after a seizure for no apparent reason. SUDEP most commonly occurs while a person is asleep. Around 1/1000 patients with epilepsy may die unexpectedly.\nSUDEP tends to be more common in those who experience frequent GTC seizures and those whose epilepsy is poorly-controlled. Better seizure control, with good compliance to an appropriate medication regimen, is therefore the best way to prevent SUDEP.\nDon’t worry about this, but I thought it was worth having an awareness that many neurological disorders can cause problems with driving and require notification of the DVLA.\nWhen someone has a blackout of any kind, fulfillment of all of the 3P’s are the key to being allowed to continue to drive. They indicate that the event was almost certainly provoked syncope, rather than an unprovoked seizure, making driving much safer.\nMake sure you get the 3 P’s straight in your head, and in the notes, and you will be well on your way.\n- Posture – the blackout occurred during a change in posture, such as rapidly standing up from a chair, or a prolonged period of standing\n- Prodrome – the event was preceded by feeling warm, nauseous, and unwell\n- Precipitating factors – the event happened at a time of pain, fear, or stress, such as when having blood taken\nDriving is a crucial consideration after a seizure or blackout. Always check if your patient drives and, if they do, tell them they need to stop until they have spoken to the DVLA. Remember, it is the DVLA that ultimately license us to drive - not you. You must be clear in both your advice and your documentation of this advice.\nThis link takes you to the DVLA guidelines. It is often helpful to look at these with your patient, so they know what to expect.\nUseful references and articles\nUseful article on the first fit, and how to approach it.\nThese “Bare Essentials” articles always age well and this is no exception. Worth a read.\nA tour de force in the Lancet – you will need your best library access for this one I’m afraid – they are mean at the Lancet!","Childhood Absence Epilepsy\nChildhood absence epilepsy (CAE) is a form of hereditary pediatric epilepsy, characterized by very frequent absence seizures. This formusually soccurs in children between the ages of 4 and 10 years and in most cases has a good prognosis. CAE accounts for 10-17% 1, 4 of all cases of epilepsy diagnosed in school-aged children 1 and its incidence has been estimated at 1-8 per 100,000 2, 3. Females are usually more affected than males, representing 60-76% of patients 4.\nChildhood absence epilepsy is characterized by frequent absence seizures with abrupt onset and offset. Photosensitivity is reported in 18% of CAE patients. In rare cases CAE is also associated with increased rates of adverse behavioral, psychiatric, language, and subtle cognitive changes, including attention deficit hyperactivity disorder (ADHD), anxiety, and depression.\nThe main clinical characteristics of absence childhood epilepsy include the following 5:\n- Onset in children of school age (peak manifestation 6–7 years)\n- Very frequent (multiple per day) absences\n- EEG with bilateral, synchronous, symmetrical spike-waves, usually at 3 Hz\n- Development of generalized tonic-clonic seizures occurring during adolescence.\nAbsence seizures are brief, most commonly lasting 5-10 seconds with an abrupt start and end. They occur frequently, 10-100 times a day 5. Seizures occur spontaneously but may be precipitated by multiple factors, including emotional, intellectual, or metabolic. The main feature of absence seizures is loss of responsiveness with cessation of ongoing activity.\nDepending on the associated symptoms, following types of absence seizures can be identified 5:\n- Simple absence, manifesting only as impaired consciousness (10%)\n- Absence with mild clonic components, usually involving the eyelids (50%)\n- Absence with atonic components, resulting in gradual lowering of the head or arms (20%)\n- Absence with tonic components (rotating the eyes upwards)\n- Absence with automatisms that are either perseverative (i.e., the patient persists in what he is doing) or de novo, such as lip smacking or swallowing (60%)\n- Absence with autonomic components (e.g., pupillary dilatation, flushing, tachycardia).\nChildhood absence epilepsy is genetically determined, and mutations in several genes have been reported so far (Table):\n- The CACNA1H gene encodes voltage-entdependent calcium channel expressed in neurons. Mutations in CACNA1H have been reported in childhood absence epilepsy (16/49), idiopathic generalized epilepsy (10/49), hyperaldosteronism (2/49), and other conditions, mostly characterized with seizures (HGMD® Professional 2017.1). Missense mutations in CACNA1H have recently been associated with amyotrophic lateral sclerosis 6.\n- The GABRA1 gene encodes GABA receptor protein, thus participating in neuronal membrane activity. Therehave been 35 mutations reported in this gene so far (HGMD® Professional 2017.1), reported as disease-causing for epileptic encephalopathy (10/35), Dravet syndrome (3/35), early infantile epileptic encephalopathy (2/35), childhood absence epilepsy (1/35), and other epilepsy-related phenotypes. Small deletion c.975delC was reported in a family affected with childhood absence epilepsy 7.\n- GABRB3 also encodes the GABA receptor protein, and 50 different variants have been reported in this gene so far, in association with autism spectrum disorders (18/50), epileptic encephalopathy (15/50), childhood absence epilepsy (1/50) and other epilepsy-related conditions (HGMD® Professional 2017.1).\n- The GABRG2 gene encodes additional GABA receptor protein, and so far the mutations in this gene have been associated primarily with generalized epilepsy with febrile seizures (7/26). Mutations in GABRG2 have also been associated with Rolandic epilepsy (2/26), childhood absence epilepsy (2/26), generalized epilepsy (2/26), and others.\n- Missense mutation c.1367C>T, p.T456MJRK reported in the JRK gene was associated with childhood absence epilepsy that evolved to juvenile myoclonic epilepsy 8.\n- The SLC2A1 gene encodes glucose transporter 1 expressed in brain, placenta, and erythrocytes. Mutations in this gene have been associated with GLUT 1 deficiency syndrome (203/253), absence epilepsy (10/253), idiopathic generalized epilepsy (9/253), intellectual disability (4/2539 and other conditions. Heterozygous SLC2A1 pathogenic variants (p.Arg212Cys and p.Arg126Cys) have been reported as disease-causing in patients affected with dystonia 9 9.\nTreatment of CAE involves the use of antiepileptic drugs such as ethosuximide, valproate, and lamotrigine. However, lack of response is common. An alternative choice for patients with CAE and photosensitivity could be the drugs levetiracetam or topiramate.\nCENTOGENE offers sequencing and deletion/duplication analysis for the Childhood absence epilepsy panel (genes: CACNA1H, GABRA1, GABRB3, GABRG2, JRK, SLC2A1). Wealso offer single gene tests for each gene included in the panel.\nThe differential diagnosis of childhood absence epilepsy-related disorders – depending on the major symptoms in the initial case – includes the following diseases:\n- Epilepsy with myoclonic absences\n- Jeavons syndrome\n- Juvenile absence epilepsy\n- Perioral myoclonia with absences\n- Juvenile myoclonic epilepsy\n- Encephalopathy due to GLUT1 deficiency\n- Absence seizures associated with chromosomal anomalies (ring chromosome 20, 15q13.3 microdeletion syndrome).\nCENTOGENE offers an advanced, fast and cost-effective strategy to test large NGS panels and diagnose complex phenotypes based on PCR-free whole genome sequencing and NGS technology. This approach offers an unparalleled advantage by reducing amplification/capture biases and providing sequencing of the entire gene with more uniform coverage.\nTo confirm/establish the diagnosis, CENTOGENE offers the following testing strategy for childhood absence epilepsy using NGS Panel Genomic targeted towards this specific phenotype:\nStep 1: Whole genome sequencing from a single filter card. The sequencing covers the entire gene (coding region, exon/intron boundaries, intronic and promoter) for all the genes included in the Childhood absence epilepsy panel. Copy Number Variants analysis derived from NGS data is also included.\nStep 2: If no mutation is identified after analysis of the Childhood absence epilepsy panel, we further recommend continuing the bioinformatics analysis of the data using whole genome sequencing to cover those genes which are either implicated in an overlapping phenotype or could be involved in a similar pathway but are not strongly clinically implicated based on the current information in literature.\nThe following individuals are candidates for childhood absence epilepsy gene testing:\n- Individuals with a family history of childhood absence epilepsy and presentation of the most common symptoms\n- Individuals without a positive family history, but with symptoms resembling childhood absence epilepsy\n- Individuals with a negative but suspected family history, in order to perform proper genetic counseling (prenatal analyses are recommended in families with affected individuals).\nSequencing, deletion/duplication of childhood absence epilepsy related genes should be performed in all individuals suspected of having this particular phenotype. In parallel, other genes reported to be related with childhood absence epilepsy should also be analyzed for the presence of mutations, due to the overlap in many clinical features caused by those particular genes.\nConfirmation of a clinical diagnosis through genetic testing can allow for genetic counseling and may direct medical management. Genetic counseling can provide a patient and/or family with the natural history of childhood absence epilepsy, identify at-risk family members, provide reproductive risks as well as preconception/prenatal options, and allow for appropriate referral for patient support and/or resources."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:2b3a7bb2-e964-41e4-9d81-12a8b0289095>","<urn:uuid:48020ce7-2a0d-4499-845c-c5abdc37a891>"],"error":null}
{"question":"Between BPA atmospheric releases and ballast water discharge, which has faced stricter regulatory control in recent years?","answer":"Ballast water discharge has faced stricter regulatory control in recent years. While BPA atmospheric releases are monitored, no specific regulations are mentioned for controlling them. In contrast, ballast water has been regulated globally through the International Maritime Organization's Ballast Water Management Convention (effective 2017) and nationally in the US through multiple measures: the National Invasive Species Act (1996), Coast Guard regulations (2012), and EPA's Vessel General Permit (2013). These regulations require specific management plans, discharge limits, certification, and detailed record-keeping for ballast water.","context":["Water contamination by endocrine and hormone disrupting chemicals is threatening global water conditions. Numerous studies have proven that harmful concentrations of BPA have been leached into waterways from pollution, but little is known about how atmospheric releases of BPA might affect water quality. Now, researchers at the University of Missouri and the U.S. Geological Survey have assessed water quality near industrial sites and wastewater treatment plants and have discovered that atmospheric releases create a concern for environmental, animal and human health.\nHere’s the press release:\nCOLUMBIA, Mo. – Water contamination by hormone-disrupting pollutants is threatening water quality around the world. Existing research has determined that harmful concentrations of Bisphenol-A (BPA), a chemical used in consumer products such as plastic food storage and beverage containers, have been deposited directly into rivers and streams by municipal or industrial wastewater. Now, researchers from the University of Missouri and the U.S. Geological Survey (USGS) have assessed Missouri water quality near industrial sites permitted to release BPA into the air. As a result, scientists now believe that atmospheric releases may create a concern for contamination of local surface water leading to human and wildlife exposure.\n“There is growing concern that hormone disruptors such as BPA not only threaten wildlife, but also humans,” said Chris Kassotis, a doctoral candidate in the Division of Biological Sciences in the College of Arts and Science at MU. “Recent studies have documented widespread atmospheric releases of BPA from industrial sources across the United States. The results from our study provide evidence that these atmospheric discharges can dramatically elevate BPA in nearby environments.”\nWater sampling sites were selected based on their proximity to the Superfund National Priorities List (NPL) or locations with reported atmospheric discharges of BPA as identified by the Environmental Protection Agency. Current or historical municipal wastewater treatment sites, which have been shown in the past to contribute hormonally active chemicals to surface water from urban or industrial sources, also were tested. Finally, relatively clean sites were chosen to serve as the control group.\nThe water then was analyzed for concentrations of BPA, Ethinyl estradiol (EE2), an estrogen commonly used in oral contraceptive pills, and several wastewater compounds. Scientists also measured the total estrogen and receptor activities of the water. This approach is used to measure all chemicals present in the water that are able to bind to and activate (or inhibit) the estrogen or androgen receptors in wildlife and humans. Levels of chemicals were highest in samples with known wastewater treatment plant discharges.\n“In addition, we were startled to find that BPA concentrations were up to ten times higher in the water near known atmospheric release sites,” said Don Tillitt, adjunct professor of biological sciences at MU, and biochemistry and physiology branch chief with the USGS Columbia Environmental Research Center. “This finding suggests that atmospheric BPA releases may contaminate local surface water, leading to greater exposure of humans or wildlife.”\nConcentrations of BPA measured in surface water near these sites were well above levels shown to cause adverse health effects in aquatic species, Kassotis said.\nThe study, “Characterization of Missouri surface waters near point sources of pollution reveals potential novel atmospheric route of exposure for bisphenol A and wastewater hormonal activity pattern,” was published in the journal, Science of the Total Environment, with funding from the University of Missouri, the U.S. Geological Survey Contaminants Biology Program (Environmental Health Mission Area), and STAR Fellowship Assistance Agreement no. FP-91747101 awarded by the U.S. Environmental Protection Agency. The views expressed are those of the authors and of the U.S. Geological Survey; however, they are not the views of the U.S. Environmental Protection Agency. Any use of trade, firm, or product names is for descriptive purposes only and does not imply endorsement by the U.S. Government.\nSource: (formerly the MU News Bureau)\nDivision of Marketing & Communications University of Missouri, http://munews.missouri.edu","Ballast water discharge and the environment\nBallast water discharges by ships can have a negative impact on the marine environment. The discharge of ballast water and sediments by ships is governed globally under the Ballast Water Management Convention, since its entry into force in September 2017. It is also controlled through national regulations, which may be separate from the Convention, such as in the United States.\nCruise ships, large tankers, and bulk cargo carriers use a huge amount of ballast water, which is often taken on in the coastal waters in one region after ships discharge wastewater or unload cargo, and discharged at the next port of call, wherever more cargo is loaded. Ballast water discharge typically contains a variety of biological materials, including plants, animals, viruses, and bacteria. These materials often include non-native, nuisance, exotic species that can cause extensive ecological and economic damage to aquatic ecosystems, along with serious human health issues including death.\nThere are hundreds of organisms carried in ballast water that cause problematic ecological effects outside of their natural range. The International Maritime Organization (IMO) lists the ten most unwanted species as:\n- Cholera Vibrio cholerae (various strains)\n- Cladoceran Water Flea Cercopagis pengoi\n- Mitten Crab Eriocheir sinensis\n- Toxic algae (red/brown/green tides) (various species)\n- Round Goby Neogobius melanostomus\n- North American Comb Jelly Mnemiopsis leidyi\n- North Pacific Seastar Asterias amurensis\n- Zebra Mussel Dreissena polymorpha\n- Asian Kelp Undaria pinnatifida\n- European Green Crab Carcinus maenas\nBallast water issues by country\nThe ballast tanks in New Zealand carry animals and plants that kill ecosystems. Ballast tanks are only used in cargo ships there. Ballast water is controlled under the Biosecurity Act 1993.\nThe zebra mussel, which is native to the Caspian and Black Seas, arrived in Lake St. Clair in the ballast water of a transatlantic freighter in 1988. Within 10 years it had spread to all of the five neighbouring Great Lakes. The economic cost of this introduction has been estimated by the U.S. Fish and Wildlife Service at about $5 billion.\nBallast water discharges are believed to be the leading source of invasive species in U.S. marine waters, thus posing public health and environmental risks, as well as significant economic cost to industries such as water and power utilities, commercial and recreational fisheries, agriculture, and tourism. Studies suggest that the economic cost just from introduction of pest mollusks (zebra mussels, the Asian clam, and others) to U.S. aquatic ecosystems is more than $6 billion per year.\nCongress passed the National Invasive Species Act in 1996 in order to regulate ballast water discharges. The Coast Guard issued ballast water regulations in 2012. Under the authority of the Clean Water Act, the Environmental Protection Agency (EPA) published its latest Vessel General Permit in 2013. The permit sets numeric ballast water discharge limits for commercial vessels 79 feet (24 m) in length or greater. EPA issued a separate permit for smaller commercial vessels in 2014.\nAmong 818 ports in the Pacific region, Singapore alone accounts for an estimated of 26 percent of cross-region (long range) species exchange. Via targeted ballast management on Singapore and a few other \"influential\" ports, cross-region species exchange to/from the Pacific region can be combinatorially reduced.\nTo react to the growing concerns about environmental impact of ballast water discharge, the International Maritime Organization (IMO) adopted in 2004 the \"International Convention for the Control and Management of Ships' Ballast Water and Sediments\" to control the environmental damage from ballast water. The Convention will require all ships to implement a \"Ballast water management plan\" including a ballast water record book and carrying out ballast water management procedures to a given standard. Guidelines are given for additional measures then the guidelines.\nThe goals of the convention are to minimise damage to the environment by:\n- Minimise the uptake of organisms during ballasting.\n- Minimising the uptake of sediments during ballasting.\n- Ballast water exchange while at sea (the ship should be minimum 200 nautical miles from shore with a depth of minimum 200 metres and can use the flow through or sequential method). At least 95 percent of the total ballast water should be exchanged.\n- Treatment of the ballast water by chemical or mechanical influences (UV-radiation, filter, deoxygenation, cavitation, ozone…)\nControl measures include:\n- International Ballast Water Management Certificate\n- Ballast water management plan\n- Ballast water record book\nThe IMO convention was ratified by enough countries and entered into force on September 8, 2017.\n- \"International Convention for the Control and Management of Ships' Ballast Water and Sediments\". International Maritime Organization.\n- Living Beyond Our Means: Millennium Ecosystem Assessment, 2005. Statement from the Board.[full citation needed]\n- Statement of Catherine Hazlewood, The Ocean Conservancy, “Ballast Water Management: New International Standards and NISA Reauthorization,” Hearing, House Transportation and Infrastructure Subcommittee on Water Resources and Environment, 108th Cong., 2nd sess., March 25, 2004.\n- David Pimentel, Lori Lach, Rodolfo Zuniga, and Doug Morrison, “Environmental and Economic Costs Associated with Non-indigenous Species in the United States,” presented at AAAS Conference, Anaheim, CA, January 24, 1999.\n- United States. Pub. L. 104-332. October 26, 1996.\n- U.S. Coast Guard, Washington, D.C. \"Standards for Living Organisms in Ships’ Ballast Water Discharged in U.S. Waters.\" Federal Register, 77 FR 17254, 2012-03-23.\n- \"Vessels Incidental Discharge Permitting\". National Pollutant Discharge Elimination System (NPDES). Washington, D.C.: U.S. Environmental Protection Agency (EPA). 2015-12-09.\n- EPA (2014-09-10). \"Final National Pollutant Discharge Elimination System (NPDES) Small Vessel General Permit for Discharges Incidental to the Normal Operation of Vessels Less Than 79 Feet.\" Federal Register. 79 FR 53702.\n- Xu, Jian; Wickramarathne, Thanuka L.; Chawla, Nitesh V.; Grey, Erin K.; Steinhaeuser, Karsten; Keller, Reuben P.; Drake, John M.; Lodge, David M. (2014). \"Improving management of aquatic invasions by integrating shipping network, ecological, and environmental data\": 1699–1708. doi:10.1145/2623330.2623364.\n- \"Ballast Water Convention to Enter into Force in 2017\". Maritime Executive. 8 September 2016. Retrieved 14 September 2016.\n- Buck, Eugene H.(2012). \"Ballast Water Management to Combat Invasive Species.\" U.S. Congressional Research Service. Report No. RL32344."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:be3963dc-1773-4729-bf79-38ff08ccab00>","<urn:uuid:e9749ea3-2ea0-436c-95fd-f59b7fb5adc2>"],"error":null}
{"question":"What's the deal with exotic woods like Purpleheart and Zebrawood - how unique are they and what's their sustainability status?","answer":"Exotic woods like Purpleheart and Zebrawood have distinctive characteristics - Purpleheart transforms from light brown to deep purple when exposed to UV light and comes in over 20 varieties, while Zebrawood features unique black and creamy brown patterns resembling zebra print. However, regarding sustainability, these tropical woods require careful consideration. Since they grow in South America and Africa respectively, they travel long distances to reach consumers, making them less sustainable than local woods. Additionally, many tropical areas where exotic woods are harvested have not been responsibly managed, and their over-harvesting can cause environmental, political, and social harm to indigenous peoples. Experts recommend using local wood sources that can be verified for responsible management practices.","context":["We use a variety of different wood species at SoKno Woodworking. Some of them are domestic woods that grow here in the United States. A few of our products are made from trees that grew in Tennessee. Other types are exotic woods that grow in different countries around the world.\nMost trees have three layers: bark, sapwood, and heartwood. Bark is the outermost layer and protect the trees from the elements. This layer is typically cut away in the milling process and occasionally left on for a \"live edge\" look. The sapwood is the adjacent layer and is used by the tree to carry water and nutrients throughout the tree. It is typically lighter in color. The heartwood is the centermost layer and is usually the desired wood for use. This layer ranges in color depending on species.\nBlack Walnut- This is my personal favorite wood to work. I love the deep dark color of the heartwood. Walnut trees provide edible nuts in the fall. Their wood is highly desired due to its color, strength, and grain patterns. The tight grains are close together and prevent bacteria from seeping down into the pores. This makes it an excellent choice for cutting boards.\nPecan- This wood also produces an edible nut in the fall. Its wood is creamy colored and extremely hard. Pecan wood is similar to Hickory, which is considered one of the most hard and resilient woods available domestically. This wood also has tight grains and is excellent for cutting board use.\nCherry- This type of tree is the wild cherry and not the domesticated type. Its heartwood is reddish in color and has beautiful grain patterns. It is a hardwood with tight grains, which make it great for cutting boards.\nHard Sugar Maple- This tree is the same tree that produces maple syrup. It has a very light colored heartwood that is almost white. It has very consistent grain patterns. It is the gold standard for cutting board woods.\nEastern Red Cedar- This wood is an aromatic softwood. It is naturally weather and insect resistant. The color consists of a reddish heartwood and whitish colored sapwood.\nDouglas Fir- This tree grows all over the US but is primarily grown for commercial use in the NorthWest. It is naturally weather and insect resistant. The color is a creamy reddish light brown. It is a soft wood used for construction. It is a favorite to wood boring bees because they can easily bore through its softwood. This is why we use it to create our bee traps.\nBocote- This wood is considered to be the most expensive wood per board foot of commonly available exotic wood. It has a beautiful wood grain pattern of black and golden brown. These trees grow in Central America and the West Indies.\nSpalted Tamarind- This wood is a beautiful white color. The spalting describes the dark streaks that run throughout the grains. The streaks are formed by microbes that enter the wood, leaving behind their marks. These trees are native to Africa.\nLeopardwood- This wood is very unique. It naturally has patterns in it that resemble leopard print. It is a pinkish color. These trees grow in Central America.\nPurpleheart- This wood has one of the brightest and most beautiful colors in nature. It grows a lightish brown color. However, once cut and exposed to UV light, it turns into a deep dark purple color. There are over 20 different varieties of purpleheart trees that each provide their own unique color. These trees grow in South America.\nYellowheart- This wood is a pleasant yellowish gold color. These trees are cousins to the purpleheart variety and also grow in South America.\nPadauk- This wood is a very unique species due to its deep dark red color. It tends to fade in sunlight and requires a UV protective finish. These trees grow in Africa.\nZebrawood- This wood is very unique due to its wood grain pattern. The pattern is a sequence of black and creamy brown, which resembles zebra print. These trees grow in Africa.\nMarblewood- This wood produces a grain pattern similar to marble. It has a pleasant light yellow and orangish pattern. These trees grow in South America.","The most sustainable wood choices for your building projects are woods that are grown locally and are well managed. Depending on where you live, the best type of sustainable wood will vary. However, nature tends to be smarter than we are. If your local wood producer is managing certain types of trees, they will likely work well for your building projects.\nFor example, Mathew Kelty, who teaches about forest ecology at the University of Massachusetts, Amherst said “In the northwest, Douglass fir is everywhere. There is also a lot of western red cedar, which is soft, but doesn’t decay. It’s often used for shingles for that reason.” Kelty added that in the northeast region a lot of spruce and fir is used due to its abundance. DIY Resource: http://www.networx.com/article/managed-forests-make-for-more-sustainabl\nThe idea of sustainable wood products is larger than what specific woods to use. Sustainability in relation to wood products has more to do with appropriate land management, biodiversity of plants and animals, and the integrity of the soil according to Emily Boss, director of the Massachusetts Woodlands Institute. “We prefer to use the term ‘responsible management’ of wood over ‘sustainable,’” said Boss. “Responsible management is the goal,” she added.\nWhen you are looking for sustainable wood products, it is important to know if they are certified woods and by whom. One of the best certifications comes from the Forest Stewardship Council. The FCS logo is an excellent indicator that you have chosen woods that have been properly and responsibly managed. It is also a good idea when researching local sustainable wood sources to look at certifications your state provides. Boss said in Massachusetts, for example, a new certification was created approximately a year ago called the Commonwealth Quality program. There are also similar programs in Vermont and Maine, Boss said. “There are no quick answers (regarding sustainable wood products). But, FCS takes into account how the workers are being treated, indigenous people’s issues; there are a lot of variable when talking about sustainable wood products,” said Boss.\nThe best sustainable woods travel the least distance from harvest to consumer. “Local soft and hardwoods use less energy to transport. If you are supporting a local business, you can get to know then, know how high their land management standards are,” said Boss. Boss said that good land management also take invasive species such as bittersweet and and wild rose into account as they take over and are destructive to native trees and plants.\nBoss said that typically in the New England region, oak, white pine, sugar maple, red maple, and birch are the most commonly used woods for lumber production. It’s also good to know where the wood is being processed. In other words, do you have a local saw mill? DIY Resource: http://www.hometalk.com\nBeware of using tropical woods such as teak, rosewood or ebony for custom woodworking. Many tropical areas of the world where these woods are harvested have not been responsibly managed, and over-harvesting often causes environmental, political and social harm to indigenous peoples.\nTo sum up how to find the most sustainable woods, look for certified woods from managed forests that travel the shortest distance from harvest to consumer."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:de6f7f2b-0cd2-4f80-9685-aa4982c9dadb>","<urn:uuid:b46c9caa-dfa8-44bd-a9c9-e36d1684f406>"],"error":null}
{"question":"How do the early psychosocial stages (0-5 years) differ between Erikson's original theory and his revised version in terms of their impacts on child development?","answer":"Both versions describe three similar early stages, but with subtle differences in their impacts. In the original theory, the first stage (0-1 years) focuses on developing basic trust, where absence of caregiver leads to mistrust and anxiety. The revised version extends this stage to 0-18 months and emphasizes that good parental care leads to confidence and security, while poor care leads to general mistrust. The second stage (originally 1-3 years vs 18 months-3 years in revised) focuses on autonomy development, with the revised version adding emphasis on self-esteem building and learning right from wrong. The third stage (3-6 years in original vs 3-5 years in revised) centers on initiative development, with the revised theory specifically highlighting increased curiosity and adult imitation, while maintaining that lack of early care leads to reduced confidence in taking on roles.","context":["Flashcards in Social Development Deck (29):\nWhat is social development\n* An individuals social interactions and expectations change across their lifespan.\n* Social and cultural environments interact with biological aging\nDescribe Erikson's Life Span Theory\n* At each stage (8) the individual is faced with a psycho-social crisis which can have either a positive or negative impact on personality development.\nWhat happens if you pass a stage of Erikson's Life Span theory?\nSuccessful completion of each stage results in a positive, healthy personality.\nWhat happens if you cannot pass a stage of Erikson's Life Span theory?\nFailure to successfully complete a stage can result in a reduced ability to complete further stages and therefore a more unhealthy personality and sense of self.\nBasic Trust v Mistrust\nStage one: 0-1 years\nDevelop sense of trust.\nCaregiver provides basic life necessities.\nAbsence of carer leads to mistrust, insecurity and anxiety.\nAutonomy v Self-doubt\nStage two: 1-3 years\nExploring and manipulation of world around them.\nDevelops sense of capability and worth.\nExcess restriction or criticism can lead to self-doubt.\nInitiative v Guilt\nStage three: 3-6 years\nBegins to initiate intellectual and motor skills.\nDevelop sense of freedom which turns into self-confidence.\nCan produce feelings of guilt, ineptitude and lack of self-worth.\nIndustry v Inferiority\nStage four: 6-11 years\nDeveloping competencies (mainly from school)\nLearning intellectual and motor skills.\nDeveloping social skills.\nFeelings of adequacy.\nCan lead to lack of self-confidence and failing feelings.\nIdentity v Role Confusion\nStage five: 11-20 years\nCrisis of discovering true identity.\nActing in different ways depending on who you are with.\nGain strong sense of self.\nFragmented sense of self when not achieved.\nIntimacy v Isolation\nStage six: 20-40 years\nDevelop capacity to make emotional, moral and sexual commitment.\nGenerativity v Self-absorption\nStage seven: 40-65 years\n30's-40's focus shifts from self and family to work, society and future generations.\nIntegrity v Despair\nLook back on life\nResolving earlier conflicts allows one to look back without regret.\nSense of wholeness, basic satisfaction with life.\nCan lead to feelings of futility (pointlessness, uselessness) and disappointment.\nWhat is temperament?\nBiologically based levels of emotion and behaviour responses to the environment.\nDescribe the findings of Kegan's (2004) study and longitudinal studies of temperament\n\"Born shy\" - cautious and emotionally reserved.\n\"Born bold\" - sociable, effectively spontaneous.\nOne's temperament will remain relatively unchanged over their lifespan and their temperament as an infant sets up for later social development.\n* close emotional connection/relationship.\n* child-Mother/Father/caregiver bond .\n* Intense, enduring social, emotional relationship.\n* Ensures survival (biological reason)\nDescribe Bowlby's theory of attachment\n* Biological predisposition to form attachment (both infant and carer)\n*attachment is created from 4 weeks old and strengthened until 6 months\n* Creates a lifetime model for social relationships (securer attachment in infancy may lead to securer attachment in later relationships)\nDescribe the method and the 4 findings of Ainsworth's strange situation research\nDemonstrated by 60-70%\nShows distress when mother leaves the room.\nCannot be settled until mother returns. (easily comforted by mother on return)\nDemonstrated by 15-20%\nNot disturbed by mother's leaving.\nFinds fascination in stranger and may even interact.\nDoesn't notice when mother returns.\nDemonstrated by 10-15%\nDo not use mother as a base of operation.\nNot disturbed by mother's leaving.\nHave mixed or ambivalent reaction to mother's return.\nSome will become very upset and even hit mother on return.\nDemonstrated by 5%\nBabies become depressed and have periods of unresponsiveness and spurts of sudden emotion towards the end of the experiment.\nDescribe the cupboard theory of attachment\nTheory referring to affection that is given purely to gain a reward. i.e. child's affection towards their carer only based on the fact they give them food.\nDescribe Harlow's research and findings\nAttachment to comforting texture vs source of milk.\nProved that the comforting texture was more important over food to infant monkeys (disproving the cupboard theory).\nOther Harlow experiments showed that monkeys who were raised without a mother couldn't form normal social or sexual relationships when exposed to other monkeys.\nWhat is socialisation?\nThe lifelong process in which an individual acquires:\nDescribe the processes involved in socialisation\nSocialisation is learnt mainly during childhood, although individuals may further their socialisation when exposed to different communities and cultures, e.g. workplace, traveling.\nStages involved in socialisation:\n• Reinforcement and punishment- B F Skinner: behaviour rewarded with reinforcement will be a behaviour repeated.behaviour punished should be discontinued. Although sometimes only supressed when authorities (parent) around. (Do it but don’t get caught)\n• Observation and Modelling- Albert Bandura: Acknowledges roles of rewards and punishment shapes behaviour. But believes social behaviours are especially learnt through imitation or modelling.In order to learn from modelling children aged 2+ need to follow these steps:1.Attention - pay attention to the behaviours of another2.Retention - retain the information observed of how the other performs the behaviour.3.Motivation - want to repeat the action because they saw the other receive some sort of positive reinforcement for the behaviour.\n4.Potential ability - child must have the physical ability to perform the behaviour, e.g. seeing an older child do a handstand doesn't mean you are suddenly able to do one to.\n• Cognitive development-emphasises the role of understanding interpersonal thought and action.\nChildren know somethings are bad or good, children can comprehend how they should relate to others and how to act.Builds an observational learning - view social development as dependant on cognitive development.\n• Children's temperaments and parents behaviours are influenced and affected by each other. Therefore during socialisation the use of different approaches depending on temperament will be more effective.\nDescribe the 3 different parenting styles\n• Authoritative-reciprocal- Parent make appropriate demands on child- Child conform to appropriate rules- Responsive to children i.e. answer questions as to why there is a rule- Open communication- Faster ability to self regulate- independence\n• Authoritarian (restricted control)/Autocratic- Power assertive - strict discipline applied- Little attention to child's autonomy- \"Because I said so\" instead of explaining why there is a rule- At extreme can lead to abuse- Child hasn't learnt how to not use that behaviour\n• Indulgent/Permissive- Parents are responsive but apply little discipline- Try to not set schedules, bedtimes etc.- Little demands on children- Fails to help children learn about structure of social rules\n• Neglecting (not really a parenting style)- Lack of responsiveness to child\n- Neglecting, ignoring, indifferent\nDescribe Piaget's early work on moral development\n• Young child cannot distinguish between when an accident happens and when the act is done intentionally. (8y/o)\nOlder children can. Therefore, they are able to see that it is worse to knock over a vase deliberately than if you accidentally knock it over.\nDescribe and evaluate Kohlberg's research and theory/model of moral development\nExtending from Piaget's work, Kohlberg presented children with different scenarios involving moral questions and asked the children what would be the right thing to do. (how they thought about there decisions)\nPreconventional morality Level 1 (7-10 years)\ns1. right/wrong matter of obtaining reward or avoiding punishment.\ns2. right/wrong matter of reciprocity and negotiation.\nConventional morality level 2 (10-16+ years)\ns3. Interpersonal expectations and conformity to rules to enhance self-image or please others.\ns4. Conformity to societal rules forms basis of moral reasoning.\nPostconventional morality Level 3 (16+ years)\ns5. Moral reasoning envolves balance between societal rules and individual rights.\ns6/7. consideration of universal principles of justice to form basis for moral reasoning.\nThe 4 Principles of Kohlberg's Model:\n1. An individual can only be at one stage at a given time.\n2. Everyone goes through the stages in the fixed order.\n3. Each stage is more comprehensive and complex than the preceding stage.\n4. The same stages occur in every culture. (However this point is contradicted by others)\nEvaluating Kohlberg's theory:\n• Not all people will reach stages 4-7. Many never reach stage 5.\n• Not all cultures experience the levels.\n• Research pool was limited to white, males in the 70s and therefore may not be resembling of other groups.\n• Gilligan (1982) believes that females are more empathetic and will reach higher levels over males.\n• Trevethan and Walker (1989) found that people use different types of moral reasoning depending on the situation of the dilemma.\n• The theory is based on, and therefore applies to, only people's judgements and not their actions.\nDescribe the traditional view of adolescence\nHall's \"Storm and Stress\" description.\ntraditionally a period of turmoil, mood swings, unpredictable behaviour\nDescribe cultural differences in adolescence experiences\nChildren gradually take on adult responsibilities without sudden turmoil.\nIndividualist v collectivist culture\nDescribe the levels of peer relationships in adolescence and outline the benefits of such relationships\ncommitment to friends\nDescribe Erikson's, Freud's and Maslow's different psychosocial stages in a adulthood\nKey focus on social relationships.\nErikson's Intimacy v Isolation, Generativity v Self-absorption and Integrity v Despair.\nFreud's love & work\nMaslow's Love & belonging and then success & esteem","Erickson’s theory revised\nErickson’s Psychosocial Development Stages\nErickson’s psychosocial theory looks closely at the impact of external factors that a person has to go through from childhood to adulthood. According to the theory, every person has eight stages that they must go through over their entire life cycle. These stages are discussed below.\nBasic Trust vs. Mistrust. This stage is mostly observed during infancy between 18 months and 2 years. When a baby is very well taken care of by the parents, the baby will grow with a lot of trust, confidence and will also feel very secure. If the care lacks, however, in the baby’s early years, they may develop general mistrust to the world and insecurity (Shaffer, David 43).\nAutonomy vs. Shame. This stage occurs when the child is about 18 months to 3 years. A child gets the opportunity to build autonomy and build their self-esteem at this stage. He/she gets the opportunity to learn new skills and also get to know right from wrong. The child that was shown care will believe in himself/herself and will be confident rather than being shy. On the other hand, the child who faced negligence will be defiant, and stubbornness can appear.\nInitiative vs. Guilt. This is the stage when the child is between 3 -5 years and is most likely in preschool (Greene, Roberta 96). This is when the child’s curiosity heightens and you find that they will ask lots of questions. They will also try to imitate the adults in one way or the other. The child that received care at infancy will always take roles that are positive while the other child might not have the confidence to take even ant roles. They underestimate themselves.\nIndustry vs. Inferiority. This stage is that of a school age child between 6-12 years. Learning, accomplishing new skills and acquiring knowledge are the main issues that take place during this stage (Greene, Roberta 94). It’s also when the child gets to develop socially. At this stage, the most important relationship to the child is with their school and neighborhood. Albeit parents are still important to them, they do not play the major role they once did.\nIdentity vs. Role Confusion. This stage is between 12-18 years. Development at this point depends entirely on what a person does. Adolescents try hard to identify themselves and get to struggle to fit in.\nIsolation vs Intimacy and Solidarity. These are now the young adults of 18-35 years. Here, people begin looking for love and companionship. The most significant relationships at this stage are not those of neighborhood, parents, or even school but those of friends and marital partners (Shaffer, David 43).\nGenerativity vs. Self-absorption or stagnation. These are the middle-aged adults between 35-65 years (Shaffer, David 43). During this stage, the most important things are a career, work, and family. Working to be stable and trying to make a difference in the society is what this stage is all about. Family, the local church as well as other communities form important relationships for them.\nIntegrity vs. Despair. This stage is the late adult stage between 55 and 65–death. According to Erickson, much of life is preparatory for middle adulthood and late adulthood has a lot to do with reflection. Some older adults look back and appreciate themselves for having lived a meaningful life and having useful to the society (Greene, Roberta 96). At this point, there is a sense of despair for those who failed in their middle adulthood.\nIn conclusion, development continues throughout life, and each stage brings about a different societal difficulty that has to be resolved.\nGreene, Roberta R. Human Behavior Theory & Social Work Practice. New Brunswick, N.J: Aldine Transaction, 2008. Print.\nShaffer, David R. Social and Personality Development. Australia: Wadsworth/Cengage Learning, 2009. Print.\nGet a verified expert to help you with any urgent paper!Hire a Writer\nfrom $10 per-page"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:7a755573-16e7-42b9-90bb-47ebee01d537>","<urn:uuid:da143c32-4c6e-4371-be6d-150d6577963a>"],"error":null}
{"question":"Can someone help me understand what makes dysthymia different from Internet addiction? Need to figure this out!","answer":"Dysthymia and Internet Addiction are distinct conditions with different diagnostic criteria. Dysthymia is a chronic form of depression lasting at least 2 years in adults (1 year in children) and requires depressed mood plus at least two symptoms like poor appetite/overeating, sleep problems, low energy, low self-esteem, poor concentration, or hopelessness. Internet Addiction, on the other hand, is characterized by compulsive Internet use that interferes with daily life, involving symptoms like euphoria when using computers, inability to prioritize tasks, loss of time sense, and physical symptoms such as carpal tunnel syndrome and vision problems. While both conditions can affect concentration and daily functioning, dysthymia is a mood disorder focused on persistent depressed mood, while Internet Addiction specifically relates to problematic Internet use behaviors.","context":["What Is Internet Addiction?\nDo you play video games on the Internet in excess? Are you compulsively shopping online? Can’t physically stop checking Facebook? Is your excessive computer use interfering with your daily life – relationships, work, school? If you answered yes to any of these questions, you may be suffering from Internet Addition Disorder, also commonly referred to as Compulsive Internet Use (CIU), Problematic Internet Use (PIU), or iDisorder. Originally debated as a “real thing,” it was satirically theorized as a disorder in 1995 by Dr. Ivan Goldberg, M.D. who compared its original model to pathological gambling. Since this hoax of sorts, the disorder has rapidly gained ground and has been given serious attention from many researchers, mental health counselors, and doctors as a truly debilitating disorder. Though not officially recognized as a disorder in the Diagnostic and Statistical Manual of Mental Disorders (DSM-IV), its prevalence in American and European cultures is staggering – affecting up to 8.2% of the general population. However, some reports suggest it affects up to 38% of the general population. The widely variable difference in prevalence rates might be contributed to the fact that no true and standardized criteria has been selected for Internet Addiction Disorder. It is researched differently among scientists and mental health professionals. And, it is researched differently across ethnic cultures.\nThe advancement in study of Internet Addiction Disorder has been negatively impacted by the lack of standardization in this area. It has been generally accepted among researchers, however, that Internet Addiction is only a subset of technology addiction in general. As the name states, its concentration is on compulsion with the Internet – as other areas of media addiction can be seen in television addiction, radio addiction, and other types of media addiction. Due to the explosion of the digital age, Internet Addiction Disorder has taken the reigns as the top culprit is technology addiction as of late. The troubling thing about this disorder is that if you are suffering from it, you are endlessly surrounded by technology. In the digital age, the Internet has taken over. Most of what we do, as a general population, can be done on the Internet. Can’t find that shirt you want in the store? No worries – the Internet has it! Need to place an order for pizza? Why call? Complete an online order! Can’t call over a friend to play a video game at 3am when you’re suffering from insomnia and can’t go back to sleep? I bet there’s someone across the globe that is awake and ready to play! That’s, in essence, why this disorder can be so troubling – even treatment-wise. It’s hard to live these days by getting rid of the Internet. We’re always surrounded by it – and for most of us, we use it daily.\nJust because you use the Internet a lot – watch a lot of YouTube videos, shop online frequently, or like to check social media does not mean you suffer from Internet Addiction Disorder. The trouble comes when these activities start to interfere with your daily life. In general, Internet Addiction Disorder is subdivided into varying categories. The most commonly identified categories of Internet Addiction include gaming, social networking, email, blogging, online shopping, and inappropriate Internet pornography use. Other researchers suggest that it is not the amount of time spent on the Internet that is particularly troublesome – rather, it is how the Internet is being used. That is, the riskiness of Internet use can be just as important as the amount of time spent. Do you have a teenager using teen dating sites that could have child molesters lurking on the site? This is risky – and one of the multidimensional aspects of Internet Addiction Disorder. Other identified multi-dimensional risk factors of Internet Addiction Disorder include physical impairments, social and functional impairments, emotional impairments, impulsive Internet use, and dependence on the Internet.\nWhat Causes It?\nLike most disorders, it’s not likely to pinpoint an exact cause of Internet Addiction Disorder. This disorder is characteristic of having multiple contributing factors. Some evidence suggests that if you are suffering from Internet Addiction Disorder, your brain makeup is similar to those that suffer from a chemical dependency, such as drugs or alcohol. Interestingly, some studies link Internet Addiction Disorder to physically changing the brain structure – specifically affecting the amount of gray and white matter in regions of the prefrontal brain. This area of the brain is associated with remembering details, attention, planning, and prioritizing tasks. It is suggested one of the causes of Internet Addiction Disorder is structural changes to the prefrontal region of the brain are detrimental to your capability to prioritize tasks in your life, rendering you unable to prioritize your life, i.e., the Internet takes precedence to necessary life tasks.\nInternet Addiction Disorder, in addition to other dependency disorders, seem to affect the pleasure center of the brain. The addictive behavior triggers a release of dopamine to promote the pleasurable experience activating the release of this chemical. Over time, more and more of the activity is needed to induce the same pleasurable response, creating a dependency. That is, if you find online gaming or online shopping a pleasurable activity and you suffer from an addiction to the Internet, you will need to engage in more and more of the behavior to institute the same pleasurable feeling prior to your dependency.\nThe variable reinforcement effects of Internet addiction is another cause of this behavior. According to the Variable Ratio Reinforcement Schedule (VRRS) theory, the reason why you might be so addicted to Internet activity (e.g., gaming, gambling, shopping, pornography, etc.), is because it provides multiple layers of rewards. That is, your constant surfing of the Internet leads to multiple rewards that are unpredictable. Perhaps your addiction to Facebook provides a multiple and unpredictable layer of rewards in the sense that every time you sign on to read your updates, you get repeated and unexpected good news. Maybe you found out one of your great friends just got engaged. The next time you sign on, you learn another friend just had a baby! Or, perhaps the man you are really interested in just posted an update that he and his longtime girlfriend just broke up. Each sign on gives you unpredictable results that keep you entertained and coming back for more. Certain games, such as MMROPGs (massively multiplayer online roleplaying games) – including World of Warcraft and Everquest may lead to Internet addiction because, in effect, they never end.\nBiological predispositions to Internet Addiction Disorder may also be a contributing factor to the disorder. If you suffer from this disorder, your levels of dopamine and serotonin may be deficient compared to the general population. This chemical deficiency may require you to engage in more behaviors to receive the same pleasurable response compared to individuals not suffering from addictive Internet behaviors. To achieve this pleasure, individuals may engage in more behavior to the general public, increasing their chances for addiction.\nPredispositions of Internet addiction are also related to anxiety and depression. Oftentimes, if you are already suffering from anxiety or depression, you may turn to the Internet to relieve your suffering from these conditions. Similarly, shy individuals and those with social awkwardness might also be at a higher risk of suffering from Internet addiction. If you suffer from anxiety and depression, you might turn to the Internet to fill a void. If you are shy or socially awkward, you may turn to the Internet because it does not require interpersonal interaction and it is emotionally rewarding.\nWhat are the Symptoms?\nSigns and symptoms of Internet Addiction Disorder may present themselves in both physical and emotional manifestations. Some of the emotional symptoms of Internet Addiction Disorder may include:\n- Feelings of guilt\n- Feelings of Euphoria when using the Computer\n- Inability to Prioritize or Keep Schedules\n- No Sense of Time\n- Avoidance of Work\n- Mood Swings\n- Boredom with Routine Tasks\nPhysical Symptoms of Internet Addiction Disorder may include:\n- Carpal Tunnel Syndrome\n- Poor Nutrition (failing to eat or eating in excessively to avoid being away from the computer)\n- Poor Personal Hygiene (e.g., not bathing to stay online)\n- Neck Pain\n- Dry Eyes and other Vision Problems\n- Weight Gain or Loss\nWhat are the effects of Internet Addiction Disorder? If you are suffering from this disorder, it might be affecting your personal relationships, work life, finances, or school life. Individuals suffering from this condition may be isolating themselves from others, spending a long time in social isolation and negatively impacting their personal relationships. Distrust and dishonesty issues may also arise due to Internet addicts trying to hide or deny the amount of time they spend online. In addition, these individuals may create alternate personas online in an attempt to mask their online behaviors. Serious financial troubles may also result from avoidance of work, bankruptcy due to continued online shopping, online gaming, or online gambling. Internet addicts may also have trouble developing new relationships and socially withdraw – as they feel more at ease in an online environment than a physical one.\nHow is it Diagnosed?\nThough it is gaining traction in the mental health field – and recently added to the Diagnostic and Statistical Manual of Mental Disorders as a disorder that needs more research, a standardized diagnosis of Internet Addiction Disorder has not been discovered. This is also a significant contributing factor to the overall variability in the disorder as a whole and wide range of prevalence in the population from 0.3% to a whopping 38%.\nOne of the more accepted diagnostic assessments of Internet Addiction Disorder has been proposed by KW Beard’s 2005 article in CyberPsychology and Behavior. Beard proposes five diagnostic criteria in the identification of Internet Addiction Disorder in the general population:\n- Is preoccupied with the Internet (constantly thinks about past use or future use)\n- Needs to use the Internet with increased amounts of time to gain satisfaction\n- Has made unsuccessful efforts to control, cut back, or stop use of the Internet\n- Is restless, moody, depressed, or irritable when attempting to control Internet use\n- Has stayed online longer than originally intended\nIn addition, Beard (2005) suggests at least one of the following must also be present in a diagnosis of Internet Addiction Disorder:\n- Has jeopardized or risked the loss of a significant relationship, job, educational, or career opportunity because of the Internet\n- Has lied to family members, therapists, or others to conceal their involvement with the Internet\n- Uses the Internet as a way of escaping from problems or to relieve a dysphoric mood (e.g., guilt, anxiety, depression, helplessness)\nIf you have sought help with an Internet Addiction Disorder, you have likely been given a mental test or questionnaire of some sort to assess your dependency on the Internet. The most common assessment tools used to help make a diagnosis of Internet Addiction Disorder include:\n- Young’s Internet Addiction Test\n- the Problematic Internet Use Questionnaire (PIUQ)\n- the Compulsive Internet Use Scale (CIUS)\nWhat are the Treatment Options?\nThe first step in treatment is the recognition that a problem exists. If you do not believe you have a problem, you are not likely to seek treatment. One of the overarching problems with the Internet is that there is often no accountability and no limits. You are hidden behind a screen – and some things that you may say or do online are things you would never do in person.\nThere is debate in the literature whether treatment is necessary in the first place. Some believe Internet Addiction Disorder to be a “fad illness” and suggest that it usually resolves itself on its own. Studies have show that self-corrective behavior can be achieved and successful. Corrective behaviors include software that controls the Internet use and types of sites that can be visited – with the majority of professionals in agreement that total abstinence from the computer is not an effective method of correction.\nSome professionals argue that medications are effective in the treatment of Internet Addiction Disorder – because if you are suffering from this condition, it is likely that you are also suffering from an underlying condition of anxiety and depression. It is generally thought that if you treat the anxiety or depression, the Internet Addiction may resolve in step with this treatment approach. Studies have shown that anti-anxiety and anti-depressant medications have had a profound affect on the amount of time spent on the Internet – in some cases decreasing rates from 35+ hours a week to 16 hours a week. Physical activity has also been indicative of effective in increasing serotonin levels and decreasing dependency on the Internet.\nSome of the more common psychological treatments of Internet Addiction Disorder include:\n- Individual, group, or family therapy\n- Behavior modification\n- Dialectical Behavioral Therapy (DBT)\n- Cognitive Behavioral Therapy (CBT)\n- Equine Therapy\n- Art Therapy\n- Recreation Therapy\n- Reality Therapy\nBecause of the prevalence of the disorder in the general population, treatment centers and programs have started to pop up in the US and across the globe. In some cases, electro-shock therapy was used to wean individuals off the Internet – this method has since been banned. The ReSTART residential treatment facility was started in 2009 in Seattle, WA for pathological computer use. In 2013, a USB-connected keyboard device was created to provide a very low voltage shock to users who visited particular websites. In other places nationwide and internationally, de-addiction centers have been started to aid individuals suffering from Internet Addiction Disorder.\nIn many instances, multimodal treatments have been employed to treat Internet Addiction Disorder. In this method of treatment, if you are suffering from this condition, you might be prescribed both medications and psychotherapy to treat your addiction to the Internet.\nContinued or Questionable Existence?\nThough originally diagnosed as a “hoax” disorder – the increased digital age has propelled us into the Internet age and Internet addiction has become a truly real “thing.” However, many researchers are uncertain of whether Internet Addiction Disorder is a disorder in its own existence or rather a symptom of other underlying conditions.\nCreating an even more problematic interaction is the fact that everything is online nowadays. It’s hard to make a distinction between online and offline worlds. Everything is Internet-based. From ordering food, interacting with friends, playing games, and even watching tv. Adding an additional layer of confusion and distinction is that other digital technology is taking over the world as well – make access to computers even easier. Now, we don’t have to be physically sitting in front of the computer – we can do anything from anywhere with just our phones, tablets, or other electronic devices.\nStill, other researchers question whether excessive Internet use is an addiction or an obsessive-compulsive or impulse-control disorder. Indeed, the Diagnostic and Statistical Manual of Mental Disorders is correct in its acknowledgement that much more research is needed to study this disorder.","Level of analysis Depression as a symptom Depression as a syndrome Depression as a disorder\nDimensions of Depression cognitive behavioral physiological\nCategories major depressive disorder major depressive episode dysthymic disorder depressive disorder NOS bipolar disorder manic episode cyclothymic disorder hypomanic episode bipolar disorder NOS mood disorder due to a general medical condition substance-induced mood disorder mood disorder NOS\nDepression A.At least one of the following three abnormal moods which significantly interfered with the person's life: –1. Abnormal depressed mood most of the day, nearly every day, for at least 2 weeks. –2. Abnormal loss of all interest and pleasure most of the day, nearly every day, for at least 2 weeks. –3. If 18 or younger, abnormal irritable mood most of the day, nearly every day, for at least 2 weeks.\nMajor Depressive Disorder Persists for two weeks and causes significant personal distress or functional impairment. Major Depression: 5 of 9 symptoms, which must include either: 1. Depressed mood or 2. Anhedonia.\nMajor Depression Diagnostic Criteria (cont’d) B.At least five symptoms have been present during the same 2-week period. –1. Abnormal depressed mood (or irritable mood if a child or adolescent). –2. Abnormal loss of all interest and pleasure. –3. Appetite or weight disturbance, either: Abnormal weight loss or decrease in appetite. Abnormal weight gain or increase in appetite.\nMajor Depression Criteria (cont’d) –4. Sleep disturbance, either abnormal insomnia or abnormal hypersomnia. –5. Activity disturbance, either abnormal agitation or abnormal slowing (observable by others). –6. Abnormal fatigue or loss of energy. –7. Abnormal self-reproach or inappropriate guilt. –8. Abnormal poor concentration or indecisiveness. –9. Abnormal morbid thoughts of death (not just fear of dying) or suicide.\nMajor Depression Criteria (cont’d) C.The symptoms are not due to a mood- incongruent psychosis. D.There has never been a Manic Episode, a Mixed Episode, or a Hypomanic Episode. E.The symptoms are not due to physical illness, alcohol, medication, or street drugs. F.The symptoms are not due to normal bereavement.\nEssential Features Not due to “rule-outs” Abnormal depressed mood –Persists continuously for at least 2 weeks. –Causes marked functional impairment. –Causes disabling physical symptoms. –Causes disabling psychological symptoms.\nEssential Features (cont’d) Abnormal loss of interest and pleasure mood: –Reduced capacity to experience pleasure (anhedonia). –Result=lack of motivation. –Abnormal irritable mood: May present primarily with irritable, rather than depressed or apathetic, mood. Unfortunately, irritability=alienating loved ones with their cranky mood and constant criticisms.\nEssential Features (cont’d) Physical symptoms –Abnormal appetite –Abnormal sleep –Fatigue or loss of energy –Agitation or slowing\nEssential Features (cont’d) Cognitive symptoms –Abnormal self-reproach or inappropriate guilt –The \"negative thinking\" –Abnormal poor concentration or indecisiveness –Marked forgetfulness –Abnormal morbid thoughts of death (not just fear of dying) or suicide\nComorbidity 40-70% meet criteria for another disorder; 20-50% have 2 or more comorbid disorders Most common: –Anxiety Disorders –Disruptive Behavior Disorders –Substance Abuse Disorders\nDysthymia Chronic –at least 2 years in adults, –1 year in children. Milder depression than Major Depressive Disorder.\nDysthymia Diagnostic Criteria A.Depressed mood for most of the day, for more days than not, as indicated either by subjective account or observation by others, for at least 2 years. Note: In children and adolescents, mood can be irritable and duration must be at least 1 year.\nDysthymia Diagnostic Criteria (cont’d) B.Presence, while depressed, of two (or more) of the following: –1. poor appetite or overeating –2. insomnia or hypersomnia –3. low energy or fatigue –4. low self-esteem –5. poor concentration or difficulty making decisions –6. feelings of hopelessness\nDysthymia Diagnostic Criteria (cont’d) C. The person has never been without the symptoms in Criteria A and B for more than 2 months at a time. D. No Major Depressive Episode has been present during the first 2 years of the disturbance (1 year for children and adolescents –Note: There may have been a previous Major Depressive Episode provided there was a full remission before development of the Dysthymic Disorder. –After the initial 2 years (1 year in children or adolescents) of Dysthymic Disorder, there may be superimposed episodes of Major Depressive Disorder, in which case both diagnoses may be given when the criteria are met for a Major Depressive Episode.\nDysthymia Diagnostic Criteria (cont’d) E. There has never been a Manic Episode, a Mixed Episode, or a Hypomanic Episode, and criteria have never been met for Cyclothymic Disorder. F. The disturbance does not occur exclusively during the course of a chronic Psychotic Disorder. G. The symptoms are not due to the direct physiological effects of a substance. H. The symptoms cause clinically significant distress or impairment in social, occupational, or other important areas of functioning.\nBipolar Disorder Individual experiences depressed episode followed by manic episode. Lifetime prevalence ~1% Male=Female Age of onset: Usually late teens to mid 30s Extremely controversial in children\nManic Episode Manic Episode=period (at least 1 week) of elevated, expansive, or irritable mood including 3 of 7 symptoms. –1. inflated self-esteem or grandiosity –2. decreased need for sleep –3. more talkative than usual or pressure to keep talking –4. flight of ideas or subjective experience that thoughts are racing –5. distractibility –6. increase in goal-directed activity or psychomotor agitation –7. excessive involvement in pleasurable activities that have a high potential for painful consequences\nManic Episode (cont’d) C. The symptoms do not meet criteria for a Mixed Episode. D. The mood disturbance is sufficiently severe to cause marked impairment in occupational functioning or in usual social activities or relationships with others, or to necessitate hospitalization to prevent harm to self or others, or there are psychotic features. E.The symptoms are not due to the direct physiological effects of a substance or a general medical condition.\nChild Assessment Methods for Depression Clinical interviews (parent, child) –Meet diagnostic criteria? –Assess associated features (e.g., social funct.) –Suicidal and/or homicidal ideation? –Check for “rule-outs” Self-report measures –Children’s Depression Inventory –Broadband measures (e.g., BASC-2, ASEBA) Projective testing Refer for medical evaluation? Direct Observations"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:4521d3a8-4d42-4c7e-ac3b-e2011c4a66cd>","<urn:uuid:ae07ac58-82e6-4830-8392-f4009d3acfd6>"],"error":null}
{"question":"How do the financial challenges of cancer treatment compare with the integrative medicine solutions proposed to address treatment side effects? Could you analyze both aspects of cancer care management?","answer":"The financial challenges of cancer treatment are severe and widespread, with cancer care projected to cost $175 billion annually by 2020 in the US, and about one-third of cancer patients experiencing extreme financial distress during treatment, often leading to bankruptcy, which increases mortality risk by 80%. Meanwhile, integrative medicine offers several cost-effective solutions for managing treatment side effects, including acupuncture (validated by NIH for treating chemotherapy-related nausea and vomiting), dietary modifications (emphasizing plant-based foods and anti-inflammatory ingredients), mind-body techniques (like guided imagery and mindfulness for stress reduction), and Traditional Chinese Medicine approaches. These integrative approaches aim to support overall patient wellbeing while managing treatment side effects, though the documents don't specify their costs. The contrast shows that while conventional treatment creates significant financial burden, integrative medicine offers complementary solutions that may help manage both the physical and financial toxicity of cancer care.","context":["When patients get sick, they need a medical intervention. But what do you do when the patient happens to be the country’s problematic health care system? For Fred Hutchinson Cancer Research Center, home to the Hutchinson Institute for Cancer Outcomes Research, the answer is the same.\nThe Hutch’s health outcomes and economics group HICOR, led by co-directors Drs. Scott Ramsey and Gary Lyman, held its latest intervention on Friday, April 7, the fourth in a series of Value in Cancer Care Summits designed to help transform cancer care in the Pacific Northwest and beyond.\nThe full day of meetings and metrics drew about 200 patients, providers, payers, policymakers and researchers from across the country to Seattle’s Bell Harbor Conference Center to share successes, frustrations, tales of financial toxicity and bold ideas on how to better serve patients by reducing the economic and human burden of cancer. Past studies by HICOR have shown that cancer patients are far more likely to go bankrupt. And some find themselves in the position of having to choose between paying for medicine or paying for food.\n“We have a problem,” said Dr. Nancy Davidson in her morning plenary presentation, going on to point out the high rate of cancer mortality in the U.S. as well as the ever-spiraling costs of care which, more and more, are being shifted to patients. Davidson was recently named senior vice president and director of the Hutch’s Clinical Research Division and president and executive director of the Hutch’s clinical care partner, Seattle Cancer Care Alliance. She also holds Fred Hutch’s Endowed Chair for Breast Cancer Research.\n“The need for us to think about how to do this more effectively is enormous,” she said, offering her take on value-based care. “High value care involves clinical quality that’s evidence-based. It’s also got to be patient-centered so it looks at quality of life, the quality of care experience, patient goals and values and quantity of life.\n“And at the end of the day, it needs to be affordable — by individual patients and by us as a society,” said Davidson. “We need to make wise use of the resources available to us.”\nToward that end, HICOR’s director Dr. Scott Ramsey spoke on the need, necessity and inevitability of transforming the cancer care model.\nCurrently, patients tap health care providers for various services — think checkups, scans, and physical therapy — with the provider billing for each service. The more services, the more fees. And cancer patients often end up with a daunting number of both.\nPayment for those services is currently based on volume and is not linked to quality or efficiency. And some argue the system encourages physicians to give as much care as possible, rather than the right or best care.\nBut that model is changing, Ramsey said, thanks to recent changes in Medicare legislation.\n“We are moving from a fee-for-service, pay-for-what-you-do world to a world where payment is going to be based on populations, and providers are going to be held responsible for managing quality and cost within a single payment approach,” he said.\nRamsey said the transformation from a volume-based, fee-for-service model to a value-based reimbursement care model is currently in its “baby steps,” but HICOR hopes to shepherd the process by sharing performance metrics that will give the local cancer care community a “jump start” on revamping their care model.\nThe Pacific Northwest, he said, can serve as a large “regional laboratory,” where insurance companies, health care providers, researchers and others try out different value-based care models and methods and then sit down at the table together and hash out what works and what doesn’t.\nOverhauling a longstanding cancer care delivery service will not be easy, especially since care is provided by both large treatment centers and smaller community clinics, each with its own mix of patients and services. Big or small, though, all providers can learn from each other, the researchers stressed.\n“We’re trying to raise the bar for all practices,” said HICOR co-director Dr. Gary Lyman.\nOne big reason to switch to a value-based system is to reduce the financial burden of cancer care.\n“The financial toxicity of cancer is an American epidemic,” said Ramsey, who’s published a number of studies on the subject. “Data suggests that a third of all cancer patients experience extreme financial distress at some point during treatment, meaning they have to remortgage or sell their house, use up all their savings, borrow money from family or friends or go into bankruptcy. A third.”\nAnd the cost of that care is steadily escalating.\nBy 2020, cancer care in the U.S. is projected to cost nearly $175 billion a year, a 40 percent increase from 2010, and that doesn’t even take into account indirect or out-of-pocket expenses. Sadly, patients and their families are bearing more and more of these costs, putting both their finances and their health in jeopardy. Not only are cancer patients far more likely to declare bankruptcy than those without cancer, those who do go bankrupt are nearly 80 percent more likely to die, HICOR studies have found.\n“It’s easy to try to blame one group — pharma or health insurance or providers,” said Ramsey. “But financial toxicity is much more complex than that and it’s an issue we have to tackle.\"\nCarla Tardif, CEO of the Boston-based financial assistance nonprofit, Family Reach, said she’s thrilled people are finally talking about it.\n“We’re been around for 20 years and much of this has not being talked about or addressed, or it wasn’t until Dr. Scott Ramsey entered the scene,” said Tardif, a two-time cancer survivor.\nTardif said she regularly talks with patients who’ve lost jobs, homes and more after a diagnosis. Some skip treatments in order to put food on the table. Others become homeless.\n“I’m seeing patients like a single mom with ovarian cancer and two young kids, and they’re all sleeping on a park bench in Philly because she lost her job and her home due to cancer,” she said.\nPart of the problem, she said, is that cancer patients are often ashamed to talk money with their providers or worry their care will be impacted if their doctors know they’re financially strapped. Another problem: providers don’t bring it up.\n“Many say ‘We don’t talk to patients about money, our focus is on cancer’,” she said. “But patients need to talk to somebody.”\nCamins Bretts, a stage 4 endocrine cancer patient, said figuring out which patients are more likely to be hit by high costs is key.\n“If you think it’s bad for common cancers like breast or colorectal cancer, try having a really rare one,” Bretts said. “My personal out-of-pocket costs have increased 400 percent since I was diagnosed. One of the things we need to look at is who is getting the strongest financial hit. This has severely impacted my ability to access care. And I know lots of people like me.”\nLyman acknowledged that cost is “the elephant in the room for most cancer patients.”\n“Not only the burden, but getting treatment or continuing treatment,” he said. “And it has a direct impact on clinical outcomes in patients, not to mention quality of life and family issues. It’s at the heart of our work.”\nHICOR’s researchers are working to identify areas where stakeholders can bump up value and bring down cost, a complicated, multidimensional issue. Friday's participants proffered ideas to accomplish this: bundled payments; group visits; virtual visits; oncology medical home programs; expanded clinic hours; centralized phone triage; patient-to-patient mentorship; text messages to improve oral drug adherence; financial navigators and risk assessment.\nAs Tardif put it, providers need to have the “understanding that patients are people and that cancer affects the whole family.”\nAll agreed that first and foremost, patients need to receive good, consistent, evidence-based care, which doesn’t always happen.\nBreast cancer patient Bridgette Hempstead, founder of the African American cancer support group Cierra Sisters, said she’s encountered a number of patients who’ve been offered wrong or inadequate care over the years.\n“Even today, there are African American women who’ve been diagnosed with a HER2 positive breast cancer and are not getting the proper treatment,” she said. “My community is hurting and my community is dying at a higher rate.”\nBreast cancer patient Rebecca Seago-Coyle, 42, of Seattle who also received inappropriate — and conflicting — recommendations after she diagnosed at age 35, lauded HICOR's work.\n“The work that they're doing, talking about the outcomes of cancer treatment and long term quality of care, is so important,\" she said. \"I love the idea of sharing best practices and of transparency between clinics. That only helps you as a patient be more empowered. You're part of that team, too. And with patients at the table, they'll have a better undertsanding of how all of this impacts us.\"\nRamsey acknowledged cancer care is always going to be expensive, but said the HICOR group and others are trying to \"figure out ways to reduce that trend.”\n“Some things, like the cost of drugs, will be beyond the control of individual oncologists,” he said. “But they have to be careful about prescribing things that work and not prescribing things that don’t work. Some providers order expensive PET scans for patients with early stage breast cancer. That’s a $3,000 test that has no value [based on ASCO recommendations]. A lot are doing that, and we need to discourage that pretty vigorously. We want people to do the right thing and not do the wrong thing.”\nMost of all, the HICOR group wants to continue to function as the “Switzerland of health care,” providing a neutral forum where stakeholders come together and hammer out a solution that works for everyone — particularly patients.\n“It’s going to take a while, but I’m comforted by the fact the conversation is happening,” said Tardif.\nDiane Mapes is a staff writer at Fred Hutchinson Cancer Research Center. She has written extensively about health issues for NBC News, TODAY, CNN, MSN, Seattle Magazine and other publications. A breast cancer survivor, she blogs at doublewhammied.com and tweets @double_whammied. Email her at email@example.com.","Treating Cancer: Integrative Medicine\nFor a new book, Dr. Weil and Donald I. Abrams, M.D., the former director of Clinical Programs at the University of California, San Francisco Osher Center for Integrative Medicine, assembled a team of experts to assess what the emerging field of integrative oncology has to offer cancer patients.\nPublished by Oxford University Press, Integrative Oncology is aimed at health professionals but can be understood by cancer patients and their families as well as by health-conscious individuals concerned with cancer prevention. The book is the first in a planned series on integrative medicine’s role in various medical specialties including psychiatry, rheumatology, asthma and immunology, pediatrics, women’s health and others.\nHere, in the first of a two-part interview, Dr. Abrams talks about his practice of integrative oncology and how integrative medicine can enhance cancer treatment. In a second article, he will discuss how integrative medicine fits into cancer prevention.\nWhat role does integrative medicine (IM) play in cancer treatment?\nThe field of oncology (cancer treatment) is fairly new but has exploded in recent years and become more and more specialized. A patient may need a surgical oncologist to remove a tumor, a radiation oncologist for radiation therapy and a medical oncologist to provide chemotherapy, hormone therapy and targeted cancer therapy (drugs that block cancer spread). Some oncologists now specialize in treating only certain types of cancer, such as colorectal or pancreatic. This increasing specialization benefits patients in that they get care from physicians who are experts in their specific disease, but in the process, the specialist may tend to see only the tumor and not the patient. Integrative oncology looks at the whole patient, body, mind and spirit.\nI tell my patients that I think of cancer as a weed. Modern western oncology is focused on destroying the weed while integrative oncology concentrates on the soil the weed grows in and on making the soil as inhospitable as possible to the growth and spread of the weed.\nWe also recognize that many cancer patients are people who have been highly functional and in control of their lives. A cancer diagnosis takes away that control and puts them at the mercy of doctors. In my practice, I try to return to the patient some sense of control by giving them things they can do to take their lives back into their own hands. At the same time I’m also trying to decrease ongoing inflammation in the body, which is at the root of many chronic diseases, and to enlist the body’s innate immunity to fight against the cancer as well as decreasing stress and increasing hope.\nAre there dietary changes that can help patients fight cancer?\nThe one thing we know for sure about diet is that obesity increases the risk of a number of different types of cancer. With hormonally driven cancers (such as breast cancer) obese patients have a worse prognosis than those with a healthy body mass index. So it is important for some patients to improve their nutritional status and decrease their weight. The most useful strategy is to eat a plant-based diet focusing on a wide variety of colored fruits and vegetables. Cruciferous vegetables such as broccoli, cauliflower and cabbage contain a cancer-preventing compound so potent that is being investigated as a chemotherapy agent. Berries are rich in beneficial phytonutrients and antioxidants. Overall, a diet that emphasizes fruits and vegetables, whole grains, nuts, cold water fish that provide omega-3 fatty acids (fish eaters have a reduced risk of cancer) is the best nutritional strategy.\nAt the same time, we recommend decreasing your intake of animal fats in general and red meat and dairy products in particular to control cancer-promoting inflammation in the body. I personally believe that refined sugar and carbohydrates are not beneficial for individuals living with cancer because of their effect on insulin production and insulin-like growth factors, which promote inflammation and are also associated with cancer cell division.\nI appreciate the fact that organic fruits and vegetables are expensive, but they are the best choices for cancer patients, not just because they’re grown without pesticides and other agricultural chemicals but because plants grown outdoors organically need to protect themselves from other plants, predators (insects, birds and animals) and the sun. Organically grown plants do this by producing more intense protective chemicals, known as phytonutrients, which are beneficial to us.\nI also recommend seasoning food with ginger, garlic, onions, turmeric, drinking green tea, all of which have anti-inflammatory effects. If you drink alcohol, stick to red wine. Excessive alcohol consumption is a cancer risk, men who drink alcohol should limit themselves to a maximum of two drinks daily and women to a maximum of one. For women at risk for breast cancer, one drink a week is safest.\nWhat about IM strategies to counter the side effects of conventional cancer treatment?\nI refer my patients to Traditional Chinese Medicine practitioners on the staff at the Osher Center. I believe that cancer patients treated concurrently with acupuncture tend to do better. In fact, the National Institutes of Health had a consensus conference on acupuncture in 1997 and found that it was useful in treating side effects of chemotherapy, including chemotherapy associated nausea and vomiting. I think it may also be useful for increasing energy, decreasing dry mouth and relieving hormonally induced hot flashes. Traditional Chinese Medicine is all about expelling evil and supporting good. Modern western medicine is mainly about expelling evil. I think my role as an integrative oncologist is to support the good as well as expelling the evil.\nYou wrote about the uses of medical marijuana in cancer treatment and prevention. What role do you see it playing in the future?\nI’ve been an oncologist for almost 30 years so my career has spanned the yin and yang of society’s acceptance and rejection of marijuana for medical purposes. We know that cannabis is useful for treating nausea, appetite loss, pain and insomnia that can be side effects of chemotherapy or cancer itself. We now also appreciate that some components of cannabis may have significant anti-cancer effects. I wrote a chapter on cannabinoids and cancer in integrative oncology with Manuel Guzman, a professor of biochemistry and molecular biology in Spain who has done a lot of work in this area. Researchers are now looking at the impact of cannabinoids on cancer. I wouldn’t be surprised to see an impact on treatment.\nTell us about the importance of mind/body approaches in cancer treatment.\nThese approaches are vital. Patients have lost a sense of control and their bodies have been assaulted with chemotherapy and radiation. Learning mind body techniques – guided imagery, hypnosis, mindfulness, stress, reduction, yoga, T’ai chi – helps decrease stress. Many people blame the stress in their lives for the development of cancer. I don’t think stress in and of itself is enough to cause cancer, but it does affect production of hormones such as epinephrine and cortisol that can depress the immune system. So, overall, stress may lead to an increased risk that cancer will spread and to shorter survival. It has been shown that women with ovarian cancer who lack a good support system have more distress and more aggressive malignancies, and this is just one example of a psychological association and a biological marker for more aggressive disease.\nRead another interview with Dr. Abrams: Preventing Cancer With Integrative Medicine."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:a7e46895-c5f2-4ba2-b380-0a7f4242567a>","<urn:uuid:bc94b560-7fad-4590-a44b-691019271e08>"],"error":null}
{"question":"¿Cuál tiene más fibra por 100g: los navy beans o la paska ucraniana? ¡Necesito datos nutricionales precisos! 🤔","answer":"Navy beans have significantly more fiber than Ukrainian paska. Navy beans contain 10.5g of fiber per 100g, while Ukrainian paska contains only 1g of dietary fiber per serving.","context":["|Nutritional Guidelines (per serving)|\n|Servings: 1 Ukrainian paska (12 servings)|\n|Amount per serving|\n|% Daily Value*|\n|Total Fat 11g||14%|\n|Saturated Fat 5g||26%|\n|Total Carbohydrate 16g||6%|\n|Dietary Fiber 1g||3%|\n|*The % Daily Value (DV) tells you how much a nutrient in a food serving contributes to a daily diet. 2,000 calories a day is used for general nutrition advice.|\nUkrainian Easter bread or paska (which means Easter) is a slightly sweet egg bread that can be decorated with religious symbols.\nIt's taken to church on Easter morning in a special basket with other foods to be blessed. Slovaks also serve paska at Easter but this is not to be confused with the molded Easter cheese dessert of the same name.\nUkrainians also feature another type of sweet bread known as babka for Easter but instead of the fluted shape favored by the Poles, theirs looks more like a Russian kulich which is tall and cylindrical in shape.\n- 1 1/2 cups milk\n- 1/2 cup sugar (plus 1/2 teaspoon)\n- 1/2 cup water (lukewarm)\n- 1 package active dry yeast\n- 7 1/2 cups all-purpose flour (divided)\n- 3 large eggs (room-temperature, beaten)\n- 1/3 cup butter (melted)\n- 1 1/2 teaspoons salt\n- For the Egg Wash:\n- 1 large egg (room-temperature)\nScald the milk and set aside to cool to lukewarm.\nDissolve 1/2 teaspoon sugar in water and sprinkle yeast over it. Mix and let stand 10 minutes.\nCombine yeast mixture with cooled scalded milk and 2 1/2 cups flour. Beat until smooth. Cover and let rise until light and bubbly.\nAdd eggs, remaining 1/2 cup sugar, melted butter, salt and 4 1/2 to 5 cups of the remaining flour to make a dough that is not too stiff and not too slack.\nKnead until dough no longer sticks to the hand and is smooth and satiny (about 7 minutes in a mixer, longer by hand).\nPlace dough in a greased bowl, turn to grease both sides, cover with greased plastic wrap and let rise until doubled. Punch down and let rise again.\nReserve 1/3 of the dough for decorating (see Note below). Shape the rest into a round loaf and place in a 10- to 12-inch greased round pan.\nNow shape the reserved dough into decorations of choice -- a cross, swirls, rosettes, braiding, etc. -- and arrange on top of the dough.\nCover the pan with greased plastic wrap and let rise until almost doubled.\nHeat oven to 400 F. Brush bread with 1 large egg beaten with 2 tablespoons water. Bake 15 minutes.\nReduce temperature to 350 F and bake an additional 40 minutes or until an instant-read thermometer registers 190 F. If necessary, cover the top of the bread with aluminum foil to prevent over browning.\nRemove from oven and turn out onto a wire rack to cool completely.\n- Some cooks make a stiffer, non-yeast, sculpting dough for the decorations so the shapes won't distort when baked. You can use the one as described in this Serbian cesnica recipe.","Almost everyone might have heard of high-fiber foods. But not everyone knows the importance of these foods in our diet.\nThe inclusion of high fiber foods is very beneficial for our overall health as these foods help us feel full, support our digestive system, keep the gut healthy, improve heart health, and last but not least help in losing weight easily.\nThe adequate intake (AI) of fiber for adult men is 33.6 grams (g) a day whereas for adult women it is 28 g as per the Dietary Guidelines for Americans. However, very few Americans can actually meet this as the AI of fiber in the US is 17 g.\nList of the Top 35 High Fiber Foods you must include in your Diet\nTo have high fiber-rich food, we need to include loads of fruits, vegetables, legumes, and whole grains in our diet.\nWe have listed 35 High Fiber Foods that actually prove to be wonders for your overall health. Check them out!\nLegumes include plant-based foods that contain high content of fiber in them like beans, lentils, and peas.\n1. Navy beans\nNavy beans are not only rich in fiber content but are also a rich source of proteins. One can have navy beans in different ways by adding them to salads, curries, etc.\nFiber content: Navy beans contain 10.5 g of fiber per 100 g (31.3 percent of AI).\n2. Pinto Beans\nPinto beans are another fiber-rich food that is popular in the U.S. Pinto beans are not only an amazing source of fiber but are also rich in calcium and iron. You can have it as a whole, mashed, or as refried beans.\nFiber content: 100 g of pinto beans contain 9 g of fiber (26.8 percent of AI).\n3. Black beans\nBlack beans are rich in iron, magnesium, and plant-based protein. Those who follow a vegan diet if they consume black beans by mixing with rice will benefit from all nine essential amino acids.\nFiber content: 100 g of black beans packs 8.7 g of fiber (25.9 percent of AI).\n4. Split peas\nSplit peas are rich in iron and magnesium.\nFiber content: They contain 8.3 g per 100 g (24.7 percent of AI).\nLentils are of different types like red lentils and French lentils. They go well with quinoa dishes, dahl, etc.\nFiber content: 100 g of lentils pack 7.9 g of fiber (23.5 percent of AI).\n6. Mung beans\nMung beans are rich in potassium, magnesium, and vitamin B-6. Dried and grounded mung bean flour can be used in making yummy pancakes.\nFiber content: 100 g of mung beans contain 7.6 g of fiber (22.6 percent of AI).\n7. Adzuki beans\nThe fiber-rich Adzuki beans are found in Japanese cuisine used to make a traditional sweet. One can even have these beans by simply boiling them.\nFiber content: In 100 g of adzuki beans, you will get 7.3 g of fiber (21.7 percent of AI).\n8. Lima Beans\nLima Beans are rich in fiber content as well as plant protein.\nFiber content: 100 g of lima beans offer you 7 g of fiber content (20.8 percent of AI).\nChickpeas also known as garbanzo beans are an amazing source of fiber and proteins. These beans are also bundled with iron, vitamin B-6, and magnesium. This legume can be used as a base for hummus as well as falafel.\nFiber content: 100 g of chickpeas pack 6.4 g of fiber (19 percent of AI).\n10. Kidney Beans\nKidney beans are one of the popular fiber-rich foods which can be included in your diet even as part of a salad.\nFiber content: 100 g of kidney beans pack 6.4 g of fiber (19 percent of AI).\nThe fiber-rich Soybeans can be used in the preparation of a number of food items like tofu, tempeh, and miso. Soybean products can also be used to replace meat and dairy in the diet. One can even have fresh soybeans raw or simply add them to salads.\nFiber content: 100 g of soybeans pack 6 g of fiber (17.9 percent of AI).\n12. Baked beans\nBaked beans are a great source of fiber and protein. It is suggested to buy those baked beans brands that contain less sugar and salt content for maximum health benefits.\nFiber content: Plain baked beans from a can have 4.1 g per 100 g (12.2 percent of AI).\n13. Green peas\nGreen peas which are a great source of fiber also come bundled with protein, vitamin C, and vitamin A. One can buy green peas either in canned form or fresh.\nFiber content: 100 g of green peas contain 4.1–5.5 g of fiber (12–16 percent of AI).\nThere is a big list of vegetables that are a great source of fiber. A few of the vegetables which are rich in fiber content are:\nArtichokes are an amazing source of calcium, folate, vitamins C and K. Artichokes can be grilled, baked, or steamed to be used.\nFiber content: A medium artichoke packs 6.9 g of fiber (20.5 percent of AI).\nPotato is another vegetable that is rich in vitamin B, vitamin C, and magnesium.\nFiber Content: A single large-sized potato (when baked with its skin) packs 6.3 g of fiber (18.8 percent of AI).\n16. Sweet potato\nSweet potatoes are rich in vitamin A.\nFiber Content: A single large-sized sweet potato (when baked with its skin) packs 5.9 g of fiber (17.6 percent of AI).\nParsnips are bundled with calcium, zinc along with vitamins C, K, and B.\nFiber Content: A single boiled parsnip offers 5.8 g of fiber (17.3 percent of AI).\n18. Winter squash\nWinter squash contains rich contents of vitamins A and C.\nFiber content: A cup of winter squash offers 5.7 g of fiber (17 percent of AI).\nThe green vegetable Broccoli is a rich source of vitamins C and A. Broccoli which belongs to the cruciferous vegetable family also packs loads of antioxidant polyphenols.\nFiber content: 5.1 g of fiber is present in a cup of cooked broccoli florets (15.2 percent of AI).\nPumpkin which is another high-fiber vegetable is also a rich source of calcium, vitamins A and K.\nFiber content: You will get 3.6 g of fiber from a part of canned pumpkin. (10.7 percent of AI).\nWell, not just vegetables, but even fruits are a rich source of fiber. Fruits can be included even as a part of snacks.\nAvocado fruit packs with it healthy monounsaturated fats which are good for your heart.\nFiber content: You will get 9.2 g of fiber from one avocado (27.4 percent of AI).\nPears are packed with loads of fiber, vitamins C and A, folate, and calcium.\nFiber content: A medium-sized pear has 5.5 g of fiber (16.4 percent of AI).\nApple is a fruit rich in vitamins C, A, and folate. Do not skip eating apple skin as most of the fruit’s fiber is found in the skin only.\nFiber content: 5.4 g of fiber is present in a large-sized apple (16.1 percent of AI).\nRaspberries are loaded with antioxidants as well as vitamins C and K.\nFiber content: 4 g of fiber is present in half a cup of raspberries (11.9 percent of AI).\nBlackberries are also a rich source of healthy antioxidants, vitamins C and K.\nFiber content: 3.8 g of fiber is present in half a cup of blackberries (11.3 percent of AI).\nPrunes which are simply dried plums are a great source of fiber. However, they may also contain high sugar content, so need to consume them in limit.\nFiber content: 3.4 g of fiber is present in five prunes (10.1 percent of AI).\nOrange is a popular fruit that is rich in fiber as well as vitamin C.\nFiber content: 3.4 g of fiber is packed with an orange fruit (10.1 percent of AI).\nBananas are loaded with nutrients like potassium, magnesium, and vitamin C.\nFiber content: 3.1 g of fiber is present in a medium-sized banana. (9.2 percent of AI).\nGuava is another fruit that is rich in fiber content as well as vitamin C and A. Guavas can also be had in the form of juices as well smoothies.\nFiber content: 3 g of fiber is packed with one guava (8.9 percent of AI).\nList of High-fiber Nuts and Seeds\nNuts and seeds are bundled with many health benefits as they come loaded with healthy fats, proteins, and essential omega-3 fatty acids.\nBuckwheat is a high-fiber seed that is also a great source of magnesium and zinc.\nFiber content: 8.4 g of fiber is packed with ½ cup of buckwheat groats (25 percent of AI).\n31. Chia seeds\nChia seeds are a great source of fiber, omega-3s, proteins, antioxidants, calcium, and iron.\nFiber content: 4.1g of fiber is present in one tablespoon of chia seeds (12.2 percent of AI).\nQuinoa is an edible seed that is loaded with antioxidants, magnesium, folate, copper, and vitamins B-1, B-2, B-6.\nFiber content: 2.6 g of fiber is present in ½ cup of quinoa (7.7 percent of AI).\n33. Pumpkin seeds\nPumpkin seeds are also rich in fiber. They are also a great source of healthy monounsaturated and polyunsaturated fats, magnesium, and zinc.\nFiber content: 1.9 g of fiber is present in ¼ cup of pumpkin seeds (5.7 percent of AI).\nAlmonds are high-fiber nuts that come loaded with vitamin E, calcium, healthy monounsaturated and polyunsaturated fats.\nFiber content: 1.5 g of fiber is present in ten almonds (4.5 percent of AI).\nPopcorn which is one of the favorite snacks for kids is also a high-fiber food. It is rich in zinc, folate, and vitamin A.\nFiber content: 1.2 g of fiber is present in a cup of popcorn (3.6 percent of AI).\nWhole grains like Freekeh, Bulgur wheat, Pearled barley are a few other high fiber foods one must include in their diet.\nHope you will benefit by including these high-fiber foods in your diet!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:07c4a3f6-1140-4f5e-81c2-42b5441049dd>","<urn:uuid:9106fd8d-d9f4-4c26-ad47-5454eca71266>"],"error":null}
{"question":"What environmental features are incorporated into the 200 Greenwich Street tower's design to achieve LEED gold certification?","answer":"The tower includes flexible zones near the perimeter that can create double-height atria, which can draw fresh air into the building during spring and autumn as part of the environmental strategy. The building is designed to meet the highest energy efficiency ratings and aims to achieve the gold standard under the Leadership in Energy and Environmental Design (LEED) by the US Green Building Council.","context":["Foster and Partners has designed a 78-storey office tower at 200 Greenwich Street as part of the redevelopment of the World Trade Center site in New York. One of the most important urban planning and architectural challenges of recent times, the concept is driven by memory, but equally by a sense of rebirth. Its sparkling glazed crystalline form and diamond shaped summit create a bold addition to the New York skyline.\nArranged around a central cruciform core, the tower comprises four blocks containing light filled, flexible, column free office floors that rise to the 59th floor, whereupon the glass façades are sheared off at an angle to address the Memorial Park. Giving the building its distinctive inclined summit, 200 Greenwich Street also acts as a symbolic marker of the location of the Memorial Park when viewed from any location. The upper floors contained within the summit provide the opportunity for spectacular multiple-height function rooms with sweeping views of the park, the river and the city.\nA continuation of Foster and Partners’ investigation into the nature of the tower, 200 Greenwich Street takes structural, functional, security, environmental and urban logic to a new dimension. The tower is informed by the geometry of the site, with the cruciform core providing the structural backbone as well as the key organising diagram. It accommodates the primary vertical circulation, with high speed shuttle elevators rising to an intermediate sky lobby where the upper floors are served by two further banks of elevators. It also allows for cross corridor circulation by providing excellent orientation at every level, and opening views out across the office spaces.\nExtending the logic of the core, the volume of the tower is punctuated on all four sides by notches – elegantly breaking up the mass of the tower into four interconnected blocks. Towards the perimeter, the core culminates in dedicated flexible zones with the opportunity to create staircases between floors, and the possibility for double-height atria. These zones can be an integral part of the building’s environmental strategy by drawing fresh air into the building during spring and autumn. Designed to the highest energy efficiency ratings, 200 Greenwich Street will seek to achieve the gold standard under the Leadership in Energy and Environmental Design (LEED) by the US Green Building Council.\nConnections with the city at street level have been reinforced with glass walls creating a visual relationship with the surrounding streets. The imposing double height ground floor lobby is connected at the Greenwich Street entrance to the MTA providing direct access to the underground infrastructure system. The lobby rises in level along Vesey Street and includes a further connection with the transport system via escalators and a four-storey shopping area connecting with Fulton Street and spilling out onto the Wedge of Light plaza.\nLord Foster said:\n“We are pleased to unveil our design for Tower Two on the site of the World Trade Center, a building that symbolises the renaissance of New York on the skyline while also re-establishing and reviving Greenwich Street at ground level. The crystalline top of the tower respects the masterplan and bows down to the memorial park commemorating the tragic events that unfolded here. But it is also a powerful symbol of hope for the future. The dramatic height of the tower celebrates the spirit that has historically driven Manhattan to build tall, and the diamond-shaped top will be a crowning landmark on the city's skyline.\"\n+44 20 7738 0455\nThank you for subscribing.\nPlease check your email for our confirmation message."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:d0c838c3-c821-4a69-adfe-427bfd53af7b>"],"error":null}
{"question":"Why is regular gun cleaning crucial for maintenance, and what role does ammunition safety play in proper firearm operation?","answer":"Regular gun cleaning is crucial as it helps identify potential problems before they occur and prevents hang-ups and debris that cause premature wear. Approximately 65% of gun issues can be resolved through proper cleaning. For ammunition safety, it's essential to use only the correct ammunition type stamped on the barrel of the gun. Users must examine every cartridge before use and only use SAAMI approved ammunition. Using incorrect caliber ammunition or damaged rounds can cause extensive damage to the firearm and serious injury. Additionally, if any off sounds or light recoil are detected when firing, stop loading immediately and inspect the weapon.","context":["Clean a 1911 – Cleaning Is a Crucial Part of Gun Maintenance\nThis article will explain step-by-step the most basic of gunsmithing skills, cleaning. Of the hundreds of guns I look at each year, 65% of them just need a good cleaning. I charge around $40 to do this simple procedure, but it can easily be done at home.\nCleaning is also the most CRUCIAL of all firearms maintenance procedures, as a good cleaning does two things: allows the user to identify any future problems BEFORE they happen, and keeps the gun running free of hang-ups and debris, which cause premature wear. Think of it as an oil change for your pistol. This is by no means a comprehensive breakdown, but it’s enough to keep a good pistol running.\nWhat Is Field Stripping?\nI have boiled it down to a tool free stripping so as to be done in the field, thus the term field stripping. Some folks clean a 1911 differently, like my friend who simply removes the barrel on his Glock, and throws the damned thing in the dishwasher. Bob swears that Glock OK’d the practice, and he’d know, being a certified Glock armorer and all. This tear down method works on all 1911 style pistols.\nSafety Procedures for Gun Cleaning\nFirst, and always first is safety! Begin by dropping the magazine and clearing the chamber. Then, clear the magazine. NEVER should the two ever meet again during the cleaning process.\nDepress Mag release button, and slide the magazine out of the mag well. Next, clear the chamber, rack back the slide, and lock it back using the slide catch. Confirm this is clear a MINIMUM of 3 times.\nCheck and clear the magazine. Also confirm 3 times, because most accidents occur when cleaning a gun especially when you clean a 1911.\nDisassembling the 1911 Pistol\nNow we are ready to disassemble our firearm. Note the slide catch and slide, there is a notch in the slide for the catch to push through and a button on the opposite side that pushes the slide catch through.\nLine the notch up with the button, depress the button, and pull the slide catch out of the gun. For simplicity, I marked the notch with a red arrow, slide catch with a yellow arrow, and the button with an orange arrow in the next two pictures.\nSo, we lined up our notch, pushed our button and removed the slide catch. This may take some wiggling and finagling, but it is easily done after a few times of doing it.\nNow, flipping the safety to the “OFF” position, we should be able to work our slide back and forth a time or two and the slide assembly will simply slide forward and off the gun, leaving us with two separate assemblies, slide and receiver, or frame. Set the receiver aside for now, and let’s concentrate on the slide at this time.\nRemoving the Recoil Spring and Guide Rod\nFirst and trickiest thing to come out is the recoil spring and guide rod. Exercise caution when removing these, as the spring can fly out.\nThis is the most powerful spring in the whole pistol – BE CAREFUL.\nI often grab the slide as shown above with one hand and fish the spring and guide rod out as an assembly with the other to prevent this from happening.\nRemoving Barrel Bushing and Barrel of 1911 Pistol\nNext thing scheduled for removal…. Barrel bushing. Some guns do not have a barrel bushing, if yours doesn’t, skip this step. Rotate the bushing 1/8 to ½ turn either clockwise or counter clockwise. This will vary from gun to gun.\nThe bushing is locked into place by the guide rod, and will NOT come out without the rod being removed. The barrel can’t come out of the slide without the bushing being removed, it keeps the barrel centered and tight in the slide. In the next picture, the barrel bushing is marked with a red arrow.\nNext, the barrel should lift out and slide free of the slide toward the breech. I stick my finger through the ejection port on the slide. Then, give a gentle push up and slide the barrel back a little bit. Once unseated, the barrel just slides up and out from the breech of the slide.\nWith the completion of this step, field stripping is complete. We should have a series of components like in the picture below, ready for cleaning.\nFrom left to right we have as follows: Magazine, Barrel, Slide catch, Slide, Barrel Bushing, Guide rod and Recoil spring, and receiver. We are now ready to clean our gun.\nClean a 1911 – Gun Cleaning Products and Tools\nFirst, let’s discuss cleaning products and tools. There are literally TONS of cleaning products out there, but a lot of them are gimmicks designed to part you and your money. It’s really all about personal preference. Pictured below are a few of the cleaning solvents out there and some cleaning tools also.\nFrom left to right, Hoppe’s #9 solvent, Wipe-out Patch-out maximum strength solvent, Sweet’s 7.62 Solvent, Browning Aerosol gun oil, 2 cleaning rods, an action brush, 2 barrel brushes, a screw on barrel brush, a wool mop, a patch jag, cleaning patches, and a bulk bag of cleaning patches.\nThis is a LOT of crap to keep up with for the leisure shooter. I do a lot of shooting and repairing of guns, so it is necessary for me to have all this stuff. However, it is much simpler for the leisure shooter or casual gunner to have a simple kit, put out by several manufacturers. Just make sure you get the kit for the caliber gun you own!\nJust a word on some of these products, I only pictured ones I know to work. I am NOT recommending anyone go out and buy all this or any of this stuff, just my personal preference. The Hoppe’s #9 solvent works fine for day to day cleaning.\nWipe-out Patch-out is a good medium duty solvent. It claims to remove copper fouling, but I know better than that. It also claims there is no need for a bore brush, BS! It is a good, medium duty solvent, but it is neither of these claims.\nThe Sweet’s 7.62 Solvent is a good heavy duty solvent. It DOES remove copper fouling, as is evidenced by the green colored metal that comes out with the dirty patches when cleaning. It still requires brushing, but is a heavier solvent then the other two. If you use a heavy solvent, you then need to use a lighter solvent to remove the residue from the heavier solvent. (Basically, you Clean a 1911 a few times to get it cleaner and residue free.)\nNow, onto the actual cleaning. Scrub the barrel first, as this is where combustion takes place, and the copper jacketed bullet slides down the barrel. Almost all the abuse the gun takes occurs here. First, we take our solvent and a bore brush, soak the brush in solvent and commence scrubbing the barrel thoroughly.\nClean guns are happy, reliable, more accurate guns. While cleaning, look for any dings at the crown of the muzzle, wear spots, or anything else that looks out of place or “beaten up”.\nAfter bore brushing, we can start running patches down our bore and clean the outside of the barrel too.\nWe get our patch jag and some patches and start swabbing. Do this until the patch comes out clean on the other end. If your patches don’t fit your bore, it is perfectly fine to cut them down to fit.\nOnce our barrel is cleaned, we shoot a light coat of oil on it and apply a light coat of oil to our bore mop. This mop is then run down the bore to apply oil and prevent rusting.\nCleaning the Slide, Recoil Spring, and Guide Rod of the 1911 Pistol\nNext, move on to the slide itself. We take our action brush, or an old toothbrush and clean the slide thoroughly, looking for any defects in the slide as we do. Note: inspect the slide rails thoroughly.\nAfter the slide and barrel are cleaned, they may be reassembled. Then we move on to the barrel bushing. A quick scrub with bore solvent makes quick work of this task and after oiling, it too can be re-installed.\nMoving along to the recoil spring and guide rod. A patch soaked in solvent and threaded through the spring generally does the trick, same as a quick wipe down of the guide rod. After oiling, they can be re-installed. I sometimes use a rubber band to hold this assembly together whilst cleaning other parts of the gun. This completes the slide assembly half of the cleaning process.\nNow we move on to the action part of our cleaning job. We will not be disassembling the action for this job, as it is the field expedient version of it. You’ll need solvent, an action brush, or toothbrush, and your receiver.\nBasically, just scrub the crap outta the receiver with your brush and plenty of solvent. Inspect all parts as you go, paying special attention to the action and the frame rails.\nYou may, if you wish remove the grips to keep the solvent off of them, however, since we are trying to do this without tools, you can forgo this part.\nFinish Reassembling the 1911 Pistol\nAfter cleaning and oiling, reassembly can begin. Don’t forget to give the slide catch a wipe down with a patch and some solvent.\nNext slide the slide onto the receiver rails, breech first. You’ll have to push the trigger release and other parts downward to make it slide all the way back. Line up the notch on the slide with the slide catch pinhole.\nSome pistols, particularly the M1911 family, have a lug that aligns the barrel inside the receiver and locks it in place with the slide catch pin. This can take some wriggling and “fiddling” with the gun, but align all holes and insert the slide catch pin.\nAfter inserting the pin, make sure to mash it down hard and make sure it’s all the way home. You should at this time, have a re-assembled pistol.\nCleaning the 1911 Pistol Magazine\nNow on to a commonly overlooked and difficult part of the gun to clean…… the mag. All you need is an action brush, solvent, and some patches. I often depress the follower and capture it through a hole in the mag with a pen or a stick to facilitate cleaning on the inside.\nIf you think about it, the mag is where a LOT of contamination happens. They get dropped in the dirt, stepped on, rattled around under truck seats, etc. and then crammed into the mag well and expected to perform. SCRUB THE HELL OUT OF YOUR MAGAZINES – inside and out!\nReloading and Securing\nAfter cleaning the magazine, it is ready to be reloaded. An empty magazine or gun in a firefight is a STICK! Unless there are children in the house, I recommend leaving the firearms loaded and locked up. You never know when you will need them.\nMine all live securely in a gun safe. Actually, a few gun safes and one has a quick action biometric lock for emergencies. The gun is now ready to shoot again or for storage. This is how we expediently fieldstrip and clean our 1911 pistols. Keep them barrels warm.","NRA: FOUR RULES OF FIREARMS SAFETY:\n1. Handle all firearms as if they were loaded.\n2. ALWAYS keep the gun pointed in a safe direction.\n3. ALWAYS keep your finger off the trigger until ready to shoot.\n4. ALWAYS keep the gun unloaded until ready to use.\nWhen using or storing a gun, always follow these NRA rules:\n- Know your target and what is beyond.\n- Be absolutely sure you have identified your target beyond any doubt. Equally important, be aware of the area beyond your target. This means observing your prospective area of fire before you shoot. Never fire in a direction in which there are people or any other potential for mishap. Think first. Shoot second.\n- Know how to use the firearm safely.\n- Before handling a gun, learn how it operates. Know its basic parts, how to safely open and close the action and remove any ammunition from the gun or magazine. Remember, a gun's mechanical safety device is never foolproof. Nothing can ever replace safe gun handling.\n- Be sure the firearm is safe to operate.\n- Just like other tools, guns need regular maintenance to remain operable. Regular cleaning and proper storage are a part of the gun's general upkeep. If there is any question concerning a gun's ability to function, a knowledgeable gunsmith should look at it.\n- Use only the correct ammunition for your gun.\n- Only BBs, pellets, cartridges or shells designed for a particular gun can be fired safely in that gun. Most guns have the ammunition type stamped on the barrel. Ammunition can be identified by information printed on the box and sometimes stamped on the cartridge. Do not shoot the gun unless you know you have the proper ammunition.\n- Wear eye and ear protection as appropriate.\n- Guns are loud and the noise can cause hearing damage. They can also emit debris and hot gas that could cause eye injury. For these reasons, shooting glasses and hearing protectors should be worn by shooters and spectators.\n- Never use alcohol or over-the-counter, prescription or other drugs before or while shooting.\n- Alcohol, as well as any other substance likely to impair normal mental or physical bodily functions, must not be used before or while handling or shooting guns.\n- Store guns so they are not accessible to unauthorized persons.\n- Many factors must be considered when deciding where and how to store guns. A person's particular situation will be a major part of the consideration. Dozens of gun storage devices, as well as locking devices that attach directly to the gun, are available. However, mechanical locking devices, like the mechanical safeties built into guns, can fail and should not be used as a substitute for safe gun handling and the observance of all gun safety rules.\n- Be aware that certain types of guns and many shooting activities require additional safety precautions.\n- Regular cleaning is important in order for your gun to operate correctly and safely. Taking proper care of it will also maintain its value and extend its life. Your gun should be cleaned every time that it is used.\n- A gun brought out of prolonged storage should also be cleaned before shooting. Accumulated moisture and dirt, or solidified grease and oil, can prevent the gun from operating properly.\n- Before cleaning your gun, make absolutely sure that it is unloaded. The gun's action should be open during the cleaning process. Also, be sure that no ammunition is present in the cleaning area.\nCOMPREHENSIVE SAFETY RULES\nAs a firearm owner, you accept a set of demanding responsibilities. How seriously you take these responsibilities can be the difference between life and death. There is no excuse for careless or abusive handling of any firearm. At all times handle firearms with intense respect for their power and potential danger. Please read and understand all of the cautions, warnings, notices, proper handling procedures and instructions outlined in your owner’s manual before using your new firearm.\n1. ALWAYS KEEP THE MUZZLE OF YOUR FIREARM POINTED IN A SAFE DIRECTION EVEN THOUGH YOU ARE CERTAIN IT IS UNLOADED.\nNever point any firearm at anything you do not intend to shoot. Be extremely alert and aware of all persons and property within the range of your ammunition.\n2. NEVER RELY TOTALLY ON YOUR FIREARM’S MECHANICAL “SAFETY” DEVICES. LIKE ANY MECHANICAL DEVICE, A “SAFETY” CAN SOMETIMES FAIL; IT CAN BE JARRED OR INADVERTENTLY MANIPULATED INTO AN UNSAFE CONDITION.\nThe word “safety” describes a firearm’s trigger block mechanism, sear block mechanism, hammer block mechanism or firing pin block mechanism. Mechanical “safeties” are designed to place your firearm in a safer status, and no guarantee can be made that the firearm will not fire even if the “safety” is in the on safe position. Mechanical “safeties” merely aid safe gun handling and are no excuse for pointing your firearm’s muzzle in an unsafe direction. See your owner’s manual for instructions on the operation of your firearm’s “safety.” Remember, safe gun handling does not stop with your firearm’s mechanical “safety” devices, it starts there. Always treat your firearm with the respect due a loaded, ready-to-fire firearm. Some firearms do not have a mechanical safety. Many target firearms, lever-action firearms and rifles do not have manual “safety” mechanisms. Therefore it is critical to read and understand the owner’s manual for every firearm, which explains the safe operation of the firearm. While it is a good idea to “test” your firearm’s mechanical “safety” periodically for proper function, never test the “safety” while your firearm is loaded or pointed in an unsafe direction.\n3. WHENEVER YOU HANDLE ANY FIREARM, OR HAND IT TO SOMEONE, ALWAYS OPEN THE ACTION IMMEDIATELY AND VISUALLY CHECK THE FIREARM’S CHAMBER AND MAGAZINE TO MAKE CERTAIN THAT THE FIREARM IS COMPLETELY UNLOADED.\nMake certain the firearm does not inadvertently contain any ammunition. Always keep the chamber empty and the “safety” in the on safe position unless shooting is imminent. If your firearm is equipped with a detachable magazine, be aware that removing the magazine does not mean your firearm is completely unloaded, as a cartridge could be in the chamber. Always remove the magazine, open the action and visually inspect the chamber to make certain the firearm is completely unloaded.\n4. ALWAYS WEAR EYE AND HEARING PROTECTION WHEN SHOOTING.\nUnprotected, repeated exposure to gunfire can cause hearing damage. Wear ear protectors (shooting earplugs or muffs) to guard against such damage. Wear shooting glasses to protect your eyes from flying particles. Allow proper distance (eye relief) between a scope and your eye when firing a scoped rifle, rifle or shotgun. Do not use unorthodox shooting methods that could cause the rearward travel of the slide or bolt of a firearm to contact your eyes, face or hands. Always keep a safe distance between the muzzle of your firearm and any persons nearby, as muzzle blast, debris and ejecting shells could inflict serious injury. Always wear eye protection when disassembling and cleaning your rifle to prevent the possibility of springs, spring-tensioned parts, solvents or other agents from contacting your eyes.\n5. KEEP ALL FIREARMS UNLOADED DURING TRANSPORT, EVEN WHEN STORED IN A HOLSTER, GUN CASE, SCABBARD OR OTHER CONTAINER.\nFor law enforcement and military personnel, refer to the procedures of your department on carrying a loaded firearm.\n6. DROPPING OR JARRING A LOADED FIREARM CAN CAUSE AN ACCIDENTAL DISCHARGE.\nThis can occur even with the “safety” in the on safe position or the hammer in the decocked position. Be extremely careful while hunting or during any shooting activity, to avoid dropping any firearm.\n7. SHOOTING FROM ELEVATED SURFACES IS DANGEROUS.\nDoing so may increase the risk of mishandling a firearm. The following rules should always be observed. Always make certain that the surface being used is safe and stable. Always make certain that your firearm is unloaded when it is being taken up and down from the surface. Always make certain that your firearm is not dropped from the surface, or dropped while it is being taken up or down from the surface. Remember, a loaded firearm may discharge when dropped, even with the “safety” in the on safe position.\n8. STORE YOUR FIREARM AND AMMUNITION SEPARATELY, WELL BEYOND THE REACH OF CHILDREN.\nTake prudent safeguards to ensure your firearm does not become available to untrained, inexperienced or unwelcome hands. Store all firearms in secure, locked cases or a gun safe. Keep your firearm unloaded when not in use. At all times, comply with federal, local and state laws. For law enforcement and military personnel, refer to the procedures of your department on storing your firearm.\n9. BEWARE OF BARREL OBSTRUCTIONS.\nMud, snow and an infinite variety of other objects may inadvertently lodge in a barrel bore. It only takes a small obstruction to cause dangerously increased pressures that can damage your firearm and cause serious injury to yourself and others. BEFORE CHECKING FOR A BARREL OBSTRUCTION, BE CERTAIN YOUR FIREARM IS COMPLETELY UNLOADED, THERE IS NOT A LIVE CARTRIDGE IN THE CHAMBER AND THE “SAFETY” IS IN THE ON SAFE POSITION. Completely unload the firearm as described in your owner’s manual. After assuring yourself that the firearm is completely unloaded, open the breech or action and look through the barrel to be sure it is clear of obstructions. If an obstruction is seen, no matter how small it may be, clean the bore with a cleaning rod and patch as described in your owner’s manual.\n10. BE ALERT TO THE SIGNS OF AMMUNITION MALFUNCTION. IF YOU DETECT AN OFF SOUND OR LIGHT RECOIL WHEN A CARTRIDGE IS FIRED, DO NOT LOAD ANOTHER CARTRIDGE INTO THE CHAMBER.\nIf your firearm fails to fire, keep the muzzle pointed in a safe direction for a minimum of 30 seconds. Carefully open the action and remove the cartridge from the chamber, and completely unload the firearm as described in your owner’s manual. If the primer is indented, the defective cartridge should be disposed of in a way that cannot cause harm. If the primer is not indented, your firearm should be examined by a qualified gunsmith and the cause of the malfunction corrected before further use. Glance down the barrel to make sure that there are no obstructions in the barrel. If there is an obstruction, completely clear the barrel before loading and firing again. Failure to follow these instructions can cause extensive damage to your firearm and possible serious injury to yourself and others.\n11. NEVER INSERT A CARTRIDGE OF THE INCORRECT CALIBER INTO ANY FIREARM.\nThe caliber of your firearm is marked on the slide. Store all cartridges of different calibers in completely separate and well-marked containers. Never store cartridges of mixed calibers in a common container or in your pockets. See your owner’s manual for more information on the correct ammunition for your firearm.\n12. EXAMINE EVERY CARTRIDGE YOU PUT IN YOUR FIREARM.\nWe assume no responsibility for the use of unsafe or improper firearm and ammunition combinations or damage or injury caused by damaged ammunition. It is your responsibility to read and heed all warnings in this owner’s manual and on ammunition boxes. See your owner’s manual for more information on the correct ammunition for your firearm.\n13. USE ONLY SAAMI APPROVED AMMUNITION.\nThe barrel and action of this rifle have been made with substantial safety margins over the pressures developed by established American commercial loads. Nevertheless, we can assume no liability for incidents which occur through the use of cartridges of nonstandard dimensions or which develop pressures in excess of commercially available ammunition which has been loaded in accordance with standards established by the Sporting Arms and Ammunition Manufacturers’ Institute (SAAMI).\n14. MAKE SURE OF ADEQUATE VENTILATION IN THE AREA THAT YOU DISCHARGE A FIREARM. LEAD EXPOSURE CAN OCCUR FROM DISCHARGING FIREARMS IN POORLY VENTILATED AREAS, CLEANING FIREARMS OR HANDLING AMMUNITION.\nLead is a substance that has been known to cause birth defects, reproductive harm and other serious injury. Wash hands thoroughly after exposure to ammunition or after cleaning a firearm.\n15. DO NOT SNAP THE FIRING PIN ON AN EMPTY CHAMBER: THE CHAMBER MAY NOT BE EMPTY!\nTreat every firearm with the respect due to a loaded firearm, even though you are certain the firearm is unloaded.\n16. KEEP YOUR FINGERS AWAY FROM THE TRIGGER AT ALL TIMES UNTIL SHOOTING IS IMMINENT.\n17. BE SURE OF YOUR TARGET AND BACKSTOP, PARTICULARLY DURING LOW LIGHT PERIODS.\nKnow the range of your ammunition. Never shoot at water or hard objects.\n18. ALWAYS UNLOAD YOUR FIREARM’S CHAMBER BEFORE CROSSING A FENCE, CLIMBING A TREE, JUMPING A DITCH OR NEGOTIATING OTHER OBSTACLES.\nNever place your firearm on or against a fence, tree, car or other similar object. For law enforcement and military personnel, refer to the procedures of your department.\n19. BE DEFENSIVE AND ON GUARD AGAINST UNSAFE GUN HANDLING AROUND YOU AND OTHERS.\nDon’t be timid when it comes to gun safety. If you observe other shooters violating any of these safety precautions, politely suggest safer handling practices.\n20. BE CERTAIN YOUR FIREARM IS UNLOADED BEFORE CLEANING.\nBecause so many gun accidents occur when a firearm is being cleaned, special and extreme care should be taken to be sure your firearm is unloaded before disassembly, cleaning and reassembly. Keep ammunition away from the cleaning location. Never test the mechanical function of any firearm with live ammunition.\n21. TEACH AND SUPERVISE FIREARMS SAFETY TO ALL MEMBERS OF YOUR FAMILY, ESPECIALLY TO CHILDREN AND NON-SHOOTERS.\nClosely supervise newcomers to the shooting sports. Encourage enrollment in hunting and shooting safety courses.\n22. NEVER DRINK ALCOHOLIC BEVERAGES OR TAKE ANY TYPE OF DRUGS BEFORE OR DURING SHOOTING.\nYour vision, motor skills and judgment could be dangerously impaired, making your gun handling unsafe to you and to others.\n23. READ AND HEED ALL WARNINGS IN YOUR OWNER’S MANUAL, ON AMMUNITION BOXES AND WITH ALL ACCESSORIES THAT YOU INSTALL ON YOUR FIREARM.\nIt is your responsibility to secure the most up-to-date information on the safe handling procedures for your firearm. We assume no liability for incidents which occur when unsafe or improper rifle accessories or ammunition combinations are used.\n24. PRACTICE PERIODIC MAINTENANCE, AVOID UNAUTHORIZED SERVICING.\nYour firearm is a mechanical device which will not last forever, and as such, is subject to wear and requires periodic inspection, adjustment and service.\nDO NOT, UNDER ANY CIRCUMSTANCES, ALTER THE TRIGGER, SAFETY OR OTHER PARTS OF THE FIRING MECHANISM OF ANY FIREARM. FAILURE TO OBEY THIS WARNING MAY RESULT IN INJURY OR DEATH TO YOURSELF OR OTHERS."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:65251b7d-c733-4ad4-9d7e-5ed43b89f1c4>","<urn:uuid:2d3684b4-a206-429c-826a-377b689b96ad>"],"error":null}
{"question":"How has the technology of road rollers evolved from the early steam-powered machines to modern versions?","answer":"Road rollers evolved significantly since the mid-19th century. Initially, steam rollers replaced horse-drawn rollers, with single-cylinder versions used for base compaction and double cylinder or compound steam rollers becoming popular from 1910 for hot-laid surfaces. During the 20th century, as internal combustion technology improved, kerosene-, gasoline-, and diesel-powered rollers gradually replaced steam rollers. The early internal combustion rollers were similar to steam rollers, using large exposed spur gears for power transmission, though they were initially disliked due to difficult engine starting, particularly the kerosene-powered ones. Steam rollers remained in commercial service in the UK until the early 1970s and were used in the United States through the 1950s. Today, virtually all commercial road rollers use diesel power.","context":["A road roller (sometimes called a roller-compactor, or just roller) is a compactor type engineering vehicle used to compact soil, gravel, concrete, or asphalt in the construction of roads and foundations, similar rollers are used also at landfills or in agriculture.\nIn some parts of the world, road rollers are still known colloquially as steam rollers, regardless of their method of propulsion. This typically only applies to the largest examples (used for road-making).\n- 1 History\n- 2 Uses on a road: Start-to-finish\n- 3 Configurations\n- 4 Gallery\n- 5 Manufacturers\n- 6 Road rollers in popular culture\n- 7 See also\n- 8 External links\nSince the effectiveness of a roller depends to a large extent on its weight, self-powered vehicles replaced horse-drawn rollers from the mid-19th century. The first such vehicles were steam rollers. Single-cylinder steam rollers were generally used for base compaction and run with high engine revs in a low gear to promote bounce and vibration from the crankshaft through to the rolls in much the same way as a vibrating roller. The double cylinder or compound steam rollers became popular from around 1910 onwards and were used mainly for the rolling of hot-laid surfaces due to their smoother running engines, however both cylinder types are capable of rolling the finished surface. Steam rollers were often dedicated to a task by their gearing as the slower engines were for base compaction whereas the higher geared models were often referred to as 'chip chasers' which followed behind the hot tar and chipping laying machines. Some road companies in the United States used steamrollers through the 1950s, and in the UK, some remained in commercial service until the early 1970s.\nAs internal combustion engine technology improved during the 20th century, kerosene-, gasoline- (petrol), and diesel-powered rollers gradually replaced their steam-powered counterparts. The first internal-combustion powered road rollers were very similar to the steam rollers they replaced. They used similar mechanisms to transmit power from the engine to the wheels, typically large, exposed spur gears. Some users did not like them in their infancy, as the engines of the era were typically difficult to start, particularly the kerosene-powered ones.\nVirtually all road rollers in commercial use now use diesel power.\nUses on a road: Start-to-finish\nRoad rollers use the weight of the vehicle to compress the surface being rolled (static) or use mechanical advantage (vibrating). Initial compaction of the substrate on a road project is done using a padfoot drum roller, which achieves higher compaction density due to the pads having less surface area. On large freeways a four wheel compactor with padfoot drum and a blade, such as a Caterpillar 815/825 series machine, would be used due to its high weight, speed and the powerful pushing force to spread bulk material. On regional roads a smaller single padfoot drum machine may be used. The next machine is usually a single smooth drum compactor that compacts the high spots down until the soil is smooth, and this is usually done in combination with a motor grader to get a level surface. Sometimes at this stage a pneumatic tyre roller would be used. These rollers feature two rows (front and back) of pneumatic tyres that overlap, and the flexibility of the tyres provides a kneading action that seals the surface and with some vertical movement of the wheels, enables the roller to operate effectively on uneven ground. Once the soil base is flat the pad drum compactor is no longer used on the road surface. The next course (road base) would be compacted using a smooth single drum, smooth tandem roller or pneumatic tyre roller in combination with a grader, and a water truck to achieve the desired flat surface with the right moisture content for optimum compaction. Once the road base is compacted, the smooth single drum compactor is no longer used on the road surface (There is however an exception, if the single drum has special flat-wide-base tyres on the machine). The final wear course of asphalt concrete (a.k.a. asphalt or blacktop in North America, or macadam in England) is laid using a paver and compacted using a tandem smooth drum roller, a three-point roller or a pneumatic tyre roller. Three point rollers on asphalt were very common once and are still used, but tandem vibrating rollers are the usual choice now, with the pneumatic tyre roller's kneading action being the last roller to seal off the surface.\nRollers are also used in landfill compaction. Such compactors typically have padfoot or \"sheep's-foot\" drums, and do not achieve a smooth surface. The pads aid in compression, due to the smaller area contacting the ground.\nThe roller can be a simple drum with a handle that is operated by one person, and weighs 100 pounds, or as large as a ride-on road roller weighing 22 short tons (44,000 lb or 20 tonnes) and costing more than US$150,000. A landfill unit may weigh 59 short tons (54 tonnes).\n- Rammer (bounce up and down)\n- Walk-behind plate compactor/light\n- Walk-behind plate compactor/heavy (with reverse)\n- Trench roller (manual unit or radio-frequency remote control)\n- Walk-behind roller/light (single drum)\n- Walk-behind roller/heavy (double drum)\nRide-on smooth finish\n- Tandem drum (static)\n- Tandem drum (vibrating)\n- Single drum roller (smooth)\n- Pneumatic-tyre, a.k.a. rubber tyre or multi-wheel\n- Combination roller (single row of tyres and a steel drum)\n- Three point roller (steam rollers are usually three-point)\nRide-on soil/landfill compactor with pads/feet/spikes\n- Single drum roller (soil)\n- 4-wheel (soil/landfill)\n- 3-point (soil/landfill)\n- Tandem drum (soil/landfill)\n- Tractor-mounted and tractor-powered (conversion – see gallery picture below)\n- Drawn rollers or towed rollers (were very common once, but not so now)\n- Impact compactor (uses a square or polygon drum to strike the ground hard for proof rolling or deep lift compacting)\n- Drum roller with rubber coated drum for asphalt compaction\n- Log skidder converted to compactor for landfill\n- Wheel loader converted to compactor for landfill\nDrums are available in widths ranging from 24 to 84 inches (0.6 to 2 metres).\nTyre roller types\nTyre rollers are available in widths ranging up to 2.7 metres (8.9 ft), with between 7 and 11 wheels (e.g. 3 wheels at front, 4 at back): 7 and 8 wheel types are normally used in Europe and Africa; 9 and 11 in America; and any type in Asia. Very heavy tyre rollers are used to compact soil.\nVariations and features\n- On some machines, the drums may be filled with water on site to achieve the desired weight. When empty, the lighter machine is easier and cheaper to transport between work sites. On pneumatic tyre rollers the body may be ballasted with water or sand, or for extra compaction wet sand is used. Modern tyre rollers may be filled with steel ballast, which gives a more even balance for better compaction.\n- Additional compaction may be achieved by vibrating the roller drums, allowing a small, light machine to perform as well as a much heavier one. Vibration is typically produced by a free-spinning hydrostatic motor inside the drum to whose shaft an eccentric weight has been attached. Some rollers have a second weight that can be rotated relative to the main weight, to adjust the vibration amplitude and thus the compacting force.\n- Water lubrication may be provided to the drum surface from on-board \"sprinkler tanks\" to prevent hot asphalt sticking to the drum.\n- Hydraulic transmissions permit greater design flexibility. While early examples used direct mechanical drives, hydraulics reduce the number of moving parts exposed to contamination and allows the drum to be driven, providing extra traction on inclines.\n- Human-propelled rollers may only have a single roller drum.\n- Self-propelled rollers may have two drums, mounted one in front of the other (format known as \"duplex\"), or three rolls, or just one, with the back rollers replaced with treaded pneumatic tyres for increased traction.\nVibrating Dynapac CC232\nA Caterpillar CS-533E vibratory roller.\nCorinsa CCR 14.21B Tyre Roller\nCorinsa TC-100 Vibratory tandem Roller\n- ABG (Germany) — SD/TD (purchased by Ingersoll Rand and now part of Volvo CE)\n- Albaret (Germany) — PT (now part of Caterpillar)\n- Ammann-Rammax (Swiss) — SD/TD/PT (Rammax of Germany and Ammann of Switerland, owner of STA designs)\n- Atlas (Germany) — SD\n- Aveling-Barford (England) — TD/PT/3P\n- Benford (England) — SD/TD (purchased by Terex)\n- Bitelli (Italy) — SD/TD/PT (now part of Caterpillar)\n- Blaw Knox (England) -TD/PT (known for pavers, but also had roller models)\n- BOM-MACH (South Africa)\n- BOMAG (Germany) — SD/TD/PT (BOMAG/HYPAC in the USA market)\n- Buffalo-Springfield Roller Company (USA) (purchased by Kohring and eventually Bomag in the USA)\n- Case CE (USA) — SD (brands the Ammann/Sta machines as Case in the USA\n- Caterpillar Inc. (USA) — SD/TD/PT (has the former lines of RAYGO, BROS and Bitelli\n- Coates (Australia) — TD (disbanded)\n- CORINSA (SPAIN) — PT/TD\n- CMI-Terex (USA) — 3P (has the former lines of REX and Benford)\n- Davelco (Australia) — TD (disbanded)\n- Dynapac (Sweden) — SD/TD/PT/3P (now part of Atlas Copco)\n- Hamm AG (Germany) — SD/TD/PT/3P (now part of the Wirtgen group)\n- Huber — Company\n- HYPAC (USA) — part of Bomag USA\n- Hyster (USA) — SD/TD/PT (part of HYPAC and Bomag USA)\n- Ingersoll Rand (USA) — SD/TD/PT (now owned by VOLVO)\n- Ingram Compaction\n- Kamani Engineering Corporation (India) (now part of the RPG Group) — tractor-mounted — production ended c. 1970-1980\n- Kemna, Breslau\n- Lebrero (Spain) — SD/TD/PT\n- LeeBoy (USA) — SD\n- Magistral-S (Russia)\n- Marshall (England) — TD\n- Mikasa[disambiguation needed]\n- Moore Malcolm Road Rollers (Australia) — PT (now disbanded)\n- Mustang (England)\n- Pacific Road Roller (Australia) — SD/PT (disbanded)\n- Pannel Plant (Australia) — SD/TD (purchased by Bomag)\n- Raygo (USA) — SD/TD/PT (purchased by Caterpillar)\n- Rex[disambiguation needed] (USA) — SD/TD/3P (purchased by CMI and then Terex)\n- Sakai Heavy Industries, Ltd. (Japan) — SD/TD/PT/3P\n- Sany (China) — SD/TD/PT\n- Sicom (Italy) — SD/TD\n- Simesa (Italy) — SD\n- Sinoway Industrial (Shanghai) Co.,Ltd\n- [World Equipment](China) — SD/TD/PT\n- STA / Stavostroj (Czech Republic) — SD/TD/PT (now owned by Ammann; many companies use the STA PT roller design)\n- STAMPEDE (South Africa)\n- Stone Equipment (USA) — SD\n- Strothert & Pitt (England) — TD\n- SuperPac (Canada) — SD (was Champion Superpac)\n- Tampo (USA) — SD/TD\n- VIPAC (South-Africa) - Manufactured by HA Plant Maintenance (High Quality Pedestrian Rollers)-TD\n- Vibromax (Germany) — SD/TD/PT (purchased by JCB, now branded JCB)\n- Volvo CE (Sweden) — SD/TD/PT (purchased Ingersoll Rand, now branded Volvo)\n- Wacker Neuson\n- Wallis & Stevens (England) — 3P\n- Waterous Engine Co.\n- NTC STAVEBNI TECHNIKA (Czech Republic) — manufacturer of walk-behind and light tandem rollers\n- SD = Single drum\n- TD = Tandem drum\n- PT = Pneumatic tyre — Rubber tyre or multi-tyre are also common\n- 3P = 3-point rollers — These are very similar to the old steam roller design\nRoad rollers in popular culture\nAs a fictional character\n- Roley is one of the main vehicle characters in the children's books and television series, Bob the Builder. He is a green roller with a cab, enclosed power unit and no chimney, and so is obviously diesel-powered. Nevertheless, his official title is Roley the Steamroller. This is an example of the persistence of \"steam roller\" to describe a large modern road roller in layman's English.\nAs a weapon in media\nRoad rollers are frequently weaponized in film and other media, either for a comedic effect or to demonstrate the finality of a human being crushed by a roller of some type. The roller typically isn't specified as being steam-powered or diesel-powered onscreen or in text, or is otherwise erroneously referred to as a steamroller. The following examples involve diesel-powered rollers only.\n- In The Naked Gun, the villain is run over first by a bus, then a steam roller and finally a marching band.\n- In Who Framed Roger Rabbit the true identity of the villain is revealed after he is run over by a steam roller.\n- At the end of A Fish Called Wanda, Ken (Michael Palin) gets his revenge on Otto (Kevin Kline) at Heathrow Airport, in a scene involving a small diesel roller and some wet concrete.\n- In Austin Powers: International Man of Mystery, a security guard is run over (in extremely slow motion) by a road roller.\n- In Maximum Overdrive, a Little League player is killed by a \"rebelling\" steam roller (actually a 1979 Rex 700 diesel roller).\n- In Part III of the JoJo's Bizarre Adventure Japanese manga, the villain Dio Brando attempts to finish off his rival Jotaro by dropping a road roller (sometimes translated as \"steam roller\") on him from midair.\n- In the 2D Fighting Game Skullgirls, Peacock—one of the playable characters—has a special attack that drops a road roller on the opponent in rare occasions. It is a reference for the previously mentioned Dio Brando's Road Roller Attack.\n|Wikimedia Commons has media related to Road rollers.|\n- Steam roller — the first powered road rollers\n- Roller (agricultural tool) — for farm rollers\n- Roller (disambiguation) — for other types of roller\n- Landfill compaction vehicle"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:fea47edc-20c9-4982-9917-ffa0f5a39749>"],"error":null}
{"question":"What are the key design advantages of planetary gearboxes, and what fatigue-related challenges do they face in high-cycle operations?","answer":"Planetary gearboxes offer several key design advantages, including compact and lightweight design, high torque density, and efficient power transmission through their intricate arrangement of sun, planet, and ring gears. However, in high-cycle operations, they face significant fatigue challenges. For instance, in a three-planet gearbox operating at 2,000 rpm, the sun gear teeth endure 2.88 million load cycles in just eight hours. Components must be designed to handle stress levels at or below their endurance limit to prevent failure, as ferrous materials show fatigue failure even when stress loads don't exceed static strength. Additionally, bearings present a unique challenge as they lack a definable endurance limit and must be specifically sized for a lifetime with an assigned statistical probability of failure.","context":["Planetary gearboxes are essential in the extrusion process, providing torque and speed control for efficient operation. This article will explore the design and benefits of planetary gearboxes in extrusion applications. We will discuss the key features of planetary gearboxes, their advantages over other gearboxes, and how they contribute to extrusion systems’ overall performance and reliability.\nThe Basics of Planetary Gearboxes\nWhat is a Planetary Gearbox?\nA planetary gearbox is a fascinating feat of mechanical engineering. At its core lies the input shaft, intimately linked to the sun gear, which is the central protagonist in this intricate gear drama. As the sun gear springs into motion, it nudges the planet gears—dutifully perched on a carrier—into action.\nThese diligent planet gears, in turn, engage with the encompassing ring gear. This meticulously choreographed dance between the gears culminates in transforming input energy to an output on the shaft, achieving the intended speed reduction with precision.\nAdvantages of Planetary Gearboxes\nCompact and Lightweight Design\nDive into the marvel of engineering with planetary gearboxes! The harmonious symphony of sun, planet, and ring gears not only refines the design but does so in a more condensed form than simple planetary gears. This gives them a featherlight advantage, a testament to impeccable engineering.\nHigh Torque Density\nImagine the might of a tornado contained in a tiny swirl. That’s the torque density offered by planetary gearboxes. When the gear springs into action, it unleashes high torque vital for operations like extrusion cooking, making it the heart of efficient raw material processing.\nEfficient Power Transmission\nHarnessing the intricate designs of spur and helical gears, planetary gearboxes are masterpieces in mechanical engineering. Their structure facilitates a harmonious interplay of power transmission, guaranteeing that every bit of energy is directed precisely. This ensures smooth operations and maximizes efficiency, making the most out of every input and optimizing output.\nPrecision and Reliability\nPrecision is the guiding star in the meticulous journey from raw materials to the final product. Planetary gearboxes, equipped with their minimal backlash mechanisms, exemplify accuracy down to the minutest detail. Their capability to handle high speeds, combined with their inherent design strengths, underscores their pivotal role in extrusion processes. Serving as the bedrock of consistency and reliability, these gearboxes ensure that every finished product mirrors the epitome of engineering excellence.\nDesign Considerations for Planetary Gearboxes in Extrusion\nLoad and Torque Determinants\nVenture into the rhythmic ballet of extrusion, and you’ll realize that understanding load and torque is not just essential – it’s transformative. These dynamics play a central role, and the chosen gear ratio acts as the choreographer, setting the pace and ensuring each movement (or operation) is pitch-perfect for stellar performance.\nLubrication and Temperature Management\nThink of the gearbox as a star athlete – if it doesn’t receive the right hydration (lubrication), it will falter. Lubrication is the elixir that ensures the gearbox runs like a dream. But that’s not all; the athletic prowess of a planetary gearbox is further refined when it’s kept cool. Ingenious cooling techniques work backstage to prevent the drama of overheating, ensuring our star – the gearbox – enjoys a long and illustrious career on the extrusion stage.\nNoise and Disturbance Management\nIn the theatre of extrusion, no one wants the unnecessary background score of noise and vibrations. We can orchestrate a serene environment by artistically designing the gearbox with a focus on noise reduction. This enhances the performance of the entire extrusion process and ensures the audience (the end-users) receives a product crafted in tranquility.\nBenefits of Planetary Gearboxes in Extrusion\nEnhanced Reliability and Durability\n- Bulwark Build: Crafted with meticulous attention to detail, planetary gearboxes boast a robust construction, primed to shoulder heavy burdens and persevere through the most abrasive operating conditions. Their strength ensures they remain unwavering, even when the going gets tough.\n- The Test of Time: Beyond their day-to-day performance, these gearboxes distinguish themselves through their enduring nature. They’re designed not just to last, but to do so with grace, exhibiting minimal wear and tear across extensive periods of use.\n- Shield Against Sudden Jolts: Machines can occasionally face unforeseen challenges, such as sudden shock loads or overloads. Planetary gearboxes equip themselves with protective features that absorb impacts without compromising performance.\nEnhanced Reliability and Durability\n- Stalwart Design: Engineered with a robust architecture, planetary gearboxes are purposefully crafted to endure not just heavy loads, but also the most rigorous operating environments. Their resilience ensures consistent performance even in challenging conditions.\n- Enduring Lifespan: Beyond their immediate function, these gearboxes stand out for their longevity. Designed for the long haul, they promise a sustained service life, all while maintaining efficiency and experiencing minimal wear and tear.\n- Guardian Against Surges: In the unpredictable world of machinery, sudden shock loads and overloads can be detrimental. Planetary gearboxes, however, come equipped with protective mechanisms, ensuring that they remain unyielding in the face of such abrupt challenges.\nFlexibility and Versatility\n- Broad Application Spectrum: Planetary gearboxes are not confined to a one-size-fits-all approach. They showcase their prowess by effortlessly catering to an extensive gamut of extrusion applications, from the simple to the complex.\n- Seamless Synergy: Beyond their standalone efficiency, these gearboxes stand out for their adaptability. They can meld harmoniously with a diverse array of extruders and equipment, ensuring streamlined operations across various platforms.\n- Tailored to Precision: Recognizing that every process may have its unique demands, planetary gearboxes come with a suite of customizable options. This allows for fine-tuning and optimization according to specific process intricacies, ensuring optimal performance at every turn.\nIn the extrusion industry, planetary gearboxes are essential powerhouses due to their intricate planetary gear train. Their unique blend of high torque, sleek compactness, and meticulous precision sets the gold standard for optimal extrusion processes. Beyond their primary functions, the need for gearbox repair expertise and gear manufacturing advancements further emphasize their significance. By comprehending the design and advantages of these gear systems, manufacturers can adeptly harness their potential, paving the way for enhanced productivity and performance.","The basic limiting factor for electrical devices is prolonged exposure to high temperatures which deteriorate insulation layers, boundary layers in transistors, and other parts. Since generated heat equals R x I2 x t the rating limitation of a motor, relay, or inverter is the RMS value of current. Similarly, the limiting factors of mechanical devices are mechanical stresses — tension, compression, bending shear, and Herzian pressure. The exponent here is not two, but ranges from 3 to 50 and above.\nFerrous material fatigue\nFatiguing of metallic components is well documented. Cyclically loaded parts fail even when the stress load magnitude never exceeds static strength (which parts can easily endure without damage.) Another well-known phenomenon: If the magnitude of the cyclic stress load is decreased enough, parts can endure unlimited load cycles. This stress level is called the endurance limit. Described by S-N Curve, this behavior is defined in terms of stress and number of cycles.\nAll major gearbox components are subjected to cyclic stresses, even if external loads are constant. For example, consider gear teeth. With every wheel rotation each tooth becomes fully loaded on engagement; then it passes through the action area, becomes unloaded, and completes a dynamic load cycle. In the case of a sun gear in a three-planet gearbox, this actually occurs three times per revolution due to multiple contacts. Assuming the gearbox is driven by a servomotor at a moderate 2,000 rpm input speed, in an eight-hour period each sun gear tooth endures 2,000 x 3 x 8 x 60 = 2,880,000 load cycles.\nCountless tests confirm that for ferrous materials, the exponential relationship between stress S and the number of endured load cycles N that result in no damage actually levels out at the endurance limit — at about 2 x 106 to 107 cycles. This is valid if the part is subjected to bending, shear, tension, or compression. Based on this we can distinguish two distinct areas of the SN relationship:\n• The area of limited load cycles — plots situations resulting in limited life. This area shows and exponential relationship between S and N, mathematically described as S = 1 / N1/E = N1/E or N = 1/SE. Because of the large range involved, the relationship is usually manipulated and plotted in its logarithmic form: log S = -1/E x log N or log N = -E x log S.\n• The area of unlimited load cycles is the horizontal portion of the S-N curve.\nThe exponent E determines steepness of the S-N relationship slope. It depends on the alloy, heat treatment conditions, and loading type. E covers a wide range — about six to 80. A comparison in the logarithmic scale allows the slope to appear as a constant linear slope. For a range or set of different stress levels and its frequency of stress level occurrence, damage accumulation calculation methods are used, including the wellknown Palmgren-Miner rule.\nHowever, keep in mind if the number of the load cycles is above the 2 x 106 the stress load has to be at or below the endurance limit; otherwise the component will fail. As shown in the example, for the number of load cycles a sun-gear endures over eight hours (2.88 x 106) the components must be sized and designed to endure unlimited load cycles. Gearbox rated torque must equal the torque level that loads all components at or below their endurance limits.\nUnfortunately there is another phenomenon that makes otherwise straightforward sizing less transparent — the bearing. Rolling element bearings behave differently than other components; specifically, they do not have a clearly definable endurance limit. The high-pressure loading between rolling elements and races do not follow the above described endurance behavior. For this reason bearings are typically sized, designed, and rated for a lifetime (say 10,000 hours) with assigned a certain statistical probability of failure (say L10 life, or a 10% chance of failure.)\nAs noted, the relationship between the load and number of load cycles is exponential, with an exponent of three to 10/3, but with no defined endurance limit. The familiar exponent three is applied to bearing calculations and also to Root Mean Cube or RMC calculations used to analyze complex load cycles consisting of different loads of varying duration.\nThe exponent of three in this formula is valid for bearings, but isn’t really applicable for the other gearbox components. Specially tailored calculations help identify the exponents valid for teeth, shafts, and other parts.\nGearbox torque rating\nThe majority of real-world gear applications far exceed 2 x 106 load cycles. For this reason, the recommendation of nearly all gear rating standards — AGMA, ISO, DIN — is to base gearbox torque ratings on endurance limits and minimum bearing life. For industrial gearboxes, AGMA recommends 5,000 to 10,000 hours.\nThere is only one true rated torque for a gearbox — for continuous duty. Unfortunately for marketing reasons sometimes ill-defined acceleration torques, peak torques, or emergency-stop torques are used as references. Still, only in applications where the number of load cycles is below 2x106 are loads exceeding rated load permissible. The majority of real-world automation applications reach this number of load cycles in a few days, weeks, or in a best-case scenario, after some months of operation. As a rule of thumb:\nIf the peak load cycle is part of the designed standard working duty cycle of the machinery, the peak load should not be higher than the rated torque unless the machinery is only working a very limited time. An hour of operation a day qualifies.\nAnother situation where peak loads can exceed rated torque is if the user and OEM do not expect extended, maintenance-free life. Since simple RMC calculations are not applicable to other internal gearbox components in such cases, data should be submitted to the manufacturer."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:2b2eec4b-bd40-4e61-b952-27e3e186ec63>","<urn:uuid:49ba8ac5-b9a7-4981-9df3-f14031302a2a>"],"error":null}
{"question":"What are the key differences between emergency response plans (ERPs) and table-top exercises (TTXs) in terms of their role in crisis preparation?","answer":"Emergency Response Plans (ERPs) and table-top exercises (TTXs) serve different but complementary roles in crisis preparation. ERPs are a component of a comprehensive Emergency Response Program but alone are not sufficient to address multiple potential events. TTXs, on the other hand, are specific simulation tools that help organizations test and evaluate plans, clarify roles and responsibilities, and identify gaps in response capabilities. While ERPs provide the framework, TTXs actively engage departments in understanding task execution and information sharing, helping to illuminate common pressures and stresses that companies face after serious events.","context":["Emergency Response Program: A Holistic Approach\nIn light of recent corporate aviation accidents and significant world events, I have seen many business aviation operators look solely to an Emergency Response Plan (ERP) as a holistic solution to their needs. ERPs, while a significant component of a robust and effective Emergency Response Program (Program), are not sufficient to address a multitude of events that may impact an operation. History has shown when an ERP is the sole component of a Program, the operators’ ability to proactively and effectively manage a response is significantly diminished. A robust, objective driven Program, which incorporates their ERP, allows operators to successfully execute an emergency response.\nThe foundation of a comprehensive Emergency Response Program is knowledge of best practices and regulatory requirements combined with company culture. Incorrect or outdated information typically results in a false sense of preparedness and poorly-scoped response procedures. As such, it is critical that operators develop a basic understanding of emergency response. Often times there is a significant discrepancy between what operators expect in a response and what actually occurs. Proper education will help companies to develop a realistic and practical approach to emergencies. Industry best practices along with regulatory requirements represent core competencies within emergency response and help foster an environment that encourages real growth and development.\nOnce operators have developed a strong knowledge base, they should engage in a Tabletop to ensure critical departments understand the mechanics of task execution and efficient sharing of information. A Tabletop will help to illuminate the common pressures and stresses that a company faces after a serious event has occurred. This helps illustrate the quantity of data that must be gathered and disseminated in the event of an actual emergency. Having simulated an entire response, it is easier to identify weaknesses that were previously unrecognizable. There are often serious discussions on topics that are nebulous or divisive. Such discussions will result in new internal procedures and protocols that add to the evolution of the existing ERP.\nOnce the ERP has been appropriately developed, conducting an exercise is a useful tool in ensuring that the operation’s response resources have a clear understanding of the process and it holds up to rigorous testing. The inclusion of direct response organizations that would be utilized in the event of an emergency, such as the NTSB, will greatly increase the effectiveness of the exercise and ensure the ERP holds up to all expectations.\nThe most effective companies are continually evolving a holistic Program including recurrent training (classroom, experiential, digital,) and a multitude of realistic scenarios ranging from terrorism to medical emergencies. Hazards are constantly evolving and companies have to move in order to anticipate these risks and adapt accordingly. Executing a response based on principles derived from outdated data could genuinely endanger a company’s brand. Responsible companies will foster a culture that promotes and encourages an iterative approach to emergency response.\nThe most prepared operators have actively begun the process of implementing an Emergency Response Program, which contains all of the elements discussed above. Working with these high performing teams and building upon their strong base of knowledge has allowed me to delve into some of the more intricate aspects of emergency response. Top tier flight departments recognize how important it is to ask for help in areas where they are not experts. Most companies do not have expertise in mortuary affairs, personal effects, family assistance, and the NTSB investigative process. As a result, it is important for organizations to utilize outside response professionals to augment their existing team. Organizations that are proactive and implement a holistic Emergency Response Program, in addition to a strong Emergency Response Plan, are best positioned to take care of what matters most—their people and their brand.\nAn international leader in Corporate Emergency Response Plan (ERP) development, Crisis mitigation and organizational training and assessment for appropriate response.\n© 2023 Fireside Partners Inc.. All Rights Reserved.Next Article\nIn the world of safety management, “power” might not be the first word that comes to mind. However, we’re going to explore an intriguing concept—the power that safety managers possess and how we can harness it to create a significant impact within our organizations.\nAfter a poor night of sleep, it is common to feel tired, sluggish and even irritable. More important for air operators, poor sleep is also associated with increased fatigue—which can directly impact employee performance and put lives at risk.","What are Table-top Exercises (TTXs)?\nTable-top exercises (TTXs) are a systematic approach to simulate different scenarios, in order to test and evaluate plans. They are often used in the crisis management domain in order to simulate crisis situations in order to practice, test, train and evaluate response capabilities.\nThe STRATEGY project uses TTXs to simulate crisis scenarios, in order to test and evaluate the different standards that have been selected. STRATEGY will then recommend that the standards that are successful in these scenarios be formalized at the EU level.\nWhat are the aims of TTXs?\nThe aim of TTXs is to help organisations achieve a high level of disaster preparedness. The most common Disaster Management Cycle (DMC) comprises four stages: pre-incident Mitigation and Preparedness and post-incident Response and Recovery.\nSeveral activities may be undertaken to achieve a high level of Preparedness. One key instrument that organisations (locally, nationally or regionally) may use to prepare for disaster response are Exercises, such as Table-top Exercises. These are controlled activity where a crisis situation is simulated in order to practice, test, train and evaluate response capabilities.\nExercises allow us, among other things, to:\n- Test and evaluate plans, procedures and tasks (e.g., operational guidelines and standard operating procedures);\n- Clarify roles and responsibilities, namely those related to chain of command, as participants perform their tasks and decision-making in simulated environment;\n- Develop knowledge and skills due to inter-agency work and challenging staff to perform new duties;\n- Improve coordination and build relationships and networks with other agencies and countries;\n- Identify gaps and reveal response plans’ failures and shortcomings, as well as highlight what works well;\n- Enable a process of continuous development (e.g., through Lessons Learned Process)\nExercises are particularly important assets in the Crisis Management domain, as integrated multi-agency, and sometimes trans-national, operations are usually required to guarantee a rapid, well-coordinated and efficient response, that can only be developed through practice.\nType of exercises\nThere are four main types of exercises which can be split into two categories:\n|Discussion-based||Tabletop exercises (TTX)||A tabletop exercise is a mediated discussion, usually informal, in a low-stress environment which promotes a constructive debate to address specific issues.|\n|Operations-based||Drills (DR)||A drill is an exercise intended to execute a single specific task or procedure in an operational context, which should be as realistic as possible, including the operation of all the adequate material and equipment. It aims to improve, test and perfect a procedure which is part of a broader response plan.|\n|Functional exercises (FX)||A functional exercise tests, in a complete and simulated scenario, an organization’s capability to respond to an incident, by practicing several task and procedures. Participants are challenged to perform their duties and responsibilities in a time-pressured situation, where the organization coordination, integration, and interaction are put to test.|\n|Full-scale exercises (FSX)||In a full-scale exercise an event is, as close to reality as possible, set up to test and evaluate the management and response to such incident, at operational, tactical and strategic levels. All the necessary resources, both human and material, are deployed and put into action in a realistic high-stressful environment. Response plans are intended to be tested as globally as possible, which means several agencies and stakeholders take part in a FSX.|\nWhy are TTXs important in the STRATEGY project?\nTTXs are important for the STRATEGY project because they allow first responders and crisis management experts to test and validate selected standards in order to ensure their efficacy before they are implemented.\nGenerally, in the crisis management domain, first responders are not involved in the standardisation process. This means that crisis management standards often have not been tested or validated by end-users before they are put into practice. As a result, they do not always facilitate efficient and effective disaster response.\nThis is why the STRATEGY project involves end users throughout the project. One of the first steps taken in STRATEGY was mapping the crisis management standardization landscape. Several gaps were identified for each of the 8 project streams: Search and Rescue, Critical Infrastructure Protection, Response Planning, Command and Control, Early Warning and Rapid Damage Assessment, CBRN-E, Training and Symbology and Terminology. The gaps were identified based on previously acknowledged end-users needs and existing standards. Those gaps in the standardisation landscape will be analysed and addressed throughout the project.\nSTRATEGY will then use TTXs to validate the efficacy of selected standards. The project will carry out one TTX per stream, and one Full-scale Exercise (FSX). The TTX will be organized and hosted by different STRATEGY partners. In those exercises all the consortium’s practitioners and tech providers will participate in collaborative Crisis Management scenarios. Moreover, end-users will also participate in scenario and use cases development to put together realistic test environments. Therefore, through TTX, first responders and other key players in Crisis Management will be able to test and validate pre-standards and pre-standardisation activities developed under STRATEGY framework and important data will be collected to develop a complex and realistic FSX.\nFor more information about STRATEGY visit the project website and follow us on Twitter and LinkedIn.\nAuthor: Luís Miguel Carvalho, Unidade Militar Laboratorial de Defesa Biológica e Química – Exército Português"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:ce4f1d55-d563-4a05-bd70-95163e35959d>","<urn:uuid:264a5fb2-5184-4ede-bdf2-a5f5a2552a1b>"],"error":null}
{"question":"¿Qué características tiene el sistema de soporte remoto en las Visor-Ex 01 y qué regulaciones de seguridad aplican a su instalación en áreas peligrosas?","answer":"The Visor-Ex 01's remote support system features three integrated cameras providing a natural perspective and unrestricted field of vision, coupled with reliable LTE connectivity through the intrinsically safe Smart-Ex 02 smartphone. For safety compliance in hazardous areas, the installation must conform to IEC 60079-14 standards, and the entire system must be certified intrinsically safe by recognized authorities like BASEEFA or SIRA. The equipment must operate under power limitations (less than 2 watts) through galvanic or zener barriers to prevent any possibility of generating sparks or heat that could ignite flammable gases.","context":["Inhospitable environmental conditions, confined spaces and limited WLAN connectivity – the offshore oil and gas industry with its remote drilling rigs is not the easiest place for digitalization. The stringent requirements for hazardous areas further restrict the choice of smart devices that can be used. This is a reason why, up to now, the staff on oil platforms often works with pen and paper. For example, to provisionally document inspection results before manually transferring the data to digital files at a computer desk. For mobile workers, this practice is associated with traversing long distances along the multilevel oil platforms. So, there is great efficiency potential waiting to be tapped in the oil and gas industry, particularly in the area of knowledge management.\nSmart devices for extreme conditions\nAnother special feature of drilling rigs is that the hazardous areas can change depending on current conditions. So the highest level of protection is essential for the equipment used. Since crews on an oil platform should be kept to a minimum for safety, cost and time reasons, remote support solutions for maintenance and repair are becoming increasingly attractive. Currently, oil and gas Industry is looking for suitable digitization solutions to ensure real-time knowledge transfer for employees and to accelerate the first-time fix. With up to 10,000 maintenance activities per month on the oil platform, streamlined processes are a significant factor to ensure efficiency.\nThat’s why a company in the oil and gas value chain started its search for suitable smart devices to help digitize processes. In addition to remote support, the most important application scenarios included data harvesting, for example during inspections or for the upcoming general storage system overhaul. Potential devices had to meet a number of requirements in order to make it on the shortlist. Wearables were of interest because they allow hands-free work – this is essential, since mobile workers must be able to safely navigate long distances along steep staircases. Global certifications such as ATEX or IECEx are mandatory to enable safe use. In addition, the devices had to be comfortable to wear, i.e. not too heavy or bulky.\nVisor-Ex® 01 smart glasses in a practical test\nThe company also subjected the explosion-proof Visor-Ex® 01 smart glasses from the Pepperl+Fuchs brand ECOM Instruments to an extensive practical test on a drilling rig. The lightweight wearable (180 g) combines high camera quality and reliable communication features in an ergonomic design. Coupled with the intrinsically safe smartphone ECOM Smart-Ex® 02 as computing unit with reliable LTE connectivity and a pocket device with replaceable battery for power supply, the smart glasses become part of an intelligent ecosystem. A total of three integrated and suitably positioned cameras transform the Visor-Ex® 01 smart glasses into a bionic eye, with the help of which remote support workers can observe the situation from a natural perspective and an unrestricted field of vision. All these features help to implement remote support scenarios without unnecessary complication, even under challenging environmental conditions. During the field test, the company was in close contact with the development team at ECOM Instruments, and the feedback contributed the smart glasses development.\nExperience and future application scenarios\nVisor-Ex® 01 was able to demonstrate its strengths during the field test, particularly in the area of data harvesting. With the help of cameras and image processing, QR codes from devices and machines can be read to gain access to sensor data such as pump pressure. This opens up a wide range of possible IoT application scenarios. But smart glasses are already scoring points because they improve the documentation of incidents not only quantitatively, but also qualitatively. Mobile workers can not only note down the causes of malfunctions, but also enrich the information with photos or video recordings. The digitized information can then also be shared with external support experts or employees on other rigs or at the company’s headquarters – for comprehensive, up-to-date knowledge management. They also don’t have to rush from the scene back to the computer or decipher handwritten notes.\nThe freedom of movement and vision that mobile workers gain from using smart glasses proved to be one of the other advantages. Because their hands are free, employees can move safely and freely up and down the stairs of the multilevel rig while fully concentrating on their task. Furthermore, they can make all the configurations they need on the associated smartphone and use the smart glasses as an optional augmented reality layer. When not in use, users can conveniently fold the OLED display of the Visor-Ex® 01 out of their field of vision and gain an unobstructed view of analogue reality.\nOverall, the testing company attests the Visor-Ex® 01’s versatility and good usability, even at the prototype stage; the intuitive operation was particularly emphasized. In the short term, the most obvious use scenario for the smart glasses is remote support during inspection and maintenance.\nThe stable LTE connectivity of the ECOM devices facilitates communication with external experts. This point is particularly worth emphasizing, since WLAN cannot be relied upon in every area of a drilling rig. In the medium term, the augmented reality functions could also significantly facilitate the onboarding of new specialists on the drilling rig. During a tour of the most important areas, for example, the relevant information or efficient routes could be shown on the OLED display of the Visor-Ex® 01 – or a connected expert could communicate via the integrated loudspeaker and describe what to look out for in certain areas. The ability to retrieve data quickly and easily from various sources (data harvesting) lays the foundation for sophisticated application scenarios for smart glasses.","If a fault develops in a piece of electrical or electronic equipment located in an area where flammable gases are present the fault could cause heat or sparks sufficient to ignite the gas and cause a disaster. There are 2 systems in general use to prevent such happenings.\n(a) Flameproof / Explosion proof equipment\nThe equipment is simply contained in a heavy protective enclosure, usually made of die cast steel, occasionally plastic. If heat or sparks from faulty equipment within the enclosure ignite flammable gas present with it the resulting explosion is contained within the enclosure. In North America metal conduit must be used for field wiring. In Europe and elsewhere suitably rated cable is connected directly to the equipment using certified flame proof cable glands.\nAdvantage – simple to design the system, suitable for high power equipment\nDisadvantage – equipment becomes extremely heavy & expensive; opening the enclosure while powered is not permitted\n(b) Intrinsically Safe\nThis approach limits the energy available to the intrinsically safe (I.S.) equipment, usually less than 2 watts, by means of a galvanic or zener barrier in such a way that under no circumstance will the equipment be able to generate sufficient heat or sparks to ignite flammable gases. Both the I.S. equipment and the zener barrier must be certified ‘Intrinsically Safe’ by BASEEFA, SIRA or a similar authority..\nAdvantage – considerably cheaper than comparable flame proof / explosion proof equipment, no special cabling required. Live maintenance permitted, no need to shut down the plant\nDisadvantage – only suitable for low power equipment e.g. sounders, beacons and smoke detectors (which must be certified Intrinsically Safe)\nFlame proof / Explosion proof (ATEX & ICEX equipment certified Exd & North American Class 1 Division 2 equipment)\ni. The terms ‘explosion proof’ and ‘flameproof’ are largely interchangeable. Although there are some subtle differences, engineers and the market in general usually use both terms to mean the same thing, i.e. a piece of electrical equipment designed for use in a hazardous area by means of heavy duty enclosure.\nii. The cabling of any system employing ATEX or ICEX Exd certified equipment e.g. E2S Ltd. BEX series sounders or GNEX series xenon beacon, must use suitably rated and mechanically protected cable. The cable must be terminated using Exd certified cable glands and junction boxes. The glands and junction boxes must be certified Exd by BASEEFA, SIRA or similar recognised authority to the same level as the field equipment.\nIntrinsically Safe Equipment (ATEX & ICEX equipment certified Exia, Exib, Exic & North American Class 1 Div 1 equipment)\nHere safety in hazardous areas is achieved by using a zener barrier situated between the control panel and the device e.g. the E2S Ltd MiniAlarm sounders, or Apollo Orbis Series I.S. smoke detectors. The basic I.S. circuit is shown below:\nThe manufacturer of the I.S. device will specify the type of I.S. safety barrier.\nConnection cabling requirements\ni. Although there are few restrictions on the type of cable used in IS circuits all cables have inductance and capacitance, and hence energy storage capabilities, thus they can affect system safety. The capacitance and inductance values of a given cable should be readily available from the cable manufacturer. In addition the capacitance and inductance values of the field mounted devices such as IS sounders and smoke detectors, must also be taken into account, again the values should be readily available from the manufacturer Consequently the system design imposes restrictions on the amount of each of these parameters. A great deal has been written on this subject but only rarely is there a serious limitation placed on the available cable.\nii. The cabling must conform to the following requirements\na. have protection from mechanical damage\nb. have protection from chemical attack e.g. acids etc.\nc. be securely fixed\nd. have a minimum conductor size of 0.017mm2\ne. must withstand 500V insulation test\nf. circuit voltage must not exceed 60V\niii. The following types of cables can be used:\na. screened instrument cable\nb. multi core signal cable (e.g. telephone cable) subject to certain conditions relating to screening and earthing\nc. multi core miniature electric cables\nd. conventional cables with conventional insulating sheaf e.g. PVC with a minimum insulation thickness of 0.3mm.\niii. There are no special requirements for junction boxes used in intrinsically safe circuits. However they must be clearly identified as being part of an Intrinsically safe system\niv. Installation of cables used in intrinsically safe circuits:\nThe installation of IS devices and associated equipment must conform to IEC 60079-14\nCable trays, ducts and conduits carrying intrinsically safe circuits should be seperate from cable trays, ducts etc. carrying any other cables. Note that in the U.K. I.E.T. wiring regulations prohibit electrical services e.g. power and lighting circuit cabling to be carried in the same conduit or duct as IS circuits.\nInstallation of cables used in intrinsically safe circuits\nIt is usually considered good practice to separate cable trays, ducts and conduits carrying intrinsically safe circuits from trays and ducts carrying any other cables, e.g. telephones & computer cables. I.E.E. wiring regulations prohibit electrical services, e.g. power and lighting to be carried in the same conduit.\nAcknowledgements & References:\nThe above notes are based on extracts from MTL application AN9003 ” A users guide to Intrinsic Safety” and “Interface Technology – Engineers Guide” published by Pepperal + Fuchs. We express our thanks to them in the compilation of these notes. These notes do not form part of any offer or contract. This information is provided for guidance only and should not be relied upon. Responsibility for safety and system design remains entirely with the end user. Always seek expert advice.\nArticle Source : lgmproducts"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:7c4db098-4538-4634-a687-aa899d20a7c2>","<urn:uuid:d400efba-0872-4ac9-9df9-de7c9f3d2e00>"],"error":null}
{"question":"What are the key differences in organizational structure and funding between Team Rubicon's volunteer-based disaster response model and the 82nd Sustainment Brigade's military response framework?","answer":"Team Rubicon operates on a volunteer model with nearly 30,000 volunteers organized across ten regions, running on a $7.5 million budget funded primarily through corporate and foundation grants, with no government support. Their structure includes volunteer-led regions with plans to add one paid staff member per region. In contrast, the 82nd Sustainment Brigade operates within a formal military hierarchy, demonstrated by their clear chain of command under Col. Christopher Sharpsten and structured units like the 82nd Special Troops Battalion and 189th Combat Sustainment Support Battalion. The Brigade employs a military style of leadership that empowers decision-making through the ranks, with dedicated personnel handling specific roles such as Brigade adjutant and Unit Movement Officer.","context":["It was 2010 when a couple of newly-discharged Marines, Jake Wood and William McNulty, watched in horror as the Haiti earthquake unfolded. They signed up 6 others, raised funds from family, packed up medical supplies and flew to the Dominican Republic. They rented a truck and crossed the river border between the Dominican Republic and Haiti. They thought of it as their own personal Rubicon, the point at which they vowed not to turn back from their task of providing aid. In fact, they found themselves very well equipped for the immediate disaster assistance deemed “too dangerous” by other aid organizations. Like Marines have always done, they went well beyond the established safety zones to reach those in most desperate straits and set up the basic infrastructure that enabled more well-established aid organizations to come in after them.\nThey didn't know it at the time, but this sort of disaster relief would become central to their post-military lives—would play in helping thousands of other veterans to build successful post-service lives through a new veterans organization: Team Rubicon. The idea: use the same skills honed in the military—sometimes using some of the same equipment—to be early responders in the wake of natural disasters.\nFounder Jake Wood is a tall, classically handsome former University of Wisconsin football player who went on to serve four years in Iraq and Afghanistan as a Marine sniper, earning a Navy and Marine Corps Commendation Medal. He is the author of a book on leadership, Take Command, that translates his service experience into broader lessons on leadership. McNulty is also a former Marine who worked in both infantry and intelligence before joining the staff of the Under Secretary for Defense, the Defense Intelligence Agency, and the National Security Council's Iraq Threat Finance Cell. Both men serve on Rubicon staff but Wood, as CEO, is the public face of the organization. The two concluded from that first Haiti mission that former soldiers can perform these rescue tasks with speed, efficiency, and impact, far outpacing more well-established organizations with larger budgets.\nOver the two years following the 2010 Haiti earthquake, Team Rubicon took shape in response both to natural disasters and personal tragedy. Wood's Marine sniper partner committed suicide in 2011. This caused the TR leadership to take more seriously the issues veterans have in adjusting back to civilian life. TR mobilized for the Joplin, MO, tornadoes in 2011, “Superstorm” Sandy in 2012, and the Moore, OK, tornadoes 6 months later. In each case, TR provided a rapid response team and volunteer leadership skills, in particular in organizing “drop in” volunteers while excelling at the logistics of clean up and recovery. Their work in the hard-hit Far Rockaway section of New York City after Sandy was particularly notable, as they used the latest technology to document flooding damage, developed anti-mold protocols and moved with such speed and efficiency that they got the attention of FEMA. With good reason. While FEMA was handing out written surveys to homeowners (which were supposed to be manually entered into a database in Washington), TR used military-quality global mapping software, immediately saved in the cloud, to record exact amounts of damage to each home, information immediately usable for volunteer deployment. A great deal of TR data analysis is conducted through Palantir software, originally used by U.S. intelligence but now with broad usage in the private sector, particularly with financial services firms. (One of Palantir's founders is PayPal founder and philanthropist Peter Thiel.)\nSays Jake Wood: “When we show up, it's structured, military, technical, and innovative.”\nAt a time when veterans are so often portrayed as suffering from PTSD or drug addiction, the growth of Team Rubicon tells another story. Its ten-region database now includes nearly 30,000 volunteers. Jake Wood is clear about the importance of helping communities hit by natural disasters—and helping the vets themselves. He stresses the importance of “the power of purpose in people's lives” and believes purpose brings “real behavior health impacts.”\nAt the same time, the help Team Rubicon provides on the ground is distinct and impressive. The organization responds to disasters both international (e.g., Nepal earthquake) and domestic (e.g., Houston, TX, floods). And it makes sure that veterans learn the post-military skills they'll need (chainsaw and heavy equipment operation, emergency medical response, and “muck-out” training) so that the national headquarters in Los Angeles can send out specific calls for volunteers with specific training—and not just after disasters. The group's regularly-scheduled service projects include work in national parks and even VFW halls.\nThe TR Hurricane Sandy response did more that get the attention of FEMA. The Goldman Sachs Foundation heard about the team's work and called to offer financial support. This was the beginning of a fruitful partnership. Goldman sent “busloads” of volunteers to help with the work, TR organized the volunteer time for maximum impact, and now Goldman is a major partner of TR in disaster response. TR struggles (as all relief organizations do) with finding enough financial resources to cover each disaster operation before the next disaster hits and people's attention and giving moves on. Last year TR lost money on all but two of its disaster responses. TR accepts no government support and operates on a budget of $7.5 million this past year, growing to just over $10 million in the coming year. Corporate & foundation grants account for over $7 million (including Goldman Sachs, Home Depot Foundation, Rockefeller, Citigroup, American Express, Bank of America, and Newman's Own), grassroots support is just over $1 million, events bring in about $1 million and major gifts (large individual gifts; for example, Lloyd Blankfein is a contributor) total $650,000.\nIn 2014 TR responded to 30 disasters, domestic and international, engaging 917 volunteers in 239 days of volunteer work amounting to 50,701 hours of service. Categories of work break down into disaster assessment, volunteer management, debris removal and expedient home repair. The various regions also organized 106 service projects, 73 training sessions, 37 fitness events, and 134 social engagements. The organization's reach is impressive: volunteers are clearing fire lines in national parks and preparing neighborhood resiliency plans in San Francisco in advance of possible earthquake events. All projects are coordinated and supported through an extensive social media platform that reaches not only what Wood calls the “marine corps mafia,” but men and women from all branches of the armed services and reserves along with non-military volunteers (mostly those with first-responder training or relevant skills).\nOne of the logistical challenges is that most TR volunteers are clumped around major urban centers or in the south around military bases. Most natural disasters occur in parts of the country where there are relatively few people, meaning relatively few TR volunteers (Hurricane Sandy and the Texas floods being notable exceptions). With access to skilled logisticians, TR deploys volunteers who live closest to the disaster, sets up temporary sleeping quarters in close-by schools or other shelters, and utilizes community organizations for meal provision while the work goes on. They train a corps of volunteers to lead Instant Management Teams (IMTs) who are the first to arrive and track damage, communicate specific volunteer needs, and set up a base. When they arrive to help, often literally working under large TR banners, local business owners often offer donated equipment, or rentals are secured in neighboring towns. Disaster relief efforts are coded by type as they occur, indicating if it warrants a regional or national response. Volunteers are reimbursed travel costs (within parameters) based on a sliding scale that depends on the type of disaster and the number of days the volunteer worked on the project. TR is usually able to arrange donated flights or reduced ticket costs through various airlines (and covers mileage costs for those who drive).\nTR got started with a group of vets from the post 9-11 generation but has grown quickly as veterans of all ages come forward to participate. Wood mentioned that Vietnam vets “still need this” community outreach, for instance, and having older vets working with younger has been to the benefit of both. More successful vets have opened doors for jobs for those just returning from war. Younger vets have brought technical skills and enthusiasm to the organization as they look for ways to use their military training to find their new life mission.\nOne female vet talks about how her volunteer service with TR after the 2013 Tacloban (Philippines) typhoon quite literally “turned [her] life around.” It gave her a sense of purpose and feeling of empowerment that spurred a job change and an entirely new outlook on life. Another Marine reservist and Gulf War veteran's first outing with TR was working to repair a community service center for disabled vets in Virginia. He described himself as unwilling to let others into his life at the time, but bonded with the TR members who were struggling with the same issues. He left law enforcement to go into the field of emergency planning for the federal government and participates in TR events whenever he can. Yet another vet was just back from Nepal working on earthquake relief. He described how lots of aid organizations were clustered around Katmandu because it was easier to work there. The 65-person TR team drove 5 hours up into the mountains and witnessed countless scenes of total devastation and no disaster teams present at all. Working with assistance from TR headquarters, the team narrowed the needs down to an “achievable mission,” setting up a base where combat medics could treat neighbors in the nearby villages, set up hospital tents, and conduct search-and-rescue missions. After that was complete, the team cleared out the rubble so that a school located at the top of a mountain in one of the villages could get back up and running, all the while enduring major earthquake aftershocks. These tasks were accomplished with the political help of Sir Edmund Hillary's granddaughter who “fell in love” with TR and is revered in Nepal. The UK chapter of TR sent over former British soldiers who are native Gurkas and knew the customs and spoke the local language.\nAs to future plans, it seems the sky is the limit. Team Rubicon has had conversations with the Secretary of the Veterans' Administration who is very interested in “the power of purpose in people's lives,” wanting to find a way to work more closely with TR. Elsewhere, Wood is interested in creating apprenticeships so that vets can obtain job training/trade skills as part of new long-term recovery work, noting that rebuilding work has not usually been done well following natural disasters. Once trade skills become part of the TR portfolio of volunteer skills, they could bid on large rebuilding contracts, many of which offer incentives for veterans to participate. Finally, the organization is adding one paid staff member to each region (regional groups being run entirely by volunteers now) in order to build a deeper volunteer pool, offer more training and build these sectors into closer communities.\nWood argues persuasively that there is no organization operating within the U.S. that has similar rapid-response capability and technical training. Interestingly, he admires the disaster response work done by the Southern Baptist organization, but points out that they cannot match TR's in-depth skills. The TR insignia is a cross turned on its side with two streams running through: that gap between the streams signifies the window of opportunity for TR responders, the time between the onset of the disaster and the arrival of conventional aid organizations. Once those aid organizations arrive, TR moves on. That gap also signifies the desire to bridge the gap between military and civilian life by providing veterans with a purpose (disaster relief), a community (through serving others), and self-worth (from seeing the impact one individual can have). The cross is a symbol of medical aid and is turned on its side to represent a new aid paradigm. In all these respects, it's clear that TR sees itself as a reinvented Red Cross. It is a grand ambition and a worthy one.","Outload Execution to Support Hurricane Sandy Relief Effort\nNovember 28, 2012\nFort Bragg, NC-- In late Oct. 2012, Hurricane Sandy, a \"once-in-a-100 years\" storm ripped through the mid-Atlantic States, leaving behind it a path of death and destruction. Coastal areas were flooded, millions were without power, and thousands were homeless. On 4 Nov., the 82nd Sustainment Brigade, under the command of Col. Christopher Sharpsten, received notification from XVIII Airborne Corps that it was to provide sustainment mission command for a logistics task force in support of the Hurricane Sandy NORTHCOM Response Force.\nThis is the type of mission the Brigade is equipped and trained to perform. It is expected to provide expeditionary sustainment, rapid provision of logistics, and personnel services necessary to maintain and prolong operations until successful mission completion.\nThe success of this type of mission is dependent upon exercising a style of leadership that empowers leadership through the ranks to be proactive and decisive when faced with a unique and peculiar challenge presented by such a destructive force as Hurricane Sandy. The fact that the Brigade was on the ground in New Jersey with a functional Mission Command Center (MCC) in 48 hours after notification is testament to the effectiveness of that style of leadership.\nThe Brigade staff clearly demonstrated its responsiveness and ability to task-organize as it began to translate the intentions of command into actions in the early morning hours of Nov. 5th. The staff decided the Brigade would deploy 83 key personnel and equipment by four modes of transportation: military air, bus, line haul, and tactical convoy.\nAccomplishing the difficult task required audacious leadership and a collaborative effort from junior and senior leaders from the company level up. These leaders' ability to task-organize and delegate responsibilities allowed the Bde. to simultaneously perform the numerous critical tasks required to out-load the deploying personnel.\nThese tasks included manifesting personnel, coordination for line haul trucks and bus support for ground movement, coordination for air support, development of load plans and their execution, identifying all necessary liaison officers, and conducting a communications exercise (COMMEX) to establish the primary, alternate, contingency, emergency (PACE) communication plan.\nAn extraordinary effort was put forth by Bde. adjutant, Maj. Batina Church and the Bde. human resources (S1) staff. As a result, manifesting began within three hours of notification. The torch party, made up of 23 personnel, was able to deploy by bus within 12 hours of notification. The tactical convoy, consisting of 11 personnel and five vehicles, deployed within 18 hours, and the main body deployed by bus and air within 24 hours of notification. The flawless execution of a well-organized and executed out-load plan enabled the Bde. to establish the command center at Joint Base McGuire-Dix-Lakehurst (JB MDL), N.J. immediately upon arrival.\n\"During a real world expeditionary contingency, it is imperative that we work as a team,\" said Bde. Unit Movement Officer (UMO), 1st Lt. William Cunningham. \"I felt comfortable empowering my subordinates to get the job done. It's the culture we live by in this brigade. Out-load is what this brigade does best; everyone understood their responsibilities and worked diligently to successfully deploy the Bde.'s Mission Command Center.\"\nThe 82nd Special Troops Battalion (STB) plans and operations (S3) shop successfully coordinated a C-17 Globemaster III aircraft to transport mission-essential communication equipment from the 178th Signal Company, 15.5 short tons of tactical equipment, and 16 personnel. They built the Unit Deployment List (UDL) for the line hauls, developed the air load plans, and coordinated the buses to push out the main body of personnel. This was all accomplished within a 24-hour timeline.\nAs the Brigade staff continued to develop and refine the out-load execution plan, the Battalions and Companies executed their respective action plans. Before 9 a.m., 5 Nov., the 189th Combat Sustainment Support Battalion (CSSB), under the command of Lieutenant Col. Theodore White, was tasked to convoy mission essential communication equipment. White's team had already completed their pre-combat checks and inspections, identified their drivers, and were ready to load three Palletized Loading System (PLS) trucks.\nThe convoy would consist of five vehicles, the PLS trucks from the 189th CSSB, one heavy expanded mobility tactical truck (HEMTT) wrecker, and one HMMWV from the 82nd STB. 189th CSSB proved their motto, \"First in Maintenance,\" to be appropriate.\nThe military vehicular convoy, traversing from Ft. Bragg, N.C. to JB MDL, a distance of more than 550 miles, successfully delivered the vital communications equipment without a single maintenance issue. This allowed the brigade to establish critical communication in their MCC (forward) in a perfunctory and timely manner. The leadership of the 189th CSSB recognized that success lies in the preparation of assets assigned to it for any expeditionary contingency. Maintaining a high readiness state at all times is imperative for the overall success of the Bde.'s mission.\nWith audacious leadership and a rigorous training regimen that drives excellence in performance, the Bde. has shown its ability to expeditiously deploy assets, meet any contingency, anytime, anywhere, in support of military action, or in support of humanitarian relief, as was the case with the Hurricane Sandy disaster response effort."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:451ca0db-b87b-4c8f-99b3-8134b5186d7c>","<urn:uuid:a45cbd2f-41c0-4e2d-bf5c-fbca5d8d467c>"],"error":null}
{"question":"What are the primary material options for exterior doors, and what historical security issues have door locks faced?","answer":"The main materials for exterior doors are wood, fiberglass, and steel, each with distinct characteristics. Wood doors offer a classic look but need regular maintenance, fiberglass doors are low-maintenance and energy-efficient, and steel doors prioritize security. Regarding historical security issues, even the most secure locks have proven vulnerable. This was demonstrated in 1851 when A.C. Hobbs picked the supposedly unpickable Bramah Precision lock after 52 hours of work, during what became known as The Great Lock Controversy. This incident shattered people's sense of security, including that of the Bank of England.","context":["Your home's exterior doors play a significant role in your home's curb appeal, energy efficiency, and overall security. Whether you're planning to sell your home or just want to give it a facelift, updating your exterior doors is an excellent investment. Here are the top 3 things homeowners should consider when updating their exterior doors, including the average cost of the project.\nThe first thing to consider when updating your exterior doors is the material. The most common materials for exterior doors are wood, fiberglass, and steel. Wood doors are the most traditional, providing a classic and elegant look, but they require regular maintenance to keep them looking their best. Fiberglass doors are low maintenance and energy-efficient, making them an excellent choice for homeowners who want a balance of style and practicality. Steel doors are durable and secure, making them an excellent choice for homeowners who want to prioritize safety.\nThe cost of updating your exterior doors will depend on the material you choose. On average, a wood exterior door costs between $500 and $2,000, while a fiberglass door costs between $1,000 and $4,000. Steel doors are the most affordable option, with an average cost of between $500 and $1,500.\nThe style of your exterior door should complement the architectural style of your home. When choosing a door style, consider the design elements of your home, such as the color, texture, and shape. Popular door styles include traditional, modern, craftsman, and rustic.\nIn addition to the style of the door, you should also consider the type of door. The most common types of exterior doors are single doors, double doors, and sliding doors. Single doors are the most popular and come in a variety of sizes and styles. Double doors add elegance and grandeur to your home's entrance. Sliding doors are an excellent choice for homeowners who want to maximize their outdoor living space and bring more natural light into their home.\nThe cost of updating your exterior door's style will depend on the type of door you choose and any customization options. On average, a single door costs between $500 and $3,000, while a double door costs between $1,000 and $5,000. Sliding doors are the most affordable option, with an average cost of between $1,000 and $3,000.\nYour exterior doors are the first line of defense against intruders, making security an essential consideration. When updating your exterior doors, consider the locking mechanism, the strength of the door, and any additional security features, such as security screens or smart locks.\nThe cost of updating your exterior door's security will depend on the level of security you require. On average, a basic lock system costs between $50 and $150, while a smart lock system can cost between $100 and $500. Security screens are an additional cost, ranging from $100 to $500.\nUpdating your exterior doors is an excellent investment in your home's value, energy efficiency, and security. By considering the material, style, and security of your exterior doors, you can find the perfect balance of style and practicality that meets your needs and budget.","Assessing Cyber Risks to Your Access Control System\nPrint Issue: March 2020\nAround lock sat in the front of Joseph Bramah’s shop in London with a challenge displayed on the window: whoever could pick the Bramah Precision lock would win 200 guineas (roughly $30,000 today). That challenge would remain for 67 years until A.C. Hobbs—an American locksmith—took up the gauntlet.\nHobbs brought a great deal of experience to the table. He had gained recognition in America for demonstrating to bank managers that their locks could be picked, so they should be replaced with locks of his own invention.\nAt the Great Exhibition hosted in London in 1851, Hobbs announced after successfully picking a Chubb “Detector” lock that he would open Bramah’s creation. Bramah’s sons set Hobbs up with a workspace above their shop. For 52 hours, Hobbs worked at the lock until he successfully picked it.\nHobbs’ success became known as The Great Lock Controversy, striking fear into the hearts of everyone who had previously used the Bramah lock—including the Bank of England—because they believed it could not be picked. Their sense of security was shattered.\nSince then, methods for locking doors and controlling access have changed with the times and technology advancements. Now, instead of having a guard monitor and log when a door is unlocked and opened in a facility, and then verify that that individual is allowed to do so, most organizations rely on access control systems. And often, these systems are connected to the Internet—making them vulnerable to cyber intrusions.\n“Older access control systems were not meant to be tied to the building network or the organization’s network,” says Coleman Wolf, CPP, CISSP, senior security consultant for Environmental Systems Design, Inc., (ESD) and a member of the ASIS International IT Security Council. “There are adapters that can be used to put those on the network. They function just fine. I can access the control panel from my desk, but the security isn’t always the best.”\nThe access control system is “meant to provide a function, but either the device was not built to have password protection or the person who installed it wanted to get it up and running, so they didn’t put in the effort to install the security with it,” Wolf adds.\nBy connecting an access control system to the Internet, the system becomes part of the Internet of Things (IoT). Typical IoT devices include thermostats, electrical outlets, light switches, refrigerators, smart speakers, and doorbells. They also now include—in the security arena—cameras, alarm systems, smoke detectors, locks, and other access control devices, says David Feeney, CPP, PMP (Project Management Professional), and advisory manager of cyber and physical security risk services at Deloitte.\n“Before IoT, everything that was connected to a network was a network device in the traditional sense,” explains Feeney, who is past chair of the ASIS Physical Security Council. “Now, almost anything can be a network device. And while the computer industry has had decades to incorporate security into its products, services, and overall DNA, IoT is essentially a toddler—growing rapidly but with most of its maturation still ahead.”\nAll of these IoT devices face a “gauntlet of cyber threats,” Feeney says, including malware, man-in-the-middle attacks, brute force attacks, dictionary attacks, IP spoofing, denial of service and distributed denial of service (DDoS) attacks, session hijacks, and more.\n“The difference that IoT brings is that the attack surface—the aggregation of all points at which an attacker can gain access—is now exponentially larger once access control and other IoT devices are added to the network,” Feeney adds.\nIt might seem obvious why someone would want to compromise an access control system: to unlock the doors to a building to gain entry.\n“The first thing that people think about is that once they’re inside the system, they have control over the system so they can unlock doors or disable sensors—things that are part of the actual mission of the access control system itself,” Wolf says.\nFor instance, in a worst-case scenario at a highly controlled environment like a hospital, a compromised access control system could be used to lock surgeons out of an operating room or open doors to the pharmacy.\nBut there’s another equally concerning reason someone might want to hack an access control system, Feeney adds.\n“Your natural first thought might be that access control systems are attacked because attackers want to gain access to an area, and the system is standing in their way,” explains Feeney. “That is one reason. But the reason is often that an attacker simply wants access to the network, and an access control system is as good an entry point as any other.”\nRegardless of the method of infiltrating an organization, attackers are often looking to infiltrate the network and then move within it to gain access to more sensitive or valuable information.\nHackers used this method during the infamous Target breach in 2013. They compromised a third-party vendor, obtained valid credentials from an unknowing authorized user, and connected to Target’s network using its vendor-portal process. The malicious actors then leveraged this access to obtain payment card data and personally identifying information about Target customers.\n“Maybe there are employee databases where they could steal information,” Wolf says. “Or they could use that access to spread ransomware, where files and systems could be encrypted and held hostage—forcing the organization to pay to free up that information.”\nLeveraging an intrusion into the access control system to the organization’s building system could also pose safety risks to employees—such as setting off a fire alarm—or equipment.\n“If you’re able to control the HVAC system, you could prevent cooling of data center space, so servers start to overheat and fail,” Wolf says. “And that can cause interruption of business or operations.”\nMitigating Existing Risk\nDespite the numerous vulnerabilities that exist, there are myriad ways to mitigate the risk of compromise to an access control system.\n“I work with a lot of clients who don’t have any drawings of where their devices are—they are flying blind,” Wolf says. “They don’t know, if something goes wrong, where to go and what component to look at.”\nThe first step for security professionals with an existing access control system that is connected to the network is to fully understand the system—where the readers are, how it works, how it is connected to the network, who has access to the system, and who has administrative privileges over it. Then, all that information should be documented.\n“Identify where everything is and, probably most importantly, how those devices intercommunicate with each other and the outside world,” Wolf adds. “An Internet connection is one thing, but with older systems we’ll see a DSL line or dial-up modem connections to systems so a contractor can log in and make changes to the system.”\nThese systems may have been installed decades ago. People often forget about those connections, which could be used by malicious actors to infiltrate access.\nWolf also recommends security professionals working with an existing access control system connected to the network assess if it meets the organization’s current security requirements.\nStarting from Scratch\nFor those in the fortunate position of installing a new access control system, the process should start with a “soul-searching discussion” on the risks and benefits of connecting that system to the Internet, Feeney says.\n“If there isn’t a significantly compelling benefit to essentially adding a door to your network, it is arguably not worth doing,” he explains. “In the case of access control, there may be a strong case for doing this—especially if the desired end goal is moving to the cloud. In this case, be sure to leverage best practices to incorporate security into your new network architecture.”\nThe organization should consider if the access control system should be on a network separated from other assets. Doing this will help mitigate the risk that an intruder will use the access control network to obtain corporate information.\n“If the ultimate goal is to move your access control system to the cloud, this network separation can still be done at the organization level,” Feeney says. “The separate access control or IoT network will connect to the cloud infrastructure. The original corporate network will separately protect all other assets. So, if the access control network’s connectivity is compromised, the attacker will not get access to the corporate network.”\nOnce a decision is made about what network the system should reside on, the organization should designate who is responsible for that network and the day-to-day management of it. This is critical because the system will require regular patching and updates to mitigate new security threats.\n“Often an organization’s IT department is better equipped to maintain the system because—if they’re a good IT organization—they will have a patch management process in place to make sure that the network switches and all the network servers are up to date,” Wolf says.\nWhen purchasing the actual access control system, the individual responsible—such as the physical or IT security representative—should ask vendors how data from the reader to the master console is protected, says Darrell Brown, CISSP, information security program manager at La-Z-Boy Incorporated and member of the IT Security Council.\n“Is that data in transit encrypted? At what level? And what is the right fit for my company?” Brown adds.\nOrganizations should also ask how often the vendor itself issues patches to its products, and what the process for issuing those patches is.\n“Proactively query your providers about patches and security updates to your hardware,” Feeney recommends. “Many access control devices traditionally get patches because customers request a feature or report an error that requires the patch. Instead, patch these devices like you do your computer—proactively as part of a comprehensive security strategy.”\nOrganizations should also have a robust master service agreement that outlines expectations and the responsibilities the vendor has to the organization.\n“Have clear lines that delineate who owns what part of the system,” Brown adds. “Who’s responsible? Where’s the backup? Is there a backup? How do we ensure failover to it?”\nAnd while the system is being installed and implemented, security professionals should ensure that the process follows best practices for maintaining good cyber hygiene. This starts with disabling default passwords to create strong, unique passwords for the system, and limiting administrative privileges.\nESD frequently encounters operating systems set up to automatically give administrator privileges to any users.\n“Most people don’t need that, and by restricting that, you’re ensuring that if a bad guy were to gain access using one person’s credentials, they wouldn’t have the ability to have administrative rights over the whole operating system,” Wolf says.\nAccess control systems, like all locks, can be compromised by motivated actors given the right circumstances. Security practitioners should not assume that the system itself is secure.\n“Security is ideally a shared responsibility between consumer and provider,” Feeney says. “You’ll find this to typically be the case. But where the separations of responsibilities lie can differ greatly. For that reason, always check your service level agreement to understand what security responsibilities your provider has and what is left to you as the consumer.”\nMegan Gates is senior editor at Security Management. Contact her at [email protected]. Follow her on Twitter @mgngates."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:75a6a9cb-1536-49d2-aafd-d489674c6a32>","<urn:uuid:e2d4eaf1-f92e-4f65-8645-3672e13810ad>"],"error":null}
{"question":"What are the key cleaning considerations for both vintage set triggers and paintball gun components, and how do their maintenance requirements differ?","answer":"For vintage set triggers, cleaning should focus on removing dirt and powder fouling while avoiding disassembly or filing of parts. Some set triggers may require extended soaking to restore functionality if oil has congealed. Paintball guns require more comprehensive cleaning procedures - they need specialized cleaning kits rather than household cleaners, must be completely disassembled (except for the trigger mechanism), require special attention to barrel cleaning with specific squeegees, and need regular inspection of o-rings for cracks or brittleness. Unlike set triggers, paintball guns specifically require specialized oil for lubrication of moving parts.","context":["Volume: 53 | Back to issueSubscribe Now\ncolumn By: Gil Sengel | July, 21\nOnce popular on pre-1930 single-shot target rifles, all European cartridge rifles and most muzzleloaders, this trigger is rarely seen on new cartridge guns today. Why? Simply because today’s primers are more sensitive and uniform than ever. Extremely heavy mainsprings to guarantee ignition are no longer needed, so trigger pulls can be adjusted downward to the point where the added expense of a set trigger is no longer necessary.\nNevertheless, anyone who likes to shoot older guns, or their new reproductions, will eventually come across a rifle and pass it up because of fear of the set trigger. As noted in the previous column, there is nothing to go wrong except dirt or powder fouling buildup, which is easily remedied. If one is disassembled for entertainment, or someone starts filing on parts, then all bets are off!\nThe foregoing also applies to a slightly different set trigger. As one would expect, humans could not leave well enough alone. They also created two-, three-, four- and even five-piece triggers! Published drawings show these pieces to be tiny, oddly shaped things, no two of which are alike. Each pivots on a pin through the trigger box. This provides a simple way to determine the number of parts in any set trigger – just count the pins and subtract one for the setting trigger.\nThese set triggers do not have ground sear surfaces that slide apart in a normal sear/hammer relationship. Thus, there is nothing to wear, chip or break. When the setting trigger is pulled, tiny flat springs push each piece into proper alignment with the next to produce a state of equilibrium. A tiny movement of the firing trigger then disrupts this balance, causing the pieces to rotate out of the way, releasing an arm on the setting trigger to spring upward, firing the rifle. One early competitor remarked that his set trigger was so finely made that the rifle would fire if simply tipped up from horizontal to vertical!\nSet triggers consisting of several parts are probably quite rare. I have seen very few. All worked perfectly except one that appeared to contain congealed oil. It took several weeks of soaking, but eventually all the little parts moved and the trigger functioned normally. Nevertheless, since one-piece set triggers can be set so light that most folks can’t feel contact with the trigger before it releases, what’s the point?\nAnother series of set triggers is that produced by Winchester. There were three in the group, with the Schüetzen Double-Set available on the Winchester single-shot rifle. It is the same as the one-piece triggers covered in the last issue. The two others in the series, the single set and close-coupled double set have small sear surfaces that slide apart, rather than being held in equilibrium. These wear and this is probably the reason many of them are found in non-working condition. If backing out the adjustment screw and cleaning doesn’t allow the trigger to set, it is worn, or worse, and will require parts to be made. This is far beyond the realm of the home gunsmith.\nNow comes a modern set trigger. It was made by the M.H. Canjar Company in Denver, Colorado. This outfit produced many accessories for high-power and small-bore target shooters, but its main product was the Canjar Precision Trigger.\nThe Canjar trigger itself, however, was not a set trigger. It was a replacement for the military designs in the dozens of surplus bolt guns being imported in the 1960s through the 1980s. Canjar triggers were better than needed on sporting rifles, but at the time, many target guns were being built on surplus Mauser and Springfield actions. Virtually all custom varmint rifles were also built on these actions, and they needed triggers as well.\nThe reason for covering the Canjar non-set triggers is because their set trigger involves only the addition of a set trigger shoe in place of the normal curved finger piece. When unset, the trigger looks like one fitted with a clamp on, half-inch wide trigger shoe so popular at the time. A closer look shows that the curved finger piece has been removed and the shoe is attached by a single cross pin. In the front of the shoe a thin, vertical slot has been milled.\nTo set this trigger, a fingernail is hooked behind the shoe and pushed forward until the set trigger lever protrudes from the slot in the front of the shoe. There is no sound produced when the trigger sets. Touching the small, exposed piece releases the shoe, which snaps back with enough force to jar the sear out of engagement and fire the rifle.\nThe only problem I have seen with a Canjar set trigger is dirt or gun case lint getting into the mechanism because it is exposed outside the stock. Simple cleaning as described in the last column corrects this. Other complaints were just what you would expect – set trigger pull was too heavy. When newly installed, I always set the trigger to release at just under one pound. Nevertheless, more than one owner wanted the set trigger to release when the side of the stock was rapped with the knuckles!\nPhotos show a Canjar set trigger installed on a Ruger No. 1 built with a very heavy 30-inch barrel as a Schüetzen-style cast bullet rifle. From a benchrest, there is no real difference in group size between an unset 2.5-pound pull and set 10-ounce let off. Offhand is a different story! The light pull cuts scores in half.\nSadly, except for muzzleloaders or a very few reproductions of old long-range rifles, newly made set triggers are a thing of the past. Yet with proper practice, they provided a delightful solution to a very real problem for competition riflefolk at the time. They are from an era when target shooting was a more leisurely pastime. Do not fear the set trigger. Just don’t disturb it so long as it functions properly, but clean if necessary – and never file, bend or disassemble one.","Your Cart is Currently Empty\n5 Tips For Cleaning Your Paintball Gun\nCleaning your gun certainly isn’t the most glamorous or exciting part of Paintball, but it is (unfortunately) an essential task. A poorly maintained gun is one that underperforms and has a much shorter lifespan. The last thing you want is for your gun to let you down mid-battle. These five tips should make the cleaning process as painless as possible!\nChoose the right equipment\nFirst and foremost, it’s important to note that standard household cleaners like soap, sponges and cloths usually won’t cut it for a paintball gun. We recommend using a specialized cleaning kit, which will include squeegees designed for use on a paintball gun, swabs, and gun oil to lubricate the various moving parts. Some guns include these tools as part of their starter kits, including the Tippmann Cronus, but they can also be purchased separately. It may be tempting to use more common alternatives, and a Q-tip or toothbrush can be suitable if you’re really desperate, but if you treat your gun well, it will reward the favor in the field. Gun oil is particularly important, so it's worth purchasing that at the very least.\nTake the gun apart\nIt's not the most enticing proposition, but if you’re going to clean your gun thoroughly, you’re going to have to deconstruct it into its component parts. The most important thing to do is remove the tank. That’s absolutely vital, and it's a major health and safety concern when you’re cleaning your gun. Modern tanks like the HK Army are exceptionally safe, but you still need to treat them with care, and it’s important to ensure that there’s no gas in your gun. After that, use your schematics diagram to disassemble the rest of the gun. Spread the parts across a table in an organized manner so they will be easy to put back together later. This will also help when you come to clean individual components.\nPay special attention to the barrel\nThe barrel is one of the main areas of concern and is likely to need the most attention. Even if the rest of your gun seems to be in good condition and you keep up-to-date with your maintenance, the barrel will almost certainly need cleaning. That’s because paint residue builds up over time, no matter how meticulous you are. The effects of this are quite profound, including decreased accuracy and even jamming in the middle of an intense battle! A squeegee is perfect for this task as you can pass it easily through the barrel and remove any debris or traces of paint. Better still, if you can get a hold of a specialized paintball gun cleaning kit complete with gun oil and swabs, this process will be much easier. Most guns, like the Tippmann U.S. Army Alpha, actually come with specialized barrel squeegees that are perfectly suited to this task.\nClean the grip frame\nAnother part of the gun that has a major effect on performance is the grip. Paint has a tendency to build up over time, as does other debris from a match. When this buildup occurs on the grip frame, it has a detrimental effect on accuracy. Fortunately, the grip is one of the easiest parts to clean. Scrub away any dried-on paint or dirt using a squeegee or even a toothbrush if you really have to. It’s important to remember not to touch the trigger, however. While it may be tempting to disassemble the trigger and give it a thorough cleaning, it will be extremely difficult to put together again, even if you’re an expert. A faulty trigger will radically undermine the gun, and it might even be enough to stop it working altogether.\nInspect the o-rings\nO-rings are crucial components on any paintball gun. They act as air/CO2 seals, and if they malfunction, you’ll be in serious trouble on the field and your gun will be next to useless! Fortunately, damaged or worn o-rings are an easy problem to spot and even easier to remedy. Look out for cracked o-rings or any that have become dry and brittle. You'll be able to spot a flimsy component right away. This isn’t a problem that you should ignore, and it’s worth replacing any worn components immediately to avoid problems further down the line. Replacement o-rings are cheap, readily available and easy to install.\nWhen you’ve completed all these tasks, perform a final maintenance check, oil the gun using paintball gun oil, and begin the process of putting everything back together!"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:fbd949d2-fb32-425c-86cb-1d1fbb559d5e>","<urn:uuid:e6a8c479-ccc9-45a8-862b-484dce0213ac>"],"error":null}
{"question":"What are the key differences between agricultural land conservation programs and aviation efficiency initiatives in terms of their environmental impact and economic considerations?","answer":"Agricultural conservation programs and aviation efficiency initiatives differ significantly in their approaches and economics. USDA's conservation programs, like the Conservation Reserve Program, provide direct financial assistance ($1.8 billion annually) to remove sensitive land from production and implement environmental practices. In contrast, aviation efficiency improvements require substantial upfront investments (approximately $11 million extra for single-aisle aircraft and $40 million for twin-aisle aircraft) but can generate significant operational savings ($2.5 trillion in lifetime operating savings by 2050). While agricultural programs focus on land preservation and environmental health through voluntary participation, aviation initiatives target fuel efficiency improvements of 15-20% through technological advances like new engines and wingtip devices, though their implementation can be hindered by low fuel prices.","context":["Land and Natural Resources\nU.S. agricultural production relies heavily on the Nation’s land, water, and other natural resources, and has a direct impact on the quality of the Nation’s natural environment. Over the years, improvement in the sector’s productive use of resources has reduced the amount of land and water needed per unit of output, and concerted public and private efforts have improved the sector’s environmental performance. These charts document several aspects of these trends.\nUSDA provides financial and technical assistance to agricultural producers through voluntary conservation programs to address natural resource concerns. USDA’s funding for major working lands conservation programs, such as the Environmental Quality Incentives Program and the Conservation Stewardship Program, has more than doubled over the past 25 years. At the same time, funding for the Conservation Reserve Program has stayed fairly constant. The Conservation Reserve Program pays farmers to remove environmentally sensitive land from production and plant species that will improve environmental health and quality. Working land programs provide technical and financial assistance to producers who use, install, or maintain conservation practices on land in production (e.g., nutrient management, cover crops, and field-edge filter strips). Agricultural easements provide long-term protection for agricultural land and wetlands. The Regional Conservation Partnership Program is a partner-driven program that leverages partner resources to advance innovative projects that address natural resource challenges on agricultural land.\nThe U.S. Environmental Protection Agency estimated that agriculture, including its electricity consumption, accounted for an estimated 11.2 percent of U.S. greenhouse gas (GHG) emissions in 2020. Globally, carbon dioxide emissions are the largest contributor to climate change. However, the emissions profile for agriculture differs from that of the overall economy. In agriculture, crop and livestock activities emit nitrous oxide and methane, mainly from fertilizer application, enteric fermentation (a normal digestive process in animals that produces methane), and manure storage and management. GHG emissions from U.S. agriculture have increased by approximately 6 percent since 1990, while total U.S. GHG emissions in 2020 were 7.3 percent lower than they were in 1990.\nThe 2012 U.S. land area amounted to nearly 2.3 billion acres, with nearly 1.2 billion acres in agricultural use. The share of the land base in agricultural use declined from 63 percent in 1949 to 52 percent in 2012, the latest year for which comprehensive national data are available. Gradual declines have occurred in cropland, while grazed forestland has decreased more rapidly. In 2012, 392 million acres of agricultural land were in cropland (an 18-percent decline from 1949); 655 million acres were in grassland pasture and range (4 percent more than in 1949); 130 million acres were in grazed forestland (59 percent less than in 1949); and 8 million acres were in farmsteads and farm roads (45 percent less than in 1949). Urban land, while it represents a relatively small share of the U.S. land base, has nearly tripled in area since 1949.\nUSDA’s Conservation Reserve Program (CRP) covered about 22.0 million acres of environmentally sensitive land at the end of fiscal 2022, with an annual budget of roughly $1.8 billion (making it USDA’s largest single conservation program in terms of spending at that time). Enrollees receive annual rental and other incentive payments for taking eligible land out of production for 10 years or more. Program acreage tends to be concentrated on marginally productive cropland that is susceptible to erosion by wind or rainfall. A large share of CRP land was located in the Plains (from Texas to Montana), where rainfall is limited and much of the land is subject to potentially severe wind erosion. Smaller concentrations of CRP land were found in eastern Washington, southern Iowa, northern Missouri, the Mississippi Delta, and southeastern Idaho and northwestern Utah.","Project Drawdown defines the efficient aviation solution as the increased use of technologies to reduce aircraft fuel burn. This solution replaces conventional aircraft with existing global fleet-wide fuel efficiency.\nIn 2005, all of aviation’s share of global warming was 4.9 percent despite being only 2.2 percent of carbon dioxide emissions in that year. This is due to aviation’s generation of other climate pollutants besides carbon dioxide that also cause warming. Considering aviation fuel consumed in 2016, and all global carbon dioxide emissions in 2016, all aviation is estimated to have caused approximately 2.6 percent of manmade carbon dioxide emissions in 2018. Growth in aviation’s share is causing increasing alarm. Airplane fuel efficiency efforts aim to reduce fuel use per passenger-kilometer of air travel. Though freight-only aircraft fuel efficiency is not analyzed here, part of the impact on air freight fuel use is accounted for in the large fraction of total air freight that is carried in the belly of passenger aircraft.\nThere are numerous technologies and operational approaches for reducing airplane fuel use; only the most impactful technologies in use today to improve fuel efficiency were included in this study. Therefore, well-publicized but noncommercial technologies such as aviation biofuels were excluded.\nThis analysis includes the newest, most fuel-efficient aircraft (called “intermediate generation”), as well as the use of fuel efficiency retrofits to existing aircraft. Intermediate generation aircraft are expected to be 15–20 percent more fuel-efficient than earlier models, in part as a result of more fuel-efficient engines, new wingtip devices, and light weighting approaches. Research suggests that the combination of these three technologies in a retrofit would amount to efficiency improvements comparable with a newer aircraft model. In this study, new and retrofitted aircraft are compared to conventional aircraft with the existing global fleetwide fuel efficiency.\nTotal Addressable Market\nThe total addressable market for efficient aviation is measured in terms of total interurban passenger travel by air, projected for every year of analysis (2020–2050), in billion passenger-kilometers. Current adoption was taken as the total passenger-kilometers provided by existing intermediate generation aircraft, in the single-aisle and twin-aisle categories.\nProjected adoption of fuel-efficient aircraft was based on the expected production of intermediate generation aircraft, according to published delivery rates of major suppliers. Delivery rates were assumed fixed for each aircraft type.\nImpacts of increased adoption of efficient aviation from 2020 to 2050 were generated based on two growth scenarios, which were assessed in comparison to a Reference Scenario where the existing fraction of higher-efficiency aircraft remains constant.\n- Scenario 1: Fuel burn is improved by 13 percent, Boeing and Airbus supply aircraft at their published rates, and an additional supplier starts adding comparably efficient aircraft to market. One hundred aircraft are retrofitted annually.\n- Scenario 2: Fuel burn is improved by 18 percent. Aircraft delivery rates, retrofitting, and retirement are similar to the Scenario 1. Global load factors increase to 83 percent (U.S. average).\nEmissions for each scenario were estimated using the fuel emissions factor taken from the Intergovernmental Panel on Climate Change (IPCC) guidelines, and applied to fuel consumption data from the International Council on Clean Transport (ICCT).\nCosts of adopting the intermediate generation aircraft are reported as the additional cost compared to adopting aircraft with average fleet efficiency. For each intermediate generation aircraft, an equivalent conventional aircraft was priced and the price difference was derived. The average difference for single-aisle aircraft was around US$11 million, and that of twin-aisle was US$40 million. Operating costs, which included fuel costs, were derived using historical data from the International Energy Agency (IEA). The solution’s operating costs were reduced by the efficiency improvements noted above.\nTo prevent double-counting, steps were taken to ensure that the total travel demand of all non-urban passenger Transport Sector solutions remained below the projected total non-urban travel demand.\nIn Scenario 1, a potential reduction of 6.3 gigatons of carbon dioxide-equivalent greenhouse gas was found from 2020 to 2050, which corresponds to an 80 percent adoption rate by 2050. Net costs over that time would be US$863 billion above the conventional approach. Efficiency improvements are estimated to bring lifetime operating savings of US$2.5 trillion, however. For the Scenario 2, the emissions avoided amounted to 9.2 gigatons with 85 percent adoption.\nThe use of more efficient aircraft is desirable for airlines in times of higher fuel prices. It would have direct bottom-line impacts, as fuel often represents a third of operating costs. Since 2015, however, fuel prices have been relatively low, and there is no assurance that prices will return to their previous levels of almost three times higher. At these lower fuel prices, the financial attractiveness of these aircraft efficiency improvements is not great, and in some cases result in negative net present values for airlines according to our calculations. However some of this may change with the coming implementation of the Carbon Offsetting and Reduction Scheme for International Aviation (CORSIA) program. To some extent, inclusion of fuel switching approaches such as aviation biofuels can help reduce the need for aircraft technology improvements.\nThere are limitations to this approach. For example, the potential of other technologies being implemented was excluded in this study. Also, the Reference Scenario conservatively assumes fixed fleet efficiency. These limiting assumptions were made to show the impact of existing technologies on the airline industry. The results indicate that airlines have a role to play in the planet reaching the point of drawdown.\n Lee, D. S., Fahey, D. W., Forster, P. M., Newton, P. J., Wit, R. C., Lim, L. L., ... & Sausen, R. (2009). Aviation and global climate change in the 21st century. Atmospheric Environment, 43(22-23), 3520-3537.\n From OECD/IEA (2018) World Energy Balances 2016, OECD/IEA, Paris\n According to Airbus, belly freight is about 52 percent of all air freight.\n Including the 787, 777X, and 737MAX family of Boeing, and the A320neo family, A330neo family, and A350XWB of Airbus.\n Also called “winglets” or “sharklets”, these devices cannot be installed on all older aircraft due to lack of sufficient wing strength and other limitations.\n For more on the Total Addressable Market for the Transport Sector, click the Sector Summary: Transport link below.\n Current adoption is defined as the amount of functional demand supplied by the solution in 2018. This study uses 2014 as the base year due to the availability of global adoption data for all Project Drawdown solutions evaluated.\n Delivery of a single-aisle aircraft is assumed to provide 247 million passenger-kilometers, and a twin-aisle aircraft 840 million passenger-kilometers, of adoption.\n This additional manufacturer can represent any or all of numerous nascent options, such as COMAC of China or the UAC of Russia. It produces around 5 percent of all efficient aircraft annually.\n For instance, the Airbus A320neo was considered a more efficient replacement for the A320, and the Boeing 777X-9 was considered a replacement for the 777-300ER. These relationships were determined through web searches for each efficient model.\n All monetary values are presented in 2014 US$.\n It is assumed that this differential represents the retrofit costs for each aircraft type, and acknowledged that airlines often pay different prices than the list prices due to negotiations that occur with the manufacturers.\n The fuel prices (2007–2018) were averaged, and this fixed average was used for the future projections.\n The net operating savings for the full lifetime of all units installed during 2020–2050.\n The potential for open rotor engines could be large, but estimates seem to indicate availability in the 2030s onward."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:58b638e6-66fb-46f6-8eae-b5e2ee95bc97>","<urn:uuid:034d41d9-10c6-4686-b3da-477b79d07814>"],"error":null}
{"question":"How does the scientific validation process differ between ion channel research and Ganoderma lucidum's medicinal properties?","answer":"Ion channel research employs well-established scientific methods including electrophysiological, biochemical and molecular approaches to directly study channel function and regulation. In contrast, Ganoderma lucidum's medicinal properties, despite centuries of traditional use, still lack complete scientific validation. While some experiments have been conducted in cell lines and animal models, no large-scale unbiased human trials have been performed, and the FDA has not approved its use as medical treatment. The fungus would need to undergo extensive clinical trials, including phase 1 safety studies, phase 2 double-blind trials, and large-scale phase 3 trials to prove its therapeutic effectiveness.","context":["Ion Channel Research Group\nIon Channel Research Group\nOur interest lies in studying the biophysics and regulation of membrane potassium channel proteins and their roles in the cellular physiology of human health and disease. To date, our research has focused on the study of potassium channels from both mammals and human pathogenic fungi, defining protein structure-function relationships, interactions with accessory proteins, pharmacology and functional regulation by environmental cues (e.g. pH, pO2). Our studies employ an integrated electrophysiological, biochemical and molecular approach to answer key physiological questions.\nWhat are ion channels?\nIon channels act as molecular portals for the passive diffusion of ions into and out of cells and their function is absolutely essential for controlling cellular electrical activity in almost all life forms. Ion channels can be defined simply on the basis of their structure and ion discrimination. Potassium channels for example allow the selective movement of positively charged potassium ions (K+) across the cell membrane. The movement of K+ ions can lead to a change in the potential difference across the cell membrane which provides a driving force for signalling pathways needed for normal cellular function. Structurally, potassium channels are formed through the assembly of multiple protein subunits encompassing a central water-filled pore or \"conduction pathway\" allowing for selective K+ diffusion across the lipid membrane. The opening and closing of the conduction pathway termed \"gating\" is tightly regulated by a variety of stimuli such as changes in membrane potential (voltage), second messenger stimulation, phosphorylation status and ligand binding. However, unregulated K+flux can be detrimental, ultimately leading to cell death. Thus understanding the molecular mechanisms underlying gating of potassium channels and the ability to activate or inhibit K+ flux is fundamental to manipulating normal cellular excitability and function and to revealing the pathological consequences of ion channel dyshomeostasis.\nOur current laboratory research\nFungal potassium ion channels and their role in fungal physiology and virulence\nOpportunistic fungal pathogens are a major cause of life-threatening infections in individuals with a compromised immune system. An increase in the patient population at risk from the development of serious fungal infections, including HIV/AIDS patients, those undergoing blood and marrow transplant, major surgery or receiving chemotherapy has led to an associated rise in the frequency of invasive infections over the past two decades. Targeted anti-fungal therapies are often complicated by the evolutionary conserved cell biology between fungi and their mammalian hosts. Furthermore, fungal infections can be recalcitrant to therapy, and resistance to traditional interventions such as fluconazole is a growing problem, hence the search for novel anti-fungal targets is critical.\nWe have recently identified and cloned a number of potassium channels from several species of human pathogenic fungi which represent the primary sources of fatal infections in the immunosuppressed population (Candida albicans, Aspergillus fumigatus and Cryptococcus neoformans). These potassium channels, called TOK1 for Two-pore Outwardly rectifying K+ channel, are unique in that they have no known structural or functional homologues in either mammals or plants, and are the only potassium-selective ion channel expressed in yeast and fungi, making them ideal candidates for future antimicrobial compounds. Each protein subunit comprises a core topology of eight transmembrane domains (TM) containing a pair of conserved semi-hydrophobic P regions (pore domains) between TM5-TM6 and TM7-TM8 respectively (see Figure 1), and functional channels are thought to form through subunit homodimerisation. Our strategy is to understand how these channels function and how they are regulated. This is achieved primarily using electrophysiological methods including two-electrode voltage clamp (TEVC), whole-cell or isolated patch clamp techniques (see Figure 2) to monitor changes in channel activity in real time and allows us to begin to probe some important and outstanding issues; How do they open and close? Why do they outwardly rectify? What molecular mechanisms underlie their unique functional behaviour? How do they impact fungal physiology?\nMammalian ion channels in health and disease\nOur second research drive is directed towards understanding the role ion channels play in human health and disease. Our previous research has focused on structure-function relationships of potassium channels, particularly voltage-gated potassium channels (KV) and their accessory subunits specifically single transmembrane accessory proteins encoded by the KCNE gene family, mutations to which have been shown to underlie critical physiological disturbances including cardiac arrhythmias. More recently we have focussed on the intricacies of potassium channel “gating” and voltage-sensing employing a combined mutagenesis and electrophysiological approach to study structure-function behaviours in mammalian potassium channels (see publications).\nWe are currently collaborating with Professor Arthur Butt in a study characterising a novel potassium channel in neural cell development and disease and employs an IBBS-funded PhD student, Miss Maria Papanikolaou. Oligodendrocytes are the specialised glial cells in the CNS that make myelin, which insulates nerve fibres and is essential for rapid conduction of nerve impulses. Oligodendrocytes and myelin sheaths are primary targets of tissue destruction in numerous diseases, including multiple sclerosis (MS) and cerebral palsy. A full understanding of the mechanisms of myelination and demyelination is critical for the development of new therapeutic interventions in these diseases. Potassium channels are key proteins in both glia and neurons. For example, potassium channels act as critical regulators of cell division and differentiation, and their loss causes membrane depolarization, increased seizure susceptibility, and the loss of myelin. We have identified a potassium channel that is expressed specifically during development of oligodendrocytes and neurons. The functions of this channel in neural cell development are completely unknown. Our project aims to investigate the functional expression of this potassium channel and how it regulates oligodendrocyte and neuronal development using a combined molecular, immunohistochemical and electrophysiological approach.\nWe are also collaborating with Professor Janis Shute in a study investigating the function of the CFTR chloride ion channel in human lung endothelial cells and its role in inflammation.","Ganoderma lucidum, is an interesting shelf fungus that is important as a medicine in the Far East, in places such as China, Japan and Korea. G. lucidum is of particular interest because it has been portrayed as a \"fix-it-all\" herbal remedy for maladies such as: HIV, cancer, low blood pressure, high blood pressure, diabetes, rheumatism, heart problems, paralysis, ulcers, asthma, tiredness, hepatitis A, B, and C, insomnia, sterility, psoriasis, mumps, epilepsy, alcoholism, and the list goes on. These claims are mostly made by the people who are selling G. lucidum herbal supplements, but G. lucidum, also known as Reishi, ling chih, and ling zhi has a long history of being used as an herbal remedy. We will get to that later.\nFirst, how do you identify Ganoderma lucidum? Ganoderma is a member of the Polypores, a group of fungi characterized by the presence of pores, instead of gills on the underside of the fruiting body. G. lucidum, considered by many mycophiles to be one of the most beautiful shelf fungi, it is distinguished by its varnished, red surface. When it is young it also has white and yellow shades on the varnished surface, differing from the dull surface of Ganoderma applanatum, the artist's conk. G. lucidum is a saprophytic fungus that tends to grow more prolifically in warm climates on decaying hardwood logs and stumps. This feature helps to distinguish it from a similar looking Ganoderma tsugae, which also has a beautiful red varnished surface, but only grows on the stumps and logs of conifers, especially hemlock (as you might guess from the name). Another distinguishing characteristic is the flesh of G. tsugae is white whereas the flesh of G. lucidum is brown. Besides the shelf form, both G. tsugae and G. lucidum can be stalked. The spore prints of both species are brown and the spores are very similar in size and shape.\nGanoderma curtisii is considered by some mycologists to be a different species because of its brighter yellow colors and geographic restriction to the southeaster United States. However, most consider Ganoderma. lucidum and G. curtisii to be the same species because of their similar appearance and habitats; they both prefer to grow on hardwoods. In \"North American Polypores,\" practically the bible for wood-decaying poroid fungi, Gilbertson and Ryvarden, do not consider G. curtisii a species separate from G. lucidum. Another fungus that resembles G. lucidum is Ganoderma oregonense, which, like G. tsugae grows on conifers, but is found in the Pacific Northwest and New Mexico. G. oregonense can get up to 1 meter across and has slightly larger spores than G. lucidum and G. tsugae. There are arguments that these four separate species (G. lucidum, G. tsugae, G. curtisii, and G. oregonense) should be considered one species. The reasons for keeping them apart are primarily due to the host specificity of each fungus. Interestingly, if given only either hardwood or conifer wood in culture, each of the four species can grow and produce fruiting bodies, despite their natural occurrence on only one of those substrates.\nIn 1995, Moncalvo, Wang and Hseu, isolated the DNA of G. tsugae and G. lucidum and found that it was hard to tell the difference between the two species. An even more recent study in 2004 by Hong and Jung, found that G. lucidum from Asia was in its own group, whereas, G. lucidum from Europe and the Americas was more closely related to G. tsugae. Clearly, further investigation into the molecular make up of these two species is needed. For more information about the relationships of the species Ganoderma For more information, see these papers: Moncalvo, J.M., Wang, H. H. & Hseu, R. S. (1995). Phylogenetic relationships in Ganoderma inferred from the internal transcribed spacers and 25S ribosomal DNA sequences. Mycologia 87: 223-238, and Hong, S.G., Jung, H. S. (2004) Phylogenetic analysis of Ganoderma based on nearly complete mitochondrial small-subunit ribosomal DNA sequences. Mycologia 96: 742-755.\nGanoderma lucidum, considered rare and hard to find in nature in China and Japan, is now commonly cultured. It can be cultured on logs that are buried in shady, moist areas. G. lucidum can also be inoculated onto hardwood stumps. Under commercial cultivation conditions, G. lucidum is normally grown on artificial sawdust logs, as shown to the right. We'll cover this cultivation method in more detail in a later Fungus of the Month. Other methods of cultivating G. lucidum and many other fungi can be found in Paul Stamets' book, \"Growing Gourmet and Medicinal Mushrooms\"\nNow let's look at the medicinal uses of G. lucidum or Reishi. If you feel the fruiting bodies, you'll notice that they're very hard, so no one tries to eat them like most (softer) mushrooms-- too tough! It has been used as an herbal remedy for such things as health, recuperation, longevity, wisdom and happiness for centuries in Asian traditional medicine. The first historical mention of G. lucidum was during the rule of the first Chinese emperor, Shin-huag of the Ch'in Dynasty, when the fungus's medicinal uses are first described. In fact, a Reishi Goddess, known as Reishi senshi, was worshipped because she would bestow health, life and eternal youth.\nThere are two different types of Reishi, the traditional wide, shelf-like fruiting body and the antler shape, known as Rokkaku-Reishi. The antler shape arises from varying carbon dioxide levels and low light. These two types are rumored to have different healing characteristics. Recently, there have been a large amount of scientific papers published with experiments attempting to quantify the effect of G. lucidum on the human body. The fungal extract has been shown to act on immune system cells, to work against herpes virus, to lower cholesterol and stop cell proliferation.\nUnfortunately, while reading these papers it seems important to remind you that we are still not sure if G. lucidum and G. tsugae are separate species.\nAlthough the molecular make up has yet to be determined conclusively, several biologically active compounds from G. lucidum have been characterized. These include adenosine, said to have an analgesic effect, R,S-ganodermic and ganasterone that have an antihepatoxic effect, and glucans and polysaccharides that are responsible for the anti-inflammatory and antitumor properties of G. lucidum.\nSomething else to keep in mind is that all these experiments were done in cell lines, mice, rats and hamsters. So far no large scale unbiased human trials have yet been performed, and the FDA does not yet approve use of Reishi as medical treatment. In order to gain FDA approval, purified compounds from G. lucidum would have to go through an intensive amount of screening in cell lines and animals; much of this pre-clinical testing has already been performed. The next step would be a phase one clinical trial, which assesses the potential drug's safety. Healthy volunteers are paid to take the drug for a certain amount of time, and the compound is studied for its absorption into the body, its metabolism, and its excretion. Once the potential drug passes phase one, which can take up to several months, it moves on to phase two. In phase two, several hundred patients participate in what is called a double blind clinical trial, in which both the patient and the physician are unaware of whether the patient is receiving the potential drug or a placebo . Phase two can last from several months up to several years. If the potential drug is proven effective after phase two, it moves to phase three. Phase three also consists of blind clinical trials, but on a much larger scale. This phase is used to understand the drug's effectiveness, benefits, and the range of possible adverse reactions. Without a doubt, G. lucidum and its researchers have a long road ahead of them before they can prove the mushrooms healing powers.\nI hoped you enjoyed learning about Ganoderma lucidum, its relatives and potential uses. Although these species of fungi can produce beautiful fruiting bodies, who would have expected them to hold so many potentially useful chemicals?\nThis month's co-author is Kathleen Engelbrecht, one of my students in Mycology, Medical Mycology, and Advanced Mycology. She's working on an interesting project looking for potentially useful compounds from fungi.\nIf you have anything to add, or if you have corrections, comments, or recommendations for future FotM's (or maybe you'd like to be co-author of a FotM?), please write to me at email@example.com\nThis page and other pages are © Copyright 2005 by Thomas J. Volk, University of Wisconsin-La Crosse.\nLearn more about fungi! Go to Tom Volk's Fungi Home Page --TomVolkFungi.net\nReturn to Tom Volk's Fungus of the month pages listing"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:aab8fa3f-7799-44f6-856b-b31ce51c8b2c>","<urn:uuid:b2e7717d-13f6-4c81-b9bf-9de343298647>"],"error":null}
{"question":"How does withdrawal management differ between opioid addiction and methamphetamine addiction? What medications are available for each?","answer":"Opioid and methamphetamine withdrawal management differ significantly in their medication options. For opioid addiction, there are several FDA-approved medications available: buprenorphine to curb cravings and withdrawal symptoms, naltrexone to block opioid effects, and methadone to reduce withdrawal and cravings. In contrast, methamphetamine withdrawal cannot be directly treated with specific FDA-approved medications like opioid addiction can. Instead, meth withdrawal management may include doctors administering mild stimulants to reduce physical side effects or SSRIs to manage mental health symptoms during detox. Additionally, unlike opioid overdoses which can be reversed with medication, meth overdoses cannot be reversed with another substance.","context":["Drug Treatment Program Glossary\nNavigating the seemingly intricate world of substance use treatment might seem a complex endeavor. With the multiple types of care, treatment locations, levels of care, medication, and behavioral therapies, being familiar with commonly used terms will help you more easily find the care you need.\nTypes of Treatment\nTreatment Types—Refers to the broad therapeutic categories used to treat substance use disorders.\nThese treatments typically have the goals of modifying the thoughts, feelings, behaviors, and perspectives of the recovering individual regarding their current situation and are delivered by trained professionals like therapists, counselors, social workers, psychologists, and psychiatrists. All of these therapeutic approaches are utilized in a number of different treatment settings and levels of program intensities. Treatment types include:\n- Individual/One-on-One Therapy. This refers to any therapy that involves the professional treating the recovering individual during a one-on-one session. Individual therapy sessions will focus on ending substance use, building needed skills for sustained recovery, and creating a plan for relapse prevention 1,2.\n- Family/Collaborative Therapy. This therapeutic format includes not only the person in recovery, but one or more family members or other supports like friends and romantic partners. Here, the goals will focus on strengthening relationships, building communication, and learning how the relationship encourages or deters substance use 3,4.\n- Group/Multi-Person Therapy. This involves at least one professional in a room with two or more individuals in recovery. It can be utilized independently or combined with one-on-one therapy to gain social reinforcement to continue recovery 2. Group therapy can be extremely valuable but may introduce some potential challenges, such as group members reinforcing drug use (common among highly delinquent adolescent members) 4.\nLevels of Care\nLevels of Care—Refers to the intensity of treatment, who will be providing the care, and where those in recovery will reside while engaged with that specific level of treatment.\nThe appropriate level of care will be based on the individual’s current substance use, coping skills, outside supports, employment, and other factors 3,4. Levels include:\n- Detoxification Process. Though it should not be regarded as a standalone treatment, detoxification is a key first step in the route away from substance abuse and towards recovery. It allows the body to process and remove the unwanted substance from the system. Detoxification can occur across a range of settings and may be performed with or without medical supervision and varying intensities of medical/pharmaceutical intervention.\n- Inpatient Care. The highest level of care for people that need the most support. Inpatient treatment will be short-term, highly structured, and most appropriate for people that have significant medical or psychiatric issues that present with their substance abuse 2,4,5. Many inpatient programs will take place in specific units in a hospital and will not resemble a residence 2.\nResidential Care. While technically also a form of inpatient care, this is the name given to a range of care levels that more resemble a typical residence than a hospital. Recovering individuals will live at the facility for a specific duration of time with the goal of establishing the foundation for a drug-free life. Residential options include:\n- Therapeutic Communities (TC). With lengths of stay that range from 6 to 12 months, TCs focus on using professional staff, other residents, and social opportunities to elicit change and “resocialize” the individual. This type of structured treatment works to confront the individual’s views and behaviors that lead to use. TCs hope to encompass all aspects of recovery and can be modified to be effective with a number of special populations like young adults or teenagers, people with mental health disorders (co-occurring situations), and people with disabilities 4.\n- Short-Term Residential Rehabilitation. Using treatment lengths of 3 to 6 weeks, this level of care is shorter in duration but remains intense. Short-term residential programs are frequently based on 12-step models. They include a detoxification period and, later, emphasis on a diligently established aftercare regimen for follow-up substance abuse treatment at the end of this initial 3-6 week duration 3,4.\n- Recovery Housing. Typically, recovery houses offer a “step-down” level of residential care that is started after first completing a period of more intensive treatment. Recovery housing focuses on transitioning the individual back into the community and may provide assistance with employment and financial matters 3.\n- Social Model. Sometimes referred to as “sober living,” social model homes will offer peer counseling, support, and appropriate role models for recovery, but there will be no formalized, professional treatment provided for residents. These services will be sought outside of the home 6.\nOutpatient Care. Similar to their inpatient or residential counterparts, outpatient services vary in frequency, intensity, and duration. The commonality is that these services allow the individual to leave the care location and return to their home, unlike inpatient programs 3,4.\n- Partial Hospitalization Program (PHP). Offering the most intensive services of all the outpatient program varieties, PHPs are appropriate for people with relatively severe symptoms that are able to be managed at home. Sometimes called “day treatment,” PHP involves at least 5 days per week for 4 to 6 hours of individual therapy, group therapy, or a combination of both\n- Intensive Outpatient Program (IOP). Available as a middle ground between standard outpatient and PHP, IOPs meet for 3 hours per session with at least two sessions per week. Like PHP, it can include group therapy, individual therapy, or both 5.\n- Standard. Standard outpatient treatment approaches may involve meeting at a care location, or at a substance abuse therapist’s office once or twice per week 5.\n- Case/Care Management. A case/care manager provides support and assistance to the individual in the process of coordinating and receiving other services. They can help those in recovery secure housing, employment, and medical care while building social skills in the community 6.\nRecovery Support Services. Though recovery support services are not a replacement for other formalized treatments, this category of carecan help reinforce and maintain improvements made by the individual through the sharing of their experiences with others 5.\n- Peer Recovery Support. These services will be similar to those provided by a case/care manager and include transportation and education. One difference is that these non-clinical services are provided by a peer, someone engaged in their own recovery 2.\n- Recovery High Schools. As an alternative school program, recovery high schools offer adolescents a more supportive environment with a mixed focus of education and recovery 5.\n- 12-Step Recovery Programs. An important part of recovery, 12-step programs (e.g., AA and NA) are group meetings that are led by group members in recovery rather than a professional. These self-help groups can supplement professional treatments by adding a sense of community, understanding, and fellowship to the recovery process. 12-step programs stress the importance of acceptance, surrender, and active involvement in the program 4.\nPharmacotherapies—Medications utilized to specifically manage various substance dependencies, ease symptoms of withdrawal, prevent relapse, and treat co-occurring mental health conditions that complicate substance use 3.\nThe use of medication in addiction treatment typically has better results when combined with behavioral therapy. When medications are used specifically for the treatment of substance use disorders, it is called Medication-Assisted Treatment (MAT) 1.\nFor Opioid Addiction. Several medications are used for the treatment of addiction to opioid substances like heroin and prescription painkillers. Even though some of these FDA approved substances are opioids themselves, they are viable treatment options that help to curb cravings and addictive behaviors 4.\n- Buprenorphine. A medication used sublingually and in other forms (e.g., in combination with naloxone as Suboxone), buprenorphine is a partial opioid agonist that helps to curb cravings and withdrawal symptoms without producing the euphoria or sedation associated with the abused opioid drugs 4,5.\n- Naltrexone. Rather than acting in a way similar to other opioids in the body, naltrexone prevents opioid drugs from binding to their respective opioid receptor sites in the brain and, in doing so, blocks their effects. This substance is available as an oral medication or an injection that lasts for a month 4.\n- Methadone. This long-acting oral opioid medication helps to reduce the withdrawal and cravings associated with more potent abused opioid drugs like heroin 5. You must visit a clinic to be administered methadone.\nFor Alcohol Addiction. Medications for alcohol addiction will have the goal of maintaining abstinence and reducing cravings 2.\n- Acamprosate (Campral). Effective in people suffering from alcohol addiction, this medication can reduce withdrawal symptoms and maintain recovery by regulating the activity of certain neurotransmitters in the brain called gamma-aminobutyric acid (GABA) and glutamate 4,5.\n- Disulfiram (Antabuse). By modifying the way alcohol is processed, disulfiram produces unwanted effects like nausea when alcohol is consumed and, in this manner, is a deterrent to continued drinking 4.\n- Naltrexone. The same medication used for opioid addiction, naltrexone can reduce the rewarding results of alcohol use 4.\nFor Nicotine Addiction. Available in a variety of forms, medications for nicotine addiction will often begin while use is ongoing to help wean nicotine use and decrease the temptation to start up again in those who want to be fully free of all toxic influences as part of their recovery 5.\n- Bupropion (Zyban). Initially used to treat depression, it was observed to suppress cravings without leading to weight gain 4.\n- Nicotine Replacement Therapy (NRT). In the forms of patches, sprays, lozenges, inhalers, and gums, NRTs provide a steady, low level of nicotine to wean the user off of other nicotine use. Treatment can be combined with other medications to enhance the results 4,5.\n- Varenicline (Chantix). This medication has the ability to mildly stimulate the nicotine receptors in the user’s brain while blocking the ability of nicotine to create pleasure 4,5.\nBehavioral Therapies—Refers to various treatment options that may or may not be utilized based on the style of the therapist or the therapeutic conventions of a specific treatment center.\nThese therapies will strive to change the perspectives and actions of the individual while promoting abstinence and increasing positive life skills 1,4. Though these therapies serve as guides, many therapists will employ a mix of therapies across orientations 1. Therapies include:\n- Evidence-Based Cognitive Behavioral Therapy (CBT). A common form of therapy that is used in mental health and substance use settings, CBT works to forecast potential issues and emphasizes productive coping strategies by discussing the interconnectedness of thoughts, feelings, and behaviors 5.\n- Contingency Management (CM)/Motivational Incentives. This style of treatment favors the reinforcement of desired, drug-free behaviors with rewards that are immediate and tangible to encourage additional behaviors that maintain recovery. Centered in behaviors, there is less attention paid to thoughts and feelings surrounding use 4,5.\n- Community Reinforcement Approach Plus Vouchers (CRA). An integrative approach that combines aspects of other styles, CRA is a 24-week program that uses multiple sessions weekly to reduce use and reinvest in employment and social health. This approach uses tangible rewards in a way similar to contingency management treatment 4.\n- Family Behavioral Therapy. This therapy involves the individual as well as at least one significant other like a parent or romantic partner to decrease use and improve the home environment 4.\n- Goal-Centered Motivational Interviewing (MI). This treatment type attempts to build internalized motivation in the client to decrease ambivalence and accept recovery 4.\n- The Matrix Model of Abuse Therapy. Designed specifically for stimulant users, the Matrix Model uses individual, group, and family therapies in a formalized system to build self-esteem and self-respect 4.\nBehavioral Therapies Specifically for Adolescents\nThough some treatment styles will work with all populations, someone specific populations, like teenagers, will require specialized types of care to produce the best results due to their unique needs 4,5.\n- Adolescent Community Reinforcement Approach (A-CRA). Like the adult version of CRA, this treatment approach works to lessen negative influences while building healthy supports at home, work, or school 5.\n- Brief Strategic Family Therapy (BSFT). Focused on creating short-term solutions, the therapist utilizing this style will interact with all family members to observe, understand, and modify how they interact with one another to better promote recovery 5.\n- Functional Family Therapy (FFT). This approach is based on the idea that unhealthy relationships in the family end with unhealthy behaviors. Treatment will involve identifying problems within the relationships and suggesting adjustments in order produce improved behaviors 5.\n- Multisystemic Therapy (MST). An effective treatment for adolescents with substance abuse issues as well as deviant or violent behaviors, MST will address issues of peers, school, parents, the community, and the teen to improve outcomes 5.\n- Multidimensional Family Therapy (MDFT). This treatment will take place in the community, school, family home, or in an office setting with the family and therapist. The goal of MDFT is to empower the entire family towards competency and health 5.\n- Substance Abuse and Mental Health Services Administration. (2015). Behavioral Health Treatment and Services.\n- Substance Abuse and Mental Health Services Administration. (2016). Treatments for Substance Use Disorders.\n- National Institute on Drug Abuse. (2016). Drug Facts: Treatment Approaches for Drug Addiction.\n- National Institute on Drug Abuse. (2012). Principles of Drug Addiction Treatment: A Research-Based Guide.\n- National Institute on Drug Abuse. (2014). Principles of Adolescent Substance Use Disorder Treatment: A Research-Based Guide.\n- Massachusetts Executive Office of Health and Human Services. (2016). Substance Abuse Services Descriptions.","How Methamphetamine Affects Your Brain and Body\nMethamphetamine, most commonly referred to as “meth,” is a highly addictive recreational drug that is abused by people of all ages.\nIt goes by many different street names, including ice, glass, crank, speed, and chalk. People with meth abuse issues often smoke, snort, or inject the drug intravenously. It usually comes in the form of small crystal-like rocks and can be blue or white in color.\nMeth is a stimulant that affects the central nervous system. Because it’s so concentrated, meth users feel an immediate, long-lasting euphoric effect. Meth users often explain feeling more motivated, more confident, and even more intelligent when they’re high on the drug.\nHowever, meth use—short term or long term—can lead to extensive damage in the brain and body. In addition to the mental and physical effects, prolonged meth use can even increase a user’s risk for certain health conditions, like stroke, heart attack, HIV/AIDS, and Hepatitis.\nStatistics on Meth Use\nOverdose is possible after a large dose of meth. In 2017, roughly 15% of all drug overdose deaths involved a substance in the methamphetamine category. Meth overdoses can be fatal because the drug affects the heart, brain, and other vital organs. Meth overdoses cannot be reversed with another substance like an opioid overdose can be.\nAlthough meth can be found in all parts of the country, it’s one of the only illegal drugs that has a strong regional concentration. Meth abuse is most often found in the western and midwestern states, including California, Nevada, Nebraska and Oklahoma. One survey found that over 70% of local law enforcement agencies from several pacific and west central regions said meth was the biggest drug threat to their area.\nIf you are considering treatment for yourself or a loved one, call us today.\nSymptoms of Meth Abuse\n- Rapid heart rate\n- High blood pressure\n- Frequent mood swings\n- Loss of appetite\n- Tremors or convulsions\n- Change in sleeping patterns\n- Significant weight loss\n- Erratic behavior\nUsing meth consistently also changes a person’s physical appearance. Some of the noticeable physical ailments include:\n- Skin sores\n- Tooth decay\n- Gum disease\n- Weight loss\n- Thinning/patchy hair\n- Dry/cracked skin\nThe physical symptoms of meth use are significant. However, meth also has a profound impact on the brain, which can lead to mental health disorders. Data shows that roughly 40% of adults who use amphetamines have a lifetime history of depression. Over 75% of meth users say they have symptoms of anxiety, and 46% of regular meth users report experiencing psychosis. Hallucinations, aggressiveness, and paranoia are also long-term side effects of meth.\nWithdrawal from Meth\nThe symptoms of meth use typically subside when the drug is fully out of the body.\nMany meth users also experience “tweaking” from time to time. Tweaking is essentially an episode where a person will feel intense cravings and feelings of extreme mental distress. Some users experience delusions, as well as severe depression and anxiety. Tweaking can be followed by crashing, where a person deals with even more significant mental health effects, as well as exhaustion and lack of appetite.\nEven one missed dose of meth can cause an addict to experience extreme physical and mental side effects. As a result, it’s recommended that meth addicts seek professional treatment when withdrawing from the drug. Many substance abuse recovery centers offer inpatient detox programs that are overseen by a medical professional. It’s never recommended for a meth addict to quit the drug cold turkey because of the life-threatening side effects.\nTreatment for Meth Addiction\nIt can be difficult to overcome meth addiction, but with the right treatment, many people make a full recovery. Most people with a severe meth addiction start treatment in a detox program, where they are treated by a medical professional. Doctors may administer mild stimulants to reduce physical side effects, or SSRIs to manage the person’s mental health symptoms.\nOnce the detox process is complete, recovering addicts move onto a partial hospitalization program (PHP), this is the highest level of outpatient care and can often be accompanied by a sober living home. In the PHP level of care clients attend treatment at the facility 5 days a week for 6 hours per day. These programs rely heavily on individual therapy, group therapy, accountability, health and nutrition, and relapse prevention. The next step is to enroll in an intensive outpatient program (IOP) or outpatient drug rehab program (OP) where recovering addicts learn the skills they need to reenter society. Continuing with individual and group therapies, relapse prevention, case management and more, clients attend treatment fewer days per week. IOP and OP treatment help bridge the gap between more intensive inpatient our PHP treatment and re-entering society independently. This phase is crucial in long-term recovery and success for many in recovery from methamphetamine addiction.\nAt Nexus Recovery, we treat individuals who have a history of meth addiction. Every treatment program is personalized to the individual client based on their unique needs. Our team is trained in a variety of therapy modalities, as well as holistic services, case management, and medication management, to treat the addiction from multiple angles.\nIn addition to partial hospitalization, we offer an intensive outpatient program, a standard outpatient program, and an aftercare program. Our facility also has gender-specific treatment programs that employ different treatment modalities for men and women. You can see what our past clients have said about their time at Nexus Recovery on our testimonials page.\nMethamphetamine addiction is a serious disorder, and it can be fatal if it goes untreated. If you or someone you love is struggling with a meth addiction, contact us today.\nIf you or a loved one are suffering from meth addiction, we’re here to help. Contact us today and speak with one of our trusted recovery advisors."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:40c2f5d5-5108-4430-adf7-42b2487625f5>","<urn:uuid:6e7c5bc7-4d71-4136-9381-b48bb3e3f763>"],"error":null}
{"question":"What roles do geographical location and local infrastructure play in climate change vulnerability, and how do social factors influence risk perception?","answer":"Geographical location significantly affects climate change vulnerability, as demonstrated by the Pacific Northwest's heat dome phenomenon where temperatures reached 25-30° above normal, challenging all-time records. Infrastructure plays a crucial role - physical infrastructure includes emergency services, health facilities, communication networks, and utilities, while social infrastructure encompasses extended families and community organizations. Risk perception is influenced by multiple factors including the extent of factual knowledge, level of personal threat, immediacy of risk, ability to control the risk, and openness to changing ideas. Local conditions also matter - for instance, areas experiencing severe to extreme drought, like parts of the Pacific Northwest, face increased vulnerability as dry soils heat more easily than moist soils, creating a reinforcing cycle of heat and drought.","context":["Historic heat wave for the Pacific Northwest\nJun 25, 2021\nExtreme and dangerous heat will overtake the Pacific Northwest this weekend and early next week.\nExtreme and dangerous heat will overtake the Pacific Northwest this weekend and early next week. Locations in Oregon and Washington will challenge all-time record highs, with temperatures edging above 100° in Seattle, and likely over 105° in Portland. Interior locations east of the Cascade Mountains, like Spokane, will soar to near 110°. In many cases, temperatures will be 25-30° above normal. See forecast highs from the NOAA/NWS National Digital Forecast Database.\nBelow are some resources to cover this historic heatwave\nCurrent all-time records (via NOAA ACIS)\nThe Climate Connection\nThere is a strong and direct link between extreme heat and climate change. In a warming climate, extreme heat is happening more often and lasting longer.\n- The weather pattern building into the Northwest is referred to as a heat dome and is associated with a blocking jetstream. The influence of climate change on blocking blocking weather patterns is an active area of research.\n- Parts of the Pacific Northwest are locked in a severe to extreme drought. Dry soils heat more easily than moist soils, contributing to the higher temperatures near the ground. And as the climate warms, soils dry out more quickly, reinforcing the heat and making droughts worse.\n- REPORT: Seniors at Risk: Heat and Climate Change\n- REPORT: Extreme Heat: When Outdoor Sports Become Risky\n- Use our Climate Central searchable media library to find local data and graphics for cities across the Northwest. Several examples below:\n|A small increase in average temperature leads to a large increase in extreme heat. Download the graphic at left.|\n|A key indicator of a warming climate, the number of new record high temperatures is outpacing the number of record lows. Find graphics for all cities (i.e. Portland).|\n|Our 2021 summer package contains city-specific data for the number of hot days, the average summer temperature (i.e. Seattle), and the average summer low temperatures.|\n|The relationship between carbon dioxide and temperature is well defined. The increase is from the burning of fossil fuels, and the jump in each has been especially strong the past few decades.|\n|Watch our workshop on extreme heat from our recent Covering Disasters series: Extreme Heat 2020.|\nExtreme heat is the leading weather killer. This is especially true in climates that are not accustomed to it.\n- 91 percent of American households have some type of air conditioning, the number is smaller in the Pacific Northwest — 44 percent in Seattle and 79 percent in Portland.\n- According to the CDC, an average of 702 heat-related deaths occurred in the United States annually between 2004-2018. And heat exposure and its impacts fall unequally, with historically underserved populations facing greater health threats. That disparity means that Black, Indigenous, Latinx, Asian, Pacific Islander, and multiracial populations, as well as those with lower incomes, are at heightened risk.\nExperts Available for Interview\n- Jennifer Vanos, Arizona State University, Assistant Professor, School of Sustainability, College of Global Futures email@example.com\n- Kristie Ebi, Professor, Environmental and Occupational Health, Global Health, University of Washington @kristie_ebi firstname.lastname@example.org\n- Juan Declet-Barrero, Senior Social Scientist for Climate Vulnerability, Union of Concerned Scientists. Contact: Ashley Siefert Nunes, Climate and Energy Media Manager, email@example.com Available for interviews in Spanish.","Disparities in exposure to climate change risk and vulnerability\nDisparities in exposure to climate change risk and vulnerability, including variations in people’s location, wealth, social differences (age, gender, education), risk perception\nDetailed examples of two or more societies with contrasting vulnerability\nVulnerability refers to the degree to which people or the things they value are susceptible to, or are unable to cope with, the adverse impacts of climate change. Thus, vulnerability determines how severe the impacts of climate change might be. There are three dimensions of vulnerability to climate change: exposure, sensitivity, and adaptive capacity.\nExposure is the degree to which people and the things they value could be exposed to climate variation or change;\nSensitivity is the degree to which they could be harmed by that exposure; and\nAdaptive capacity is the degree to which they could mitigate the potential for harm by taking action to reduce exposure or sensitivity.\nThe expression “things they value” not only refers to economic value and wealth, but also to places and to cultural, spiritual, and personal values. In addition, this expression refers to critical physical and social infrastructure, including such physical infrastructure as police, emergency, and health services buildings, communication and transportation networks, public utilities, and schools and daycare centers, and such social infrastructure as extended families, neighborhood watch groups, fraternal organizations, and more. The expression even refers to such factors as economic growth rates and economic vitality. People value some places and things for intrinsic reasons and some because they need them to function successfully in our society. Some groups of people are inherently more vulnerable to climate change than others. The very old or very young, the sick, and the physically or mentally challenged are vulnerable. Disadvantaged groups, such as minorities, those with few educational opportunities, or non-English speakers are more vulnerable than the majority, better-educated, English-speaking population. Women, who typically spend more time and effort on care-giving to parents, children, and the sick than men do, are more vulnerable because that care-giving exposes them more to the impacts of climate change. More vulnerable groups often combine these categories, such as the poor—who can be old, minority, non-English speaking, and female, for example. Another example of a particularly vulnerable group is the single-mother household, which can be headed by a poor woman of color who is responsible not only for caregiving, but also for providing the family income.\nThe concept of resilience is important to understanding adaptive capacity to climate change. Resilience refers to the ability of a human system to withstand contemporary shocks and to anticipate and plan for future shocks. Resilient systems have the ability to learn from past experiences and to use that knowledge when confronting problems. Systems with high adaptive capacity are therefore resilient and able to reconfigure themselves to deal with climate change. Systems with low adaptive capacity are much less resilient and much more vulnerable to climate change. From https://www.e-education.psu.edu/geog438w/node/252\nHow does the CCVI calculate a score from 1 to 10 in order to determine vulnerability to the impact of climate change? Give examples of countries (and their scores) at both ends of the scale. (p189). What are the similarities and differences between the CCVI and the CRI? Which do you think is the better measure of vulnerability? Why?\nThe UNDP states that “99% of the casualties from climate change will be in developing countries”. Explain how the following demographic groups within those countries will be disproportionately affected by climate change: (p195)\nPoorer people (3 reason)\nWomen (8 reasons)\nOld people (2 reasons)\nChildren (1 reason)\nWhat is “risk perception”? (p197)\nExplain how the climate change controversy influences risk perception. Describe 4 general factors that affect general risk perception. (p198 - also see the RLS in the Geography and TOK section).\n3. Climate change and location\nQuestions to consider:\nWhat is the pattern shown in the CCVI and the CRI? What are the similarities? Why are they different? (refer back to reading).\nWhy are there so many different methodologies for examining the risk to a particular location?\nWhat are the factors that are connected to location which affect the extent to which populations are vulnerable to climate change (SEEP)?\nWhat do they all have in common in terms of overall conclusions?\n4. Climate change and wealth\nWhy are poorer people more vulnerable to climate change?\nWhy are the poorer people more vulnerable within countries?\nWhat is it? Why is risk perception important? How do you rate your own perception of the risks from climate change? Can you explain this using the factors which affect risk perception? Factors affecting risk perception:\nExtent of factual knowledge/data\nLevel of personal threat\nImmediacy of the risk\nExtent to which the risk can be controlled\nExtent to which person/community is open to changing ideas."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:143df405-e180-4ad7-bb4a-053889d091dc>","<urn:uuid:6af4738a-8621-405d-94ad-e9d2979659b5>"],"error":null}
{"question":"What is the average weight difference between Icelandic Atlantic salmon and Skagit River Chinook salmon?","answer":"Icelandic Atlantic salmon typically weigh 5-7 pounds (with multi-winter salmon reaching 9-16 pounds), while Skagit River Chinook salmon are generally larger, averaging 20 pounds, though they can grow much heavier with records up to 135 pounds.","context":["Fly fishing for Atlantic salmon in Iceland is one of the best options for Atlantic salmon fishing in the world today.\nThe fishing packages for salmon are most often 3 to 6 days including fishing permit, full board accommodation local transfer and one guide with for every two rods, private guide by request. A few rivers also offer shorter terms and self catering accommodations.\nMost of the salmon rivers in Iceland are gin clear and some times easy to spot the fish. Fishing for salmon in Iceland is most often with floating line riffling hitch, small flies or Sun ray shadow for aggressive surface action in the gin clear Icelandic rivers is fantastic if you fish salmon\nThe salmon season: June 5th to end of sept\nThe fishing hour: 08:00 to 13:00 lunch break to 16:00 to 21:00\nThe prime: July 15th to August 15th.\nSalmon fishing has been practiced in Iceland since the first settlers arrived here in the late 9th century. Dragnets were widely used, but now people argue whether our ancestors fished by rod or not. (A fine topic for debate, as no one can prove his point) Soon after 1860 English and Scottish gentlemen came here to fish for salmon. They frequented rivers in the south-west area, such as the Ellidaár, Grímsá, Langá, Thverá and Norduá. Some even bought all fishing rights in rivers, like the Elliðaár and the Langá.\nThis continued for the next 50 years until the First World War put an end to it.\nAttendance was never the same.\nIn the late 1960′s some American anglers rediscovered Icelandic salmon fishing and soon became the most common foreign fishermen in Iceland. In the last two decades the number of European anglers has increased and today they almost equal the Americans.\nThe flow of foreign anglers increased the demand for good fishing and raised the prices considerably, so local fishermen were not at all pleased. Today this dispute has settled and Icelandic anglers acknowledge that salmon fishing is a costly sport.\nIceland is a great destination for your fishing holiday\nRiver Miðfjarðará (Queen of rivers)\nThe River Miðfjarðará is one of the best rivers to fish for salmon in Iceland today. The last 5 years average catch is 3.138 salmon per year.\nThe river system is based on 4 rivers, main river the Miðfjarðará, the Austurá, the Vesturá and the small Núpsá. There are over 220 named pools on the whole system and we only fish with 6 to 10 rods depending on the time of the season.\nAnglers will have enough space to fish and the pools are well rested between fishermen to keep the fishing pressure down. The Midfjardara is perfect for those who like to use single or small double-handed rods with floating line and small flies or hitch-tubes.\nThe main run of the river is predominantly made up of grilse but in the early season the majority of fish tend to be multi-sea-winter fish in the 10 to 18 pound range. The joy of the Midfjardara is that there is so much water to fish that even if one opts out of the canyon section in the Austura there are numerous different pools to fish.\nRiver West Ranga\nThe river West Rangá is one of the Iceland most providing salmon rivers of Iceland, this 16 rod river provides 4000 – 7000 salmon each year.In the river you fish for Atlantic salmon few Arctic char and sea trout are also caught each year. The Salmon size is 5-7 pounds and 9-16 pounds the multi winter salmon. The salmon in the river has great shape, and the male fish that are coming after spending one year in the sea are often be 6-9 pounds.\nRiver Fossá is medium size salmon river in the South of Iceland. Foss is the Icelandic word for waterfall and you will see Tree stunning waterfalls where you can fish in. Háifoss at the top of the trout beat is the second highest waterfall in Iceland 122m. Fossá river system is fly only, catch and release. The salmon beat is below the waterfall Hjálparfoss.\nGo salmon fishing in Iceland and fish River Sog for Atlantic salmon\nThe River Sog lies in the south of Iceland, around a one hour drive to the east from Reykjavik. It is the largest spring-fed river in Iceland and runs from Lake Thingvallatn to its junction with the glacier-fed river Hvita although, due to hydro-electric installations, only some 12 kms are passable by salmon.","- THINGS TO DO\nSalmon of the Skagit River Watershed – Free Guided Tours at Marblemount Fish Hatchery\nSockeye Salmon (also called reds)\nSockeye salmon spawn only in streams having lakes in their watershed. The young fish, known as fry, spend one to three years in the freshwater before migrating to the ocean. They spend three to four years in the salt water, and thus are four to six years old when they return to spawn in the fall (September-December). Sockeye are blue tinged with silver in color during their ocean life. Male sockeye develop a hump during their transition from salt to fresh water and their jaw and teeth become hooked. Both sexes return to spawn with bright red bodies, green heads, and a dark stripe on their sides. When mature, they average 33 inches in length and weigh six to eight pounds.\nPink Salmon (also called humpies)\nPink salmon spawn in the Skagit Watershed only every other year; during years that end with odd numbers (1995, 1997, 1999…). This species prefers sloughs and slow moving water for spawning. The young emerge from the gravel during April and May and quickly migrate downstream as fry. They return to freshwater in the fall of the following year as two year old adults. These are the most abundant and the smallest of the Pacific salmon with an average weight of five to six pounds and length of 30 inches. These fish change from bright silver in the ocean to pale gray on the back with yellowish white belly when spawning. The males develop a large humpback during spawning, hence their nickname “humpies.”\nCoho Salmon (also called silvers)\nCoho salmon utilize shallower reaches of water and small streams in the Skagit Watershed for spawning. The young spend one to two years in the fresh water before migrating to the ocean in late March through July. During their ocean phase, coho have silver sides and dark blue backs. They will live in the salt water for one or two years before returning to spawn. During their spawning phase, the jaws and teeth of the coho become hooked, and they develop bright red sides, bluish green heads and backs, dark bellies with dark spots on their back. Mature coho average 38 inches in length and seven to 11 pounds in weight.\nChum Salmon (also called dog)\nChum fry migrate out to sea from March through July, almost immediately after becoming free swimmers. They spend one to three years traveling long distances in the ocean. Their ocean coloration of silvery blue green changes for spawning to splotchy purplish red and with distinct yellow and pink vertical bars on their sides. Color in the female is similar but not usually as distinct. Chum salmon develop a very hooked jaw with fierce teeth at spawning time. These are the last salmon to spawn (November to January). They utilize the lower tributaries of the watershed, tend to build redds in shallow edges of the watercourse and at the tail end of deep pools. Chum, on average, weigh eight to nine pounds and measure 40 inches in length. This species of salmon is the favored meal for wintering Skagit bald eagles.\nChinook Salmon (also called king, tyee, blackmouth)\nChinook are the least abundant species of salmon in the Skagit River Watershed. They are the longest lived and largest of the Pacific salmon. Chinooks spend one or more years in the fresh water before migrating to the ocean. They generally remain in the ocean for two to four years, although some stay as long as eight years. Chinook are overall olive-brown to purple in color with large irregular spots on their backs, upper sides and tails. The males are usually darker than the females. They do not change radically in appearance during spawning as other salmon do. Their principal spawning months are from August through October. Chinook, because of their size, generally stay in the deep, fast waters of larger streams and rivers. Chinook average 20 pounds in weight, but have been recorded up to 135 pounds, and can grow to a length of 58 inches.\nSkagit Fisheries Enhancement Group"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:aee0acb1-6b9a-4754-b527-26b5282dfcf4>","<urn:uuid:5a844c62-9a87-4bf9-b962-9db674d63dc5>"],"error":null}
{"question":"Is there a difference between above-ground and underwater carbonate formation in CO2 storage settings?","answer":"Yes, there are differences in carbonate formation between these settings. In above-ground storage, CO2 is injected into designated fractures where carbonate precipitation can lead to fracture blockage, with the critical time depending on Peclet and Reynolds numbers. In underwater settings such as oceans, carbonate formation is actually inhibited by CO2 dissolution, making it harder for marine organisms to form calcium carbonate structures like shells and coral reefs, as evidenced by damaged phytoplankton and eroded foraminifera shells.","context":["Geochemical reaction modeling of carbon dioxide\nAlizadeh Nomeli, Mohammad\nMetadataShow full item record\nRecently, the need to decrease CO<sub>2</sub> concentration in the atmosphere has been recognized because of the role of CO<sub>2</sub> as a greenhouse gas that contributes to global warming. Carbon Capture and Sequestration CO<sub>2</sub> is one of the most promising long term solutions for the reduction of CO<sub>2</sub> in the atmosphere. To this end, injection of CO<sub>2</sub> into saline aquifers has been proposed and investigated theoretically and experimentally in the last years. Modeling the storage of CO<sub>2</sub> in saline aquifers on a reservoir scale is very demanding with respect to computational cost. Long-term subsurface storage of CO<sub>2</sub> in saline aquifers may induce a range of chemical processes in response to disturbances in existing chemical equilibria that include, but are not limited to, dissolution of primary minerals and precipitation of secondary carbonates. CCS projects also can be done above the ground by injecting CO<sub>2</sub> into designated fractures. The work presented in this thesis focuses on developing a fundamental understanding and modeling approach for 3 basic aspects of sequestration: 1) the effect of CO<sub>2</sub> solubility on rates of geochemical reactions, 2) density of brine after dissolution of CO<sub>2</sub>, and 3) time dependent porosity variation of a single fracture due to precipitation of carbonates. A new method is developed to determine the reaction rates of minerals, on the basis of transition state theory, in saline aquifers containing brine and a supercritical CO<sub>2</sub> phase. A general Arrhenius-type equation that depends explicitly on the pH of brine is employed to determine the reaction rates. The dependence of pH on the amount of aqueous CO<sub>2</sub> dissolved in brine is modeled in this study. An accurate pressure-volume-temperature-composition (PVTx) model is employed to determine the dissolution of supercritical CO<sub>2</sub> in brine for the temperature range of 50-100<super>°</super>C and pressures up to 600 bar. Solubility of CO<sub>2</sub> and dissolution rate of calcite predicted by the model are validated with experimental data available in the literature for specific thermodynamic and salinity conditions. The effects of CO<sub>2</sub> activity on pH and reaction rates are evaluated by means of four different models for the activity coefficient of dissolved CO<sub>2</sub>. The results indicate that dissolution of CO<sub>2</sub> decreases the pH of the system but an increase in the temperature and salinity values limits the pH reduction. The rates of reactions are found to increase with pressure and temperature. The results suggest that among the available mineral compositions in deep saline aquifers, the dissolution rate of anorthite is the rate limiting factor. The significance of the pre-exponential factor and the reaction order associated with the modified Arrhenius equation is evaluated to determine the sensitivity of the reaction rates as a function of the system pH. We find that the transition state theory can reasonably reproduce experimental data with new parameters that we are obtained in this study on the basis of sensitivity analysis. Finally, we develop a long-term geochemical modeling of CO<sub>2</sub> storage on a designated fracture above the ground to investigate the impacts of temperature, pressure, and salinity on the reaction rates and, subsequently, the critical time of blockage due to precipitation of carbonates. With regards to the second focus of this thesis, the effect of CO<sub>2</sub> solubility on the density of binary H<sub>2</sub>O-CO<sub>2</sub> and ternary H<sub>2</sub>O-CO<sub>2</sub>-NaCl solutions in saline aquifers is investigated. These solution densities as dispensable properties play pivotal roles in estimating the dynamic evolution of plume containing aqueous CO<sub>2</sub> and brine and also affect fracture dynamics in geologic media. An improved model is proposed to predict the density of saturated binary and ternary solutions as a function of pressure, temperature, and salinity. The model is based on an extended form of the Redlich-Kwong Equation of State that yields more representative values of the molar volumes of liquid CO<sub>2</sub>. The extension involves finding new coefficients for the cubic Redlich-Kwong equation to match one of the solutions with the liquid molar volume deduced from experimentally measured density of binary solutions. The new coefficients are constrained to ensure that the solution branch corresponding to the molar volume in the gas phase remains unchanged. Due to variability in the experimentally measured density of binary solutions, an effective liquid molar volume is obtained with the help of a multi-parameter non-linear regression with respect to pressure and temperature. The proposed model is validated by comparing it with experimental data and is used to study the density-pressure-temperature-salinity relationship. It is found that the density of the saturated solution is proportional to the mole fraction of dissolved CO<sub>2</sub>. In general, solution density is found to increase with pressure but decreases with an increase in temperature within the range of 50-100<super>°</super>C. It is also found that the solution density decreases monotonically with an increase in salinity. Finally, a new model is presented to simulate a reactive fluid within a fracture. Permeability of a fracture controls the path of aqueous CO<sub>2</sub> migration, therefore aperture width of a fracture has a pivotal effect on solubility and mineral trapping of injected CO<sub>2</sub>. This study investigates the impact of the formation of precipitates within fractures on CO<sub>2</sub> transport and storage capacity. The problem involves the flow of CO<sub>2</sub> between finite walls that represents a single fracture. Fluid convection, diffusion, and chemical reactions inside a finite space are solved as a simplified representation of natural mineral trapping. The model is composed of direct numerical simulation of incompressible flow and transport combined with the kinetics of corresponding chemical reactions. For each time step, transport and reactions are solved by means of a finite difference method using a sequential non-iterative approach. The purpose of the current study is to show the time evolution of the aperture shrinkage caused by precipitation of calcite. The current model predicts the actual efficiency of the mineral trapping mechanism by considering the physical properties of the fluid such as its density, pH, and the characteristics of the mineral compositions. It is found that for low Peclet numbers (Pe ≤ 100), the critical time for a fracture blockage is insensitive to the Reynolds number and increases with the Peclet number. At a high Peclet number (Pe=1000), however, the critical time generally decreases with increasing Reynolds number.","Ocean acidification: global warming's evil twin\nWhat the science says...\n|Select a level...||Basic||Intermediate|\nThe current debate on the connection between CO2 emissions and climate change has largely overlooked an independent and equally serious problem, the increasing acidity of our oceans. Last December, the respected journal “Oceanography” published projections (see graphic below) for this rising acidity, measured by falling pH [i], through to the end of the century [ii].\nThe current debate on the connection between CO2 emissions and climate change has largely overlooked an independent and equally serious problem, the increasing acidity of our oceans. Last December, the respected journal “Oceanography” published projections (see graphic below) for this rising acidity, measured by falling pH [i], through to the end of the century [ii]. In 2095, the projected average ocean surface pH is 7.8, and lower still in the Arctic Ocean.\nFig 1: Ocean surface pH - historical values and projected future values based on current emission projections.\nCO2 in the atmosphere has increased from 278 ppm in pre-industrial times to 390 ppm today. During this time, the amount of CO2 dissolved in the ocean has risen by more than 30% [iii], decreasing the pH of the ocean by 0.11 units. As with CO2 and global warming, there is some lag between cause and effect. That means that, even if all carbon emissions stopped today, we are committed to a further drop of up to 0.1 units.\nThe close relationship between CO2 in the atmosphere, CO2 dissolved in the ocean, and the effect of the latter in falling pH, is illustrated by the graph [iv] below:\nFig 2: Annual variations in atmospheric CO2, oceanic CO2, and ocean surface pH. Strong trend lines for rising CO2 and falling pH.\nCO2 dissolves in waterto form carbonic acid. (It is worth noting that carbonic acid is what eats out limestone caves from our mountains.) In the oceans, carbonic acid releases hydrogen ions (H+), reducing pH, and bicarbonate ions (HCO3-).\nCO2 + H2O => H+ +HCO3- (1)\nThe additional hydrogen ions released by carbonic acid bind to carbonate ions (CO32-), forming additional HCO3-.\nH+ + CO32- => HCO3- (2)\nThis reduces the concentration of CO32-, making it harder for marine creatures to take up CO32- to form the calcium carbonate needed to build their exoskeletons.\nCa2+ + CO32- => CaCO3 (3)\nThe two main forms of calcium carbonate used by marine creatures are calcite and aragonite. Decreasing the amount of carbonate ions in the water makes conditions more difficult for both calcite users (phytoplankton, foraminifera and coccolithophore algae), and aragonite users (corals, shellfish, pteropods and heteropods).\nThe photo below left shows healthy specimens of calcifying phytoplankton Gephyrocapsa oceanica. The photo below right shows the damage to the same creature under conditions expected by the end of the century.\nFig 3: Healthy phytoplankton; same species with malformed shell plates as a result of damage by seawater with simulated end of century chemistry.\nSource: Nature, Reduced Calcification of Marine Phytoplankton in Response to Increased Atmospheric CO2, Issue 407 p.364 -367\nIt is often said that a picture is worth a thousand words.\nResearch in the Southern Ocean provides evidence that the formation of foraminifera shells is already being affected. Even though these creatures use calcite, which is less soluble than aragonite, there are already clear signs of physical damage. According to Dr. Will Howard of the Antarctic Climate and Ecosystems Cooperative Research Centre in Hobart, shells of one species of foraminifera (Globigerina bulloides) are 30 to 35 percent thinner than shells formed prior to the industrial period.[vi]. The photo below left shows a pre-industrial exoskeleton of this species obtained from sea-floor sediment. The photo below right shows a exoskeleton of a live specimen of the same species obtained from the water column in the same area in 2007. These stunning images were obtained using an electron microscope. (An interview with Dr. Howard was broadcast on the Catalyst television program). [vii] What is staggering is the amount of erosion in the right image compared to the left. The right sample look porous with larger holes and a 10-fold increase in their number. These and creatures like them are at the base of an ocean food chain, and they are already seriously damaged. If they are lost, it is not just biodiversity we are losing, but our food supply as well.\nFig 4. Pre-industrial and current samples of Globigerina bulloides from same location. Latter shows extensive erosion with a ten-fold increase in holes.\nSource: Australian Broadcasting Corporation, Ocean Acidification – The Big Global Warming Story, 13 September 2007\nThe implications of all of this are disturbing. For corals to absorb aragonite from seawater, the latter needs to be saturated in this mineral.\nNow a report from NOAA scientists found large quantities of water undersaturated in aragoniteare already upwelling close to the Pacific continental shelf from Vancouver to northern California [v]. Although the study only dealt with the area, the authors suggest that other shelf areas may be experiencing similar effects.\nFor corals like those in Australia’s Great Barrier Reef, the outlook is grim. They are threatened with destruction on two fronts, both caused by CO2 emissions. Not only do increased ocean temperatures bleach coral by forcing them to expel the algae which supplies them with energy (see photo at left) [viii], but increased ocean CO2 reduces the availability of aragonite from which reefs are made.\nIt is time to wake up. Our planet is dying. I urge you to find the time to view a 20 minute documentary on the problem of ocean acidification produced by the international Natural Resource Defence Council. Simply go to: www.acidtestmovie.com\nFig 5. Coral killed by above average ocean temperatures.\nReferences and Notes\nIntermediate rebuttal written by alan_marshall\nUpdate July 2015:\nHere is a related lecture-video from Denial101x - Making Sense of Climate Science Denial\nAdditional videos from the MOOC\nExpert interview with Annamieke Van De Heuvel\nExpert interview with Charlie Veron\nExpert interview with Ove Hoegh-Guldberg\nLast updated on 8 July 2015 by pattimer. View Archives"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:a7548d75-77d1-4629-823f-ad5bee24de22>","<urn:uuid:0b5304f2-0a0e-44f7-85df-f8c396571f32>"],"error":null}
{"question":"How does the length of Argentinosaurus's existence compare to the entire reign of dinosaurs on Earth?","answer":"Argentinosaurus lived around 95 million years ago during the late Cretaceous period, while dinosaurs as a group existed for approximately 170 million years throughout the Mesozoic Era. This means Argentinosaurus appeared relatively late in dinosaur history, existing only in the final period of the Age of Reptiles before the Cretaceous-Paleogene Extinction Event around 66 million years ago wiped out all non-avian dinosaurs.","context":["Argentinosaurus was a Huge Cretaceous Sauropod\nArgentinosaurus lived during the late Cretaceous period about 95 million years ago and comes from the Titanosauria family of Sauropods, meaning armored giants. Occasionally known as the “Dino Don” the Argentinosaurus is one of the most famous sauropods of huge proportions that was discovered in the 1990’s.\nThe name Argentinosaurus refers to the country in which it was discovered, Argentina, and comes from the Greek language which when translated literally means “Argentina Lizard”. Named in 1993 by Rodolpho Coria and Jose Bonaparte, Argentinosaurus is pronounced ahr-gen-TEEN-oh-SAWR-us.\n|Prehistoric Era||Late Cretaceous|\n|Weight||80 – 110 Short Tons (72.57 – 99.79 Tonnes)|\n|Length||120 feet (36.58 meters)|\n|Height||70 feet (21.34 meters)|\n|Maximum Speed||Approximately 6 MPH|\n|Territory||Argentina, South America|\nWhat did Argentinosaurus Look Like?\nArgentinosaurus was a very large dinosaur which had a long neck extending more than 29 feet, a relatively small head, a long tail and four rather short muscular legs.\nPalaeontologists know very little about Argentinosaurus as only a few fossilized bones have been recovered from a single individual. But basing their estimates on similar Titanosaur Sauropods, that of the Saltasaurus and Raperosaurus, they have estimated it’s size to be in the region of 72-120 feet long with a height of about 70 feet. Estimates of around 80 tons were recently given for Argentinosaurus weight though by the implementation of a new formula for calculating dinosaurs weight – this is now likely to be much less than previously thought.\nUntil a complete skeleton of Argentinosaurus is found Palaeontologists can not know for certain how large this dinosaur actually was, nor exactly what it looked like though the bones discovered, along with comparing other Sauropods, prove that this dinosaur was one of the largest ever discovered (though not the largest as is often mistakenly thought.)\nPhysical Attributes of Argentinosaurus\nPalaeontologists measured a single vertebra (back-bone) from Argentinosaurus at more than 5.24 feet tall, its tibiae (the joints between knee and ankle) measured 4.9 feet long, the humerus (the bone of the forelimb which would have joined the shoulder and elbow) measured almost 5.9 feet long and an incomplete femur shaft measured 3.87 feet making this dinosaur extremely large and quite intimidating.\nScientists have worked out that this dinosaurs back worked like a bridge made from bone, strong enough to support the weight of the animal but still light enough to produce a dinosaur of such immense size.\nResearchers have also discovered that Argentinosaurs bones were hollow, a very interesting characteristic. It is thought that this served as an evolutionary strategy for maximizing strength and size in relation to its weight.\nWhat did Argentinosaurus Eat?\nArgentinosaurus was an herbivore. This large sauropod had good teeth for grinding and chewing the tough plant material found in Cretaceous period Argentina.\nSome biologists believe that dinosaurs, particularly this large Argentinosaurus, were able to reach such a massive size due to the rate of their metabolism. It is thought that at the height of adolescence an Argentinosaurus would have been able to gain roughly 100 pounds per day – That’s a lot of plant matter!\nHow did Argentinosaurus Move?\nArgentinosaurus walked on four legs but little else is known about its method of locomotion due to a lack of fossil evidence. Some say that because this dinosaur was so big and heavy with rather short legs it may have had trouble moving and certainly wouldn’t have been able to run, but until more evidence is uncovered this is just speculation. We do know that close relatives to Argentinosaurus in the Titanosaur family with similar body shapes were slow movers so it is likely that Argentinosaurus was too.\nWhere did Argentinosaurus Live?\nArgentinosaurus lived about 95 million years ago on the super continent of Gondwana in an area that we recognize today as Argentina, South America. During that period the Patagonian desert was a lush paradise for dinosaurs such as Argentinosaurus.\nThe Patagonia region is one of the world’s hot-spots for the biggest dinosaurs, the 45 foot long carnivorous Giganotosaurus having also roamed here during the same time. It is possible that Giganotosaurus may have preyed on young or sick Argentinosaurus’ and that multiple Giganotosaurus’ may have hunted full-grown Argentinosaurus.\nThe Discovery of Argentinosaurus\nThis dinosaur was only recently discovered in the mid 1990’s at a farm in Patagonia, Southern Argentina, alongside a Giganotosaurus and not much is known about it.\nA shepherd called Guillermo Heredia discovered what he thought was a massive piece of fossilized wood from a tree trunk on his farm and called in palaeontologists from the nearby Carmen Funes Municipal Museum to take a closer look. It was discovered that this was no piece of wood, this was a huge shin bone (tibia) from a very large dinosaur who lived in the Cretaceous age, and a new species at that – A. huincelensis of the new genus Argentinosaurus.\nPalaeontologists went on to discover in total 3 anterior dorsal vertebrae, 3 posterior dorsal vertebrae (back bones), the 1st to 5th sacral vertebrae (the part of the backbone which is attached to the pelvis), sacral ribs of the right side, a major piece of fragmented dorsal rib and the right tibia (lower leg bone).\nBecause only a few fragmentary bones have been found, making up only 5% of the skeleton and the fact that no skull has been found, palaeontologists still have a lot of unanswered questions about this dinosaur and have very few clues to go on as to what it looked like.\nHopefully another Argentinosaurus specimen will be discovered in the future along with more pieces from the holotype, perhaps a skull, to enable palaeontologists to shed more light on this mighty long neck.\nThe Importance of Argentinosaurus\nThe discovery of a new dinosaur is always important as it helps palaeontologists to learn more about what was roaming the land in prehistoric times, shedding light on how future dinosaurs species evolved.\nThe Titanosaur Sauropods were one of the most successful dinosaur families to live after the decline of their predecessors and the discovery of Argentinosaurus hollow bones may fill in some of the missing data on how the Sauropods evolved over time. Unfortunately however without a complete skeleton or at least a skull it is difficult to know exactly what Argentinosaurus really resembled.","When were dinosaurs alive? On this page you’ll learn about the dinosaur periods of the Mesozoic Era – the ‘Age of Reptiles’.\nWe’ll look at each of the three ‘dinosaur periods’ – the Triassic, Jurassic and Cretaceous – and find out what life on Earth was like in those times.\n- You can find out more about dinosaurs at our main Dinosaur Facts page.\nWhen Were Dinosaurs Alive?\nDinosaurs were alive in the Triassic, Jurassic and Cretaceous periods. Together, these three periods make up the Mesozoic Era. Due to the dominance of the dinosaurs and other reptiles during the Mesozoic Era, it has become known as the ‘Age of Reptiles’.\nMesozoic Era (252.17 to 66 million years ago)\n- Triassic Period (252.17 to 201.3 million years ago): Dinosaurs begin to appear, having evolved from reptiles called Archosaurs.\n- Jurassic Period (201.3 – 145 million years ago): Dinosaurs become the dominant land vertebrates.\n- Cretaceous Period (145 – 66 million years ago): Dinosaurs continue to thrive and diversify.\n- Cretaceous–Paleogene Extinction Event (around 66 million years ago): The dinosaurs are wiped out; only avian dinosaurs (birds) survive.\nFurther down the page you’ll find information on each of the three periods of the Mesozoic Era, including examples of the dinosaurs that existed during each period.\nMesozoic Era: ‘Age of Reptiles’\nThe Mesozoic Era lasted for around 186 million years. It began around 252.17 million years ago, and ended around 66 million years ago. Dinosaurs started to appear around 243 to 231 million years ago, during the Triassic Period.\nDinosaurs are among the most successful groups of animals ever to have lived. They walked the earth for around 170 million years. (Bear in mind that humans have only existed for 2 million years!)\nHowever, the dinosaurs’ successful reign came to an abrupt end.\nDinosaur Periods: Extinction\nThe Mesozoic Era ended with the ‘Cretaceous–Paleogene Extinction Event’, which wiped out the dinosaurs and many other species.\n(An extinction event is a sudden and wide-ranging decrease in the amount of life on Earth.)\nDivisions Of The Mesozoic Era\nAs we’ve seen, the Mesozoic Era is subdivided into three periods: the Triassic, Jurassic and Cretaceous periods. These are ‘geological periods’ of time: each corresponds to a particular layer of rock.\nThe scientific body responsible for measuring the geological timescale is the International Commission on Stratigraphy.\nIn the geological timescale, each period is further divided into ‘epochs’. The Triassic and Jurassic periods are divided into three epochs, the Cretaceous into two.\nMesozoic Era (252.17 to 66 million years ago)\n- Triassic Period (252.17 to 201.3 million years ago)\n- Early Triassic Epoch (252.17 – 247.2 million years ago)\n- Middle Triassic Epoch (247.2 – 237 million years ago)\n- Late Triassic Epoch (237 – 201.3 million years ago)\n- Jurassic Period (201.3 – 145 million years ago)\n- Early Jurassic Epoch (201.3 to 174.1 million years ago)\n- Middle Jurassic Epoch (174.1 to 163.5 million years ago)\n- Late Jurassic Epoch (163.5 to 145 million years ago)\n- Cretaceous Period (145 – 66 million years ago)\n- Early Cretaceous Epoch (145 to 100.5 million years ago)\n- Late Cretaceous Epoch (100.5 to 66 million years ago)\nThe Age of the Dinosaurs\nLet’s find out what the world was like during the three ‘dinosaur periods’ of the Mesozoic Era …\n1: Triassic Period (252.17 to 201.3 million years ago)\nThe Eoraptor is one of the first dinosaurs. It appeared during the Triassic Period.\nThe Triassic Period followed the worst extinction event that the world has ever experienced. (Yes, it was even worse than the later extinction event that would wipe out the dinsoaurs.)\nThe Permian-Triassic Extinction Event, or the ‘Great Dying’ as it is otherwise known, caused between 90% and 96% of all species on Earth to became extinct.\nAt the beginning of the Triassic Period, life on Earth struggled to rebuild itself. At first, the mammal-like reptiles, successful before the extinction event, started to dominate once again.\nMammal-like animals such as the Lystrosaurus – a strange, dog-sized animal with tusks – thrived in the Early Triassic. Mammals themselves would appear towards the end of the Triassic Period.\nHowever, it was another group of animals that would win the race to supremacy: the Archosaurs. Through the course of the Triassic Period, these reptiles became the dominant land vertebrates (animals with backbones).\nAs the Triassic Period progressed, the archosaurs split into two main branches. One of these was the Pseudosuchia, which includes the Crocodilians, and similar animals. The other branch was the Avemetatarsalia, which itself split into Pterosaurs and Dinosaurs.\nThe first dinosaurs were, small, walked on two legs, and ate meat.\nIn the Triassic period, all of the world’s land was joined together in one vast supercontinent called ‘Pangaea’, which means ‘whole Earth’. The climate was hot and dry. The interior of Pangaea was a vast desert.\nPlants such as conifers and ginkgoes flourished. There was no grass, and there were no flowering plants.\nWhen Were Dinosaurs Alive: Triassic Period Dinosaurs\nOne of the earliest dinosaurs was the Eoraptor, a small predator that lived around 228 million years ago (see picture, above). Found in north-west Argentina, it walked on two legs and stood knee-high to a human.\nEoraptor looked like a ‘typical’ dinosaur, with a long tail, long neck and short arms.\nSaurischia and Ornithischia\nEoraptor was a saurischian, one of the two main types of dinosaur. All of the meat-eating dinosuars were saurichians, as were many of the large, four-legged plant eaters.\nThe other main type of dinosaur was ornithischia. The Ornithischians were all herbivores (plant-eaters)\nOne of the earliest known Ornithischians is the Pisanosaurus. This was a small dinosaur that walked on two legs, and outwardly looked much like early bipedal (2-legged) saurichians.\nWhen Were Dinosaurs Alive: Triassic Period Dinosaurs\n2: Jurassic Period (201.3 – 145 million years ago)\nThe Jurassic Period began with another extinction event – the Triassic-Jurassic Extinction Event. While not quite as devastating as the earlier Permian-Triassic Extinction Event, it still led to a substantial decline in both sea and land species.\nThe extinction set the scene for dinosaurs – who were already flourishing by the end of the Triassic – to completely dominate the land.\nPangaea began to break apart in the Jurassic Period, forming two landmasses, Laurasia in the north, and Gondwana in the south. As the continents separated, the climate became wetter and more humid.\nConifer forests covered much of the land, especially near the poles. Ginkgoes, palms, tree-ferns and horse-tails were also present. The first birds appeared. Insects and amphibians continued to develop. Mammals evolved fur coats and started giving birth to live young.\nHuge sauropods such as Brachiosaurus walked the land, feeding on the flourishing vegetation. Large predators, such as Allosaurus also made an appearance.\nWhen Were Dinosaurs Alive: Jurassic Period Dinosaurs\nExamples of Early Jurassic Dinosaurs\nExamples of Mid Jurassic Dinosaurs\nExamples of Late Jurassic Dinosaurs\n3. Cretaceous Period (145 – 66 million years ago)\nDuring the Cretaceous Period, the continents continued to separate. Gondwana broke up to form South America and Africa, and Antarctica and Australia also drifted away. Laurasia began to split into North America, Europe and Asia. The world – as we know it today – began to take shape.\nThe climate became wetter, and the newly formed oceans offered new habitats.\nFlowering plants appeared in Laurasia at the beginning of the Cretaceous Period. By the end of the Cretaceous they were the Earth’s dominant plant type. Oak, maple and beech trees were all present. Insects evolved alongside the new plants.\nWhen Were Dinosaurs Alive: Cretaceous Period Dinosaurs\nAlthough some types of dinosaur, such as the Stegosaurs, died out during the Cretaceous Period, ever-more varied types evolved to take their places.\nDuck-billed dinosaurs such as Iguanodon, armoured dinosaurs such as Polacanthus, and the Ceratopsids, including Triceratops, all thrived during the Cretaceous Period.\nCretaceous–Paleogene Extinction Event\nMany of these dinosaurs existed right up to the end of the Cretaceous Period. However, 66 million years ago, the Earth was rocked by a catastrophic event that wiped out over 75% of all living species.\nThis was the Cretaceous–Paleogene Extinction Event, and it brought the whole Mesozoic Era to a close. At the dawn of the Cenozoic Era, the only dinosaurs still alive were the birds.\nAll of the non-avian dinosaurs had become extinct.\nScientists believe that the Cretaceous–Paleogene Extinction Event (which is also known as the K–Pg extinction event, or Cretaceous–Tertiary (K–T) extinction event) was caused by a large asteroid striking the Earth.\nThe explosion would have thrown up a dust cloud big enough to hide the sun for months, or even years. Plants would have been unable to grow in the darkness, and many of the Earth’s animals – including the dinosaurs – would have been unable to find enough food to survive.\nThe age of the dinosaurs had come to an end.\nExamples of Early Cretaceous Dinosaurs\nExamples of Late Cretaceous Dinosaurs\nDinosaur Periods: When Were Dinosaurs Alive – Conclusion\nThe Mesozoic Era is subdivided into three periods: the Triassic, Jurassic and Cretaceous periods.\nDinosaurs first appeared towards the end of the Triassic Period. Following the Triassic-Jurassic extinction event, the dinosaurs quickly became the dominant land animals on Earth. They would remain so throughout the Jurassic and Cretaceous Periods.\nThe dinosaurs became increasingly diverse throughout the Cretaceous Period, and thrived right up to the Cretaceous–Paleogene Extinction Event.\nThis extinction event, believed to have been caused by a large asteroid striking the Earth, wiped out all of the (non-avian) dinosaurs. Only avian dinosaurs – or birds – survived. (Many scientists today believe that birds are actually dinosaurs, meaning that birds are the only dinosaurs to have survived the extinction event).\nWe hope that you’ve enjoyed reading about the three ‘dinosaur periods’ of the Mesozoic Era.\nOther Relevant Pages on Active Wild\nYou can find more dinosaur information on our main Dinosaur Facts page, or check out these pages for in-depth dino facts:"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:b3713a21-f19f-4461-9776-5c9d8ab8134b>","<urn:uuid:9a6e8fa5-cab4-43f4-9eb6-c7dda4ff9d92>"],"error":null}
{"question":"How do saline brines contribute to the process of base metal leaching in the McArthur Basin's volcanic rocks, and what are the key characteristics of these fluids?","answer":"The saline brines responsible for base metal leaching were non-gassy, low-temperature (~100°C) Na-K-Ca-Mg-rich brines with salinity greater than 20 wt % NaCl equivalent. These fluids were oxidized, hematite-stable, and had low H2S contents, which gave them a high capacity for transporting base metals. They interacted with dolerites, causing significant chemical changes and almost 100 percent depletion of Cu, Pb, and Zn. The brines likely originated from overlying evaporitic carbonates during diagenesis, as evidenced by their high salinities and the presence of hydrocarbons.","context":["K metasomatism and base metal depletion in volcanic rocks from the McArthur Basin, Northern Territory - implications for base metal mineralisation\nCooke, DR and Bull, SW and Donovan, S and Rogers, JR, K metasomatism and base metal depletion in volcanic rocks from the McArthur Basin, Northern Territory - implications for base metal mineralisation, Economic Geology, 93, (8) pp. 1237-1263. ISSN 0361-0128 (1998) [Refereed Article]\nEvidence for the leaching of base metals by oxidized, saline brines has been recognized from dolerites of the Upper Tawallah Group, southern McArthur basin. In the Mallapunyah dome region, the Upper Tawallah Group consists of a series of shallow-level dolerite sills (Settlement Creek and Gold Creek Volcanics) that have intruded a sequence of fluvial, lacustrine and shallow marine hematitic sandstones and evaporitic siltstones and carbonates. Oxidized sandstones and evaporitic carbonates of the Lower McArthur Group overlie the Tawallah Group. Formation of the Mallapunyah dome occurred due to uplift at end-Tawallah Group times, marked by the emplacement of volcano-sedimentary breccias interpreted as debris flow deposits of the Gold Creek Volcanics. K-metasomatism has resulted in the replacement of dolerites of the Settlement Creek and Gold Creek Volcanics by potassic (orthoclase + quartz ± sericite ± hematite ± dolomite ± anatase ± barite) and chlorite-orthoclase (chlorite-orthoclase-quartz ± dolomite ± sericite ± actinolite ± albite ± anatase) mineral assemblages. Three varieties of potassic alteration have been recognized: intense, texturally destructive potassic alteration halos around quartz ± hematite ± dolomite ± chlorite veins; intense, texturally destructive pervasive potassic alteration; and intense, pervasive, texturally destructive potassic alteration rinds (<1 cm thick) that occur around amygdules. K-metasomatism caused significant chemical changes to dolerites of the Settlement Creek and Gold Creek Volcanics, which now contain up to 11.8 wt percent K 2O, 68.4 wt percent SiO 2 and between 0.4 and 23.5 wt percent Fe 2O 3. Zr, Ti, Al, and Nb remained immobile during the formation of potassic and chlorite-orthoclase alteration, whereas Y and P were mobilized. Mass-balance calculations have shown that significant leaching (~9.8% net mass loss) took place during texturally preserving chlorite-orthoclase alteration at Mallapunyah dome. Additional leaching (3.5-6% net mass loss) at higher water/rock ratios resulted in destruction of primary textures and development of the potassic alteration assemblage. Many chemical components were removed from the dolerites, including an almost 100 percent depletion of Cu, Pb, and Zn. The fluids responsible for potassic alteration were non-gassy, low-temperature (~100°C) saline (>20 wt % NaCl equiv) Na-K-Ca-Mg-rich brines. The high salinities and the presence of hydrocarbons are consistent with brine derivation from the overlying evaporitic carbonates during diagenesis. Carbon-oxygen (carbonate) and oxygen (silicate) isotope analyses are consistent with the formation of dolomite veins and potassic alteration in the Settlement Creek Volcanics during interaction with low-moderate temperature (~100°C) evolved meteoric waters ± seawater (δ 18O((fluid)) ~ -1‰; δ 13C((fluid)) ~ -7‰), which descended through the overlying carbonate horizons, becoming progressively more saline and enriched in 18O as they interacted with the partially lithified sediments. The fluids responsible for metal leaching and potassic alteration of the Tawallah Group dolerites are interpreted to have been low temperature, hematite-stable, saline brines with a high base metal transporting capacity due to their oxidized nature and low H 2S contents. The metals acquired by these brines could have been transported significant distances through a suitable aquifer (e.g., well-sorted hematitic sandstone), and the resultant metalliferous brines were probably involved in the formation of at least some of the stratiform Pb-Zn, MVT, and breccia-hosted Cu deposits in the Upper Tawallah and McArthur Groups."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:acb55a19-faeb-4d14-a595-6faa286c5b62>"],"error":null}
{"question":"Could you compare the duration of volcanic activity between the Fuego volcano in Guatemala and the 2021 Cumbre Vieja eruption in La Palma? I'm particularly interested in their active periods.","answer":"While the Fuego volcano in Guatemala has remained consistently active over time with periodic eruptions, the 2021 Cumbre Vieja eruption lasted for a specific duration of 85 days (from September 19 to December 13, 2021), making it the longest known eruption on La Palma. The Fuego volcano's activity is more continuous, with regular eruptions that can be observed, though you need to be lucky to see significant eruptions.","context":["Albert Dros has been a great friend to Lonely Speck over the last few years, sharing with us his experiences shooting landscape astrophotography around the world. We had the pleasure of meeting him in his native environment of the Netherlands when we traveled through Europe last spring. A few weeks ago, Albert messaged me about his plans to photograph the Milky Way behind an erupting volcano. In this article, Albert Dros recounts his personal experience planning and shooting the Fuego Volcano in Guatemala.\nNature has lots to offer for landscape photographers. We love to shoot nature’s paintings. Storms, rainbows, tornadoes, lightning strikes: they’re all a gift from nature that we can play with as a landscape photographer. Volcanoes are one of them, too, especially when they’re erupting. I have been fascinated by volcanoes; they have been on my list to shoot for quite a while. My younger brother recently went to Guatemala for some backpacking and learning the Spanish language. When he sent me some photos of an erupting volcano, my photography senses were immediately triggered. The erupting volcano was called ‘Fuego’ (literally “Fire”). I managed to find webcams and activity on scopes and checked how active Fuego was. According to the history, the volcano has remained quite active, but you had to be lucky to see a lot of eruptions. Still, the idea of meeting up with my brother and shooting a volcano seemed like a good enough reason to go.\nWhen I decided I wanted to go to Guatemala to try and shoot the volcano, I started doing my research on how I wanted my shot to look. Erupting lava is best visible in evening and night, so I was obviously going for that. I researched other shots from this volcano. Most good shots were during a full moon so that you could see the scenery well, lit by the full moon in combination with the lava eruptions. I wanted to try something different. I have always been intrigued with planning and photographing the Milky Way at particular locations. How awesome would it be to shoot the erupting volcano with the Milky Way?\nI checked from what angle I would be able to see the erupting volcano. The place from which I was going to be shooting was the (inactive) neighbour volcano Acatenango. It’s possible to hike up to the top of this Acatenango for a good view of the active Fuego. I planned the shot with the PhotoPills app, and to my excitement this shot was actually possible. In the last week of March, around 3 AM, the Milky Way galactic center would be in a good position right next to the volcano. By planning on PhotoPills and visualising the view in my head, I could see how the optimal shot would unfold.\nI made my plan a few weeks before going to Guatemala, targeting the date of 30 March, 2017. Should the conditions change, the plan wouldn’t differ too much for the other days around my target date.\nWhile I made my plan with a private Alpha version of PhotoPills for Android, PhotoPills has since released a public Beta for Android users.\nWhat I Needed\nSo what did I need to get the shot?\n1) The right date for the Milky Way to rise next to the Fuego volcano, as seen from the Acatenango volcano\n2) A clear night free of cloud cover\n3) Date close to new moon for good visibility of the stars\n4) Most importantly: luck. I wanted lava eruptions at the right times of the evening\nI figured it would be extremely difficult to get both the stars and the lava properly exposed in one exposure because of the huge contrast difference. To get the perfect balance of exposure, I thought I would have to shoot during late blue hour at sunset or early blue hour at sunrise. When planning a trick shot like this, there are a lot of factors I considered. I always like to plan everything that can be planned.\nWhen I succeed in making a difficult landscape shot, people often say “wow, you were so lucky.” They’re often actually right. In the end you always need that extra bit of luck for everything to fall into place. But ultimately, I try to keep the chances as good as possible with careful planning. For example: checking scopes and webcams every day to ‘get to know’ the volcano and calling the weather station multiple times to improve my awareness of the chances of getting a successful shot.\nA few weeks later, after a nearly 30 hour plane trip including transfers, I found myself in Antigua, Guatemala, a nice town close to the Fuego volcano. From the town, I could see the top of the Fuego blowing smoke with occasional rumbling.\nChecking the seismograph activity online showed that, in the days during my travel to Guatemala, the volcano had been very active. We called the weather station multiple times that day to ask their thoughts on what day would be best to climb the adjacent Acatenango volcano in regards to both volcanic activity of Fuego and for clear skies. According to the station, the weather predictions for the next day looked good and it would be the best day to try our luck. I was originally planning on getting a day of rest in Antigua before climbing the volcano but I knew I had to move fast.\nI knew the hike wasn’t going to be easy so I had to keep my gear relatively light while still maintaining great image quality. I also heard stories about bandits robbing tourists on the volcanoes in Guatemala and those stories worried me the most as I was bringing expensive gear. I chose to put my camera gear in a super worn out bag that didn’t look like a camera bag at all. I figured that with a relatively light and small kit, I wouldn’t stand out. I needed a tripod, but not one that would scream ‘I’m a photographer’ so I brought a small Mefoto travel tripod that I borrowed from my friends at Benro. It was small enough that it could fit in my backpack such that no one would see it. Here’s the final list of camera gear that I brought up to the volcano:\n- Sony a7RII body (Amazon / B&H)\n- Sony Zeiss 16-35 f/4 (Amazon / B&H) (for general shots)\n- Sony Zeiss 55 f/1.8 (Amazon / B&H) (for tighter shots during the night, perfect lightweight prime for nightscapes)\n- Sony 85 f/1.8 (Amazon / B&H) (new medium telephoto lens, very small and light, good for tighter shots)\n- Samyang/Rokinon 14mm f/2.8 (Amazon / B&H) (my go-to lens for Milky Way nightscape panoramas)\n- Mefoto Traveler tripod (B&H)\nThe next day, after a very tough steep hike, I found myself on the Acatenango volcano, arriving to the shooting location just before sunset. Unfortunately, it was very cloudy and I couldn’t even see the Fuego volcano next to me. However, the clouds were moving fast so I hoped it was going to clear up. It did.\nWhen I finally saw Fuego erupt up close, combined with the power of its sound, I was paralysed with awe. It was amazing. It was one of the most impressive things I had ever seen in nature.\nMy research paid off. All the elements I needed to create the shot that I wanted seemed to fall into place. It’s a great feeling when things go as planned. The real show started as it got darker: Fuego kept erupting and the glowing lava finally became visible. It was surreal. The sight of an erupting volcano is something I was only used to seeing in movies.\nDuring the blue hour, the volcano unfortunately became calm for a while. Blue hour would have been perfect to shoot the eruptions as the contrast between the sky and the lava would not have been as large. I figured that it would be much more difficult to shoot during the dark hours of the night because of the increased contrast between the bright lava and the dark night sky.\nI was right. The pure darkness during the night made for difficult shooting conditions. The huge contrast between the bright lava and the darkness of the night made it extremely difficult to shoot everything in a single exposure. In this early shot, the lava is overexposed while the rest of the image is still very dark.\nFor good close up shots with the Milky May, I knew I had to wait for the early morning blue hour and hope for a good eruption. Only until then, the Milky Way would line up with the volcano. Early in the night, only the fainter parts of the Milky Way were visible off to the left of the volcano.\nEven early in the night, the view was nothing short of spectacular. Seeing the Fuego erupt under thousands of stars was unbelievable. Below is a panoramic shot from the view in front of my tent. The volcano on the left is a sleeping volcano called Agua. Agua, water. Fuego, fire. In between these volcanoes are a few little towns. I was surprised to see that these towns did not cause that much light pollution the sky. Luckily, there was some kind of haze layer blocking some of the light pollution, allowing us to see a beautiful starry sky. I knew the best part of the Milky Way would arch across the valley in early morning, but I already found this view amazing.\nI kept shooting for a while until I decided to get some sleep in my tent around 10 PM. While it was around 30°C (86°F) in Antigua during the day, at 3500 m (11,483 ft) it was below 0° Celsius (32°F). Even though I was prepared, it was still extremely cold. Furthermore, I didn’t get very much sleep as the volcano periodically kept erupting in loud explosions. I eventually woke up around 2 AM for more shooting. As planned, the Milky Way stretched over the valley to the left of Fuego.\nAlthough all of this was amazing, I wouldn’t be me if I still wasn’t 100% satisfied. As I mentioned before, I really wanted a close up of the erupting volcano with the Milky Way. My best opportunity was that morning. I put my camera in position for the early blue hour when the Milky Way would still be visible. At that time, a very faint crescent moon had risen in the sky, giving me some extra light on the foreground. I set everything up and waited for the right moment. I just needed that right eruption. And then it happened.\nA captured a perfectly timed shutter with the Milky Way in place behind the fiery lava of the erupting Fuego volcano. When I first saw it on my camera screen, I couldn’t believe my eyes. The satisfaction that I got from succeeding in taking what seemed to be an almost impossible shot is hard to describe.\nHaving the shots I wanted for the night, I enjoyed the warmth of the rising sun not too long afterwards. I was already satisfied so I didn’t shoot too much more, deciding instead to enjoy the moment. After the sun was fully up, the Fuego treated us a final goodbye show with nonstop eruptions that caused the whole valley to be covered in smoke and ash.\nI still feel that all of the images here still don’t do justice to the reality of my experience. Seeing a volcano erupt at night is one of the most beautiful things in nature I have ever seen.\nHelp Support Us!\nWe hope that you enjoyed this inspirational article by our guest contributor and great friend, Albert Dros. Check out more of Albert’s spectacular landscape photography and astrophotography on his website: AlbertDros.com and follow Albert’s worldwide travels and photography adventures on his Instagram, Twitter, Facebook and 500px.\nAll photographs on this page are copyright of Albert Dros. All Rights Reserved.\nWe are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites. We are also a participant in the B&H Affiliate Program which also allows us to earn fees by linking to bhphotovideo.com.\nAstrophotography 101 is completely free for everyone. All of the lessons are available on the Lonely Speck Astrophotography 101 page for you to access at any time. Enter your email and whenever we post a new lesson you’ll receive it in your inbox. We won’t spam you and your email will stay secure. Furthermore, updates will be sent out only periodically, usually less than once per week.\nHelp us help you!\nBelieve it or not, Lonely Speck is my full-time job. It’s been an amazing experience for us to see a community develop around learning astrophotography and we’re so happy to be a small part of it. I have learned that amazing things happen when you ask for help so remember that we are always here for you. If you have any questions about photography or just want to share a story, contact us! If you find the articles here helpful, consider helping us out with a donation.Donate\nThanks so much for being a part of our astrophotography adventure.","2021 Cumbre Vieja volcanic eruption\nThe 2021 Cumbre Vieja volcanic eruption was a volcanic eruption of Cumbre Vieja on the island of La Palma, one of the most active volcanoes in the Canary Islands, Spain. It is the first volcanic eruption on the island since the eruption of Teneguía in 1971. At 85 days, it is the longest known eruption of a volcano on La Palma.\n|2021 Cumbre Vieja volcanic eruption|\n|Start date||19 September 2021|\n|End date||13 December 2021|\n|Location||La Palma, Spain|\nMap of the lava flow on 23 November 2021\nAn earthquake swarm started on 11 September, which led to the volcanic eruption on 19 September.\nAround 300 people from the local area were evacuated shortly after the eruption.\nIt is the most damaging volcanic eruption on La Palma since records began.\nInitially, when the eruption started, it had a Volcanic Explosivity Index (VEI) of 0, when it was a purely lava eruption. But with the ashfall that began a week later, the Volcanic Explosivity Index of the eruption rose to 2.\nOn 28 September, at around 23:02 UTC, the lava flow reached the sea at the Perdido Beach.\nOn 20 November, the Volcanic Explosivity Index (VEI) was upgraded from VEI 2 to VEI 3, when the ashfall reached 10 million m³.\nOn 12 December, the volcanic eruption broke the local record, when it reached 85 days of continuous activity. The eruption is the longest known eruption of a volcano on La Palma. Previously, the eruption of the Tajuya volcano in 1585 was the longest at 84 days. No reliable data is available about earlier volcanic eruptions, before Spanish colonization of La Palma in the 15th century.\nOn 13 December, the volcanic eruption stopped. Noting weak seismicity and zero tremors, scientists said that a resumption of the eruption is highly unlikely, giving locals hope that it is over.\nOn 25 December 2021, after 12 days with no activity from the volcano, the eruption was officially declared to have ended.\n- \"Entra en erupción el volcán en La Palma\". El País. 19 September 2021. Retrieved 2021-09-19.\n- Parra, Aritz; Hatton, Barry (2021-12-15). \"After 3 tense months, Spanish volcano eruption may be over\". Associated Press. Retrieved 2021-12-20.\n- EFE (2021-11-20). \"El volcán de La Palma sube el índice de explosividad por la emisión de piroclastos\" [The La Palma volcano increases the explosivity index due to the emission of pyroclasts] (in Spanish). EFE. Retrieved 2021-11-23.\n- \"Overall Orange alert Volcanic eruption for La Palma\". Global Disaster Alert and Coordination System (GDACS). 2021-09-27. Retrieved 2021-09-27.\n- Carracedo, Juan Carlos; Troll, Valentin R. (1 January 2021), \"North-East Atlantic Islands: The Macaronesian Archipelagos\", in Alderton, David; Elias, Scott A. (eds.), Encyclopedia of Geology (Second Edition), Oxford: Academic Press, pp. 674–699, ISBN 978-0-08-102909-1, retrieved 10 October 2021\n- \"Spanish island volcano eruption hits local record of 85 days\". Associated Press. 2021-12-12.\n- \"Lockdown lifted for 33,000 confined on La Palma due to bad air quality from volcano\". El País. 2021-12-13.\n- \"Spanish Canary Island volcano erupts after weeks of earthquakes\". the Guardian. 19 September 2021.\n- \"Lava shoots up from volcano on La Palma in Spain's Canary Islands\". Reuters. 19 September 2021. Retrieved 19 September 2021.\n- \"La Palma island volcano erupts spewing lava, ash and pyroclastic debris, local evacuations begin\". The Canary - News, Views & Sunshine. 19 September 2021. Archived from the original on 21 September 2021. Retrieved 19 September 2021.\n- 20minutos (4 October 2021). \"Últimas noticias de las erupciones volcánicas en La Palma\". www.20minutos.es – Últimas Noticias (in Spanish). Archived from the original on 4 October 2021. Retrieved 4 October 2021.\n- \"The new volcano is the most damaging among the historical eruptions on La Palma\". Canarian Weekly. 20 October 2021.\n- \"La lava del volcán de La Palma alcanza el mar\". elDiario.es (in Spanish). 2021-09-29. Retrieved 2021-09-29.\n- Jones, Sam (2021-12-15). \"'Tremor is zero': La Palma volcano may be calming down\". The Guardian.\n- Trujillo, Marco (2021-12-16). \"Inside La Palma's volcano: lull in activity allows look into crater\". Reuters.\n- Vega, Guillermo (2021-12-15). \"La Palma volcano comes to stop: 'It is not emitting lava, nor sulfur dioxide, nor registering seismic activity'\". El País.\n- \"Spain's La Palma volcano eruption declared over after three months\". BBC News. 2021-12-25."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:f3508dff-1149-44f7-a41d-75c89b6438b4>","<urn:uuid:f25aa0a4-9888-46b9-8ba8-3f3845009027>"],"error":null}
{"question":"Could you provide a detailed timeline of both the geological formation of Lake Superior agates and the historical use of turmeric in medicine, arranged chronologically?","answer":"Over 1 billion years ago: North American continent began splitting, creating iron-rich lava flows along Lake Superior. The Superior trough formed and gas pockets in solidified lava were filled with quartz-rich solutions, forming banded agates. 2 million years ago: Ice Age began, with Superior lobe glacier moving 10,000-15,000 years ago, carrying and polishing agates. For turmeric, it has been used in Ayurvedic medicine for over 5,000 years. More recently, modern research has revealed its active compound curcumin's anti-inflammatory properties, though it has poor bioavailability. Studies in recent years, including a 6-month randomized controlled trial, have demonstrated curcumin's benefits for type 2 diabetes patients when properly absorbed.","context":["More than a billion years ago, the North American continent began to split apart into two separate continents. This catastrophic event, spurred by molten rock moving deep within the earth, poured out massive, iron-rich lava flows. These flows now are exposed along the north and south shores of Lake Superior.\nThe tectonic forces that attempted to pull the continent apart, and which left behind the lava flows, also created the Superior trough. The trough eventually became the basin of Lake Superior and the lava flows became the birthplace of Lake Superior agates.\nWater vapor and carbon dioxide became trapped within the solidified flows in the form of millions of bubbles, called gas pockets or vesicles. Later, groundwater carrying ferric iron, quartz, and other dissolved minerals passed through the trapped gas vesicles. These quartz-rich groundwater solutions crystallized into concentric bands of fine-grained quartz called chalcedony.\nOver the next billion years, some of these quartz-filled, banded vesicles -- agates -- were freed by running water and chemical disintegration of the lavas, since these vesicles were now harder than the lava rocks that contained them. The vast majority, however, remained lodged in the lava flows until the next major geologic event that changed them and Minnesota.\nAbout 2 million years ago, the world's climate grew colder signaling the beginning of the Great Ice Age. A lobe of glacial ice, the Superior lobe, moved into Minnesota 10,000 to 15,000 years ago. It followed the agate-filled Superior trough. The glacier picked up surface agates and carried them south. Its crushing action and cycle of freezing and thawing at its base also freed many agates from within the lava flows and transported them, too. The advancing glacier acted like an enormous rock tumbler, abrading, fracturing, and rough-polishing the agates.\nThe Lake Superior agate differs from other agates found around the world in its rich red, orange, and yellow coloring. This color scheme is caused by the oxidation of iron. Iron leached from rocks provided the pigment that gives the gemstone its beautiful array of color. The concentration of iron and the amount of oxidation determine the color within or between an agate's bands.\nThe gemstone comes in various sizes. The gas pockets in which the agates formed were primarily small, about the size of a pea. A few Lake Superior agates weigh more than 20 pounds, about the size of a bowling ball. Such giant agates are extremely rare, but no doubt others are yet to be discovered.\nThe most common type of Lake Superior agate is the fortification agate with its eye-catching banding patterns. Each band, when traced around an exposed pattern or \"face,\" connects with itself like the walls of a fort, hence the name fortification agate.\nA common subtype of the fortification agate is the parallel-banded, onyx-fortification or water-level agate. Perfectly straight, parallel bands occur over all or part of these stones. The straight bands were produced by puddles of quartz-rich solutions that crystallized inside the gas pocket under very low fluid pressure. The parallel nature of the bands also indicates the agate's position inside the lava flow.\nProbably the most popular Lake Superior agate is also one of the rarest. The highly treasured eye agate has perfectly round bands or \"eyes\" dotting the surface of the stone.\nOccasionally, collectors find a gemstone with an almost perfectly smooth natural surface. These rare agates are believed to have spent a long time tumbling back and forth in the waves along some long-vanished, wave-battered rocky beach. They are called, appropriately enough, \"waterwashed\" agates.\nFinally, the rarest Lake Superior agate is the one that recurs in a collector's dreams but is discovered in reality perhaps once in a lifetime. On average only one out of every 10,000 agates fits this description. They are the ones weighing 2 pounds or more and having perfect shape, color, and banding quality. They are the ones called \"all-timers.\"\nThe word \"gemstone\" implies that a stone can be used as a jewel when cut and polished. The Lake Superior agate certainly qualifies, although only a fraction of the stones are of the quality needed for lapidary -- the art of cutting and polishing stones. During glacial movement, most of the agates were badly fractured by tremendous pressures within the ice and by repeated freezing and thawing.\nThree lapidary techniques are used on Lake Superior agates. The most common technique is tumbling. Small gemstones are rotated in drums with polishing grit for several days until they are smooth and shiny.\nMedium-size \"lakers\" (one-quarter pound to 1 pound) often are cut with diamond saws into thin slabs, which then are cut into various shapes. One side of the shaped slab is polished producing fine jewelry pieces and collectible gems called cabochons. Cabochons can be set in rings, bracelets, belt buckles, and tie clasps.\nA technique called face polishing is less commonly used on the state gemstone. It involves polishing a curved surface on a portion of the stone and leaving the major portion in its natural state","Improve the Benefits of Turmeric by Adding Black Pepper\nThis article looks at turmeric and why we should be including black pepper in our meal, to increase the benefits associated with using turmeric.\nTurmeric is increasing in popularity for its health benefits, having been used in Ayurvedic medicine over 5,000 years ago!\nBlack pepper in its own right, also, has an abundant amount of health benefits. It is a great source of manganese, which helps the body form connective tissues, bones and sex hormones. However, there is also another beneficial function of black pepper, when you combine it with turmeric, which we will now look at.\nTurmeric contains a compound called curcumin, a bright yellow chemical, which gives turmeric its vibrant colour. Curcumin has been identified as being beneficial for its anti-inflammatory properties.\nWhen you ingest turmeric with black pepper, you are increasing the amount of the curcumin you can absorb and your body can use.\nCurcumin has been associated with numerous health benefits including anti-inflammatory and an antioxidant, protecting healthy cells from free radicals which can cause damage.\nThe reason that black pepper enables this increase in our body using curcumin, is due to piperine a compound found in black pepper, which slows our liver from metabolising the curcumin too quickly and removing it through urine.\nBy slowing this process our body is able to utilise more of the curcumin and its beneficial effects!\nCurcumin is quickly metabolised and removed from the body by the liver and the intestinal wall, due to its poor bioavailability.\nWhat is ‘Bioavailability’?\nThe bioavailability of a food is the amount of a nutrient which is available and readily absorbed by the body to use for metabolic purposes in the body, from the food that we ingest.\nSome nutrients have a high bioavailability and can be digested, absorbed and metabolised by the body with ease, however, when it has a poor or low bioavailability (certain vitamins and minerals) the process of digestion, absorption and metabolism can vary and this can also be impacted by other vitamins and minerals that we consume these can either inhibit or facilitate these processes.\nTo facilitate our body to increase the bioavailability of curcumin it has been found that adding black pepper enables this increase in bioavailability.\nA 6 month randomised, double-blinded and placebo controlled (high standard for testing) study, on subjects diagnosed with type 2 diabetes, found that those who were not taking the placebo and had 3 capsules twice a day of curcumin, had a lower atherogenic risk, and an improvement in their metabolic profile (Chuengsamarn et al., 2014).\nPiperine in Black Pepper\nThe compound, piperine, found in black pepper is what gives black pepper its taste.\nPiperine has been shown to increase the bioavailability of nutrients in both food and supplements. This includes selenium, the B vitamins, and beta-carotene.\nPiperine has also been found to support and enhance the liver’s detoxification process (Murray et al., 2005).\nThe way that piperine enables the increase of bioavailability of nutrients and in this case curcumin, is that it inhibits the rate of metabolism of curcumin by increasing the time it resides in the intestines to increase intestinal absorption, and inhibits some of the enzymes (which are drug detoxifying enzymes) in the intestines that would usually break down and metabolise the curcumin (Ajazuddin, 2014).\nThis process of inhibiting enzymes is beneficial in the case for increasing the bioavailability of curcumin and another compound called EGCG (a polyphenol found in green tea which has been linked to certain health benefits). However, this can also negatively implicate the process in which our body excretes excess drugs through urine, halting the process, leading to elevated levels of the drugs in our system. This excretion of drugs helps to protect us from toxic chemical substances.\nA study found that when participants took a 2g capsule of curcumin alone, it was found at undetectable or very low levels in the serum levels in the blood (Shoba et al., 1998).\nWhen it was accompanied with 20mg of piperine, a higher concentration of serum levels was found from 0.25 to 1-hour post administration, the researchers found an increase in bioavailability of 2000%. It was found that piperine increases the bioavailability of curcumin with no adverse effects (Shoba et al., 1998).\nIt was also found that when curcumin and piperine are administered together, the intestinal absorption rate increased, and stayed significantly longer in the body tissue than when curcumin was administered alone (Suresh and Srinivasan, 2010).\nHow Much Black Pepper Do You Need?\nAlthough there is limited information on how much black pepper is required to aid bioavailability, it is advised that we eat between 1 to 3g of powdered turmeric a day.\n5% of turmeric is composed of curcumin, and 5% (varies between 4.6%-9.7%) of black pepper (by weight) is composed of piperine. Sources state that even just 1/20th of black pepper can increase the bioavailability, and just 20mg of piperine is effective in enhancing bioavailability.\nAddition of Fat\nThe curcumin is also fat-soluble, which means that it needs fat to be dissolved and then absorbed directly into the bloodstream, where it does not need to be metabolised by the liver.\nIn meals where turmeric is used, there is usually a fat and black pepper in the meal, which aids the bioavailability and absorption of the turmeric. This is why in our turmeric latte, we include both black pepper and Lucy Bee Coconut Oil.\nStorage and Use of Pepper and Turmeric\nTo get the best flavour from your pepper, you should buy whole peppercorns, and grind them up yourself. This means that you will just be receiving peppercorns, and not pepper with other spices, which can happen when you purchase pre-ground pepper.\nYou should store pepper in a cool, dark and dry place. It is also best if you add pepper towards the end of cooking, as the oils in the pepper lose their flavour and aroma if heated for too long.\nYou can get turmeric in powdered form or fresh. When fresh it should be kept in the refrigerator, where it can last for a month. You can also slice it and store it in an airtight container for 3 months.\nIf using powder, you should store it in a tightly sealed container in a cool, dark and dry place, where it will last for up to a year.\nPoints to Note\nIf you suffer with a history of oxalate-containing kidney stones, you should avoid over consuming black pepper as it contains low amounts of oxalates (these prevent the absorption of calcium) (Murray et al., 2005).\nAs black pepper slows down the rate that the liver clears drugs, it is advised not to consume over 1tsp. a day with certain medications – please consult your health advisor if you are considering consuming over 1tsp. a day and on medication including digoxin or phenytoin (Turmeric for Health, 2016).\nUnless advised or discussed with your health professional, there is no need to take turmeric capsules. You can use the powered or fresh turmeric within meals and drinks.\nLong term ingestion of turmeric capsules may lead to nausea, diarrhoea, stomach ulcers, and other problems.\nResearch has shown that turmeric may slow blood clotting, so if you’re taking medication for blood thinning you should talk to your health advisor as well, before considering taking turmeric supplements.\nIt is also recommended that pregnant women do not take turmeric supplements as it can stimulate the uterus which can cause menstrual flow, but is safe to use when seasoning foods.\nBoth turmeric and black pepper have been used in Ayurvedic medicine. Black pepper is indigenous to Kerala, and in Ayurvedic medicine it was known as an important healing spice. It was combined with long pepper and ginger, forming a herbal blend called trikatu, an important ingredient in Ayurvedic formulas.\nBlack pepper was highly prized within trading and expensive to buy – it was even found stuffed in Ramessess II nostrils as part of the mummification process.\nIn Ayurvedic medicine, turmeric was believed to balance the three doshas, and was taken both internally and externally to help with a variety of ailments (Gallant, 2016).\nTurmeric has an abundance of beneficial health effects that you can research and read up on, especially with more research being conducted on just how powerful it is.\nJust be warned when it gets onto your hands it can stain them yellow!!\nI even put it on my fried egg (cooked in Lucy Bee Coconut Oil) in the morning, with some black pepper, delicious!\nAjazuddin. Alexander, A. Qureshi, A. Kumari, L. Vaishnav, P. Sharma, M. Saraf, S. and Saraf, S. (2014). Role of herbal bioactives as a potential bioavailability enhancer for active pharmaceutical ingredients. Fitoterapia, 97, pp. 1-14.\nChuengsamarn, S. Rattanamongkolgul, S. Phonrat, B. Tungtrongchitr, R. and Jirawatnotai, S. (2014). Reduction of atherogenic risk in patients with type 2 diabetes by curcuminoid extract: a randomized controlled trial. The Journal of Nutritional Biochemistry, 25(2), pp. 144-150.\nGallant, L. (2016). Turmeric: “The Golden Goddess”. California College of Ayurveda, available: http://www.ayurvedacollege.com/articles/students/turmeric#Turmeric_and_Ayurveda\nMurray, M. T. Pizzorno, J. E. and Pizzorno, L. (2005). Black Peppercorn, Turmeric. The Encyclopaedia of Healing Foods, pp. 502-523.\nShoba, G, Joy, D. Joseph, T. Majeed, M. Rajendran, R. and Srinivas, P. S. (1998). Influence of piperine on the pharmacokinetics of curcumin in animals and human volunteers. Planta Medica, 64(4), pp. 353-356.\nSuresh, D. and Srinivasan, K. (2010). Tissue distribution & elimination of capsaicin, piperine & curcumin following oral intake in rats. Indian J Med Res, 131 pp. 682–691\nTurmeric for health, http://www.turmericforhealth.com/turmeric-benefits/health-benefits-of-black-pepper-and-turmeric\nAbout Lucy Bee Limited\nLucy Bee is concerned with Fair Trade, ethical and sustainable living, recycling and eating close to nature with additive free products for health.\nMembers of the Lucy Bee team are not medically trained and can only offer their best advice. Any information provided by us is not intended to diagnose, treat, cure or prevent disease.\nPlease note you should always refer your health queries to a qualified medical practitioner."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:8dde1f7c-60e8-418a-8bb3-f12b226b2076>","<urn:uuid:b3c39000-c101-4668-b81b-a6b3e1222765>"],"error":null}
{"question":"Could you explain how Orthodox icons differ from Western religious art in terms of artistic style and spiritual purpose? For example, what techniques they use for faces and colors?","answer":"Orthodox icons differ fundamentally from Western religious art in both style and purpose. In terms of style, Orthodox icons use symbolic rather than realistic representation - faces are always turned frontally toward the viewer with large, burning eyes that engage directly with the observer. They use metaphorical colors rather than natural ones - deep red and purple symbolize Christ's blood, blue represents heaven, and white suggests purity. Regarding spiritual purpose, while Western art aims to tell stories and evoke sentiment through realistic depiction, Orthodox icons serve as conduits for prayer and worship. They are not meant to be aesthetic achievements or realistic narratives, but rather gateways to contemplation that 'bear down' upon the viewer. The icon does the asking, forcing the viewer to be 'seen' and 'read' by it rather than the other way around.","context":["Article by Tom Sutcliffe\nIcons have never been part of our culture in the west, the way they are in the Orthodox Christian east. But now the word has come home to roost here too. Thanks to Apple Mac and Microsoft Windows, the idea of icons as the gateway to convenience and (without our understanding exactly how) practical operation is well established in all our minds. Icons do something for us. The mouse arrow goes to the icon and click, we’re there. Getting what we wanted. Icons on our computer desktops open the door to a paradise of processing. Icons in Orthodox churches, sometimes carried in processions, always revered, are not quite so instantaneous in the way they answer in response to prayer. As artefacts they are by no means all of them great aesthetic achievements. From those devoted to them, they invite a passive submission.\nAll art can be regarded as functional. The icons of Orthodox Christianity work in a very different way on the imagination of those staring wonderingly at them from the masterpieces of painting which we in the west admire – sometimes to idolatrous distraction. What icons supply is not readily what they show on the surface, except they are always full-face with burning, open in an important sense unrevealing, even inexpressive, eyes. They both require and prompt the religious person’s contemplation as they evoke a sacred universe. They are certainly not there to tell a story overtly. But they have a story, they are a story – and for each Orthodox Christian who looks at them, drawing on their power, they can come to stand for a personal story. Icons do look back at those regarding them, but not in the way that the person being portrayed or represented in a western painting may. Icons engage with the viewer in a far more searching way than humane Western painting does, for they are not trying to be an expressive gripping narrative. Orthodox icons are certainly not performing a camera-like service to those minutely examining them. They, the icons, are doing the asking, icons never show faces in profile, because if they did they couldn’t look us, the viewers, the audience, in the eye. They in a sense command the stage: we, watching and looking, are the audience.\nThe word icon immediately brings to mind the issue of iconoclasm. It may be remembered that the iconoclasts, who for more than a century ran Byzantium, rejected the veneration of icons because it risked idolatry. Better, they considered, to destroy all the icons in the world than to be led astray from the right path to understanding religion and God by a misplaced revering of mere objects that could readily be considered to be precisely the graven images condemned in the Ten Commandments. Luckily good sense prevailed. The danger was more of a fantasy. Icons are no more than images meant to lead to certain ideas. What they can show is more real and true than what they artistically are, because they are just a gateway. Interesting that the theatre should have generated its own iconoclasts in England during the Commonwealth when the puritans were in charge, and for very similar reasons. Like icons, the theatre could command – and certainly exercised – power.\nThe fact that icons are not engaged in the descriptive or realistic narrative process that dominates most western art brings them tellingly close, I think to be the issue of theatrical realism. Icons are not meant to be representative. As Rowan Williams, the Archbishop of Wales, says in his recent book Lost Icons, they are not empirical data to be read. They do not show us how God or heaven look. In fact, God or heaven don’t really look ‘like’ anything. (One thing about which everybody agrees is the biblical line” No man hath seen God”). But this is precisely what fills our galleries. When we go to the opera, we are not being told about something else – some other history of which the opera is just one treatment. If we think of opera or theatre or ballet or music like that, we will certainly be missing the point. The performing arts are not means of communication; they are the message not the medium. The truth they show is a truth that we discover within ourselves as a result of engaging our imaginations properly and organically with what we are witnessing on stage.\nOne inadvertent consequence of mechanical reproduction on CD, video DVD and film is that the performance (which is meant to have no more than the status of an icon) can very easily become itself the subject of worship. Enormous promotion and public related campaigns are devoted to persuading us all that certain artists and certain performances have almost divine significance, are virtually definitive. Yet a recording is, however you regard it, a shadow of the real thing – though it may be fabulously detailed, handy as hell, and often fascinating in the information it gives us. One should not, however, get stuck admiring if not worshipping something one can play over and over again. That sort of obsessive appreciation and in respect ought to generate a suitably iconoclastic response.\nWhy do we like going to the same operas over and over again? The answer surely is that the operas we like have become sort of icons for us, performing icons. We don’t go to see and hear them because we need to learn their basic stories again. What we are doing is refreshing our idea of that opera. And that way of enjoying repeated performance of familiar operatic works is very similar to the repainting of icons in the Greek and Russian traditions. Every great icon that is recognised as works of magnificent art are over –painted and repainted from time to time – and this process of refreshment of their colour and richness as objects enhances their spiritual value without destroying their aesthetic power – through the power they wield (unlike most, more or less, representation Western art) is not primarily aesthetic.\nOf course, this isn’t the kind of iconic status conceded (by the media at least) to performances and performing artists. I am not using the word icon as the papers do when they call Madonna or the late Princess Diana an icon. Stars certainly can become icons, in a sense that invites iconoclasm – as part of the depressing media-round of hyperbole – followed-by-defacement. Operas, plays, ballets and concert and church music are designed for repeated performances. The works remain what they are – however often we may see them. Performance is devoted to bringing out and honouring the essence of a work, that which repays attention and invites or commands our total engagement and often devotion. That devotion is matched when an icon is repainted. Repainting is done with the same spiritual commitment that the original creation of the icon involved. The essence is felt to have been enhanced by the careful re-colouring. This is very different from the cleaning and stripping down that does on in our great international museums – sometimes so controversially. Repainting an icon is an act of love and veneration, not the pursuit of an “original” artistic inspiration which has been overlaid by time and possibly neglect. Restoration as we in the west understand it often claims to be a return to the artists first thought, the initial birth of the art-work. That first creation is seen as the heroically perfect eternal statement. By contrast Orthodox icons are living artefacts. They share experience of people’s lives – at least in the Orthodox imagination. They are regarded as alive in the world in a real and very important sense.\nBut there’s another aspect of icons that relates to performance: the otherness and objectivity that keeps us in the audience apart from and outside what we are observing, though invited to look deep into its eyes and receive food for the soul. This separate theatrical or musical life is a sustenance that would come to us no other way. Its otherness is crucial. Performing arts invite us into dialogue with them, with their physicality and reality. But they are not part of our life. We are absolutely separate from them as they happen. That is vital. We are the audience, and they are the performance – and though we may like to play with the conventions involved in this distinction, we need to respect it.\nArchbishop Rowan Williams, one of the most charismatic theologians in the Church, was Lady Margaret Professor of Divinity at Christ Church, Oxford before he moved back to his native Wales as Bishop of Monmouth. His poetry helped prompt the writing of James MacMillan’s new opera Parthenogenesis (to be performed at this summer’s Edinburgh Festival).He could well be describing the proper way of approaching our role as an audience when talks about Orthodox icons towards the end of his book. “The person looking at the icon,“ he writes, “is invited (instructed?) to let go of being an agent observing a motionless phenomenon: the idiom of the painting insists on its own activity, its ‘bearing down’ upon the beholder, shedding rather than receiving light, gathering and directing its energy rather than spreading from an invisible point of convergence. And this finds its fullest expression in the iconographer’s depiction of the eyes of Christ or the saints… the eye of the iconic figure acts, searches, engages. The skill of looking at icons, the discipline of ‘reading’ them, is indeed the strange skill of letting yourself be seen, be read. “That seems to me a perfect description of how we are meant to lend ourselves to the performance, to be engaged by it, changed by it, forced to relate ourselves to it without in any way altering what it objectively is. We are the ones who change because of the performance. That is the sublime power of live performance.\nWilliams goes on “the religious icon is the evocation of the non-existent ‘Other’ simply by its subversion of what we might expect in a devotional artefact… the icon is always a wall that confronts (at the same time as being a rather peculiar kind of window), that can’t be seen from the back, and so does not occupy a space alongside me, does not share the dimension I inhabit.” Here at Holland Park, as in any theatre or opera-house, and regardless of the intrusive cries of the peacocks in the grounds, we lend ourselves totally to the attention that performance requires, which works – in opera – on so many different levels. This is one very good reason why opera is so much less engaging (in fact not really like opera at all) on television or DVD. Opera really does have to be a live encounter with that wide variety of elements, not a channelled record of something that happened somewhere else once upon a time, selected and narrowed down by a microphone and an editor. The separation between our everyday world and what we are witnessing is crucial. We in the audience are subject to ‘virtual’ experience as representation of life, which speaks directly to us but is never a realist copy of something other than what it is. When people say that the music and singing are the most important thing in opera they are simply confirming what we all know – that opera isn’t a way of reproducing everyday life. Rather, it is an inspirational provocation to feel and think spiritually and subconsciously about many different aspects of the narrative which is forming it and to which it is providing a simultaneous intriguing gloss.\nIn the west there seems never to have been such an anxiety about representation as in the Orthodox east. We have never been concerned overmuch about the threat of graven images and incipient polytheism. Making stories come alive – the engine of the theatre and of opera – was always more welcome in Italy, France, Germany and England. From well before the full flowering of the renaissance (which led directly to the humanistic age of Shakespeare and opera) our overt desire in the west has long been to describe fully, to tell the whole story, to encourage a flood of sentiment as we see and relish yet another highly personal artistic depiction. And we know and care a great deal about the creative heroes of our world, the painters, the poets, the musicians, who have been able to bring their genius to making whole worlds beyond worlds cone alive for us with the strokes of their brushes and refinement of their colouring, the flexibility of their language, or the beauty of their melodies.\nOf course works being performed are not the only icons in the performing arts, interpreters – conductors, pianists, violinists, sopranos, tenors – may also themselves become icons in a sense possessing some kind of inner power to make us examine ourselves in the context of their challenging and enlightening artistry. We often delude ourselves that we understand and can therefore love the stars we admire – but a lot of their expressiveness depends on their remaining aloof. Stars are icons because they are in a different world, on a different level. We build up our personal idea of an opera or song or play – and every time we see it done by somebody new that adds further layers to our own inner icon in our personal memory bank of what that work, that phenomenon is for us. That’s why performance is such an individual taste. It also why sometimes what people see won’t fit with the icon in their memory, so they say ‘That’s not The Ring’, ‘That’s not Carmen’ because what they have in their memory, their personal icon of the work in question, cannot accept that kind of over-painting. What they are seeing won’t fit with what’s stored in their brains. Pianists, singers, and actors in classics face the problem, that their living representation of the work they are performing has inevitably to compete with the work in the audience’s memory – if the audience have such memories. But performers themselves do become icons in their own rite, as we get to love their individual qualities, their voice, their face, their way of behaving. We plaster our memories with all of this – because we understand that performance demands our full commitment, if it’s worthwhile. We put that sense of value to the test each time we try a performance. We have our memories filled with what often becomes for us in the audience much more real and distinctive than our everyday activities.\nOur icons are always very personal, and our way of responding to performance cannot be anything else. But that’s because the relationship between an audience and a live performance is organic and totally subjective. Critics have to try and balance out the subjectivity with experience and sympathy. But the sense that the performance is designed for each one of us and focussed on our attention is not just communal activity but the charismatic extravagance that we count on in the theatre. We do not significantly affect the performance. Our attitude is always that we are the recipient. But the power of the relationship, as with icons, is that we feel challenged by what we experience. It is we who will change, not they on stage. Mozart and Wagner look deep into our souls as we listen yet again to the profound and provocative soul-searching in which they have engaged as composers. Operatic music dramatizes that whole process and provides us in the audience with exactly the kind of enlightenment and elevation that the Orthodox Christian obtains from the timeless contemplation of an icon.\nTom Sutcliffe is opera critic of the London Evening Standard. He edited The Faber Book of Opera (£20), and his book on the theatrical interpretation of opera, Believing in Opera (Faber £14.99), is available in paperback.","The Icon of the Eastern Orthodox Church – Research Paper\nObjectively speaking, an icon is a two-dimensional work of art found in the Eastern Orthodox religion, often portraying religious figures such as Jesus Christ, the Virgin Mary, and various saints. Obviously, icons (sometimes spelled ikons) are revered in this tradition, but their precise significance is often hard to understand.\nThe very concept of religious images is, in fact, a broad area of concern, one that did not begin even with Christianity (Gerhard 8).\nHowever, the case within this specific tradition is a very unique one. In Eastern Orthodoxy, icons are religious works of art, which, although possessing a long history and complexity of manufacture, are centrally concerned with portraying a symbolic message and serving as a tool of worship rather than exhibiting any aesthetic value.\nThe origin of religious concern for representative images does not lie with the Eastern Orthodox faith, nor did it begin with Christianity at all. The Mosaic law of Judaism contained a tenet which read, “Thou shalt not make unto thee any graven image, or any likeness of any thing that is in heaven above, or that is in the earth beneath, or that is in the water under the earth” (Exodus 20:4). Although the English translation appears quite clear, in ancient Judaism, this commandment was a constant subject of argumentation, as many interpreted the word “image” as closer to “idol” than any literal image (9).\nThe developing Christian world, however, was nurtured in a land influenced by more than Jewish tradition. The Greek attitude toward images and even image worship was quite favorable. Paintings and statues of their mythical gods and heroes covered classical Greece, while even Rome adopted the Greek imagery into the culture of its own people (12). In addition, the Syrian civilization introduced to the Mediterranean world its own artistic style of frontal poses and large facial features (Cavarnos 14). Israel, the birthplace and location of the ministry of Jesus, was the cradle of Christianity and was centrally Jewish, which usually rejected images unconditionally. However, Christianity was quickly becoming an expanding church, and its increasing acceptance forced Christians throughout the Old World to evaluate their stand on representative images (Gerhard 14).\nAmong the Orthodox tradition, there exists a legend of the first icon, which began with Christ. John Stuart explains:\nTradition has it that Abgar, King of Edessa, who was afflicted with leprosy, heard tell that Christ could restore him to health. He accordingly sent one Ananias as an ambassador to Palestine with instructions to find Our Lord and return with him to Edessa. When Ananias finally caught up with him, Christ was addressing a great throng of people. Being unable to approach nearer, Ananias began to sketch the face of Christ, although needless to say, with very little success. But Christ was aware of what Ananias was doing. When he had dismissed the crowds, he took a piece of linen; soaking it in water, he pressed it firmly to his face and then handed it to Ananias. When the latter had taken the towel into his hands, he saw that Christ’s features were clearly imprinted upon it.\nChrist declined to go to Edessa but promised to send a disciple after his death. And Edessa was to become, in fact, the first Christian state. Meanwhile, Ananias was instructed to take the towel to King Abgar, as a substitute for Christ’s presence. (31)\nEventually, with the increasing influx of complete Mediterranean culture in the Christian world, images gained greater acceptance. In the Byzantine area (the region around Constantinople named for the old name of the city, Byzantium), the Christian imagery was mostly affected by the Hellenistic (Greek and Roman) and Syrian culture (Cavarnos 14).\nThe central Hellenistic influence in Christian iconography was the art of mosaics. Early Christians used this technique to decorate the walls, floors, domes, etc of their churches. Syrian art effectively gave rise to the use of frescoes in Christian churches. The third type of icon—the panel icon—is the most widely used in Russia and most other regions of the Orthodox faith. It consists of a picture painted on a chalk-covered wooden panel treated with an egg solution, or tempera (17).\nThe actual process of creating a panel icon is very complex. First, the icon-maker must go search for the correct type of wood. Cypress was used in Greece; birch and oak were often sought after in Russia, as well as was a good, sturdy pine from Siberia (Gerhard 208). After carving the panel into the correct size and shape with an axe or two-handed plane, it is stored away to remove its moisture. This process normally takes five or six years. After this period, gesso, or chalk, is ground onto its surface to prepare the panel for the next step. This step involves the draughtsman, who sketches the basic outline of the picture in charcoal. When this is completed, he removes the charcoal and paints the outline in a black-colored paint. After the fundamental outline of the image is complete, the surface is gilded with an egg-paste mixture to prepare it for the actual pigmented paint (Stuart 42).\nOn the icon, the first sections painted are the background (such as buildings and nature) and the clothing of the subjects involved. Normally, gold ornamentation follows, which involves painting on sticky resin followed by the application of light gold sheets, after which the sheets are polished. Next, the icon-painter begins painting the subjects’ faces. These comprise the most precise skill on the part of the painter, who must endow the faces with the very spirit and life force of the subject in the picture. A layer of varnish, normally comprised of linseed or olive oil is applied. Finally, it is transported to a church for a blessing (Gerhard 210). The icon is then complete.\nThe Byzantine art style is fundamentally different from the classic western style of realistic sketches and Renaissance-type paintings. The icon painter, as a member of this Byzantine tradition, approaches art with symbols in mind, rather than a realistic concept of some natural object (Stuart 25). Much like a Chinese calligrapher wanting to depict a tree in a work of writing composes a specific character meaning “tree,” rather than drawing any actual tree that he may see or conceptualize, the icon painter creates specific symbolic paintings that illustrate the various religious ideas wishing to be expressed.\nTruly, iconography is more concerned with symbolism than physical appearances. The object of an icon is to capture the spirit and meaning of what the image is trying to portray. Constantine Cavarnos maintains that “True iconography is intended to take us beyond anatomy and the three-dimensional world of matter to a realm that is immaterial, spaceless, timeless—the realm of the spirit, of eternity. And hence the forms and colors are not those that one customarily observes around him, but have something unworldly about them” (38). Indeed, these metaphors elicit associations and can give an extended message than what is possible in a work concerned with physical beauty and perspective exactness.\nIt is of importance to note that the colors used in an icon are metaphorical rather than actual; icon colors often do not follow the color patterns in nature. Rather than making sure all the colors are in harmony with natural appearance, the icon painter will seek a harmony with the spiritual message in his art. Colors are very important for this harmony; each color symbolizes an aspect of the icon and gives a special meaning. For instance, deep red and royal purple are symbolic of the blood of Christ and are often used for the shoes of royal figures. Blue represents heaven and the ethereal. The greens and browns are usually used in familiar manners, representing the earth and vegetation—a reminder of our existence on this earth. From scarlet red comes vigor and vitality, a color used for the blood of martyrs and the cloak of St. George. Orange-red symbolizes the purification of the spirit. White suggests purity and colors the garments of Christ and his angels (28).\nTo give a specific example of the abstract nature of icon art, the faces of the characters depicted always are turned facing the viewer—the person giving their respects and their prayers. This rule holds true regardless of the character’s perspective position in their environment (Upensky 60). In fact, not only are the heads facing the viewer, the important figures in the image have their entire body turned outward in this manner. The rest, the less important, are normally subject to the laws of three-dimensional perspectives. Additionally, where those significant figures are generally depicted as stationary, the rest are again interacting with their environment and are often moving (65).\nSuperceding the hassle over the concern of the icon complying with the “hows” of natural laws and perspectives is the concern of why the natural laws work. This question of “why?” has always been a consideration for Byzantine religious artists. They do not comply with the classic paintings—those that depict photographically accurate settings; again, icons portray the religious nature and symbolism of their scenes (Stuart 36). A naturalistic painting may show Saint Peter as tall and powerful, completely in perspective with his environment, but an icon will depict him in an unrealistic-looking but completely symbolic and explanatory setting.\nIcons may be placed in any location, such as a home or shop, but the central location where they are situated is, of course, the church. When one enters an Orthodox church, immediately noticeable is the iconostasis—a giant screen, composed of wood or marble, that supports the panel icons. On top of the iconostasis is a large cross with the figure of the crucified Christ. In Eastern Orthodoxy, there is great significance given to the Virgin Mary and John the Baptist, whose icons are placed on the iconostasis to the right and left of Christ (Cavarnos 23). In most church buildings, icons cover most of the interior. As mentioned before, each icon portrays a religious message. When all the icons are displayed, the composite of the images inside the church gives the building an entirely new symbolism. The church is, in effect, a microcosm for the universe, where the iconographic messages reveal the universal plan of eternal salvation (Stuart 38).\nDuring church services, the icons are ritually given respect. The deacon of the church wields a censer and directs it toward the icons. This indicates to the congregation that they are to contemplate the icons and understand that the saints painted on the icons are participating in the service in a similar manner as the worshippers themselves (33).\nIcons in the Eastern Orthodox tradition serve several primary purposes. Most apparent to outsiders is their aesthetic value. They embellish and amplify the beauty of a church. Secondly, they instruct their faithful members in matters of doctrine, many times employing symbols that effectively surpass written doctrine (Cavarnos 30). Icons also remind these members of their faith. Their powerful message serves to remind and awaken the faith of the members of the church. In almost every instance, a saint or holy figure is portrayed on the icon. This serves to set an example for the members of the Eastern Orthodox faith. The righteous individual on the icon gives them a model with which to pattern their lives. This person on the image causes the member to be stirred up in faith and righteous zeal (32).\nSurpassing all other purposes, the icon is a conduit for prayer and worship (Stuart 29). Each member of the congregation is allowed to light a candle, come to an icon, and make the sign of the cross. They then will reverence the icon with a kiss and say a prayer (Ugolnik 45). The Eastern Orthodox Church makes it very clear, however, that its members are not worshipping the icon, but giving it “honorable reverence.” Worship is due only to God, and the icon is a medium through which that worship may be expressed (Cavarnos 33).\nThis worship is the ultimate fulfillment of Byzantine iconography. Even with its extensive history and stunning methods of artistry, the sacredness of the icon surpasses all aesthetic and external value. The symbolism of the holy icon is truly the center of Eastern Orthodox worship. It allows its members to transcend their visible physical reality and enter into the ultimate reality, where spiritual truth is juxtaposed with material truth (Stuart 39). It allows one to comprehend the mutual dependence of matter and spirit and truly gives a perspective of far greater significance than the visible temporal universe that one is commonly allowed.\nCavarnos, Constantine. Orthodox Iconography. Belmont, Massachusetts: The Institute for Byzantine and Modern Greek Science, 1977.\nGerhard, H.P. The World of Icons. New York: Harper and Row, Publishers, 1971.\nStuart, John. Ikons. London: Faber and Faber, 1975.\nUgolnok, Anthony. The Illuminating Icon. Grand Rapids, Michigan: William B. Eerdmans Publishing Company, 1989.\nUpensky, Boris. The Semiotics of the Russian Icon. Lisse: The Peter DeRidder Press, 1976."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:704113cb-20da-49b9-8636-cd4db90747be>","<urn:uuid:6970be19-af48-4ce8-9569-812e5f2bc72b>"],"error":null}
{"question":"How did McLeod's Brandywine mine demonstrate success in gold mining, and what environmental impacts typically result from such mining operations?","answer":"The Brandywine mine was highly successful, producing over $70 million worth of gold, silver, lead and zinc over seven years. However, mining operations generally cause significant environmental impacts, including erosion, loss of biodiversity, contamination of soil and water, deforestation for debris storage, and the creation of large holes that damage natural landscape beauty. The extraction process can also threaten wildlife populations and risk turning areas into lifeless wastelands.","context":["View by Year Inducted or by Surname:\n|A - C||D - F||G - I|\n|J - L||M - O||P - R|\n|S - U||V - Z|\nDonald McLeod is a revered and iconic figure in Canada’s mining industry and an inspirational role model for young mining entrepreneurs. Born and raised in Stewart, BC, he began his career as a pack-horse operator and miner’s helper in the 1940s, and went on to become a successful mine finder, developer, and founder of the Vancouver-based Northair Group of Companies. He is best known for developing the Brandywine and Summit gold mines in BC, and for making high-grade gold discoveries at the Brucejack project later acquired by Pretivm Resources. He also mentored and encouraged countless people to pursue opportunities in the mining industry, including his daughter Catherine and son Bruce, who both achieved success in their own rights.\nMcLeod’s life journey was shaped his Scottish roots and the mining heritage of his home town. Starting as a teen-ager, McLeod learned almost every aspect of the business as he rose through the ranks at various mines. After managing the discovery of a rich lead-zinc deposit at Pine Point, NWT, he was inspired to move his young family to Vancouver and start his own mining company. In 1972, as president of Northair Mines, he optioned a grassroots discovery near Whistler, BC, and brought it into production 42 months later. It was an astounding feat, accomplished in a politically challenging era through stubborn persistence and his famously infectious optimism. Over the next seven years, the Brandywine mine profitably produced more than $70 million worth of gold, silver, lead and zinc. McLeod also developed the Summit gold mine and raised more than $200 million of equity for his Northair Group of Companies before retiring in 2014. In the 1980s, one of his companies, Newhawk Gold Mines, discovered high-grade gold deposits at the Brucejack project in the famous “Golden Triangle” north of Stewart. Brucejack was ultimately acquired by Pretivm Resources, which went on to discover the 6.9-million-ounce Valley of the Kings gold deposit slated for commercial production in 2017.\nMcLeod exemplifies the qualities that have made Canada a leader in the global mining industry. His willingness to take on projects in difficult terrains and climates — often under challenging political or market conditions — is a testament of his tenacity and pioneering “can-do” spirit. He demonstrated integrity and professionalism throughout his 70 years in mining and earned the trust of his peers, employees and shareholders. He was intimately familiar with every aspect of the industry from the bush to the boardroom and these experiences gave him the credibility and the sensitivity to encourage others to follow their dreams in the “equal opportunity” mining industry. He was an inspirational role model and mentor for many young people, including his daughter and son, who went to become successful industry leaders.\nMcLeod has generously supported health and education causes, including the Mining for Miracles campaign, and St. Paul’s Hospital Foundation through the creation of the McLeod Family Professorship in Valvular Heart Disease Intervention. In addition to being named a “Mining Living Legend” by Cambridge House, McLeod was the recipient of AME BC’s E.A. Scholz Award for excellence in mine development, and the CIM’s Proficiency Award.","Mining has several bad effects. It leaves behind a huge hole after mining is done. Secondly it damages natural beauty. A beautiful landscape which once existed is now a huge piece of dug up earth.\nEnvironmental Effects. Environmental issues can include erosion, formation of sinkholes, loss of biodiversity, and contamination of soil, groundwater and surface water by chemicals from mining processes. In some cases, additional forest logging is done in the vicinity of mines to create space for the storage of the created debris and soil.\nThe effects of mining in Africa have left large-scale devastation when companies do not honour their responsibility. Because mining areas are left in an unsustainable condition, plant species and wildlife are threatened and these areas are at risk of becoming lifeless wastelands.\nThe Impact and Effect of Illegal Mining (galamsey) towards the Socio-economic Development of Mining Communities: A Case Study of Kenyasi in the Brong Ahafo Region Adjei Samuel1, N.K.Oladejo1, I.A. Adetunde2, * 1University for Development Studies, Department of Mathematics, Navrongo. Ghana.\nSome of the major effects of mining on the environment are as follows: Minerals are the natural resources which play an important role in the economic development of the country. But the extraction and mining of these natural resources leads to some adverse effect on our environment as well.\nMar 09, 2017· The mining industry has the potential to disrupt ecosystems and wipe out wildlife populations in several different ways. Here's how mining affects the environment and wildlife. Habitat Loss; Mining can lead to the destruction of habitats in surrounding areas. The …\nModern mining is an industry that involves the exploration for and removal of minerals from the earth, economically and with minimum damage to the environment. Mining is important because minerals are major sources of energy as well as materials such as fertilizers and steel.\nApr 25, 2017· Mining is the extraction of minerals and other geological materials of economic value from deposits on the earth. Mining has the potential to have severely adverse effects on the environment including loss of biodiversity, erosion, contamination of surface water, ground water, and soil.\nSome gold can be found by panning in rivers; heavy gold will remain in the pan, whereas lighter rocks and minerals float out. This small-scale form of gold mining has little effect on the body of water, but the large-scale practice of mining gold from ore can have tremendous negative effects on water quality.\nMining can effect the earth because first, deforestation, and because mining requires large portions of land to be removed before they can start mining, lots of trees and plants are removed.\n1.1 PHASES OF A MINING PROJECT There are different phases of a mining project, beginning with mineral ore exploration and ending with the post-closure period. What follows are the typical phases of a proposed mining project. Each phase of mining is associated with different sets of environmental impacts. 1.1.1 Exploration\nFeb 07, 2018· The effects in such cases can be devastating for the environment. Be it due to ignorance of the regulations or just a freak accident, incidents like the Guyana spill of 1995 may occur again. This highlights the fact that issues like mining's effect on the environment are worth some serious deliberation.\nAug 26, 2010· Dust, radon and mercury impact miners' health. Dust, radon and mercury impact miners' health. ... Miners Face Health Risks, Even on Good Days ... mining …\nThe effects of mining coal on the environment. There are 2 ways to mine coal – Strip Mining and Underground Mining – both ways have their own impact to the environment and health. We know it but coal is such a cheap energy source that we don't want to let go of it. The negative effects of coal mining cannot be disputed:\nApr 21, 2019· The human health effects due to cyanide leach gold mining are not well documented, and this is no exception in Montana. The State of Montana has done no formal studies to specifically study mine-related health effects. Pegasus, the last mining company at Zortman-Landusky, started to fund a health study with the $1.7 million supplemental money from the 1996 settlement, but because …\nADVERTISEMENTS: Some of the major environmental effects of mining and processing of mineral resources are as follows: 1. Pollution 2. Destruction of Land 3. Subsidence 4. Noise 5. Energy 6. Impact on the Biological Environment 7. Long-term Supplies of Mineral Resources. Mining and processing of mineral resources normally have a considerable impact on land, water, […]\npositive and negative effects of mining on the environment. Mankind has been mining for precious metals since 42000 years ago and that's a staggeringly long time ago and that's exactly how long our species has been digging into the ground, to harvest its precious metals.\nDownload Coal Mining sounds ... 76 stock sound clips starting at $2. Download and buy high quality Coal Mining sound effects. BROWSE NOW >>>\nMining affects the environment by exposing radioactive elements, removing topsoil, increasing the risk of contamination of nearby ground and surface water sources, and acidification of …\nApr 20, 2015· Effects of Mining. Coal mining, the first step in the dirty lifecycle of coal, causes deforestation and releases toxic amounts of minerals and heavy metals into the soil and water. The effects of mining coal persists for years after coal is removed.\nJul 25, 2018· Environmental impacts from fossil fuel pollution are rapidly increasing in regions that have the highest concentrations of fuels. There are multiple effects of mining fossil fuels. Drilling and mining practices take a substantial toll on local water sources, biologic life and natural resources.\nPublished by the American Geosciences Institute Environmental Awareness Series. ... How can metal mining impact the environment? PDF version. Material adapted from: Hudson, T.L, Fox, F.D., and Plumlee, G.S. 1999. Metal Mining and the Environment, p. 7,20-27,31-35,38-39. Published by the American Geosciences Institute Environmental Awareness Series.\nMining operations usually create a negative environmental impact, both during the mining activity and after the mine has closed. Hence, most of the world's nations have passed regulations to decrease the impact. Work safety has long been a concern as well, and …\nEffects of mining on aquatic resources are both physical and chemical in nature. Most of earthmoving activities of mining occurred well before the enactment of laws designed to protect aquatic resources - particularly the 1977 Federal Water Pollution Control Act.\nThe former is known as underground mining, the latter as strip mining or mountaintop removal. Either process contributes a high level of damage to the environment: #12 Noise pollution. One of the most obvious (albeit perhaps least harmful) environmental effects of coal mining is noise pollution.\nMining has an adverse effect on soil quality. Soil degradation is the prime impact. Another impact is deforestation and loss of fauna and flora.\nThe impact of mining on the environment and the effects of mining techniques need to be more advanced with the utilization of modern equipment to be unintrusive to the environment. Economic growth is high on the agenda of leading countries, sustaining …\nMining is an inherently invasive process that can cause damage to a landscape in an area much larger than the mining site itself. The effects of this damage can continue years after a mine has shut down, including the addition to greenhouse gasses, death of flora and fauna, and erosion of land and habitat.\nNov 14, 2016· After mining is over, the land is left as barren land. The effects of mining sometimes vary depending on what is mined out, but these are some of the general effects you will see in all mine-areas. I'm not an expert when it comes to health impact on miners, but here are some of the things I know will affect them-\nJul 08, 2017· In coal mining, the extraction, crushing, and transport of coal can generate significant amounts of airborne respirable (extremely fine) coal dust. Dust less than 10 microns in size (cannot be seen with the eye). In non-coal mining, stone, and san...\nEnvironmental impacts of mining can occur at local, regional, and global scales through direct and indirect mining practices. Impacts can result in erosion, sinkholes, loss of biodiversity, or the contamination of soil, groundwater, and surface water by the chemicals emitted from mining processes. These processes also have an impact on the atmosphere from the emissions of carbon which have ...\nApr 04, 2017· The Dangerous Effects of Illegal Mining. April 4, 2017 Environmental Issues Written by Greentumble. Illegal mining has been ravaging our planet for. decades. Not only is illegal mining riskier from a safety perspective for those who choose to participate, but it encourages reckless behavior and leads to outcomes that have negative long-term ..."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:751ddb0a-9c46-484e-b2af-1668ddf1542e>","<urn:uuid:11ce18f5-51f7-4dfa-a26b-c4a5796e1622>"],"error":null}
{"question":"What are the early signs of dyslexia, and how does CSLOT's therapy program address these challenges?","answer":"Early signs of dyslexia include late speech development (3 years or later), mixing up sounds in multi-syllable words, inability to rhyme by age 4, difficulty with substitutions and deletions, unusual pencil grip, trouble remembering rote facts, and confusion of left vs. right. CSLOT addresses these challenges through a comprehensive approach combining computer-based home therapy, in-person multi-sensory reading instruction, and speech and language therapy. Their program targets the neurobiological roots of reading disorders using Fast ForWord® for speech sound discrimination, the Slingerland method for multi-sensory education, and specific speech and language therapy for phonemic awareness training. The program requires a minimum three-month commitment and may take up to 2.5 years to achieve grade-level reading skills.","context":["What is Dyslexia?\nDyslexia is a neurological difference often characterized by difficulties with reading, writing and spelling. It may run in the families and cannot be “cured.” Individuals with this condition must learn coping strategies.\nDyslexia has nothing to do with intelligence. With the right instruction, almost all individuals with dyslexia can learn to read. A multi-sensory, phonics based approach is often the best way to help kids learn to read. The Orton-Gillingham, Barton System and/or Lindamood-Bell programs are well known programs that work.\nThis great Ted-Ed talk provides an overview of dyslexia.\nWhat should I look for?\nDecoding Dyslexia offers these early signs of dyslexia:\n- Late speech (3 years or later)\n- Mixing up sounds in multi-syllable words (e.g. bisghetti, aminal, mazageen)\n- Inability to rhyme by age 4\n- Difficulty with substitutions, omissions and deletions\n- Unusual pencil grip\n- Difficulty remembering rote facts (months of the year, days of the week)\n- Confusion of left vs. right\nOne of the biggest challenges of dyslexia is counteracting shame caused by teasing and misunderstanding. Children are often teased because they can’t read as well as others. Teachers may say things like “she’s a slow reader” in front of the child or parents. Kids know what “slow” means and they often grow up believing they are “stupid” and/or “lazy.”\nHeadstrong Nation’s Learn the Facts wants you to know the facts, help your child recognize her/his strengths and weaknesses, learn how to talk about it with trusted friends and family and eventually, be comfortable sharing one’s real self with the world.\nDyslexia Assessment in Multnomah County\nOregon Senate Bills 612 and 1003 require school districts to universally screen for risk factors of dyslexia in kindergarten. The Oregon Department of Education provides guidance and training for districts and educators. If you or your child aren't in school or you feel the school is missing something, here are a few of the many assessment and intervention providers in the County.\nThe Blosser Center - Accredited by the Academy of Orton-Gillingham Practitioners and Educators, the Blosser Center provides assessment, tutoring and teacher training.\nLanguage Skills Therapy - Provides assessment and tutoring\nNew Leaves Clinic - Provides assessment and treatment in Hillsboro, Oregon\nPDX Reading Specialist, LLC - Provides assessment, tutoring, advocacy and professional development\nHow the library can help\nThere are three valid types of reading: with your eyes (print & video), with your ears (audiobooks), and with your fingers (Braille).\nTypically easier for someone with dyslexia, the library has thousands of audiobooks on CD and in downloadable formats for people who read with their ears. Library information staff can help you find and use audiobooks.\nDVD/Blu-ray and streaming\nThe library has thousands of DVDs, Blu-ray and downloadable films for people who read with eyes and ears. Library information staff can help you find and use these media.\nE-books are available to borrow through OverDrive to read on your desktop or with the Libby app. Accessibility options include using screen readers, changing text size, turning on dyslexic font, reading in sepia or night mode, and more. When searching for a subject, you can also look for the format \"OverDrive Read-along\" which provides narration that plays along while you read. The OverDrive help page explains how to find these read-along books and library staff can help as well.\nBookshare e-books have functions for people with print disabilities, including low vision, dyslexia and the inability to hold a physical book. Adults with a library card can get free access through the library. Students can get access through their school.\nThe Oregon Talking Book and Braille Library is free for any Oregonian with a print-disability including dyslexia or dysphasia.\nAdd new comment","CSLOT’s reading therapy program uses a combination of computer-based home therapy, in-person multi-sensory reading instruction, and speech and language therapy to target the neurobiological roots of reading disorders.\nReading disabilities, including dyslexia, are common, affecting 10-15% of the population. Because our world uses the written word to impart education and knowledge, a child with a reading disability often experiences global academic delays and low self-esteem.\nCSLOT’s reading therapy program uses a combination of computer-based home therapy, in-person multi-sensory reading instruction, and speech and language therapy to target the neurobiological roots of dyslexia and other reading disorders. By repeated practice, our program takes advantage of the brain’s inherent plasticity, especially in the auditory processing system.\nAreas Addressed by Reading Therapy\nDyslexia: Difficulty with accurate and/or fluent word recognition and by poor spelling and decoding abilities.\nReading Disability: Challenges with phonological processing, processing speech, and comprehension of written language.\nPhonological Awareness: Problems with the awareness of and the manipulating of small units of language, such as word parts and syllables.\nPhases of Reading Therapy Services\nA personalized therapy program is created for each client based on the results of a comprehensive literacy assessment. The following therapy methodologies are used in part or as a whole, either sequentially or concurrently, depending on the need of each client.\nFast ForWord®, from Scientific Learning, Inc., is a computer-based program that takes your child through a series of age-appropriate, highly motivating computer games, which build the skills necessary for learning to read. Playing the games at home for 8-12 weeks, supported by weekly parent consultations with CSLOT’s Fast ForWord® specialist, your child will learn to discriminate speech sounds, a foundational skill for learning to read.\nFast ForWord Language v2\nThe Language series develops listening accuracy, phonological awareness, and language structures and moves elementary students who are reading below grade level toward grade level reading skills.\nFast ForWord Language to Reading v2\nThe Language to Reading series emphasizes the link between spoken and written language to guide young students to become proficient grade level readers.\nMulti-Sensory Language Education and the Slingerland Method\nStudies show that children with dyslexia need a multi-sensory approach to reading. Multi-sensory education incorporates three learning pathways: auditory (hearing), kinesthetic (touching or movement), and visual (seeing). The Slingerland method systematically appeals to all of these senses to address reading and writing.\nSpeech, Language, and Phonemic Awareness Training\nA speech-language pathologist will support your child’s auditory processing by teaching your child how to play with sounds in words, manipulating and changing them. Additionally, speech therapy will help your child produce speech sounds correctly.\nAlso from Scientific Learning Inc., Reading Assistant™ uses speech recognition software to provide real-time corrective feedback as your child reads out loud. This program “listens” to your child read and supports fluency by providing visual cues. This is a program for use at home once your child has reached minimum reading fluency levels.\nAges for Reading Therapy\nOur reading program is available for children starting at age 3.5 years old and adolescents through age 18.\nHow Therapy Works\nFirst, an evaluation determines the client’s reading level and indicate areas of need. Following the evaluation, our literacy specialist meets with the client (depending on age) and/or parents to discuss the results of the evaluation. Together, a customized plan is created to meet the needs of each individual.\nOnce a plan is established, the therapy process can take many forms. Depending on the needs of the client, some aspects of therapy take place at home using computer-based technology such as Fast ForWord® and Reading Assistant™ while other aspects of therapy happen in our clinic with our literacy specialist and/or a speech-language pathologist.\nHow Long Will it Take?\nOur reading therapy program requires a minimum commitment of three months. During this time, you are likely to see large gains in your child’s reading skills. However, it may take up to 2 1/2 years to get your child up to age and grade level."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:bf7b5887-a854-47a2-9238-c2657d3d1267>","<urn:uuid:b87b5f2b-f5b6-4575-9af1-3f5e9ead394b>"],"error":null}
{"question":"What's the fundamental difference between savikalpa samadhi and nirvikalpa samadhi in their levels of consciousness?","answer":"Savikalpa samadhi represents a lower level of consciousness where the mind is still conscious and the imagination remains active, requiring effort to maintain the state. In contrast, nirvikalpa samadhi represents a higher transcendent state where the senses are inactive and thoughts are totally absent, resulting in an intense and blissful experience of Pure Consciousness. In nirvikalpa, one experiences pure unadulterated bliss, wholeness, and perfection where all things are one - it is considered the highest transcendent state of consciousness and the heights of yoga.","context":["======= Understanding Hinduism =======\nQ & A\nThe teachings of Sri Ramana Maharshi\nEdited by David Godman; Arthur Osborne, Kavyakantha\nMeditation and Concentration\nSri Ramana Maharshi's insistence that awareness of the \"I\" thought was a pre-requisite for Self-realisation led him to the conclusion that all spiritual practices which did not incorporate this feature were indirect and inefficient:\nSri Ramana Maharshi said: This path (attention to the ' I ' ) is the direct path; all others are indirect ways. The first leads to the Self, the others elsewhere. And even if the others do arrive at the Self it is only because they lead at the end to the first path which ultimately carries them to the goal. So, in the end, the aspirants must adopt the first path. Why not do so now? Why waste time?\n[Note: By David Godman: That is to say, other techniques may sometimes bring one to an inner state of stillness in which self-attention or self-awareness inadvertently takes place, but it is a very roundabout way of reaching the Self. Sri Ramana maintained that other techniques could only take one to the place where self-enquiry starts and so he never endorsed them unless he felt that particular questioners were unable or unwilling to adopt self-enquiry.]\nSri Ramana Maharshi said: The goal is the same for the one who meditates [on an object] and the one who practises self-enquiry. One attains stillness through meditation, the other through knowledge. One strives to attain something; the other seeks the one who strives to attain. The former takes a longer time, but in the end attains the Self.\n[Note: Although Sri Ramana vigorously defended his views on self-enquiry he never insisted that anyone change their beliefs or practices and, if he was unable to convince his followers to take up self-enquiry, he would happily give advice on other methods.]\nQuestion by a disciple: There is more pleasure in dhyana\n(concentration) than in sensual enjoyments. Yet the mind runs after the sensual enjoyments\nand does not seek the former.\nSri Ramana Maharshi: Pleasure or pain are aspects of the\nQuestion: It is said that the Self is beyond the mind and yet the realisation is with the mind. The mind cannot think it. It cannot be thought of by the mind and the mind alone can realise it. How are these contradictions to be reconciled?\nSri Ramana Maharshi: Atman (Self) is realised with mrita manas (dead mind), that is, mind devoid of thoughts and turned inward. Then the mind sees its own source and becomes that (the Self). It is not as the subject perceiving an object.\nWhen the room is dark, a lamp is necessary to illumine, and eyes are necessary to recognise objects. But when the sun has risen there is no need of a lamp to see objects. To see the sun no lamp is necessary, it is enough that you turn your eyes towards the self-luminous sun.\nSimilarly with the mind. To see objects the reflected light of the mind is necessary. To see the Heart it is enough that the mind is turned towards it. Then mind loses itself and Heart shines forth.\nThe essence of mind is only awareness or consciousness. When the ego, however, dominates it, it functions as the reasoning, thinking or sensing faculty. The cosmic mind, being not limited by the ego, has nothing separate from itself and is therefore only aware.\nAgain people often ask how the mind is controlled. I say to them, 'Show me the mind and then you will know what to do'. The fact is that the mind is only a bundle of thoughts. How can you extinguish it by the thought of doing so or by a desire? Your thoughts and desires are part and parcel of the mind. The mind is simply fattened by new thoughts rising up. Therefore it is foolish to attempt to kill the mind by means of the mind. The only way of doing it to find its source and hold on to it. The mind will then fade away of its own accord.\nYoga teaches CHITTA VRITTI NIRODHA (control of the activities of the mind). But I say ATMA VICHARA (self-investigation). This is the practical way. Chitta Vritti Nirodha is brought about in sleep, swoon, or by starvation. As soon as the cause is withdrawn there is a recrudescence of thoughts. Of what use is it then? In the state of stupor there is peace and no misery.But misery recurs when the stupor is removed. So Nirodha (control) is useless and cannot be of lasting benefit.\nHow then can the benefit be made lasting? It is by finding the cause of misery. Misery is due to the perception of objects. If they are not there, there will be no contingent thoughts and so misery is wiped off.\n'How will objects cease to be'? is the next question. The sruti (scriptures) and the sages say that the objects are only mental creations. They have no substantive being. Investigate the matter and ascertain the truth of the statement. The result will be the conclusion that the objective world is in the subjective consciousness.The Self is thus the only reality which permeates and also envelopes the world. Since there is no duality, no thoughts will arise to disturb your peace. This is realisation of the Self. The Self is eternal and so also is realisation.\nAbhyasa (spiritual practice) consists in withdrawal within the Self every time you are disturbed by thought. It is not concentration or destruction of the mind but withdrawal into the Self.\"\nQuestion: Why is concentration ineffective?\nSri Ramana Maharshi: To ask the mind to kill the mind is like making the thief the policeman. He will go with you and pretend to catch the thief, but nothing will be gained. So you must turn inward and see from where the mind rises and then it will cease to exist.\nQuestion: In turning the mind inwards, are we not still employing the mind?'\nSri Ramana Maharshi:Of course we are employing the mind. It is well known and admitted that only with the help of the mind can the mind be killed. But instead setting about saying there is a mind, and I want to kill it, you begin to seek the source of the mind, and you find the mind does not exist at all. The mind, turned outwards, results in thoughts and objects. Turned inwards, it becomes itself the Self.\nQuestion: What is samadhi?\nSri Ramana Maharshi: The state in which the unbroken\nWhen the mind is in communion with the Self in darkness, it is called nidra (sleep), that is the immersion of the mind in ignorance. Immersion in a conscious or wakeful state is called samadhi. Samadhi is continuous inherence in the Self in a waking state. Nidra or sleep is also inherence in the Self but in an unconscious state. In SAHAJ SAMADHI the communion is continuous.\nThe immersion of the mind in the Self, but without its destruction, is known as Kevala Nirvikalpa Samadhi. In this state one is not free from vasanas and so one does not therefore attain mukti (liberation). Only after the vasanas have been destroyed can one attain liberation.\"\nQuestion: When can one practice Sahaj Samadhi?\nSri Ramana Maharshi:Even from the beginning. Even though one practises Kevala Nirvikalpa Samadhi for years together, if one has not rooted out the vasanas one will not attain liberation.\nQuestion: Is samadhi, the eighth stage of raja yoga, the same as the samadhi you speak of?\nSri Ramana Maharshi: In yoga the term samadhi refers to some kind of trance and there are various kinds of samadhi. But the samadhi I speak of is different. It is SAHAJ SAMADHI. From here you have samadhan (steadiness) and you remain calm and composed even while you are active. You realise that you are moved by the deeper real Self within. You have no worries, no anxieties, no cares, for you come to realise that there is nothing belonging to you. You know that everything is done by something with which you are in conscious union.\nQuestion:If this sahaj samadhi is the most desirable condition, is there no need for nirvikalpa samadhi?\nSri Ramana Maharshi: The nirvikalpa samadhi of raja yoga may have its use. But in Jnana yoga this sahaj sthiti (natural state) or sahaj nishtha (abidance in the natural state) itself is the nirvikalpa state. In this natural state, the mind is free from doubts. It has no need to swing between alternatives of possibilities and probabilities.It sees no vikalpas (differences) of any kind. It is sure of the truth because it feels the presence of the real. Even when it is active, it knows it is active in the reality, the Self, the Supreme Being.\nQuestion: How can one function in the world in such a state?\nSri Ramana Maharshi: One who accustoms himself naturally to meditation and enjoys the bliss of meditation will not lose his samadhi state whatever external work he does, whatever thoughts may come to him. That is Sahaja Nirvikalpa. Sahaj Nirvikalpa is Nasa Manas (total destruction of the mind). Those who are in the laya samadhi state (a trance like state in which the mind is temporarily in abeyance) will have to bring the mind back under control from time to time. If the mind is destroyed, as it is in sahaj samadhi, it will never slide down from their high state.\nQuestion:Is samadhi a blissful or ecstatic state?\nSri Ramana Maharshi: In samadhi itself there is only perfect peace. Ecstasy comes when the mind revives at the end of samadhi. In devotion the ecstasy comes first. It is manifested by tears of joy, hair standing on end, and vocal stumbling. When the ego finally dies and the Sahaj is won, these symptoms and the ecstasies cease.\nSiddhis (super natural powers)\nQuestion: On realising samadhi, does not one obtain siddhis (super natural powers) also?\nSri Ramana Maharshi: In order to display siddhis, there must be others to recognise them. That means, there is no jnana in the one who displays them. Therefore, siddhis are not worth a thought. Jnana alone is to be aimed at and gained.\nTuriya-the fourth state\nQuestion: Is samadhi the same as Turiya, the fourth state?\nSri Ramana Maharshi: Samadhi, Turiya and nirvikalpa all have the same\nimplication, that is, awareness of the Self. Turiya literally means the fourth\nstate, the Supreme Consciousness, as distinct from the other three states of\nconsciousness: waking, dreaming and dreamless sleep. The fourth state is eternal and\nthe other three states come and go in it. In Turiya there is the awareness that the mind\nhas merged in its source, the Heart, and is quiescent there, although some thoughts\nstill impinge on it and the senses are still somewhat active. In nirvikalpa, the\nsenses are inactive and thoughts are totally absent. Hence the experience of Pure\nConsciousness in this state is intense and blissful. Turiya is obtainable in savikalpa","Samadhi is the 8th and final limb of yoga. Samadhi is a state of concentrated meditation that transcends the intellect, mind, and body and complete detachment from the physical world (meaning consciousness becomes detached from the body). This final stage of yoga is also known as enlightenment and can be achieved in Corpse Pose, after meditation involving Dharana and Dhyana. In this state, the yogi can suspend consciousness away from the body, being at one with the environment and surroundings while not being limited to physical restraints of the body. Samadhi represents a state of enlightenment and over time the yogi obtains a ceaseless state of transcendent bliss.\nIn Buddhism, Samadhi is known as the 8th wheel of the eightfold path referring to right concentration. Buddhists believe that this right concentration leads to extraordinary intelligence and even superpowers. But these are simply distractions for the practitioner from the goal of Moksha, or liberation. Samadhi leads to a pleasantness in your current life, knowledge of the divine third eye by concentration on light, clear comprehension of the fluctuations of feelings, perceptions, and thoughts through mindfulness, and the elimination of the 5 Skandha’s (attachments to matter, sensation, perception, mental habits, and discernment). In Buddhism, Samadhi does not refer to enlightenment, rather a state of concentrated meditation that leads to enlightenment. Nirvana is enlightened freedom from attachment and Samsara through Moksha.\nSamadhi is a state of supreme detachment, where consciousness is free to leave the body and can expand beyond the borders of the physical corpse of the consciousness. It is a supreme state of bliss that is experienced in Savasana, or in meditation after a yoga practice is completed. This is why you don’t skip Savasana! Meditate after your yoga practice, it is far more powerful after the body has been tempered. The sensations and insights that flow during these meditation can alter your perspective and even mental processes that can change. It is integral to the yoga practice to rest in Savasana and meditate; they are the most important things you can do to amplify the healing and regenerative qualities of yoga.\nSamadhi is intricately related to consciousness. It can be described as full awareness, perfect concentration, or an altered state of consciousness characterized by ananda and sukha (bliss and joy). Vyasa, one of the authors of the Mahabharata, said ‘yoga is Samadhi’. It is ultimately complete control over the fluctuations of consciousness including distractions and normal functionality of the nervous system and conscious experience.\nPatanjali said that Samadhi has three different aspects: Savikalpa, Asamprajnata, and Nirvikalpa. In Savikalpa the mind is still conscious and the imagination is active and the state can be described as holding onto the imagination with effort. Asamprajnata is a step forward from Savikalpa and is not quite gross awareness, but is a heightened state of conscious awareness. Nirvikalpa is the highest transcendent state of consciousness, the highest of the heights of yoga. It is an engrossing awareness where all things are one and pure unadulterated bliss, wholeness, and perfection are experienced. It is pure joy, freedom, and steady bliss in the knowledge of awareness.\nSamadhi is like balancing blocks on top of one another, where it takes years to learn all of the nuances of each block and how they work together. Simply allowing the body to meditate is not enough; full concentration and focus is required to obtain the state of pure freedom.\nThe final liberation of the yogi comes at the time of death, known as mahasamadhi and is a controlled exit of the consciousness from the body to merge consciousness with the divine. Maha means great.\nI would like to dedicate this post to BKS Iyengar, who died this morning, one of the greatest (yoga) teachers the world has ever known. My hope is that he found mahasamadhi in his last hours and that he has found the freedom and peace beyond. He brought yoga into the west and gave everyone seemingly limitless knowledge on even the most minuscule and minute details. He gave us in the west the opportunity to scale the heights of Raja yoga and changed the world for the better. Thank you."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:50885791-0510-429f-b5aa-709a98c0dd25>","<urn:uuid:c198a1dd-6ba4-49c6-b875-26176848e6be>"],"error":null}
{"question":"Could you explain the detailed process for freeing Hebrew slaves in ancient times, including the specific rules about their release and provisions?","answer":"Hebrew slaves were to be freed after serving for six years, with their release occurring in the seventh year. When freeing slaves, owners were required to provide them with resources from their flock, grain, and wine, giving as the Lord had blessed them. They couldn't send slaves away empty-handed. However, if a slave declared they wanted to stay due to loving their master and family and having a good life, there was a specific procedure: the owner would pierce the slave's earlobe with an awl through to the door, making them a permanent slave for life. This rule applied to both male and female slaves.","context":["Deuteronomy 15Expanded Bible (EXB)\nThe Special Seventh Year\n15 At the end of every seven years, you must ·tell those who owe you anything that they do not have to pay you back [grant remission of debts; Ex. 23:10–11]. 2 This is ·how you must do it [the manner of remission]: Everyone who has ·loaned money [a claim] must ·cancel [remit] the loan and not make a neighbor or ·relative [or countryman; L brother] pay it back. This is the Lord’s time for ·canceling what people owe [remitting debts]. 3 You may make a foreigner pay what is owed to you, but you must ·not collect [remit] what ·another Israelite [a relative; or a countryman; L a brother] owes you. 4 But there should be no ·poor [needy] people among you, because the Lord your God will richly bless you in the land he is giving you as your ·own [possession]. 5 He will bless you if you obey the Lord your God completely, but you must be careful to obey all the commands I am ·giving [commanding] you today. 6 The Lord your God will bless you as he promised, and you will lend to other nations, but you will not need to borrow from them. You will rule over many nations, but none will rule over you.\n7 If there are ·poor [needy] among ·you [your relatives; or your countrymen; L your brothers], in one of the ·towns [L gates] of the land the Lord your God is giving you, do not be ·selfish [L hard-hearted] or ·greedy [L tight-fisted] toward them [Prov. 28:27; 29:7, 14]. 8 But ·give freely [L open your hand] to them, and freely lend them whatever they need. 9 Beware of ·evil [useless] thoughts. Don’t think, “The seventh year is near, the year ·to cancel what people owe [of remission].” ·You might be mean to [L Your eye might be evil toward] ·the needy [your needy relative/or countryman/L brother] and not give them anything. Then they will ·complain [call out] to the Lord about you, and he will find you guilty of sin. 10 Give freely to the poor person, and do not ·wish that you didn’t have to give [begrudge him this matter]. The Lord your God will bless your work and everything you ·touch [undertake; L send from your hand]. 11 There will always be poor people in the land, so I command you to ·give freely [L open your hand] to your ·neighbors [or relatives; or countrymen; L brothers] and to the poor and needy in your land.\nLetting Slaves Go Free\n12 If one of your own ·people [relatives; L brothers] ·sells himself [or is sold] to you as a slave, whether it is a Hebrew man or woman, that person will serve you for six years [Lev. 25:39; Neh. 5:4–5]. But in the seventh year you must let the slave go free. 13 When you let slaves go, don’t send them away ·without anything [empty-handed]. 14 ·Give them [Provide/Outfit them with] some of your flock, your grain, and your wine, giving to them as the Lord has ·given to [L blessed] you. 15 Remember that you were slaves in Egypt, and the Lord your God ·saved [ransomed; redeemed] you. That is why I am commanding this to you today.\n16 But if your slave says to you, “I don’t want to leave you,” because he loves you and your ·family [L house] and has a good life with you, 17 stick an awl [C a pointed tool for making holes] through his ·ear [earlobe] into the door; he will be your slave for life. Also do this to a female slave.\n18 Do not think of it as a hard thing when you let your slaves go free. After all, they served you six years and did twice the work of a hired person. The Lord your God will bless you in everything you do [Ex. 21:2–6; Lev. 25:39–46].\nRules About Firstborn Animals\n19 Save all the first male animals born to your herds and flocks [Ex. 13:2, 11–16; 22:29; Num. 18:15–18]. They are ·for [consecrated to] the Lord your God. Do not work the first calf born to your oxen, and do not cut off the wool from the first lamb born to your sheep. 20 Each year you and your ·family [L house] are to eat these animals in the presence of the Lord your God, in the place he will choose to be worshiped [C Zion; 12:4–7]. 21 If an animal is crippled or blind or has ·something else wrong [some blemish/defect], do not sacrifice it to the Lord your God. 22 But you may eat that animal in your own ·town [L gate]. Both clean and unclean people [C in a ritual sense] may eat it, as they would eat a gazelle or a deer. 23 But don’t eat its blood; pour it out on the ground like water [12:24].\nStarting your free trial of Bible Gateway Plus is easy. You’re already logged in with your Bible Gateway account. The next step is to enter your payment information. Your credit card won’t be charged until the trial period is over. You can cancel anytime during the trial period.\nClick the button below to continue.\nYou’ve already claimed your free trial of Bible Gateway Plus. To subscribe at our regular subscription rate of $3.99/month, click the button below.\nIt looks like you’re already subscribed to Bible Gateway Plus! To manage your subscription, visit your Bible Gateway account settings.\nFor the best Bible Gateway experience, consider upgrading to Bible Gateway Plus. Bible Gateway Plus equips you to have in-depth biblical discussions with your friends, your family, and your peers. Try it free for 30 days!\nThree easy steps to start your free trial subscription to Bible Gateway Plus."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:4ca806d8-6aac-41a4-b27c-1bc24c68598d>"],"error":null}
{"question":"How does Queryparser process SQL queries in its three-phase analysis pipeline?","answer":"Queryparser processes SQL queries in three distinct phases: 1) Parse phase - transforms the raw query string into an abstract syntax tree (AST) representation, 2) Resolve phase - scans the raw AST and applies scoping rules, transforming plain column names by adding table names and plain table names by adding schema names (requires catalog information), and 3) Analyze phase - scans the resolved AST to identify columns that are compared for equality.","context":["In early 2015, Uber Engineering migrated its business entities from integer identifiers to UUID identifiers as part of an initiative towards using multiple active data centers. To achieve this, our Data Warehouse team was tasked with identifying every foreign-key relationship between every table in the data warehouse to backfill all the ID columns with corresponding UUIDs.¹\nGiven the decentralized ownership of our tables, this was not a simple endeavor. The most promising solution was to crowdsource the information by scraping all the SQL queries submitted to the warehouse and observing which columns were joined together. To serve this need, we built and open sourced Queryparser, our tool for parsing and analyzing SQL queries.\nIn this article, we discuss our implementation of Queryparser, the variety of applications it unlocked, and some problems and limitations encountered along the way.\nInternally, Queryparser is deployed in a streaming architecture, as shown in Figure 1, below:\nQueryparser consumes the real-time stream of queries submitted to the data warehouse, analyzes every single one, and emits the analysis results to a separate stream. Individual queries are processed in three steps, explained below and illustrated in Figure 2.\n- Phase 1: Parse. Transforms the query from a raw string of characters into an abstract syntax tree (AST) representation.\n- Phase 2: Resolve. Scans the raw AST and applies scoping rules. Transforms plain column names by adding the table name, and transforms plain table names by adding the schema name. Requires as input the full list of columns in every table and the full list of tables in every schema, otherwise known as “catalog information.”\n- Phase 3: Analyze. Scans the resolved AST, looking for columns which are compared for equality.\nThe implementation and architecture successfully identified foreign-key relationships—a great result, given that the prototype only had partial coverage of the SQL grammar, the catalog information was entirely hard-coded, and our understanding of what counted as a foreign-key relationship was continually evolving.²\nThe Haskell choice\nOne of the first things you may have noticed in the open source Queryparser repository is that it is written in Haskell. Queryparser was originally conceived by an Uber engineer who was a Haskell enthusiast, and it quickly gained traction with several other engineers. In fact, many of us learned Haskell specifically to develop in it.\nHaskell turned out to be a good choice for prototyping Queryparser for a variety of reasons. To start, Haskell has very mature library support for language parsers. Its expressive type system was also extremely useful for the frequent and extensive refactors of our internal model of a SQL query. Additionally, we leaned heavily on the compiler to guide us through those big, scary refactors. If we attempted the same using a dynamically-typed language, we would have lost weeks chasing runtime bugs that Haskell’s compiler can quickly flag for us.\nThe main drawback of writing Queryparser in Haskell was that not enough developers knew it. To introduce more of our engineers to Haskell, we started a weekly reading group, which met over lunch to discuss Haskell books and documentation.\nNote that for interoperability with the rest of Uber’s non-Haskell infrastructure, Queryparser was (and is) deployed behind a Python proxy server. See the Deploying Queryparser section of this article for more details.\nDiversity of solutions\nAfter the initial success of Queryparser, we considered other ways in which the tool could improve our data warehouse operations. In addition to implementing join detection, we decided to implement several more analysis functions:\n- Table access: which tables were accessed in the query\n- Column access: which columns were accessed in each clause of the query\n- Table lineage: which tables were modified by the query, and what were the inputs that determined their final state\nTogether, the new analyses gave a nuanced understanding of the access patterns in our data warehouse, permitting advances in the following areas: table administration, targeted communication, understanding data flow, incident response, and defensive operations, outlined below:\nAs far as table administration was concerned, the benefits were threefold. First, table access statistics let us free up storage and compute resources by finding tables that were infrequently accessed and then removing them.\nSecond, column access statistics let us improve database performance by optimizing table layouts on disk, particularly with Vertica projections. The trick was to set the top GROUP BY columns as the shard keys and the top ORDER BY columns as the order keys.\nFinally, column join statistics let us improve data usability and reduce database load by identifying clusters of tables that were frequently joined together and replacing them with a single dimensionally modeled table.\nTable access statistics let us send targeted communications to data consumers. Instead of blasting the entire Data Engineering mailing-list with updates about table schemas or data quality issues, we could notify only the data consumers who had recently accessed the table.\nUnderstanding data flow\nTable lineage data unlocked a special use case: if a sequence of queries were analyzed together, then the table lineage data could be aggregated to produce a graph of dataflow across the sequence.\nFor example, consider the hypothetical SQL in Figure 3, below, which produces a new version of modeled table A from dependent tables B and C:\n|drop A_new if exists|\n|create A_new as select … from B|\n|insert into A_new select … from C|\n|drop A_old if exists|\n|rename A to A_old|\n|rename A_new to A|\nFigure 3: Sequence of SQL queries for computing modeled table A from dependent tables B and C.\nIn Figure 4, below, we describe the table lineage that Queryparser would produce for each query in the sequence. Additionally, we depict and explain the cumulative observed dataflow for each query in the sequence. At the end, the cumulative data flow (correctly!) records that table A has dependencies on tables B and C:\nFigure 4: SQL from Figure 3, with table lineage for each query in the sequence, and cumulative table lineage for the entire sequence.\nWe modified our ETL-framework to record the sequence of SQL queries in every ETL and submit them to Queryparser, at which point Queryparser was programmatically generating graphs of data-flow for all the modeled tables in our warehouse. See Figure 5, below, for an example:\nTable lineage data has been useful in responding to data quality incidents, decreasing the mitigation time by offering tactical visibility into incident impact. For example, given the table dependencies in Figure 5, if there was an issue in raw table A, we would know that the scope of impact included the modeled tables E and G. We would also know that once the issue was resolved, E and G would need to be backfilled. To address this, we could combine the lineage data with table access data to send targeted communications to all users of E and G.\nTable lineage data is also useful for identifying the root cause of an incident. For instance, if there was an issue with modeled table E in Figure 5, it could only be due to the raw tables A or B. If there was an issue with modeled table G, it could be due to raw tables A, B, C, or D.\nFinally, the ability to analyze queries at runtime unlocked defensive operations tactics that enabled our data warehouse to run more smoothly. With Queryparser, queries can be intercepted en route to the data warehouse and submitted for analysis. If Queryparser detects parse errors or certain query anti-patterns, then the query can be rejected, reducing the overall load on the data warehouse.\nProblems and limitations\nFred Brooks famously argued that there is no silver bullet in software engineering. While beneficial for our storage needs, Queryparser was no exception. As the project unfolded, it revealed some interesting essential complexities.\nLong tail of language features\nFirst, and least surprising: when adding support for a new SQL dialect, there is a long tail of infrequently-used language features to implement, which can require significant changes to Queryparser’s internal representation of a query. This was immediately apparent during the prototype phase, when Queryparser exclusively handled Vertica, and was further confirmed when support for Hive and Presto was added. For example, parsing TIMESERIES and OFFSET in Vertica required adding new clauses to SELECT statements. Additionally, parsing LEFT SEMI JOINs in Hive required a new join type with special scoping rules, and parsing the bonus top-level namespace of “databases” in Presto (where tables belong to schemas belong to databases) required extensive re-working of struct-access parsing.³\nTracking catalog state\nSecond, tracking catalog state was hard. Recall that catalog information is needed for resolving column names and table names. Uber’s data warehouse supports highly concurrent workloads, including concurrent schema changes, typically creating, dropping, and renaming tables, or adding or dropping columns from an existing table. We experimented briefly with using Queryparser to track catalog state; if Queryparser was already analyzing every query, we wondered if we could simply add an analysis that reported the schema changes and produce the new catalog state by applying them to the previous catalog state. Ultimately, that approach was unsuccessful due to the difficulty of ordering the entire stream of queries. Instead, our alternative (and more effective) approach was to treat the catalog state as more-or-less static, tracking the schema membership and column-lists of tables through configuration files.\nThird, sessionizing queries with Queryparser was difficult. In a perfect world, Queryparser would be able to track table lineage across an entire database session, accounting for transactions and rollbacks and various levels of transaction isolation. In practice, however, reconstructing database sessions from the query logs was difficult, so we decided not to add table lineage support for those features. Instead, Queryparser relies on Uber’s ETL-framework to sessionize the ETL queries on its behalf.\nFinally, Hive is a leaky abstraction over the underlying filesystem. For instance, INSERTs can be accomplished by several means:\n- INSERT INTO foo SELECT … FROM bar\n- ALTER TABLE foo ADD PARTITION … LOCATION ‘/hdfs/path/to/partition/in/bar’\nUber’s ETL framework initially used the first method, but was migrated to use the second method, as it showed dramatic performance improvements. This caused issues with table lineage data, as ‘/hdfs/path/to/partition/in/bar’ was not interpreted by Queryparser as corresponding to table bar. This particular issue was temporarily mitigated with a regular expression to infer the table name from the HDFS path. However, in general, if you choose to bypass the SQL abstractions of Hive in favor of filesystem-layer operations, then you opt out of Queryparser analysis.\nDeploying a Haskell service in Uber’s non-Haskell infrastructure required some minor creativity, but never amounted to a substantial problem.\nInstalling Haskell itself was straightforward. Uber’s standard infrastructure pattern is to run every service in a Docker container. Container-level dependencies are managed through config files, so adding Haskell support was as simple as adding Stack to the list of required packages.\nQueryparser is internally deployed as a Haskell artifact, running behind a Python service wrapper for interoperability with the rest of Uber’s infrastructure. The Python wrapper acts as a proxy server and simply forwards requests to the Haskell backend server in the same docker container. The Haskell server consists of a main thread that listens for requests on a UNIX-domain socket; when a new request arrives, the main thread spawns a worker thread to handle the request.\nThe Python wrapper also handles metric emission on behalf of the Haskell backend. Metric data is passed via a second UNIX-domain socket, with data flowing in the reverse direction: a daemon-thread in the Python layer listens for metrics from the Haskell layer.\nIn order to share configuration between the Python and Haskell layers, we implemented a tiny configuration parser in Haskell, which understood Uber’s standard Python convention of layered configuration files.\nFinally, to define the service interface, we used Thrift. This is the standard choice at Uber, and since Thrift has Haskell support, the Haskell server worked out-of-the-box. Writing the Python code to transparently forward requests required diving into the binary protocol and was the most difficult operations step.\nQueryparser unlocked a diversity of solutions and had some interesting limitations. From its humble origins as a migration tool, it became a vehicle for insight into large-scale data access patterns.\nIf you are interested in working on similar projects, reach out to email@example.com and/or apply for a role on with us via the Uber Careers page and tell your Uber recruiter that you’d like to work on the Data Knowledge Platform team.\n¹Spoiler alert: there ended up being dozens of primary keys to migrate. Each primary key could have many foreign keys under different aliases. The worst offender had over 50 different aliases.\n² Foreign-key relationships ranged from the obvious like “SELECT * FROM foo JOIN bar ON foo.a = bar.b” to the less obvious like “SELECT * FROM foo WHERE foo.a IN (SELECT b from bar)” to the debatable like “SELECT a FROM foo UNION SELECT b FROM bar”. We erred on the side of being liberal about what we counted as a relationship, since output would be manually inspected anyway.\n³ Given the SQL “w.x.y.z”, which identifier is the column name? Depending on the catalog state and what is in scope, it could be “w” with “x.y.z” referring to nested struct fields, or it could be “z” with “w.x.y” referring to “database.schema.table”, or anything in between."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:68078766-19b4-4669-9efe-a723c61f54a8>"],"error":null}
{"question":"Which has a bigger impact on national security - renewable energy or energy efficiency measures? Really curious about the strategic benefits! 🤔","answer":"Both contribute to national security but in different ways. Energy efficiency directly enhances security by reducing dependence on fuel transport in military operations - statistics show that 80% of battlefield supply missions in Iraq and Afghanistan were for fuel, with one soldier death occurring per 50 refueling convoys. In 2011 alone, there were 1,100 attacks on fuel convoys. Meanwhile, renewable energy helps by reducing dependence on foreign oil imports and providing reliable backup power during emergencies - for example, solar systems can power critical facilities like hospitals and police stations after storms when the grid is down. Both approaches help decrease overall energy demand and reliance on foreign energy sources.","context":["of alternative energy\nIf you want to lower your energy costs you need explore the benefits of alternative energy. Alternative energy sources provide many benefits and renewable energy can create new jobs and promote economic development, especially in areas far from the city where most jobs are located. If used to diversify utility energy sources, alternative energy technologies can provide a hedge against rising fuel prices and can be valuable risk management tools.\nWhile some renewable energy resources are not always available (the wind does not blow or the sun does not always shine), the technologies perform reliably when the \"source\" is available. In this regard, they can add to the reliability of the electricity grid, especially for businesses in which power outages are extremely costly.\nWhere they come from, solar and wind technologies are emissions-free. This makes them attractive from an environmental standpoint. An additional environmental benefit could be the brightfields concept: installing clean energy technology-related businesses in environmentally blighted areas (brownfields).\nFinally, selected applications of energy efficiency and renewable energy technologies can enhance the disaster resiliency of communities and individual structures. For example, solar electric systems can provide needed power to hospitals, fire stations, police departments, gas stations, national guard armories, etc. in the sunny days that follow destructive storms.\nWhy We Need An Alternative\nThe very idea of looking for alternative energy implies that we need something better. We know we do. So seeking what the benefits of alternative energy would offer, is a no-brainer.\nWe know the limitations of many of our current fuel sources…\nLimited supply of resources (oil, coal)\nHigh costs and getting higher\nNegative effect on the environment and natural resources (water, air, forests)\nCarbon based fuels add to global warming\nDependence on other countries for oil\nThe main benefits of an alternative energy source would be that they counter the problems and limitations above.\nEconomicsStates that import electricity, or utilities that import fuel for power plants from other states, lose vital financial resources because those payments leave the state and local economies. Renewable energy and energy efficiency tend to be labor-intensive and local. They can mean promising, quality job growth in manufacturing, construction, operation, and maintenance.\nIn addition, studies indicate that dollars saved through energy efficiency tend to be spent locally and then respent multiplying the benefits\nRenewable energy and energy efficiency also can help revitalize rural communities. Biomass energy crops or wind turbines — or both — can provide energy, create new cash crops for farmers, and provide rural communities with new tax revenue. Especially in Rocky Mountain and Plains states, farmers are \"harvesting\" the wind, as well as both plant and animal biomass.\nFarmers on windy lands can lease space to wind developers, earning thousands of dollars for each turbine every year. The footprint of a utility-scale wind turbine is minimal, so farming and ranching operations continue uninterrupted. Rural counties receive tax revenues to support their operations, as well as local schools.\nRenewable energy technologies can be an economical addition to an energy supplier's resources. Examples include providing solar-generated electricity during peak sun times or shifting from purchased fuels to wind-generated electricity on windy days.\nEven though wind is an intermittent resource, it is predictable and can be planned by utilities as part of their generating portfolios. Small wind turbines can generate electricity in homes or on farms, offsetting the need for the equivalent amount of purchased electricity.\nHere's other clear economic benefits of alternative energy...\nEnergy efficiency investments start saving energy immediately and have short paybacks.\nReducing usage lowers operating costs and can help make industry, farms, and merchants more economically competitive.\nEnergy efficiency also helps minimize the need to build new and expensive power plants.\nStudies indicate that energy efficiency technologies cost substantially less than building or purchasing new energy supply.\nAlternative energy technologies have significant environmental benefits. Solar and wind technologies are emissions-free at the point of use; emissions from biomass are lower than comparable conventional fuels; and energy efficiency, by definition, reduces energy consumption, which results in fewer emissions.\nIf future environmental regulations include carbon dioxide, renewable and energy efficiency technologies can provide a cushion for states and utilities. This could serve as a hedge against possible litigation, as conventional energy production and consumption contribute significantly to carbon dioxide emissions.\nRenewable energy technologies also have minimal impact on water resources. They do not discharge pollutants into surface water, and toxins do not seep into groundwater. Cooling water is not required for solar and wind technologies — an important consideration in arid or semi-arid states, or where riparian rights are contested.\nAlternative energy technologies can provide a measure of assurance of continued electricity supply at times when it otherwise might be threatened. In some circumstances, renewable energy technologies can be more reliable than other forms of electricity.\nFor example, solar electricity systems can be used after storms for response and recovery. Renewable energy technologies such as generators powered by photovoltaics (PV) can supply electricity if the grid fails. Often the sun comes out in the immediate aftermath of a devastating storm. It can take weeks to repair the electricity grid and restore power to all customers. As long as the sun shines, however, rooftop or building-integrated PV can produce electricity on-site, despite downed wires. If battery storage is added to the system, it can supply electricity even after the sun goes down or through several cloudy or stormy days.\nIn California, policy makers minimized economic losses during the 2001 energy crisis by supporting and funding energy efficiency programs. The $1.3 billion that California taxpayers and ratepayers invested in energy efficiency and demand response programs in 2001 is favorable compared to the estimated $2 billion to $20 billion in potential losses from rolling blackouts that were avoided — in addition to savings associated with avoided wholesale power purchases.\nReliability is critical for electricity providers. As our economy becomes more dependent on complex computer technology, the standard for reliability has been raised to an unprecedented \"six 9s:\" reliable electricity must be available 99.9999% of the time. The power also must be of premium quality to supply highly sensitive equipment.\nIt may sound strange to describe renewable energy technologies as reliable. After all, they are intermittent resources — the wind does not always blow and the sun does not always shine. However, although the wind does not always blow, it is predictable and can be planned for quite reliably. When added to the electricity generation mix, renewable energy technologies can help energy suppliers stretch their other fuel supplies and mitigate the risk of blackouts during times of peak electricity demand.\nThe most reliable kilowatt is the one that does not need to be generated, transmitted, distributed, or stored. In California, energy efficiency and energy-conserving behaviors enhanced system reliability during the 2001 energy crisis by reducing demand on the system. Moreover, this was a supremely cost-effective effort. The $1.3 billion that California taxpayers and ratepayers invested in energy efficiency and demand response programs in 2001 is favorable compared to the estimated $2 billion to $20 billion in potential losses from rolling blackouts that were avoided (in addition to the savings associated with avoided wholesale power purchases).\nRenewable energy sources offer several avenues for satisfying public concern for environmental preservation. National and utility-specific surveys indicate that consumers prefer environmentally clean energy and are willing to pay extra for \"green\" power. Increasingly, however, the premium for \"green\" decreases as the prices of conventional fuels increase.\nAmericans also support energy efficiency technologies and efforts because they view these investments as fiscally sensible and environmentally responsible. Polls across all demographic categories and political parties during the past 20 years have shown that these programs are consistently favored by the public.\nThe benefits of alternative energy are\nclear and the fact that\nthe public and the government feel strongly about moving to a greener\neconomy only makes them that much more compelling. The future is indeed\nbright and will be lit by alternative energy.\nThe US Department of Energy was a source for much of this information.","Top 5 Reasons to be Energy Efficient\nEnergy efficiency – doing more with less energy – benefits you, your country, and the world. The benefits of energy efficiency are numerous. But the top five reasons that people, companies and governments choose to use energy more efficiently are:\n- Energy efficiency saves you money.\n- Energy efficiency improves the economy.\n- Energy efficiency is good for the environment.\n- Energy efficiency improves national security.\n- Energy efficiency enhances quality of life.\nThese reasons are in no particular order because each person's priorities are unique. Read on to see which reasons to be \"EE\" are most important to you.\nThe average U.S. household spends $5,550/year on energy. But buying energy-efficient appliances, making energy-efficient home improvements, and taking energy-efficient actions every day can save hundreds of dollars.\n- Buying ENERGY STAR appliances saves up to 30% on electricity bills. For instance, a new ENERGY STAR-rated refrigerator saves $165 compared to a regular model in its lifetime.\n- Replacing incandescent light bulbs with energy-efficient halogens, CFLs or LEDs saves 30-80% on energy bills. That adds up to annual savings of $50 to more than $100.\n- Taking daily, energy-efficient actions while you’re at home, at work and on the go saves energy and money. Washing clothes in cold water can save $63/year, and keeping your tires inflated can save $61/year.\nWhile energy efficiency helps you save at home and at the pump, it helps businesses and city, state and federal governments save on a much bigger scale.\n- Saving billions: Overall, energy efficiency is saving the American government, its citizens and businesses more than $500 billion a year in avoided energy costs.\n- Creating jobs: In addition to saving money, energy efficiency projects (like building improvements and infrastructure repairs) create jobs. In 2010 alone, energy efficiency accounted for more than 830,000 jobs nationwide.\n- Spurring innovation: Industry leaders make energy-efficient innovations, and energy-efficient policies lead to breakthroughs among manufacturers. For instance, standards that started in 2012 requiring light bulbs to be at least 25% more energy efficient than traditional incandescent bulbs spawned an array of new lighting products. From LED streetlights to flame-shaped, dimmable candelabra CFLs, energy-efficient lights are just as pleasing to the eye as the old bulbs but use far less energy.\nIt’s a no-brainer: When we use less energy, we save precious natural resources and cut down on pollution.\n- Saving energy resources: The United States uses 56% less energy today than if we didn’t have energy-efficient technologies and policies. That’s 52 quads of energy saved per year – the same amount of energy needed to power 12 states for a year. If we didn't have energy efficiency, we’d have to produce or import energy sources like oil, natural gas, and coal. So, energy efficiency helps us keep more resources on the earth longer.\n- Avoiding pollution: From power plants to cars, consuming energy can produce emissions that harm our environment. But investments in energy efficiency across the biggest sectors of our economy could abate up to 1.1 gigatons of greenhouse gas emissions annually – that’s equal to taking all U.S. cars and trucks of the road for one year.\nEnergy efficiency safeguards our nation by decreasing the overall demand for energy, and therefore the need to import and transport fossil fuels.\n- Enhancing energy independence: Using fewer of America's energy resources – like oil to power our vehicles – means we don't need to depend so much on foreign nations. With energy efficiency, we save energy resources for future generations to use.\n- Saving money for defense: As the armed forces improve the energy efficiency of their equipment, buildings and general practices, they save money that can be invested directly in defense programs.\n- Keeping our troops safe: The armed forces need fuel to supply their troops, but battleground supply missions can be dangerous. In fact, 80% of on-the-ground supply delivery missions to troops in Iraq and Afghanistan are for fuel, and (on average) one soldier dies for about every 50 of those refueling convoys. In 2011 alone, there were 1,100 attacks on fuel convoys. Using electric and hybrid vehicles, energy-efficient generators and other energy-saving measures mean fewer convoys, and fewer convoys mean fewer casualties.\nYou might not see it, but you can feel it: Energy efficiency improves quality of life.\n- More comfortable: Notice how your insulated home keeps AC inside during the summer, and heat in during the winter? Or how you rarely need to change your energy-efficient light bulbs? That’s energy efficiency making your environment more enjoyable.\n- More productive: Businesses can improve productivity, as well as the bottom line, by taking advantage of energy efficiency in office buildings and production processes.\n- More accessible: Residents of cities that employ smart growth technologies and transportation systems have an easier time of getting around – and getting consistent access to electricity.\nWant More Reasons to be Energy Efficient?\n- Energy Conservation vs. Energy Efficiency: What's the Difference?\n- Top 10 Home Energy Efficiency Tips\n- Fuel Efficiency: Top Tips to Save Gas and Money comprehensive guide\n- Chart of how much energy we save, import and create in Energy Efficiency: America's Greatest Energy Resource"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:241d65fd-6fd6-4eb9-ab14-0d07cb934491>","<urn:uuid:42130e70-9ff4-4c64-81e5-7d1b15c2fbfd>"],"error":null}
{"question":"¿Podría decirme por favor cuál es la vida útil esperada de las tejas básicas de 3 lengüetas?","answer":"Basic 3-tab shingles have a life expectancy of 15-20 years.","context":["Estimated Cost Comparison Table\n$1.50 – $3 / sqft\nAverage Cost Estimate\n$3.50 – $5 /sqft\n$5 – $8 /sqft\n|Type of Roofing Shingle||Basic 3-Tab||Mid-Range Shingles||Mid-High Range Architectural|\n|Existing Shingle Removal||If Needed||Yes / No||Yes|\n|Hurricane Zone?||No||As Needed||As Needed|\n|Life Expectancy||15-20 Years||15 – 30 Years||25 – 35 Years|\n|Underlayment Condition||Remain||Remain / Repair||Remain / Repair|\n|Roof Features and Construction||Few / None||Average||Average / Difficult|\n|Installed By||DIY / Helper||DIY / Pro||Roofing Pro|\n|Disposal Costs||None||$400 / Included||Included|\n|Permits and/or Inspection||$0 – $250||$150 – $250||$150 – $250|\nSections: Overview | Product Costs | Installation Cost | DIY or Pro | Web Compare | Shared Pricing\nOverview of Asphalt Shingle Roofs\nAsphalt shingles remain the top choice in residential roofing. They’re available in a wide range of styles to suit your home’s architecture and deliver 20-30 years of durability. Asphalt shingles cost is among the most affordable of any roofing option. Three-tab and basic dimensional shingles update a home’s curb appeal when you’re ready to sell, while high-end architectural shingles from CertainTeed, Owens Corning and GAF add distinction to a home you intend to live in for decades to come.\nThis Costimates entry covers the cost to shingle a roof whether you’re building a new home, adding a layer of shingles or tearing off existing shingles to start fresh. The cost estimate covers various grades of material plus underlayment and other accessories often overlooked in shingle cost estimates. Roofing labor cost per square is listed separately in the table above and again down below. We’ve gathered online estimates from around the Web and given homeowners space to share their asphalt roofing costs too. Your research here will allow you to put together an accurate estimate for the type of shingles you plan to use and the size and complexity of your roof.\nShingle Roof Cost Details\nMaterial Cost Factors\nAsphalt shingles cost for materials and installation ranges from cheap to moderate compared with other roofing materials based on these factors:\n- Does Your Old Roof Need to Be Removed? – Tearing off one or two layers of old shingled roofing and then paying for disposal will increase your total cost to shingle a roof. In most cases, 2 layers of shingles is the maximum allowed standard. If you have a single layer of shingles now, you may be able to lay the new roof directly on top of it.\n- Scope of the Work – The most affordable asphalt shingle roof cost is done by adding a new layer over existing shingles. When roofing new construction or after a tear-off of old roofing, new underlayment, moisture barrier in valleys and along eaves and a row of starter shingles increases material and labor costs. Replacing damaged roof sheathing raises roofing costs even higher.\n- The Grade of Shingle you Use—Your options are affordable 3-tab shingles with warranties of 20-25 years, mid-range dimensional 30-year shingles or top of the line architectural shingles with a lifetime warranty.\n- Specialty Shingles – Expect to pay a slight premium for shingles that are resistant to the elements such as Owens Corning TruDefinition Storm (wind), CertainTeed Landmark IR (impact), GAF Timberline Cool Series (solar/UV) and Owens Corning Supreme AR (algae).\n- Choosing a complete Roof System to Get a Better Warranty – Top brands like CertainTeed, GAF, Owens Corning and Tamko offer multiple warranty options. Better warranties cover 100% of replacement costs for defective materials for more years before the warranty starts being prorated by 2-4 percent per year. Some also offer a warranty on labor beyond the standard 0-12 months. For example, CertainTeed offers three options: General Warranty (short with basic coverage), Sure Start (longer/better) and Sure Start Plus (longest/best). To get the better warranties, you need to use several of the brand’s premium roofing system products such as underlayment, moisture barrier, ridge vent and starter shingles, usually at a premium cost.\n- Who Does the Work – DIY homeowners pay for materials, supplies and tools only. Unlicensed roofers cost less than licensed roofing contractors, but you typically get what you pay for in the workmanship of the installation. Also, if you want a shingle brand’s premium warranty, you’ll have to hire a brand-certified roofer, and they’re rates are typically higher than average.\n- Enhanced Installation – When installed with standard techniques, most dimensional shingles have a 110MPH wind warranty. To increase the wind warranty to 130MPH, a good idea in high-wind areas like High-Velocity Hurricane Zones (HVHZ) and “tornado alley,” extra nails, roofing cement and materials are required, so cost is higher.\n- Roof Pitch —The cost of a new roof rises as the pitch or the roof gets steeper because there are more square feet of roof, and roofing it is more difficult.\n- The Complexity of the Roof—Roofs with hips instead of gables, more than four corners and obstacles such as skylights cost more to roof than simple roofs.\n- Delivery Charges – Delivering the materials to your home and transporting them to the roof can be extra charges when you buy the materials and hire a roofing contractor separately. These costs are typically included in the total cost of a new roof when hiring a contractor to manage the entire process.\nCost of Supplies\nThe scope of your project will determine the supplies required from the following list:\n- Tear off with repairs: All supplies in the list\n- New construction and tear off with no repairs: All supplies except sheets of roof sheathing\n- Adding a second layer of asphalt shingles: Shingles, ridge and hip shingles, nails, ridge vent\nHere is roofing cost per square (100 square feet) and per linear foot based on the material’s application.\nRoofing Supplies Prices:\n- $38-$42 per square | Roof sheathing – 7/16” sheets\n- $24-$40 per square | Roofing underlayment (Roofing paper)\n- $2.65-$4.25 per square | Roofing nails\n- $1.35-$2.65 per linear foot | Moisture barrier for valleys, eaves and rakes\n- $3.50-$5.50 per linear foot | Ridge vent\n- $.35-$.70 per linear foot | Drip edge\n- $3.10-$6.25 per linear foot | Ridge and hip shingles\nAsphalt Shingle Prices:\n- $60-$80 per square | Basic 3-tab shingles\n- $80-$95 per square | Better 3-tab shingles\n- $85-$100 per square | Basic dimensional/architectural shingles\n- $100-$120 per square | Mid-range dimensional / architectural shingles\n- $110-$165 per square | Premium dimensional / architectural shingles\nPopular Asphalt Shingle Prices:\nPerhaps it will help you determine a roofing cost per square foot if we list shingle costs per square for popular brand lines:\n- GAF Royal Sovereign: $65-$80\n- CertainTeed XT25: $72-$86\n- Owens Corning Supreme: $68-$84\n- Mid-grade dimensional/architectural:\n- GAF Timberline and Timberline HD: $118-$148\n- CertainTeed Landmark Premium: $125-$140\n- Owens Corning Duration: $108-$124\n- Tamko Heritage: $84-$105\n- Premium dimensional/architectural:\n- GAF Woodland: $148-$162\n- CertainTeed Highland Slate: $150-$170\n- Owens Corning Duration Designer Series: $110-$140\n- Tamko Heritage Woodgate: $175-$200\nPermits, Inspection, Related Costs and Installation Time\nPermits and Inspection Cost\nNow we’ll review asphalt roof installation cost including permits and labor.\n- $125-$300 | A permit is required for installing a new roof. One or two inspections will be included. The size of the home is considered in many communities when determining the cost of a roofing permit.\nRelated Costs and Installation Time\nOnly consider the costs that apply to your new roofing project:\n- $25-$250 | Total delivery charges for materials, when applicable\n- $100-$750 | Cost to raise shingle bundles to the roof, when applicable\n- $90-$165 per square | Removal and disposal of one or two layers of shingles and roofing paper\n- $115-$235 per square | Installing new asphalt shingles and required accessories\nAsphalt Roof Install Time Schedule\nThe average home in North America is +/- 2,000 square feet, though the average size of new homes is about 2,500 square feet. Here’s a timeframe that fits the average home.\n- 1 day: If necessary, remove old roofing and make necessary repairs to the roof sheathing.\n- 1 day: If necessary, install roofing paper. Begin installing shingles.\n- 1-2 days: Complete roofing most homes.\n- 3-4 days: Complete roofing homes with large and/or complex roofs.\nDIY or Hire a Pro?\nI’ve shingles a roof before, but it’s not one of those things an everyday DIY homeowner is going to like to do. I installed a metal roof on a storage building in my backyard, and long long ago, decided I would re-shingle the roof on our home when we lived in the Northeast. All I can say is, due to a new roof being a costly home repair, is it’s not really worth the time to do it as compared to hiring a professional. You need too many tools and skills to get it done properly in an acceptable amount of time.\n- Requires a lot of friends or helpers to move along quickly.\n- Unless you like carrying 40 pound bundles of shingles up a ladder, you’ll need special tools to hoist them up for you.\n- Hot, back-breaking work under a time schedule to beat bad weather.\nI’ll leave whole-house roofing to a pro every single time now.\nAsphalt Shingle Roof Replacement Costs from the Web\n|Costimates||$4.20 / sqft installed||$1.50 – $8 / sqft|\n|HowMuch.net||$2.90 / sqft installed||$1.20 – $4 / sqft|\n|RoofingCalc.com||$4.75 / sqft installed||$3.50 – $5 / sqft|\n|HomeWyse.com||$3 / sqft installed||$2.50- $3.5 / sqft|\n|Suggest a Cost Comparison from Another Website|\nCosts Submitted by Homeowners and Pro’s"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:942bf13c-b5cf-435c-9f19-5618a7f828dd>"],"error":null}