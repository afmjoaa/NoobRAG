{"question":"how building protect from bad air coming from outside????","answer":"Buildings have two lines of defense: the thermal envelope (skin) that prevents leakage around doors and windows, and air handling units (lungs) that control the introduction of outside fresh air. Additionally, buildings can use enhanced particle filtration systems like MERV or HEPA filters to keep out chemical or biological contaminants.","context":["When it comes to protecting a building's occupants from airborne dangers within the building and from outside which are attempting to come in, your building has an immune system similar to that of your own. Your building has two lines of defense, yet it is the building owner, manager, or facility engineer that determines the strength of that immunity.\nThe health of your facility's thermal envelope — its skin — its' ability to keep thermal comfort heating and cooling in, and outside air and contaminates out, is measured by the amount of environmental leakage around doors and windows. The lungs of your building — its air handling units — which introduce the regulatory required amount of outside fresh air, is your building's second line of defense.\nVentilation system recommissioning with an added ventilation safety audit is probably the most obvious approach to learning how your facility is performing and how it currently rates. Building envelope air-tightening with building pressurization (more outside air introduced into your building than exhausted) are common practices that are unfortunately not exercised effectively and in most cases inefficiently. The isolation of vulnerable spaces such as lobbies, in a number of cases, are eliminated by value engineering and renovation projects which turn a blind eye to this extremely important building feature.\nWithin the DC area there are a number of buildings featuring automated heating, ventilating and air-conditioning (HVAC) operational changes in response to contaminant sensing. These exterior wall and roof-top mounted sensors tie directly into your building's automation system, but at an extremely high cost. However, in the alternative, I am familiar with a number of buildings that feature an emergency panic button type of shutdown of their building's air-handling-units upon the detection or notification of an external chemical or biohazard alert.\nA review of a facility's outdoor air intake (how your building breathes) audits the safe location (out of sight out of reach) of your building's air supply and the concern of a potential introduction of contaminated air coming into your building. Conversely, what happens if such airborne contaminate reaches your air-handing-unit?\nEnhanced particle filtration is the most popular when you select your filter using the Minimum Efficiency Reporting Value (MERV) rating system, or the High-Efficiency Particulate Air (HEPA) for filter selection. It is MERV or HEPA that will advise you which filter product-rating is most effective in keeping out the chemical or biological bad stuff.\nAs an example and at the time of this writing, the Ebola virus is not an airborne disease here in the US, but there are a number of airborne viruses and bacterial germs, such as the legionella bacteria, anthrax, and others, that can become airborne by negligence, intentional application, or otherwise. But if there is an upside to this danger, because a virus ranges from 0.005 - 0.3 microns in size, and bacteria from .3 to 60 microns, the HEPA filter product is a great way of stopping bad airborne stuff from entering your building.\nNow if you want more of a guarantee, than sorbent-based gaseous air cleaning, ultraviolet germicidal irradiation, or photocatalytic oxidative air cleaning, in conjunction with your HEPA filtration, can keep your building or workplace environment isolated from these airborne dangers, until someone has time to push the wall-mounted emergency stop button for your air-handling units.\nThe cover article of the next AFE Journal will feature a how-to on retrofit options for your facility against internal and external airborne chemical and biological releases and hazards. Meanwhile, because each building has its own personality, I would suggest you consider speaking with your Certified Air Filtration Specialist (CAFS), certified by the National Air Filtration Association (NAFA), for the best professional advice."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:a4549c0b-bc99-4d4d-907e-04815f27fe7b>"],"error":null}
{"question":"What is the difference between asthma preventer and reliever medications?","answer":"Reliever medicines are bronchodilators that provide quick relief of asthma symptoms, usually coming in blue or grey inhalers. They work fast but only provide temporary relief. Preventer medicines, on the other hand, are typically inhaled corticosteroids that come in brown, orange, rust or yellow inhalers. They are used for long-term asthma management by reducing inflammation in the airways to reduce the risk of severe asthma flare-ups. Preventers should be taken daily, even without symptoms, while relievers should only be needed once or twice per week if asthma is well-controlled.","context":["It’s a frightening time when you or someone you love first experiences asthma symptoms. When your doctor gives you an asthma diagnosis and tells you it is treatable and manageable, you may feel the relief that often comes when you know what you’re dealing with. “Great”, you say. “Just tell me what to do!” Sometime later, you leave their office with a handful of prescriptions and brochures and a headful of new information. What are these medicines for? What’s an asthma action plan? It can be overwhelming,\nIn this article we'll aim to answer some common questions we’ve received over time in the hope we can make the journey of learning about asthma a little easier.\nSpirometry is a test used to diagnose asthma and other lung conditions in adults and in children over the age of 6. It measures how well a person can breathe in and out using a device called a spirometer. Different measurements taken during the test to show how well the lungs are working. It is usually quite a straightforward test that takes around 10-20 minutes.\nA study in the US found almost half of parents surveyed didn’t completely understand what type of asthma medication their child was taking or how often they should take it. A little alarming, but understandable. Before asthma affected your life, you probably thought the only asthma medicine that existed was the one that comes in a blue puffer.\nThe two main types of asthma medicines are relievers and preventers. These are usually delivered using metered dose inhalers (MDIs) and are also known as puffers.\nReliever medicines for asthma are from a group of medicines that are known as bronchodilators. The inhaler devices for these medicines are usually blue or grey. These medicines work by relaxing the muscles that tighten up around the airways (the bronchial tubes) that carry air to the lungs, and opening the tubes up to allow more air into the lungs. Reliever medicines act fast - within about 4 minutes - and keep the airways open for up to 6 hours after use.\nThey do not, however, treat the underlying inflammation caused by asthma. This is why reliever medicines are only used for short-term relief of asthma symptoms and in an asthma emergency. If your asthma is well-controlled, you should not need to take your reliever medicines more than once or twice per week, not counting before exercise.\nPreventer medicines are a part of long term asthma management for most adults and some children. Inhaled corticosteroids are the most commonly used group of preventer medicines. This type of medicine reduces inflammation in the airways to reduce a person’s risk of a severe asthma flare up. The inhaler devices for these medicines are usually brown, orange, rust or yellow.\nThere are many different medicines and brands used to treat asthma in Australia. One way to break it down is to think about active ingredients vs brand names. The active ingredient is the chemical in a medicine that makes it work. A medicine can have more than one active ingredient, and medicines with the same ingredients are available under different brand names. For example, Ventolin, Asmol and Airomir are different brands that have the same active ingredient of salbutamol.\nYou may have seen the chart below on the wall of your doctor’s office (if not, they can contact us to get one!). It shows the asthma medicines available in Australia by category.\nThere are also combination medicines. These are preventer medicines that include a second medicine in addition to the inhaled corticosteroid to help control symptoms better. Your doctors’ recommendation of preventer medicine will depend on the severity of your asthma symptoms and other factors. The most important thing is that if you've been given any sort of preventer, you should take it every day - even when you have no symptoms. But the medicine should be prescribed at the lowest strength that works for you or your child; there’s no extra benefit in taking medicine that is stronger than you need.\nDon’t be troubled by the term ‘steroid’. We’re not talking about the bodybuilding kind! The corticosteroids in asthma preventer medicines have been used for many years, so there is a lot of reliable information available about possible side effects. There are also non-steroid preventer medicines available.\nPrednisolone (also known as prednisone), is the active ingredient of a group of corticosteroid medicines that are given orally as tablets or syrup. These medicines are only used for a short period of time to treat severe asthma or in the case of a major asthma flare up.\nA nebuliser is a machine that changes liquid medication into a vapour. Pressurised air is pumped through the liquid to form a fine mist, which can then be breathed in through a mask or mouthpiece.\nThe use of spacers over nebulisers for ongoing asthma management has long been a hot topic. A lot of research has been done in this area. There is a strong evidence base that using a puffer with a spacer works just as well as a nebuliser for treating asthma, including during a flare-up. Using a puffer with a spacer is also easier, cheaper, more portable and reduces the potential for side effects.\nNebulisers are still used for treating severe or life-threatening asthma, usually in a hospital when more than one treatment is needed at the same time, or for people in certain circumstances. This may be someone who has other complex conditions besides asthma.\nIf you’d like some more help in deciphering anything to do with your medicines, ask your doctor or consider visiting your local chemist. Your community pharmacist is often easily accessible and will be able to answer many of the questions you may have about your asthma medicines and your asthma management plan.\nIn Part 2, we’ll work on demystifying your ongoing asthma management."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:5318eae2-3057-4380-a51e-0421a1d48ea5>"],"error":null}
{"question":"With the rising importance of workplace safety and sports regulations, how have traditional aggressive techniques evolved over time in both loading dock operations and defensive football plays, and what safety measures are now required in both contexts?","answer":"In football, dangerous techniques like Deacon Jones' head slap move targeting the helmet have been banned by the NFL, though modified versions targeting shoulder pads are still permitted. Modern defensive ends now rely more on controlled techniques like the speed rush, spin move, and forklift move. Similarly, loading dock operations have evolved to prioritize safety through mandatory measures like proper forklift operator certification per OSHA regulations, carbon monoxide alarms, safety nets across dock edges, wheel chocks for trailers, and clearly marked routes for traffic. Both fields now emphasize proper training, awareness, and preventive measures to protect individuals from injury.","context":["Free Defensive End Techniques\nIn football, no position on the defensive side of the field might be as important as the defensive end. The defensive end can alter the course of the game and change the opponent's strategy if he can pressure the quarterback. The defensive also must be able to stop the run consistently.\nThe speed rush is one of the most explosive moves a defensive end can have on the football field. If the right defensive end lines up 2 yards outside of the left tackle and has a burst of speed, he might be able to get to the quarterback before he completes his setup in the pocket. In order to perform this move, the end must dip his inside shoulder and get it underneath the left tackle who is attempting to block him. Once you are even with the tackle, you stay low until you are within one step of the quarterback and then you drive your shoulder into his chest.\nIn order to confuse the offensive tackle, an athletic defensive end can perform the spin move. With this move, the defensive end will take two steps toward the quarterback and then when the tackle engages him to block, the defensive end spins 360 degrees to keep the offensive tackle from blocking him. This move might make the offensive tackle lose his bearings and could leave the defensive end with a clear path to the quarterback. This was the favored move of Hall of Fame defensive end Bruce Smith, who played for the Buffalo Bills.\nThis move is for defensive ends with dominating strength. When you perform the forklift move, you want to take an explosive first step into the chest of the offensive tackle. As you make contact, you extend your arms in an explosive upward move to lift the tackle off the ground. This is similar to the way a forklift works in a factory. If you do this on a running play, you can drop the tackle into the path of the oncoming running back. If you do it on a passing play, you might be able to toss the blocker at his own quarterback. This was the favorite move of Hall of Famer Reggie White, who dominated the game with his strength while playing for the Eagles and the Packers.\nThis is a derivation of the head slap move that was perfected by Los Angeles Rams defensive end Deacon Jones during the 1960s. Jones would slap the helmet of the opposing offensive tackle with his left arm and then his right arm and run by him after the tackle lost his balance. While the head slap is no longer legal in the NFL, defensive ends use the move on the opposing tackle's shoulder pads to drive him off balance. This gives the defensive end the edge he needs to get to the quarterback.\nSteve Silverman is an award-winning writer, covering sports since 1980. Silverman authored The Minnesota Vikings: The Good, The Bad and The Ugly and Who's Better, Who's Best in Football -- The Top 60 Players of All-Time, among others, and placed in the Pro Football Writers of America awards three times. Silverman holds a Master of Science in journalism from the Medill School of Journalism.","Four Loading Dock Dangers and Precautions for Prevention\n\"Every day in America, 12 people go to work and never come home. Every year in America, nearly 4 million people suffer a workplace injury from which some may never recover. These are preventable tragedies that disable our workers, devastate our families, and damage our economy. American workers are not looking for a handout or a free lunch. They are looking for a good day’s pay for a hard day’s work. They just want to go to work, provide for their families, and get home in one piece.” – Secretary of Labor Hilda L. Solis, Workers Memorial Day\nLoading Dock Dangers\nLoading docks are the behind-the-scene settings for essential operations of businesses everywhere. Yet they are, by no means, exempt from their fair share of accidents and injuries. “Twenty five percent of all industrial accidents occur at the loading dock.”2 And for each accident, there are about 600 near misses.3 Loading docks are flooded with potential danger, and without the proper training, procedures, equipment and maintenance they are liable to deliver disaster at every turn. What is the best defense against such a threat? Knowledge. In order to prevent accidents and injuries, you must first be aware of the hazards and the precautions you can take to create a safe working environment. This article will survey four of these hazards and the steps you can take to prevent them from occurring.\nBy far, forklifts present the most danger on a loading dock. They are large pieces of machinery that can cause considerable amounts of damage if the proper precautions are not met. A study conducted by the National Institute of Occupational Safety and Health revealed that every year, over 94,750 Americans are injured by forklifts.4 They can tip over, pin people, and fall off the edge of loading docks, to name a few of the more frightening mishaps. Forklift accidents cost a company in many ways that are not at first apparent. Some of these costs include:\n- equipment damage\n- building and property damage\n- product damage\n- production delays\n- an injured employee’s compensation\n- the cost to hire and train a replacement for the injured employee\n- potential OSHA fines\n- potential lawsuits\n- loss of time and efficiency, and the reputation of the company5\nAside from these hefty expenses, there is a greater cost to consider: the health and safety of employees. The following story unfortunately illustrates the seriousness of forklift accidents:\nOn August 30, 2002, a 39-year-old male forklift operator was fatally injured when he was crushed under a fallen forklift. The victim was a full-time forklift operator at a company that manufactured wooden pallets. At 2:48 p.m., the victim was using an 8,600 pound forklift to move waste material into a large, drive-in waste dumpster positioned at the company’s outdoor loading dock. The victim had apparently just dumped the waste and was backing out of the dumpster when he backed off the side of the loading dock, falling 3 feet 9 inches to the asphalt. He was partly thrown from the forklift and was crushed under the lift’s rollover cage. He was taken by helicopter to the area trauma center where he was admitted with injuries to his hip and leg. Despite treatment, he suffered complications related to his injury and his condition deteriorated. The victim died at the hospital on September 9, 2002, nine days after the incident.’ 6\nThe means to avert such needless tragedies are both simple and cost effective. First of all, forklift operators should be fully trained and certified according to OSHA regulations. Likewise, when a forklift is running, the operator needs to be wearing a seatbelt. Another safeguard that could have saved the life of the man mentioned above, is for employers to provide a barrier across the edge of a loading dock, such as a safety net. Additionally, a provision that cannot be overlooked is the routine maintenance of forklifts. These precautions are the solution to a very real and present threat lingering around each and every forklift.\nTrailer creep is when, through the back and forth process of loading and unloading a truck, a gap is slowly widened between the trailer and loading dock. This can happen because of the constant shifting of weight going on inside the trailer. A gap harbors limitless accidents just waiting to happen. The first safety measure you want to take is to place wheel chocks behind the trailer’s back wheels, or you could put a hook on the back axle of the trailer. These are rudimentary means of prevention that must be in place. Secondarily, a dock leveler can be employed. Dock levelers act as a bridge between the trailer and dock to create a smooth transition between the two. Also, be sure to have the driver of the truck sit in a waiting area while employees are working the trailer. This will prevent any misunderstanding resulting in the driver pulling away from the dock while there are still employees or equipment in the trailer.\nCarbon Monoxide Poisoning\nCarbon monoxide is a colorless, odorless gas that can build up in the air when fuel is being burned in a poorly ventilated area. Excessive amounts of carbon monoxide are hazardous and potentially lethal to everyone in the vicinity. The first and easiest preventative measure to take is to be sure that a truck’s engine is turned off when loading or unloading is taking place. Additionally, use electric machinery, such as forklifts, as an alternative to machinery that runs on gas. You should also ensure that the loading dock is a well-ventilated area to diminish a hazardous accumulation of the gas. One of the most important steps to take when seeking to prevent carbon monoxide poisoning is to utilize well-maintained carbon monoxide alarms. These alarms work much in the same way as fire alarms do and are vital because they are the only way one can be warned of a deadly build-up of this noxious gas.\nSlips, Trips, and Falls\nSlips, trips and falls are the most common among accidents to take place at a loading dock, but they are no less dangerous. Loading docks are a high traffic area. With all the hustle and bustle of personnel and machinery, in addition to the clutter of pallets stacked with product, mishaps are bound to occur. Once again, there are very simple ways to restrain these accidents waiting to happen. Primarily, work to keep the loading dock clean, organized and free of clutter. The floor should be clear; everything should have its place, rather than be left out for employees or forklifts to run into. Have clearly marked routes for forklifts and personnel to cut down on confusion and traffic. Working in a dimly lit area is another factor that can lead to slips, trips and falls, so be sure to have sufficient lighting both on the loading dock and inside the trailer that is being worked in. When a trailer is not at the dock, you can place a safety net across the edge of the loading dock to keep employees and equipment from falling off the edge. It would also be wise to highlight the edge of the loading dock with a bright paint to make it clearly visible to all who approach.\nYou have now taken the first step to create a safer working environment by equipping yourself with the knowledge of the hazards of a loading dock. The above mentioned precautions will greatly aid in promoting safety, but the most important accident prevention of all may be the most overlooked: awareness. Everyone on a loading dock needs to have the proper training and procedures to follow. They must be familiar with the environment and alert to everything that is taking place around them. Attentiveness and a careful attitude go a long way in creating a safer atmosphere, which is one of the best ways to protect personnel, product, and equipment. It is as they say, “An ounce of prevention is worth a pound of cure.”"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"}],"document_ids":["<urn:uuid:15d42b06-c70c-4cbe-abef-ac58c7ac6beb>","<urn:uuid:ab1b20a1-1d69-49d3-af68-b95a9bdc2148>"],"error":null}
{"question":"I enjoy outdoor navigation: how do the trail markers and navigation challenges differ between Snow Lake trail and Upper Snowbird trail?","answer":"The Snow Lake trail is well-marked with clear trail junctions and signage, including marked trails like #1013 and #1012, making navigation straightforward. In contrast, the Upper Snowbird trail presents significant navigation challenges, with poorly marked trailheads, critical unmarked forks (where taking the right fork is essential), and the need to count larger stream crossings to find the correct turn marked by orange flagging tape. Some sections of the Snowbird trail even seem to disappear temporarily, requiring careful attention to direction.","context":["Get full access to Outside Learn, our online education hub featuring in-depth fitness, nutrition, and adventure courses and more than 2,000 instructional videos when you sign up for Outside+ Sign up for Outside+ today.\nStart at the Alpental ski resort parking lot, and you get a sense of what’s in store for you, as the surrounding peaks here rocket skyward, giving one the sense that you’ve left the state of Washington for more distant, famous peaks, perhaps even the namesake of the local ski resort, the Alps. The mountains here are more vertical, but don’t let that fool you, for the elevation gain here is moderate. After filling out your backcountry permit at the trail head for Snow Lake #1013, start the gentle climb up to Snow Lake, along a shaded forest trail with occasional openings across large talus fields of granite. These openings give you wide open views of the surrounding peaks along the route. At 1.7 miles in, you reach your first trail junction, at the Source Lake trail. Stay right here, and begin your first uphill switchback to reach your first saddle before dropping down into Snow Lake. It’s appx. .6 miles up, and a little over 530ft of elevation gain, across steep rocky terrain, mostly in the open, so during hot summer days, you’ll want to tackle this in the morning. Once at the top, you get your first views of this side of the area, and Snow Lake below, is beautiful! Deep turquoise waters surrounded by granite cliffs and small meadows full of alpine firs. This is all visible, with distant views of other mountain tops. Drop down into the Snow Lake basin at 2.8 miles in, and pass the campsite trail which veers off to your left. If you desire, you can continue on the campsite trail as it will re-join the main trail on the other side, so you can see the different sites available. Just past the campsites, you’ll get an awesome opportunity to take a quick break, and view the lake from the best viewpoint, a rocky bluff overlooking all there is to see here, including hulking Chair Peak, that keeps a watchful eye on the lake below, also providing the necessary shade to keep the namesake snow fields from melting out. Stow your camera, and continue along lakeshore to your next junction, at 3.32 miles, and turn left and follow the signage for Gem Lake, trail #1012, your next lake destination. The trail continues upward from here, and you will remain in the open, following the stair-stepped little meadows up to Gem Lake. There is no shortage of talus fields on this hike, and you will cross many large ones on the way to the lake. Once at Gem lake, you’ve reached your highpoint, at 4922ft. There are several campsites here, and you can tell that this place is heavily used, little trails running everywhere, but it’s not surprise. The views here are spectacular, and the lake is a destination all to itself. Small and compact, it sparkles in the midday sun, vanquishing any doubts as to why it was so aptly named. The peaks here are dramatic, like spear points piercing the sky, ominous and inspiring all at the same time. They remind you of the famous pictures we’ve all seen of the Alps, the only thing they’re missing is the snow caps on top. You’ll want to take some extra time to follow some of the well worn paths here that lead you to big views of the surrounding peaks and valleys. I waited until my return trip to wander around the banks here, for I wanted to make sure that I would be able to secure a spot at the upper lakes. The trail rounds Gem Lake here, and then once on the other side of the lake, drops down across a steep mountain side. Again, it’s fairly open here, broken up by sparse old growth, and the valley and mountains here will cause you to pause, and marvel at the ruggedness and beauty that is spread out before you. From this vantage point at the beginning of the downhill, you can see distant Mt. Roosevelt, and know that at its base, is where your destination for the day is at. The hillside is steep, but the switchbacks do a good job of getting you down with minimal effort, it’s about 713ft loss in ¾ of a mile. At the bottom, you’ll cross a meadow, then a small stream at the beginning of another large talus field. After crossing the talus field, the trail skirts lower Wildcat Lake, and officially ends at the lake shore, where you’ll find one lone campground at 6.62 miles. At the last stream crossing, you can see where people have camped as well, where the ground is flat and cleared out. Here around the lake there is an abundance of Huckleberry brush, and tree cover. The lake here, after all you’ve seen so far, is a bit of a disappointment, but don’t despair! Just to the right of the campsite here, you can see a faint trail after crossing the outlet stream that runs uphill to Upper Wildcat Lake. It’s only about another 15 minutes on a faint path through overgrown Huckleberry brush to the lake, and it’s well worth the effort. This trail is not on any map, but can be fairly easily followed. Once you get to Upper Wildcat, there are at least 3 campsites that are good for 3 person tents. The first, and most obvious, is right at the water’s edge as you reach the lake, and is by far the best site, large enough for at least two tents. Continue to follow the faint trail on the right bank, and you’ll see a site about 50 feet up in the forest, nice and flat, and another below it, next to the water’s edge, that has a nice accessible sandy beach. The water is cold, but inviting, especially on a hot day. This too, is a beautiful lake, filled with trout, and on the opposite side of the lake is Mount Roosevelt, providing a dramatic backdrop to the lake. It also has a small tree covered island in the lake, and everywhere there is a foothold in the steep granite here, you will see small alpine trees eking out a living. Another benefit to the way this lake is set up, is the trees that line this eastern shore, seem to provide good shelter from the wind that blew the entire time I was here. You could hear it pushing it’s way through the upper ring of trees and see it ripple out in the middle of the lake, but never felt it’s effects here, only a slight breeze. Although not that many people come to Upper Wildcat to stay, you definitely want to get here early, so you can claim your spot. Snow Lake is a heavily used lake, mostly by day hikers, as it’s a beautiful destination close in. Once viewing it yourself, you will be able to see why so many make the trek here.\n- Distance: 23.0\nLocation: 47.444923, -121.423561\nPark here at large parking lot at end of road, to your left.\nSnow Lake trl#1013\nLocation: 47.445518, -121.423325\nStart of trail, here you will fill out a backcountry permit.\nSource Lake Overlook\nLocation: 47.458183, -121.447853\nTrail junction here. Stay Left, and follow the trail uphill.\nSnow Lake Saddle\nLocation: 47.460144, -121.446968\nTop of the saddle, where you drop down into Snow Lake Basin\nRocky point View\nLocation: 47.466076, -121.44854\nA great place to stop and take pictures of the lake. Best view spot.\nGem Lake Junction\nLocation: 47.468513, -121.448067\nStay left here, follow signage to Gem Lake, and trail #1012\nLocation: 47.475998, -121.464546\nLocation: 47.477345, -121.468735\nSwitchback begins here, descending to lower Wildcat lake.\nLocation: 47.479244, -121.473747\nSwitchback ends here in small meadow.\nLocation: 47.47821, -121.476112\nA stream crossing here with small waterfall, and begin crossing large talus field.\nLocation: 47.484825, -121.482109\nOnly one small campsite here, at end of trail. look for trail continuation to your left\nLocation: 47.486759, -121.487442\nLocation: 47.487476, -121.487709\nLocation: 47.474342, -121.465767\nA worthwhile side trip, to see the valley and mountains here. Also, can look down upon Snow Lake from here.\nLocation: 47.444575, -121.423516\nParking lot at Alpental Ski Area.\nLocation: 47.445562, -121.423087\nTrailhead sign for Snow Lake Trail #1013\nLocation: 47.452411, -121.434546\nLooking west towards Bryant Peak, and Chair Peak. Moon is still visible over the mountains.\nLocation: 47.460594, -121.446133\nAs seen from the saddle, before dropping into Snow Lake Basin.\nLocation: 47.465816, -121.447849\nFrom the view point, looking at NW end of lake. Can still see the snow fields that feed the lake, in mid September\nLocation: 47.467151, -121.447935\nMore views from the banks of Snow Lake\nLocation: 47.470908, -121.455274\nViews from the trail across Snow Lake to Kaleetan Peak.\nLocation: 47.474418, -121.465917\nThe shark fin is Kaleetan Peak, as seen from Gem Lake viewpoint\nSnow Lake birds eye\nLocation: 47.474331, -121.465487\nFrom the viewpoint at Gem Lake, looking down into Snow Lake\nLocation: 47.477841, -121.464629\nGem lake and the surrounding peaks.\nLocation: 47.479233, -121.470315\nJust some of the views available on the steep switchbacks coming out of the valley\nLocation: 47.479349, -121.47716\nJagged peaks that supply ample talus to the valley below.\nLocation: 47.480233, -121.47819\nJust a small pond along the way to Lower Wildcat, that acts as a mirror.\nLower Wildcat Lake\nLocation: 47.484743, -121.48201\nView of the lake, as seen from the single campsite at end of trail.\nUpper Wildcat Lake\nLocation: 47.487339, -121.487653\nMorning provides the best light for reflecting Mt. Roosevelt off the surface of the lake.","Hike into the Upper Snowbird from the Hooper Bald parkinglot on the Cherohala Skyway. The Upper Snowbird has fourwaterfalls in between sections of class III whitewater. Theriver then changes into class IV whitewater for the last few miles. Three of the waterfalls can be found in most senicwaterfall books and are labeled on most maps. Upper falls is along slide, Middle falls is a 22' riverwide drop, Big falls is a series5 or 6 small slides ending with a 10' drop, and the last waterfall (which is not labeled on the map) is a 4' drop directly on to a 20'slide. If you are in the area and everything else is too high this will be a good run.\nSnowbird is by far one of the best runs in the southeast. It has all the elements of a truly long, expeditious paddle which passes through multiple styles of SE rivers all set in a hard to reach area of WNC. It includes probably 1 mile of mank, followed by 2 miles of class III micro-creeking, after that a section of 4 class IV+ waterfalls, followed by about 4 miles of continuous class III-IV boogie water to the takeout.\nThe takeout for upper snowbird is at the end of Big Snowbird Road near Lake Santeetlah. Park in the obviously large gravel parking lot at the end of the dirt road and from here you can get a good look at the river by hiking about 50 yards down the trail to a bridge. If the creek is raging (no/few visible rocks) from the takeout/bridge then the upper section will be running. Just keep in mind rain could still make this rise or drop out quickly and you have about 2 hours of driving and hiking before putting on the river.\nAt this point you can consider a couple of options regarding shuttle:\n1) From here you do have the option to hike your own shuttle, big creek style. There's a trail that parallels the creek on river left all the way up to the top. The waterfalls are 4 miles up so this would be a long hike in but you could walk a shorter distance and enjoy continuous class III-IV boogie water and make the lower section longer.\n2) With snowbird, It is certainly an adventure just getting to the put in and involves careful navigation. It will also require carrying your kayak and gear 2.5+ miles on poorly maintained trails.\nIf you elect to hike down from the top, start off by taking the Cherahola Skyway to the parking lot for Hooper Bald. Begin your hike with the trail to the right of all the signage in the parking lot. You'll hike for about 100 yards and come to a gravel road with a gate on your right. Turn right onto the road and head down. BE DISCREET as you hike because there is surrounding private property and you'll need the road to get access to the trailhead. After a little bit, the road will fork. Be sure to take the right fork. Continue down until the road turns to dirt and there is a house a little ways in front of you. Off to your right will be signage for the trailhead (Snowbird #64). This is the start of the long trail section of the hike and is where things can get interesting if you're not careful with your directions.\nContinue along the trail and be conscious of the number of \"streams\" you cross. Along the way, there will be multiple streams you cross but you're only keeping track of the significantly larger ones. After you've crossed 2 of these larger streams, be on the lookout for a trail going off to the left marked with a bunch of orange flagging tape. This trail was after a steep uphill section and was about 2 miles into the hike.\nFrom here you're getting close! As you follow this trail, you'll come across a few sections with multiple trees and logs laying in the path. It seemed like the trail disappeared for a small portion of this section but it was obvious which direction to head. After about a mile or so of heading downhill through slick mud and ducking under oak trees, you'll eventually reach an intersection with a well marked sign and snowbird creek!\nAs tempting as it may be to put on here after a long hike, Snowbird Creek will only be a small stream and you'll have to continue down the trail. Once you reach a tributary coming in from your left. Take a sigh of relief as you've made it to the actual put-in and the boating begins!\nThe character of the put-in tributary will be the character of the river for the first mile or so of the run. There was one portage early in the run but it was obvious and we easily walked down a side stream on river left. After you've passed this, continue to bounce down the mank knowing that reinforcement flows are coming your way. You'll pass multiple tributaries as you head down, each one delivering it's share of water and making the creek more navigable the further you go downstream.\nThe mank will begin to fade and the river will slowly begin to widen, resulting in a few 2-3 foot ledges and slides. Approximately one mile in is where the first big rapid of the day comes up. The high flow made the ride down this bad boy very cushy and controllable but provided little to no eddies above it, causing us to route it blind. Everything was good to go and we ran it right down the middle, ending in a nice boof into the pool below. I’d describe it a similar slide to rapid transit on the green.\nThe river will begin to mellow back on the gradient after the slide, making it seem like a weirdly placed feature. For our high flow day, this part became continuous in nature but nothing more than class 2. Approximately ¾ of a mile past the slide, the river will make a slight bend to the left and a horizon line will develop resulting in a small series of boat scoutable ledges that can be run down the left. Continue past these and after 150 yards look for the river to make another left hand bend and grab the large eddy on the right. Just downstream is another big horizon line and the tallest waterfall of the day!\nStart at the top by navigating the boogie water and keeping the general game plan of staying right. The first feature you will approach is a diagonal ledge hole that tends to typewriter you to the left. The 22’ vertical drop is immediately after this. The drop can be run almost anywhere but there is a sweet autoboof right of center. If you aim right of center off the lip, look for the rooster tail, which can launch you if you hit it just right. All in all, it’s a clean line into a big pool and quite the sight to gaze at after running it.\nFor the next few miles the river goes back to it’s continuous class 3ish nature. Somewhere in this stretch we encountered a river wide log that was hanging above the water (it came into view around a left hand bend). There’s an eddy to catch on the left and you can duck under the far left side of it. After this, the river begins another bend to the left and few slots form in the river. With the high water we were able to get through the left slot, but at lower flows it may be more feasible to run it down the center or right.\nA little while later, the river will form another horizon and signal the third big drop of the run. This one has the trickiest and longest lead-in of the 4 big drops. You’ll start out by punching and boofing over multiple ledges which will culminate into a double drop (1st drop 7ft, second drop 12ft) There is an eddy on the left after 1st 7ft drop. The 12ft drop is best run left of center to avoid the stronger side of the hole on the right. The second drop also has an autoboof on the far left but lands in green water in an eddy. The lines might change at a lower water level\nVisible from the bottom of the 12 footer is the horizon line for the last big waterfall of the day. Grab an eddy on the right and crawl through the rhodo to scout. This last waterfall (around 25ft) is a broken/stair stepped slide down the left side of a large drop.\nWater level will definitely dictate which entrance lines will open up for this one but the game plan is all the same. One way or another you’ll want to run this down the left side. At higher flows you can take the far left side setting you up perfectly for the slide and the eventual 8 foot boof at the bottom of it. Lower flows may have you enter from the middle, heading left through a slot and turning hard to the right. This one also has a lot more eddy service at lower flows and can make the boat scouting a lot easier.\nThis drop concludes the larger rapids of the day and is your marker for approximately being halfway down the river. From this point on for the next 3.5 to 4 miles the river begins to move in a continuous flow, meandering in and out of class 3/4 rapids and slides along with the occasional log & branch duck. A 4 foot boof (somewhat similar to Tanner’s boof on Tallulah) is a signal to be on the lookout for an eventual river wide tree strainer, 4 feet in diameter. THIS IS A MANDATORY PORTAGE! As soon as you see it, grab an eddy on the left to use the trail. If you eddy on the right it will result in the classic southeastern rhododendron suffer-fest portage.\nShortly after this, you’ll continue downstream and be greeted by the familiar bridge from which you started your day many hours ago. Be vigilant about catching an eddy here if it’s a high flow day as lower snowbird starts right after the bridge.\nUpper snowbird is quite the adventure for anyone looking for a sweet wilderness run. This creek offers every logistical skill required for an epic trip and shouldn’t be taken lightly. If your lucky to go with someone who’s been down before, it’ll make a world of a difference in your experience (it certainly did for us). Having the right map, beta, stamina, gear, and crew will make all the difference in making this run some of the best 8 miles of whitewater you can paddle in the southeast!\n-Emory Klesick (2/12/2018)\nsnowbird info New [add to watch]\nRe: Some questions on Treemont, Ranses cascades, Snowbird creek (in the smokies) otto New\nDate: Feb 04 2004, 21:13 GMT\nI ran snowbird by hiking down from the skyway...first of all if you do this start out EARLY..it takes forever, and you'll need ALOT of water\n2nd ...the trail head on the map isn't clearly marked when you get there and takes a little work to find out where you need to go\nonce you figure out that you are hiking in the right direction its a long walk..several miles before you reach the creek..then a little longer before it becomes large enough to put on. (you'll step over it a couple times while you descend the trail)\nyou'll paddle alot of flat stuff before reaching the falls..you'll wonder if you are on the right creek\nthe waterfalls and slides are GREAT!!!! pretty big and challenging.\nthen the creek turns into continuous fun class three/four stuff...we got screwed by nightfall and had to hike out and missed the last half mile or so....\nif I were to do it again and had a medium level at the takeout...I'd hike from the bottom until I reached the big river wide 25-30 footer, and put on above it (it would be a long hike, but an obvious and straightforward trail)...you won't miss much except for a slide or two, but you'll spare yourself the hike in from the top, and alot of work. When the bottom half is running medium the top half won't have much water (tributary effect) and won't be worth the effort (you'll scrape over alot of stuff)...\nNOW if the lower is really high...THEN I would consider hiking in from the top and catching the waterfall section, because then it would probably be at a good level. However the lower sections might get kinda out of control and force you to get off and have to hike out...or you could run out of daylight like we did, so make sure you start EARLY..it takes much longer than it looks like it would from reading the map...especially if you have to scout.\nall in all..I'd probably just hike up and put on when you get tired of walking\nwant more info..email me (and if you do it..keep your eyes peeled for a small black pelican box....)\nLots of rain is needed for this run.\nPermits are not required for this reach.\nWe have no additional detail on this route.\nUse the map below to calculate how\nto arrive to the main town from your zipcode.\nBoof and Shake\nIf someone gets hurt on a river, or you read about a whitewater-related injury, please report it to\nAmerican Whitewater. Don't worry about multiple submissions from other witnesses, as our safety\neditors will turn multiple witness reports into a single unified accident report.\nLog into the American Whitewater website and you can contribute to river descriptions,\nflow and access tips, and maps associated with runs you've done. You can even add new\nruns to the inventory!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:3d663dad-256f-4b88-b67e-120e0228bfd1>","<urn:uuid:184c363b-3011-4484-8e4a-fdccbaff07be>"],"error":null}
{"question":"How does the microbiome protect us from diseases?","answer":"The microbiome protects us from diseases in several ways: 1) It competes with harmful invaders for resources, effectively starving them out. 2) It secretes antimicrobials and toxins to kill invaders. 3) It neutralizes toxins from pathogens by creating proteins that bind with them. 4) It can target specific harmful microorganisms without harming beneficial ones. 5) It produces chemical warnings that stimulate our immune system to produce antimicrobial peptides before an invasion occurs.","context":["Our Several Trillion Closest Friends\nAmericans today are germaphobic. We scrub, spray, and anoint ourselves with various antibacterial substances, and take antibiotics for nearly every illness. We believe that most illnesses are caused by germs, so that the more germ free we become, the healthier we’ll be. This mindset is not only misleading, but downright dangerous.\nBacteria, archaea, fungi, single celled eukaryotes and even viruses that live on and inside of us make up the collection of microorganisms known as our microbiome. They live on our skin, in our orifices, and the largest population dwells on the linings of our digestive system. A normal healthy individual houses at least as many microbial cells in and on the body as there are human cells. Our microbiome not only lives peacefully with us, but is vital to our health. Scientists at the National Institute of Health’s Human Microbiome Project, recognizing this vital role, are calling our microbiome “the other human genome.”\nFor the last couple of decades, the microbiome has become the focus of intense scientific study. The findings have been profound in their implications. The microbiome impacts our health in every conceivable way. It aids in development during the formative years, helping to create a strong immune response. It controls the rate of digestion, so that healthy fruits and vegetables are given more transit time for digestion in the gut. The micobiome plays a key role in digestive function, particularly by breaking down the insoluble fiber that our bodies are incapable of digesting, and supplies our bodies with vitamins, short-chain fatty acids like Butyrate, Propionate and Acetate along with other vital metabolites. These important products circulate throughout the body to maintain healthy bodily function. In fact, our bodies cannot function normally without these products.\nThough it is true that infections and some diseases are caused by microscopic invaders, it is also true that our first line of defense against these invaders is the collection of microbes that normally dwells in and on our bodies. They not only compete for the same resources with the unhealthy invaders effectively starving them out, but our microbiome secretes antimicrobials and toxins to kill the invaders.\nIn addition to directly impacting the proliferation of pathogens, our microbiome is also capable of neutralizing toxins that are excreted from invading pathogens, by creating proteins that bind with the toxins to render them harmless. They can target specific microorganisms in order to wipe out an invader without harming neighboring beneficials. They can even produce\nchemical warnings that stimulate our immune system to produce antimicrobial peptides in time to ward off an eminent invasion.\nAt birth the child is exposed to a living film of protective organisms as it passes through the birth canal. The medical community is now learning that a caesarian birth puts a newborn baby at a distinct disadvantage by losing out on this early inoculation of symbiotic organisms. Such deficiency has been linked to incidence of asthma, allergies and other health conditions in children. In order to make up for this deficiency in exposure some doctors have tried smearing the newborn with a swab of its mother’s vaginal secretions in order to replicate the normal introduction to the mothers fauna.\nNursing the baby rather than feeding formula can also help alleviate the conditions caused by an insufficiently diverse microbiome, since it exposes the infant to the organisms living on the mother’s skin as well as to any organisms that thrive on human breast milk. The mother’s instinctive touching, cuddling and kissing her infant also allows her to share her beneficial organisms. In fact, even having a family dog has been shown to create a more resilient microbiome, so that children who share a home with a dog are less susceptible to asthma and allergies.\nAs the child continues to grow, and throughout adulthood, the microbiome aids in the development and continued functioning of the immune system. It produces metabolites that stimulate production of immune cells in the bone marrow. It communicates with lymphocytes to establish a system that can distinguish between friend and foe. It even has an impact on gene expression, encouraging the production of anti-inflammatory substances and inducing protective intestinal immune responses. Research in these areas is still in its early stages, but it is becoming quite plain that our microbiome plays a key role in immunity.\nDysbiosis—The Enemy Within\nThe particular variety and balance of microorganisms in our system is known as our Enterotype. One of the more important goals of the Human Microbiome Project is to understand the difference between the type and diversity of organisms in a healthy person and those who are suffering from various diseases. It is clear that, though there is a diversity in enterotypes of healthy individuals, similar clusters of organisms in populations of people have been identified. In like manner, similarities can be identified between people suffering from the same illnesses. One prominent characteristic in the enterotypes of individuals suffering from various chronic illnesses is a lack of diversity in organisms. Another similarity is the prevalence of Bacteroidetes, which thrive on the digestion of animal based products, and the reduction in number of Firmicutes, which thrive on the fiber found only in plant sources.\nDysbiosis—defined as disruptions in the microbiome characterized by reduction in diversity and dominance by unhealthy organisms—has been linked to many chronic illnesses including diabetes, heart disease, Crohn’s Disease, Irritable Bowel Syndrome, obesity, cancer and even mental disorders such as Alzheimer’s Disease. A multitude of studies have shown that interactions between the immune system and the microbiome play a decisive role in diseases or in their prevention. It has even been suggested that individual characteristics of disbiosis associated with various types of cancer can aid in the diagnosis of difficult to identify cancers.\nWe Are What We Eat\nDysbiosis has complex causes, but relatively simple solutions. The overuse of antibiotics has been linked to the destruction of a healthy microbiome. The prevalence of preservatives in the standard American diet also plays a role in its destruction. Preservatives and antibiotics were created to kill pathogens that can harm our bodies, but their detrimental effects to our beneficial organisms may cause as much harm as they do good. Antibiotic use should be avoided except in cases of life-threatening infection. We can also limit our exposure to preservatives by avoiding processed foods.\nThe simplest solution to dysbiosis is a change in diet. What we eat has the greatest influence on the health of our microbiome. As the China Study demonstrated, those who eat a whole food plant based diet—avoiding both animal products and highly processed foods—avoid the diseases most prevalent in affluent societies. Among indigenous populations of rural China heart disease, diabetes, high blood pressure and Alzheimer’s Disease are nonexistent. Cancers common in our society like colon, breast and prostate cancers are rarely seen. The same has been found among other native populations like those in rural Uganda and Tanzania.\nFeeding our microbiome sufficient quantities of fiber rich foods is the key to good health. The lack of fiber in animal based foods is just one of its unhealthy aspects, but may be among the most crucial differences. Eschew meat, dairy, eggs and fiber poor refined food products. Eat plenty of fresh fruits and vegetables, legumes, whole grains, nuts and seeds. What is good for the microbiome is also good for us.\nIn future articles, we’ll explore the role our microbiome plays in Heart Disease, various bowel diseases (like IBD and Crohn’s Disease), Weight Control, and Mental Health (including Alzheimer’s Disease, Autism and depression)."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:e0779199-27b6-4ec5-9b19-3993440c27a5>"],"error":null}
{"question":"After my car accident, my shoulder hurts but my hip is also painful - could these be connected through fascia?","answer":"Yes, they could be connected. Fascia is one continuous structure that interconnects everything in our body, like a spider's web. Because of this interconnectedness, restriction in one part of the body can affect other distant parts. When trauma occurs, fascia loses its pliability, and these restrictions can produce pain, pressure, and range of motion loss throughout the body.","context":["Any traumatic force to the head can cause restrictions in the dural fascia, as well as the superficial and deep fascia of the head and neck. Restrictions in this area can affect the whole body. Myofascial Release is a technique for the evaluation and treatment of pain and dysfunction. The technique is gentle, and the goal is to restore mobility in fascia and to soften connective tissue that has become rigid. It works very well as part of a comprehensive physical therapy program including therapeutic exercises and modalities.\nFascia is a loose, irregular connective tissue that spreads three-dimensionally throughout the body. It covers the muscles, bones, nerves, organs, and vessels. It consists of four layers:\n• Subcutaneous - continuous layer over the entire body between the skin and deep fascia\n• Deep - series of sheets and bands that hold muscles and other structures in place\n• Subserous - lies between the fascia and serous membranes lining the body cavities\n• Deepest - within dura mater of the craniosacral system (cranium, spine, sacrum)\nThe fascia can not be seen on x-rays, CT scans or EMGs. Its functions include support, protection, separation, cellular respiration, elimination, fluid flow, immune system function, and allowing the body to resist mechanical stresses. All structures of the body can be affected when fascial restrictions occur.\nFascia is a system in the body that looks like a spider’s web. It is densely woven over and in every muscle, bone, nerve, arteries/veins, and all of our internal organs. The fascial system can be thought of as one continuous structure that twines throughout our body, interconnecting everything. This provides strength to the argument that everything in our bodies are connected—when one thing is out of whack, multiple things can be affected.\nFascia in a healthy state is relaxed, stretchy, and movable. When one experiences physical trauma, fascia loses its pliability. Trauma, inflammation, and surgeries create restriction in the fascia that can produce incredible amounts of pain, pressure, and range of motion loss within the body. Fascial restrictions affect our flexibility and stability, impeding our every-day activities. The restrictions can be caused by physical trauma or injury, poor posture or structural imbalance, and inflammation or infection. Restrictions can cause limited mobility, postural distortion, poor cellular nutrition, pain, and other dysfunctions. Because of the interconnectedness of the tissue, restriction in one part of the body can affect other distant parts. The fascia also stores memory of past traumatic events. Psychosomatic adaptations may occur, which may cause one to avoid positions which are associated with pain.\nYour therapist will evaluate your body visually and by palpating (feeling) tissue texture. Gentle pressure is applied by slowly pushing, pulling, and stretching the skin. Fascia has the characteristic of thixotrophy, which means it can change from a more solid to a more gel-like state with movement and increase in temperature. Some techniques are:\n• Sustained Stretch - gentle pressure into the direction of restriction, usually with a sliding motion that stretches the tissue.\n• Skin Rolling - gently picking up and pulling skin away from underlying structures. This stretches subcutaneous fascia, breaks cross-links, and makes tissues more pliable."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:435d7435-f2b2-45fa-9f9a-8e77610c9087>"],"error":null}
{"question":"What role does power consumption play in both gaming PC power supplies and display driver boards, and how is efficiency measured in these components?","answer":"Power consumption and efficiency are critical for both components. For display driver boards, they require around 5V @ 500mA and can be powered directly from a USB port, though proper power supply and cable quality (24AWG or smaller) are essential to prevent weird reboots. For gaming PCs, power consumption varies by component, with GPUs being particularly power-hungry (e.g., GTX 1080 Ti uses 250W, while GTX 1070 Ti uses 180W). Efficiency is formally measured in PC power supplies through the 80 PLUS rating system, which certifies conversion efficiency from AC to DC power, ranging from basic 80 PLUS (80%) up to Titanium (90% at full load, 94% at 50% load).","context":["This is our most compact and least expensive driver board. It only has an HDMI input and doesn't have audio.\nThis driver has a scaler built in. That means you can use it to drive an 800x480 display but set the computer to output 1280x800 and it will scale the display down. However, the image will be stretched out (distorted) if the aspect ratio of the scaler doesn't match up. For example, if you have an 800x480 display, the aspect ratio is 1.6 so 1280x720 would look stretched out (1.77 ratio) but 1280x800 would probably look OK (1.66 ratio)\nIt's the same chipset (RTD2660H) as the larger HDMI/VGA/NTSC/PAL driver, so the interface and functionality is the same\nAs it is TTL only, not LVDS, we only have it for our smaller low-resolution screens. Basically, 1024x600 or smaller screens\nThe nice thing about this driver is it is compact, simple, and can be powered directly from a USB port, the power requirement is basically 5V @ 500mA\nTo let the Pi A+/B+ drive a display power over USB, first make sure you have a 2A power supply, with a good quality USB cable, a thin wire power cable is no good. Make sure its 24AWG or smaller, shorter USB cables are better too. Then add\nIf you're getting wierd reboots, its likely the power supply and/or power USB cable is not good enough. A powered hub will also solve this problem\nThe PROG JST connect is generally for factory use only. It's the port we use to program the board before sending it to you\nAll JST connectors are JST-XH type, 2.5mm pitch.\nPower input: 5v USB - current draw depends on the display size a bit, but is basically ~500mA\nEach driver board comes with a few menus of customizable settings. We go through each below, with some helpful pictures, to show you what you're able to easily control!\nThe keypad buttons help you navigate the display menus and sub-menus.\nAs shown in the picture above:\n- key is DOWN\n+ key is UP\nMENU key is SELECT (brings you to the next menu or option)\nAUTO key is BACK\nWhen you first start up, you can use the Auto/Back key to select the input source!\nBrightness - Adjust the brightness\nColor - Adjust the color\nSaturation - Adjust the saturation\nLanguage - There are a full range of language options for your display. They are:\nEnglish, French, Italian, Mandarin, Cantonese, German, Spanish, Japanese, Korean, and Russian\nH Position - Horizontal Position\nV Position - Vertical Position\nOSD Timeout - Adjust the time for the display to go black.\nTransparent - Adjust the OSD (on screen display) menu's transparency against the background image\nReset - Reset settings to factory default\n- 4:3 - compresses image to 4:3 - does not cut off the image!\nSleep - Sleep timer - this will completely shut off the screen at the end of the set time (0-120 minutes)\nBlue Screen - On/Off - This changes the color of the screen on start up when you choose your input\nSharpness - Adjust the sharpness from 0 to 100\n- SYS1 - Makes the text backward from SYS3\n- SYS2 - rotates the screen 180°\n- SYS3 - Default - has screen situated with bottom toward the cable\n- SYS4 - Rotates 180° and makes the text read backward\nPower Saving - 10s to 60s - how long it takes for the screen to shut off\nBurnin - On/Off - a function to prevent screen burn-in","What You Need to Know About Picking a Power Supply for a Gaming PC\nFrom next generation CPUs, to the fastest RAM, to the beefiest graphics cards—if you’re building a gaming PC, chances are you’ve already got your heart set on the latest and greatest PC components.\nBut there’s one more component that often gets overlooked: the power supply. It won’t improve your framerate and it isn’t the most aesthetically appealing part of a build, but without a power supply, your gaming rig is literally dead weight.\nBeginners often make the mistake of settling for a cheap off-brand unit that boasts a large power supply rating. Others might overspend on a larger power supply rating to ensure they’ll have enough juice for their high-end components.\nBut if you’re looking to build a gaming PC that will last, a good power supply is a must. Here’s what you need to know about picking a power supply for a gaming PC.\nHow much wattage do you need?\nIt’s no secret that high-speed circuits such as GPUs and CPUs are energy hogs. Add fans, lighting, and liquid cooling to the mix, and you begin to understand how much energy you’ll need to power your rig.\nYou can find power consumption requirements for different components online from manufacturers or on sites such as Tom’s Hardware. Or you could just use a handy power supply calculator like this one from OuterVision. It lets you build a hypothetical rig by selecting parts from drop-down menus and calculate the recommended wattage for your system.\nHere are some typical benchmarks for power draw requirements for high performance PC components:\nCPU: Intel Core i7-9700K CPU, 95W\nVideo Card: Nvidia GTX 1080 Ti, 250W\nRAM: DDR4 2133 8GB, 3W\nSSD: Samsung SSD 850 EVO 500GB, 4W\nYou’ll notice that the video card takes up a lot of power. Maybe you don’t really need the latest flagship Nvidia GTX Titan series card, and can settle for last year’s model. The Nvidia GTX 1070 Ti only draws 180W. It won’t only save you on the cost of the card, but also the cost of your energy bill and the power supply unit for your rig.\nIt’s not all about size: 80 plus rating system\nBesides the raw power rating listed on a power supply, energy efficiency is another important metric that you’ll want to understand.\nYour GPU, CPU, and other computer components all run off of DC (direct current) power. Your wall outlet only supplies AC (alternating current) power. When your power supply converts AC power from the wall into the DC power used by the rest of the components in your gaming rig, at least some of that energy is lost as heat.\nThat means you’re never getting 100% of the power drawn from your wall. So how do you compare two power supplies that have close to or the same wattage rating?\nEnter the 80 PLUS rating system. It was created to encourage manufacturers to create more energy efficient power supplies. The 80 PLUS rating system certifies power supplies are able to convert more than 80% of the AC power received from your wall into the DC power needed by your components. There are six levels for non-redundant (power) power supplies:\n80 PLUS: 80%\n80 PLUS Bronze: 82%\n80 PLUS Silver: 85%\n80 PLUS Gold: 87%\n80 PLUS Platinum: 89%\n80 PLUS Titanium: 90%\nAll efficiencies were based on 100% of rated load. Efficiencies can be higher at lower loads, as with 80 PLUS Titanium hitting 94% efficiency at 50%.\nBudget for a quality power supply in your wattage range\nWhile it can be tempting to snag deals on power supplies with high wattage ratings, it’s important to do your due diligence and check user reviews, manufacturer reputations, power draw requirements, and energy efficiency ratings. Often times if a deal sounds too good to be true, it probably is.\nThe right way to save money on power supplies is to pick a quality unit from a reputable manufacturer that’s within your required wattage range. Be sure to add enough margin to account for any upgrades you plan to make in the future. Choose the best power supply for your needs.\nAbout the AuthorFollow on Linkedin Visit Website More Content by Cadence PCB Solutions"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:5cd80f87-7dad-4c3c-bf56-f67b69ea58c9>","<urn:uuid:b7d0371e-4029-4226-9649-59e5142a08f8>"],"error":null}
{"question":"Yo fishers! Why should beginners take professional fishing lessons instead of self-learning, and what are the key water safety concerns that make proper training important?","answer":"Professional fishing lessons are beneficial because they provide complete beginners with all necessary equipment, expert instruction from qualified coaches like Stuart (a level 2 angling coach), and structured learning through programs like the CAST awards system, which helps develop progressive skills from basic fish identification to advanced techniques. Regarding safety concerns, proper training is crucial because many fishers engage in dangerous practices like fishing in unsafe waterbodies, using unsafe vessels, lacking appropriate safety equipment, and operating while untrained or fatigued. Professional instruction ensures proper education about water hazards, safety regulations, and essential skills like CPR and rescue techniques, which are vital for preventing drowning incidents.","context":["Welcome to Fishing Adventures\nFishing Adventures offers a variety of different ways to enjoy the sport of fishing. Such as private fishing tuition, fishing birthday parties for children, corporate team building days, Saturday fishing club, school enrichment lessons and fun family events. Based at Manor Farm Lakes in Biggleswade, Bedfordshire, the complex of 7 lakes offers an abundance of coarse fishing for all abilities. Stuart is a fully qualified level 2 angling coach with up to date first aid, safeguarding and DBS checked. Having over 30 years of angling experience he started Fishing Adventures as he now enjoys teaching others who share the same passion for angling.\nPrivate Fishing Tuition\nPrivate fishing tuition is offered 1-1 up to groups of 5. Whether you are a complete beginner or would like to learn more about a specific skill of coarse fishing a private lesson is an ideal solution. All equipment is provided although own equipment can be used if preferred. A great idea for a birthday present, gift vouchers are available.\nSaturday Fishing Club\nRun from April till October.\nEach fishing session is 2.5 hours.\nNo experience or equipment necessary.\nAges 7-16 years old.\nAchieve Angling Trust CAST awards.\nMeet new friends and learn a new hobby.\nCorporate Fishing Events\nFishing is the perfect choice for a team building outing. Firstly, instead of being stuck in the office you’ll be outside by the lakes in Bedfordshire and surrounded by nature. Fishing is a sport that is accessible to everyone, and has a level playing field. There is definitely an element of competition as teams work together to catch the most and biggest fish! Learning skills such as tying a fishing knot, casting a rod and playing a fish can be very rewarding and it can often be the person that least expects it that enjoys fishing the most! Trophies awarded for most fish, biggest fish and angler of the day.\nChildren’s Birthday Parties\nIf you have a fishing crazy child then a children's fishing party is a great birthday idea! No experience is necessary and all fishing equipment and bait is provided. Located in Biggleswade, Bedfordshire and close to Hertfordshire, we can cater for up to 12 children (ages 7-16yrs old), and they will learn how to set up a fishing rod, bait up, cast out and catch a fish! The children will all receive their Angling Trust CAST Starter Award.\nFamily Fishing Events\nWe organise family fishing events to encourage families to continue with their fishing journey. Ideal for families that have already had lessons with us and want to continue practicing, but know that help is on hand if they get into any tangles:)! Fishing equipment is available if they haven’t yet got their own gear.\nSchool Enrichment Lessons\nWe organise fishing lessons for schools in Bedfordshire and Hertfordshire so they can provide enrichment opportunities to their students.\nStudents are able to achieve their CAST awards while learning the basics of fishing, in a peaceful environment surrounded by nature. The lessons would be particularly beneficial to young people struggling to learn in a classroom setting, pupils lacking in confidence and self esteem, those with complex learning difficulties or suffering from anxiety and depression.\nFishing lessons are offered between Easter and October half term.\nFrequently Asked Questions\nDo I need to have any fishing experience before having a lesson?\nNo - We offer fishing lessons for complete beginners. Although even the most experienced angler is always learning, so anyone could benefit from a fishing lesson.\nDo I need to bring my own fishing equipment?\nWe can provide all the fishing tackle and bait. However, if you would like to use some or all of your own tackle then that’s absolutely fine.\nWhat are the CAST awards?\nThe awards set out a series of progressive steps to help anglers develop skills. A new angler can gain a starter award in their first session by identifying fish species & bait, learning about safety near water and helping to net a fish. Keen anglers can continue to work through 6 other levels!\nWhat type of fish could I catch?\nWe will be fishing for coarse fish. Manor Farm Lakes in Biggleswade, Bedfordshire, has a variety of different lakes for all abilities. You could choose to catch plenty of smaller fish such as roach, perch, rudd & bream or wait it out for a big carp!\nWhat fishing methods could I try?\nThere are many different styles of fishing. You may enjoy using a float or quiver tip. Other's prefer modern day carp fishing techniques. It’s important to understand the wide variety of fishing methods so you can choose the best method to catch your chosen quarry.\nIs it safe for children?\nWe always complete a full risk assessment. The children are taught how to keep safe when near water and how to handle fishing equipment in a safe manner. Teaching the children these habits early on should encourage them to always behave correctly near water while enjoying a healthy and fun sport such as fishing.\nWhere are you located?\nEasily accessible from Hertfordshire and the surrounding areas we are based at Manor Farm Lakes in Biggleswade, Bedfordshire. The complex is made up of 7 lakes offers an abundance of coarse fishing for all abilities.\nStuart gave me advice on the best kit and tackle to help get me back into fishing after many years. He’s experienced and knowledgeable with tons of tips and tricks to improve your fishing skills. Go on one of his Fishing Adventures… you’ll have fun and learn loads too.\nI spent many a wasted afternoon fishing in my youth, and usually caught next to nothing. Now that l'm retired, l decided to take it up again, and so l contacted Stuart. He very kindly spent a couple of free hours with me buying some equipment, and l had my first lesson at Manor Farm. l can honestly say, that l caught more fish with him on that first lesson, than l ever did in my younger days. I've been out a few times on my own, caught more, and can't wait to get back to it once the weather warms up a bit more. Mal Collins\nStuart led a number of sessions with our Key Stage 3 and 4 students this year which they thoroughly enjoyed. The sessions were informative and engaging with Stuart passing on his expert knowledge to the students in an effective way. The feedback from our students was excellent and they were desperate to have another session. I would certainly recommend this enrichment experience for students of all ages.\nGet in touch today to schedule a session with Fishing Adventures.\nManor Farm Great North Road, Lower Caldecote, Biggleswade, Bedfordshire, SG18 9BB, UK\nNews & Updates\nEaster Fishing Camp\nCourse dates:Tuesday 11th April 12-2.30pm Wednesday 12th April 12-2.30pm Thursday 13th April 12-2.30pm\nWe are now taking bookings for Easter Fishing Camp🎣 Suitable for ages 6-16yrs. Children must be supervised by a parent.","Individuals and families living and working in fishing communities are at high risk of drowning due to their increased exposure to water. Many fishers rely on the income made from their catch to support an entire household. This leads to their involvement in dangerous fishing practices, such fishing in bad weather or in unsafe waterbodies, using unsafe fishing vessels, not having appropriate safety equipment accessible, and allowing fishing vessels to be operated by untrained or fatigued staff. These high-risk practices are particularly prevalent in low-income countries and rural/remote areas, where water vessel and water safety regulations may not be effectively enforced.\nThe children of fishers who live in close proximity to water are also at high risk of drowning as they may be left unsupervised for extended periods of time while their carers are fishing. Therefore, drowning reduction programs must target both adults and children simultaneously in order to effectively prevent drowning in this context.\nReducing drowning among fishers\n- Educate individuals on the risks and hazards of water, enabling them to identify and avoid dangerous weather conditions and unsafe waterbodies\n- Encourage large commercial fishing boats adhere to safety regulations, protecting the occupants on board and ensuring smaller private boats are not endangered\n- Encourage boat occupants adhere to safety regulations such as wearing life jackets and not exceeding maximum occupancy\n- Provide fishers with CPR and rescue skills to enable them to act effectively in an emergency\n- Improve swimming skills and water safety skills so that individuals can stay afloat if they fall overboard or are swept off the shore\n- Ensure hazardous and shallow waterways are clearly marked Avoid consumption of alcohol and other drugs when fishing or on the water\nReducing drowning in children and infants\n- Provide good adult supervision around the home and in day care. Carer education may be required to establish the elements of good supervision.\n- Reduce exposure to water through the use of barriers\n- Educate older children on the hazards of water, water rescue and CPR\n- Improve swimming survival skills so that children can remain afloat should they enter the water\n- Remove potential hazards such as nets and lines near the water’s edge\n- There are a number of approaches for preventing drowning developed for the general population which could be effectively implemented in fishing communities.\n- Many are cost-effective and simple.\n- Many can to be implemented within communities without external resources or support.\n- Some interventions are costly and these costs may be borne by individuals, such as purchasing lifejackets or refurbishing fishing vessels.\n- Some interventions are complex and require significant infrastructure to run, such as enforcing commercial boating regulations.\n- Fishers may be resistant due to associated time requirements and changes to the way they work.\n- May impact on how effectively fishers are able to generate income and support their families.\nDue to their heightened water exposure, it may be appropriate to first identify and target fishing communities when implementing drowning reduction strategies in an area. Be prepared to think and work towards creative solutions as the context of fishing communities is different to that of the general population. To enhance the likelihood of the adoption of potential drowning prevention strategies, it is critical to involve the fishing community from the earliest stages of project development.\nHigh risk practices among fisherman (Greece): Frantzeskou, Elpida, et al. \"Risk factors for fishermen’s health and safety in Greece.\" International maritime health 63.3 (2012): 155-161.\nFishermen’s perceptions of risk (PDF 351KB)\nMeasuring and improving safety for recreational boating: Amanpreet Virk and Terri Pikora, Developing a tool to measure safe recreational boating practice. Accident Analysis and Prevention 43(1):447-500 2001\nSet objectives and interventions"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:c29106a1-052b-4ba3-b344-0b23adf7f32d>","<urn:uuid:5290588e-d569-47ac-b566-b5e1cb615d22>"],"error":null}
{"question":"How has the printing press impacted literacy and newspaper research in American history?","answer":"The printing press had a profound impact on American literacy and newspaper development. In colonial America, it enabled widespread literacy among white men, with rates rivaling Scotland by 1800, though literacy was more prevalent in cities and the North. The press became crucial for colonial communication about royal taxes and independence plans, with Benjamin Franklin considering it a vital 'engine' of the revolution. Regarding newspaper research, historic newspapers have become valuable genealogical resources, containing rich information about social occasions, business advertisements, marriage announcements, and death notices. Modern digital platforms like Chronicling America have made newspaper research more accessible, allowing full-text searching of over 6 million newspaper pages, though researchers must be mindful of name variations and historic terminology when conducting searches.","context":["Ever since its first appearance in the American colonies in the 17th century, the printing press has served an important role in the history of the United States. In the original thirteen colonies, emphasis was placed on teaching children to read and write in order to be good Christians and citizens. In the South, Thomas Jefferson drafted a bill for the Virginia Assembly in 1770, entitled “A Bill for the More General Diffusion of Knowledge.” Jefferson proposed the establishment of public schools in which “reading, writing, and common arithmetick” would be taught to “all the free children, male and female.” (This meant that education would only be available to white people, not people of color, slaves, Indians, or indentured servants.) Jefferson believed that only a literate population could prevent the growth of tyranny. The printing press thus became a strategic weapon in the colonists’ fight for independence.\nThe printing press has played an important role in American history since the first Europeans arrived in North America. The very first printing press on the continent was brought from Seville, Spain to Mexico City in 1539 and was used to print Catholic catechisms. In 1693, the “Mercurio Volante,” a small pamphlet containing local and international news printed in Spanish, became the first periodical printed in North America.\nThe British colonies did not have access to a printing press until 100 years later. In 1639, Stephen Day opened a press at Harvard College, in Cambridge, Massachusetts. The first publication produced was a form called the “Oath of a Freeman.” All settlers in the Massachusetts Bay Colony were required to take this oath, a promise of loyalty to the Massachusetts Bay Company, which controlled the colony.\nThanks to its invention by Johannes Gutenberg in the city of Mainz, Germany in 1440, the printing press made Germany a center for literate culture. When German Lutheran immigrants began to move to Pennsylvania in the 17th century seeking religious freedom, they brought that culture with them, as well as their metal typefaces. Even Stephen Day’s Cambridge printing press used metal type imported from Amsterdam. The European influence on American presses was significant because, by design, metal typefaces from Germany and the Netherlands only included the letters needed to print in German and Dutch--not English. American printers worked around the problem by adapting Olde English into the new typeface. The best example of this is the disappearance of the common Anglo-Saxon letters, thorn (Þ or þ) and eth (Ð or ð).\nThe English language is unusual in its reliance on the “th” sound, as in words such as thing, myth, and the. As the English alphabet developed, letters were created for all the commonly-occurring sounds, and “th” was so prevalent that the Anglo-Saxons adopted two letters, thorn and eth, to symbolize it. Thorn and eth were both pronounced “th” and were used interchangeably. In the Early Middle Ages, when most books were still being copied by hand, the letter eth became indistinguishable from the letter Y.\nAnd that’s where things got complicated for American printers. As the English colonies grew, so did demand for an English-language press. But printers like Stephen Day in Cambridge, Massachusetts and, later, Benjamin Franklin in Philadelphia, faced the challenge of printing the English language with an available metal typeface based on the German alphabet. Not surprisingly, the German alphabet did not contain the English letters thorn and eth. But it did contain a Y.\nAmerican printers made do, and thus was born an avalanche of “Ye Olde” this and that. A reader in the 18th century would immediately know how to pronounce the word ” Ye:” the same way today we pronounce the word “the.” Y, when followed by a superscript, was recognized as the letter eth. (Eventually, over time, the letters t + h were adopted to form the “th” sound.)\nWhat began as a simple printing adaptation has now become a sort of cliched signifier of anything colonial or even medieval; from Ye Olde Ice Cream Shoppe to the Ye Olde Renaissance Faire. Modern speakers often incorrectly pronounce “Ye” with the y and long e sounds, or “yee,” instead of the modern word “the.” No one in centuries past called anything “Ye Olde” anything! All because the German alphabet didn’t include a thorn.\nOf course, printing presses were only useful to a literate population. By 1800, most of the white men in the original thirteen colonies were literate, a rate rivaled only by Scotland at the time. Literacy was more prevalent in cities and in the North than in rural areas and the American South, but it was nevertheless relatively widespread throughout the American Revolutionary period. The printing press thus became a central mode of communication for colonists trying to keep up with the latest royal taxes and, later, circulating plans to declare independence. Benjamin Franklin, who owned his own printing press in Philadelphia, believed the press was a crucial “engine” of the revolution.\nIn declaring independence, the Founders made freedom of the press a fundamental right for Americans. This idea was important, not only to leaders such as Franklin, but also Thomas Jefferson, an intellectual who regularly sought out books and pamphlets in his own quest for self-education. Jefferson knew that freedom of expression and a press liberated to print the truth were key to the future of the newborn United States. “Where the press is free, and every man able to read,” Jefferson wrote in 1816, “all is safe.”\nLearn about available townland records to add generations to your family tree with the free virtual presentation “Irish Genealogy: Exploring Townlands.”\nDid you have an ancestor who may have deserted the military? If so, you may be able to locate them in the newly available collection, “U.S., WWII Army Deserters Pay Cards, 1943-1945.”\nOne of the country’s oldest publications, York Daily Record, was first published 225 years ago, with a history that began as a German-language newspaper.\nRegister in advance for the full-day St. George’s Day England Research Seminar, which includes, among other topics, “That's English?! Reading Old Handwriting.”\nNewspaper Research - Invaluable to the Family Historian\nIn pursuit of the answers to the genealogical mysteries of our ancestors, we commonly refer to the various records that were created over the span of their lives. Census records, vital records, immigration records, and the like are the cornerstones of our research and, therefore, key sources for understanding our ancestors. This is fundamental research and an essential step in the process of documenting their lives, but each of these types of records has one thing in common: they are all forms. As such, they are designed to identify very specific facts for predetermined categories, leaving little room for auxiliary details. The form documents are great sources, but they don’t always provide all of the facts.\nThis is where newspapers come in! Historic newspapers can provide a wealth of information, as the details included in articles and announcements were not restricted to merely what would fit into a standardized field on a form and instead allowed for all details pertinent to the subject at hand to be shared. They can not only provide additional information and context, but oftentimes are responsible for providing clues which lead to previously unknown documents. In addition to the more commonly sought newspaper publishings of obituaries, marriage announcements or probate notices, researchers should also seek the less obvious items, such as social news, birth announcements, military updates, classifieds or business advertisements.\nIf lucky, the newspapers have been indexed with either databases created manually by humans or through the use of Optical Character Recognition software (OCR), both of which can include errors. The possibility of these potential errors should be kept in mind when conducting searches. Commonly mistakes with OCR include pairs of letters having similar shape to other letters, such: as cl for d, rn for m, nn for m, ol for d, vv for w and li for h.\nWhen searching be methodical and exhaustive, especially in the quest for an obituary. Just because an obituary, death notice or funeral announcement is located, does not mean that there is not a better one out there. Oftentimes there are additional publications which provide different versions, such as a publication in a nearby community, or in the location of residence of a close family member. Other times there is a short death notice or obituary published in a morning edition and a more detailed version is printed in the evening edition, or even the next day’s issue. In the examples shown below, the third time was a charm! The first two articles located provided scant details, but diligence paid off and the third one revealed bountiful information about the deceased. New details included a specific location of birth and previously unknown family members who had remained in their native country, paving the way for more accurate results in records there.\nBe comprehensive by searching for multiple variants of an ancestor’s name. Though in official records, they may have been known as James Benjamin Smith, a newspaper article may have published their name in various forms, such as James Smith, James B. Smith, J. B. Smith, Ben Smith, Jim Smith or J. Smith. In the case of females, it was common, as illustrated in the funeral and obituary notices above, for them to be recorded not only under a nickname or initials, but potentially using the name of her spouse. If the husband’s name is known, in addition to the standard variants for the subject, also search for variants of the husband’s name, such as Mrs. James B. Smith, Mrs. Jim Smith, and so on.\nAs mentioned earlier, newspapers can open doors to information that may never have been discovered otherwise. One such case began in search for an obituary of a mother lost due to complications from the flu, coming at the end of the Spanish Flu pandemic in 1920. Searches initially revealed a “card of thanks” type announcement where the family was thanking everyone for their kindness following the death of their mother (the research subject) and Marvin. Who was Marvin? No living family members had ever heard of anyone in the family named Marvin. Further research found that three generations of the family resided together and the day that the funeral of the research subject, Lucretia, was to take place, her two-year-old grandson, Marvin, succumbed to the same horrible illness. As a result, Lucretia’s funeral was postponed to allow for further preparations, resulting in a double funeral honoring the grandmother and grandson together. Though the original notice and subsequent obituaries found for Marvin and Lucretia did not reveal all of these details, they were responsible for revealing that Marvin ever existed and led to pursuit of additional records, revealing details that would have been lost to time otherwise.\nThere are numerous sources for historic newspapers where you may try your newly learned search methods that can be accessed for free, including The Library of Congress’ Chronicling America and Google News Archive, in addition to state or university archives, such as The Gateway to Oklahoma History or the Wyoming Digital Newspaper Collection, among others. Be thorough in your search for newspaper collections. If not available online digitally, they can often be accessed on microfilm through local libraries, many of which offer interlibrary loans.\nUtilizing Boolean search techniques can sometimes reveal information that would otherwise not be found and is a necessary tool in the arsenal of a successful family historian. Learn more about utilizing smarter search techniques in our blog post How to Conduct Successful Google Searches, These methods should be used for newspaper database searches, in addition to the internet browser searches referenced in the article.\nAdditional tips for locating your ancestors in newspapers can be found in our blog post, Genealogy on Deadline: Newspapers Bring Ancestors to Life.\nPOTUS on TV - Read Here\nThe Genealogy of Health - Read Here\nNew Year, New You, New Ancestors - Read Here\nWhy We Map - Read Here\nAre You a Good Ancestor? - Read Here\nField Guide: Decoding Old Cemeteries - Read Here\nThe First Black Friday: September 24, 1869 - Read Here\nWhy We Eat Turkey on Thanksgiving - Read Here\nDeutsches Historisches Museum: (https://www.dhm.de/ : accessed 28 January 2021), “First Printing in German of the Declaration of Independence of the United States of America, July 4, 1776: German Language Printing in the American Colonies up to the Declaration of lndependence (part 2)”\nJSTOR (https://www.jstor.org/ : accessed 28 January 2021), The German Press in Pennsylvania and the American Revolution.”\nWilliam S. Reese,The Antiquarian Booksellers’ Association of America (https://www.abaa.org/ : accessed 28 January 2021), “The First Hundred Years of Printing in British North America: Printers and Collectors.”\nThe Library of Congress (https://www.loc.gov/ : accessed 28 January 2021), The Germans in America.”\nAmerican Antiquarian Society (https://americanantiquarian.org/ : accessed 28 January 2021), “Colonial Print Culture.”\n\"Mrs Delia Halpin\" The Springfield Union (Springfield, Massachusetts), 4 October 1961, digital images, GenealogyBank (https://genealogybank.com : accessed 27 January 2021), citing print edition, p. 24, col. 4.\n\"Mrs Timothy Halpin\" The Springfield Union (Springfield, Massachusetts), 2 October 1961, digital images, GenealogyBank (https://genealogybank.com : accessed 27 January 2021), citing print edition, p. 8, col. 3.\n\"Mrs Timothy Halpin\" The Springfield Sunday Republican (Springfield, Massachusetts), 1 October 1961, digital images, GenealogyBank (https://genealogybank.com : accessed 27 January 2021), citing print edition, sec. A, p. 22, col. 5.\n\"Card of Thanks\" South Bend News-Times (South Bend,Indiana), 1 February 1920, digital images, Newspapers.com (https://newspapers.com : accessed 28 January 2021), citing print edition, p. 11, col. 5.\n\"Marvin Harlin\" South Bend News-Times (South Bend,Indiana), 29 January 1920, digital images, Newspapers.com (https://newspapers.com : accessed 28 January 2021), citing print edition, p. 12, col. 2.\n\"Mrs. Albert Alexander\" South Bend News-Times (South Bend,Indiana), 27 January 1920, digital images, Newspapers.com (https://newspapers.com : accessed 28 January 2021), citing print edition, p. 9, col. 2.\nEnd of Email Prize\nHere is the coolest, semi-useless website we found for you this week:\nSee you next week! 👋🏼","Historic newspapers are valuable resources for genealogical research. Rich with all types of information, newspapers can be useful in locating material regarding families and ancestors. 19th and 20th century newspapers devoted a lot of their print space to local and state events. Social occasions, business advertisements, marriage announcements, real estate transfers, and death notices are a few examples of the many types of information that can be found within historic newspapers.\nChronicling America: Historic American Newspapers has made researching newspapers much easier. Long gone are the days of indexing names in newspapers on microfilm; with Chronicling America, not only can research be conducted at the convenience of a personal computer (and for free!), these digitized newspaper images are full-text searchable as well as downloadable.\nBefore diving in to the over 6 million newspaper pages made available on the site, here are a few things to keep in mind when conducting genealogical research with historic newspapers:\n1. Try searching variations of names.\nOftentimes, full names are not printed in historic newspapers in the same way they are today. Men’s first names are sometimes shortened (i.e., William is printed as Wm.) or only initials are used (i.e., William Jonathan Taylor is printed as W.J. Taylor). In some cases, married women are listed under their husband’s name (i.e., Mrs. William Taylor). Additionally, the spelling of many family surnames has changed over time. With these in mind, do not be afraid to search variations of first and last names to see what kind of results turn up.\n2. Be aware of historic terminology.\nLanguage changes over time, so it is important to understand that some terms considered commonplace today were not used when these newspapers were printed. In the same respect, many terms used then have now become obsolete. For example, searching for a marriage announcement may not produce many results if using the terms “marriage” or “wedding” as these words were not always used; try including older words such as “nuptials” or “hymeneal” in conjunction with a family name for possible results. When you do locate results, take note of the terms used for use in later searches.\n3. Limit the date range to narrow the results.\nWhen searching for a specific event or person, try altering the date range by using the “Advanced Search” tab. Dates can be limited to a range of years or to a set of specific dates. The database of newspapers in Chronicling America covers 87 years, so even if the exact date is unknown, narrowing the search to a five-year, ten-year, or even twenty-year period will narrow the results.\n4. Be patient.\nResearch takes time. While Chronicling America makes historic newspapers much more accessible than ever before, the research process still requires time and patience. Although every newspaper page is run through OCR (Optical Character Recognition) technology to enable keyword searching, this process is not 100% accurate meaning errors will occur. Additionally, the Chronicling America database is continually growing and evolving; new pages and titles are added on a regular basis along with new states contributing content. A search that produces limited or no results may generate more once new content is added.\n5. Keep up with what you find.\nWhen doing any type of research, it is important to document relevant findings and results. Within Chronicling America, there are several ways to keep up with pages or articles of interest.\n- Persistent link: each newspaper page has a persistent link listed underneath the viewer; copy and save this link in order to return to that exact page.\n- Clip image: when viewing a newspaper page, an icon in the upper right-hand corner of the toolbar features a pair of scissors. This will “clip” the page as currently seen in the viewer. This is helpful to capture headlines, short articles, images, and advertisements. A great feature with clipping images is that it also keeps the persistent link and other citation information with it.\n- PDF: along the toolbar of the page viewer is a “PDF” icon; clicking this opens up the entire current newspaper page in PDF format. Right-clicking on this PDF image allows for saving the whole page to a desktop or flash drive.\nHave you used Chronicling America for genealogical research? What kind of results did you find? What other tips would you give researchers for using this database?"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"}],"document_ids":["<urn:uuid:3b25608f-af07-474d-992f-314bf7e506e8>","<urn:uuid:1281bc1d-88e2-4671-bf0e-9a0d395000e4>"],"error":null}
{"question":"What are the mental health impacts of chronic stress, and how can relationship communication exercises help manage stress levels?","answer":"Chronic stress can cause serious mental health impacts including lack of motivation, irritability, anger, lack of concentration, and difficulty focusing. It can also lead to behavioral changes like angry outbursts, changes in eating habits, substance abuse, and social withdrawal. To manage these impacts, relationship communication exercises can be helpful, such as taking turns explaining emotional experiences to each other uninterrupted, repeating back what was heard to ensure understanding, and working together to transform unhealthy negative emotions into healthier alternatives. These exercises help build empathy, improve communication, and provide emotional support which can help reduce stress levels.","context":["3 Exercises to Stop Thinking Irrationally Before It Results in an Argument\n“Stop glorifying the idea that the right person will just know the way to love you; that they’ll be able to just meet your emotional needs without you ever voicing them. Great relationships don’t just happen because two mind readers come together, they happen because people communicate clearly and directly. They happen because they’re willing to teach another where their boundaries lie, and how they prefer to be loved.” – Vienna Pharaon\nAt Keys to Counseling in Tampa, FL, I specialize in a specific type of therapy called Rational Emotive Behavior Therapy (REBT). Established by Dr. Albert Ellis in 1955, REBT is an active, directive, solution-focused, and goal-oriented approach to counseling and it is recognized as the pioneering form of Cognitive Behavioral Therapy (CBT).\nAccording to REBT theory, unhealthy negative emotions are:\n· Problematic Jealousy\n· Problematic Envy\n· Problematic Anger and Rage\nOur goal in counseling is to transform your unhealthy negative emotions into healthy alternatives, such as:\n· Non-Problematic Jealousy\n· Non-Problematic Envy\n· Annoyance or Non-Problematic Anger\nUltimately, it is your irrational beliefs about specific events and adversities within your life (including your beliefs about your partner and your relationship) that lead you to experience unhealthy negative emotions (anxiety, depression, or anger about your relationship) and dysfunctional behaviors (such as screaming at your partner or threatening a break-up). Once you feel yourself become emotionally activated (i.e. you are beginning to experience unhealthy negative emotions) you can separate yourself and your relationship from your negative emotions by evaluating exactly what your thought process is within that moment:\nIn other words, you can ask yourself:\n· What specifically am I thinking and telling myself when I start to feel anxiety, depression, or anger about my partner, our relationship, or myself within the relationship?\nIf you catch yourself thinking irrationally, you can dispute your thoughts and replace them with healthier rational beliefs.\nFurthermore, even if you do not believe you are thinking irrationally, you can still ask yourself:\n· How is thinking, feeling, and acting in this way helping me to accomplish my goals of feeling happier within my relationship, enjoying our time together as a couple, arguing less intensely with my partner, and improving our overall communication?\nIf the answer to this question is that the thoughts you are thinking, the emotions you are feeling, and the way you are behaving are NOT helping you to achieve your goals, then what do you have to lose by working to transform the somewhat stubborn and habitual way you have learned to think and process information into something more flexible, functional, and helpful for your relationship?! Cognitive processes (the way you think) are learned; therefore, you can challenge your current way of thinking, and ultimately learn healthier ways of thinking about yourself, your partner, your relationship, and the world in general!\nRemember, no one else has the power to entirely upset you: you upset yourself by the way that you think about things and react to them! You are responsible for your own emotional and behavioral reactions in life and in your relationship, and therefore, you have the power to stop upsetting yourself!\nOnce both you and your partner identify and commit to working on the cognitive, emotive, and behavioral changes that you wish to implement within your own life, as well as within your role in the relationship, it will be so much easier to then find practical solutions together as a couple!\nSo, the next time you feel the potential to experience any unhealthy negative emotions towards one another or about your relationship, practice these 3 exercises:\n1. Listen To One Another: Hear & Repeat Each Other’s Narratives\nAs you feel yourself becoming emotionally activated (i.e. upset), take turns explaining your emotional experience to one another: this means you can tell each other exactly what upset you in the moment, how you felt, how your behavior was impacted, and what your thought process was relating to the activating event that upset you. Share this information with each other, one at a time, uninterrupted. Once you/your partner has finished sharing your/their emotional experience, have the other person repeat exactly what they have just heard. Do this until you/your partner is accurately repeating what you/they said, and correctly conveying the other person’s emotional experience. Once this achieved, switch roles, and repeat the activity. When attempting this exercise, remember:\n· Even if an argument has already taken place, you can still partake in this activity. In other words, if you or your partner are already emotionally activated, you can use this exercise as an opportunity to alleviate your emotional upset and come back together as partners by viewing the completion of this activity as a goal you can accomplish together as teammates within your relationship.\n· As a couple, always view your challenges and problems as being separate from your relationship. You two are partners and on one side of the room is your partnership, and on the other side of the room is your problem. Your problems, challenges, individual mistakes, as well as your partner’s mistakes are all separate from your partnership as a whole. Your challenges and flaws are only partial components within your relationship, as well as partial/incomplete descriptions of you and your partner. In other words, your relationship problems and individual mistakes do not entirely define your relationship, nor do they define the entire identity of you or your partner.\n· If an argument has already taken place and/or one or both of you is so emotionally activated that you do not feel you can calmly partake in this activity, it can then be an effective idea to take a small amount of time apart: ideally somewhere between 20 minutes to 1 hour. Once both of you have returned to a more rational mindset, and your unhealthy negative emotions have begun to deactivate and return to a healthier level, then you can come back together and complete this exercise. The same principle can be applied for when you become emotionally activated in public and/or around other people, meaning you cannot comfortably partake in this activity in the moment. In this scenario, you can save this exercise for later in the day when you have time to complete it together in a more private setting.\n· Even if you do not agree with each other’s recollection of events and/or entirely understand your partner’s emotions, just calmly, compassionately, and respectfully listen to what they are saying, and then repeat their experience as they conveyed it to you. Once you successfully achieve this, you will have the opportunity to share your own emotional experience about the same activating event from your perspective. This will help both of you to understand that even though you were both present for the very same event, adversity, or conflict, each of your emotional experiences can be highly dissimilar, which is why two people often react so differently to the same circumstance.\nBy sharing your narratives with one another, the goal is to develop empathy for your partner, and to better understand that neither of you are mind readers or fortune tellers: you cannot automatically know what your partner’s emotional experience is, nor can your partner accurately predict how you will feel or behave in response to every event or challenge that arises. The purpose of this exercise is to build the foundation for compassionate and effective communication within your relationship.\n2. Close Your Eyes & Imagine\nAfter completing the first exercise, with your partner beside you, close your eyes, imagine, and ask yourself:\n· What can you (yourself) do to transform your unhealthy negative emotions and/or unhelpful behaviors relating to your relationship into a healthier/more helpful alternative?\nNext, keep your eyes closed and ask yourself:\n· How can you challenge and replace your irrational (unhelpful) beliefs with rational and effective new beliefs that will help you to accept your partner as they are?\nFinally, ask yourself:\n· What can you tell yourself to reduce your unhealthy negative emotions (ex. anxiety, depression, anger, rage) about your partner and/or your relationship?\nOnce you have completed this activity, discuss your answers with one another, and truly listen to and think about the emotional solutions you and your partner have cultivated for yourselves regarding what each of you can do to improve the relationship based upon changing the way that each of your think about the relationship, as well as how you think about one another. This is what it means to take responsibility for your own emotional and behavioral consequences within your life and your relationship! Furthermore, this is how you put your relationship in the best position possible to change for the better: you strive to change yourself before attempting to change your partner. When both people can do this, profound transformation can be achieved!\nKeep in mind, this exercise is also something you can practice on your own regarding your irrational beliefs about YOURSELF and your perceived role in the relationship, as it will not be helpful for either of you to experience unhealthy negative emotions about yourself (ex. shame, self-directed anger, depression, guilt, etc.). You are both human, and all human beings make mistakes within their relationships and their lives, but as long as you are open to continuously learning, you can always find new ways to improve yourself and your relationship, as well as learn to cope more effectively with the inevitable stressors that arise within life and relationships!\n3. Ask one another: how can we make life together more interesting and enjoyable?\nThis is an exercise that you can permanently integrate into your relationship! It is a question worth prioritizing, as the answers can constantly change, and your ideas for how to do this can be added to your schedules, so you truly remember to value this concept and plan for special and exciting experiences together, whether that is extra time in bed together in the morning, grocery shopping and cooking dinner with one another, planning new date night ideas for each other, or sharing more about your work day with your partner. Contrary to popular belief, making life together more interesting and enjoyable does not solely arise from planning elaborate vacations or unusual excursions, because the idea is that you want to make your daily lives with one another more exciting, passionate, spirited, and fun! How you go about doing this is purely subjective, based upon your and your partner’s interests and desires. The important message is that you both make this an ongoing priority within your partnership!\nTry to have fun with the exercises above!\nUse them whenever either of you become emotionally activated, and remember that if/when your emotional activation occurs at an inconvenient time (such as in public places, around family/friends, during the work day, or while you are under the influence of alcohol), you can actively and decisively choose to emotionally reject conflict, enjoy your time out in spite of a disagreement, and commit to sharing your feelings and completing these exercises once you are alone with one another.\nAdditionally, when other people are around, and you become emotionally activated, you can skip exercise #1 and complete exercise #2 individually within your mind: i.e. you can dispute the way that you are thinking in that moment to instantly transform the start of any unhealthy negative emotions/behaviors into healthier ones. This can help both you and your partner to quietly deactivate and avoid unnecessary conflicts around friends and family.\nIn REBT-based couples counseling, when both partners are dedicated to healthy transformation, self-exploration, and personal as well as relational growth, so many wonderful goals can be achieved for the future of your emotional and behavioral well-being as individuals and as partners!\nAt Keys to Counseling in Tampa, Florida, my mission is to promote healthy living through rational thinking! I provide both individual and couples counseling, and I would be honored to cognitively, emotively, and behaviorally accompany you on your journey to living, loving, being, and staying better!","How Does Stress Affect The Body: Symptoms And Solutions\nUpdated August 27, 2020\nMedically Reviewed By: Lori Jones, LMHC\nAre you exhausted all the time? Do you have a lot of muscle tension and pain? Is your head or stomach bothering you? It could be stress. There is a long list of symptoms that falls under the question, “How does stress affect the body?” And, learning how to identify the symptoms can help you find the right solution.\nStress levels have been on the rise in Americans over recent years. It’s impacting people of all ages and spans a wide range of worries and concerns.\nThe Impact Of Chronic Stress\nEveryday stress can have a negative impact on multiple areas of your life. However, when the stressful situation passes, you may find that things return to normal even if you didn’t do anything to address your stress. This isn’t the healthiest way to get through stress, but it happens this way for some people.\nHowever, if you’re experiencing chronic stress, it’s not going to just go away. It may not be tied to a specific situation in your life. Instead, it might be the result of poor habits or not knowing how to deal with past trauma. It will not just go away if left untreated.\nThe Effect Of Stress On The Body\nStress can wreak havoc on your body if it’s left unchecked. Not only does occasional stress show up in your body, but chronic stress can also have long-term negative consequences for your physical health. When you are feeling stressed, you may experience:\n- Increased heart rate\n- Rising blood pressure\n- Muscle tension\n- Upset stomach\n- Lack of sexual desire\n- Change in appetite\nAnd these are just a few of the symptoms that you may experience. If you suffer from chronic stress, the symptoms above can start to turn into more serious health consequences.\nChronic stress can lead to health problems such as heart disease, high blood pressure, gastrointestinal problems, heart attack, and strokes, among others. These are clear indicators that allowing chronic stress to continue in your life can be detrimental to your physical health and well-being.\nHow Stress Affects Mental Health\nStress also impacts your mental health and wellness. It can lead to you experiencing many different negatives and difficult emotions such as sadness, anger, frustration, and fear.\nSome of the mental health symptoms that you may notice in your life from stress include:\n- Lack of motivation\n- Irritability and anger\n- Lack of concentration and focus\nThese are serious symptoms that should not be taken lightly. If you experience chronic stress, you may begin to think that these symptoms are just a normal part of life. But, they’re not. All of these symptoms can grow into more serious problems if you don’t work on addressing them.\nHow Stress Affects Behavior\nStress can also impact your behavior. If you look at the symptoms listed above under physical and mental health, it can be easier to understand how stress changes your behavior. If you’re living under constant overwhelm and anxiety and experiencing things like frequent headaches or stomach aches, it can be easy to lose your temper with your loved ones, for example. Here are some of the other behavioral changes that you may experience in your life as a result of stress:\n- Angry outbursts\n- Eating too much or not enough\n- Substance use or abuse\n- Social withdrawal\nThese behaviors can have a negative spiral effect on your life. For example, as your withdrawal from friends and family because of stress, you may find that you struggle even more to cope with stress in your life. This can lead to additional problems which keep you away from a social activity even more. This is why it’s important to learn to recognize and healthily address your stress.\nStress Management Tips To Overcome Chronic Stress\nThankfully there are many things that you can do to address your chronic stress and learn to overcome it. This doesn’t mean that you’ll never experience stress again. Instead, it means that when you do go through stressful situations, you’ll have tips and strategies that you can use to relieve stress and handle it healthily.\nSome of the stress management solutions you may benefit from include:\nLearn to identify your stress triggers\nWhen you start to feel stressed, it can be helpful to take time to identify where the feelings are coming from. This allows you to begin investigating what you can do to make to address it.\nWhile there will be some things causing you to stress that you can’t do anything about, there will be some things that you can address. For example, if a family member’s behavior is causing you to feel stressed, you probably aren’t going to be able to control how they are behaving. But you may be able to establish boundaries in your life that stop the other person’s behavior from having as large of a negative consequence on you.\nThere will be some things that you find are short term stressors. But there also might be habits that you identify that are causing you unnecessary stress. When you learn where the stress is coming from, you can start to take your first steps to address or removing it.\nPractice Deep Breathing\nWhen you’re starting to feel the stress and tension build up within your body, deep breathing can help to break up some of the physical symptoms that you’re experiencing. For example, you may notice that you start to breathe faster as your frustration grows. This can cause your heart to race, as well. And, as your heart beats faster, your blood pressure rises. These physical symptoms can continue to build and even lead to things like full-blown panic attacks.\nDeep breathing can help to stop your physical symptoms from progressing. As you start taking slow, deep breaths in and out, you may notice that it feels like your blood pressure is lowering, and your heart rate is returning to normal.\nYou may also find that deep breathing can help you to slow your thoughts. Your mind will be forced to temporarily shift from your stress and worry to the breathing technique that you’re using. This can help you to regain mental clarity and look for solutions to the stressful situation or problem that you’re facing.\nThere are multiple types of breathing techniques that you can use, so practice a few of them to find what works best for you. It can also help to practice them when you’re not under stress, so when you find your stress starting to build, you will know how to put the breathing exercise to use without too much thought.\nNot getting enough sleep can make it even harder to deal with stress. You may find that you struggle to be patient with others, and you cannot think clearly to look for solutions. If you’re having problems falling asleep or staying asleep due to stress, it’s an important symptom to address.\nMany different things may help improve sleep troubles. A few that you could try include:\n- Keeping a strict sleep schedule\n- Cutting out caffeine\n- Not exercising too close to bedtime.\n- Sleeping in a dark, cool room\n- Using white noise\nHowever, if you’re continuing to struggle, don’t be afraid to talk with your doctor to explore additional options.\nGet More Physical Activity\nPhysical activity and exercise can help you release tension that has built up from chronic stress. It also releases chemicals in your brain that work to boost your mood. But these chemicals also act as natural pain killers, which can help reduce some of the physical symptoms you’re experiencing.\nThere are other ways that physical activity and exercise can help with stress. You may find that you sleep better when you exercise. And, you may experience a boost in your self-esteem as well.\nThe Anxiety and Depression Association of America shares that you may start to experience these positive mental boosts after just five minutes of physical activity. So, if you’re feeling stressed, you don’t need to feel like you have to get in a full workout. Simply getting moving for a few minutes can start to help.\nTalk To Someone\nHaving a trusted person to turn to for support can help when you’re going through stressful situations or experiencing chronic stress. This could be a friend or family member. It could also be a support group. For example, if you’re under stress as a result of losing a loved one, you may benefit from connecting in a group for others experiencing grief from losing someone.\nIf you don’t have anyone to turn to or could use additional support in handling your stress, a licensed therapist is an effective option to consider. Not only can they listen as you talk through the stress in your life, but they also have education on how to help you overcome it. A therapist, like those at BetterHelp, can assist you in finding stress-relieving strategies that work for your specific situation.\nPrevious ArticleHow Stress Can Lead To Emotional Breakdowns And What You Can Do To Avoid It\nNext ArticleAre You Under Too Much Stress? Symptoms, Treatment And Tips\nLearn MoreWhat Is Online Therapy? About Online Counseling\nAbuse ADHD Adolescence Alzheimer's Ambition Anger Anxiety Attachment Attraction Behavior Bipolar Body Dysmorphic Disorder Body Language Bullying Careers Chat Childhood Counseling Dating Defense Mechanisms Dementia Depression Domestic Violence Eating Disorders Family Friendship General Grief Guilt Happiness How To Huntington's Disease Impulse Control Disorder Intimacy Loneliness Love Marriage Medication Memory Menopause MidLife Crisis Mindfulness Monogamy Morality Motivation Neuroticism Optimism Panic Attacks Paranoia Parenting Personality Personality Disorders Persuasion Pessimism Pheromones Phobias Pornography Procrastination Psychiatry Psychologists Psychopathy Psychosis Psychotherapy PTSD Punishment Rejection Relationships Resilience Schizophrenia Self Esteem Sleep Sociopathy Stage Fright Stereotypes Stress Success Stories Synesthesia Teamwork Teenagers Temperament Tests Therapy Time Management Trauma Visualization Willpower Wisdom Worry\nFeeling Overwhelmed? Learn These Stress Management Strategies How To Stop Stressing: 7 Tips To Find Balance And Relax How Stress Can Lead To Emotional Breakdowns And What You Can Do To Avoid It Are You Under Too Much Stress? Symptoms, Treatment And Tips 7 Tips On How To Handle Stressful Situations Stress Management That Works: How To Be Less Stressed"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:8a7f09bf-a91f-434e-a4cc-5d396611bd7a>","<urn:uuid:1fe21db8-8096-462d-a9b3-85cbac331785>"],"error":null}
{"question":"Having studied at both Chinese and American institutions, I'm curious: how do Schramm and Yuan's teaching backgrounds compare in terms of their international academic experience?","answer":"Both professors have extensive international teaching experience, but in different regions. Ron Schramm has taught at multiple Chinese institutions including UIBE in Beijing, Hong Kong University of Science and Technology, CEIBS, and Shanghai Jiao Tong University, while also teaching at Columbia Business School in New York. Yuan Yuan's academic path has been more focused within Chinese institutions - he studied and taught at CAFA and Tsinghua University, earning his bachelor's, master's and PhD degrees in China, without mention of teaching abroad.","context":["New Developments in China's Financial and Economic System\nOn November 6, 2020, Professor Jin Wei interviewed Ron Schramm about new and important developments in China’s financial and economic system since the first edition of Schramm's textbook in 2015 (Routledge/Taylor&Francis): China Macro Finance: A US Perspective. Both new reforms and retrenchments in the Chinese economy were discussed as well as the fraught economic relationship with the United States. Students and scholars of China benefited by putting their own research in the context of how far China has come and where it is going in terms of economic and financial reform.\nSpeaker: Ronald Schramm, Visiting Associate Professor of International and Public Affairs, Columbia University\nProfessor Ron Schramm has spent over 30 years teaching master’s students, PhD candidates, and undergraduates around the world. Most of his career was spent teaching MBA students at Columbia Business School of New York, where he taught the widest range of courses of any faculty member. He has also taught at numerous Chinese universities, including the University of International Business and Economics (UIBE) in Beijing (as a Fulbright scholar), Hong Kong University of Science and Technology, Chinese European International Business School (CEIBS), Xian Jiao Tong Liverpool University’s International Business School of Suzhou (IBSS) (created and directed their PhD program), and Shanghai Jiao Tong University (taught the first course ever in corporate valuation). In addition, he spent three years as an economist at the International Monetary Fund working on debt workout for heavily indebted emerging economies.\nModerated by: Shang-Jin Wei, N. T. Wang Professor of Chinese Business and Economy and Professor of Finance and Economics, Columbia Business School\nDr. Shang-Jin Wei is N.T. Wang Professor of Chinese Business and Economy and Professor of Finance and Economics at Columbia University’s Graduate School of Business and School of International and Public Affairs. During 2014-2016, Dr. Wei served as Chief Economist of Asian Development Bank and Director General of its Economic Research and Regional Cooperation Department. He was ADB’s chief spokesperson on economic trends and economic development in Asia, advised ADB’s President on economic development issues, led the bank’s analytical support for regional cooperation fora including ASEAN+3 (China, Japan, and Korea) and APEC, growth strategy diagnostics for developing member countries, as well as research on macroeconomic, financial, labor market, and globalization issues. Prior to his Columbia appointment in 2007, he was Assistant Director and Chief of Trade and Investment Division at the International Monetary Fund. He was the IMF’s Chief of Mission to Myanmar (Burma) in 2004. He previously held the positions of Associate Professor of Public Policy at Harvard University, the New Century Chair in Trade and International Economics at the Brookings Institution, and Advisor at the World Bank. He has been a consultant to numerous government organizations including the U.S. Board of Governors of the Federal Reserve System, United Nations Economic Commission on Europe, and United Nations Development Program, the Asian Development Bank, and to private companies such as Pricewaterhouse Coopers. He holds a PhD in economics and M.S. in finance from the University of California, Berkeley.\nThe event is co-sponsored by the Weatherhead East Asian Institute and the APEC Study Center at Columbia University.","Editor’s Note: On May 20th, CAFA Online Graduation Season was officially launched. Within the first 24 hours, online browsing exceeded 2.13 million visitors and the number of individual visitors reached 530,000. Currently, online browsing has exceeded 2.46 million with 620,000 independent visitors from 115 countries around the world. This graduation exhibition has attracted global participation and attention.\nOffline exhibitions can collect feedback from the audience as soon as they visit, and they can accurately receive information from the art market and then become a stage for exchange and learning between students ... In comparison, we know very little about the online graduation exhibition. How do teachers from CAFA look at this new form of graduation exhibition? How do they guide students to create? What challenges did they encounter?\nCAFA ART INFO interviewed Professor Yuan Yuan from the Fundamental Department of CAFA. He shared his opinions on topics such as teaching on the postgraduate level, the difference between the Fundamental Department and the Oil Painting Department, the future development of online exhibitions, as well as the changes in students’ creations.\nInterviewee | Yuan Yuan (Professor of Fundamental Department, the School of Fine Arts, CAFA)\nInterviewer | Yang Zhonghui /CAFA ART INFO\nInterview time | May 9th, 2020\nImages | Courtesy of Professor Yuan Yuan and graduates\nTranslated by Emily and edited by Sue/CAFA ART INFO\nCAFA ART INFO: Hello, Professor Yuan. Because of the pandemic, the graduation exhibition at CAFA has changed a lot this year. We have also paid attention to the topics related to the graduation creations of students. Can you introduce the graduation creation class of the Fundamental Department to us?\nYuan Yuan: Our department is different from other departments in the School of Fine Arts. At the undergraduate level, we only have freshmen. In this case, regarding graduation creations, it basically refers to the postgraduate level. The postgraduate teaching in our department started in 2000, and it has been going for 20 years. I was only a young teacher 20 years ago and I could not guide postgraduate students at that time. Currently, I am in charge of the teaching work of the Fundamental Department. Postgraduate teaching in our department is divided into two parts. The first part is dominated by supervisors. If the supervisors’ proposals are approved by the School. They can take on their postgraduate students to complete the proposals. The other part is daily teaching, which is targeting postgraduate students from Year One and Two. The class is always structured around sketching, color, anatomy, and perspective. Based on these topics, we usually conduct indoor and outdoor sketching. It can be said that our course is always with models, classes, and tutors, which is regular professional teaching. When it comes to the third year of postgraduate study, all basic training courses are stopped and we turn our attention to thesis and graduation creation. In the Fundamental Department, we require students to connect their theses with their graduate creations, so their dissertations and final pieces are integrated. In the Year One and Year Two stages, we always invite tutors who focus on theory study, such as professor Yin Shuangxi, to give lectures on essay writing for students.\nYuan Yuan, \"Lady LL\", Oil on Canvas, 140x100cm, 2019\nOur teaching takes cultivating talent as a focus with realistic paintings as the goal, as the supervisor group almost all have an oil painting background and mainly creates oil paintings. I graduated from BA Oil Painting at CAFA, and then took MA Mural Painting in Academy of Arts & Design at Tsinghua University (Prior Central Academy of Arts and Design). After that, I returned to CAFA and followed professor Jin Shangyi on the Ph.D. program. Although I have been involved in diverse fields, I have always been involved in deep research in oil painting. No matter how my student’s ability is when he or she entered the school, I always require them to have a skill in modeling. As regards oil painting, no matter if you are a freshman, or have been learning for many years, or are already a master, the basic point is your modeling ability, which directly relates to the level of a creator or a piece of work. In this case, our fundamental course is about the training in the deep exploration of modeling ability, which is needed at an undergraduate level in terms of teaching. However, we have a higher standard of content.\nSome people do not quite understand why we stick to sketching and painting models in class for a long time. Children in kindergarten can draw an object, as can a postgraduate student or an artist, but the content, level and depth of research are completely different. For oil paintings, especially realistic oil paintings, sketching is the most basic means to improve the level. Painting various landscapes, figures, still life, etc. is a conventional training method. At the same time, sketching is also a creative method for many artists. As we know it, Freud is the most typical sketching painter. The figures are almost the theme of his life. He continued to study this subject. The objects he painted and the process of painting objects have actually become the medium of his art practice and his art itself.\nThe general characteristic of our postgraduate teaching is to seek common ground while reserving views on differences. Although the educational background and research direction of each of our tutors are generally consistent, there are still individual differences. In our previous graduation exhibition, students presented a variety of creative faces. The students’ personality and the influence of tutors are related. For students with strong personalities, tutors can retreat a little. If students’ personality is weaker, supervisors’ subjective intentions can be implemented a little more to help students find a direction for development. To some extent, postgraduate teaching is a game between teachers and students. This can also be said to be teaching according to aptitude and personality.\nYuan Yuan, \"Jesur and Nazra\", Oil on Canvas, 200x200cm, 2017\nYuan Yuan, \"Ride the wind\", Oil on Canvas, 80x100cm, 2018\nYuan Yuan, \"Military Flag Flying\", Oil on Canvas, 97x130cm, 2018\nCAFA ART INFO: You just mentioned the course in the Fundamental Department mainly focuses on oil painting. Regarding works, what is the difference between students in your department and students from the Oil Painting Department?\nYuan Yuan: Many situations determine the similarity and difference between the Oil Painting Department and the Fundamental Department. Almost all of our tutors graduated from the Oil Painting Department, so it is hard to say that there is a very big difference between the two departments. In fact, the main difference is the source of students. The students of the Oil Painting Department basically come from our department, and the students of the Fundamental Department include both the undergraduates of the Oil Painting department, the students from other departments and many students from other universities. This means that our postgraduate student sources and works will be relatively diverse, which can be clearly seen in the annual graduation exhibition.\nCAFA ART INFO: As you mentioned just now, the diverse students’ source in the Fundamental Department and the influence of tutors bring about various appearances in works. How do these specific aspects reflect in the work of the postgraduates you supervised this year?\nYuan Yuan: I am in charge of two postgraduates this year, Wang Hanyi graduated from the BA Mural Painting Department at CAFA and Chen Hui graduated from Jingdezhen Ceramic Institute in Jiangxi. The different appearances of paintings caused by different student sources are fully reflected.\nChen Hui's Graduation Creation, \"Girl's Dream\", Oil on Canvas, 120x120cm, 2020\nChen Hui's Graduation Creation, \"Secret Gardern Series\", Oil on Canvas, Variable Size, 2020\nChen Hui's Graduation Creation, \"The Peach Blossom Spring Series\", Oil on Canvas, 30x30cm, 2020\nChen Hui is sensible in color. During the three-year postgraduate study, she has worked hard to make up for her shortcomings in modeling ability. The way she draws combines my guidance with her personalized methods. When guiding her creation, my basic purpose is to retain her sensitivity to colors and the personalized and feminine color system, allowing her to create freely. Meanwhile, with the help of indoor and outdoor sketching, I gradually guide her to use colors in a more ideal way. All of this can be clearly felt in her graduation work. She showed a girl’s sensitive thoughts, color judgment and emotional characteristics on feminine colors very well.\nChen Hui's Graduation Creation, \"Flower Series\", Oil on Canvas, 30x30cmx4, 2020\nChen Hui's Graduation Creation, \"View of Jiangnan\", Oil on Canvas\nAlthough Wang Hanyi graduated from the Mural Painting Department of CAFA, he cannot be regarded as a typical student with the characteristics of the Mural Painting Department. The murals are relatively flat and decorative, but his abilities in sketching, character-shaping, and in-depth depiction are relatively strong, which allows him to control the details well. His work is closer to oil painting. In this case, I hope that he can draw as deep and detailed as possible. He is interested in researching urban life and I offered him a lot of suggestions. Some of my ideas are reflected in his works, but they are also tailored according to Wang Hanyi's own abilities and interests.\nWang Hanyi's Graduation Creation, \"Window\", Oil on Canvas\nWang Hanyi's Graduation Creation, \"Window\", Oil on Canvas-sketch\nWang Hanyi, \"City Window Series\", Sketches\nCAFA ART INFO: How did the pandemic affect postgraduate teaching and the students’ graduation creation in the Fundamental Department?\nYuan Yuan: The impact of the pandemic in terms of students’ graduation creations is not great in our department. We settled the final direction of the students’ presentation at the end of last semester. What we need to discuss with students are the details. The only change would be the sizes of works. At that time, students could only create from home without the use of a studio in the school and we were not sure if they could actually present their work, so we suggested students abandon large-scale paintings due to the transportation difficulties. Thanks to the internet, the communication between teachers and students is quite smooth. Compared to face-to-face communication, online communication can be clearer and more comprehensive. Students majoring in fine arts mainly create paintings on easels, although we may lose some texture and detail from the judgments through online supervision, we were able to focus on the entire effects of the works. Moreover, students are less disturbed at home, which can help them concentrate on thesis and creations.\nProfessor Yuan Yuan was guiding students online.\nI think the postgraduate teaching during the pandemic showed a tendency to return to the origin of painting. Due to the pandemic, students have to stay at home, observe life, paint, and complete the assignments arranged by the teacher in a familiar environment. In fact, these assignments were also designed around their surroundings, forcing them to observe what they are familiar with, painting family members, objects at home, and the surrounding sceneries, which has a more personal creative meaning than sketching in the school classroom. What is the relationship between this new teaching model and our classroom teaching? Because of the pandemic situation, our teaching requirements are more closely integrated with students’ self-expression and observation of life and their paintings are more sentimental. Although the works are smaller in size, shorter in time and less in-depth. They are more vivid, with a more personal feeling and personal life inside, I think it is more intimate.\nChen Hui‘s Graduation Creation - Sketches\nWang Hanyi, \"Still LIfe Series\", Oil on Canvas, 2020\nDuring the pandemic, Guan Yilin was sketching outside.\nGuan Yilin's work, Acrylic on Canvas, 20x20cm, 2020\nGuan Yilin's sketches, 2020\nHuang Yinyu's work, 2020\nCAFA ART INFO: This year, CAFA announced a \"virtual exhibition hall\" for the first time. How do you see the future of this new form of graduation display? Are different types of artists suitable for online presentations?\nYuan Yuan: Online exhibitions are the direction of the future. The pandemic allows the online display to be realized and promoted. From my point of view, I think the online exhibition will be the norm in the future and it will be more dazzling than offline museums, because the exhibition of physical museums is subject to various restrictions on space, light, exhibition location, etc., but online displays can present the concept of a perfect museum. The online art museum is not necessarily a copy of the physical art museum but it considers presenting works in the best way. For example, the video and installation work from the School of Experimental Art can be fully displayed online without restrictions from physical space. For students major in fine arts, everyone’s painting can be placed in a great place and angle online. It is the advantage of online display. The problems in terms of “the best place to present” among others are solved in the online version. Every exhibition hall is perfect in this way.\nAs for the online graduation exhibition of CAFA, we do have some specific technical issues. As students completed their work from home, photographing can be a big problem, which includes accuracy and pixel difficulties. In the future, the online exhibition may be more interesting than offline display, as the perfect presentation is at its core. Once the technical problems are solved, the online exhibition hall would shift to an e-book, which can be read anytime and anywhere. It is intimate and it changes with people’s reading method at present.\nGoing back to the question you just asked, if artists have to face online exhibitions in the future, there will indeed be a difference here. When you are an installation artist, you will be affected a bit more, while oil painting artists will be less affected. Purely from the perspective of display effects, my feeling is that the improvement of online art museums should be based on 5G technology.\nYuan Yuan, \"Daughter of Dunhuang\", Oil on Canvas, 180x180cm, 2019\nYuan Yuan, \"Lily\", Oil on Canvas, 130x97cm, 2016\nYuan Yuan, \"New City\", Oil on Canvas, 110x160cm, 2000\nCAFA ART INFO: Some people hold the view that the offline exhibition may be replaced by the online display. What is your opinion?\nYuan Yuan: With such a perfect online exhibition, will people still visit the offline exhibition? I think both of them have to be maintained, because the offline exhibition is in a physical space, with a concrete size and is perceptible. Viewing one thing can be different in terms of feelings online and offline. Some things require the audience to participate, such as installation works and the sculpture is tactile, including its volume, which can only be felt on site. From this point of view, online exhibitions cannot replace physical exhibitions.\nCAFA ART INFO: How about your graduation creation? Can you talk about this?\nYuan Yuan: My feeling may have a lot to do with my oil painting creation. At the BA and MA level, I would deliberately draw a piece for my graduation creation. However, my doctoral graduation work is actually a piece I usually draw. With the improvement of personal ability and aesthetic cultivation, even if you just paint a portrait and a sketch, it may have some creative factors in it. It will no longer be a simple exercise, but a piece of work. This is my personal feeling. I am not in favor of drawing work very deliberately. The concept of creation may be related to the them, or it may be related to language. From this perspective, it can be understood that practice and creation should not be treated differently. I think it may be more appropriate to use the concept of work because it is more related to creativity.\nYuan Yuan's Doctoral Graduation Work, \"Smoking Girl\", Oil on Canvas, 200x100cm, 2011\nCAFA ART INFO: Finally, please send wishes to all graduates this year.\nYuan Yuan: Graduating from the postgraduate program is the beginning of a new life stage for you. In the days to come, you might be successful, and you will encounter ups and downs, success and failure. As alumni of the Central Academy of Fine Arts, you have to believe in yourself and do the process well and you will always welcome joy. I hope you all have a bright future.\nYuan Yuan, \"Untiled\", Oil on Canvas, 180x180cm, 2009\nYuan Yuan, \"Staring I\", Oil on Canvas, 180x150cm, 2012\nYuan Yuan, \"Staring II\", Oil on Canvas\nAbout Artist Yuan Yuan\nYuan Yuan, born in 1971 in Nanjing City, Jiangsu Province, Ph.D., is currently a professor at the Central Academy of Fine Arts, a supervisor for master students, and a Deputy Dean of the Fundamental Department at the School of Fine Arts. His oil paintings “Memories of the Monument”, “Su He” and many other works have been collected by many museums and institutions such as the National Museum of China, General Administration of Sport of China, National Centre for the Performing Arts, CAFA Art Museum, the Dadu Art Gallery, and the Taiwan Changliu Art Gallery.\nIn 2013, he graduated from the Central Academy of Fine Arts with a Ph.D. degree under the supervision of Professor Jin Shangyi.\nIn 1997, he graduated from the Decorative Arts Department of Central Academy of Arts and Design (Now the Academy of Arts and Design, Tsinghua University) under the supervision of Du Dakai with a master's degree. In the same year, he entered the Mural Painting Department of the Central Academy of Fine Arts to teach.\nIn 1994, he graduated from Studio One of the Oil Painting Department at the Central Academy of Fine Arts with a bachelor's degree.\nIn 1990, he graduated from the High School Affiliated to the Central Academy of Fine Arts."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:c95d454f-bf15-41ca-89cd-f3353b92ab46>","<urn:uuid:bac7fde7-64d0-4a9e-bc92-6e6955837ff5>"],"error":null}
{"question":"Are arrow wounds or gunshot wounds easier to treat in terms of projectile removal?","answer":"Gunshot wounds are generally easier to treat in terms of projectile removal. With arrow wounds, the arrowhead must be located and extracted since it cannot remain in the body - its rough edges prevent healing and cause infection. In contrast, an 18th century bullet could become encysted in tissue or encased in bone and safely remain in the body. For gunshot wounds, while bullet pieces may sometimes need to be removed, in some cases leaving small shards in place may cause less damage than attempting removal.","context":["Battle wounds in the American Revolutionary War were of a wide variety, none of which were easy to treat medically. One of the worst was when the victim was struck by an arrow. While the vast majority of combatants carried muskets or rifles, bows and arrows were used, sometimes along with a musket, by Native Americans.\nMedical texts during the Revolutionary War period are silent regarding the treatment for arrow wounds. The most complete and detailed account of arrow wounds and treatments is Dr. Joseph Howland Bill’s “Notes on Arrow Wounds,” which is considered the “definitive work on American arrow wounds.”\nDr. Bill did not practice during the American Revolution. He served during the Civil War. However, the wounds he dealt with would have been comparable to those of the 18th century. Bill was originally from Philadelphia and attended Jefferson Medical College. After graduation he joined the U.S. Army, was commissioned 1st Lieutenant, and in 1860 was assigned to Fort Defiance, New Mexico. There he wrote his 22-page essay, “Notes on Arrow Wounds,” published in the American Journal of Medical Sciences, 1862. In less than a year Bill was transferred east. He continued to serve in the Army until his death in 1885.\nBill states arrows inflict wounds “with a fatality greater than that produced by any other weapons — particularly when surgical assistance cannot be obtained.” Bill understood the importance of recording his observations for the Army and future settlers as well as documenting his experiences and findings, from both living and dead arrow wound victims, for history and medicine.\nArrowheads could be made from stone, antlers, shells, hardwood, bone, or metal. The arrowheads Dr. Bill most encountered were filed metal while the shaft was usually made from a dogwood branch. For the shaft the dogwood branch was soaked, all the bark removed, and then the limb was straightened using a twisting method. This whole straightening process took about three days. Feathers were also an important part of the arrow. The size and type of feather used determined the speed and rotation of the arrow. The heavier the arrowhead the larger the feathers needed to spin the arrow.\nOnce the shaft was ready, the arrowhead was attached using tendons and sinews. This kept the head secure, until the tendon got wet. Once wet, the arrowhead would become loose and easily separate from the shaft. So, when the arrow penetrated the body the arrowhead would loosen from its contact with blood and other bodily fluids. Dr. Bill explains the worst thing a friend could do was to try to remove the arrow by pulling on the shaft, which would cause the arrowhead to be left behind forcing the doctor to search for the projectile.\nIn some situations the arrow proved more destructive to the victim and more difficult to treat for the doctor than a gunshot wound. The problems came from the nature of arrow warfare and the shape and texture of the projectile. Dr. Bill estimates an “expert bowman can easily discharge six arrows per minute.” In one of Dr. Bill’s cases three soldiers suffered a total of 42 arrow wounds between them. Although this number of wounds was extreme, Bill states he rarely saw someone with a single arrow wound.\nFurther complicating the multiple wounds was that each arrowhead had to be removed. Unlike a gunshot wound, the arrowhead must be located and extracted. Arrowheads were rough and sharp. No tissue around the arrowhead could heal and in the body’s attempt to rid itself of the foreign object infection would rage forming an abscess. Every time the victim moved the arrowhead’s rough edges would inflame and aggravate the injury and eventually lead to a fatal infection or amputation. In contrast a 18th century bullet did not have the sharp edges and could become encysted in tissue or encased in bone and safely remain in the body. The importance of removal is clear in Dr. Bill’s instructions: “We might as well cut the patient’s limb up until we do find the arrow-head.”\nNow the gravity of a friend’s attempt to pull the arrow from a wounded comrade becomes apparent. If the shaft was left in place, Dr. Bill’s treatment was to make an incision to enlarge the entry wound and slide a finger down the shaft to feel the depth of the wound and determine if the arrowhead is lodged in bone. Without the shaft in place the doctor was forced to search for the arrow by making a larger incision, probing through tissue, causing more trauma, and taking more time. It was much easier for the doctor and patient if the shaft was left intact until a doctor could remove the head and shaft as one piece. Further, there was always the danger that the arrowhead could not be found leaving the “angular and jagged head… buried in bone to kill – for so it surely will.” If, however, the arrowhead is removed properly, the wound was likely to heal naturally.\nIf lodged in bone, the doctor could expect to use great force to remove the head. Special instruments were usually employed for this procedure. For instance, a wire loop was often used to grasp the arrowhead, but Dr. Bill frequently reported using strong dental tooth-forceps. The doctor would guide the forceps down his finger and onto the arrowhead. Once the forceps grasped the arrowhead the finger was withdrawn and traction could be applied. Sometimes, however, the arrowhead would be lodged so deeply in bone the forceps would bend from the force of the traction used.\nOne method to determine if the arrowhead was lodged in bone was by “twirling the shaft,” if the shaft moved the arrowhead was declared not to be lodged in bone. The force needed to remove an arrowhead embedded in bone was surprising. In one particular case Private Bishop was hit in the upper arm near the shoulder. Dr. Bill describes his effort; “…and bracing my knees against the patient’s thorax, I applied all the traction I could muster. Suddenly the arrow-head flew out of its seat, and I would have fallen on the floor, had not the steward caught me.” In 1876 Dr. Bill presented his own design of forceps specifically for removing arrowheads.\nMuch of the victims’ chance of survival depended on where they were injured and how deep the wound. A number of injuries to the arms were reported, probably because soldiers would attempt to shield themselves with their arms and hands. If the arrow went through a limb it would usually heal normally. The entrance wound appeared as a “very small and narrow slit“ surrounded by a reddish bruise while the exit wound would be larger but without the bruise. For the treatment of this kind of wound Bill would apply “cold or evaporating lotions” and order the patient to allow the injured arm or leg to rest. Meanwhile Bill would watch for any sign of infection which he would treat with “bandages, compresses, and an early evacuation” of any drainage if necessary. Barring any infections, however, the injury would generally heal in a week.\nComplications could occur, however. For instance, even though doctors knew how to treat a severed artery, medical help often could not be obtained in time to stop the victim from bleeding to death. Other complications included fractures, broken bones, and severed nerves, but if the arrowhead was removed these injuries were not usually fatal. One particular example of a complication and Bill’s skill is that of Private Martin of the 3rd Infantry. Martin suffered an arrow wound to his right leg; while the arrow did pass through, Martin was left with “agonizing pain” in his toes and foot. The arrow had injured a major nerve, which Dr. Bill divided to stop the pain.\nOne particular complication of limb wounds involved muscle contractions. If the arrowhead “scrapes the bone near the edge” it could cause a muscle contraction so forceful the metal arrowhead tip was bent to resemble a “fish-hook.” Apparently this complication was common enough for Bill to write “that the digital examination of arrow wounds should always be practised” because if the arrow head is bent upward pulling on it would only injure the victim more. Two precautions should be taken. First, the doctor should push down on the arrowhead to dislodge the hook and then the doctor’s finger should remain on the curved point of the arrowhead during the removal “in order to prevent the entangling” of the hook in any tissue. Bill treated two men who suffered this complication. In the first injury the arrowhead had wrapped around the ulna in the forearm, and the second, around the fibula in the lower leg.\nSome of Bill’s most interesting cases involved the head. Bill reports on a total of five head wounds. In three of the cases the brain was wounded and two men died and in the two cases where the brain was not injured both men lived. Unless the arrow was fired straight at the head from a short distance it usually did not penetrate the skull. According to Bill the danger of a headshot came mainly from compression of the outer table of the skull since few arrows reached the brain itself. The result of cerebral compression can include unconsciousness, slowed respirations, high blood pressure, fever, and rapid pulse. Thus, the doctor would have to not only remove the arrowhead but also trephine the skull to release the pressure. Usually fatal were hits to the “orbit” or eye socket but Bill never treated this particular wound himself.\nA post guide named Miguel was hit on the left side of his skull by an arrow. By the time Miguel reached Bill someone had removed the shaft and Miguel was suffering from the symptoms of compression sickness. Bill prepared to trephine the skull after he removed the arrowhead. However, once the arrowhead was dislodged “symptoms of compression at once vanished, the man turned over and sneezed, and rose up on his feet.” Later Miguel had to be treated for a headache but otherwise recovered fully.\nA great deal of Dr. Bill’s essay describes wounds of the trunk. The chest and abdomen represent the largest part of the human body and house the majority of the major organs. The bowmen knew that a hit to the trunk was likely to be fatal and is where they aimed. Thus, the trunk received more injuries than other areas of the body. Moreover, particular care had to be allotted for all trunk injuries until the location and depth of the wound could be ascertained because any arrowhead could be potentially lodged in the spine, which was usually fatal. Bill would use his knowledge of anatomy and arrow wounds to ascertain if an arrowhead was more likely to be lodged in a rib or vertebrae from the length of the exposed shaft.\nAn arrow wound to the lung, explains Bill, is much more dangerous than a gunshot wound for three reasons: amount of blood loss, infection, and emphysema. For example, arrow wounds cause more bleeding than gunshot wounds because an arrow “makes clean slits and punctures” while a “ball tears and bruises.” Bill also explains arrows tend to lodge themselves in the lung “whilst a ball generally passes” causing empysema, an infection in the body cavity. Bill states the “third danger peculiar to arrow wounds of lung is the supervention of emphysema” about twelve hours after the injury occurred. Emphysema is a condition where the air spaces in the lungs are distended causing difficulty in breathing. However, Bill goes on to say that the onset of emphysema is more of a nuisance than danger.\nOf the fifteen men Bill saw with chest wounds, six had injured lungs and four of them died. Of the nine men without injuries to the lungs all survived. The wide range of chest injuries Bill encountered demonstrates the nature of complications possible. From the five detailed cases that included chest wounds, chest wounds were usually accompanied by infections, such as the case of Salvador Martinez. An arrow entered Martinez‘s chest “between the fifth and sixth ribs on the right side, and passed out between the seventh and eighth on the left.” When Martinez saw Dr. Bill he was having difficulty breathing and in great pain. Bill treated Martinez aggressively for sixteen days but was unable to save him. Upon a postmortem examination Bill found the right lung “solidified and engorged with pus” and the left lung also full of infectious matter.\nAbdominal wounds also proved to be exceedingly dangerous because unlike the lungs the abdomen is not protected by the rib cage. Of Bill’s twenty-one abdominal cases all but one was fatal. As Bill states, “Arrow wounds of the abdomen are generally fatal. An arrow can scarcely pass through the abdomen and fail to open a vessel or wound an intestine.” If the abdominal wall is breached the main threat is from a hemorrhage or an infection resulting from a punctured intestine. Bill recommends enlarging the wound in order to examine the abdominal cavity. If the intestines are lacerated, gold wire was used to suture the injury. Again, the arrowhead must be removed if the patient was to have a chance at recovery.\nOverall Bill reports he “observed” eighty arrow wounds, the majority to the trunk, thirty-six in all. Of these thirty-six men injured twenty-two died. The extremities are next with a total of 35 wounds.\nBill’s observations from treating the wounded as well as his empirical postmortem research provided the medical community then and the history community today with the only documentation for the nature and treatment of arrow wounds.\nThe author wishes to thank Lisa A. Ennis for her assistance with the research of this article.","Gunshot wounds are extremely traumatic and painful for the injured person. While there are ways for you to stabilize the injured person, they still need to get to a hospital as quickly as possible. If you have a first-aid kit and know how to treat a gunshot wound you can do so immediately when you find the injured person. You may not be able to assess how much damage has been done, but controlling the bleeding may be the difference between life and death for the victim.\nIn the meantime, there are steps you can perform to ensure that you give the victim as much care and attention as you possibly can. It is vital that you act no later than 10 minutes after the gunshot itself. There are different gunshot wounds depending on where the person is hit, e.g. the head, abdomen or limbs (legs or arms). For these different areas, different procedures are needed and you must not mix one treatment for a different wound, or there is a risk to worsen the victim’s condition.\nHow the damage occurs\nBefore we get to explaining how to treat a gunshot wound we need to look a bit closer to how the damage occurs in the first place. First of all let’s take a look what a bullet looks like. It’s a small casing, which contains powder charge. As a person shots the bullet, it will fly at an incredible speed – about 1500 meters per second – the speed varies and depends on the actual bullet, its weight and the gun it’s been shot from.\nAs the bullet hits a target, the powder charge explodes and damages everything nearby. Usually the upper body (head and abdomen) are most vulnerable, and if hit by a bullet, the person may suffer rapid blood loss and serious damage to internal and vital organs.\nLet’s look even closer to how much damage a gunshot bullet can cause. As the bullet penetrates the body, it will start tearing tissue, muscles and other body structures along its path. Some non-elastic tissues like the brain may suffer more, since they can’t recoil back, like other tissues (skin for example) can. Usually, a ‘cavity’ appears at the injured place, which can’t be repaired and the wound is opened to infection and high risk of blood loss. In some cases a bullet may penetrate the body on one side and leave it on the other, which may even further progress the loss of blood.\nThe result of a gunshot wound may be various but most often the injuries are the following:\n- Heavy bleeding/blood loss\n- Injury to vital organs\n- Broken bones\nUsually surgery is necessary to remove the bullet’s pieces and if there are broken bones, the bones’ pieces must also be removed, since they can severely damage nearby tissues and/or organs. Also, the wound must be washed, disinfected and sewn.\nTreating a gunshot wound\nBefore you begin treating the wound you need to assess the severity of the damage. You have to look for the bullet and even may have to remove it, so you can safely clean the wound. If the bullet remains in the wound an infection may progress and make the victim’s condition far worse.\nIn other cases, there may be small shards from the bullet that have remained around the wound, but it may cause more damage by trying to remove them, rather than if you just leave them there. If you’re in the surgery and medical personnel can do the operation, then they can also remove all pieces from the wound.\nIf you’re somewhere in the wild, and far from a hospital or the emergency, you should at least try to remove the larger pieces of the bullet, so you can clean and disinfect the wound. You have to bandage the wound and make sure you have stopped the bleeding, before you can find a hospital. You must change the bandage regularly and keep it clean all the time, so you can prevent infection. This may be your main concern. If you managed to control the bleeding, then the next threat to you is infection. In order to perform all these, you will have to have a well-equipped first-aid kit (we have a great set of reviews here).\nIf you have antibiotics, by all means, take some. They will prevent the progress of any infection, which may have started as you got wounded. Also, don’t hesitate to take any painkillers (if you have any). They will subdue the pain and will keep you sane and focused to find your way to civilization so you can get adequate help. If you don’t know how to determine if a wound or cut is infected, take a look at our article on how to tell if infection occurred.\nAnd here is another important thing, which may help you. Depending on where you got shot, you have to keep the wound higher in elevation from the heart. For example, if you got shot in the leg, the best thing to do is to prop the leg slightly elevated, above the heart level. This will prevent from blood surging into your leg and causing too much swelling.\nIf someone else (your camping/hiking companion, friend or relative) got shot you will have to treat them yourself, before you can get to a hospital. Your first 5 actions are the so-called ‘A, B, C, D, E’. Here is what they mean:\n- Airway (A) – This is one of the most important things you must check first, meaning, can the person still breathe. If they are conscious and can speak, and don’t seem to struggle breathing, then they are fine, and the airway passage is clean. In the cases when the person is unconscious you have to assess if they can breathe or if the airway passage is obstructed somehow.\nCheck their throat by opening their mouth and see if there’s something blocking the airway passage. If the tongue is in the way, try to remove if from the way. It is often possible that the shock caused the person to literally swallow their tongue, which causes them to suffocate. If the tongue isn’t in the way, then maybe there’s blood accumulated in the throat (if for example the person was shot in the lungs, throat or other vital organs damaging the lungs).\nTry to remove the accumulated blood, by either turning the person around so the blood seeps out of the mouth, or you can soak it up with a piece of cloth.\n- Breathing (B) – If you successfully performed the above, then you probably have already determined if the person can breathe or not. If for example, there haven’t been any airway passage obstruction and yet the person in unconscious, there is a chance that maybe they don’t breathe. You may have to perform mouth-to-mouth to make the person breathe again.\nAlways check if the chest is rising or falling (a good indication for breathing). Also, don’t ignore factors like weird, rapid or in any way unnatural breathing the person has, even if they are conscious. There is a chance that something is going on and you must be alert of any changes in the victim’s behavior.\n- Circulation (C) – This is related to the blood circulation and to what extend it may cause serious blood loss. You must apply pressure on the wound so you can minimize as much as you can any further blood loss, which may occur. Also, check regularly the victim’s pulse, either at the wrist, or the throat. If the person is unconscious, and they don’t have a pulse you may have to perform CPR (rescue breathing).\n- Disability/Deformity (D) – This check is important before moving on to helping the victim. What this means is that if the person has an injury to the spinal cord (disability), and you try to move them, position them somehow different from how you found them, could potentially make their situation worse, to the extent that they remain permanently disabled.\nBy deformity we mean that the person may suffer an injury, which somehow deforms their body in an unnatural way (strangely broken limbs, joints, etc). These are closely related to the nervous system and any movement may cause even more damage. This is why it is so vital that you first assess these before you proceed to any action.\nUsually the Red Cross advises that, if a person suffers from a spinal cord injury, they should not be moved until help comes, or if you have to move them to help them breathe for example, you have to be extra careful and move them very slowly. But this is only in extreme situations where a person doesn’t breathe. Helping them breathe is of top priority.\n- Exposure (E) – It is also important that you find all the bullet wounds that you can, including any possible exit wound. You may have to look even the armpits and other such difficult to access areas. You are not advised though to completely undress the injured person, as this may cause shock for them.\nHow to properly treat different parts of the victim’s body\nAfter you’ve assessed the victim’s condition, you have to prioritize your actions. If the wound is severe and bleeds a lot, you must immediately find a way to stop the bleeding. The first thing to do is to apply pressure directly over the wound. You could use pads, clothing or even your fingers to apply pressure and try to control the heavy bleeding. Find clean pieces of cloth and bandage the wound. Use as much clothing as you can find, but make sure they are clean, or you may expose the victim to infection.\nIf any limb has been shot (arm, leg or thigh) you could apply pressure to specific areas near the wounds. For example, if the person is shot in the arm, you could press the area of the armpit, since there is an artery there and it leads directly to the heart. If you press that artery, less blood will be pumped by the heart to the arm and as a result the blood loss will be reduced. If you have some paracord around, you can use it to create a rudimentary tourniquet. If you don’t know how, take a look at our tutorial here.\nThe same applies to injuries on the legs or thighs. There is a similar artery near the bikini area, so you can press that area. It is possible that you can even feel the pulse there. Press the artery and the blood loss should diminish somewhat.\nIn cases when the gunshot wound is in the abdomen (torso) area, and vital organs may be damaged, it is usually difficult to do anything for the person, without special medical attention. Yet, some commercial products like QuikClot and Celox could help in a way. The principle behind these products is that they increase the blood clotting extremely quickly and could be helpful in severe cases.\nFor example, QuikClot contains kaolin, which is a potent chemical, accelerating the blood clotting. Celox works on the same principle and could be applied as a gauze, and claim that it’s possible to stop the bleeding within no more than 5 minutes of applying pressure to the open wound.\nThese products are mostly manufactured for the military, but they are open to purchasing to the general public. For example, you could purchase several Celox gauze and carry them always in your backpack as a life-saving measure in case an incident happens.\nYou are often advised to get to know the instructions and read the manual for using, but it is often much simpler, and you have to simply apply the pad and hold it slightly pressed to the wound so that it can do its work. As we said, 5 minutes are enough to have significantly affected the blood loss.\nAlso, you have to be prepared that the victim may suffer shock. This is a traumatic event and it can affect the victim’s behavior. Not only that but the injury itself, pain and blood loss are also affecting factors and can lead to a state of shock. In order to help the victim as much as possible, try to keep them warm (if they feel cold to the skin) or try to fan them if they are hot and seem to have a fever (possibly an infection is going on).\nIf you have antibiotics, you should administer them to prevent the spread of the infection. And again, don’t attempt to elevate the legs, if the wound is on the abdomen/torso area. There is a risk that the person may begin to suffocate due to the blood accumulation in the torso area.\nYou need to be psychologically prepared that a gunshot wound in the head is in most cases fatal. There is little you can do. The only thing that is in your hands is to get the person to a hospital as soon as humanely possible, and also, try to keep the head upright. If the head is positioned horizontally it may more rapidly fill with blood and thus the brain may swell and even if the person was still alive, an infection and brain swelling can kill them much more quickly.\nAreas like the face and neck tend to bleed profusely. The victim can lose significant amount of blood within less than a minute or two and if you don’t apply pressure immediately, the end can be fatal. The only thing to consider when applying pressure to the neck is that you don’t press the carotid arteries. They are the passage for blood to the brain and if you press these arteries, the brain will end up being oxygen deficient and you may cause even more damage to the person (leading to coma or brain death).\nAnother thing to consider is wounds to the chest and back. You must be prepared that these area also hard to treat, since the rib cage obstructs the access to the actual wound. Sometimes, lungs may be punctured by the gunshot and as the person breathes in and out, they may draw blood in the lungs (and can literally drown in their own blood). This is called ‘sucking chest wound’. To prevent that from happening, you should try to tightly seal the lung wound with a plastic or an airtight bandage.\nAs you apply it, press the bandage on three sides around the wound, but leave the fourth side open, so that you can allow the chest to have its negative pressure. The idea is that as the person inhales, the air will escape from the fourth opening/valve, and no blood will enter the wound.\nFinal tips on treating a wound\nAs you manage to get the victim to the emergency, you must tell them exactly what you did so far to stabilize the person. Also, you must remember that pressure is the major key factor to keeping a person alive as long as possible.\nWhen it comes to spinal cord injuries, as we said, move slowly, and also, try to keep the neck, head and back in one line (aligned). This will ensure that there is no further damage to any nerves.\nKeep in mind that, even if you can control the outer wound, there may be internal bleeding. You may not be able to do much about that, and it may be the thing which worsens the victim’s condition. So, even if you managed to successfully treat the exit/enter wounds, the internal damage may be far more severe.\nAnd finally, as we said, it is possible that a gunshot wound be fatal for the victim. Do not risk your own life. As long as you are safe, you can proceed to helping the victim. If you are the injured person and you’re conscious you can apply the above advice."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:2f095014-721b-49bd-a6ed-0e5c4bf683b1>","<urn:uuid:1dab3eb9-3c3f-4163-bd88-2aaec4a49539>"],"error":null}
{"question":"Para usar el AutoGlow 200 en limpieza por plasma, ¿cuáles son las configuraciones posibles de las muestras y sus efectos?","answer":"The AutoGlow 200 offers three different configuration options: 1) Placing samples on the bottom shelf for a more aggressive reaction when using Ar or other process gases, 2) Configuring the ground shelf below the powered shelf and placing samples on the grounded electrode for a less aggressive reaction, or 3) Placing samples on the very bottom of the chamber with a floating ground configuration, which some customers report good results with.","context":["Plasma Cleaning Prior to Wire Bonding and Gold Bump Flip Chip\nPlasma technology is often characterized as a “dry” plasma cleaning process, using ionized gases in vacuum chambers. Typically these oxides are very thin, and if left on bond pads, could contribute to bond strength degradation in both wire bonding and gold bump flip chip applications. Plasma Cleaning Prior to Wire Bonding and Gold Bump Plasma cleaning can remove contaminants to improve yields in gold bonding processes.\n- The surface modification deals with altering the molecular makeup of the substrate and die surfaces of interest.\n- Plasma cleaning prior to wire bonding, and plasma treatment in this application will result in a rougher surface that becomes more hydrophilic,thus improving underfill and encapsulant wetting and adhesion.\nContamination on Gold Bond Pads\nDie attach and subsequent adhesive cure steps can cause contamination to form on substrate or package gold bond pads. Untreated, this can lead to no-sticks or low ball shear at the wire bonding operation. Oftentimes the wire bonder is thought to be faulty. The use of plasma cleaning also extends to gold stud bump flip chip bonding. Studies prove that Ar plasma treatment improves the die shear strength of these joints as well.\nPlasma Surface Modification\n- Oxygen plasma cleaning improves adhesion of fluids to substrates, namely underfills and encapsulants. For example, an untreated substrate surface may be hydrophobic, causing voids and/or slow underfill wetting. Unlike unreactive argon gas, oxygen plasma breaks down into O+ ions and neutral O radicals where the radicals are of main interest.\n- Unaffected by the electric field in the chamber, these highly reactive species find their way under flip chip gaps.\n- This is key, because it is precisely the area where chemical functionalization needs to occur.\n- The radicals graft additional molecular structures on the surface of the substrate and bottom of die, which appear as a roughening or texturing.\n- Thus resulting in a more hydrophilic surface as shown by water contact angle measurements.\nPlasma cleaning and surface modification technology is a necessary step in the microelectronics assembly process. Argon plasma in a parallel plate (RIE) vacuum chamber design has proven effective at removing nickel compounds from gold bond pad surfaces. As engineers look to reduce Au plating thicknesses to save on material costs, the propensity for nickel migration increases and thus the need to remove these surface impurities by plasma treatment. With Au thicknesses down to 50nm (2 <µin) being introduced, an objective review of the plasma cleaning method in place is important to insure quality remains high in the wire bonding and flip chip attach steps.\nThe AutoGlow 200 can be used for plasma cleaning prior to bonding. Placing samples on bottom shelf will allow for a more aggressive reaction when using Ar or other process gases (see below):\nFor a less aggressive reaction, configure the ground shelf below the powered shelf–then place your samples on the grounded electrode (see below):\nSome Customers report good results by placing samples on the very bottom of the chamber with the above configuration. The bottom of the chamber will be a floating ground.\nWe have Customers that also use the GLOW system for cleaning/treatment prior to wire bonding. Most Customers use argon gas for this application. Click here for more information on the GLOW plasma system.\nPaper from Research Gate…Effects of plasma cleaning on the reliability of wire bonding: click HERE"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:32560b21-cf58-44fb-82da-da27bfd4c9bb>"],"error":null}
{"question":"Help! My baby gets allergic reactions to food and now has a weird rash - what's the connection between food allergies and skin conditions in infants? 🤔","answer":"Food allergies and skin conditions in infants are closely related. Food allergies can manifest as skin symptoms including itching, boils, eczema, face redness, and swelling. When introducing solid foods around 4-6 months, babies commonly develop rashes and hives as their immune systems are still developing. Allergic reactions are very common in babies since their immune systems need time to develop, and if breastfeeding, the mother's diet can affect breast milk and cause reactions in the baby. Common allergic triggers include peanuts, dairy milk, and shellfish. Additionally, baby skin is extremely sensitive in the first 12 months of life, making them prone to various skin conditions. While some rashes are due to allergies, others may be common conditions like milia, nappy rash, or fungal infections that clear up without treatment.","context":["Defining food allergy: Food allergy is the body’s response or reaction or way to fight back and resist certain types of protein found in food. Usually, an allergy reaction appears very soon after the consumption of any kind of food called food allergen. Its symptoms can range in severity between mild and profound. And because they are quite similar to signs of other illnesses, we advise you to read on this article and get to know the differences so you would be able to help your child if he gets allergic.\nIn general, food allergy in babies and children has a wide variety of symptoms, some of them are related to skin and heart muscles, some others are related to respiratory and digestive systems, like: itching, boils, eczema, face or extremity redness and swelling, lip or tongue or mouth swelling, abdomen pains, nausea, vomiting or diarrhea, sneezing, coughing, shortness of breath, wheezing, dizziness or fainting.\nWhenever the allergy affects more than one of the functions mentioned above, it becomes a severe response and a life-threatening danger. In that case, allergy is known as Anaphylaxis that requires an immediate medical intervention.\nIt is to be noted that food allergy is completely different from food-borne illnesses like food poisoning, skin rash and diarrhea. It is also different from congenital intolerances towards particular types of food or hypersensitivities to some dietary ingredients added to food, such as food coloring and preservatives.\nAccording to some resources, allergy conditions are very common among children coming from families with a long history of asthma, eczema, Scarlet fever and food allergy. If your child belongs to this category, we advise you to breastfeed him for at least the first year (exclusive breastfeeding for 6 months and breastfeeding with complementary foods for at least 12 months). And when it’s time for him to enter the world of solid foods, we ask you to be patient with him.\nTry to introduce allergenic foods to your bundle of joy one at a time. Make sure you observe him closely to see if he experiences an adverse reaction towards any of them. Here are some examples of allergenic foods: cow milk, eggs, wheat, soya, peanuts, nuts (like walnuts, pistachios), seeds (like sesame), fish (like tuna and salmon) and mollusks (like oysters and shrimps).\nFortunately, most children with allergy to milk or eggs or soya or wheat, outgrow their health issue without medication, while 75% of children allergic to nuts, peanuts, seeds and seafood, continue to struggle with their condition as adults.\nIf you’re wondering about ways and measures to prevent your baby from getting food allergy, well, and as confirmed by many medical research, there are no clear guidelines in this concern, but it would be a plus if you can follow these beneficial tips:\n- Breastfeed your baby exclusively until he’s 6 months old.\n- Keep on breastfeeding your baby while you introduce him to solid food.\n- Abstain from smoking while breastfeeding.\n- Keep your baby away from all form of smoking.\nBut if you suspect your baby has food allergy, it’s better to take him to the doctor who will ask about your family medical history, your child’s symptoms, when they first appear and how often do they recur, as well as he will carry out some tests and examinations.\nOnce the diagnosis is confirmed, you will be asked to do your best to keep your child away from the food that irritate him and cause him allergy, since there are no effective medications for allergy conditions and treatment is limited to dealing with signs and symptoms resulting from same:\n- Read the nutrition labels on food packages and check whether they contain or not the substance that irritate your child.\n- Be careful when you eat with your child in restaurants. Always check the ingredients of the dishes that you choose for him.\n- Inform your family members and school or nursery personnel about your child’s condition.\n- Follow the doctor’s instructions and keep your child’s medications at hand if his condition is severe and requires such a precaution.\nAnd above all, don’t let food allergy affect your child’s life in a negative way. Help him cope with his condition and use it as a stimulus to maintain a healthy living style and make healthy nutritional choices!\nRead More: Allergic March In Children\nGet full access to expert-backed nutrition support\nCurated content based on your preferences\nLearn about various feeding options and what each means for you and your baby\nTailored Practical Tools\nTry our tailored practical tools to guide you through the parenting journey.\nMy First 1000 Days club\nCustomised notifications, reminders and newsletters\nStill haven't found what you are looking for?\nTry our new smart question engine. We'll always have something for you.","Baby Skin Conditions\nYour newborn baby’s skin is extremely sensitive. It should be expected that some form of rash or skin irritation will develop in the first 12 months of life.\nMost of these will clear up without treatment, needing only a small amount of extra attention to bathing routines. There are some bacterial or fungal infections that are common that do need medicines. Most of these medicines can be bought over the counter and come mainly as a cream to be applied to the affected area.\nBaby skin conditions symptoms\nDue to the range of conditions your baby can get, the symptoms differ.\nVery young skin has to grow and adapt to the world outside the womb. This growth stage takes about a year. After this time the skin is better at dealing with irritation and better at resisting everyday bacteria.\nOne of the earliest skin conditions that half of babies get is milia. Milia presents as small white spots on the face, these will disappear without any intervention in the first few weeks of life.\nBecause of the tenderness of the skin, rashes due to irritation form easily. Nappy rash or sweat rash are examples. Both of these present as a red rash or blisters. Nappy rash can sometimes be a fungal infection, but is usually due to prolonged exposure of the bottom to urine and stools or chafing of the nappy.\nThere are many other types of fungal infections or irritation rashes, such as ringworm, eczema and cradle cap. While these may have rashes or spots as symptoms they do not always bother the baby. While many of these skin conditions will resolve themselves, special attention should be paid to them to stop any discomfort to your baby.\nWith any rash or discomfort your child shows you should also get the advice of your GP. They may recommend certain treatments or prescribe creams or medicines.\nIt is important to take care of your baby's skin during this sensitive period. Keeping your baby's skin clean and dry will help stop rashes and irritation. Using mild and fragrance-free soaps and hypoallergenic creams and lotions are important. Keep in mind to clean under folds of skin, as this is a high risk area for chafing and sweating.\nIf a rash does break out, barrier creams with zinc oxide or petroleum based products help protect the skin. Letting the skin breathe by uncovering the skin or loose fitting clothing help stop rashes and chaffing. This also stops irritation and reduce the risk of conditions like sweat rash.\nAllergic reactions are very common in babies as their immune systems need time to develop. If you are breastfeeding, your diet affects your breast milk and can cause reactions in your baby. Common allergic triggers are peanuts, dairy milks and shellfish.\nBreast milk is widely thought among doctors to be best for babies however in some case breast milk can cause problems and you may be advised to switch to formula.\nWhen your baby is around 4 to 6 months old you should start introducing solid foods to their diet. Do this slowly so you can see if your baby has any problems. Rashes and hives are common at this stage. Introducing solid foods one at a time will allow you to see which foods cause problems."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:17d11195-3752-432d-bbd3-a33c07de3b20>","<urn:uuid:ccb70b79-1688-4bdc-9a74-707477f4ff3b>"],"error":null}
{"question":"Can you explain how the process of ensuring proper coffee saturation differs between French press and cold brew methods, and why this matters for extraction?","answer":"In French press brewing, you break through the coffee crust and stir at the 1-minute mark to ensure all coffee is submerged. For cold brew, stirring is crucial during the first 10-15 minutes as the coffee starts absorbing water, with multiple stirs needed until the top changes to a hazelnut-colored foam. Without proper stirring, cold brew coffee will float to the top, resulting in weak extraction, while in French press, inadequate stirring can lead to uneven extraction and potentially bitter coffee.","context":["How To Make French Press Coffee\nI drink a lot of coffee. In fact, I'm pretty sure that without coffee life wouldn't be worth living. Over the years I have tinkered with all sorts of different coffee makers, from automatic drip brewers, pour-over, Moka pots, espresso machines and with the French Press. As great as all of the other brewing methods are the French Press has always had a special place in my heart. It was one of the first coffee makers I used when I transitioned away from push-button brewers, and it is here where my love of coffee began.\nSo if you have got on the French Press pot bandwagon and have just purchased a new press pot, I bet you’re wondering how to make French Press coffee. On the other hand, if you’re simply looking for some tips to make your daily brew that little bit better then this article is for you.\nFrench Press Brewing At A Glance\nWhat You Need\n- 8- cup French Press pot\n- 56g (8 tablespoons) of fresh whole coffee\n- Hot water just off the boil (about 205°F)\n- Coffee grinder (burr grinder recommended)\n- Wooden spoon\n- Coffee scale\n- Coffee mug\n- Timer (recommended)\nPress Pot End Result\nTotal brew time: 4:00\nYield: 8 cups (1L)\nCup Characteristics: Heavy and robust\nFrench Press How To Use\nBrewing with a French Press is super simple, to be honest, its probably one of the easiest, most forgiving, and least expensive ways to brew great tasting coffee at home. Follow my below step-by-step guide on how to use a French Press.\nStep 1: Boil Your Water\nTurn on your kettle and heat your water to 205 degrees by bringing it up to a boil and letting it stand for 30 seconds. Even though I'm using a gooseneck, no fancy kettle is needed for the French Press a regular kettle is just fine.\nStep 2: Weigh Out And Grind Your Whole Coffee\nDifferent French Press Coffee Ratio\nWeigh out 56 grams of whole bean coffee (about 8-10 tablespoons) and set your coffee grinder to a coarse setting. The ground coffee needs to be as coarse as breadcrumbs so try and aim for that consistency when grinding. Take a look at my coffee grind guide here.\nStep 3: Pre-Heat Your French Press\nBy now your Kettle should have boiled. With your hot water give your French Press a rinse, this helps to maintain the temperature of the French Press while brewing. Pour away rinse water once done.\nStep 4: Add Your Coffee And Some Water\nHave your timer and hot water nearby. Add your coffee grounds to the French Press and start to pour in your hot water. As soon as you start to pour start your timer. Stop pouring when you reach roughly half way up the French Press.\nStep 5: Gently Stir\nWhen your timer reads 1-minute take a wooden spoon (or as I have used the AeroPress spatula) and start to break through the top layer (the crust). Give your French Press coffee a good stir. The goal here is to get all of the coffee submerged with water.\nStep 6: Add More Water\nWith the timer still ticking away fill the French Press with water to the top. Place the plunger on the top but do not push down just yet.\nStep 7: Press Down The Plunger\nWhen your timer read 4-minutes, it’s time to push down the plunger. Using both hands, one to hold the French Press and the other on the plunger, slowly begin to push down. Don’t push down too fast, try and apply firm but moderate pressure as you push.\nStep 8: Serve And Enjoy\nYou're done! If you are drinking the coffee straight away pour into your coffee mugs, otherwise pour into a decanter immediately to avoid over extraction (If the coffee sits on the grounds too long, it will continue to extract, and you will find that your coffee becomes bitter.\nFrench Press Brewing Tips\nAlways make sure that your French Press is clean before you brew coffee in it. Most of the mesh filter will unscrew so you can get rid of any old coffee grounds. If you leave these stale grounds inside the filter there is a good chance that your coffee will taste bitter.\nAs with all brewing methods I strongly recommend that you start off by using whole coffee beans and grind just before you brew. If you grind your coffee too early (storing your coffee already ground), you will find that the coffee will lose almost all of the compounds that give it such delightful flavors and aromas.\n- Coffee Tastes Weak: Most likely your coffee grind is simply too coarse nest time try grinding the coffee a little bit finer (remember to aim for a consistency like breadcrumbs). Also make sure that you are steeping the coffee for 3-4 minutes.\n- Coffee Tastes Bitter: If your coffee is tasting bitter the chances are that you have ground your coffee too fine. Next time you brew opt for a coarser grind. Also its worth mentioning that if you are using a dark roast, make sure the coffee is fresh and also try to lower the brewing temperature to around 195 F.\n- Coffee Taste Too Strong: Try to reduce the steep time to 3 minutes. Once brewed don’t let the coffee sit inside of the carafe, pour into a decanter if its not going to be drunk straight away.\n- Gritty/Thick Sediment At The Bottom Of Your Mug: Either your coffee grind is too fine and the grounds are passing through the mesh plunger filter or there is a problem with your filter not forming a tight seal inside of the glass carafe.","I am excited today to talk a little bit about our cold brew process and how you at home can do it as easily as we do it in our shops.\nSo, what is cold brew? How is it made? And what do you need to make it at home? Cold brew is basically no different than hot brewed coffee except, as the name implies, you brew it cold. By doing that you’re going to maybe make the flavor a little bit smoother, a little bit more chocolatey, and a little bit more caramel forward as opposed to bringing out the brighter flavors or acidity you might get in a hot brew.\nThe process for doing this is pretty simple: you’re going to take some coffee, grind it on the coarsest setting you have, and then steep it for anywhere from 12 to 24 hours. What you’ll need to do this is some coffee, some water, and a filter.\nWhen producing cold brew for the shops, we generally don’t like using a dark-roasted coffee. When you use a dark roasted coffee, it brings out too much bitter-sweet and charcoaley flavors with too much intensity. When the brew method is already giving you smooth chocolatey flavors, a medium roast really suits the process better.\nAs you measure out your coffee and your water, you will want to use a ratio of one gallon of water for every pound of coffee. When producing cold brew on a mass scale, we often will make batches containing up to 35 pounds of coffee (and 35 gallons of water). However, in the video below we are only using 3.5 pounds of coffee, and, for brewing at home, as single pound should suffice.\nWith regard to the filter, when making cold brew for the shops, we use a muslin filter rather than a paper or mesh or very fine mesh filter made of stainless steel. We do this because we find that the muslin filter will give you a full flavored cup with a chocolatey taste while getting all the sediment and preventing the murkiness and grittiness the sediment can produce.\nOnce you have your coffee and water measured out, and after you have chosen your filter, we can begin making our cold brew.\nSo, to start, we will pour our coffee into our grinder and grind right on into our container using the coarsest setting we have. Next we’re going to transfer our coarsely ground coffee to our filter. After the coffee has been transferred, we’re going to add a little bit of water first then we’re going to give it a stir just so we can kind of get the coffee saturated evenly, making sure there are no dry pockets before adding the rest of our water.\nOne thing that’s really important with cold brew is to giving it some good stirs during the first 10-15 minutes as the coffee starts absorbing the water. If you don’t do any stirring, the coffee’s going to float to the top and your extraction could get a little weak. So, during the first 10-15 minutes, give it a stir. Let it sit for a couple minutes. Come back. Give it one more stir. And eventually you will see the color on top change from a dark color to that of a hazelnut-looking foam.\nAt this point we will then let our coffee steep for 12-24 hours. When producing cold brew for the shops, we don’t necessarily brew it cold, but at room temperature. Therefore our extraction usually takes about 16 hours. But, if your wish to try putting it in the fridge, you may have to go closer to 24 hours to get the flavors you’re looking for.\nAs you become more experienced making your own cold brew, there are lots of ways you can alter this method, especially with regard to the coffee and the filter you use, as well as the temperature you steep it at, and the extraction time you aim for. But these instructions and the video tutorial below should definitely get you started.\nI hope you at home have fun giving this a try and I hope your cold brew turns out great. Thank you."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:326452fe-6e9b-42aa-a846-60c603b33722>","<urn:uuid:34ecf944-8b86-4c9f-b93e-9876f6b2a175>"],"error":null}
{"question":"What are the key differences between bovid horns and other animal horns?","answer":"Bovid horns consist of a bony protrusion covered in a keratin sheath. This differs from deer antlers, which are solid bone and shed annually; pronghorn horns, which shed their keratin sheaths yearly; giraffe horns, which are cartilage bumps covered by skin; and rhinoceros horns, which are formed of compacted hair.","context":["Sable antelope, Hippotragus niger\nBovids have mutually beneficial symbiotic relationships (mutualism) with bacteria and other microorganisms that allows the digestion of cellulose, the most abundant form of living terrestrial biomass, but one that is indigestible for many animals, including humans. Harmonious mutualistic relationships also exist with some birds, such as the cattle egret. Some bovids, notably cattle, sheep, and goats, have been domesticated and these domesticated species have increased their numbers worldwide. On the other hand, overhunting and other anthropogenic activities have resulted in threats to many bovids, including extinction of aurochs and some bison species.\nThe largest bovids, for instance the bison and the gaur, can weigh over 1,000 kg (2,200 lbs) and stand 2 meters (6.5 feet) tall at the shoulder; the smallest weigh about 3 kg (7 lbs) and stand no taller than a large domestic cat.\nBovids are members of the Artiodactyla (even-toed ungulate) order. As such, they walk on the third and fourth toes of each foot, which are covered and protected by hoofs—specialized claws. Standing on the toes has the effect of lengthening the legs, which gives them greater quickness and speed in running and jumping and lets them hold their heads higher above the ground to better watch out for predators (Huffman 2007).\nAll bovids are ruminants, which means that they have a four-chambered stomach that allows them to digest foods that are too low in available nutriments for many other animals, notably grasses and the leaves of trees and bushes. No animal is able to directly digest cellulose, the material of plant cell walls; ruminants rely on their symbiotic relationship with bacteria and other microorganisms in their first stomach, called the rumen, to break down cellulose by fermentation.\nBecause of the size and weight of their complex digestive systems, many bovids have a solid, stocky build; the more gracile (slender) members of the family tend to have more selective diets, and tend to be browsers (prefer higher-level plants) rather than grazers. The fermentation taking place in the rumen generates heat and can help the animal keep warm in cold weather (Lott 2002).\nBovids have large molars for chewing their food. They have no upper incisors or canine teeth and the lower incisors and canines project forward so that the plant materials they eat are torn off rather than bitten. Food is eaten quickly and later on regurgitated from the rumen back into the mouth so it can be chewed; this is known as rumination, or chewing the cud.\nIn all bovid species, males have horns on their heads, while some females also have horns. A bovid horn consists of a bony protrusion covered in a sheath of keratin, a material found in skin, hair, and claws. Some other hoofed animals also have horns, but they differ from bovid horns. Deer, the second largest ungulate family, have antlers, which are solid bone and are shed and regrown each year. The pronghorn of North America differs from bovids by shedding the keratin sheaths of its horns each year. The horns of giraffes are bumps of cartilage covered by skin. The horns of rhinoceroses are formed of compacted hair.\nThe horns of some bovid species are used to fight, and sometimes kill, predators such as wolves and lions. However, in most species the main use of the horns is in fighting between males for dominance and the right to mate with females. In many species, the horns of the males are curved or spiraled, which reduces the danger in these conflicts. Often dominance is established merely by the size of one animal's horns without a fight having to take place. The horns of males are also thought to be attractive to females by showing the good health and maturity of their bearer. Some bovids use their horns to dig for food or to pull down tree branches to eat the leaves (Voelker 1986). Horns can also help an animal keep cool in hot weather since blood is circulated through them and can shed heat by radiation (Rath 1998).\nAlmost all bovids are social animals and live in groups, called herds or flocks. Groups can range in size from small family groups to herds of many thousands, or even millions in species such as the wildebeest and the American bison. In many species, herds migrate seasonally to find food or better climatic conditions. Smaller groups are often lead by a mature animal, either male or female.\n- ORDER ARTIODACTYLA: even-toed ungulates\n- Suborder Ruminantia: ruminants\n- Family Bovidae\n- Subfamily Bovinae: cattle, buffalo, bison, and spiral-horned antelopes, 24 species in 9 genera\n- Subfamily Cephalophinae: duikers, 19 species in 2 genera\n- Subfamily Hippotraginae: grazing antelopes, 6 species in 5 genera\n- Subfamily Antilopinae: gazelles, dwarf antelopes and the saiga, 38 species in 14 genera\n- Subfamily Caprinae: sheep, goats, muskox, 26 species in 12 genera\n- Subfamily Reduncinae: reedbucks, lechwe, 8 species in 2 genera\n- Subfamily Aepycerotinae: impala, 1 species in 1 genus\n- Subfamily Peleinae: rhebok, 1 species in 1 genus\n- Subfamily Alcelaphinae: wildebeest, topi/tsessebe, 7 species in 4 genera\n- Subfamily Panthalopinae: chiru\n- Family Bovidae\n- Suborder Ruminantia: ruminants\nBovids in nature\nBovid species are found in a great variety of habitats including forests, grasslands, deserts, mountains, and tundras. As major consumers of plants, they play a vital role in the ecosystems in which they live. Their constant grazing and browsing helps keep forest floors open and helps prevent grasslands from being overrun by brush. They help plants reproduce by passing their seeds through their digestive systems and they fertilize the soil with their manure.\nBovids are an important food source for many species of predators, parasites, and scavengers. Other animals benefit from symbiotic relationships which them, for instance birds such as the cowbird and the cattle egret prey on insects and other small animals startled by grazing bovids. The birds in turn can help the bovids by alerting them to predators.\nBovids and humans\nBovids were hunted by humans from very early times and provided them with an important food source. Many species of bovids have become extinct due to overhunting, including the aurochs, the ancestor of domestic cattle, and some species of North American bison, which are thought to have been hunted to extinction by early Native Americans. Today a number of bovid species are in danger because of hunting and habitat loss (IUCN 2007).\nSheep and goats were among the first animals to be domesticated. They were followed by cattle and water buffalo. Each of these species now numbers in the tens of millions and together they provide much of the human food supply through their meat and milk. Sheep and goats also provide wool for clothing. In many countries, cattle and water buffalo still play an important role as work animals to pull carts and draw plows.\nThe yak, the banteng, and the gayal, all close relatives of cattle, were also domesticated in Asia. Some other bovid species are now in the process of domestication, or at least being considered as potential future domestic animals; these include the muskox, the eland, and the American bison (Huffman 2007; Lott 2002).\nSince prehistoric times, bovids have been depicted in art and have played important roles in mythology and religion. The American bison is seen to have great spiritual importance by many Native Americans. Cattle have played an important part in many cultural and religious traditions, as they continue to do in Hinduism today. In Judaism, Islam, and Christianity, sheep and goats have symbolic roles. In Judaism, a shofer, a \"trumpet\" made from the horn of a ram or sometimes that of a goat or antelope, is sounded at Rosh Hashanah, the celebration of the new year (Slifkin 2006). In Christianity, it is believed that the sounding of a shofer will announce the return of Christ.\n- Huffman, B. 2007. The Ultimate Ungulate Page. Retrieved February 1, 2007.\n- IUCN Species Survival Commission (IUCN). 2007. 2006 ICUN Red List of Threatened Species. International Union for Conservation of Nature and Natural Resources. Retrieved February 3, 2007.\n- Lott, D. F. 2002. American Bison. Berkeley: University of California Press.\n- Nowak, R. M., and J. L. Paradiso. 1983. Walker's Mammals of the World. Baltimore: Johns Hopkins University Press. ISBN 0801825253\n- Rath, S. 1998. The Complete Cow. Stillwater, MN: Voyageur Press. ISBN 0896583759\n- Slifkin, N. 2006. Exotic Shofars. Zoo Torah. Retrieved February 8, 2007.\n- Voelker, W. 1986. The Natural History of Living Mammals. Medford, NJ: Plexus Publishing. ISBN 0937548081\nNew World Encyclopedia writers and editors rewrote and completed the Wikipedia article in accordance with New World Encyclopedia standards. This article abides by terms of the Creative Commons CC-by-sa 3.0 License (CC-by-sa), which may be used and disseminated with proper attribution. Credit is due under the terms of this license that can reference both the New World Encyclopedia contributors and the selfless volunteer contributors of the Wikimedia Foundation. To cite this article click here for a list of acceptable citing formats.The history of earlier contributions by wikipedians is accessible to researchers here:\nNote: Some restrictions may apply to use of individual images which are separately licensed."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:9ff3afea-475d-4d50-9f16-4efcc374ba54>"],"error":null}
{"question":"As a Bengali cultural enthusiast, how exactly was Pahela Baishakh celebrated traditionally in Bengal, and what were the main customs associated with this new year celebration?","answer":"Pahela Baishakh was traditionally celebrated with several key customs. The main event was opening a halkhata (new book of accounts), where traders and businessmen would close old account books and open new ones. They would invite customers to share sweets and renew business deals. People would perform elaborate household cleaning, bathe early in the morning, dress in their best clothes, and visit relatives, friends, and neighbors. Special foods were prepared for guests, and Baishakhi fairs were organized featuring agricultural products, handicrafts, toys, cosmetics, and various foods. These fairs included entertainment like folk songs, narrative plays, puppet shows, and traditional performances such as Jatra, Pala Gan, Kavigan, and Gambhira Gan.","context":["Pahela Baishakh first day of the Bangla calender. Pahela Baishakh is celebrated in a festive manner in both Bangladesh and West Bengal. In Bangladesh Pahela Baishakh is a national holiday. The day falls on April 14 or 15.\nUnder the Mughals, land taxes were collected according to the Arabic or Hijri calendar. However, as the Hijri calendar is a lunar calendar, the agricultural year does not coincide with that of the fiscal. As a result, farmers felt hard-pressed to pay taxes out of season. In order to streamline the land tax system, the Mughal Emperor akbar ordered a reform of the calendar. Accordingly, Fatehullah Shirazi, a renowned scholar and astronomer, formulated the Bangla year on the basis of the lunar Hijri and Bangla solar calendars. The new Fasli San (crop year) was introduced on 10/11 March 1584, but was dated from Akbar's accession to the throne in 1556. The new year subsequently became known as bangabda or Bangla year.\nCelebrations of Pahela Baishakh started from Akbar's reign. It was customary to clear up all dues on the last day of Chaitra. On the next day, or the first day of the new year, landlords would entertain their tenants with sweets. The occasion was marked by fairs and other festivities. In due course the occasion became part of domestic and social life, and turned into a day of merriment.\nThe main event of the day was to open a halkhata or updated book of accounts. This was wholly a financial affair. In villages, towns and cities, traders and businessmen closed their old account books and opened new ones on Pahela Baishakh. They used to invite their customers to share sweets and renew their business deals with them. This tradition is still maintained, especially by jewellers and grocers.\nNew year's festivities are closely linked to rural life in Bengal. On this day people make elaborate household cleaning and bathing. People bathe early in the morning and dress in clean and best clothes and visit public places, relatives, friends and neighbours.\nSpecial foods are prepared to entertain guests. Baishakhi fairs are arranged in many parts of the country. Various agricultural products, traditional handicrafts, toys, cosmetics, and variety of foods and sweets are sold at these fairs. The fairs also provide entertainment, with singers and dancers staging JATRA, PALA GAN, KAVIGAN, jarigan, GAMBHIRA GAN, GAZIR GAN and alkap gan. They present folk songs as well as baul, marfati, murshidi and bhatYali songs. Narrative plays like laily-majnu, yusuf-zulekha and Radha-Krishva are staged. Among other attractions of these fairs are puppet shows and merry-go-rounds.\nMany old festivals connected with new year's day are no longer practised. On the other hand, new festivals have been introduced. With the abolition of the zamindari system, festivals connected with the punya have disappeared. Kite flying in dhaka and bull racing in munshiganj used to be very colourful events. Among popular village games and sports include horse races, bullfights, cockfights, flying pigeons, boat racing and so on. Some Baishakhi festivals are quite regional, such as, bali or wrestling in Chittagong and gambhira song in Rajshahi.\nThough agricultural in origins, the Pahela Baishakh festivities are now more marked in urban societies than in rural societies.'\nThe most colourful new year's day festival now takes place in Dhaka. Large numbers of people gather early in the morning under the banyan tree at Ramna Park where chhayanaut artistes open the day with Tagore's famous song, Eso he Baishakh eso eso (Come O Baishakh, come), welcoming Baishakh. A similar ceremony welcoming the new year is also held at the Institute of Fine Arts, university of dhaka.\nStudents and teachers of the Institute take out a colourful procession and parade round the campus. Social and cultural organisations celebrate the day with cultural programmes. Newspapers bring out special supplements. There are also special programmes on radio and television. [Sambaru Chandra Mohanta]"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:7dd77bfb-ef65-431c-a4a1-0151013aea56>"],"error":null}
{"question":"How do string tension recommendations differ between Isospeed Black Fire and professional players' polyester string setups, and what impact does this have on power and control?","answer":"For Isospeed Black Fire, manufacturers recommend reducing tension by 10% compared to nylon strings, with testers finding good results in the lower-to-mid 50-pound range. Professional players using pure polyester strings typically stay at or below 55 pounds (like Nadal with RPM Blast at 55 lbs), as polyester can be strung looser while maintaining decent control. Generally, lower tensions provide more power while higher tensions offer more control. The lab testing of Black Fire showed it had a stiffness rating of 232, allowing it to maintain control at lower tensions, similar to how professional players' polyester setups perform.","context":["The key point is that you (the player ) should decide and not the stringer or coach. By all means, be guided in the right direction but if finances permit try a few variations of string types & tensions to see what you like best.\nIn a nutshell:\n1/ Full polyester for more spin and control but harder on the arm.\n2/ Full soft strings for more feel and less loss of tension. Natural gut is the best but very expensive - only if you play in dry conditions and don't use too much spin as the strings won't last!\n3/ A hybrid of polyester and a softer string which provides a mix of good spin, power, and feel\nWhat do the top male players in the world use in terms of strings/tensions:\nNovak Djokovic | Babolat VS Team Natural Gut / Luxilon ALU Power Rough 59/56lbs\nRoger Federer | Wilson Natural Gut/Luxilon Big Banger Alu Power Rough 48.5/45lbs\nAndy Murray | Luxilon Big Banger Alu Power/Babolat VS Touch 62lbs\nNick Kygrios |Yonex Poly Tour Pro 125 51lbs\nRafael Nadal | Babolat RPM Blast 130 55lbs\nGael Monfils | Luxilon Big Banger Alu Power 57/55lbs\nMilos Raonic |Luxilon M2 44/46lb\nAlexander Zverev | Babolat VS Touch/Head Hawk Touch 62lb\nRoberto Bautista Agut | Luxilon Big Banger Original 57lb\nDiego Schwartzman | Luxilon Big Banger Alu Power 50lbs\nOut of this group of 10 players we have 6 using only polyester and the other 4 with a hybrid of polyester and a softer string. Tensions vary from 44/46lbs - Raonic to 62lbs - Zverev & Murray. Therefore, quite a variation in string types and combinations plus different ideas on tensions.\nIn general lower tensions provide more power and higher tensions more control. Polyester strings can be strung looser and still have decent control which is probably why all the players using polyester only are no higher than 55lbs - Nadal. (Rafa is one of the few players on tour who never changes his string tension no matter whatever the conditions are)\nFor young players and lower-level club players, a hybrid restring is generally better to help protect the arm and provide a bit more feel. If a mid-level or slightly older junior likes polyester I would advise no more than 50lbs again to protect the arm and provide easier power for slower racquet head speeds.\nIf you want a restring that doesn't lose tension quite so much then VS Gut would be the best but as I said previously it's very expensive and breaks easily.\nHigher-level club players are probably the ones who will experiment a bit more to find out what suits them best and a huge consideration for aspiring young pros is the cost as they will break strings regularly no matter what the type of string they use!\nTo sum up... try not to get too fanatical about strings as a good stringer should be able to guide you towards the most appropriate tension and string type for your level of play. The higher the level of player the more they will feel subtle differences. You will sometimes see pro players complaining to their team about string tensions in practice or during matches which can be genuine but can also be players looking for excuses.\nFind a string and tension that you like and stick to it - just like Rafa!","Playtest: Isospeed Black Fire\nBy Greg Raven\nIsospeed Black Fire is a modified co-polyester monofilament that is made using a triple-heating process to soften the stiff modulus somewhat. Isospeed tells us the string is produced very stiff for control, but shrinking the string in the last heating step reduces vibration on the arm. The result is a stiff string that still has power and comfort.\nIsospeed has successfully tested Black Fire 17 with demanding professional tour players. It is designed to give hard-hitting college and pro players maximum control without sacrificing power.\nBlack Fire is available in 17-gauge (1.25mm) in black only. It is priced from $7.50 per set of 12 meters. For more information or to order, contact Isospeed at 800-883-6647, or visit isospeed.com/en/.\nIN THE LAB\nThe coil measured 40 feet. The diameter measured 1.26-1.28 mm prior to stringing, and 1.22-1.23 mm after stringing. We recorded a stringbed stiffness of 73 RDC units immediately after stringing at 60 pounds in a Wilson Pro Staff 6.1 95 (16 × 18 pattern) on a constant-pull machine.\nAfter 24 hours (no playing), stringbed stiffness measured 66 RDC units, representing a 10 percent tension loss. Our control string, Prince Synthetic Gut Original Gold 16, measured 78 RDC units immediately after stringing and 71 RDC units after 24 hours, representing a 9 percent tension loss. In lab testing, Prince Synthetic Gut Original has a stiffness of 217 and a tension loss of 11.67 pounds, while Isospeed Black Fire 17 has a stiffness of 232 and a tension loss of 21.2 pounds. Black Fire 17 added 16 grams to the weight of our unstrung frame.\nThe string was tested for five weeks by 31 USRSA play-testers, with NTRP ratings from 3.5 to 6.0. These are blind tests, with testers receiving unmarked strings in unmarked packages. Isospeed recommends reducing the reference tension by 10 percent compared to a nylon string, and we so advised our playtest team members. The average number of hours tested was 23.9.\nBlack Fire feels thicker than its 17 gauge out of the package. The surface is smooth and cylindrical, and it feels “soft” during stringing. It is easy to weave and pull the crosses through the mains, but the string is slightly springy, so you have to pay attention during knotting.\nNone of our testers broke the sample during stringing, three reported problems with coil memory, one reported problems tying knots, none reported friction burn, and one reported other problems.\nON THE COURT\nIsospeed Black Fire’s smooth surface makes installation easy, and seems also to contribute to the characteristic of aiding its resistance to movement. Our testers rated Black Fire the 15th best string in this category of the 174 strings we’ve play tested for publication to date. Isospeed promises control with Black Fire, and our testers agreed, rating Black Fire excellent in the Control category. Our testers also awarded Black Fire with well-above-average ratings in six categories: Durability, Playability, Power, Tension Retention, and Spin Potential. As a result, overall Isospeed Black Fire garnered an excellent rating from our test team.\nNone of our testers reported premature fraying or peeling, one reported buzzing, and four reported notching. None of the testers broke the sample during the playtest period.\nConsidering that Isospeed designed Black Fire 17 for players whose abilities are well above those of most of our test team’s, it speaks well of the Isospeed process that even lesser players found a lot to like in Black Fire 17. No string receives great scores in seven categories (including one in the top 20) — and an overall excellent rating — by accident.\n“This is a softer feeling poly with great spin. The low power level lets me take big swings with confidence. Overall, this is a good, well-rounded poly.” 3.5 male baseliner with moderate spin using Prince EXO3 Tour (16x18) strung at 44 pounds CP (Gamma Synthetic Gut 17)\n“I am surprised by the comfort of this poly. Even strung in the low forties, the control, spin and overall playability are exceptional.” 4.0 male baseliner with heavy spin using Babolat Pure Drive + Cortex GT strung at 43 pounds CP (Head Sonic Pro 17)\n“Firm but feisty. This is a great string for the player who likes to hit hard and wants great tension maintenance. This one snaps back nicely. Despite feeling firm when installed, the overall playability should appeal to both singles and doubles players.” 4.5 male all court player using Babolat Pure Drive Roddick GT strung at 47 pounds CP (Solinco Tour Bite/Solinco Vanquish 18/16)\n“This is a spin-friendly co-poly but with the comfort of a nylon multifilament.” 5.0 male all court player using Babolat Pure Drive Cortex strung at 60 pounds CP (Luxilon Alu Power 16L)\n“For a poly, there is a good balance of control, power and, surprisingly, feel. This string is very well rounded, with features that should satisfy many playing styles. It has the forgiving feel of a nylon but the durability and control of a poly. The power is very controllable. There is a also enough touch to hit drop shots. Let’s just say I am a fan.” 4.0 male all court player using Pro Kennex Kinetic Pro 7g strung at 55 pounds CP (Tourna Big Hitter Black 7 17)\n“Kapow! Bam! Pow! Zap! I feel like Batman fighting crime with this weapon. The exceptional playability is there from the first to last hit. It has control, touch, and power. Every stroke feels good. Serves have nice bite and placement, and groundies have penetrating depth without much fuss. I’m not a ‘poly player,’ but this string has me considering a switch.” 4.5 male all court player using Babolat AeroPro Drive GT strung at 54 pounds LO (Tourna Quasi Gut 16)\n“The high levels of comfort and power are very impressive (and rare) for such a durable poly. The playability and excellent feel will give this one broad appeal. It’s also got great spin, which helps with control.” 4.0 male baseliner with heavy spin using Dunlop Aerogel 4D 1 Hundred strung at 40 pounds LO (Luxilon XP 17)\n“Despite feeling stiff during installation, this poly is very comfortable in play. Achieving depth is easy. This is one of the best polys I’ve tested. Truly wonderful.” 4.5 male all court player using Dunlop Biomimetic 400 strung at 50 pounds CP (Tecnifibre Pro Red Code/Gamma Synthetic Gut 18/16)\n“This string has better tension maintenance than similar feeling polys. It makes it easy for me to control points with spin.” 6.0 male serve-and-volley player using Yonex V Core Xi (300 Grams) strung at 67 pounds CP (Yonex Poly Tour Pro 16L)\n“This is very ‘stringer friendly.’ Installation is quick and painless with little coil memory or friction bun. On court, this plays like my favorite polys with high marks for control and spin. It also has average comfort and touch.” 5.0 male all court player using Head Youtek Speed Lite strung at 50 pounds CP (Polyester 16)\n“This is the first poly that I don’t mind playing in a full stringbed. Spin and power were average for a non-shaped poly, but comfort and feel are better than expected. I still prefer the playability of a hybrid, but it’s nice to play with a full bed of poly that does not aggravate the arm.” 4.5 male all court player using Prince EXO3 Rebel (hole inserts) strung at 49 pounds LO (Solinco Tour Bite/Prince Premier Attack 18/17)\n“Great sound from the first hit. When striking the ball I am rewarded with a very solid, authoritative pop. This is a surprisingly comfortable poly. While I could use a tad more spin, I am impressed by the comfort and playability.” 4 male baseliner with heavy spin using Wilson BLX Six One (16×18) strung at 50 pounds CP (Pacific Prime Gut/Genesis Black Magic 16/16)\n“Very good touch for a durable control string.” 4.0 male baseliner with heavy spin using Babolat Pure Drive Roddick GT strung at 62 pounds LO (Solinco Tour Bite 16L)\n“Strung in the mid fifties, the feel is stiff and the sweet spot feels small. After a short break-in, playability steadily improves and the strings loosen up. Serves have slightly more pop. Ground strokes have average spin and power with good control. Volleys feel crisp. I suggest a reference tension of 52 pounds for a midplus frame.” 4.5 male all court player using Babolat Pure Storm Tour + GT strung at 55 pounds CP (Tier One Tour Status 17)\n“Very impressive playability for a co-poly. The balance of control and power is excellent. I typically hybrid polys, but not this one. It has more than enough feel and comfort by itself.” 4.0 male serve-and-volley player using Dunlop Aerogel 3 Hundred strung at 46 pounds CP (Wilson Sensation 17)\n“This string plays with a little zing. Before I could swing confidently, I needed to adjust to the lively stringbed response. The spin is excellent, but off-center volleys feel a bit dead. It needs a bit more playability to work for serve and volley players.” 4.5 male serve-and-volley player using Head Youtek Radical MP strung at 54 pounds CP (Gamma Asterisk Tour 17)\n“This is a comfortable poly. I found a groove from the first hit. Recommended to the player who wants a durability string with above average comfort and power.” 5.0 male all court player using Head Youtek Graphene Speed Rev strung at 62 pounds CP (Luxilon Timo 18)\n“The feel goes down over time but the performance remains high. Nice combination of spin and power.” 4.0 male all court player using Head Youtek Prestige MP strung at 54 pounds CP (Gamma Live Wire XP 17)\n“This is one of the softest polys I’ve hit. Great pocketing and very easy spin production for a round, non-textured string. This is recommended to players who want the durability and control of a poly, but with less shock to the arm.” 4.0 male all court player using Head Youtek IG Prestige Pro MP strung at 52 pounds CP (Head Synthetic Gut PPS 17)\n“The pocketing and spin potential are exceptional. This poly does not ‘play dead,’ nor does it feel like a trampoline. I’m able to teach longer than usual with it. No pain when feeding balls.” 5.0 male baseliner with heavy spin using Prince EXO3 Rebel Team strung at 52 pounds CP (Prince Beast XP 16)\n“Excellent tension maintenance. Very good control and spin potential. No string straightening necessary.” 3.5 male baseliner with moderate spin using Prince O3 Speedport Black (port inserts) strung at 58 pounds CP (Zons Polymo Hexplosion 17)\n“The string pocketing is better than expected. This is a great option for non polyester players who want to make the transition to polyester.” 4.5 male all court player using Wilson BLX Blade strung at 56 pounds CP (Luxilon 4G 16L)\n“Plays with a lot of power ‘right out of the box.’ This string retains its comfort after many hours of play. Nice action on groundies and serves, and good control on volleys. It would work well in a hybrid.” 4.0 male all court player using Babolat Pure Drive strung at 54 pounds CP (Natural Gut 17)\n“This string lacks the ‘wow’ factor. There isn’t enough of an upside to justify switching from my typical string. It is just an average string.” 4 male all court player using Volkl V1 Classic strung at 52/54 pounds CP (Wilson Hyperlast Spin 19)\n“These strings hold tension well and never move, even when hitting heavy spin. However, there is no outstanding quality that makes me want to switch from my favorite string. The industry has to stop making so many black strings. Give me some color please.” 4.0 male baseliner with moderate spin using Babolat AeroPro Drive Cortex strung at 54 pounds LO (Tourna Big Hitter Black 7 17)\n“Very easy installation, with low coil memory. Tension maintenance is decent for a poly. Comfort is average. Control is adequate. Spin is not up the level of my shaped poly. Power, however, is good, especially when freshly strung.” 4.5 male baseliner with heavy spin using Babolat Aero Storm Tour GT strung at 56 pounds LO (Babolat RPM Blast 16)\n“This test string has average playability. It would be good in a hybrid with a multifilament or natural gut cross.” 4.0 male baseliner with moderate spin using Babolat AeroPro Drive strung at 56 pounds CP (Babolat RPM Blast 17)\n“I expect to get more pop from a poly like this, but the sweet spot is too small. It could be that I am in a little slump; I am not in a hurry to try this one again. My wrist and hand are not in a hurry either.” 3.5 male all court player using Wilson kBlade strung at 53 pounds CP (Solinco Tour Bite/Gamma TNT2 16L/17)\n“This is a dull string overall. Nothing stands out. All elements of the string were average or below average. It might play better if textured or shaped. I want my string to snap back or trampoline on flat serves. This one fails the liveliness test.” 4.5 male all court player using Wilson BLX Steam strung at 59 pounds CP (Luxilon Savage 17)\n“This is an average polyester with decent power and spin. If it is priced less than ten dollars a set, I will recommend it. But it’s not for me.” 5.0 male all court player using Babolat Pure Drive + Cortex strung at 43 pounds LO (Luxilon Alu Power 16)\n| EASE OF STRINGING\n(compared to other strings)\n|Number of testers who said it was:|\n|about as easy||23|\n|not quite as easy||4|\n|not nearly as easy||0|\n| OVERALL PLAYABILITY\n(compared to string played most often)\n|Number of testers who said it was:|\n|about as playable||11|\n|not quite as playable||13|\n|not nearly as playable||1|\n| OVERALL DURABILITY\n(compared to other strings of similar gauge)\n|Number of testers who said it was:|\n|about as durable||16|\n|not quite as durable||0|\n|not nearly as durable||0|\n|From 1 to 5 (best)|\n|Resistance to Movement (15th overall)||4.1|\nSee all articles by Greg Raven\nAbout the Author\nGreg Raven is an associate editor for RSI magazine and technical writer. He is certified as a Master Racquet Technician by the U.S. Racquet Stringers Association. He can be reached via e-mail at email@example.com, or through Facebook, LinkedIn, and Twitter. He plays tennis five days a week, and is turning into an avid cyclist.\nTI magazine search\nTI magazine articles\n- Playtest: Tecnifibre XR3 17\n- Our Serve: Mainstream Marketing\n- Industry news\n- RacquetTech: Two-Piece Stringing without a Starting Knot\n- Inventory Management: Select the Right Gear to Stay Competitive\n- USTA: Catching Up With New USTA President Katrina Adams\n- Footwear: The In-Store Advantage\n- Court Construction & Maintenance Guide: The Hard Facts\n- Serious Propositions"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:cd03fe54-1691-46cd-80b8-9f9c226ab499>","<urn:uuid:7e6d9e4f-6a67-46ef-9928-de63feefc0f2>"],"error":null}
{"question":"What is the spillover phenomenon in catalysis, and how does it relate to modern hydrocracking processes in refineries?","answer":"The spillover phenomenon occurs when hydrogen atoms activated on metal surfaces like platinum move to the catalyst surface. This phenomenon was discovered in the 1960s and was recently explained by researchers using platinum nanoparticles covered with aluminosilicate, which blocks competing reactions. They found that Brönsted acid sites on aluminosilicate play a crucial role in the process. This understanding is relevant to hydrocracking processes, which take place in hydrogen-rich atmospheres at high temperatures (260-420°C) and pressures (35-200 bar) to convert heavy oil fractions into higher-value products. The process combines cracking and desulfurization of crude petroleum oil in the presence of hydrogen, making it a vital technology in modern refineries.","context":["Researchers at KAIST have identified spillover phenomenon, which has remained controversial since its discovery in the early 1960s.\nKAIST Department of Chemical and Biomolecular Engineering’s Professor Min-Gi Choi and his team has explained the \"spillover phenomenon,\" using their own model catalyst system where platinum is selectively located within the amorphous aluminosilicate.\nThe research results were published on the 25th February online edition of Nature Communications.\nSpillover refers to a phenomenon that occurs when hydrogen atoms that have been activated on the surface of metals, such as platinum, move to the surface of the catalyst. It was predicted that this phenomenon can be used to design a catalyst with high activity and stability, and thus has been actively studied over the last 50 years.\nHowever, many cases of the known catalysts involved competing reactions on the exposed metal surface, which made it impossible to directly identify the presence and formation mechanism of spillover.\nThe catalysts developed by the researchers at KAIST used platinum nanoparticles covered with aluminosilicate. This only allowed the hydrogen molecules to pass through and has effectively blocked the competing reactions, enabling the research team to study the spillover phenomenon.\nThrough various catalyst structure and reactivity analysis, as well as computer modeling, the team has discovered that Brönsted acid sites present on the aluminosilicate plays a crucial role in spillover phenomenon.\nIn addition, the spillover-based hydrogenation catalyst proposed by the research team showed very high hydrogenation and dehydrogenation activity. The ability of the catalyst to significantly inhibit unwanted hydrogenolysis reaction during the petrochemical processes also suggested a large industrial potential.\nProfessor Min-Gi Choi said, “This particular catalyst, which can trigger the reaction only by spillover phenomenon, can be properly designed to exceed the capacity of the conventional metal catalysts. The future goal is to make a catalyst with much higher activity and selectivity.”\nThe research was conducted through funds subsidized by SK Innovation and Ministry of Science, ICT and Future Planning.\nThe senior research fellow of SK Innovation Seung-Hun Oh said, “SK Innovation will continue to develop a new commercial catalyst based on the technology from this research.”\nJuh-Wan Lim and Hye-Yeong Shin led the research as joint first authors under supervision of Professor Min-Gi Choi and computer modeling works were conducted by KAIST EEWS (environment, energy, water, and sustainability) graduate school’s Professor Hyeong-Jun Kim.\nHolographic cameras can provide more realistic images than ordinary cameras thanks to their ability to acquire 3D information about objects. However, existing holographic cameras use interferometers that measure the wavelength and refraction of light through the interference of light waves, which makes them complex and sensitive to their surrounding environment. On August 23, a KAIST research team led by Professor YongKeun Park from the Department of Physics announced a new leap forward in 3D2023-09-05\n[ From left, Ph.D. candidates See-On Park and Hakcheon Jeong, along with Master's student Jong-Yong Park and Professor Shinhyun Choi ] See-On Park, Hakcheon Jeong, Jong-Yong Park - a team of researchers under the leadership of Professor Shinhyun Choi of the School of Electrical Engineering, developed a highly reliable variable resistor (memristor) array that simulates the behavior of neurons using a metal oxide layer with an oxygen concentration gradient, and published their work in Nature2022-11-01\nThis catalyst capability allowing stable hydrogen production from commercial diesel is expected to be applied in mobile fuel cell systems in the future hydrogen economy On August 16, a joint research team led by Professors Joongmyeon Bae and Kang Taek Lee of KAIST’s Department of Mechanical Engineering and Dr. Chan-Woo Lee of Korea Institute of Energy Research (KIER) announced the successful development of a highly active and durable reforming catalyst allowing hydrogen production from2022-09-07\n- The first images of mid-infrared optical waves compressed 1,000 times captured using a highly sensitive scattering-type scanning near-field optical microscope. - KAIST researchers and their collaborators at home and abroad have successfully demonstrated a new methodology for direct near-field optical imaging of acoustic graphene plasmon fields. This strategy will provide a breakthrough for the practical applications of acoustic graphene plasmon platforms in next-generation, high-perfor2021-03-16\nProfessor Mu-Hyun Baik at the Department of Chemistry was honored to be the recipient of the 2021 POSCO TJ Park Prize in Science. The POSCO TJ Park Foundation awards every year the individual or organization which made significant contribution in science, education, community development, philanthropy, and technology. Professor Baik, a renowned computational chemist in analyzing complicated chemical reactions to understand how molecules behave and how they change. Professor Baik was awarded i2021-03-11","This is an established and reliable method for transforming low value heavy oil fractions into higher value products. In hydrocracking process a number of problems cause poisoning of catalysts which used. Hydrocracking and hydrotreating refining processes needed for. Maximize distilate yeilds hydrocracking altrernative uop llc. The major licensors of hydrocracking processes include chevron, uop, exxonmobil research and engineering, bp, shell, and basfifp. In this process the number of valuable oil subproducts increases, due to their formation from the residues with low commercial values naturally present in.\nHydrocracking crystalline silica alumina base with rare earth metals deposited in the lattice platinum, palladium, tungsten, andor nickel rare earth metals typically mixture of lanthanum, cerium, and other minor quantities acid function promotes the cracking feed stock must first be hydrotreated. Hydrocracking science and technology chemical industries. Modeling and optimization of an industrial hydrocracking unit. Hydrocracking is a process that is suitable to produce products that meet or exceed all of the present environmental regulations. During the laboratory experiment of hydrocracking process, the experiment was set up at 16. Our catalysts are universal regardless of the equipment or type of hydrocracking technology youre using, youll get the optimal catalysts for your hydrocracking operation.\nIntegration with other units due to the number of products produced by any slurry hydrocracking technology, integration with the existing or new complex is critical to extract full value from the technology. The process consists of causing feed to react with. Hydrocracking and hydrotreating refining processes needed. Honeywell uop unity hydroprocessing catalysts offer tailored performance through our vast lineup of hydrotreating, pretreat and hydrocracking solutions. Heavy aromatic feedstock is converted into lighter products under a wide range of very high pressures 1,0002,000 psi and fairly high temperatures 7501,500 f, 400800 c, in the presence. Specific reference may be made to the chapter beginning at page 174 which describes single stage. Hydrocracking processes are designed for, and run at, a variety of conditions. The second one addresses specifically the hydrocracking of longchain paraffins, but at a more fundamental level as compared to the first one.\nThe ht and hc consist of 2 and 4 beds, respectively, with quenching by h 2 to cool the reaction mixture between the beds and control the reaction temperature. Various process configurations have been developed, which can be classified as singlestage, twostage and seriesflow hydrocracking. The unicracking technology can produce lpg, naphtha, kerosene and diesel, as well as highquality unconverted oil to use downstream to produce lube oils or for fcc feed through the conversion of heavier feedstocks and the addition of hydrogen. W withheld to avoid disclosure of individual company data. The slurryphase hydrocracking is a promising technology, which could process inferior feedstock oils. They are then reformed in presence of hydrogen at extreme pressures and temperatures. Hydrocracking is the refining process in which middle and heavy distillate fractions are cracked broken into smaller molecules.\nHydrocracking simulation chemical process simulation. We also have many ebooks and user guide is also related with. The feed to the hydrotreater is a mixture of hvgo bp range 505860 k and h 2 which are heated separately. Comparison of catalytic cracking and hydrocracking process. In uops newest generation of hydrocracking catalysts.\nDear all, i want to ask whether any of you have a tutorial or a hysys simulation file for hydrocracking of a oil. A two stage hydrocracking process is characterized by operation of the second hydrocracking zone at a reduced. The uop portal provides information on products and services for uop customers and partners. It is a catalytic process used in refineries for converting heavy oil fractions into. The hydrocracking process is overall exothermic, it is necessary to control this surplus. The process takes place in hydrogenrich atmosphere at high temperatures 260420 c and pressures 35200 bar.\nThe process takes place in a hydrogenrich atmosphere at elevated temperatures 260 425 c. Hydrocracking process description and criterion zeolyst. Amoco shell shell development center basfifb badische anilin, ifp unibon uop, llc isomax chevron, uop, llc there are other processes such as lcfining, which are not based on fixed bed reactors. Hydrocracking description benefits literature contact isocracking, offered by chevron lummus global clg, a joint venture between mcdermotts lummus technology and chevron u. A catalytic process combining cracking and desulfurization of crude petroleum oil in the presence of hydrogen.\nSlurryphase hydrocracking of heavy oil and model reactant. Dec 27, 2014 during the laboratory experiment of hydrocracking process, the experiment was set up at 16. These products can be monetized directly as fuels, or provide excellent petrochemical complex feedstock. Catalytic reforming is a catalytic chemical process used in petroleum refineries to convert naphthas, typically having low octane ratings, into highoctane liquid products called reformates which are components of highoctane gasoline also known as petrol. Zeolysttm z863 is the only hydrocracking catalyst in the world, specifically designed to be highly nitrogen tolerant. Fcc or hydrocracking unit, with or without, pretreatment in the uniflex unit. Hydrocracking is a process that breaks down complex hydrocarbon molecules into simpler ones by using a catalyst and an elevated partial pressure of hydrogen gas. Catalytic hydrocracking has shorter history than catalytic cracking and it was started in 1958. The hydrocracker upgrade involved implementation of licensordeveloped technology for the highpressure circuit. At present, this process is called the uop uniflex process. Modeling and optimization of an industrial hydrocracking.\nComparison of catalytic cracking and hydrocracking process in. Oct 11, 2019 hydrocracking usually uncountable, plural hydrocrackings organic chemistry the production of highoctane petroleum fuel and kerosene by hydrogenating large or complex hydrocarbons and then cracking them. Modelling and simulation of the hydrocracking of heavy oil. Hydrocracking definition is the cracking of hydrocarbons in the presence of hydrogen. Proper material selection is required to minimize the risk of corrosion in the process equipment handling this media. The process flow diagram without coolers, pumps, and heat exchangers for simplicity and proprietary reasons is shown in fig. Uop unicracking process can produce lpg, naphtha, kerosene and diesel, as well as highquality unconverted oil and fcc feed through conversion of heavier feedstocks and adding hydrogen. In 2007, they tested the use of a v 2 o 5 catalyst, before acquiring the rights to perform the canmet hydrocracking process. Hydrocracking diagram ebullated bed hydrocracking page 1 of 2. Uops bensattm process can be used on a light reformer. Hydrotreating and hydrocracking process training course. Hydrocracking diagram ebullated bed hydrocracking page 1. Total hydrocracking catalyst component loading in the first stage was lowered by almost 60% while maintaining hydrocracking activity. Houdry hydrocracking article about houdry hydrocracking by.\nThe process can also produce fcc feed through the conversion of heavier feedstocks and the addition of hydrogen. Uop uniflex process, a slurry hydrocracking process, maximizes conversion of residues to transportation fuels and reduces residue byproducts. There are now over 300 hydrocrackers around the world almost as popular as the fcc, and getting more popular as. Robust, costeffective solution for residue conversion. In this work in order to study the regeneration of deactivated catalysts, several samples are regenerated decoking by a fluidized bed reactor and addition of active metal and the initial test of activities are studied. Hydrocracking is a catalytic process used in refineries for converting heavy oil fractions into high quality middle distillates and lighter products such as diesel, kerosene, naphtha and lpg. In 2006 uop began work with nrcan to evaluate and improve their canmet hydrocracking process technology package. See definitions, sources, and notes link above for more information on this table. This is generally a more demanding hydrotreating process, but is. Adding in the power of our complete portfolio of hydrocracking catalysts, uop hydrocracking solutions are designed to improve your overall profitability. It withstands severe process upsets, and will recover faster and more completely than competitive catalysts. Uop acquired the exclusive worldwide rights to license the canmet hydrocrackingprocess in 2007. Comparing thermalcracking and catalytic hydrocracking in the.\nHydrocracking fundamentals hydrocracking has been around for over 50 years, since chevron u. Jul 06, 2014 catalytic hydrocracking has shorter history than catalytic cracking and it was started in 1958. The process design will depend on many factors such as feed type, desired cycle length, and the desired product slate. Hydrocracking experiments were carried out at different temperatures using a homemade stainless steel autoclave. The primary reactions taking place are hydrocracking, hydrogenation, hydrodesulfurization, and denitrification. The industryleading uop unicracking technology gives you the flexibility you need to upgrade a variety of feedstocks to highquality, lighter transportation fuel products. Hydrocracking processes distillate hydrocracking is a refining process for conversion of heavy gas oils and heavy diesels or similar boilingrange heavy distillates into light distillates naphtha, kerosene, diesel, etc. Houdry hydrocracking article about houdry hydrocracking. A worldleading supplier of hydrocracking catalysts, honeywell uop inaugurated the use of catalysts in the refining industry in 1931. The uop unicracking process is carried out at moderate temperatures and pressures over a fixed catalyst bed in which the fresh feed is cracked in a hydrogen atmosphere. Nov 01, 2017 hydrocracking is the refining process in which middle and heavy distillate fractions are cracked broken into smaller molecules. Hydrocracking science and technology chemical industries book 66 kindle edition by scherzer, julius, gruia, a. Worldwide demand for gasoline and middle distillate fuels is increasing at the expense of heavy fuels and the diesel fuel market is growing faster than that of gasoline. Modeling and simulation of a hydrocracking unit 883 journal of engineering science and technology june 2016, vol.\nHydrocracking is a catalytic chemical process used in petroleum refineries for converting the highboiling constituent hydrocarbons in petroleum crude oils to more valuable lowerboiling products such as gasoline, kerosene, jet fuel and diesel oil. Hydrocracking in petroleum processing springerlink. The uniflex mc process converts vacuum residue and other. The first model is targeted for the hydrocracking of vacuum gas oil. Modeling of hydrocracking is only considered for hc and the character of the materials of hc is the same with ht in the ref. This enabled higher hydrotreating capability, increasing the potential to process more difficult feed. Comparing thermalcracking and catalytic hydrocracking in. Planning start the planning process for transport at the time of initial design. Past, present and future article in petroleum technology quarterly 54. In fact, the overall hydrocracking process is highly exothermic in nature. J download it once and read it on your kindle device, pc, phones or tablets. The effluent vapour from the hydrocracker reactors can contain several corrosive compounds, such as wet carbon dioxide, hydrogen sulfide and ammonium bisulfide. Mar 27, 2010 hydrocracking simulation posted in chemical process simulation.\nHydrocracking definition of hydrocracking by merriamwebster. Hydrocracking ebullated bed hydrocracking ebullated bed hydrocracking valve number valve description design temperature range design pressure range pipe size recommended valve1 deg f deg c psig bar g inches dn cseries isolator 2. Chevron built the first commercial unit at standard oil of ohio in the 1960s. Catalytic reforming encyclopedia article citizendium.\nThe differences between these configurations are partial or complete conversion of feed to lighter. This situation is a problem in many regions for refiners with fccs. Hydrocracking is an alternative to solvent refining technology which allows production of a far more pure and stable base stock. Idle refineries represent refineries where distillation units were completely idle but not permanently shutdown as of january 1 of the year. Introduction hydrocracking is one of the most versatile of all petroleumrefining processes 1. Improvement of the performance of a hydrocracking reactor. In the industrial hydrocracking process, the hydrocarbon cracking reaction is often occurrence in the ht. Hydroprocessing hydrotreating hydrocracking samson.\nImprovement of the performance of a hydrocracking reactor using a computational uid dynamics perspective. Ghu pilot plant demonstrates capabilities on refinery residuals the increasing global demand of crude oil is turning towards heavier oils. These two processes also have differences in feedstock, process objectives and their products. Catalytic hydrocracking energy information administration. Keywords slurry phase hydrocracking heavy oil mos 2 free radical mechanism molybdenum naphthenate introduction the hydroprocessing of residue includes.\nThe hydrocracking process depends on the nature of the feedstock and the relative rates of the two competing reactions, hydrogenation and cracking. This refiner is planning to use enhanced first stage. Hydrocracking simulation posted in chemical process simulation. Use features like bookmarks, note taking and highlighting while reading hydrocracking science and technology chemical industries book 66. Maximizing corrosion resistance in refinery hydrocracking. They often have excess gasoline and heavy fuel capacity and yet must import diesel fuel to keep up with their customers demand. Hydrocracking is the phenomenon where big petroleum molecules are broken into smaller molecules with a lower boiling point in the presence of hydrogen.\nTracking of each package should entail every step of the process, who received the package last, when the package was received, and when the package was released from that part of the process. Steadystate modeling of an industrial hydrocracking. Hydrocracking and hydrotreating refining processes needed for increasing heavy oil demands utilizing hydroconversion refining for world oil demand and heavy oil processing obstacle. The hydrocracking process is uniquely suited, with proper optimization, to assist in solving these problems.\nTwo separate mechanistic kinetic models have been developed for the hydrocracking of complex feedstocks. It is also known as a hydrogen addition process, but fluid catalytic process is known as carbon rejection process. Am1525 new hydrocracking developments demonstrate lower. The main hydrocracking reactions are cracking and hydrogenation. A bifunctional catalyst is used in the process in order to facilitate both the cracking and hydrogenation. In addition, the organometallic compounds in the feed are broken down under high temperature and high hydrogen partial pressure and are, in part, adsorbed on the catalyst, the remainder passing through the catalyst bed, ultimately. Steadystate modeling of an industrial hydrocracking reactor. Through significant advances in catalyst technology, we can increase the. Uop s uniflex mc process is a slurry hydrocracking process which achieves the highest conversion and produces the maximum naphtha and diesel yield compared to other residue conversion technologies.594 909 1183 1152 206 487 739 187 1653 321 1365 1007 338 593 536 1201 976 811 372 742 255 1493 1243 1273 284 1093 1068 1133 1466 834 1494 721 935 159 1181 468 718 140 135 1303 751 988"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"}],"document_ids":["<urn:uuid:1daf5358-a023-4132-9008-c5e465819eed>","<urn:uuid:1510e4b0-8d81-4dab-97e9-d7951f228854>"],"error":null}
{"question":"As someone interested in weather patterns, I'm wondering how temperature affects both air density and pressure, and what this means for atmospheric conditions?","answer":"Temperature has significant effects on both air density and pressure. When air is heated, the molecules move faster and spread apart, becoming less dense and creating lower air pressure. Conversely, cool air is denser and creates higher air pressure. This relationship is explained by the ideal gas equation of state, where density depends on both pressure and absolute temperature. In weather terms, high pressure generally indicates fair weather conditions, as warm moist air cannot rise and form clouds. Low pressure, associated with warmer, less dense air, generally means cloudy and rainy weather as air masses move apart and warm air can rise to form clouds.","context":["The principle of hydrostatic equilibrium is that the pressure at any point in a fluid at rest (whence, “hydrostatic”) is just due to the weight of the overlying fluid.\nAs pressure is just force per unit area, the pressure at the bottom of a fluid is just the weight of a column of the fluid, one unit of area in cross-section.\nThis principle is simple to apply to incompressible fluids, such as most liquids (e.g., water). [Note that water and other common liquids are not strictly incompressible; but very high pressures are required to change their densities appreciably.] If the fluid is incompressible, so that the density is independent of the pressure, the weight of a column of liquid is just proportional to the height of the liquid above the level where the pressure is measured. In fact, the mass of a unit-area column of height h and density ρ is just ρh; and the weight of the column is its mass times the acceleration of gravity, g. But the weight of the unit-area column is the force it exerts per unit area at its base — i.e., the pressure. So\nFor example, the density of water is 1000 kilograms per cubic meter (in SI units), so the weight of a cubic meter of water is 1000 kg times g, the acceleration of gravity (9.8 m/sec2), or 9800 newtons. This force is exerted over 1 m2, so the pressure produced by a 1-meter depth of water is 9800 pascals (the Pa is the SI unit of pressure, equal to 1 newton per square meter).\nThe unit of pressure used in atmospheric work on Earth is the hectopascal; 1 hPa = 100 Pa. So the pressure 1 m below the surface of water (ignoring the pressure exerted by the atmosphere on top of it) is 98 hPa. Standard atmospheric pressure is 1013.25 hPa, so it takes 1013.25/98 = 10.33 meters of water to produce a pressure of 1 atmosphere. (That's about 34 feet, for those who like obsolete units.)\nThe pressure in the ocean increases by about 1 atmosphere for every 10 meters of depth. The average depth of the ocean is about 4 km, so the pressure on the sea floor is about 400 atmospheres.\nThe density of air, under standard conditions, is about 800 times less than the density of water — almost 1.3 kg per cubic meter. So the height of a column of air needed to exert the standard atmospheric pressure of 1013.25 hPa would be about 8 thousand meters (8 km), if it were all the same density — i.e., homogeneous. That height is “the height of the homogeneous atmosphere.”\nYou can see from the relation above that this height, H, is just P/(gρ). Even though the atmosphere isn't really homogeneous, this 8-km height is a useful characteristic length that keeps turning up in calculations of atmospheric refraction. (A better name for this concept is Radau's term, “reduced height”.)\nHydrostatic equilibrium is a little more complicated to apply to air, because air is very compressible. The same principle still applies, but we now have to deal with a density that varies with pressure and temperature.\nis the differential equation that expresses hydrostatic equilibrium. [Remember that g is the local acceleration of gravity, which is needed to convert the element of mass ( ρ dh ) into the force (i.e., its weight) it adds to the unit area beneath it. The minus sign is there because g acts in the negative direction along the height scale. We are implicitly assuming that the range of h is so small compared to the radius of the Earth that g can be assumed constant.] Its elementary solution is\nand if ρ = const., we can take it outside the integral:\nIn other words, the pressure is just proportional to the height, h, of the column of fluid, as we already knew. (The minus sign comes from the fact that we measure h positive upward, but the atmosphere's weight is directed downward.)\nFor air, things are not so easy. The density, ρ, depends on both P and T, the absolute temperature. The equation of state is the function that tells us the density. For air, it's a very good approximation to use the equation of state for an ideal gas,\nwhere μ is the (dimensionless) molecular weight — about 29 for dry air — and R is the “gas constant” that takes care of the units.\nEven though this relation is very simple, it still complicates the integrand of the hydrostatic equation. First of all, it gets P involved in the integrand, which is no longer a simple function of h. Secondly, it introduces a new independent variable, T.\nWe'd like to express everything inside the integral as a function of a single variable. To do this, we need some additional relationship among P, ρ, and T, which would allow us to get rid of the second independent variable.\nUnfortunately, there is no additional physical relationship available, in general. The actual dependence of P, or ρ, or T, on height, is quite variable in the real world. This dependence is what's meant by the phrase “the structure of the atmosphere.” [In the astronomical literature of the 18th and 19th Centuries, it was often called the “constitution” of the atmosphere, which is confusing to a modern reader; “constitution” today means “composition” rather than “structure.”] The structure of the real atmosphere varies considerably from place to place and from time to time.\nIt's often convenient (though somewhat unrealistic) to assume that the structure of the atmosphere is polytropic; this is explained on the polytropes page.\nBut, even though we can't integrate the hydrostatic equation until some additional information (such as the run of T with height, or the dependence of P on ρ) is available, we can still evaluate the height of the homogeneous atmosphere. That's just the height the atmosphere would have if it had the same density everywhere (i.e., the density at the surface of the Earth), and the same pressure at the bottom as the real atmosphere.\nGiven the temperature and pressure at the surface, and the composition of the gas there (which is what determines the mean molecular weight, μ), we can find the density of air at the surface. Then the height of the homogeneous atmosphere is just\nbecause P is the weight of a column of gas of height H and density ρ in the gravitational field of the Earth, with acceleration g.\nIf you'd rather think in terms of the mass of one molecule, m, then the gas law is ρ = μP/(NkT), where N is Avogadro's number, k is Boltzmann's constant, and μ is the (dimensionless) molecular weight. (The molecular mass m is μ times the atomic mass unit, u.) Then the height of the homogeneous atmosphere is\nbut we can use the ideal gas law, ρ = μP/(R T) , to get rid of ρ. So, write dP as\nNow, integrate this. On the left side, we get ∫ dP/P , which is just ln P ; on the right, T is constant, so we get some constants times ∫dh, which is just h. Of course there is a constant of integration; we see that it has to be the value of ln P at h = 0. So:\nCombine the two logarithms to get ln (P/P0) on the left. Then get rid of the logarithm by exponentiating both sides:\nNow, remember the homogeneous atmosphere? Its height H was RT/μg. Notice that this is the reciprocal of the coefficient of h in the argument of the exponential. So we have\nIn this case, the reduced height H is usually called the “scale height” of the atmosphere.\nFinally, because T is constant, the density decreases exponentially with height exactly as the pressure does. This is important for the bending of rays near the horizon, because the bending is proportional to the density gradient.\nThere's a fine webpage on Hydrostatics at the University of Denver, if you'd like to know more about this subject.\nCopyright © 2003 – 2006, 2010, 2014 Andrew T. Young\nrefraction calculation page\nGF home page\nor the alphabetic index\nor the website overview page","can vary at any particular point on the Earth depending on the density of the air Air Pressure can vary at any particular point on the Earth depending on the density of the air Density = mass / volume Density = mass / volume\nWhere is air pressure higher, up in the mountains or down in the valley?\nElc&feature=related Air Pressure and Altitude\nThis bottle was photographed at 3600m (left) then again at sea level (right) We all live underneath a huge ocean of air that is several miles deep: the atmosphere. The pressure on our bodies is about the same as ten meters of sea water pressing down on us all the time. At sea level, because air is compressible, the weight of all that air above us compresses the air around us, making it denser.\nDensity Density = Mass / Volume Warm air is less dense than cool air. Warm air rises. Cool air sinks. Air at high altitudes is less dense than air at lower altitudes.\nFactors that affect Air Pressure Temperature Water Vapor Elevation\nTEMPERATURE AND AIR PRESSURE HEAT Molecules move faster Move apart, become fewer and weigh less LESS AIR PRESSURE\nHIGH TEMPERATURE, LOW AIR PRESSURE LOW TEMPERATURE, HIGH AIR PRESSURE\nAMOUNT OF WATER VAPOR consists of air and water molecules\nMore water vapor means less air molecules (more water molecules) LOW AIR PRESSURE DRY AIR = HIGH AIR PRESSURE\nAir Pressure & Weather\nHigh pressure generally means fair weather Air mass in upper atmosphere Layer of Air Warm, moist air cannot rise No clouds\nLow pressure generally means cloudy, rainy weather Air masses move apart Warm air rises, clouds form\nWeather map Low pressure system: Increased cloudiness, winds, temperatures, and chance of precipitation. High Pressure System: Indicates clear, calm conditions with reduced chance of precipitation. Drier air usually results in a greater range of high and low temperatures.\nMeasuring Air Pressure Air Pressure is measured by an instrument called Barometer Types of Barometer Mercury Barometer Aneroid\nAir pressure increases, column of mercury rises Air pressure decreases, column of mercury drops\nHigh Pressure: Rising or steady - Continued fair Slowing falling - Fair Rapidly falling - Cloudy, Warmer Medium pressure: Rising or steady - Same as present Slowing falling - Little change Rapidly falling - Precipitation likely Low Pressure: Rising or steady - Clearing, cooler Slowing falling - Precipitation Rapid falling - Storm\nFactors Affecting Air Pressure FACTORIncrease/DecreaseAir Pressure Density Temperature Water Vapor Altitude\nAt the top of a mountain you drank a bottle of water, sealed it, but imploded on your way down. Why? How does air pressure affect scuba diving? A rising barometer indicates a spell of cool dry weather. A series of hot, humid days is preceded by a falling barometer. A southern, coastal areas tend to have lower air pressure than an inland area farther north. Rapidly dropping temperatures are accompanied by a rising barometer. You are planning a Picnic and check the barometer, which is falling. Why should you cancel the picnic? Why would a serious athlete decide to train at a high altitude? You are hiking Mount Everest and find it hard to breathe at a high altitude. How does a hot air balloon work?"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:7e14f7c5-bba2-4062-b8ff-170066aab2b7>","<urn:uuid:093f8ee1-8783-49be-afc5-26eed433c767>"],"error":null}
{"question":"is oxycontin more dangerous than buprenorphine?","answer":"Both medications have risks, but they serve different purposes and are regulated differently. OxyContin (oxycodone) is a Schedule II controlled substance with very high potential for abuse and significant addiction risk. Buprenorphine (combined with naloxone in medications like N8 M pill) is a Schedule III controlled substance used to treat opioid addiction rather than for pain. Buprenorphine includes naloxone which blocks opioid effects to prevent abuse. Both can cause dangerous side effects like slowed breathing and death if misused, but buprenorphine has built-in abuse deterrents that OxyContin lacks.","context":["The orange, six-sided pill with the imprint M 8N has been identified as Buprenorphine Hydrochloride and Naloxone Hydrochloride (Sublingual) 8 mg / 2 mg supplied by SpecGx LLC. Buprenorphine is an opioid medication, sometimes called a narcotic. Naloxone blocks the effects of opioid medication, including pain relief or feelings of well-being that can lead to opioid abuse.\nN8 M pill is used to treat narcotic (opiate) addiction. Buprenorphine and naloxone is not for use as a pain medication. N8 M pill may also be used for purposes not listed in this medication guide. Risk cannot be ruled out during pregnancy. Buprenorphine/naloxone 8 mg (base) / 2 mg (base) is classified as a Schedule 3 controlled substance under the Controlled Substance Act (CSA).\nWhat should I discuss with my healthcare provider before taking N8 M pill?\nYou should not use this medicine if you are allergic to buprenorphine or naloxone (Narcan).\nTell your doctor if you have ever had:\n• breathing problems, sleep apnea;\n• enlarged prostate, urination problems;\n• liver or kidney disease;\n• abnormal curvature of the spine that affects breathing;\n• problems with your gallbladder, adrenal gland, or thyroid;\n• a head injury, brain tumor, or seizures; or\n• alcoholism, drug addiction, mental illness.\nSome medicines can interact with N8 M pill and cause a serious condition called serotonin syndrome. Be sure your doctor knows if you also take stimulant medicine, herbal products, or medicine for depression, mental illness, Parkinson’s disease, migraine headaches, serious infections, or prevention of nausea and vomiting. Ask your doctor before making any changes in how or when you take your medications.\nIf you use this medicine while you are pregnant, your baby could become dependent on the drug. This can cause life-threatening withdrawal symptoms in the baby after it is born. Babies born dependent on habit-forming medicine may need medical treatment for several weeks. Tell your doctor if you are pregnant.\nN8 M pill can pass into breast milk and may cause drowsiness or breathing problems in the nursing baby. Tell your doctor if you are breast-feeding.\nHow should I take N8 M pill?\nFollow all directions on your prescription label and read all medication guides. Your doctor may occasionally change your dose. Never use N8 M pill in larger amounts, or for longer than prescribed.\nThis medicine may be habit-forming. Never share this medicine with another person, especially someone with a history of drug abuse or addiction. MISUSE OF NARCOTIC MEDICINE CAN CAUSE ADDICTION, OVERDOSE, OR DEATH, especially in a child or other person using the medicine without a prescription. Selling or giving away N8 M pill is against the law.\nRead and carefully follow any Instructions for Use provided with your medicine. Ask your doctor or pharmacist if you do not understand these instructions.\nUse dry hands when handling this medicine. Place the sublingual tablet or film under your tongue. Place the buccal film against the inside of your cheek. Allow the medicine to dissolve slowly. Do not chew or swallow it whole.\nIf you switch between medicines containing buprenorphine, you may not use the same dose for each one. Follow all directions carefully.\nDo not stop using N8 M pill suddenly, or you could have unpleasant withdrawal symptoms. Ask your doctor how to safely stop using this medicine.\nYou will need frequent blood tests to check your liver function.\nAll your medical care providers should know that you are being treated for opioid addiction, and that you take N8 M pill. Make sure your family members know how to provide this information in case they need to speak for you during an emergency.\nNever crush or break a N8 M pill to inhale the powder (snort) or mix it into a liquid to inject the drug into your vein. This practice has resulted in death.\nStore this medicine in the foil pouch at room temperature, away from moisture and heat. Discard an empty pouch in a place children and pets cannot get to.\nKeep track of your medicine. This medicine is a drug of abuse and you should be aware if anyone is using it improperly.\nDo not keep leftover opioid medication. Just one dose can cause death in someone using this medicine accidentally or improperly. Ask your pharmacist where to locate a drug take-back disposal program. If there is no take-back program, remove any unused films from the foil pack and flush the films down the toilet. Throw the empty foil pack into the trash.\nWhat happens if I miss a dose?\nTake the medicine as soon as you can, but skip the missed dose if it is almost time for your next dose. Do not take two doses at one time.\nWhat happens if I overdose?\nSeek emergency medical attention or call the Poison Help line at 1-800-222-1222. An overdose can be fatal, especially in a child or other person using this medicine without a prescription.\nOverdose symptoms may include extreme drowsiness, cold or clammy skin, pinpoint pupils, fainting, slow heart rate, very slow breathing, or coma.\nWhat should I avoid while taking N8 M pill?\nDo not drink alcohol. Dangerous side effects or death could occur.\nAvoid driving or operating machinery until you know how this medicine will affect you. Dizziness or severe drowsiness can cause falls, accidents, or severe injuries.\nWhat are the possible side effects of N8 M pill?\nGet emergency medical help if you have signs of an allergic reaction: hives; difficult breathing; swelling of your face, lips, tongue, or throat.\nLike other narcotic medicines, N8 M pill can slow your breathing. Death may occur if breathing becomes too weak. A person caring for you should seek emergency medical attention if you have slow breathing with long pauses, blue colored lips, or if you are hard to wake up.\nCall your doctor at once or seek emergency medical attention if you have:\n• weak or shallow breathing, breathing that stops during sleep;\n• a light-headed feeling, like you might pass out;\n• confusion, loss of coordination, extreme weakness;\n• blurred vision, slurred speech;\n• liver problems –upper stomach pain, loss of appetite, dark urine, clay-colored stools, jaundice (yellowing of the skin or eyes);\n• low cortisol levels –nausea, vomiting, loss of appetite, dizziness, worsening tiredness or weakness; or\n• opioid withdrawal symptoms –shivering, goose bumps, increased sweating, feeling hot or cold, runny nose, watery eyes, diarrhea, muscle pain.\nSeek medical attention right away if you have symptoms of serotonin syndrome, such as: agitation, hallucinations, fever, sweating, shivering, fast heart rate, muscle stiffness, twitching, loss of coordination, nausea, vomiting, or diarrhea.\nLong-term use of opioid medication may affect fertility (ability to have children) in men or women. It is not known whether opioid effects on fertility are permanent.\nCommon side effects may include:\n• dizziness, drowsiness, blurred vision, feeling drunk, trouble concentrating;\n• withdrawal symptoms;\n• tongue pain, redness or numbness inside your mouth;\n• nausea, vomiting, constipation;\n• headache, back pain;\n• fast or pounding heartbeats, increased sweating; or\n• sleep problems (insomnia).\nThis is not a complete list of side effects and others may occur. Call your doctor for medical advice about side effects. You may report side effects to FDA at 1-800-FDA-1088.\nWhat other drugs will affect N8 M pill?\nSometimes it is not safe to use certain medications at the same time. Some drugs can affect your blood levels of other drugs you take, which may increase side effects or make the medications less effective.\nNarcotic (opioid) medication can interact with many other drugs and cause dangerous side effects or death. Be sure your doctor knows if you also use:\n• other narcotic medications –opioid pain medicine or prescription cough medicine;\n• a sedative like Valium –diazepam, alprazolam, lorazepam, Ativan, Klonopin, Restoril, Tranxene, Versed, Xanax, and others; or\n• drugs that make you sleepy or slow your breathing –a sleeping pill, muscle relaxer, tranquilizer, antidepressant, or antipsychotic medicine.\nThis list is not complete. Other drugs may affect N8 M pill, including prescription and over-the-counter medicines, vitamins, and herbal products. Not all possible drug interactions are listed here.\nWhere can I get more information?\nYour pharmacist can provide more information about N8 M pill.","What are Opioids? What if I am caught with them without a prescription?\nWhat are Opioids?\nThe most powerful prescription painkillers prescribed by a doctor are called opioids. Opioids are opium-like compounds manufactured to react on the nervous system in the same way as drugs derived from the opium poppy, like heroin. Some of the most commonly abused opioid painkillers are oxycodone, hydrocodone, meperidine, hydromorphone and propoxyphene.\n- Oxycodone is sold under the brand names Percodan, Endodan, Roxiprin, Percocet, Endocet, Roxicet and OxyContin.\n- Hydrocodone brand names include Lorcet, Vicodin, Anexsia, Dicodid, Hycodan, Hycomine, Lortab, Norco, and Tussionex.\n- Meperidine is branded as Demerol, hydromorphone is sold as brand name Dilaudid and propoxyphene is sold with the brand name Darvon.\nOpioids are classified as Schedule II controlled substances under the Federal Controlled Substances Act (21 U.S.C. § 802.). A Schedule II drug is a prescription drug that has been found to be safe when used as prescribed but has a very high potential for abuse and significant risk of addiction. The federal government heavily regulates the manufacture, possession, and distribution of Schedule II drugs. In addition to federal laws, Florida also has their own stringent drug laws under Florida Statutes Chapter 893 that also apply.\nSelling vs. possession\nPossession of opioids such as oxycodone or OxyContin without a valid prescription is a serious crime with harsh penalties. It is a third degree felony to possess less than four grams of Oxycodone without a valid prescription.\nWhen a person is caught with oxycodone but not in the act of selling it, the prosecutor must prove that there was the intent to sell it in order to convict that person of the more serious crime.\nMost drug trafficking charges arise in situations where the prosecution must rely on circumstantial evidence of the defendant’s intent to sell. This is because most defendants will deny that they intended to sell the drug and possessed it only for personal use (which carries a lesser penalty).\nCircumstantial evidence of intent to sell a controlled substance includes:\n- amount of the drug in the defendant’s possession,\n- drug packaging such as plastic bags, scales or other paraphernalia indicating dealing, and\n- the presence of large amounts of cash (assumed to be from sales).\nA person convicted of attempting or conspiring to sell oxycodone or OxyContin is subject to the same penalties as a person convicted of making an actual sale of the drug.\nSale or attempted sale near a school or other facility\nUnder the Controlled Substances Act, a person convicted of selling or attempting to sell oxycodone or OxyContin near a school, including a college, or other areas where young people may be present faces twice the maximum prison sentence, twice the maximum fine, and twice the term of supervised release.\nA person is subject to the enhanced penalties if he or she is convicted of selling or attempting to sell the drug within:\n- 1,000 feet of a public or private elementary, secondary or vocational school\n- 1,000 feet of a public or private college, state college, junior college, or university\n- 1,000 feet of a playground, or public housing facility, or\n- 100 feet of a public or private youth center, or video arcade\nHow is Selling Oxycodone/OxyContin Punished?\nUnder federal sentencing guidelines, someone convicted of selling or attempting to sell oxycodone or OxyContin faces five to 20 years in prison, a $250,000 to $5 million fine, or both. As previously stated, if the defendant is convicted of selling or attempting to sell the drug near a school or one of the other specified facilities, the penalty (both prison time and monetary fine) doubles. And, if anyone dies as a result of the drug sale (from overdose or otherwise), the defendant may face life in prison."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:43551d0b-e54b-4755-be4d-8d0e63cb51e7>","<urn:uuid:b6aa494b-5b1c-4425-9d01-8c9d2e21caaa>"],"error":null}
{"question":"How to remove those gray marks that appear on white dishes from using silverware?","answer":"To remove gray marks from dishes, you have several options. One method is using commercial cleaners like Barkeeper's Friend - sprinkle it on a wet dish and scrub with a moistened dish scrubber. Alternatively, you can make a homemade paste using equal parts baking soda and water, then apply it with a sponge and gently scrub. Adding a few drops of dish detergent can provide extra cleaning power. Another effective method is using silver polish applied with a cloth. After any method, make sure to rinse the dishes clean.","context":["Nothing ruins the appeal of a home-cooked meal like a dirty dish. But some dishes appear to be dirty when they're really not. Gray marks on white dishes often develop on dinnerware that's used frequently for serving meals. These marks aren't actually dirt or debris; they're simply signs of normal wear and tear on the dishes.\nVideo of the Day\nMaking Grey Marks on White Dishes\nThe marks left behind on your dinnerware are often a light, silvery gray, but they may also be more like black. The gray tinged marks give a hint about what put them there — silverware. It can happen any time metal rubs against the white porcelain surface.\nThe simple act of cutting your food or even rubbing the plate with a spoon or fork leaves a metal deposit on the plate. If you whisk an egg in a bowl with a wire whisk, you might see the scuff marks.\nThe metal deposit is thin enough not to harm the utensil, though it does sully plate appearance. This type of damage to your dinnerware is reversible, however, and doesn't mean that the dishes are ruined for life.\nEliminating Gray Marks\nGetting rid of those marks is straightforward. Mildly abrasive cleaning products formulated for dishes are available commercially and are often labeled specifically for mark removal. Barkeeper's Friend is a popular powdered cleaner used for this purpose. Sprinkle it onto a wet dish, scrub it with a moistened dish scrubber and rinse well.\nThese products are helpful but not necessary, as you can create your own mark-eliminating cleaner at home using equal parts of baking soda and water. Combine these ingredients to make a paste. Apply the paste to your dishes using a sponge.\nGently scrub away the metal deposits. Add a few drops of dish detergent for extra cleaning power if needed. Rinse dishes clean afterward. A dab of silver polish applied with a cloth is another effective treatment.\nPreventing These Marks\nYou can't do much about the gray marks left behind by cutlery during normal use. But you may be able to prevent some gray mark by properly loading your dishwasher or being careful with dishes in the sink.\nCutlery in the dishwasher may get jostled around and bump into nearby dinnerware, leaving behind those characteristic gray marks. This also occurs in sink washing when plates bump around in the same basin as cutlery. Avoid this problem by keeping dishes well away from cutlery when loading the dishwasher and by washing dishes and silverware separately in the sink. If you have a stainless steel drying rack for dishes, be careful with tines on the rack that might scratch the plates.\nScratches and Other Damage\nGray or black marks on dishes from the dishwasher or silverware aren't classified as scratches, as they rarely leave an indentation on the surface of the dish. A true scratch leaves an indentation in the dish's surface that you can feel with your finger.\nSome scratches are actually chips in progress, a hairline fracture that develops into a true chip over time. Dishes exposed to very high temperatures may also become rough or visibly distorted on their surface. Unlike utensil marks, scratches on dinner plates and other dishes are often irreparable and could mean the dish needs to be replaced."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:b5cea994-ef2f-4365-8d47-a238e7994438>"],"error":null}
{"question":"As a boxing historian studying immediate rematches, I'm curious how the psychological impact of a knockout loss compares to the round structure changes in modern combat sports - what insights can we draw from historical examples?","answer":"The psychological impact of knockout losses can be devastating in immediate rematches, as shown by the Marciano-Walcott case where Walcott's confidence never recovered from the first fight's KO, leading to a quick loss in the rematch. This contrasts with modern MMA's structured format, where fights are limited to either 3 or 5 five-minute rounds with one-minute rest periods, providing a more controlled environment. The fixed duration of modern fights (maximum 17 or 29 minutes) differs significantly from early UFC events that had no rounds or time limits, as evidenced by the 36-minute Gracie-Shamrock fight.","context":["An immediate return match after a tough loss can be a risky proposition. There is no physical reason for this; after a few weeks the body repairs itself and the welts and bruises fade away. But psychologically, the challenge may prove insurmountable; the wounds to a boxer’s confidence can take much longer to heal. Though the ego is soothed by the reassurances of trainers, handlers, and sundry members of the retinue, and though the boxer may tell himself that next time will be different, there’s no escaping the fact that when that time comes, the conquered pugilist may be stepping right back into the same situation that humbled him several short months ago. Sort of like visiting the dentist again to get the rest of the fillings done.\nUnless he has devised some new tactics or ring strategy (as for example Sugar Ray Leonard did for his immediate rematch with Roberto Duran), and unless he honestly believes all of the stories he has told himself, all of the rationalizations for his defeat, the rematch can become simply a continuation of the first meeting and the disaster plays itself out all over again. Think Jack Dempsey vs Gene Tunney; Ismael Laguna vs Ken Buchanan; Danny Lopez vs Salvador Sanchez; Ray Mancini vs Livingstone Bramble, or Mike Tyson vs Evander Holyfield.\nAnother excellent example of why it’s often wise for a losing fighter to forego a rematch in favour of a restorative tune-up bout or two, took place on May 15, 1953, when Rocky Marciano defended his world championship for the first time against the man he took it from, Jersey Joe Walcott.\nWalcott had lost the belt in sudden fashion the previous September in Philadelphia, concluding one of the most thrilling struggles ever for the heavyweight title. He had been well ahead on points when, early in the thirteenth round, Rocky decided matters with a single crushing right hand. The vicious blow was perfectly timed and perfectly thrown and just about removed Walcott’s head from his shoulders. If he’d wanted to, the referee could have counted to a hundred over the crumpled form of Jersey Joe. Rocky Marciano was the new heavyweight champion of the world.\nThe rematch took place in Chicago and anticipation was high. After all, Marciano vs Walcott I had been a titanic struggle, one of the most bruising and dramatic action bouts in years, and the public perception of Rocky was still uncertain. Many in the fight crowd were unconvinced that this relatively small and rather crude banger possessed the skill to be a top-shelf champion. Walcott remained the more proven commodity, a cagey and crafty ring veteran, despite his advanced years.\nBut neither size, nor skill, nor age were the determining factors in this rematch. Instead, confidence was. Because, as everyone would quickly find out, Walcott’s had yet to recover from that devastating right hand clout six-and-a-half months earlier.\nMarciano vs Walcott II was a brief and uneventful affair. For just over two minutes of the first round, the boxers milled about, Marciano lunging behind wild punches and forcing Walcott to sidestep or retreat, the challenger clutching and grabbing as Rocky tried to get to him. Few clean punches had connected when a retreating Jersey Joe set, feinted, and threw a jab to set up a right hand. But before Walcott could follow through with the right, Marciano countered with a wide left hook and then leaped in behind it with a right uppercut that sent the off-balance Walcott sprawling on his back, his feet flying high above him.\nThe challenger pulled himself up to a sitting position, one hand on the ropes, apparently unhurt. He then chose to sit there, like a man trying to decide if he wants to get out of bed or not, and let the referee count him out. Once the fatal ten was reached, Walcott finally hoisted himself to his feet and promptly assumed the demeanour suitable for a victim of injustice, gesturing and expressing disbelief, strenuously arguing that he was the victim of a fast count, though this was clearly not the case.\nInstead of a fast count, Walcott was the victim of having been put right back into the ring, before his nerve and fighting spirit could restore themselves, with the same man who had rendered him unconscious with a single vicious blow in Philadelphia. Something more than Joe’s world title had been separated from him that night. Perhaps in those empty seconds when he sat gazing at nothing as the referee counted off the final moments of the bout, Joe had been contemplating the scattered shards of his broken confidence, still unmended months after that crushing right hand, and now completely shattered. Walcott never fought again.\n— Michael Carbert","As a newfound MMA fan, you might wonder how long an MMA match lasts, especially if you’ve never watched other combat sports, such as boxing. How many rounds is a fight? What decides the number of rounds? How much rest time is given between rounds?\nIf you’re looking for the answer to these questions, well then look no further my friend, because in this post, I will cover all the factors involved in deciding the length of a UFC fight. How long does a UFC fight last?\nA UFC fight can last either 3 or 5 rounds, with each round being 5 minutes long. In between rounds, the fighters are given one minute of rest time. This means a 3-round fight can last up to 17 minutes, while a 5-round fight can last up to a maximum of 29 minutes when you include rest time.\nHowever, this short answer doesn’t look at the whole picture. In the rest of the post, I will cover all the details that go into the length of an MMA match.\nAlso, this post specifically covers the length of a single UFC match. If you were instead looking for the length of an entire UFC card, check out this post: How Long Is A UFC Event?\nWhat Decides 5 Rounds Vs 3 Rounds\nSo now you know how long a UFC fight can be. But now you’re wondering, Why are some fights 5 rounds instead of 3? Well in short, 5 round fights are reserved for Championship fights, as well as main event fights.\nFive-round fights test the mettle of the fighters and create entertaining fights. Such was the case of the five-round war between Yoel Romero and Robert Whittaker.\nTypically, MMA fights are 3 rounds, as already mentioned previously. However, championship fights are expected to not only demand a greater challenge from the fighters, but also a better viewing experience for the fans.\nIncreasing a fight from 3 rounds to 5 makes it more entertaining, and also lengthens possible viewership time. So whenever a UFC Championship title is on the line, the fight will be scheduled for five rounds.\nWhat about main events? The last fight on a UFC event, otherwise known as the main event, will usually also be scheduled for five rounds. This is for the same reasons as before, such as challenging the fighters and increasing the entertainment value.\nDespite being moved to the main event of UFC 234, Adesanya vs Silva remained a three-round fight.\nThis includes both pay-per-view events as well as other less watched UFC cards. Of course, there are exceptions to this 5-round rule, typically when the main event changes on short notice.\nSuch was the case when Israel Adesanya vs Anderson Silva was moved to the main event of UFC 234, when Middleweight Champion Robert Whittaker was rendered unable to fight one day prior to the event. Despite Adesanya vs Silva being made the new main event, the fight remained scheduled for 3 rounds.\nHow Often Does An MMA Fight Go The Distance?\nSo we know how long a fight can be scheduled for, a maximum of 29 minutes. But perhaps you came here looking for the average length of an MMA fight, including finishes.\nOf course, the average length of a fight will be less when we take into consideration the fights that end early. So to find the true length of an average UFC fight, I took the current top 15 pound-for-pound fighters in the UFC. I then looked at each fighter’s last three fights, to see at what time it ended.\nJon Jones and Khabib Nurmagomedov are currently #1 and #2 on the pound-for-pound list, respectively.\nTaking three fights from 15 fighters gives us a data set of 45 fights to collect times from. From there, we simply find the average fight time of all the fights collected. So what were the results?\nFor the 45 fights collected, the average fight length was 17 minutes (almost exactly). This means the average UFC fight ends 2 minutes into the 4th round.\nOf the fights collected, 25 did NOT go the distance, meaning they ended in a TKO, KO, or submission. This means about 55.5% of UFC fights end before the scheduled time limit.\nOf the 45 fights collected, 55.5% of them ended in a finish, either by knockout, submission, or doctor stoppage.\nThese averages should be taken with a grain of salt, as we can’t possibly expect 45 fights to match the average of thousands of UFC fights that have happened in the past. If you would like to see the stats, you can see the spreadsheet here.\nFight Length In The Early UFC Days\nI am now going to cover fight length in the early days of the UFC, on the off chance that you were searching for that. It would be a reasonable thing to search, as you might be watching UFC 5, having watched 30 minutes of the main event, wondering, “Will this ever end?!”\nThe 5-minute rounds that we are familiar with today were not introduced into the UFC until UFC 21, after which the round system became a rule for most MMA fights. However, prior to this, there was no round system in MMA, and there initially wasn’t a time limit.\nThe main event of UFC 5 was the anticipated rematch between Royce Gracie and Ken Shamrock. It ended up being the longest match in UFC history, which unfortunately ended in a draw after 36 minutes.\nThe longest fight in the UFC’s history was Royce Gracie vs Ken Shamrock at UFC 5. The match lasted 36 minutes, with no rounds or rest periods, before being stopped and declared a draw.\nSo there is really no way of knowing how long a UFC fight held before UFC 21 will last, except that it will be last than 36 minutes.\nI hope this post helped clear up any confusion you might have had about the UFC’s round system.\nIn short, a UFC fight can last either 3 or 5 rounds, and each round is 5 minutes long. At the end of each round, there is a one-minute rest period. This means a fight can last a maximum of 17 minutes for a three-round fight, and 29 minutes for a five-round fight.\nIf you liked this post, feel free to check out similar ones on the Martial Arts History page. Thanks for reading!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:1bdd995b-675e-4196-a684-df353fcb2ada>","<urn:uuid:9a5e291d-9dfe-4f45-9889-c65735b68c44>"],"error":null}
{"question":"Are both the STFC Boulby Underground Laboratory and the Ursoiu Geodynamic Observatory used for scientific measurements in underground mines, and what specific measurements are conducted at each location?","answer":"Yes, both facilities conduct scientific measurements in underground mines. The STFC Boulby Underground Laboratory, located 1.1 kilometers underground in Europe's deepest operating mine, is used for dark matter detection research. Its deep location provides an interference-free environment ideal for developing techniques to detect and analyze dark matter. The Ursoiu Underground Geodynamic Observatory is situated in an old mine shaft at 470m above sea level, where it conducts crustal deformation measurements using specialized sensors like water-tube tiltmeters. These tiltmeters work optimally in mining galleries where temperature is constant, measuring small displacements to monitor geodynamic phenomena.","context":["Science and Technology Facilities Council\nBritish winner of prestigious global science photography prize\nBritish photographer Simon Wright has won the 2018 Global Physics Photowalk competition with a stunning image from the STFC Boulby Underground Laboratory deep under North Yorkshire.\nShining a light on dark matter at STFC’s Boulby Underground Laboratory – 2018 Global Photowalk judges winner\nMr Wright, of Blyton in Lincolnshire, was awarded first place by an international panel of photographers. He also won the public online vote 3rd place with an image at the STFC Chilbolton Observatory in Hampshire. He said: “To say I am on cloud nine would be an understatement, I still keep saying ‘WOW!’. I’ve been taking photographs for as long as I can remember and I’m always looking for somewhere different to visit with my camera, so the opportunity to go into the STFC facilities was too good to pass up. Each location was completely different and I really enjoyed the opportunity to talk to the scientists and staff during the photowalks too.”\nThe competition involved thousands of images submitted by hundreds of photographers from 18 laboratories around the world. The Photowalk was designed to provide a rare glimpse into the people, engineering and technology behind some of the world’s most inspiring, amazing and sometimes peculiar science.\nSTFC’s five UK laboratories participated over the summer months, with the UK regional winners joining the global competition. These world-leading labs have been instrumental in discovering new insights into the formation of stars in distant galaxies, new drug treatments and new weather forecasting models produced on some of the world's fastest supercomputers.\nUnderground tunnels at STFC’s Chilbolton Observatory – third place in the public vote\nProfessional photographer Enrico Sacchetti was a member of the international judges’ panel. Commenting on Mr Wright’s winning image he said: “The lighting is what attracts you to this silent but powerful image. It’s great seeing her completely at ease in this lonely environment.”\nPanel member Ale de la Puente, a Mexican artist and designer, also praised the winning image: “Alone where the unknown still lies, there is light, darkness, and a shadow cast that intriguingly take us deep back to the tunnel, beyond the excellence of technique the metaphor of pushing the horizon far away from light and our view is compelling.”\nYou can see the rest of the winners on the Interactions website.\nAbout the photographs\nSimon Wright – Boulby\nShining a light on Dark Matter - Deep under the North Yorkshire moors in the UK, physicists at the STFC Boulby Underground Laboratory play a lead role in the search to detect and understand the mysteries of Dark Matter. Just five per cent of the Universe is visible matter - stars, planets, galaxies, ourselves. The rest is called ‘Dark Matter’ for obvious reasons, and although not actually yet detected its existence has been inferred from numerous astrophysical observations taken over a vast range of distance and time scales. Located 1.1 kilometres underground in Europe’s deepest operating mine, the Boulby lab is almost entirely free of outside interference – allowing physicists a perfect “quiet” area to develop new techniques in the quest to detect and analyse Dark Matter. Photographer Simon Wright cleverly used a miner’s lamp to highlight the face of STFC’s Tamara Leitan as she scanned an information board at the Lab, thus avoiding the need for a flash which would have strobed off the safety equipment all workers and visitors must wear at the mine. Judges praised the photo’s composition and technical qualities.\nSimon Wright – Chilbolton\nFluorescent lighting glows green in this image at the STFC Chilbolton Observatory - home to a wide range of science facilities covering research in atmospheric science, radio-communications, astronomy, space science and technology. Underground tunnels carry cabling to minimise interference with above-ground measurements.\nLatest News from\nScience and Technology Facilities Council\nListen to the sounds of space in free online film18/10/2018 08:05:00\nAccording to the movie Alien, ‘in space, no-one can hear you scream’. This helped to perpetuate the popular opinion that there is no sound in space, just a noiseless vacuum.\nSOXS to track exploding stars17/10/2018 10:32:00\nA new instrument is set to transform how astronomers look at exploding stars, dangerous asteroids and the sources of gravitational waves.\nHow STFC is helping in the mission to end world hunger16/10/2018 14:32:00\nToday is World Food Day, a global action day celebrated every year on the 16th October. On this day, the world comes together to declare its commitment to end world hunger and to ensure food security and nutritious diets for all.\nGreen Great Britain Week16/10/2018 11:30:00\nThe first Green Great Britain Week will take place 15 – 19 October 2018.\nNew training centre to keep Oxfordshire a hi-tech hub16/10/2018 10:05:00\nA new training centre in Oxfordshire will equip up to 350 apprentices a year with badly-needed technical skills for the local economy.\nLaser research could make £18billion industry more efficient10/10/2018 14:05:00\nSTFC’s world-leading Central Laser Facility (CLF) has been instrumental in new research which might see efficiency savings being made in an industry worth billions to the UK.\nSTFC welcomes £14million investment in the UK's Catalysis Hub10/10/2018 13:17:00\nResearchers at the Rutherford Appleton Laboratory have welcomed the new £14million investment into the UK’s Catalysis Hub that will support a nationwide research programme.\nBudding young scientists enjoy Space Explorers Day10/10/2018 11:33:00\nChildren from six local primary schools visited STFC’s Rutherford Appleton Laboratory in Oxfordshire on Friday as part of World Space Week.","(credit fot this post: Cadicheanu Nicoleta)\nThe Institute of Geodynamics has a network of observatories and observation points, equipped with specific sensors. The department of geodynamical observatories has concentrated its efforts in the frame of the priority theme of the Romanian Academy “Complex geophysical research in geodynamically active areas with a special concern for the Vrancea seismogenic area” on:\n1. Continuous monitoring of local deformations using sensors placed at the level of underground geodynamic observatories (Ursoiu, Crăciuneşti) and of the surface observatory (Căldăruşani)\n2. Correlating the crustal deformations with two important geophysical parameters in order to:\na) Understanding the mechanism of response of the crust to the pressure and temperature variations\nb) Separating the crustal deformations caused by different causes (earth tides, loads due to rain, snow, etc.).\n3. Observing the crustal deformation in the evolution of specific fingerprints of climatic and before major earthquakes.\n4. Updating seismic data base of our institute from CSEM using the following legend:\nAs usual, we remind a few important features of geodynamics observatories network coordinated by the Institute of Geodynamics of the Romanian Academy. This network is composed of three polygons: Căldăruşani-Tulnici geodynamic polygon, Crăciuneşti-Deva, Sarmizegetusa-Regia, Padeş-Gorj geodynamic polygon and Delta Dunării – Mangalia geodynamic polygons (Fig.1).\nThe Geodynamics Observatory Căldăruşani is located in the Romanian Plain (26 ° 16’12” longitude, 44°40’36 ” latitude and altitude h = 75 m above), about 40 km N-NE of Bucharest, in a region associated with more active geodynamic stages, and an important fault (Intramoesic fault). The location of the observatory in this area allows the collection of useful information on the effects of the displacement of tectonic compartments, important information for understanding the mechanisms that lead to the accumulation of energy and the earthquakes triggering in the Vrancea region.\nThe Underground Geodynamic Observatory Ursoiu (22°53’51” longitude and 46°00’43 latitude) is situated at 470 m above sea level, in an old mine shaft, having between 600m and 800m from the entrance to the gallery, rooms with sealed doors to reduce drafts.\nThe Underground Geodynamic Observatory Crăciuneşti (22°52’28” longitude and 46°00’47 ” latitude) is located in a disused mine shaft lies just north of Ursoiu observatory in similar geological conditions and altitude.\nGEODYNAMIC SENSORS FOR CRUST DEFORMATION MEASUREMENTS\nAnalysing the geodynamic phenomena by continuous recording of the crust deformations, indirect measurements were carried out, based on measurements of very small displacements of the sensitive elements from the system measurements. These displacements are measured by the help of displacement sensors which give a variable tension versus monitored displacement.\nWater-tube tiltmeters (Figs.2 and 3) have a base of tens or hundreds of meters. For the complete recording of the variations in horizontal plane two clinometers are necessary, perpendicular on each other. Water-tube tiltmeters work in optimal conditions in a mining gallery where the temperature is constant. If the tiltmeters are situated in a location where the temperature has variations over 1oC, the measurement of the temperatures of the two terminals and the application of a temperature correction is necessary. The latter can be theoretically calculated, but it must be verified experimentally, especially in the case of tiltmeters that do not have identical environmental conditions at the two terminals.\nFigure 2. Water-tube tiltmeter (single terminal)\nFigure 3. Tiltmeter raw recordings – 2014. URSOIU Geodynamical Underground Observatory\nTiltmeters with vertical pendulum (Fig.4) show the direction of G vector through a normal or inverse pendulum. The length of the pendulum represents the measurement base and is limited from design reasons at values of meters or tens of meters, fact that imposes a high sensitivity of the displacement sensors which are used. One pendulum can record the movement on two perpendicular directions in plane if it is equipped with displacement sensors.\nFigure 4. Vertical pendulum\nThe recording gravimeters (Fig. 5) for observatory are ASKANIA GS11 type. This type of gravimeter was initially designated for the field measurements, using a direct reading, carried out by an operator. The instrument was modified and adapted for a continuous recording, replacing the system for reading with a displacement sensor of high sensitivity. In this way there are carried out continuous recordings of the variations of the intensity of G vector, with a higher sensitivity than the original device. The stability of the recordings was raised, as well, by assembling the instrument in fix location, continuous electric supply and by its maintenance in chambers with small variations of temperature. Gravimeters will be assembled on a concrete pile, very deeply embedded in terrain. The setting in perfect horizontal position has to be done periodically to eliminate the possible modifications of this position meantime, fact that have a sensitive influence over the recordings.\nFigure 5. Askania gravimeter\nThe temperature of the chamber, in which gravimeter is set, must be rather constant for improving the thermostat functioning. This demand will be the best-achieved in underground observatories in which the variation of the temperature is maximum +/- 0.50C during one year.\nFigure 6. Gravimetric raw recordings – 2014. CALDARUSANI Geodynamical Observatory\nAt the other observatories the gravimeters are installed in special chambers, thermally insulated, situated in the underground, assuring a slow variation and small amplitude of temperature. In actual conditions the quasi-continuous recordings allow a good observation of the phenomenon of earth tides and allow noticing some anomalies, linked to the local conditions of surface or subsurface.\nWe have used the north-south and east-west records from tiltmeters, vertical records from Askania gravimeters and the records from temperature and pressure sensors (Fig.7 and Fig.8)\nThe atmosphere is a complex interface between outer space and Earth’s surface on the one hand, and an environment sensitive to its internal processing. From this perspective, atmospheric pressure and temperature are two important parameters whose variations can provide additional information related to the evolution of crustal deformation and, indirectly, subcrustale processes.\nThe air pressure changes reflected both the effect of temperature variations of the atmosphere, and the result of attraction of the Earth and its external bodies, mainly the moon and sun. In order to quantify these effects, we retained the variations of the atmospheric pressure, of the temperature and of the three directions of the crustal deformation: vertical, north-south and east-west.\nThe electronic systems of acquisition of the data are different, from the professional ones of type National Instruments on 16 bites, with own software Lab View.\nFigure 7. Pressure variations from Ursoiu – 2014.\nFigure 8. Temperature variations from Ursoiu – 2014\nWe mention that the existence of a laboratory for calibration and ageing of the geodynamic equipment (LERAG) was necessary in the framework of the activity of research for realizing performing sensors for geodynamics.\nTHE PRESENCE OF THE PRESSURE VARIATIONS IN THE RECORDS\nThe study of the of the atmospheric pressure influences on the crustal deformation is not simple. The Earth’s atmosphere, defined by highly fluctuating parameters, can be measured and survey only by advanced techniques and a dense network of observation stations. An example is the weather getting harder to do in terms of sudden changes, in terms of the variations of the coefficients of the nonlinear equations in the currently used algorithms.\nVariations of different amplitudes and frequencies of some important geophysical parameter can be found in the geodynamical records (Ex: component daytime or semidiurnal). These parameters are: daily temperature variations associated with the corresponding atmospheric pressure variations, earth tides and anthropogenic activity.\nWe have analyzed by means of the FFT and HICUM methods, the common periods of the atmospheric pressure variations and crust deformation variations recorded by sensors mentioned in Chapter geodynamic observatories.\nProcessing of the data was done with the MICROGRAPH program and own programs written in MATLAB environment.\n– A band of low frequency corresponding to the relatively random variation of the temperature and to the seasonal periods related to the movement of Earth’s revolution around the sun and the rotation axis inclination to the ecliptic;\n* A band of frequencies corresponding to diurnal solar attraction of the Moon on air masses and frequencies “daily”due to the Earth’s rotation axis;\n* A band of frequencies corresponding to the semidiurnal moon-sun attraction.\nPHASE VARIATIONS OF THE AMPLITUDE FOR THE M2 EARTH TIDE COMPONENT AT THE LEVEL OF THE GEODYNAMIC OBSERVATORIES FROM ROMANIA.\nEarth tides are an important natural phenomenon which causes periodical variations in the gravitational field and deformations of the earth’s interior and earth’s surface. Measurements of the Earth tides provide information on the elastic constants of the Earth (Love numbers). In contrast to earth tides, which can precisely computed, earthquakes are almost unpredictable although some investigations have shown that the elastic properties of rocks may change before earthquakes occur. If the elastic properties of rocks could be monitored it would be, in principle, possible to contribute to earthquake precursory research.\nSome parameters of earth tides, as amplitude and phases of their components, are directly related to the elastic properties of rocks. Through the modeling and systematic observations of earth tide parameters related to rock elasticity it should be possible to detect precursors of earthquakes.\nBut measurements of the deformation of the Earth are generally complex functions of the direct response of the Earth to the deforming forces combined with instrument response, local and regional loading and crustal structure. Finding of the most appropriate method able to provide information about variations of the elastic properties of rocks remains a difficult challenge.\nWe have chouse to monitories the phase variations of the amplitude for the M2 Earth tide component at the level of the geodynamic observatories from Romania. This is a first step to understand the possible relation between the temporal variations of M2 phase and other local and global important geophysical phenomena (tectonically processes, seismic precursory, etc.). Our methodology is based on HiCum methods applied in sliding windows on the time series of gravimetric and tilt records.\nDISSEMINATION OF RESULTS\nThe researchers of the “Sabba S. Stefanescu” Institute of Geodynamics of the Romanian Academy were present with a lot of scientific communications to prestigious national and international symposium, conferences and workshops. Their scientific activity is also reflected in many papers published in appreciated scientific revues.\nVirtual International Laboratory of Geodynamics (2001-to present) – “Sabba S. Stefanescu” Institute of Geodynamics of the Romanian Academy in cooperation with the United Institute of Earth Physics “O. Yu. Schmidt” of the Russian Academy of Sciences\nCIPACT 930173-ERB-351 PL 926540 Contract, Co-operation Programme between the Royal Observatory of Belgium and the Institute of Geodynamics of the Romanian Academy – studies of the influences induced by earth tides on the geophysical data.\nUnesco Chair in Geodynamics (2004-to present) – Agreement between the United National Educational, Scientific and Cultural Organization and “Sabba S. Stefanescu” Institute of Geodynamics of the Romanian Academy (Romania)\nResearch stages (2011-2012) at the Royal Observatory of Belgium in the frame program of a Phd on the theme “Studies of the gravimetrical influences induced by earth tides on the intermediate Vrancea seismic activity”\nNational and international Symposium\nAnnual Scientific Conference of the Faculty of Physics of the University of Bucharest, Bucharest, June 17, 2011\nCADICHEANU Nicoleta., Horia MITROFAN, Mirela-Adriana ANGHELACHE, Constantin MARIN & Alin TUDORACHE, Appraisal of a well-defined category of earthquakes: the intermediate-depth Vrancea events with NW-SE-striking fault-plane solution.\n17th International Symposium on Earth Tides, „Understand the Earth”,Warsaw, Poland, 15-19 April, 2013\nCadicheanu Nicoleta, van Ruymbeke Michel & Zhu Ping, On the variability of the coupling between some earth tide periodicities and earthquake triggering from three important seismic nest regions on earth.\nNEMO Workshop – Numerical Modelling Using High Performance Computing Infrastructures, Bucharest, Romania, 10-11 June 2013\nCadicheanu Nicoleta, Validation of the statistical parameter of correlation between earth tides and earthquakes\nAnnual Scientific Session of the Institute of Geodynamics of the Romanian Academy, Bucharest, January 9-10, 2014\nCadicheanu Nicoleta, Phase variations of the amplitude for the M2 Earth tide component at the level of the geodynamic observatories from Romania.\n5th National Conference on Earthquake Engineering and 1st National Conference on Earthquake Engineering and Seismology, Bucharest, Romania, June 19-20, 2014\nMirela-Adriana Anghelache, Florina Chitea, Horia Mitrofan, Nicoleta Cadicheanu, Assessing possible effects of earthquakes in terms of groundwater radionuclide pollution in Cernavodă area"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:4bb0e5c6-9b36-4f78-8ca8-ef7ad961e5fe>","<urn:uuid:fa098be6-70c7-4b74-b7c3-6360391ceb71>"],"error":null}
{"question":"What are the differences in visibility impacts between Great Smoky Mountains and Yosemite National Parks?","answer":"Both parks suffer from significant visibility degradation, but with different specifics. In Great Smoky Mountains, the average visibility has decreased 40% in winter and 80% in summer since 1948, with current average visibility at 25 miles compared to natural conditions of 93 miles. In Yosemite, pollution reduces the average natural visual range from about 160 miles to about 75 miles, and on high pollution days, visibility drops from about 110 miles to below 35 miles. While Great Smoky Mountains' visibility is mainly affected by sulfate particles from power plants, Yosemite's worst visibility problems are often caused by smoke from nearby forest fires.","context":["Air pollution is shrinking scenic views, damaging plants, and degrading high elevation streams and soils in the Great Smoky Mountains. Even human health is at risk. Most pollution originates outside the park and is created by power plants, industry, and automobiles.\nGreat Smoky Mountains National Park has an array of air quality initiatives underway, including research and monitoring. Research and monitoring conducted in the park has shown that airborne pollutants emitted from mostly outside the Smokies are degrading park resources and visitor enjoyment. The burning of fossil fuels—coal, oil, and gas—causes most of the pollution. Inadequate pollution control equipment in power plants, factories, and automobiles is the primary problem.\nWind currents moving toward the southern Appalachians transport pollutants from urban areas, industrial sites, and power plants located both near and far. The height and physical structure of the mountains, combined with predominant weather patterns, tend to trap and concentrate human-made pollutants in and around the national park.\nViews from scenic overlooks at Great Smoky MountainsNational Park have been seriously degraded over the last 50 years by human-made pollution. Since 1948, based on regional airport records, average visibility in the southern Appalachians has decreased 40% in winter and 80% in summer. These degradations in visibility not only affect how far one can see from a scenic overlook, they also reduce how well one can see. Pollution causes colors to appear washed out and obscures landscape features. Pollution typically appears as a uniform whitish haze, different from the natural mist-like clouds for which the Smokies were named.\nThe burning of fossil fuels produces tiny airborne sulfate particles which scatter light and degrade visibility. Increasingly, visitors no longer see distant mountain ridges because of this haze. Annual average visibility at Great Smoky MountainsNational Park is 25 miles, compared to natural conditions of 93 miles. During severe haze episodes, visibility has been reduced to under one mile. Sulfate concentrations increased in the region by 27% from 1984-1999. Electricity-generating power plants are the source of most sulfates.\nIn a 1996 survey, 74% of summer visitors to the Smokies said clean air was “extremely important” to them during their stay in the park; 84% said scenic views were “extremely important.”\nGround-level Ozone Pollution Threatens People, Plants\nAnother air quality problem, ozone pollution, threatens human health and park plants. Not to be confused with the naturally occurring, beneficial ozone layer which filters the sun’s ultraviolet rays, ground level ozone is a colorless gas created when nitrogen oxides mix with hydrocarbons in the presence of sunlight. Power plants, automobiles, and factories are the main producers of nitrogen oxides. Most ozone pollution originates outside the park and travels to the Smokies on prevailing winds.\nOzone exposures in the park are among the highest in the East and in recent years have exceeded levels that threaten human health. On average, ozone levels over the ridgetops of the park are up to two times higher than in nearby cities, including Knoxville and Atlanta.\nOzone is a powerful respiratory irritant for humans. Research shows that ozone can cause coughing, sinus inflammation, chest pains, scratchy throat, even permanent damage to lung tissue and reduced immune system functions. Children, the elderly, people with existing health problems, and active adults are most vulnerable.\nOzone levels are injuring trees and other plants. Thirty species of plants showed leaf damage after being exposed to controlled ozone levels identical to those that occur in the park. To further quantify ozone injury to plants, permanent monitoring plots were set up in the park. In general, researchers have found that ozone exposure and damage to plants are worse at the higher elevations. They have also documented that up to 90% of black cherry trees and milkweed plants in numerous park locations show symptoms of ozone damage. Some of the other plants that show ozone damage symptoms include tuliptree, sassafras, winged sumac, blackberry, and cutleaf coneflower.\nAcid Rain, Acid Clouds, and Nitrogen Overload\nPlants and animals in Great Smoky MountainsNational Park are also threatened by airborne sulfur and nitrogen pollution. The park receives the highest sulfur and nitrogen deposits of any monitored national park. These pollutants fall to the ground not only as acid rain, but also as dry particles and cloud water. The average acidity (pH) of rainfall in the park is 4.5, 5-10 times more acidic than normal rainfall (5.0-5.6). Clouds with acidity as low as 2.0 pH bathe the high elevation forests during part of the growing season.\nResearch shows that certain high elevation soils in the park are receiving so much airborne nitrogen that they are suffering from advanced nitrogen saturation. This condition limits the availability of forest nutrients, especially calcium, to plants and causes the release of toxic aluminum that can hurt vegetation and streamlife. Mountain streams and forest soils are being acidified to the point that the health of the park’s high elevation ecosystems is in jeopardy. Nitrate levels in some streams are approaching the public health standard for drinking water.\nFederal mandates for clean air\nCongress passed the Clean Air Act in 1970, establishing national policy for preserving, protecting, and enhancing air quality. The 1977 amendments designated all national parks that exceed 6,000 acres as mandatory Class I areas worthy of the greatest degree of air quality protection under the Act. Also under the Act, Congress mandates the federal land manager (Department of Interior Assistant Secretary for Fish, Wildlife, and Parks, in the case of the Smokies) to “protect air-quality related values,” including visibility, flora, fauna, surface water, ecosystems, and historic resources. It further directs the land manager to “assume an aggressive role in protecting the air quality values of land areas under his jurisdiction... In cases of doubt the land manager should err on the side of protecting the air quality-related values for future generations.”\nUnder the Clean Air Act, the National Park Service is invited to comment on state air quality permit applications for major factories, power plants, and other air pollution sources proposed for location near Class I areas. Since 1980, the Park Service has sent comments to nearby state and local agencies on over two dozen permit applications covering new pollution sources near the park. The Park Service has worked with state authorities to try to ensure that any increases in pollution be “offset” by reductions in pollutant output elsewhere, and that the best available control technology be used to minimize the amount of new pollution produced.\nIn 1992, the U.S. Interior Department Assistant Secretary for Fish, Wildlife, and Parks recommended that air pollution permitting authorities in five neighboring states not issue permits for new major pollution sources within 120 miles of the park unless measures are taken to prevent increasing impacts on park resources.\nAlso in 1992, the Southern Appalachian Mountains Initiative (SAMI) was established as a comprehensive approach to improving regional air quality. SAMI is a voluntary, multi-organizational initiative charged to curtail the adverse effects of air pollution on the southern Appalachians, particularly in Class I areas. Members include state and federal agencies, environmental groups, and industry and utility representatives. However, until the SAMI completes its work, and effective regional solutions are developed and adopted, the Park Service will continue to act on individual permits on a case-by-case basis to prevent air pollution from worsening. The lack of an emissions offset requirement is hindering the air quality protection efforts for the park.\nPark Service Position\nIt is the position of the National Park Service that new emission permits for industries and utilities in the region that will adversely impact the park should be granted only when “best available control technology” is planned and when offset reductions are taken to prevent any net increase in pollutants. The Park Service also supports the strictest possible state regulations on auto and other emissions which contribute to the problem.\nThe Park Service is working with state regulatory agencies, the Environmental Protection Agency, and industrial and utility interests to develop a comprehensive plan to prevent future damage through such measures as offset programs, the use of improved technology, and determination of emission caps and government standards for various pollutants. To remedy air pollution problems at the park, additional reductions of nitrogen oxides and sulfur dioxide are necessary.\nWhat you can do:\n• Conserve energy in the home and work place\n• Use energy-efficient appliances and forms of transportation\n• Keep your motor vehicles in good operating condition\n• Let government officials know that air quality is important to you.","For more information about National Park Service air resources, please visit http://www.nature.nps.gov/air/.\nAir Pollution Impacts\nYosemite National Park\nNatural and scenic resources in Yosemite National Park (NP) are susceptible to the harmful effects of air pollution. Ozone, nitrogen, mercury, and fine particles impact natural resources such as lakes, streams, fish, and vegetation, and scenic resources such as visibility. Click on the tabs below to learn more about air pollutants and their impacts on natural and scenic resources at Yosemite NP.\n- Nitrogen & Sulfur\n- Toxics & Mercury\nOzone and Public Health Concerns\nGround-level ozone concentrations at the park are among the highest recorded in national parks and sometimes exceed the National Ambient Air Quality Standards set by the U.S. Environmental Protection Agency to protect public health.\nOzone is a respiratory irritant, causing coughing, sinus inflammation, chest pains, scratchy throat, lung damage and reduced immune system functions. Children, the elderly, people with existing health problems and active adults are most vulnerable.\nIf ozone concentrations are predicted to be high at Yosemite NP, the park educates employees and park visitors by posting alerts about the risks of exposure to high ozone levels and precautions to reduce exposure.\nNaturally-occurring ozone in the upper atmosphere absorbs the sun’s harmful ultraviolet rays and helps to protect all life on earth. However, in the lower atmosphere, ozone is an air pollutant, forming when nitrogen oxides from vehicles, power plants, and other sources combine with volatile organic compounds from gasoline, solvents, and vegetation in the presence of sunlight. In addition to causing respiratory problems in people, ozone can injure plants. Ozone enters leaves through pores (stomata), where it can kill plant tissues, causing visible injury, or reduce photosynthesis, growth, and reproduction.\nEffects of ozone on vegetation at Yosemite NP include:\n- Widespread injury to ponderosa pine needles, with up to 30–40% of pines injured at certain survey sites (Peterson et al. 1991; Peterson and Arbaugh 1992; Arbaugh et al. 1998);\n- Reduced growth of ozone-injured pines (Peterson et al. 1991; Peterson and Arbaugh 1992);\n- Greater ozone injury on low elevation ponderosa pines as compared to ponderosa pines on dry, upslope areas in the park, indicative of stomatal opening and ozone uptake on trees in moist areas (Panek and Ustin 2004).\nSearch the list of ozone-sensitive plant species (pdf, 184 KB) found at each national park.\nHow much nitrogen is too much?\nNitrogen is a fertilizer and some nitrogen is necessary for plants to grow. However, in natural ecosystems, too much nitrogen disrupts the balance of plant communities, allowing weed species to grow faster. Nitrogen deposited from air pollution may upset the balance of some high elevation lakes at Yosemite NP. Nitrogen deposition is now about 3–4 kg/ha/yr (Sickman et al. 2001). Projects are underway to examine the effect of excess nitrogen to other resources in the park and throughout the Sierra Nevada, and determine whether the critical load has been exceeded. In Sierra Nevada forests, research suggests that the critical load for some lichen species is about 3.1 kg/ha/yr (Fenn et al. 2008). Above that level of nitrogen deposition, lichen communities begin to change, with sensitive species gradually replaced by pollution-tolerant species. Critical loads for lake and forest resources can be used to establish goals for ecosystem recovery.\nNitrogen and sulfur compounds deposited from air pollution may harm lakes, streams, soils, and vegetation in Yosemite NP. While sulfur deposition is generally very low in California and unlikely to affect most ecosystems, nitrogen deposition is higher and its effects are more widespread. Some high elevation ecosystems in the park are particularly sensitive to nitrogen deposition. Not only do these systems receive more nitrogen deposition than lower elevation areas, but short growing seasons and shallow soils limit the capacity of soils and plants to absorb nitrogen, and dilute surface waters cannot buffer the effects of acid deposition.\nEffects of nitrogen and sulfur deposition at Yosemite NP include:\n- Elevated ammonia in lichens from park forests, which may lead to the decline of sensitive lichen species (Jovan and McCune 2006);\n- Decrease in abundance of certain lichen species important for wildlife food and habitat and replacement by weedy, nitrogen-loving species (Fenn et al. 2008).\nToxic air pollutants include pesticides, industrial by-products, heavy metals like mercury, and flame retardants for fabrics. Certain toxic contaminants are known or suspected to cause cancer or other serious health effects in humans and wildlife, including reproductive problems, impaired growth and development, behavioral abnormalities, and reduced immune response.\nEffects of mercury and airborne toxics on ecosystems at Yosemite NP include:\n- Elevated concentrations of current-use pesticides (chlorpyrifos, endosulfans, dacthal, and lindane) in park vegetation samples (Landers et al. 2010; Landers et al. 2008);\n- Concentrations of current use pesticides and other toxic air contaminants in air and vegetation samples ranked above the median as compared to other national parks studied (Landers et al. 2010; Landers et al. 2008);\n- Dramatic population declines of several frog species, including the endangered mountain yellow-legged frogs, likely linked to pesticides (Sparling et al. 2001; Fellers et al. 2004; Davidson and Knapp 2007);\n- Elevated concentrations of mercury in fish from Hetch Hetchy Reservoir (Davis et al. 2009 [pdf, 10.8 MB]).\nMany visitors come to Yosemite NP to enjoy world-class views of famous landmarks like El Capitan and Yosemite Falls. Unfortunately, these vistas are often obscured by haze caused by fine particles in the air. Many of the same pollutants that ultimately fall out as nitrogen and sulfur deposition contribute to this haze and visibility impairment. Organic compounds, soot, and dust reduce visibility as well. Some of the park’s worst visibility is caused by smoke from nearby forest fires.\nVisibility effects at Yosemite NP include:\n- Reduction of the average natural visual range from about 160 miles (without the effects of pollution) to about 75 miles because of pollution at the parks;\n- Reduction of the visual range from about 110 miles to below 35 miles on high pollution days.\n(Source: IMPROVE 2010)\n- Explore scenic vistas through a live webcam at Yosemite National Park!\n- Learn about the Yosemite Aerosol Characterization Study (YACS), a field campaign conducted in 2002 to investigate visibility-impairing aerosols at the park. An aerosol is a gaseous suspension of fine solid or liquid particles. Determining the content of those particles allows researchers to examine sources of aerosols, either natural or human-influenced. more »\nFire and Smoke at Yosemite NP\nConcentrations of fine particles in the park’s air sometimes exceed the National Ambient Air Quality Standards set by the U.S. Environmental Protection Agency to protect public health. These episodes are most often due to fires, including both wildland and contained campfires. Fine particles (smaller than 2.5 microns) are also a result of direct emissions from other sources including power plants, mobile sources (like cars), agriculture, and construction sites, or are formed downwind from sources by reactions with gases and aerosols that react in the atmosphere. For example, power plants, industries, and automobiles emit gases such as sulfur dioxides and nitrogen oxides, which form particles of sulfate and nitrate in the atmosphere.\nFires and the resultant smoke are issues of particular concern at Yosemite NP. Not only do park visitors enjoy a fire while camping in the park, but wildland fire is a natural part of the Sierra Nevada ecosystem. However, the smoke a given fire (big or small) produces impairs visibility and can harm human health. Canyon bottoms like Yosemite Valley are areas that commonly experience the highest fine particle levels during calm, smoky periods.\nSmoke particles come in all sizes, but the small or “fine” smoke particles pose the greatest health concern because they can get deepest into the lungs and can cause serious health problems. Temporary symptoms from short-term exposures can include burning eyes, runny nose, coughing, shortness of breath, and illnesses like bronchitis. Longer-term exposures to particle pollution may aggravate asthma, increase risk heart attacks and premature death in people with heart or lung disease. Visit Smoke in Yosemite and the park’s Air Quality and Smoke Monitoring web pages for more information about current smoke impacts in Yosemite NP.\nStudies and monitoring help the NPS understand the environmental impacts of air pollution. Access air quality data and see what is happening with Studies and Monitoring at Yosemite NP.\nLast Updated: February 23, 2016"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:68016f0c-2fa3-4610-8d3d-0f845b09b904>","<urn:uuid:254157df-8d4f-47f0-abfe-5780d83c12cf>"],"error":null}
{"question":"I work in wildlife research and want to understand the data exchange capabilities between marine navigation systems and GPS tracking devices. Can both systems effectively share route information using the same file format?","answer":"Yes, both marine navigation systems and GPS tracking devices can share route information using GPX (GPS Exchange Format), which is the standard data format in the marine electronics industry. Marine auto-routing systems can export routes, waypoints, and track logs in GPX format, which can be transferred between devices via SD cards or apps. Similarly, GPS tracking devices, including miniature GPS loggers used for wildlife tracking, create GPX files that can be exchanged between different devices and systems. However, compatibility issues may arise when manufacturers add additional information that isn't compatible with all devices and programs, or when GPS files contain too many individual points.","context":["Auto-Routing, A Crash Course\nAuto-routing software for boats first appeared over five years ago when Garmin took their road-based navigation to the water. Since then there have been a myriad of updates, technological advances, and new players in the marketplace. The basic idea is that you can enter a start and finish coordinate on an electronic chart and the algorithms in the software will determine the safest route based on the description of your boat and the navigational aids on the chart.\nGarmin refers to it as “auto guidance” while Navionics (owned by Garmin), Raymarine, and Navico (Lowrance, Simrad, and B&G) refer to it as dock-to-dock auto-routing. To start, you enter your boat’s safe depth, width, and height parameters. Once you enter your starting point and your destination, the software will plot waypoints (a route) for you to follow. It can also provide the total distance, time to your destination, and fuel consumption.\nThe first time I used the software, I entered the actual draft of my boat, which was a mistake. I should have used the depth of water that I felt comfortable with! My boat draws 6’ but I would prefer to be in 10’ of water. In the initial setup, you can either enter 10’ or enter 6’ with a keel offset of 4’. The challenge, in shallow water, is to remember if you set the keel offset or not. And remember, the depth calculation is based on a zero tide.\nOne of the best applications of auto-routing is trip planning. I commonly find myself wondering where I should go next. Ultimately, part of that decision is the distance to the next destination. Using the auto-route feature, I quickly calculate the distance to various destinations around me. Having those realistic routing distances readily available allows me to decide how far I’ll go on my next destination.\nQuite often the system will plot the shortest route possible, however, many areas in the Pacific Northwest contain traffic separation zones and shipping lanes. These will show up as warning triangles along the route. In these cases, you can tap anywhere along the navigation route and drag the waypoint to where you want it to clear an obstacle. When you release the new waypoint, the software will automatically re-calculate the route and update your distance and time to destination.\nWhile you are underway, you can watch your progress and see the updated stats. Another cool feature is that you can browse through services and points of interest like marinas, restaurants, or marine repair shops. Using Navionics or the Garmin Active Captain App, you can call directly from the app to either a VHF channel or a telephone number to confirm a slip assignment or make reservations. You can even get fuel prices and write reviews. If you have a compatible chartplotter you may be able to transfer auto-routing information and software updates from your smart device.\nIf you are using a mobile app, it relies on the internal GPS receiver of your device to determine location. If your device does not have an internal GPS, you can automatically pair it with your compatible chartplotter via Bluetooth, and the chartplotter will give you the GPS information. GPS Exchange Format (GPX) is more or less the standard data format that the marine electronics industry uses, which allows you to share files with friends and other chartplotters. You can still use an SD card and the apps will automatically share routes, waypoints, track logs, software updates, screenshots, and sonar recordings.\nWhen choosing a navigation system, it is important to understand the difference between raster and vector charts. Most multifunction displays have charts available in either format, but apps usually use only one. A raster chart is basically a photocopy of a paper chart and require significantly more digital storage. However, if you are familiar with paper charts, there is little-to-no learning curve. Vector charts are a digital copy of a raster chart and allow you to access additional information as you zoom in. That is how you can view details about marinas and even access social media.\nThe bottom line is that auto-routing is a very cool feature, but it is based on electronic chart information and is not a replacement for safe, visual navigation practices. Give it a try!","In any discussion of routes, navigation or GPS devices, you have probably seen people mentioning ‘GPX files’. GPX is shorthand for GPS eXchange Format and is a type of file that’s really helpful to anyone who loves the outdoors, and is the most popular way of saving and exchanging routes.\nWhat’s in a GPX file?\nYou can actually open a GPX file in any text editor, and you’ll get something like the image here. While this looks complex, all most people need to know is that it is a list of precise locations, in order, that make a up a route for walking, running, cycling or any other activity. This route can then be placed on top of a map for printing or following on screen.\nUsing a GPX file – with a mapping application\nIf you use a mapping application such as our own OS getamap you can use a GPX file to follow routes created by others, or to create your own routes for saving or sharing.\nCreate a route from a GPX file by first saving the route on to your hard drive or USB stick. You can then import the route. Look for an option labelled ‘Import Route’ or ‘Import GPX file’. You then should be able to see the exact planned route on screen, allowing you to review, print or edit as needed.\nCreate a GPX file from a route by drawing the route on screen. You will be able to export the route as a GPX file and import it into a different mapping application or to a GPS. As it’s a simple text file, you can also easily email it to others. Even if they use a totally different mapping application or different brand of GPS, they should still be able to open it.\nUsing a GPX file – with a GPS Device\nMost GPS devices designed for outdoor sports and navigation can both create and use GPX files. The great thing about the universal nature of a GPX file is that different brands of device, with different maps loaded can all use the same GPX file.\nUse an existing GPX file by loading it on to the device. Check your manual for details, but this normally means connecting the device to your computer by USB cable or Bluetooth, then sending the file to the device. The new route will then appear in the saved routes list on the device, and when active you will be able to follow it. Basic devices without on-screen mapping will generally just show an arrow to point to the next ‘waypoint’ (usually the next turning or fork) while more advanced ones will display the route on a map as well.\nCreate a GPX file by activating the ‘Record Trail’ or similar function. Every few seconds the GPS device will log where you are, and at the end of your trip the file can be exported back to your computer, usually by connecting it via a cable or Bluetooth and finding the file in the memory. You can then load the file into your favourite mapping application to check the distance covered, time taken and altitude profile, or share it with your friends or online.\nWhat else is a GPX file good for?\nGPX files can contain a time for each point and therefore the route as a whole. This is really useful for comparing your performance with your previous best or with others, and is a favourite of runners and cyclists.\nMiniature GPS loggers can be attached to wildlife and pets. These create GPX files and can be used to understand more about animal behaviour – or just to find out where your cat is getting its second dinner from.\nGPX files are a type of XML file initially designed for use by GPS devices, but now used more widely for exchanging route information between different devices and systems. There is an official schema currently at version 1.1 that describes how GPX files should be constructed.\nMost of the problems with GPX files come from various manufacturers who add additional information that is not compatible with all devices and programs that can use GPX files, or GPS files that contain a large number of individual points.\nThis will often mean that you cannot open a GPX file created on one device or program in another. There are some desktop and online tools that will try to tidy the files, and there is always the option of manually editing them useing a plain text editor, such as Notepad in Windows or TextEdit on Mac."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:cc87fc7f-1732-474a-badb-5c9e620f41b9>","<urn:uuid:77da50a3-eb92-4ac4-a08e-f4efff54eae3>"],"error":null}
{"question":"Hey, I'm doing research on medieval book production - what's the difference in animal skins needed between the Devil's Bible and the Codex Amiatinus?","answer":"The Devil's Bible required the skins of 160 animals (most likely donkeys) to create its 310 parchment leaves, while the Codex Amiatinus required a much larger number - the skins of approximately 500 animals for its production.","context":["It’s a mysterious book that in its day was believed to contain all human knowledge. But why did medieval people believe that the author sold his soul to the devil to be able to write it?\nThe “Devil’s Bible,” a behemoth volume weighing in at 165 pounds, believed to have been produced by a single monk over the course of decades in the 13th Century, is the focus of a documentary that was featured on the National Geographic Channel.\nA complete Old Testament and New Testament, and a collection of a number of secular works besides, the Devil’s Bible is an encyclopedia of medieval knowledge. But it has also been haunted by dark speculation, including that its writing was guided by the devil’s hand.\nDevil’s Bible Photo open on the page of the picture showing Satan © MHP\nIt got its name “Devil’s Bible” from the illustration of the devil on page 290 (in the photo above). It is believed to be the only bible of its era that depicts Satan. There the devil is, looking more like a cartoon character in an ermine diaper, rather than evil incarnate.\nDevil’s Bible (Codex Gigas) manuscript © MHP\nWhat makes the Devil’s Bible such an object of fascination is the back story associated with it. According to the TV show, which I watched when it premiered, the legend about the Devil’s Bible was that it was written by a monk in a single night.\nCompact with the devil\nThe story goes that such a feat was possible only because the monk had made a compact with the devil. The implication is that the devil himself wrote this bible, which is why his portrait adorns it.\nHowever, if the devil inspired the book then there is nothing in it that appears to cast Satan in a good light, at least not that I can find by searching for information on the Web about the Devil’s Bible. (It is more properly known as Codex Gigas, or “Giant Book.”)\nCodex Gigas manuscript © MHP\nThe television show combined the story and the extraordinary history of this giant book with modern forensic science to see what can be established about the Devil’s Bible. The manuscript was definitely produced by one person, according to analysis of the ink and penmanship.\nMost likely the producer of the Devil’s Bible was a monk whose name is mentioned in the index and who probably devoted many, many years to the task, perhaps as a form of penance. The Devil’s Bible was written by one person, but it was not written in a single night.\nDevil’s Bible (Codex Gigas) manuscript © MHP\nPortraits of the Devil are common in medieval art, but this one in the Codex Gigas may be unique in books for showing him alone and occupying a whole page. The Heavenly City (photo on the left) and the Devil Portrait are the only full page pictures in the Codex Gigas.\nThe provenance of this extraordinary book and its unlikely story as well as its journey across centuries, passing through a succession of monasteries and royal palaces to its current destination, the National Library of Sweden, is a legitimate story for National Geographic to cover. And it makes good television too.\nExorcism and Magic Spells in the Devil’s Bible\nThere are also two magic spells, both with specific instructions on how to identify and catch a thief.\nPossession by demons was commonly thought during medieval times to be the cause of many illnesses.\nThe church had specific rituals to exorcise evil by casting demons out of an afflicted person’s body.\nIn the name of Jesus\nAccording to the Christian New Testament, Jesus gave his disciples the power to cast out evil spirits, which is why scholars believe the medieval exorcists commanded demons to leave an afflicted person’s body “in the name of Jesus Christ.”\nThe incantations for exorcism would not be out of place in the Devil’s Bible, appearing after this picture of the devil.\nDevil’s Bible facts:\n- The 310 parchment leaves (620 pages) of the Devil’s Bible are made of vellum, from the processed skins of 160 animals, most probably donkeys. Some pages of the Devil’s Bible are thought to have been removed, and no one knows what happened to them.\n- The entire Devil’s Bible is written in Latin. The calligraphy is lavishly luminated throughout.\n- Including its wooden case, which is ornamented with metal, the Devil’s Bible is so heavy (about 165 pounds) that it requires at least two adults to carry it.\n- The portrait of the devil faces a picture of the “City of Heaven,” the only other image in the Devil’s Bible. Some scholars believe that the picture of Heaven negates the portrait of the devil. Others have noted that no people can be seen in the City of Heaven.\n- Also in the Devil’s Bible is the “encyclopedia” by St. Isidore, who, more than a millennium after he lived, is regarded as the patron saint of the Internet. Isidore’s Etymologiae was an attempt to record all universal knowledge of his time, the 7th Century.\nDevil’s Bible additional information:\nCodex Gigas (Official Codex Gigas site at the National Library of Sweden, contains highlights and scholarly analysis of the Devil’s Bible.)\nCodex Gigas (World Digital Library’s full digital scan of the entire Devil’s Bible)\nManuscriptorium (Czech-language site’s high-res scans of the Devil’s Bible)\nDavid Maxwell Braun is director of outreach with the digital and social media team illuminating the National Geographic Society’s explorer, science, and education programs.\nHe edits National Geographic Voices, hosting a global discussion on issues resonating with the Society’s mission and major initiatives. Contributors include grantees and Society partners, as well as universities, foundations, interest groups, and individuals dedicated to a sustainable world. More than 50,000 readers have participated in 10,000 conversations.\nBraun also directs the Society side of the Fulbright-National Geographic Digital Storytelling Fellowship.","MGM, at its zenith in the 1940s, used to boast that it had more stars than there are in heaven on its roster. It’s a phrase that came back to me walking round the current, jaw-droppingly good exhibition at the British Library, Anglo-Saxon Kingdoms: Art, Word, War. By the time I was half way through it, perhaps sooner, I was planning my next visit. And I’m not sure that one will be my last either.\nIt’s an exhibition so prodigal in its glories that it is almost casual about them: one case alone houses four manuscripts that contain about 90% of all surviving Anglo-Saxon literature: the Nowell Codex, which includes Beowulf; the Vercelli Book, which includes the Dream of the Rood; the Exeter Book, which includes Deor, The Seafarer and The Wayfarer; and the Junius manuscript, which includes Genesis and Exodus.\nIf English literature is important to you, this single case is worth the exhibition’s entry price alone. It is not just that these are the earliest manuscripts of these works, or the best. They are in most part the only manuscripts. Without these few handfuls of parchment, there would barely be any pre-Conquest literature to speak of. And when you think how heart-stoppingly tenuous their survival has been, you realise with some force how precarious and vulnerable our connections to the past are. The 10th-century Vercelli Book is back in England for the first time in perhaps 900 years: it was left behind by an unknown visitor to the northern Italian town of Vercelli, a resting point on the road to Rome, at some point early in the second millennium. The Exeter Book, also 10th century, shows evidence of having been used as both a chopping board and a beer mat in its long life. The Nowell Codex – written c1000 – in common with a number of manuscripts in the exhibition was part of the library of Sir Robert Cotton, the great early 17th-century antiquary, which was caught in a fire at the prophetically named Ashburnham House on 23 October 1731. It was only just saved: the edges of its pages are heavily scorched. Other manuscripts, of course, were far less fortunate.\nOn one level the abundance on offer is dazzling: Anglo-Saxon Kingdoms is the best and most comprehensive exhibition about the Anglo-Saxons you will ever see, covering the period from Gildas, a Romano-British monk of the 6th century who bore bitter witness to their arrival in his excoriating De excidio Britanniae (‘On the Ruin of Britain’), and ending in the aftermath of the Norman Conquest. One should avoid superlatives, but the exhibition invites them because it contains so many itself. I defy anyone to walk around it and keep track in their head of all the firsts, the earliests, the oldests, and the onlys among the manuscript descriptors.\nEveryone will have their favourites here, things that offer hair-on-the-back-of-the-neck moments of recognition, surprise and awe. You expect to be overwhelmed by the lavish intricacies of the illuminated gospels and psalters and you are: the pages are careworn, creased and stained with age, but the sheer energy caught in these thickets of colour and invention remains startlingly fresh. Again, the Lindisfarne Gospels, created in Northumbria, are worth the entry price alone; set alongside the Mercian Barberini Gospels, or the Kentish Stockholm Codex Aureus with its purple-stained pages, or the aptly-named Harley Golden Gospels from East Francia, or the Irish Book of Durrow – to name just a few – they give vivid life to the phrase ‘an embarrassment of riches’.\nMore surprising, for me, was the line work that emerged in gorgeous clarity and simplicity towards the end of the period. It’s displayed here in a range of marginal and other illustrations, from the strange five-person Trinity of Aelfwine’s Prayer Book to the dynamic figures accompanying the psalms in the Harley Psalter and the watchful portrayals of agricultural life on the Julius Work Calendar. The latter is an inadvertent reminder that agriculture and book production – the preserve of monastic scriptoria throughout the period – were intimately connected. Monastic wealth was predicated on gifts or bequests of farmland. Books themselves were made from animal hides, stretched and pared and scraped to provide a smooth writing surface; scribes who made mistakes could simply scratch away the top layer of skin and start again.\nI was also surprised to find myself particularly drawn to the St Cuthbert Gospel, one of the more modest exhibits on display, being a small pocket-sized book of the gospel of St John created by the scriptorium at the great double monastery of Jarrow-Wearmouth in Northumbria. It was once said to be the personal gospel book of St Cuthbert himself – “the most benevolently charismatic of all British saints” the DNB says – who died in Lindisfarne in 687. It was found beside his head when his coffin in Durham Cathedral was opened in 1104, but is now thought to post-date his death by a decade or two.\nI think the appeal is its intimacy. Whether it belonged to Cuthbert or no, it is designed to be held in the hand, for its owner to carry with them as they went about their rituals and devotions. I find it hard to think it doesn’t carry something of the freight of that connection, rubbed somehow into its red leather covers, caught somewhere on the ink and skin of its pages. And it is, besides, the earliest European book still in its own binding. Its intactness gives me a little of the same kind of charge later pilgrims to his shrine must have had holding it in their hands and exulting in the spark of sanctity they felt from its little heft, its light aura of holiness.\nIronically, the same scriptorium also produced the vast Codex Amiatinus, which weighs in in at some 75lbs. It is a book so big it required the skins of some 500 animals to produce.\nThe technical term for the Amiatinus is a pandect: a single manuscript volume containing all the books of the Bible. This one is the oldest complete Latin Bible in existence. It was commissioned – along with two other pandects – by St Ceolfrith, abbot at Jarrow-Wearmouth at the close of the seventh century. The mere fact that such a project could be countenanced is a testament to the expertise available in Northumbria at the time; indeed, the early part of the exhibition demonstrates what an engine of learning and culture the kingdom was, one of Europe’s greatest bulwarks against the chaos that consumed so much of it. Likewise, the fact that the earliest known copy of the Rules of St Benedict is English – more properly, Mercian or West Saxon – exemplifies both the strength of the English monastic community c700, and the instabilities and vicissitudes elsewhere on the continent.\nTwo of the pandects were intended for each of the abbey’s churches. The third, Ceolfrith himself took to Rome in the summer of 716 on what would prove to be his final journey: he died en route in Burgundy on 25 September at the age of 74. At some point over the next few hundred years it found its way to the Tuscan monastery of San Salvatore at Monte Amiata, from which it gets the name by which it is now known. It is the only one of the three to have survived.\nOf the other two, one has disappeared entirely. The second was dismembered, presumably during or shortly after the Dissolution of the Monasteries, which saw the gutting of England’s great monastic libraries alongside its other destructions. Some dozen folios from it are known to survive: one turned up in a shop in Newcastle in 1882; another among estate papers in Kingston Lacey in Dorset a century later. Most of them, however, were found being used as wrappers for the Willoughby family’s estate papers in Nottinghamshire – as powerful a symbol of the post-reformation desacralisation of England’s catholic cultural heritage as you could wish for. It is these – known as the Wollaton Leaves – that are on display here alongside the Amiatinus.\nIf there is a frisson from the Amiatinus being on these shores again for the first time since it left with Ceolfrith from the mouth of the River Humber on 4 July 716 – and how powerful the specificity of such information is when so much of these centuries’ history is blank – then surely there is another from the juxtaposition of it with the Wollaton Leaves a few feet away. Two once identical works created at the same time by the same hands in the same scriptorium, using the same ink and the same hides from the same herds – but with antithetical fates: one magnificently whole, the other broken up five centuries since, carelessly reused, scribbled on, abused.\nThis duality of survival and loss is something runs throughout Anglo-Saxon Kingdoms. The sheer profusion of the exhibition – its ability to offer display after eloquent display of deep history and often high art – sharpens our sense of how arbitrary and rare these survivals are. So much has been lost, destroyed by the vagaries of time, by the violence of determined men and by the determined neglect of others, each indifferent in their own way to the dead and to the beauty and mystery and importance of the past.\nIt is a fitting thought, however, because endurance and loss – the plaintive awareness of how closely ruin shadows even the brightest civilisations – are very Anglo-Saxon qualities. It is there quite explicitly in the Codex Amiatinus, which has a frontispiece featuring a painting of the prophet Ezra sitting and copying out the scriptures on his lap. Behind him is a full shelf of books. Above the picture a scribe has written in Latin, “When the sacred books had been consumed in the fires of war, Ezra repaired the damage”, referring to the tradition that Ezra used memorial reconstruction to recover the Hebrew Scriptures for future generations after the Babylonians had destroyed them. It is also quite clearly making a claim on behalf of the Amiatinus, of Ceolfrith, and of the scribes at Jarrow-Wearmouth: their work is one of recovery, restoration and rebuilding from a period of darkness and war.\nThe same point – which of course itself also echoes the laments of Gildas about the Anglo-Saxons themselves – is made by King Alfred in his preface to the translation of Gregory the Great’s Pastoral Care, which he distributed to his bishops in the 890s. Alfred had fought the vikings to a standstill and prevented them from over-running his kingdom. But after suffering their attacks for decades, England was much decayed. “[B]efore it had all been ravaged and burnt… the churches throughout all England stood filled with treasures and books, and there were also a great many of God’s servants… [M]en from abroad came to this land in search of wisdom and teaching [but]… now we must get them from abroad if we shall have them.” There were very few south of the Humber who could translate Latin, Alfred said, and not a single one south of the Thames when he came to the throne. Wisdom and learning, like the land itself, had to be fought for if it was to be won again. Alfred wasn’t alone in feeling civilisation to be vulnerable: some 9th-century charters have caveats specifying that their land grants should only endure while Christianity endured among the English, clearly suggesting some scepticism about that eventuality.\nThere is a wider emotional sense behind this – elegaic yet defiant, or, more accurately, elegaic and defiant – which is expressed most powerfully in some of Anglo-Saxon England’s most memorable poetry. It is there in Deor, with its ubi-suntish refrain, ‘That passed away, and so may this’, and it is there in The Wanderer and the extraordinary passage beginning (in Robert Hamer’s translation):\nWhere is the horse now, where the hero gone?\nWhere is the bounteous lord, and where the benches\nFor feasting? Where are all the joys of hall?\nAlas for the bright cup, the armoured warrior,\nThe glory of the prince. That time is over,\nPassed into night as it had never been…\nAll is hardship\nHere property and friendship pass away,\nHere man himself and kinsmen pass away.\nAnd all this earthly structure comes to nought.\nIt is hardly surprising that Boethius’ Consolations of Philosophy – represented here both in Latin and Anglo Saxon versions – was so popular. Alfred himself has been claimed as the author of the latter and around 20 per cent of all surviving manuscripts of the work pre-1100 are English.\nI wrote earlier that this was the best exhibition about Anglo-Saxon England you will ever see. But I’m tempted to add that it may also be the best exhibition about nation-building you will ever see; and, for the same reason, the best exhibition about the power of literacy and the power of the book you will ever see. The English language was Alfred’s chosen cultural weapon against the erasure that the Danes represented, and he described his translations as being made word for word and sense for sense. You might say that, word by word and document by document, Anglo-Saxon Kingdoms bears witness to the capacity of literacy to order a both society and a landscape, and of language – vernacular and Latin alike – to shape and sustain a people. And thereby to remember that people when time has swept them aside.\nI have only mentioned a few manuscripts, but really the exhibition touches on so much: politics, poetry, history, riddles, music, medicine, wills, farming, laws, letters, land-ownership. In one sense or another, we see history everywhere being written and rewritten, made and unmade.\nAnd yet it is all so achingly fragile. Here are what must be thousands of animal hides laboriously worked up into parchment on to which the our ancestors poured their souls in line after perfectly inscribed line, in voluptuous ornament, in sometimes rough and sometimes elegant design. I don’t know what should strike us as more remarkable, that these memorials to an entire culture should be so vulnerable they could simply be scraped from the very skins on which they are written. Or that their frailties should have endured for so long, undefeated by time, and tenderly, piercingly human in their doubts and certainties, their hopes and fears.\nImage: King David composing the psalms, Vespasian Psalter, 8th century, Kent ©British Library"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"}],"document_ids":["<urn:uuid:e7617951-1ff1-457f-a108-69d7ff8c4044>","<urn:uuid:be245760-d34a-4128-b185-37890987926c>"],"error":null}
{"question":"How to operationalize voter registration in a survey?","answer":"To operationalize voter registration in a survey, ask respondents 'Are you currently registered to vote in your state?' with two response options: (1) Yes, I am registered to vote; (0) No, I am not registered to vote.","context":["Levels of measurement are important because they serve as a way to think about both the amount of information available in a measure and the mathematical properties of the measure. In this exercise you are going to consider the amount of information available in variables that measure the same concept with different levels of measurement.\nFor each of the variables below, identify the level of measurement. Second, explain why one variable provides more information than the other. Finally, why might you prefer to use one measure over the other? Why is capturing more information important?\nVariable #1: What is your highest completed level of education?\nNo formal education\nHigh school College\nVariable #2: How many years of formal education have you completed?\nHerrmann, Tetlock, and Visser1 define the disposition of military assertiveness as “the inclination toward different methods of defending American interests abroad, in particular, whether a person prefers more militant and assertive strategies or more accommodative and cooperative approaches.” To measure military assertiveness, they used ten items. For the first eight items, they asked respondents to indicate whether they strongly agreed, agreed, neither agreed nor disagreed, disagreed, or strongly disagreed with the statement.\nWhich of the following items do you think are the most valid measures of the concept of military assertiveness and why? Which ones do you have trouble relating to the concept and why? What kind of validity (face or construct) do you think the items exhibit?\n1. The best way to ensure world peace is through American military strength.\n2. The use of military force only makes problems worse.\n3. Rather than simply reacting to our enemies, it’s better for us to strike first.\n4. Generally, the more influence America has with other nations, the better off they are.\n5. People can be divided into two distinct classes: the weak and the strong.\n6. The facts on crime, sexual immorality, and the recent public disorders all show that we have to crack down harder on troublemakers if we are going to save our moral standards and preserve law and order.\n7. Obedience and respect for authority are the most important virtues children should learn.\n8. Although at times I may not agree with the government, my commitment to the United States always remains strong.\n9. When you see the American flag flying, does it make you feel extremely good, somewhat good, or not very good?\n10. How important is military defense spending to you personally: very important, important, or not at all important?\nMost valid measures of the concept of military assertiveness:\nWorst “fit” for concept:\nKind of validity:\n1Richard K. Herrmann, Philip E. Tetlock, and Penny S. Visser, “Mass Public Decisions to Go to War: A Cognitive-\nInteractionist Framework,” American Political Science Review 93 (September 1999): 554.\nOperationalization is deciding how to record empirical observations of the occurrence of an attribute or a behavior using numerals or scores. In other words, it is deciding how to move from defined concept to quantifiable variable. In this exercise you are going to consider the challenges involved in quantifying both concrete and abstract concepts that are commonly used in political science research. You will find below a series of conceptualized terms.\nYour job is to explain how you would operationalize each term for use in a survey research project by creating the questions that would yield the appropriate variable for each concept. (Hint: Concrete terms are much easier to work with than abstract terms. Pay close attention to the abstract terms, such as ideology and efficacy.) Example: Voter registration: Whether someone is currently registered to vote. Answer: Ask each respondent to indicate whether he or she is currently registered to vote by asking, “Are you currently registered to vote in your state?” (1) Yes, I am registered to vote; (0) No, I am not registered to vote.\n1. Gender: Male and female\n2. Household income: The amount of money earned by all members of a household in a year\n3. Race: The race each respondent most closely identifies with\n4. Ideology: A set of beliefs and ideas, including one’s moral code and worldview. The most important issues and ideas involve how the government should address those unable to provide food, health care, and housing for themselves and their children. The extent to which the government should extend services to support those in need in these areas makes up the worldview.\n5. Political efficacy: The belief that one’s political action will have a meaningful effect. In particular\nI define political action as interpersonal communication with elected officials.\nBelow you will find a series of hypotheses. For each hypothesis, 1) identify the independent and dependent variables, and 2) explain how you could measure each variable. When explaining your measurement strategy, be careful to consider validity and reliability.\n1. Small business owners are more likely to support tax cuts than other voters.\n2. The availability of government-subsidized childcare causes household income to rise.\n3. An increase in the number of nongovernmental organizations operating in an authoritarian state increases the rate at which the state democratizes.\n4. Access to clean drinking water causes life expectancy to increase."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"}],"document_ids":["<urn:uuid:a871c94e-d3c1-4396-86d6-ceaec174e078>"],"error":null}
{"question":"What does the EU single market look like for services, and what are the pros and cons of using tariffs to protect such markets?","answer":"The EU single market for services shows limited integration despite services representing 80% of GDP, with only 21% of cross-border business being services. While some progress has been made through directives like the 2006 Services Directive and the Capital Markets Union, financial services integration remains particularly low. For example, in investment funds, 70% of assets are held in funds authorized only for domestic distribution. Regarding protective measures like tariffs, they can help protect local industries and create jobs by making foreign goods more expensive, but they also have significant drawbacks. Tariffs can lead to inefficiency in local industries due to reduced competition, spark trade wars through retaliation from other countries, and ultimately make goods more expensive for local consumers. Additionally, tariffs require costly infrastructure and systems to implement, and their administrative costs may sometimes outweigh their benefits.","context":["There has been much discussion around the single market for both goods and services. While there has been considerable progress in creating a free trade area for goods, something which is welcomed by all sides of the current debate, there has been far less actual integration in financial services than the headlines would suggest. Some progress has also been made on the free movement of service providers, but this does not however gain similar widespread support.\nMoves have been made by the EU to improve free trade for services. The Services in the Internal Market (Bolkenstein) Directive in 2006 laid out guidelines to prevent national governments from impeding the establishment or provision of cross-border services in a range of sectors excluding finance. The Capital Markets Union, now accelerated to come into operation in 2019 is designed to deepen and further integrate the capital markets of the EU member states by removing barriers to cross-border investment and lower the cost of funding in the EU especially for new and small firms.\nOn average across the EU 80% of GDP is in services and yet only 21% of cross border business is services. The European Commission itself has recognised the lack of integration in a number of financial services. Specifically in March this year it issued a proposal for a regulation to facilitate the cross-border distribution of collective investment funds. The following narrative, which is taken from the Commission’s proposal, highlights the extent to which a free and single market in financial services is far from reality.\nInvestment funds are investment products created with the sole purpose of pooling investors’ capital, and investing that capital collectively through a portfolio of financial instruments such as stocks, bonds and other securities. In the EU, investment funds are categorised as undertakings for collective investment in transferable securities (UCITS) and alternative investment funds (AIFs) managed by alternative investment fund managers (AIFMs).\nRules for EU investment funds allow managers of investment funds to distribute, and with some exceptions, also to manage their funds across the EU. While EU investment funds have seen rapid growth, with a total of EUR 14 310 billion in assets under management in June 2017, the EU investment fund market is still predominantly organised as a national market: 70 % of all assets under management are held by investment funds authorised or registered for distribution only in their domestic market. Only 37 % of UCITS and about 3 % of AIFs are registered for distribution in more than three Member States.\nAlthough part of the constraint on the development of cross border distribution has been financial – the paper estimates that the cost of the necessary registration process for five funds across three countries is approximately €250,000 – the Commission also recognised that other factors including national tax regimes applicable to investment funds and investors, vertical distribution channels and cultural preferences for domestic investment products all contributed to slow progress in creating a more harmonised market.\nWhile there will no doubt be some impact on UK managers and the distribution of their funds into the EU the current “European passport” regime under which we operate does not provide borderless access but comes with specific registration/notification requirements in each country and associated costs.\nPaul Brewer is CEO of Rubicon Fund Management, London.","PROS AND CONS OF TARIFFS\nProsand Cons of Tariffs\nProsand Cons of Tariffs\nAtariff is a tax or charge levied on imports or exports entering orleaving a particular country. While the sole purpose of the tariff isto restrict trade, there are a number of advantages that accrue withthe imposition of tariffs. Generation of income, restricting tradeand protecting industries are the advantages that accrue with theimposition of tariffs. On the other hand, the imposition of tariffsin an economy carries some disadvantages along with itsimplementation in the economy. In most cases, the increase in theprices of goods and services, reduction of sales volume and traderelations are the cons of imposing tariffs in an economy. Thediscussion on tariffs will illustrate their advantages anddisadvantages in an economy.\nTheAdvantages of tariffs\nOneof the main advantages of tariffs is the protectionism function,where they act as tools of protecting local industries from externalcompetition. Most times, consumers will opt for foreign commoditiesthat are produced instead of buying the same commodity producedlocally. This trend forces the government to impose tariffs oncertain goods so as to protect their own domestic industries or atthe same time make extra money (Gandolfo& Trionfetti,2013).It should be noted that consumers are not prohibited in any way tobuy foreign goods, but the art of imposing tariffs on those foreigngoods makes them expensive (Northrup& Turney, 2003).The consumer will have no choice but to buy the locally availableproducts produce by the local industries.\nAsa result, another advantage of tariffs, creating jobs is achieved.The imposition of tariffs leads to the creation of jobs in an economydue to the protectionist function of tariffs levied on the imports ofgoods, which can be available in the local market. By imposingtargeted tariffs on the importation of certain products, thegovernment prevents the exporting of employment to other countriesand encourages the creation of jobs in the country. This is becauseimporting goods gives the foreign producers the local market andtakes the market away from the local manufacturers (Gandolfo& Trionfetti,2013).Therefore, the local industries cannot grow when the local populationis creating a market for the foreign producers other than their ownindustries. Imposing tariffs cuts the demand and production capacityof the foreign manufactures and gives the same to the localproducers, thereby increasing local production (Gandolfo& Trionfetti,2013).By increasing production levels in the country, the tariffs end upcreating jobs locally.\nInsuch circumstances, it is the responsibility of governments toprotect their domestic employment. As we have seen above, when thereis a stiff competition of imported goods with a country’s domesticgoods, there the domestic industries end up being threatened. Thiscan result in the domestic companies firing their own employees ordeciding to shift to oversee countries, all with the purpose ofcutting costs (Smith,2005).The effect of this will result in a country having an increasednumber of unemployed, unhappy electorates. When ascending to power,many leaders always promise to create employment to their localcitizens, and tariffs open a way of preserving jobs for those whoalready have jobs.\nTheimposition of tariffs is also an advantage to the infant industriesin a country, which are competing with established internationalmanufacturers. A government can also decide to impose tariffs solelyin order to protect its own infant industries that are still tryingto pick up (Smith,2005).When a country wants to come up with its own industry, producing andsupplying a particular type of a good, it must protect the localmarket from the dominance of foreign producers. To achieve this, agovernment must make imports expensive. At the same time, thegovernment must make exports to the local consumers expensive for theforeign producer to viable pursue. To do this, the government will beforced to impose high tariffs on similar products produced fromforeign countries and in the process discouraging local consumersfrom buying the product.\nAnotheradvantage of imposing tariffs is the protection of consumers fromcheap or low quality products from foreign markets. Governments canalso choose to protect their own local consumers when they feel thatsome imported goods are low quality and promote dumping of cheapproducts from foreign producers (Michaely,2009).In such a case, a government will impose high tariff on the good, sois to discourage foreign producers from exporting them to localmarkets. At the same time, the imposition of a high tariff will forcelocal consumers to avoid them as they would be highly expensive toimport.\nTheimposition of tariffs on a product to protect consumers from lowquality products is implemented when a government has no legalgrounds of imposing a total ban on the product (Gandolfo& Trionfetti,2013).This may be as a result of lack of evidence or adherence tointernational trade agreements that may be in favor of the exportingcountry. A good example is where country A imposes a high tariff onmeat or beef from country B. Country A does this if the governmentbelieves that the meat from country B is low quality, but not enoughreason to ban its importation. As a result, the meat imports fromcountry B to country A will reduce or end, because its consumers willfind alternative market to import from.\nAnothersignificant advantage of imposing tariffs by a government is thegeneration of income from the fee levied on imports and exports.Income by the government is earned through the specific types oftariffs levied in the form of cash. For instance, the governmentraises income from the Ad valorem tariffs placed by the importingnation while putting into consideration the percentage of the goodbeing imported overall value (Gandolfo& Trionfetti,2013).\nThegovernment also raises income from the specific tariffs, where afixed fee is always levied on any amount or value of a good beingimported. For example, a country could be charging $500 for all carsbeing imported into its market. The tariff is always flexibledepending on the type of good. For instance, all fresh fruitsimported could be levied at $10 while fresh animal products beingimported could be levied at $30. All this translates into income forthe government.\nTheDisadvantages of Tariffs\nOneof the disadvantages of tariff is inefficiency of local industries,particularly when the tariffs are used as tools for protecting localindustries. When local industries are protected from foreigncompetition through tariff imposition, they face an easy tradeenvironment which may make them compromise on quality(Baier & Bergstrand, 2001). Inthis case, we can see that the art of imposing tariffs on foreigngoods can result to the local industries to be less efficient as theyare not subjected to eternal competition. At the same time, tradewars might arise between nations where the foreign nation might hitback by imposing their own tariffs on all imported goods from a givennation.\nAnotherdisadvantage of imposing tariffs is the impact they have on thebilateral and multilateral trading relationships with othercountries. The imposition of a tariff may induce a retaliatoryrelationship where the concerned countries hurt each other’s tradeby imposition of tariffs on the other country’s exports (Gandolfo& Trionfetti,2013).This may be as a result of a country being motivated to imposetariffs as a retaliation strategy. A country may think that anothercountry has not played by the agreed rules and thus is forced toimpose high taxes on all imported goods entering from the othernation. Retaliation also comes in handy when another nation simplydecides to go against the host nation on foreign government policies.\nAnotherdisadvantage of tariffs is that they create a cost aspect in theirimposition. For tariffs to be effective, they require a country toincur a cost for their imposition to be implemented. This cost is inthe form of employees for tax authorities, tariff infrastructure andsystems put in place (Gandolfo& Trionfetti,2013).The disadvantage comes where the costs incurred outweigh the benefitsgenerated from the tariff. For example, if a tariff meant to protectdomestic producers leads to high administrative costs of imposing it,it ends up being a disadvantage. This may happen where with noreasonable competition, the price of commodities will rise, whichwill also guarantee the sales of those producers to also rise.\nAnotherdisadvantage of tariffs is that they can lead to reduced employment,instead of creating or protecting local employment. Tariffs may limitthe importation of new technology and production potential to acountry, especially tariff levied on machines, raw materials andentrepreneurial equipment(Baier & Bergstrand, 2001). Ifa tariff is imposed on such goods or resources, local productionreduces as producers end up relying only on the local technology. Ifthis happens, the need for the domestic producers to employ moreworkers reduces, which will mean that the jobs will reduce in thecountry (Michaely,2009).As a result, the employment in the country reduces or stays at theold low level, other than creasing through the use of foreigntechnology.\nOnesuch good example that can show how bad tariffs can affect acountry’s economy is the imposition of tariffs on the imposition ofsteel. This will have the short run of benefiting the local producerswho will benefit from high prices to a point that they can even makehigh profits. But in the long run, the increasing cost associatedwith steel will make the cost of production in the economy high. Thelarger cost incurred are then distributed evenly to all consumersthrough high prices (O`Rourke& Smith, 2007).In addition, the production of basic goods will reduce, since steelis used in most factories. The infrastructural development willreduce as almost all industries use steel from buildings, railway,communication, and energy industries among many others. The impact isa crumbled economy, which will rely on imports to sustain itsconsumer needs.\nAnotherdisadvantage of imposing tariffs is the possibility of hurting theeconomy of the country by reducing the quantity and gains of thecountry’s exports. Remember as all this is happening, the tariffincreased and this means that the government is generating moreincome to benefit the economy. The consumer will be left with onlytwo viable options, either to buy less of those expensive goods orseek solace in buying less of other goods. With this increase inprice would mean that the consumer income will be deemed to bereduced.\nMoreimportantly, imposing high tariffs on certain goods discourages theirexportation to export and reduces the quantity of exports. This hasthe negative effect of reducing the amount of revenue a governmentcollects on such commodities (Jones& Martin, 2008).At the same time, reduced exports mean that the country’s foreignexchange will reduce. As a result, both the balance of trade andbalance of payment gets affected negatively, and reduces.\nAnotherbasic disadvantage of tariffs is that they make life expensive forlocal consumers by increasing the price of the products. As far astariffs are concerned, the consumer is always on the receiving end.This happens because the proportion of tariffs levied on imports istransferred by importers to the consumer in terms of a high price(Baier,& Bergstrand, J. (2001).The only time that consumers can be said to benefit from tariffs iswhen in the long run, the domestic industries use the advantage ofthe tariffs to improve on the quality of the production instead ofrelaxing.\nItis therefore a disadvantage that consumers benefit from the effectsof tariffs, but at a cost (O`Rourke& Smith, 2007).This happens because tariffs are designed to mostly favor the localproducers and the government. When tariffs are imposed on certaingoods, they have the impact on making related domestic production tobe favored and not the consumers. On the other hand, imposing oftariffs on certain goods ensure that the government benefits directlythrough revenue collection and not mainly consumers.\nTheimposition of tariffs has both advantages and disadvantages to theeconomy, the producers, consumer and the government. Imposing tariffsearn the government income and gives it a tool to protect localmarkets and industries from foreign markets. Imposing tariffs isadvantageous to consumers as they are protected from low qualityproducts from foreign producers. At the same time, tariffs protectproducers from competition from foreign products throughprotectionism policies. However, tariffs attract a cost in theircollection, reduce exports and may limit the introduction of foreigntechnology. At the same time tariffs may end up punishing the localconsumers as they are transferred in terms of prices. Despite thediscussed disadvantages, tariffs are not only important but necessaryfor an economy and their advantages prove the reason why they shouldbe levied.\nBaier,S., & Bergstrand, J. (2001). The growth of world trade: tariffs,transport costs, and income similarity. JournalOf International Economics,53(1),1-27.\nGandolfo,G., & Trionfetti,F. (2013). InternationalTrade Theory and Policy.New York: SpringerScience & Business Media\nJones,V., & Martin, M. (2008). Internationaltrade.[Washington, D.C.]: Congressional Research Service.\nMichaely,M. (2009). Tradeliberalization and trade preferences.Hackensack, N.J.: World Scientific.\nNorthrup,C., &Turney, E. (2003). Encyclopediaof tariffs and trade in U.S. history.Westport, Conn.: Greenwood Press.\nSmith,J. (2005). In praise of tradeoffs. BMJ,330(7498)Retrived From, <http://dx.doi.org/10.1136/bmj.330.7498.0-g>29 October, 2015"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:e093b585-9ad7-402e-90e6-ac2375567f2a>","<urn:uuid:809b5bf4-df61-42c2-8929-4f9de7462280>"],"error":null}
{"question":"As an ISO auditor, I'm curious about the documentation differences between medical device and environmental standards. How do the documentation requirements in ISO 13485 for medical devices compare to the documentation needs in ISO 14001 for environmental management?","answer":"ISO 13485 has more extensive and specific documentation requirements compared to ISO 14001. For medical devices, ISO 13485 requires detailed documentation including quality policy and objectives, quality manual, computer software validation procedures, medical device files, employee training records, and specific procedures for contamination control and supplier quality agreements. In contrast, ISO 14001's documentation approach is more flexible and framework-based, focusing on environmental management system components without establishing strict performance requirements. While both standards require documentation of management participation and continuous improvement processes, ISO 13485 places heavier emphasis on product safety and quality control documentation, whereas ISO 14001 concentrates on documenting environmental impacts and resource efficiency measures.","context":["When it comes to ISO certifications, one thing companies can count on is a mountain of documentation.\nIt’s especially true for certifying to ISO 13485 for medical device quality management, as medical device manufacturers must provide extensive documentation as evidence of the safety of their products—and the effectiveness of their quality processes.\nIn today’s post, we’re examining ISO 13485:2016 documentation requirements to help manufacturers get organized as they transition to the latest standard version.\nQuality Management System (QMS) Documentation\nTo earn your ISO 13485 certification, you’ll need a documented Quality Management System (QMS) that complies with the standard and all applicable regulatory requirements.\nAside from the documents you will need for your individual jurisdiction, ISO requires you to document elements like:\n- Quality policy and objectives: You’ll need written statements that describe not just your commitment to quality, but also the detailed objectives that will help you reach those goals.\n- Quality manual: Your quality manual should include QMS scope and references to documented quality procedures.\n- Computer software validation procedure: The U.S. Food and Drug Administration (FDA) requires medical device manufacturers to validate any software used in the design, manufacture, packaging, labeling, storage, installation and servicing of finished devices.\n- Quality procedures and records: These need to cover all processes, including procedures for document and record control.\n- Medical device file: This document refers to the device master record as well as its technical documentation.\nDocumenting Management Participation\nOne thing we’re seeing across the board in international standards is an increased focus on management accountability. What are ISO auditors looking for in terms of documenting management participation?\n- Clearly defining roles and responsibilities in your documentation.\n- Maintaining a schedule showing dates of QMS reviews and other planning activities.\n- Keeping records from planning meetings and reviews.\nEmployee Training Records\nManufacturers need a documented Employee Training program that includes steps to determine competence and awareness of team members. You’ll need records and other personnel information handy, which is easier with an integrated QMS that can push and pull data from external systems like human resources (HR).\nInfrastructure and Maintenance\nISO 13485 requires documentation of infrastructure requirements needed to ensure quality. A key focus here is documenting standardized maintenance procedures and keeping records of any maintenance work.\nTo address issues of contamination, the standard requires medical device manufacturers to document elements such as:\n- How to prevent environmental conditions from affecting finished product quality.\n- Clothing or hygiene considerations for personnel.\n- Procedures for handling contaminated products.\nClause 7 of ISO 13485, dedicated to product realization, covers a number of documentation requirements. These cover areas that include:\n- Customer requirements review process and results.\n- Procedures for communicating with customers.\n- Design and development files, procedures, plans and outputs.\n- Verification of materials and outsourced products.\n- Calibration and installation records.\n- Computer validation records.\nMedical device manufacturers typically work with a number of suppliers and contract manufacturers. Given the level of risk that suppliers can introduce to products, ISO 13485 includes requirements to proactively address supplier quality.\nThe standard specifically calls out written supplier quality agreements as a required. Supplier quality agreements are also a best practice recommended by the FDA, helping establish formal requirements for product specifications and supplier practices.\nDocumenting Measurement and Monitoring\nMonitoring and analysis are central to the ISO approach, and this standard is no different. Clause 8 of ISO 13485 delves into a wide range of monitoring requirements, requiring documentation and records of processes like:\n- Complaint Handling and customer feedback.\n- Regulatory reporting.\n- Internal audits.\n- Nonconforming product.\n- Corrective and preventive action.\nHow Automation Helps with ISO 13485 Documentation\nDocumentation is critical to achieving ISO 13485 certification. If you’re still using paper and spreadsheets, it can be a fairly complicated and time-consuming process to track down everything you need.\nConversely, automated Quality Management Software centralizes your documents, allowing you to apply best practices in documenting and recording critical processes addressed by the standard. These tools include:\n- Document Control to centralize documents and ensure a smooth change process.\n- Employee Training tracking tools to make sure all staff members have the necessary competence and awareness.\n- Audit Management capabilities to help you verify that documented procedures are followed.\n- Centralized Reporting tools to make sense of all the data and get a high-level picture of risk (not to mention easily access data at an auditor’s request).\n- Corrective and Preventive Action (CAPA) tracking to manage problems more efficiently and trigger any necessary changes to documents, procedures or quality requirements.\nWhen you get down to it, the documents are the foundation of everything you do in medical device manufacturing. They’re also just the beginning of the journey, providing a starting place for ensuring quality and safety while continuously improving your process over time.","What Is ISO 14001:2015 – Environmental Management Systems?\nISO 14001 on ASQTV™\nISO 14001 is the international standard that specifies requirements for an effective environmental management system (EMS). It provides a framework that an organization can follow, rather than establishing environmental performance requirements.\nPart of the ISO 14000 family of standards on environmental management, ISO 14001 is a voluntary standard that organizations can certify to. Integrating it with other management systems standards, most commonly ISO 9001, can further assist in accomplishing organizational goals.\nThe International Organization for Standardization (ISO) defines an environmental management system as “part of the management system used to manage environmental aspects, fulfill compliance obligations, and address risks and opportunities.” The framework in the ISO 14001 standard can be used within a plan-do-check-act (PDCA) approach to continuous improvement.\n- Who should use the 14001:2015 revision?\n- What are the benefits of ISO 14001?\n- ISO 14001 certification\n- ISO 14000 family of standards\n- ISO 14001 resources\nISO 14001:2015 should be used by any organization that wishes to set up, improve, or maintain an environmental management system to conform with its established environmental policy and requirements. The requirements of the standard can be incorporated into any environmental management system, the extent to which is determined by several factors including the organization’s industry, environmental policy, products and service offerings, and location.\nISO 14001:2015 is relevant to all organizations, regardless of size, location, sector, or industry.\nWhat topics does ISO 14001:2015 cover?\nAt the highest level, ISO 14001:2015 covers the following topics with regard to environmental management systems:\n- Context of the organization\n- Performance evaluation\nISO 14001 Environmental Management Systems (EMS) Framework\n14001:2004 vs. 14001:2015\nThe 2015 revision of ISO 14001 introduces a number of changes from previous versions. A detailed explanation of the changes can be found in this ISO 14001 presentation by the ASQ Energy and Environmental Division.\nAs part of the effort to structure all ISO standards in the same way, the ISO 14001:2015 revisions include incorporating a required high-level structure, using mandatory definitions, and incorporating common standards requirements and clauses.\n10 major areas of impact of the 2015 revision:\n- Expansion in EMS coverage and scope\n- Required interactions with external parties\n- New requirements for leadership engagement\n- Expanded legal compliance requirements\n- Need for risk-based planning and controls\n- New documentation requirements\n- Expanded operational control requirements\n- Changes in competence and awareness requirements\n- Impacts on the internal audit program\n- Increased certification costs\nIntegrating ISO 9001 and ISO 14001\nResponsibilities for the combined standards might include:\n- Drafting a policy statement and quantifiable objectives\n- Setting up organizational charts and job descriptions\n- Providing adequate resources\n- Managing documentation for both standards in a single document control system\n- Appointing a management representative as well as coordinators for the quality and environmental managements systems\nWhen adding ISO 14001 components to those of ISO 9001, planning must be expanded to deal with environmental impacts, and the inspection and test systems modified to cover environmental conformance. The organization must meet the environmental expectations of customers and the government, and it must incorporate environmental management elements into internal audit programs and training sessions.\nISO 14001 can be integrated with standards besides ISO 9001 in order to provide synergy with other systems, such as OHSAS 18001 and ISO 13485.\nUsing ISO 14001:2015 has many benefits for organizations with environmental management systems. Organizations and companies find that using the standard helps them:\n- Improve resource efficiency\n- Reduce waste\n- Drive down costs\n- Provide assurance that environmental impact is being measured\n- Gain competitive advantage in supply chain design\n- Increase new business opportunities\n- Meet legal obligations\n- Increase stakeholder and customer trust\n- Improve overall environmental impact\n- Manage environmental obligations with consistency\nOrganizations that have already achieved ISO 14001 certification are encouraged to transition to the 2015 version. Organizations will have a three-year transition period to update their environmental management systems to the new standard.\nTo get started with ISO 14001:2015:\n- Review existing quality management system requirements (ISO 9001:2015)\n- Purchase ISO 14001:2015\n- Get ISO 14001 training\n- Certify to ISO 14001\nISO 14001 is the most popular standard of the ISO 14000 family, which also includes standards such as the following:\n- ISO 14004:2016 - Environmental Management Systems - General Guidelines On Implementation\n- ISO 14006:2011 - Environmental Management Systems - Guidelines For Incorporating Ecodesign\n- ISO 14015:2001 - Environmental Management - Environmental Assessment Of Sites And Organizations (EASO)\n- ISO 14020:2000 - Environmental Labels And Declarations - General Principles\n- ISO 14031:2013 - Environmental Management - Environmental Performance Evaluation - Guidelines\n- ISO 14040:2006 - Environmental Management - Life Cycle Assessment - Principles And Framework\n- ISO 14050:2009 - Environmental Management - Vocabulary\n- ISO 14063:2006 - Environmental Management - Environmental Communication - Guidelines And Examples\n- ISO 14064-1:2018 - Greenhouse Gases Part 1\n- ISO 19011:2018 - Guidelines For Auditing Management Systems\nArticles and Case Studies\nISO 14001 Standard: Literature Review And Theory-Based Research Agenda (Quality Management Journal) Environmental sustainability has gained momentum in the business world and academia. After about 20 years of research in this field, this paper presents a holistic literature review specifically focused on ISO 14001, which is widely considered the most important environmental certification.\nStewardship And Sustainability: Serigraph's Journey To ISO 14001 (Journal for Quality and Participation) Leaders of Serigraph understand that sustainability and social responsibility require the simultaneous promotion of equitable economic growth, environmental protection, and social well-being. Serigraph uses ISO 14001, Six Sigma, and lean as its templates for environmental and sustainability improvement.\nA Framework For The Development Of An Environmental Management System: A Case Study In A Thermal Power Plant (Quality Engineering) Questions regarding implementation of ISO 14001 prompted NP Power, the electric power company of New Brunswick, Canada, to develop a framework to assess its compliance to the standards."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:d2ce6a82-2649-4768-b54d-8fb2a11be355>","<urn:uuid:8b228415-8471-4596-8694-cc54b2c84a94>"],"error":null}
{"question":"What is the relationship between human freedom and development, and how does this connect to environmental responsibility?","answer":"Freedom is fundamental for human development, as documented by Amartya Sen, but development requires human effort and responsibility. While freedom enables people to develop their capabilities, it must be balanced with environmental responsibility and solidarity. This relationship extends to ecological concerns, as humans need to transition from being purely economic beings (Homo economicus) to becoming ecologically responsible (Homo ecologicus). The connection between freedom and environmental responsibility is reflected in how sustainable development must promote integral human development while ensuring responsible stewardship of natural resources. This balance is essential because abusing environmental freedom ultimately compromises human development possibilities for present and future generations.","context":["The almost fifty years that separate Humanae Vitae (“HV”) (1968) and Laudato Si’ (“LS”) (2015) have seen great changes take place in the planet’s structure, and great transformations in the balance among different cultures. The dynamics of globalization have led to much sharper confrontations among human groups that are characterized by their different cultures, which already had seen considerable internal evolution. However, the issues concerning human life and the specific issues dealt with by HumanaeVitae have not lost their relevance.\nFrom the sense of generation to the “sacredness” of life\nIn the framework of the many theological, and especially theological-moral, questions that in these past fifty years have been raised about Humanae Vitae, I would first like to consider what I believe to be the most important affirmation in this Encyclical, its wisest and most valuable theological and anthropological legacy, namely, the “unbreakable bond” (HV 12) between marital unity and the passing on of life. The phrase has its origin in the earlier Section 9 of the document where Paul VI lists the four principal “characteristics” and requirements of marital love: 1) It is “thoroughly human,” that is, both sensual and spiritual. 2) It is “total”; it is “a special form of personal friendship” where husband and wife share everything generously and love each other for the other’s sake and not for personal gain. 3) It is “faithful and exclusive until death.” 4) Lastly, it is “fruitful.” With this last characteristic, Paul VI reconciled the age-old question of the relationship between the purposes of marriage: the “primary” end (the prolis generatio et educatio) and the “secondary” end (mutuum adiutorium e remedium concupiscentiae). Pope Paulaffirms that it is equally ordered to the personal communion between husband and wife and to the bringing forth of new lives. This seems to me the first, essential, “conquest” of the encyclical of Paul VI—a prophetic lesson in human wisdom, which we can not and must not forget.\nWe have to remember that in the late 60s the Pope foresaw a difficulty and an objection that at that time was barely perceived, but that today has doubtless become radicalized and even extremely so—namely, the separation between marital love and the passing on of life. In today’s culture, both in individual lives and in the media, sex is viewed ambiguously. On the one hand, it is considered indispensable for happiness. On the other hand, it seems unable to provide the deep satisfaction that individuals hope to derive from it. Seeing this, we have to ask ourselves whether this ambiguity is not the result of an incomplete understanding of the relationship between sexuality and the other dimensions of humanity and of relationships.\nAnother aspect of this ambiguity is that we are no longer sure that a child has any right to be brought into the world within a loving relationship between a man and a woman, or even within a relationship that is stable and socially established and recognized—a family. Here we touch something central to the Christian faith. The reality of generation introduces us into the mystery of our Trinitarian God, Himself, in which the generation by the Father has its counterpart in the being generated that is proper to the Son, and the bond between Father and Son results in the being they share in and with the Spirit. Thus revelation shows that the love that leads to happiness cannot be lived except by “making” the other in a circle of life that is accessible to the human creature, and in which he or she can participate responsibly. The entry of God into the passing on of human life with His Incarnation (in the womb of a Woman) opens up a vision which, incorporating history, with all its contradictions, through a structure of agape, arrives at the Resurrection.\nOnly in this broader framework can we understand what is meant by the “sacredness” of life. Only within the framework of our supernatural calling can we understand the greatness and the preciousness of human life, earthly as well as eternal, as St. John Paul II writes Section 2 of his Encyclical Letter, Evangelium Vitae, where he points out that “… it is precisely this supernatural calling which highlights the incomplete character of each individual’s earthly life. After all, life on earth is not an “ultimate” but a “penultimate” reality; even so, it remains a sacred reality entrusted to us, to be preserved with a sense of responsibility and brought to perfection in love and in the gift of ourselves to God and to our brothers and sisters.” Each one of us is therefore called to live his or her life as a gift, close to God and our brothers and sisters. In Section 47 of the Encyclical, the Pope writes: “…the life of the body in its earthly state is not an absolute good for the believer, especially as he may be asked to give up his life for a greater good. As Jesus says: ‘Whoever would save his life will lose it; and whoever loses his life for my sake and the gospel’s will save it.’ (Mk 8:35). The New Testament gives many different examples of this…John the Baptist, precursor of the Savior testifies that earthly existence is not an absolute good; what is more important is remaining faithful to the word of the Lord even at the risk of one’s life (cf. Mk 6:17-29). Stephen, losing his earthly life because of his faithful witness to the Lord’s Resurrection, follows in the Master’s footsteps and meets those who are stoning him with words of forgiveness (cf. Acts 7:59-60), thus becoming the first of a countless host of martyrs whom the Church has venerated since the very beginning. No one, however, can arbitrarily choose whether to live or die; the absolute master of such a decision is the Creator alone, in whom ‘we live and move and have our being.’” (Acts 17:28)\nFrom Humanae Vitae to Laudato Si’.\nThe question of the passing on of life is a kind of crossroads, a meeting place not only of the lives of individuals and families but also of all of society. The connection that Blessed Paul VI himself made between Humanae Vitae and Populorum Progressio lets us take a further step toward Laudato Si’. We realize that the entire planet, even allowing for significant differences on the different continents, is aging. And those societies that have fewer children appear more affected by a decline that is not only material but also spiritual. Laudato Si’ highlights how the land is not ungenerous, but rather that our stewardship of it is not fair. Human groupings are strongly tempted to focus on their own interests, culturally inclined as they are to reproduce themselves as individuals rather than to build communities. If self-fulfillment is emphasized, sterility increases. Laudato Si’ shows us how, if we allow ourselves to be enlightened by the generative mystery of God who reveals Himself in the reality of the Son made man in Mary’s womb, the Church is called to restore confidence to a world that struggles to pass on the meaning of “coming into the world.” But it also offers other insights that invite us to understand human life as we live it in our common home, respecting the notion of integral ecology. This integrated perspective helps us see the interconnectedness of various aspects of life that we often look at separately and thus limit the horizons of our thinking. Integral ecology allows us to develop a clearer and more convincing (and perhaps even more shareable) understanding of some groups that we are committed to as we defend and promote human life at every stage, especially those that are weaker and more threatened.\nI would now like to offer some brief reflections on the meaning of “dignity of the person,” the subject of your meeting this morning. We know that the notion of dignity is in one that is important to everyone. In general, reference is made to the Preamble of the Declaration of Human Rights and of the Citizen of 1948, which states: “the recognition of the inherent dignity of all members of the human family and their equal and inalienable rights constitutes the foundation of freedom, justice and peace in the world.” And Article 1 reaffirms: “All human beings are born free and equal in dignity and rights.” It is also repeatedly invoked in the UNESCO Universal Declaration on Bioethics and Human Rights (2005). The notion of dignity, however, remains imprecise, and is not able to furnish definitive interpretations of individual situations, especially in the area of bioethics. The diversity of interpretations also stems from the diversity of cultural horizons. These can be grouped in the West into three main currents: the Judeo-Christian tradition, Kantian-inspired ethics, and the more recent anthropology of (late) modernity.\n- The Judeo-Christian Tradition. Although the Judeo-Christian tradition has known different emphases and nuances over the centuries and has reacted to varying cultural contexts, it has shown remarkable consistency about the central elements of dignity. As emphasized by the Second Vatican Council (in particular Gaudium et Spes, Sections 12-22), the Christian vision of dignity is based on the biblical witness, amply confirmed by patristic tradition, according to which man is created “in the image and likeness of God.” Although sin disfigures this image, it is restored by the grace and the salvation that Jesus Christ offers to humanity. This applies to every man and every woman. In this sense, dignity is another name for each of us being a child of God. Dignity does not depend on factors such as behavior or the particular abilities of an individual, but only on the fact of being children of God, created in his image and likeness. To this, Jesus adds that the poor—those who are cast aside because they have no dignity—represent God on earth. They are his sacrament.\nThe Kantian Change of Direction. In his Groundwork of the Metaphysic of Morals, at the end of its Second Formulation, Kant presented a proposition that was to have a huge following in Western civilization. He states that the condition that makes something an end in itself, and to which it is impossible to attribute a price, is dignity, which is intrinsic to the person. Dignity cannot be given an economic value. It has no graduations, nor is it divisible. Everyone must be accorded the same dignity, and likewise must recognize it in others. Kant bases this dignity on the moral law that everyone finds within himself. In a certain sense, therefore, he “secularizes” what in the Christian tradition is dependent on man’s relationship with God. In that context, we can see that the Constitution Gaudium et Spes, speaking in Section 16 about the conscience as a place where mankind finds a law which it does not impose upon itself, but rather is written by God, forges a solid bond between the Christian and the Kantian perspectives.\n- Modernity. We are seeing today the emergence of both subjectivity and relationality—dignity being linked to both the judgment of others and to one’s own belief about him or herself. We therefore speak now about the perception of one’s own dignity rather than about its ontological dimension, which, obviously, must not be lost. In Aristotelian terms, it can be said that dignity that is not recognized by others is potential and not yet actual. That’s why a believing doctor’s friendly face is an important encouragement for patients who needs a little comfort and a little less anxiety when faced with doubts about their dignity because of their weakness and dependency. It is essential to support positive interaction between doctors and patients, especially in highly debilitating circumstances or when death is imminent. For me, this kind of relationality is essential to dignity.\nThe three aspects of dignity.\nThere are three different lines of though underlying the notion of dignity, and they furnish valuable insights into the meaning of the term. I welcome the words of a secular French philosopher, Luc Ferry, who says: “…the very idea that a human being can ‘lose his dignity’ because he has become weak, sick, old and therefore in a situation of dependency it is an intolerable idea on an ethical level, and is redolent of the deathly policies of the 1930s.” And the observations of an Italian writer, Lucio Magris, an attentive scholar of contemporary culture, on the question of dignity in the context of euthanasia offer food for thought: “Proposed in the name of mercy and human dignity, euthanasia can easily become a shameful, even if unwitting, societal cleansing—an exercise of the arbitrariness of those who, in the name of the quality of life, affirm that below a certain level, life is no longer worthy of being lived, and who give themselves the right to establish the level that authorizes the elimination of those who do not possess that level. Doubtless, for many of the millions of frighteningly malnourished children who, even in their scandalous circumstances, are often abused psychologically and physically, death would be a lesser evil than the terrible life that awaits them, but it is doubtful that this authorizes their elimination.”\nThere is a wise and but somber text from the Second Vatican Council that is worth reading and that will encourage each of us to consider “the other” as another “self”: “Whatever is opposed to life itself, such as any type of murder, genocide, abortion, euthanasia, or willful self-destruction, whatever violates the integrity of the human person, such as mutilation, torments inflicted on body or mind, attempts to coerce the will itself; whatever insults human dignity, such as subhuman living conditions, arbitrary imprisonment, deportation, slavery, prostitution, the selling of women and children; as well as disgraceful working conditions, where people are treated as mere instruments of gain rather than as free and responsible persons; all these things and others like them are infamies indeed. They poison human society, and they do more harm to those who practice them than to those who suffer from the injury. Moreover, they are a supreme dishonor to the Creator”. (Gaudium et Spes, 27).\nI do not believe there is any question that each person should live and die in a dignified manner. I was moved by the words of a ninety-year-old lady who told me what death with dignity meant for her: “I would like a peaceful death, in my bed, not at the hospital. I would like to have a clear conscience and be at peace with God and everyone I know. I would like people around me to say me a word of love, to give me the strength to die, to caress me with loving and tender gestures. to let me slip into death without forcing me to eat, if I don’t want to. I want to feel life around me, children running, people talking; and if I suffer, I want someone give me what helps me not to suffer. For me, this is death with dignity.” Of course, this kind of death is not something you can legislate. Really, talking about dignity in dying means promoting a new culture of life and relationships. Dignity is not putting a lethal drug on the night table of someone who is dying; it is not a heart-stopping injection, or a deadly drink, even if the patient requests it. And it is certainly not dignity to ignore the ocean of loneliness and confusion of those who think life is no longer worth living. Such indifference is the bitter confirmation of what torments the dying: to no longer be worth anything to anyone. The Catholic doctor—at least—stays at the bedside and is close to the dying, tries to heal if possible, but never stops caring. This is what Jesus did and this is why in the ancient Church he was called “the Healer.”\nDear friends, true dignity is what the frail, sick person feels when he or she is treated with sensitivity, touch, attention and affectionate, generous accompaniment. Dignity is being recognized as a person, in every condition and situation. Closeness, physical contact—holding hands, a kind word, a caress on the cheek at the last moments of earthly life—confirm to the dying their great dignity and to those who remain they offer a lesson about the meaning of life when life is slipping away. That is why we should oppose the shameful deaths of the millions who die from famine, war, medical neglect, and so on. Pope Francis writes in his most recent Apostolic Exhortation, Gaudete et Exultate: “Our defense of the innocent unborn, for example, needs to be clear, firm and passionate, for at stake is the dignity of a human life, which is always sacred and demands love for each person, regardless of his or her stage of development. Equally sacred, however, are the lives of the poor, those already born, the destitute, the abandoned and the underprivileged, the vulnerable infirm and elderly exposed to covert euthanasia, the victims of human trafficking, new forms of slavery, and every form of rejection.” It would seem to me very opportune to encourage cultural initiatives—like this Conference—together with legislative proposals, that ensure for everyone a dignified healthy life and appropriate health care. In a short essay written by Evangelical Church Christians and Roman Catholics in Germany, and published by Bernhard Vogel under the title “Focus on the Dignity of the Human Being,” it is stated clearly that “dignity is the demanding of respect.” But perhaps rather than “demand” the term “right” should be used. And then the phrase would be: “Dignity is the right to be respected.”\n(Congresso Mondiale dei Medici Cattolici a Zagabria)","Recent issues have dealt with gender equality and clean energy as two necessary ingredients to attain the transition from cosumerism to sustainability. Other ingredients may be necessary, and it is impossible to isolate the combination of ingredients that would be sufficient. However, the ultimate goal of the transition must be made clear, and this goal is integral human development that can be sustained. All other goals, no matter how desirable and how legitimate, are to be pursued to the extent that they support integral human development. The term sustainable human development is defined as\ndevelopment that promotes the integral human development of people today without compromising the integral human development of people tomorrow. This definition is patterned after the Brundtland Report (1987) and Amartya Sen (1999) definitions with additional of emphasis on the integration of the physical and psychological needs of people. Maslow's hierarchy of human needs is used as the basis for \"integrating\" human development. For each level in Maslow's hierarchy, some of the applicable interdisciplinary resources are mentioned and the effort required to use them is assessed, with emphasis on fostering gender equality and clean energy.\nIntegral Human Development\nIntegral human development (IHD) is a concept derived from Catholic social teaching. It entails holistic development of each human person, not in isolation but in solidarity with other people to foster justice and peace. Thus IHD entails holism, solidarity, and peace with justice:\nHolistic: Integral Human Development promotes the good of every person and the whole person; it is economic, social, political,\ncultural, ecological and spiritual. It also promotes the integrity of creation.\nSolidarity: Integral Human Development promotes the rights and responsibilities of each person and of every person to one another.\nJustice and Peace: Integral Human Development promotes a just and peaceful society that respects the dignity of every person.\nIntegral Human Development, Catholic Relief Services, 2008.\nThe concept of integral human development goes back to the emergence of Homo sapiens. It is certainly a biblical concept (Cf. Mark 8:36) rooted in the human vocation to be imago Dei. It encapsulates all dimensions of human well-being. It fully takes into account that humans must live in harmony with the human habitat. It is of course a central theme of Catholic social doctrine, but is by no means restricted to the Catholic ethos.\nDefinition of Sustainable Human Development\nThe Brundtland Report (1987) defines sustainable development as \"a form of development which satisfies the needs of the present generation without compromising the ability of future generations to meet their own needs.\" Even though this was not necessarily the intent of the Brundtland Commission, sustainable development has been narrowly associated with economic development pursuant to meet the material needs of people. In his seminal work, Development as Freedom (1999), Amartya Sen put this misconception to rest by showing that the top priority is to enable people to develop their capabilities to the maximum possible extent. Sen perceives freedom (both physical and psychological) as fundamental for individual and social development.\nrecent presentation about the 2011 Human Development Report (due out November 2011), Eva Jespersen has proposed the following definition of sustainable human development: \"The preservation – and whenever possible expansion – of the substantive freedoms and capabilities of people today while undertaking reasonable efforts to avoid risks that would seriously compromise the capability of future generations to have similar – or greater – freedoms.\" This is a further elaboration of Sen's definition to stress distributive justice, the need to ensure - as much as possible - the freedoms required for further development of human capabilities, and the need for careful analysis of the risks and uncertainties associated with technological development and plans for required substitution of resources. It is a good step forward, both conceptually and analytically. However, it is possible to go even further.\nThe term sustainable human development is defined here as development that promotes the integral human development of each and every human person today without compromising the integral human development of people tomorrow. This definition is patterned after the Brundtland Report (1987) and Amartya Sen (1999) definitions, albeit with additional of emphasis on the integration of the physical, psychological, and spiritual needs of people. People need bread, but they need more than bread. People need respect and esteem, but they still need more. People need freedom to develop their talents and capabilities, but they also need to use freedom and capabilities responsibly. People need to grow in solidarity with others, for it is only in self-giving to others that humans become fully human. This fundamental insight, which is shared by all ethical and religious traditions, must be kept in mind at all times; for sustainability without solidarity is a social impossibility.\n\"The part cannot be well until the whole is well.\" Plato, 428-348 BCE\nMaslow's Hierarchy of Human Needs\nAbraham Maslow (USA, 1908-1970) created the \"hierarchy of human needs\" in the 1940s. Maslow's model explicitly takes into account the physiological, safety, emotional, love/belonging, esteem/self-esteem, and self-actualization stages of integral human development. The hierarchy of human needs is usually represented as a pyramid, with the most basic needs at the bottom and the socialization needs at the top. There are many variations of the pyramid: one is shown to the right and others can be easily found. Going upward, the progression for each human being is to satisfy (1) the basic physical and physiological needs, (2) the need for safety and security, (3) the need psychological well-being, (4) the need for self-actualization (self-esteem, social responsibility), and (5) the need for self-giving to others which, if lived to a heroic degree, leads to people like Francis of Assisi and Teresa of Calcutta. For further discussion of Maslow's \"levels of human development\" - and other models of human development - the reader is referred to the May 2010 issue of Mother Pelican. It is suggested that\nembracing the ethic of solidarity is practically impossible under level 3, and generally requires level 4. What about sustainability?\nOutgrowing Homo economicus and becoming Homo solidarius\nThe ethic of solidarity is basically the ethic of reciprocity. In the Christian tradition, it is also known as the Golden Rule, i.e., \"do to others whatever you would like them to do to you\" (Matthew 7:12, Luke 6:31). The ethical concept of solidarity in modern economics started with the publication of Ethics and the National Economy (Heinrich Pesch SJ, 1918). Outgrowing Homo economicus, and becoming Homo solidarius, basically entails applying the Golden Rule to economic decision-making. In one form or another, the Golden Rule is recognized as a basic norm of human behavior in\nmost religious traditions. It is, however, seldom practiced in today's economic world of neo-liberal capitalism. Homo economicus must become Homo solidarius. People must adapt to the ethic of solidarity. Institutions must adapt to the same ethic. It is hard for people to change as long as institutions don't change, and institutions don't change because people don't change. This is the vicious cycle that must be broken.\n\"Do to others|\nyou would like them\nto do to you.\"\nMatthew 7:12, Luke 6:31\nSee also Luke 10:30-37\nOutgrowing Homo economicus and becoming Homo ecologicus\nAn ethic of solidarity is also needed in the relationship between humanity and the human habitat. Actually, taking good care of the planet is but one application of the ethic of solidarity; for abusing the planet eventually leads to harming people. This has been so the emergence of Homo sapiens (Genesis 2:15), and remains true today; except that today the harm done to people is more observable in terms of health and climate change impacts. Therefore, becoming Homo solidarius and becoming Homo ecologicus is one and the same process. Human solidarity is meaningless if it excludes taking good care of the very natural resources that are indispensable for human survival. Another term for Homo ecologicus is Homo sustinens, i.e., humans capable to living in a sustainable manner. Again, people must adapt to the ethic of sustainability, and institutions must adapt to the same ethic. Else, the vicious cycle of extravagant consumerism and resource exploitation will lead to an increasingly unsustainable outlook for human civilization.\n\"Is it not enough for you|\nto feed on the good pasture?\nMust you also trample the rest\nof your pasture with your feet?\nIs it not enough for you\nto drink clear water?\nMust you also muddy\nthe rest with your feet?\"\nDimensions of Sustainable Human Development\nTwo dimensions of sustainable human development are crucial going forward: gender equality and clean energy. Gender equality is crucial because it is the most universal form of human solidarity. As long as cross-gender solidarity is lacking, how can we expect any other form of solidarity to be sustainable? Clean energy is critical because the environmental predicament confronting humanity is fueled by the burning of fossil fuels. As long as we keep abusing the planet, how can we expect any level of human development to be sustainable?\nTransition from Gender Inequality to Gender Equality\nIt is hard to imagine sustainability without solidarity, and it is hard to imagine sustainable solidarity without gender equality:\nAs Amartya Sen has pointed out, \"development that is not engendered in endangered.\" The wisdom of this statement is confirmed in the World Health Organization's Getting to grips with gender inequality and many other analyses and reports, notably the United Nations' Human Development Reports and Human Development Index.\nTransition from Fossil Fuels to Clean Energy\nThe following time frame was initially offered for consideration in the June 2011 issue of this journal, and has been further refined as follows:\nNote: The following acronyms, and terminology are used in this transition concept and subsequent discussion:\nA brief synopsis of this transition concept is provided below. For further energy transition analysis click here.\nFinancial Transaction Tax (FTT)|\nGlobal Citizens Movement (GCM)\nHuman Development (HD)\nHuman Development Index (HDI)\nHuman Development Report (HDR)\nIntegral Human Development (IHD)\nLand Value Tax (LVT) or Resource Value Tax (RVT)\nMaslow's Hierarchy of Human Needs (MASLOW)|\nNon-Governmental Organization (NGO)\nPrinciple of Solidarity (SOLIDARITY)\nPrinciple of Subsidiarity (SUBSIDIARITY)\nPrinciple of Sustainability (SUSTAINABILITY)\nSustainable Development (SD)\nSustainable Human Development (SHD)\nThere are four phases in this transition concept:\n- The first phase (2011-2020) is concientization to enable incentivation. The objective is to create widespread popular support for the required revisions of tax codes and energy subsidies. In other words, the first phase is about creating a collective mindset of social responsibility. The global citizens movement has received new impetus with the recently launched Widening Circles initiative. The new ISO 26000 guidelines on social responsibility can also be instrumental in fostering a mindset of solidarity and sustainability in business and government.\n- The second phase (2021-2030) is incentivation to enable redistribution. The objective is to reform tax codes and energy subsidies to expedite the transition to clean energy. Applicable reforms include shifting taxes from earned income to unearned resources (via \"Land Value Taxes\" or, more generally, \"Resource Value Taxes\") and taxing financial transactions of dubious social value (via \"Financial Transaction Taxes\"). These resource usage revenues and financial transaction revenues should be set high enough to yield a surplus after public services and clean energy subsidies. This surplus should then be distributed to all citizens via a guaranteed basic income (next phase).\n- The third phase (2031-2040) is redistribution to enable democratization. The objective is to institutionalize democracy with distributive justice. Applicable reforms include adopting a Universally Guaranteed Personal Income (i.e., a basic minimum income rather than a minimum wage) and a Maximum Allowable Personal Wealth (i.e., an upper limit on financial wealth accumulation) that can be adjusted periodically. This democratic reform is required to reverse the unsustainably widening rich-poor gap but should not be confused with state socialism. Minimum income and maximum wealth thresholds are to be used as checks and balances against both left-wing and right-wing extremism.\n- The fourth phase (2041-2050) is democratization with widely institutionalized solidarity, sustainability, and subsidiarity. The principle of subsidiarity has already been included in the constitution of the European Union. It prescribes decisions to be made at the lowest possible level consistent with governance capabilities and the common good of the global commonwealth. In other words, a world government would only act (i.e. make laws) if, and only if, any possible action by individual countries is insufficient. Keeping the peace between nations, and formulating laws pursuant to the ecological integrity of the planet, are the two areas where some form of democratic global governance is required. Global problems require global solutions. National problems require national solutions. Local problems require local solutions. There may be regional problems that require regional solutions.\nThese four phases are further analyzed in the Status of the Transition to Clean Energy supplement (still work in progress). The four phases are sequential to some extent, but overlaps and iterations are to be\nexpected. Clearly, the concientization phase should start immediately but will have to be sustained indefinitely. It is hard to envision the incentivation and redistribution phases happening sequentially. Only God knows if a global democracy can be achieved by 2050, but we must try. The biggest temptation, for nations as well as individuals, is to succumb to cynical pessimism.\nHuman Development is not Free\nFreedom is required for human development, but human development is not free. Experience confirms that human capabilities tend to decrease in dictatorial states. But even under total freedom, human development takes human effort and integral human development even more so. The era of \"externalities\" (\"free\" natural resources) is rapidly coming to an end, and so is the era of extravagant energy consumption at a low cost. It will not be simply a matter of working longer hours and postponing retirement until age 75, although some such adjustments may become necessary. What is bound to increase is the investment in mental and emotional effort, because people will need to adapt their ways of thinking and behaving to changing conditions. In making decisions they may be compelled to think about the common good and act accordingly. The consequent inner conflicts may in turn induce many to undertake the inner journey earlier in life. This is more difficult than simply running around in pursuit of material gratifications, for it requires overcoming fear: \"It takes more courage to dig deep into the dark corners of one's own soul than it does for a soldier to fight on the battlefield.\" (William Butler Yates, Ireland, 1865-1939)"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"}],"document_ids":["<urn:uuid:c55ad993-d088-4fad-a4bb-a861ffdbb6e7>","<urn:uuid:499bb0da-c4a7-44e2-bdbf-fcbc54ed40ea>"],"error":null}
{"question":"I want to learn about path planning - what is the difference between the local costmap and global costmap in AI Habitat vs ROS navigation?","answer":"In ROS navigation, there is a clear distinction between local and global costmaps - the global costmap is used for long-term planning over the entire environment while the local costmap is for short-term planning and obstacle avoidance. The costmaps store information about obstacles and are configured through separate parameter files. In contrast, AI Habitat uses a single NavMesh mechanism to handle collision constraints during navigation, which can be loaded for a scene or recomputed at runtime to let agents take actions within navigable areas. Both systems aim to enable safe navigation but use different approaches to represent and handle obstacles in the environment.","context":["How to Train Your [Dragon] Embodied Agent (with AI Habitat)\nECCV 2020 Tutorial\nSunday, 23rd Augst\nThere has been a recent shift in the computer vision community from tasks focusing on internet images to active settings involving embodied agents that perceive and act within 3D environments. Practical deployment of AI agents in the real world requires study of active perception and coupling of perception with control as in embodied agents.\nIn this tutorial, we will demonstrate how to utilize the Habitat platform to train embodied agents to perform a variety of tasks in complex and photo-realistic environments.\n|Introduction to AI Habitat||Video|\n|Navigation in Habitat||Video|\n|Habitat-Sim Basics for Navigation||Video||Colab|\n|Habitat-Lab for Navigation||Video||Colab|\n|Habitat-Sim for Interaction||Video||Colab|\n|Habitat-Sim Advanced Topics||Video||Colab|\n|Habitat-Lab for Interaction||Video||Colab|\n|Faster RL Training: Profiling and Optimization||Video||Colab|\nWelcome and introduction In this section, we will first cover the scientific motivation for embodied AI. We will cover the design philosophy and architecture of AI Habitat, to help potential users and researchers understand how AI Habitat views training virtual robots in simulated environments.\nTask: Navigation in Habitat In this session we discuss, at a high level, training agents to perform navigation tasks (i.e. ‘Go to the bedroom’) in AI Habitat. Specifically, we discuss the task of PointGoal Navigation (i.e. go 5 meters forward and 2 meters to the left) and explain the embodiment of the agent, the deep neural network used to control it, how to frame the task as a reinforcement learning problem, and where Habitat-Sim and Habitat-Lab are used to train this agent with deep reinforcement learning.\nHabitat-Sim Basics for Navigation Habitat-sim is a highly efficient, photorealistic 3D simulator for embodied agents operating in the virtual environments. This tutorial helps you to learn our simulator for navigation through a series of coding examples. It demonstrates how to load a scene, set and configure an agent, as well as its sensors (e.g., color, semantic, and depth sensors), instruct the agent to navigate and obtain the observations. It also introduces the NavMesh, an efficient mechanism to handle the collision constraints during the navigation. It teaches you how to load a NavMesh for the scene, recompute it at runtime, and let the agent take actions within the NavMesh.\nHabitat-Lab for Navigation In this section we discuss how Habitat-Lab is used in defining embodied AI navigation tasks, evaluating agents, and training agents.\nHabitat-Challenge In this section, we provide an overview of the Habitat Challenge – an AI challenge where participants upload agents to be evaluated in unseen environments.\nHabitat-Sim for Interaction Habitat-sim is interactive! Users can now add new objects to a static background scene, set object states, run dynamics simulation, and more with ease through the Simulator API. This use-case driven tutorial covers interactivity in Habitat-sim. Topics such as adding objects to a scene, kinematic object manipulation, dynamics simulation, collision checking, and configurable navigation constraints will be covered. We will demonstrate a number of example applications, including: generating data for physical reasoning tasks, adding objects to the scene via rejection sampling on the NavMesh, and an embodied object fetch task.\nHabitat-Sim Advanced Topics Expanding on the Habitat-Sim Basics and Interaction tutorials, this tutorial will cover some advanced topics for making the most of the Habitat-sim API. In addition to a detailed discussion of the object construction via attributes templates and the template libraries, we will demonstrate: tracking objects with a motion following camera, retrieving and displaying 2D projections of 3D points, and programmatically configuring semantic ids for objects and scene nodes.\nHabitat-Lab for Interaction In this tutorial, we will look at how to setup an interaction task in Habitat Lab. We’ll cover key components using the task of furniture rearrangement as an example. We will walk through how to create, store and load objects into the simulator; define new action spaces such as a magic pointer action for grabbing / releasing objects; extend the observation space to include information about the objects and create reward functions for training RL agents. Finally we will train an RL agent to solve a single episode of this task. After going through this tutorial, one should be able to utilize all the interactive features of the Habitat Simulator and expose them through Habitat Lab in the form of observations, new action spaces, measurements and reward.\nFaster RL Training: Profiling and Optimization Why focus on performance optimization for RL training? The goal is higher framerates. A higher framerate lets us scale our training to more steps, and it lets us iterate faster on our day-to-day experiments. In this short, accessible tutorial, we’ll profile and optimize an example program in real time in a Colab notebook. We’ll use one of Habitat’s PointGoal navigation baselines as our example program, but the lessons here can be applied to any RL training. We’ll walk through the process of capturing a profile, identifying candidates for optimizations, making improvements to our code, and evaluating speedup. We’ll try some profiling tools including py-spy, speedscope, and Nsight Systems. We’ll use a multithreaded trace to identify GPU-bound scenarios and opportunities for better parallelism.","Once the quadrotor can reliably and stably navigate the environment based on a series of desired waypoints, the quadrotor system can be used to sense and comprehend it’s surrounding environment. A map is a representation of the environment where the quadrotor is operating. To operate in the map, the quadrotor needs to know its position in the map coordinate frame. Ultimately, the goal is to develop a system that allows the quadrotor to autonomously reach a desired goal state in the map. The path from the initial state to the goal state can be a series of waypoints or actions, if a path exists.\nA perfect estimate of the quadrotor’s pose needed to map creation is typically not available, especially in indoor environments. Simultaneous Localization and Mapping is the process of both making and updating a map of the environment while also estimating the system’s location in that map. This map can be saved and used later for localization and navigation without the need to rebuild the map. Typically, lasers are used to create two dimensional maps based on range measurements. However, these are often too large in size and mass or power intensive for use on small quadrotors. Instead, a RGBD sensor is used as the primary means of measuring the environment. This sensor, a Microsoft Kinect, contains stereo cameras as well as a depth sensor. The Kinect outputs point clouds which can be used by the SLAM algorithms to build the map of the environment. It is also possible to use these point clouds to emulate a 2D laser scan output.\nIn an ideal world, the map accurately reflects the environment, the environment is stable, and the localized estimate of the quadrotor’s pose in that map is accurate. However, in the real world, the environment is dynamic and sensor measurements are noisy. Therefore, obstacle avoidance and detection systems are developed as methods of continually updating the map. The ROS Navigation Stack combines all of these requirements into a complete sense-plan-act system.\nThe Navigation Stack\nThe ROS Navigation Stack is a 2D navigation stack that takes in information from odometry, sensor streams, and a goal pose and outputs safe velocity commands that are sent to a mobile base. The Navigation Stack will rely on the map_server package for the 2D map, the amcl package for localization in that map, sensor and odometry messages from the quadrotor, and the move_base packages to fuse all the messages in order to output a desired velocity command. This integration can be visualized below.\nThe Navigation Stack needs to be configured for the shape and dynamics of a robot to perform at a high level and there are several pre-requisites for navigation stack use.\n- The navigation stack can only handle a differential drive and holonomic-wheeled robots. It assumes that the mobile base is controlled by sending desired velocity commands to achieve in the form of: x velocity, y velocity, theta velocity.\n- The shape of the robot must either be a square or a rectangle. The Navigation Stack was developed on a square robot, so its performance will be best on robots that are nearly square or circular.\n- The robot have a tf transform tree in place so that the robot publishes information about the relationships between the positions of all the joints and sensors.\n- It requires a planar laser mounted somewhere on the mobile base. This laser is used for map building and localization. The robot must publish sensor data using the correct ROS Message types.\nConstructing a Mapping Environment\nFor simulating this application, the original 3DR Kit C Gazebo model was modified to include a Kinect sensor mounted on the front arm of the quadrotor. Additionally, the WillowGarage world was loaded to provide an indoor environment suitable to mapping. The WillowGarage world and RGB output of the Kinect sensor can be seen in the Gazebo screenshot below.\nDeveloping the 2D Map\nIn order to make an initial map of the environment, a series of waypoints was recorded. These waypoints maneuvered the quadrotor from its initial position outside the office complex, in and around several rooms, and returning back to the initial position. This resulted in a repeatable path with enough sensor coverage to support the development of the environment map.\nIn order to create the occupancy grid map to be used for future path planning, the Kinect sensor output was modified to appear like a laser scan output. The Kinect sensor provides depth information in a 3-dimensional point cloud. However, for 2D mapping, all that is necessary is a series of depth images at a single altitude. This reduces computation costs and makes navigating basic environments much simpler. In order to do this, the depthimage_to_laserscan package was used. This packages reduces computation even further by using the disparity image instead of the complete point cloud. The node takes the Kinect sensor’s disparity image input and needs to Kinect’s coordinate frame to correctly output the laser scan data. This node outputs a LaserScan message that can be used to build the 2D occupancy grid map.\nTo launch this package in the WillowGarag world with the appropriate control nodes, the quad_slam_laser_map.launch file was used. The depthimage_to_laserscan node portion of the launch file is reproduced below. This depicts several of the variables that were set for this implementation of the depthimage_to_laserscan node. Specifically, the coordinate frame of the sensor is set as well as the input point cloud topic name and desired output laserscan topic name.\n<!-- Fake laser --> <node pkg=\"nodelet\" type=\"nodelet\" name=\"laserscan_nodelet_manager\" args=\"manager\"/> <node pkg=\"nodelet\" type=\"nodelet\" name=\"depthimage_to_laserscan\" args=\"load depthimage_to_laserscan/DepthImageToLaserScanNodelet laserscan_nodelet_manager\"> <param name=\"scan_height\" value=\"10\"/> <param name=\"scan_time\" value=\"0.033\"/> <param name=\"range_min\" value=\"0.45\"/> <param name=\"range_max\" value=\"10.0\"/> <param name=\"min_height\" value=\".10\"/> <param name=\"max_height\" value=\"2.0\"/> <param name=\"output_frame_id\" value=\"quad/camera__link\"/> <remap from=\"image\" to=\"/quad/camera_/depth/disparity\"/> <remap from=\"/scan\" to=\"/sim_scan\"/> </node>\nThe image below depicts a sample laser scan measurement overlaid on top of the point cloud that it was sampled from.\nNext, OpenSlam’s Gmapping algorithm was used to create the 2D map. The gmapping package contains a ROS wrapper for the Gmapping algorithm that provides laser-based SLAM. The node subscribes to the laser scan message and outputs a map in the form of a OccupancyGrid message. The gmapping node portion of the launch file is reproduced below. Note that we remapped the laserscan input to the output of the depthimage_to_laserscan node. The odometry frame value is also explicitly set.\n<!-- Run OpenSlam's Gmapping to create 2-D Occupancy Grid Map --> <node name=\"slam_gmapping\" pkg=\"gmapping\" type=\"slam_gmapping\"> <remap from=\"scan\" to=\"/sim_scan\"/> <param name=\"odom_frame\" value=\"world\"/> </node>\nOnce the environment has been sufficiently mapped, the map can be saved for later use. Specifically, the map can be used to support localization and future path planning algorithms. The map_server node is used to save dynamically generated maps to a pair of files. A YAML file describes the map meta-data, and names the image file. The image file encodes the occupancy data. The map is saved using the map_saver utility using the example code below.\nrosrun map_server map_saver -f mymap\nThe final map of the WillowGarage environment is depicted below.\n2D Localization Utilizing the Map\nIn order to localize in the environment, a previously recorded map is loaded with the map_server node. This node reads a map from disk and offers it via a ROS service. The current implementation of the map_server converts color values in the map image data into ternary occupancy values: free (0), occupied (100), and unknown (-1). The map is available on the map topic as a OccupancyGrid message. This node is initialized with the following excerpt from the quad_2dnav.launch file and loads the map file previously generated for the WillowGarage environment.\n<!-- Load a Map --> <node name=\"map_server\" pkg=\"map_server\" type=\"map_server\" args=\" $(find quad_2dnav)/maps/wg_map.yaml\" />\nThe amcl (adaptive Monte Carlo localization) package is a probabilistic localization system for a robot moving in 2D. This approach uses a particle filter to track the pose of a robot against a known map. As currently implemented, this node works only with laser scans and laser maps. The amcl node takes in a laser-based map, laser scans, and transform messages, and outputs pose estimates. The amcl node has many configuration options that can affect the performance of localization. A description of these parameters can be viewed here. These parameters are set in the amcl_quad.launch file. Portions of that file are reproduced below. Specifically, the input laserscan topic name is set as well as the coordinate frames for the quadrotor, world, and frame.\n<node pkg=\"amcl\" type=\"amcl\" name=\"amcl\"> <remap from=\"/scan\" to=\"/sim_scan\"/> <!-- Publish scans from best pose at a max of 10 Hz --> <param name=\"odom_model_type\" value=\"omni\"/> <param name=\"odom_frame_id\" value=\"world\"/> <param name=\"base_frame_id\" value=\"base_link\" /> <param name=\"global_frame_id\" value=\"map\" /> </node>\nWhen the node is created, it initializes its particle filter according to the parameters provided. If no parameters are set, the initial filter state will be a moderately sized particle cloud centered around the origin. It is possible to set the initial position in RVIZ using the 2D Pose Estimate button. Alternatively, the initial x, y, and yaw can be set in the launch file. The particle cloud can be viewed as a Pose Array in RVIZ. The particle cloud (a series of red arrows) will converge around the current localized posed of the quadrotor. As the quadrotor maneuvers in the environment, the amcl node will use the laser scan data and the odometry data to continually update the particle cloud with the predicted location of the quadrotor. An example of the amcl point cloud visualization is depicted below.\n2D Path Planning\nThe move_base node is a major component of the navigation stack that provides a ROS interface for configuring, running, and interacting with the navigation stack on a robot. The move_base node links together a global and local planner to accomplish its global navigation task. The move_base node also maintains two costmaps, one for the global planner, and one for a local planner that are used to accomplish navigation tasks. Running the move_base node on a robot that is properly configured results in a robot that will attempt to achieve a goal pose with its base to within a user-specified tolerance. The move_base node may optionally perform recovery behaviors when the robot perceives itself as stuck. These recovery behaviors can be configured using the recovery_behaviors parameter, and disabled using the recovery_behavior_enabled parameter. For more information on configuration of the move_base node, and the navigation stack as a whole, please see the navigation setup and configuration tutorial.\nThe excerpt below is from the quad_2dnav.launch file. Here, the odometry topic name is modified to fit the simulation environment and the planning configuration files are loaded.\n<!-- Load Navigation Stack --> <node pkg=\"move_base\" type=\"move_base\" respawn=\"false\" name=\"move_base\" output=\"screen\"> <remap from=\"odom\" to=\"/quad/ground_truth/odometry\" /> <rosparam file=\"$(find quad_2dnav)/resource/planning/costmap_common_params.yaml\" command=\"load\" ns=\"global_costmap\" /> <rosparam file=\"$(find quad_2dnav)/resource/planning/costmap_common_params.yaml\" command=\"load\" ns=\"local_costmap\" /> <rosparam file=\"$(find quad_2dnav)/resource/planning/local_costmap_params.yaml\" command=\"load\" /> <rosparam file=\"$(find quad_2dnav)/resource/planning/global_costmap_params.yaml\" command=\"load\" /> <rosparam file=\"$(find quad_2dnav)/resource/planning/base_local_planner_params.yaml\" command=\"load\" /> </node>\nThe navigation stack stores information about obstacles in the world in two costmaps. The global costmap is used for long term planning over the entire environment whereas the local costmap is used for short term planning and obstacle avoidance. One configuration file contains options common to both costmaps while other configuration files contain options specific to the global or local costmap.\nThe costmap_common_params.yaml file specifies the thresholds on obstacle information put into the costmap, footprint of the robot, inflation radius for the costmap, and the list of sensors that are going to be passing information to the costmap. The global_costmap_params.yaml file defines the costmap coordinate frame, robot coordinate frame, an update frequency, and the availability of a map served by the map_server. The local_costmap_params.yaml file includes similar coordinate frame and update options. For documentation on the full range of options, please see the costmap_2d documentation.\nLastly, a configuration file for the base_local_planner is loaded. The base_local_planner is responsible for computing velocity commands to send to the quadrotor waypoint node. The base_local_planner_params.yaml file contains options to configure the base_local_planner to make it compatible with the quadrotor’s control systems. Specifically, it is necessary to set the holonomic flag so that the local planner can compute the full range of appropriate velocity commands. For documentation on the full range of options, please see the base_local_planner documentation.\nRVIZ is a good tool for visualizing all the possible data processed by the navigation stack. It was previously described how RVIZ can be used to set the initial robot pose for the amcl node as well as visualize the point cloud pose estimate generated by the amcl node. Additionally, the navigation goal can be set using RVIZ. This results in a local and global plan that can be visualized. Additionally, both the local and global costmaps can be visualized to depict obstacles identified in the environment.\nIn the screenshot above, the quadrotor’s footprint is the red box and the global goal is the large red arrow. The global path is the green line from the quadrotor’s current position to the global goal and the blue line is the local path. The previously recorded map is shown as well. On top of the map, is the global cost function identifying all the walls as obstacles. The local cost function based on the current sensor readings is displayed slightly brighter and in the immediate vicinity of the quadrotor.\nA video summarizing this section as well as displaying ROS and Gazebo footage is available below."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:04c932c5-5778-4d0e-a608-e6f1a0316963>","<urn:uuid:77a4227b-9311-42d0-99e6-5db19bd19dbd>"],"error":null}
{"question":"What were the production credits of Murder Clinic, and how did HIPAA affect the relationship between healthcare providers and patients?","answer":"Murder Clinic's production team included Lee Wright as creator and script adapter, Robert Lewis Shayon, Alvin Flanagan, and Sherman MacGregor as successive producers/directors, and featured performers like Maurice Tarplin, Helen Claire, and Ted deCorsia. The show's scripts were adapted by Wright and John A. Bassett, with Bill Hoffman handling sound effects and Ralph Barnhart composing music. Regarding HIPAA's effect on provider-patient relationships, it created tension by establishing complex privacy notices that many patients couldn't understand, allowing providers to share information with a 'holy trinity' of insurers, providers, and claims clearinghouses without patient knowledge, and creating situations where patients might feel betrayed upon discovering the extent of information sharing permitted under the legislation.","context":["MURDER CLINIC: Radio’s Golden Age of Detection\nby Victor A. Berch, Karl Schadow & Steve Lewis\nWhatever the laws of physics and probability are as they relate to research on matters relating to detective fiction, they invariably lead investigators into bypaths and side journeys that lead them into areas which were totally unanticipated beforehand. While working on the tribute page to author John Godey after his death, Victor and Steve came across a radio play written by Morton Freedgood (Godey’s real name) entitled “Let Me Tell You About Manhattan,” which was broadcast on July 12, 1942, as part of the CBS series, Columbia Workshop.\nIn the same box of highlights for the day on the New York Times radio page was a notice of a new series called Murder Clinic on WOR, the flagship station for the Mutual network. The title of the play that evening was “The Ordinary Hairpins,” a Philip Trent short story by E. C. Bentley.\nThis of course caught both of our attentions, and we decided to investigate further. No logs of the series were found, and the series seems to have escaped the attention of such OTR (Old-Time Radio) researchers as John Dunning (On the Air: The Encyclopedia of Old-Time Radio, Oxford, 1998) and Jim Cox (Radio Crime Fighters, McFarland, 2002). Nor is there a hint of a log on Jerry Haendige’s extensive old-time radio site.)\nEach week on Murder Clinic another detective story from another well-known mystery writer was adapted for broadcast. Fans of the so-called Golden Age of Detection should certainly sit up and take notice at the veritable cornucopia of delights that were heard during the year and a few months that the program was on the air. Every week another story by an author such as Edgar Wallace, Ngaio Marsh, Carter Dickson (John Dickson Carr), Agatha Christie, Margery Allingham, G. K. Chesterton, Jacques Futrelle, Stuart Palmer, and (as we discovered) on and on.\nIt took some digging, mostly in old newspapers from across the country, but after some persistence, we have come up with an almost complete list of the titles of the stories that were broadcast in the series. As much as possible, since in many cases all we had to go by was the title of the story, we have supplied the author, the detective and the first appearance of the story. FOOTNOTE A.\nSoon after the first version of the log was posted, Karl Schadow emailed Victor and Steve, saying that he had been researching Murder Clinic on his own for many years (see above) and he was able to fill in many of the missing episodes, and were we interested? The immediate reply back was an enthusiastic “yes,” and the result of this combined effort is an almost complete listing.\nBefore we begin with the log itself, here is brief overview that includes all that we have learned about the program so far.\nPrior to the program’s initial appearance over WOR (New York), the time slot between 9:30 and 10:00 pm was filled by various orchestras, among them Kay Kyser, Alvino Rey and Claude Thornhill until June 30, 1942. The July 7, 1942, star featured the All Star Baseball game and the following week’s time slot featured a Win the War Mass Meeting. Then Murder Clinic kicked in on the following week (July 21, 1942). Eight months later, on March 7, 1943, the program switched to Sunday nights between 9:00 and 9:30, replacing the Navy show Anchors Aweigh.\nOn October 4, 1942, The First Nighter program switched over from CBS to Mutual and was broadcast from 6:00 to 6:30 on Sunday evenings. At the end of the regular season for The First Nighter, on May 2, 1942, Murder Clinic switched time periods and came on three hours earlier as the summer replacement for the other program.\nThere were several other changes of days and times for Murder Clinic in the months that followed. The final curtain rang down on October 27, 1943, after providing mystery lovers of the day well over a year’s worth of audio adaptations of many of their favorite stories. What we wouldn’t give for having a time machine at our disposal so that we could easily go back and listen to each one of them ourselves – and wouldn’t you?\nOPENING: “Murder Clinic. Stories of the world’s greatest detectives – men against murder. Each week at this time, WOR-Mutual turns the spotlight on one of the world’s greatest detectives of fiction and invites you to listen to the story of his most exciting case. Tonight we see Sir Henry Merrivale, known to all his friends as H. M., in a story, ‘Death in the Dressing Room.’” [September 9, 1942.]\nCLOSING: “You have been listening to Murder Clinic. Murder Clinic, the WOR-Mutual series which brings you each week one exciting case; one member from the special branch of the world’s great detectives. Next week, Murder Clinic will bring you one of the best-known and best-beloved figures of all crime fiction, Agatha Christie’s Hercule Poirot. Tales told on Murder Clinic are adapted by authors Lee Wright and John A. Blanton. This is the Mutual Broadcasting System.”\nKNOWN CREDITS [Compiled by Karl Schadow]\nLee Wright (creator, story collector/script adapter-writer)\nJohn A Bassett (script adapter-writer)\nRobert Lewis Shayon (producer/director) 07/21/42 - 08/11/42\nAlvin Flanagan (producer/director) 08/18/42 - 11/24/42\nSherman \"Jock \"MacGregor (producer/director) 12/01/42 - end of run\nBill Hoffman (sound effects)\nRalph Barnhart (music composer)\nBob Stanley (orchestra director)\nFrank Knight (announcer)\nDick Willard (announcer see 09/29/42 below)\nCast (in no particular order)\nFrancis Nielson (Frances Nielsen)\n08/11/42 The Governor of Cap Haiten: Herbert Yost (Poggoili), Juan Hernandez (Boisrand)\n08/18/42 The Holloway Flat Tragedy: Alfred Shirley (Carrados), Horace Braham (Louis Carlyle)\n09/22/42 The Scrap of Lace: Elizabeth Morgan (Mme. Storey), Inge Adams (Louise Mayfield), Humphrey Davis (Jack Rowcliffe)\n09/29/42 Death in The Dressing Room: Roland Winters (Merrivale), Paul Stewart (Tony Caplin, bartender), Inge Adams (Paula), Ann Thomas (Francine Rapport), Dick Willard (announcer for Air Raid Warning)\n10/06/42 The Tragedy at Marsdon Manor: Maurice Tarplin (Poirot)\n10/13/42 Gulf Steam Green: Mark Smith (Parr), Inge Adams (Estrelle)\n12/01/42 Footsteps: Alan Hewitt (Dr. Hailey)\n12/29/42 A School Master Abroad: Louis Hall (Dr. Dollar)\n01/12/43 The Blue Geranium: Vivian Ogden (Miss Jane Marple)\n01/26/32 The Sweet Shot: Alan Hewitt (Philip Trent)\n02/16/43 Murder at Pentecost: Ian Martin (Detective Montague Egg)\n07/11/43 Ashcomb-Poor Case: Helen Claire (Mme. Storey), Charlotte Manson\n07/25/43 Yellow Iris: Ted deCorsia (Poirot)\nNotes: Bonnell, Tate, Nielsen and Thor may have composed the stock character list. Elizabeth Morgan was cast as the lead (The Scrap of Lace) and appeared in other episodes throught the run. Although the cast was promoted as being different every week, there are recurring cast members. This info comes from various sources.\nSPONSORS. We do not believe that any of the episodes had sponsors, although what local stations may have done is beyond our knowledge.\nNETWORKS AND TIMES OF BROADCAST [Commentary provided by Karl Schadow]\nUnless specifically indicated otherwise, all of the programs in the series originated in the studios of WOR, New York, and were heard on most of the stations belonging to the Mutual network. The broadcast times as listed in the log are as they would have appeared in local listings on the East Coast as Eastern War Time. On the West Coast, Mutual was closely associated with the Don Lee network, and many of the programs in the series were heard on Don Lee stations, but at different times than those that are listed. The program also aired in Canada as part of a CBC exchange, which is mentioned at the end of some of the existing recordings.\nThe short chart below appears here only to reduce clutter in the log itself.\n07-21-42 WOR-Mutual [Tuesday; 9:30-10:00 EWT]\n07-21-42 to 8-25-42 WOR-Mutual; Don Lee, the following Sundays at 8:00-8:30 Pacific War Time (PWT)\n09-01-42 WOR-Mutual; Don Lee, the following Sunday at 8:30-9:00 PWT.\n09-08-42 to 10-06-42 WOR-Mutual; Don Lee, the following Sundays at 8:00-8:30 PWT.\n10-13-42 WOR-Mutual; Don Lee, the following Saturday at 10-16-42 at 6:00-6:30 PWT (??)\n10-20-42 WOR-Mutual; Don Lee, the following Saturday at at 6:00-6:30 PWT.\n10-27-42 to 11-03-42 Pre-empted on WOR-Mutual, suggesting that there were also no later broadcasts heard on the Don Lee stations.\n11-10-42 WOR only. Most if not all of the other Mutual stations aired Music for Fighting Men at this time; likewise did the Don Lee stations the following Saturday at 6:00-6:30 PWT.\n11-17-42 to 01-30-43 WOR-Mutual; Don Lee, the following Saturdays at 6:00-6:30 PWT.\n02-02-43 WOR-Mutual; unknown if broadcast on the Don Lee network.\n02-09-43 to 03-02-43 WOR-Mutual; the program is now carried live on Don Lee stations from 6:30-7:00 PWT.\n= Except for WOR, all other publicity indicated that 03-02-43 was the last episode.\n03-07-43 to 03-21-43 WOR only. [Sunday; 9:00-9:30 EWT] All other Mutual stations aired Old Fashioned Revival at this time.\n03-28-43 to 04-04-43 WOR-Mutual. [Sunday; 5:30-6:00 EWT] During this two-week period Murder Clinic was shifted to replace The Shadow, which had ended its season a week earlier; it is not known if later broadcasts were aired on these two days in the program\n04-11-43 to 04-24-43 WOR only.\n05-02-43 to 09-19-43 WOR-Mutual. [Sunday; 6:00-6:30 EWT] Most Don Lee stations carried the program live at 3:00-3:30 PWT\nAdditional research needs to be done for the programs listed from 09-05-43 on. A good deal of switching around seems to have been going on. Murder Clinic appears to have aired at the times and days stated for the Mutual network, but perhaps not for the Don Lee stations. This is apparently true even for WOR itself between 09-05-43 to 09-19-43, as they had a sponsored program, The Show Shop, that was on the air in the place of Murder Clinic during the 6:00 to 6:30 time period. One supposition is that they broadcast these shows live for the Mutual stations, but that they recorded and aired these three programs later at times as yet unknown to us.\nFIRST APPEARANCES OF STORIES:\nAs well as we have been able to determine, we have supplied both the first periodical and the first book appearance for each of the stories which were broadcast as part of the series. Many, many gaps remain. If you can be of assistance, please do. See the email address for Steve after the log below.\nFOOTNOTE A. We are aware of the limitations of using newspaper and magazine listings as primary source material. Publications printed in advance could know only what was planned to be broadcast and not necessarily what really was. Changes may have been made up to the very last minute, including the possibility that a totally different story was used, rather than the one that was scheduled, or even more extreme, programs do get cancelled with very short notice.\nHere’s a relevant example. An early version of the log below had Murder Clinic continuing through November 17, 1943, but when we received an email from Karl Schadow, we weren’t quite so sure, since Karl’s research showed that Nick Carter had gone on the air in that same time slot three weeks earlier. Karl was right, and here’s what happened:\nThe New York Sunday Times would run a listing of the week’s programs and that’s where it was that Murder Clinic showed up in the time slot we had. However, if you go to the daily listing, it becomes evident that that period was filled by a Nick Carter program. Victor looked through the Boston Globe and sure enough, on November 3, 1943, over WNAC (the WOR equivalent in that part of the country) began The Return of Nick Carter.\nSince this leaves us with the possibility, however, that there may even have been stories in the planning stages for the last three weeks of shows, through November 17, they are not included in the log below, but we felt that it was worth documenting in a footnote that they may have existed.\nEven once the title of the story used for an evening's performance had been solidly identified, from whatever source, those same sources did not generally include either the author or the detective involved, and thus more research had to be done. Karl’s work was done separately and independently from Victor and Steve’s, and as the pieces were put together, many identifications agreed, while others did not. The log below is the result of combining the results of each of us, and deciding upon the ones we believe to be correct.\nTo help achieve 100% accuracy, we’ll keep checking and double-checking. There are other steps to take, such as consulting the scripts at the Library of Congress, and as we find more to add or corrections that need to be made, we will sure to do so, as this is an ongoing project. Needless to say, but we will anyway, we’d be happy to have any omissions or corrections supplied to us in any instance where we have erred or have gone astray. Our thanks thus far to Martin Grams, Arthur Lortie, Dennis Lien and Allen J. Hubin for their additional information, suggestions and overall support.\nUPDATE 1. Besides the six in general circulation, two additional half-episodes exist at the Library of Congress: “The Age of Miracles” (9/15/1942; second half only), and “The Oracle of The Dog” (10/20/1942; first half only). In the former, Uncle Abner is played by A. Winfield Hoeny.\nMURDER CLINIC: Broadcast Log\n Thanks to Arthur Lortie for providing the mp3 copies of the six episodes that exist.\n The character in the original story was Colonel March, of the Department of Queer Complaints.\n The author’s name is incorrectly cited as Frederick Irving Sanderson.\n The story “The Big Time” was originally scheduled for 2/16/43, but it was postponed until the following week.\n The Shadow had ended its season the week before at this time, and Mutual filled the gap for this week and the following week with Murder Clinic. It is has not been confirmed that two episodes were broadcast on each of the two evenings, as suggested by some sources, with the second one going on the air at the usual 9:00 hour on WOR only.\n A novel or short story collection by Marten Cumberland having the same title is suggested by at least one source on the Internet, but no additional evidence of its existence has been found.\n These programs were aired live over the Mutual network, but may have been recorded for broadcast later on WOR. See the extended comments in the section entitled NETWORKS AND BROADCAST TIMES above.\n The author of the story with this title has not been confirmed, but the one by Oppenheim is the strongest possibility.\n Not yet confirmed.\n As pointed out in FOOTNOTE A above, there is a possibility that three additional programs were in the planning stages.\nYOUR COMMENTS ARE WELCOME.\nCopyright © 2006 by Victor A. Berch, Karl Schadow & Steve Lewis.\nReturn to the Main Page.","|Healthcare Training Institute - Quality Education since 1979CE for Psychologist, Social Worker, Counselor, & MFT!!\nConfidentiality Issues in the time of HIPAA\nRead content below or listen to audio.\nLeft click audio track to Listen; Right click to \"Save...\" mp3\nIn the last section, we discussed three changes in ethical boundaries in regards to the disclosure of raw test data. These three test data boundary changes include: shift in standards; effects of HIPAA; and protecting test security.\nOn this section, we will discuss three controversies created by HIPAA and its possible breach of ethical boundaries. These three HIPAA privacy controversies include: governmentally accessed information; contradictory language; and employer access.\n3 HIPAA Privacy Controversies\n♦ Controversy #1 - Governmentally Accessed Information\nThe first HIPAA privacy controversy is governmentally accessed information. The branch of the government, Health and Human Services, otherwise known as HHS, in addition to taking on the responsibility of writing the legislation, also takes on the responsibility of monitoring it. However, to do this, the HHS demands unlimited access to clients’ records with or without consent of the client. Upon the inception of HIPAA, the HHS facilitated the federal government’s admittance to the records of millions of mental health clients.\nFor the first time in history, an act of legislation makes it legal for the United States government to retrieve medical information about its citizens, often without the knowledge of the citizens themselves. In addition, HHS has created what HIPAA expert Michael Freeny terms \"a holy trinity of insurers, providers, and claims clearinghouses\" who can exchange information freely between each other without the client’s knowledge.\nEssentially, the information that the client only wanted and thought would be shared just between him or herself and the clinician becomes a free-for-all among these HIPAA approved entities. However, clients are never aware of these transactions and believe their information to be perfectly confidential because, as we discussed in section 3, the Notice of Privacy Policies are so convoluted and obscure that they cannot cipher through it all. Therefore the federal invasion of privacy remains undetected unless a client extensively researches HIPAA for him or herself.\nI have found that many clients who have undertaken the laborious task of sifting through HIPAA legislation feel cheated and betrayed by the government and most significantly by their therapist. This puts an unnecessary strain on the client-therapist relationship so that is why I try and make the language of my NPP as clear as possible to my clients from the beginning so they are not surprised by newly discovered and interpreted legislation.\nThink of your clients. Can you think of any clients who may be shocked by the extent to which the government has access to his or her records?\n♦ Controversy #2 - Contradictory Language\nThe second HIPAA privacy controversy is contradictory language. Although the legislation presents all appearances of attempts to protect a client’s privacy, upon closer scrutiny, it becomes apparent that certain passages may contradict each other.\nMost specifically, Michael Freeny points out a specific section within the legislation which guarantees consumers the right to see and copy their health records and request corrections of mistakes that may be contained in those records. However, providers are obligated by HIPAA to inform clients that they are not bound to fulfill such requests. Therefore, the client’s rights may not be recognized by the provider if the provider deems it unnecessary.\nIn addition, the guidelines stipulate that clients maintain the right to restrict the distribution and transmission of their medical information. However, Freeny points out, \"It’s not true because the next sentence says that the provider is under no obligation to give you that information.\" Even further, although the client may retain the right to restrict the distribution of their information and the provider consents, there are certain entities to which the provider cannot deny access, specifically the federal government, police, and public health agencies.\nSo although HIPAA may appear to be more restrictive regarding the distribution of records, this restriction only applies to certain individuals not among the HIPAA approved agencies. Many clients and clinicians are not aware of these contradictions due to the convolution of the regulations themselves. Michael Freeny believes that many therapists prefer to do the bare minimum in regards to HIPAA compliance due to the time it would consume to actually understand the guidelines at a deeper level. Do you agree?\n♦ Controversy #3 - Employer Access\nIn addition to governmentally accessed information and contradictory language, the third HIPAA privacy controversy is employer access. As we discussed in section 4, certain authorities may access information illegitimately and use it to the disadvantage of the client. However, certain employers who operate under the Employee Retirement Income Security Act as insurers for their employees have access to their employees' health records.\nThis information includes symptoms, medication, and even diagnoses. According to HHS, employers are not allowed to use this information in any business transaction. However, there are no consequences implemented to force the employer to take responsibility for his or her action.\nJohnny, age 32, suffered from alcoholism. He had just obtained a job with a packing company who acted on the Employee Retirement Income Security Act and had access to his mental health records. After about a month at this company, he was fired, even after a positive evaluation. His employer stated that Johnny had been a part of a series of cutbacks, although no other employees, even those with less experience and worse evaluations, had been let go. Johnny believes that his supervisor had been told about Johnny’s drinking problems through this act, but there was no way to prove he had been the victim of this discrimination.\nThink of your Johnny. Could he or she run the risk of losing his or her employment due to his or her disorder?\nIn this section, we discussed three controversies created by HIPAA and its possible breach of privacy boundaries. These three HIPAA privacy controversies included: governmentally accessed information; contradictory language; and employer access.\nPeer-Reviewed Journal Article References:\nBenefield, H., Ashkanazi, G., & Rozensky, R. H. (2006). Communication and records: Hippa issues when working in health care settings. Professional Psychology: Research and Practice, 37(3), 273–277.\nCampbell, L. F., & Norcross, J. C. (2018). Do you see what we see? Psychology's response to technology in mental health. Clinical Psychology: Science and Practice, 25(2), Article e12237.\nDouglas, S., Jensen-Doss, A., Ordorica, C., & Comer, J. S. (2020). Strategies to enhance communication with telemental health measurement-based care (tMBC). Practice Innovations, 5(2), 143–149.\nGlueckauf, R. L., Maheu, M. M., Drude, K. P., Wells, B. A., Wang, Y., Gustafson, D. J., & Nelson, E.-L. (2018). Survey of psychologists’ telebehavioral health practices: Technology use, ethical issues, and training needs. Professional Psychology: Research and Practice, 49(3), 205–219.\nRichards, M. M. (2009). Electronic medical records: Confidentiality issues in the time of HIPAA. Professional Psychology: Research and Practice, 40(6), 550–556.\nStiles, P. G., & Petrila, J. (2011). Research and confidentiality: Legal issues and risk management strategies. Psychology, Public Policy, and Law, 17(3), 333–356.\nWhat are three controversies created by HIPAA and its possible breach of privacy boundaries? To select and enter your answer go to ."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:2d4d6236-12ff-4125-beb9-21cd0ee99784>","<urn:uuid:e84a5fa8-27a3-4eb0-be19-a8ca48d08943>"],"error":null}
{"question":"How do Histosols and claypan soils differ in their relationship with water movement and soil quality? Can you explain the key distinctions in their hydrological characteristics?","answer":"Histosols and claypan soils have contrasting relationships with water movement and soil quality. Histosols form in wet conditions where water saturation prevents air and oxygen from entering the soil profile, creating anaerobic conditions that slow organic matter decomposition. This water saturation is essential for their formation and maintenance. However, when Histosols are drained, they experience subsidence, losing soil depth at approximately 1 inch per year. In contrast, claypan soils are characterized by a high clay-content argillic horizon 10 to 100 cm below the surface that restricts water movement. This restriction affects soil quality by reducing nutrient efficiency and impacts both production and environmental buffering capabilities.","context":["This is the second of a series of blog posts where I will describe some of the interesting features of each of the 12 soil orders in Soil Taxonomy – the soil classification system developed for the US by the United States Department of Agriculture. Each order will be “profiled” (forgive the bad soils pun) in the order in which they are “keyed out” in Keys to Taxonomy.\nHistosols are soils with organic matter as the primary parent material. They occur when conditions allow organic matter to accumulate at a faster rate than it can be decomposed. This is usually under wet conditions such as a wetland (think the Florida Everglades) or in areas where it’s just too cold for the microbial community to decompose plant material fast enough (think the Arctic Circle).\nHistosols have organic surface layers at least 40 cm deep that are at least 12-18% organic carbon (not living roots) depending on clay content. Some frozen soils that were once classified as Histosols have been now reclassified as Histels once the Gelisol soil order was introduced.\nHistosols occur where wet conditions exist because saturated conditions don’t allow air (and oxygen) to enter the soil profile, thus eventually creating anaerobic conditions. Under these conditions decomposition or organic matter is slowed, and what would have been converted into carbon dioxide by microbial respiration in dry conditions instead remains in the soil as organic matter. This organic matter builds up over time and eventually forms a Histsol.\nThere are different types of organic soil materials including fibric, hemic, and sapric soil materials. Fibric soil materials are organic soil materials that contain three-fourths or more plant fiber material after rubbing [to soil scientists, rubbing means rubbing the material between two fingers 10 times]. Sapric soil materials are organic soil materials that contain less than one-sixth plant fiber materials by volume after rubbing. Sapric materials will feel “greasy”. Hemic soil materials are in-between fibric and sapric.\nFor Histosols, the formative element for the order is “ist”. As described by Buol, et al (1997) Histosols have five suborders and they are classified in the following order in Soil Taxonomy. Wassists are Histosols that are floating on top of free water. Folists are Histosols that formed not due to wet conditions, but from high rates of accumulation of organic matter (relative to decomposition). The rest of the suborders are classified based on the state of decomposition. Fibrists are Histosols with fibric materials, Hemists are Histosols with hemic materials, and Saprists are soils with sapric materials.\nAs said above, Histosols form anywhere that has a rate of organic matter accumulation greater than decomposition.\nAt the scale of this map, it’s difficult to pick out many expansive areas of Histosols. However, they do occur throughout the world, but usually in small areas. This map of the US shows a better depiction of their occurrence.\nHistosols are used for crop production and forestry, as well as wildlife and recreation. The organic material can also be harvested for horticultural potting soil and for heating and electricity. They can be production crop soils, however extensive drainage is required.\nUnfortunately, drainage leads to subsidence. Subsidence is the loss of soil depth. Subsidence occurs when water is drained from the profile. The organic materials “float” in saturated conditions and become more compact when drained. Once drained, the soil begins to oxidize and microbes consume the organic matter and slowly turn it into carbon dioxide with time. Subsidence, as a rule of thumb, occurs at a rate of 1 inch of soil per year. This creates problems for drainage ditch maintenance and long term uses of agricultural soils.\nHistosols, when drained, are also vulnerable to fires. Here is a recent news story about a fire that occurred in Alligator River National Wildlife Refuge here in North Carolina <http://outerbanksvoice.com/2011/06/10/million-of-gallons-of-water-pumped-on-peat-fire/>.\nHere’s an excerpt from that article:\nFlammable organic peat ranges from a few inches to 8 feet deep in the ground, said the multi-agency team fighting the fire.\nBecause of the lack of rain, peat, which was once used as a fuel, continues to burn even when the surface fire is put out, according to the North Carolina Incident Management Team.\n“The ground fire will continue until the fire consumes all the peat down to mineral soil, the fire burns down to a level of high moisture content, or the soil moisture level rises to the fire as a result of an extended heavy rain or pumping operations,” the team said in a statement Friday.\nMy current research involves Histosols in a Carolina Bay wetland. The wettest part of the wetland (the center) is where the Histosols occur. They’re really interesting soils (I might be biased because I’m a wetland soils guy).","Submitted to: Meeting Abstract\nPublication Type: Abstract Only\nPublication Acceptance Date: April 27, 2006\nPublication Date: April 27, 2006\nCitation: Jung, W., Kitchen, N.R., Sudduth, K.A. 2006. Understanding productivity variation on un-irrigated claypan soils [abstract]. Korean Crop Science Society annual meeting, April 27-28, 2006, Choenan, Korea. Technical Abstract: A high clay-content argillic horizon occurring 10 to 100 cm below the surface restricts soil water movement and reduces nutrient efficiency of claypan soils, which affect soil quality related to production and environmental buffering. The objective of this study was to determine the impacts of long-term (12 yr) annual cropping systems (ACS) and conservation reserve program (CRP) practices on the soil quality of a claypan soil in north central Missouri. In 2002, soil cores were collected (0- to 7.5-, 7.5- to 15-, and 15- to 30-cm depths) from summit, backslope, and footslope landscape positions (LP). Management systems included: (i) annual cropping system 1 (ACS1), a mulch tillage corn-soybean rotation system; (ii) annual cropping system 2 (ACS2), a no-till corn-soybean rotation system; (iii) annual cropping system 3 (ACS3), a no-till corn-soybean-wheat rotation system with red clover as a cover crop; and (iv) CRP, a continuous cool-season grass and legume system. Soil cores were analyzed for soil particle size distribution, bulk density, cation exchange capacity, soil organic carbon (SOC), total N (TN), microbial respiration, and water-stable soil aggregation. No interactions were observed between cropping system and LP. At the 0- to 7.5-cm soil depth, CRP increased SOC storage by 33% and TN storage by 34%. Soil aggregation under CRP management was more than double that of the ACS. On the backslope, soil aggregation was significantly higher than on the footslope. SOC and TN were significantly higher on the footslope than on the backslope at the 7.5- to 15-cm soil depth. These results show that soil quality of claypan soil landscapes was not significantly different among ACS management practices. Compared to ACS, CRP enhanced soil quality. Understanding relationships between sensor-based measurements and soil properties related to soil quality may help in developing site-specific management options. The objective of this research was to examine whether sensor-based apparent soil electrical conductivity (ECa) could be used to predict soil quality indicators for claypan soil fields in the U.S. Midwest. Soil samples were obtained in 2002 at three depths (0 - 7.5 cm, 7.5 - 15 cm, and 15 - 30 cm) and at 65 locations within a 4-ha area of an agricultural field located in north central Missouri. Samples were analyzed for numerous physical, chemical, and microbiological properties that serve as soil quality indicators. ECa measurements were also collected with an electromagnetic induction-based sensor in different orientations and at different heights above the soil. Yield, obtained using a combine equipped with a yield-sensing system, was available for corn (Zea mays L.)(4 years) and soybean (Glycine max (L.) Merr) (5 years) crops. At the deepest sampling depth, soil bulk density (BD), clay, silt, cation exchange capacity (CEC), and Bray-1 P were the most significantly correlated (r>0.55) with ECa. Soil properties were regressed against ECa, and R2 values were often improved by including a quadratic term of ECa, especially at the 0- to 7.5-cm depth. Some soil properties (e.g., clay and CEC) and ECa that were positively correlated to yield in years with average or greater than average cumulative July to August precipitation (>15 cm), were negatively correlated to yield for years with less than average precipitation (<15 cm). We found that our best results were when we used the EC sensor near the soil surface, as opposed to lifting the sensor above the ground. Our results suggest that sensor-based ECa can be an efficient way of estimating some claypan soil quality measurements."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:a2dbb52d-d6cb-4c46-883c-4d9092e8a236>","<urn:uuid:6e865119-d4da-4446-8af1-2d26679f3ca6>"],"error":null}
{"question":"What is the connection between metal stamping hardness testing and on-site hardness measurements in industrial applications?","answer":"In metal stamping operations, hardness is measured using Rockwell hardness testers, particularly for small, complex-shaped stampings that require testing on small planes. For on-site testing of components that cannot be removed from service, portable Krautkramer devices are used, which calculate hardness based on indenter rebound from the test surface. However, on-site testing has limitations due to the mass and thickness requirements of the test sample, unlike traditional Rockwell testing used in stamping operations.","context":["different types of Auto Stamping Parts?\nAuto stamping Parts, as the name suggests, are metal stampings that make up automotive parts. In automotive stamping parts, some of them are directly transformed into auto parts after being stamped, and the other part is subjected to welding, machining, or painting after being stamped to become auto parts. There are many kinds of automobile stamping parts, such as automobile shock absorber stamping spring tray, spring seat, spring bracket, end cover, cover, compression valve cover, compression valve sleeve, oil seal seat, bottom cover, dust cover, impeller, oil cartridges, lugs, brackets, etc. These are all automotive stampings. In Auto Stamping Parts China, stamping is sometimes referred to as sheet forming, but with a slight difference. The term “sheet forming” refers to the use of sheet material, a thin-walled tube, a thin profile, or the like as raw material. The method of forming plastic work is collectively referred to as sheet forming, and at this time, deformation in the direction of the thick plate is generally not considered. First, the application range of metal stamping parts:\n1. Special stamping enterprises. Such as the stamping of aviation parts, etc. belong to such enterprises, but these craft factories are also owned by some large factories.\n2. Stamping of parts and components in the automotive industry. Mainly punching and forming. Many of the companies in this sector belong to scale factories, and there are also some independent stamping plants. At present, there are many such small factories near some automobile factories or tractor factories.\n3The stamping factory of daily necessities. Do some crafts, tableware, etc. These factories have also grown significantly in recent years.\n4. Stamping in the automotive industry. Mainly drawing. In this part of China, we mainly focus on large factories such as automobile factories, tractor factories, and aircraft manufacturers. Independent large scale stamping and deep drawing plants have not been seen.\n5. Electric stamping plant. This type of factory is a new industry that has developed along with the development of electrical appliances, which are mainly concentrated in the south.\n6. Household appliance parts stamping plant. These factories only emerged after the development of household appliances in China, and most of them are distributed to household appliances enterprises.\nSecond, the detection of metal stamping parts:\nThe hardness of metal stamping parts is measured by a Rockwell hardness tester. Small, complex-shaped stampings can be used to test small planes that cannot be tested on ordinary Rockwell benchtop hardness testers. Stamping parts processing includes punching, bending, drawing, forming, finishing and other processes. The materials processed by stamping parts are mainly hot-rolled or cold-rolled (mainly cold-rolled) metal strip materials, such as carbon steel sheets, alloy steel sheets, spring steel sheets, galvanized sheets, tin-plated sheets, stainless steel sheets, copper and copper alloys. Plate, aluminum and aluminum alloy plates, etc.\nRockwell’s PHP series of portable surface hardness testers are ideal for testing the hardness of these stamped parts. Alloy stampings are commonly used in metal processing and mechanical manufacturing. Stamping is a process that uses a Stamping Mould to separate or form a metal strip. Its application range is very broad.","The two categories of bend-testing determine the flexibility or strength of a material.\nThis type of bend-testing determines the smallest radius that a specimen can bend without cracks forming on the outer surface. This bend test is often used to test the flexibility of welds.\nBending strength tests determine the modulus of elasticity and the strength of flat metallic samples in the form of strip, sheet, or plate.\nCharpy Impact Testing for Toughness\nCharpy Impact Testing is the application of a sudden applied load confined to a localized area of a material to determine its notch toughness or impact strength.\nThese tests determine a material’s toughness at subzero temperatures. A charpy impact test sample has a V-notch, keyhole, or U-notch machined on one side. It is supported at both ends and struck from behind the notch by a swinging pendulum of fixed mass. The energy that is absorbed by producing the fracture is the material’s impact energy. The more impact energy that a material absorbs, the more robust it is.\nThis test is often performed to determine the toughness of roll-over protection systems for farm equipment and automobiles. It is also critical in determining the ductile to brittle transition temperature of materials—essential in the failure analysis of structures at subzero temperatures. This material property is crucial for structural members such as bridge girders.\nTension testing is a routinely used method of determining material strength.\nThe test determines a material’s yield strength, ultimate tensile strength, and percent elongation (ductility). Tension testing assists in establishing if the alloy has been heat-treated to increase strength.\nTestlabs International machines tensile test specimens and is capable of performing tension tests at subzero (as low as -40 C), room, or elevated temperatures.\nA material’s hardness is a measure of the resistance of a material to surface indentation or abrasion. Hardness is a routinely measured and this parameter can indicate the strength and heat treatment of the material.\nA hardness test forces a ball, diamond cone, or pyramid into the material. The total force to the area or depth of indentation provides the measure of hardness.\nHardness testing includes:\nRockwell A, B and C Scale\nRockwell hardness testing is the most widely used method for determining hardness. It can determine the hardness of most metals and alloys, ranging from the softest materials to the hardest steels.\nVickers hardness testing is a form of micro-hardness testing, where a Vickers indenter (square-based pyramidal diamond) is forced into the test surface of the material using loads ranging from 1 to 1000g.\nMacro-hardness testing utilizes an applied force much higher than a micro-hardness test. Similar to Micro Vickers hardness testing, a pyramidal diamond indenter is forced into the test surface using loads ranging from 1 to 100 kilograms.\nOn-site Hardness Testing (Portable Krautramer)\nOn-site hardness testing is performed on components and structures that cannot be removed from service for laboratory testing. Hardness measurements are calculated based on the rebound of the indenter from the test surface. For this reason, this test method has limitations due to the mass and thickness of the test sample.\nCyclic and Constant Pressure Hydraulic\nPressure testing is used to validate that a pipe, tube, fitting, or component can withstand a designed internal pressure with a margin of safety. Pressure testing consists of non-destructively charging the test sample to a specified, constant pressure, and held for a predetermined duration. At this pressure, the test sample is observed for leaks or other indications of failure.\nPressure testing can also consist of cyclic fatigue testing to determine if the sample can withstand repeated pressure variations without fatigue and failure. This test is valuable as an accelerated evaluation to simulate the life cycle of the test component."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"}],"document_ids":["<urn:uuid:16c16da0-f45c-4261-9477-9605baa906cf>","<urn:uuid:ade0270e-2622-4576-b571-1a5066b149b9>"],"error":null}
{"question":"How do strength training approaches differ between 10K runners and marathon runners in terms of building endurance and preventing fatigue, and what specific training recommendations are given for each distance?","answer":"For 10K runners, strength training focuses on a combination of speed, endurance, and power. They should incorporate strength exercises like planks, wall sits, lunges, glute bridges, and body weight squats, along with plyometric moves like jump lunges and burpees. For races under 10K, runners should pull a weight sled for 30 minutes, marking their distance and trying to improve it. Marathon runners, however, need a different approach since leg fatigue is the main limiting factor, not lung capacity. They should focus on maximal strength training and use weight sleds with a three-week wave of 25, 35, and 45 pounds. Marathon runners should do four trips using the interval method with power walking, aiming to increase speed on subsequent trips. Both distances require reducing regular running by at least 30% when incorporating weight sled work to prevent overtraining.","context":["10 Tips For Running Your Best 10K\nMake this year’s Windsor 10K your best 10K every with these 10 training tips.\n10K is a great race distance – short enough that you can hold a good pace and push through, but long enough to challenge you (after all, who wants to be finished before you got into your stride?) Here are 10 things to consider as you tick off your 10 training plan for Windsor.\n#1 Warm Up\nMake sure you do a good warm up, especially for speed work, tempo runs, or race-pace runs. Walk and jog for a mile, then do some 100m drills like strides and high knees. Develop a warm up that you can use before the race, and consider it part of your training strategy!\n#2 Vary Your Sessions\n10K races need a combination of speed, endurance, strength, and a burst of speed to finish if you can. So make sure your training sessions incorporate them all. Get used to running at your race pace, but also get used to running at a slightly slower pace – and a slightly faster pace. Make sure you know what race pace feels like for you, so you can get up to speed and hold it. Try 3 sets of 2-mile efforts at your 10K race pace as a training session.\n#3 Finish faster\nTry pushing past your comfort zone on long runs by varying the tempo. Either put some 1-minute surges throughout the run, do a negative split, or aim to run the final mile faster than the previous ones. Varying the tempo within a longer run helps your mind deal with tough patches, and gets your body used to holding a higher intensity.\n#4 Build Leg Strength\n10K training doesn’t take as much time as marathon training, so use the extra time to do yoga or strength training. Strengthening your core, hips, and legs will improve your form and help protect against injuries. You can do plenty of useful things at home: plank holds, wall sits, lunges, glute bridges, and body weight squats are a great combination.\n#5 Build power\nAdding some plyometric moves into your strength training will build lower body power, which will translate into faster race times. Try jump lunges, squat jumps, burpees, and bounding. These will strengthen your glutes, quads, hamstrings and calves and build explosive power.\n#6 Hit the track\nDo you have access to a running track? Track sessions will transform your 10K time. Go shorter than you’d think – 200m and 400m repeats are beneficial to a 10K training plan. Try 8 x 200m (with 200m jog recovery) at 80%-90% effort. Work your way up to 20 repeats (or 10 x 400m repeats). You can also use the track for a super accurate 5000m or 10000m time trial if you really want to!\n#7 Pyramid Sessions\nThese are longer intervals that work really well for 10K training. An example would be running hard for 60 seconds (then a recovery), hard for 90 seconds (then a recovery), hard for 3 minutes (plus recovery), hard for 5 minutes (recovery) and then back down through the intervals so the session resembles a pyramid.\n#8 Build Endurance\nIf speed is already your friend, but you struggle with endurance, then go over and above the 10K distance in your long runs. Build up to 8-10 miles for your long runs and your body will be forced to adapt with extra endurance.\n#9 Mimic The Race\nYou already know what the Windsor 10K course will be like, so make sure some of your training runs mimic how the race will go for you. Add in hills, climbs, and flat sections at the relevant points in your training runs. That way you’ll be comfortable with everything on the day.\n#10 Finish Fast\nTrain for a steady race with a faster finish. Aim for negative splits (where the second half of your training run is faster than the first). Think about running a controlled first 3K, pushing on from 4K-8K, then picking things up from the 8K mark. It’s a great skill to develop","No Products in the Cart\nIn 2014, at thirty years old, Dennis Kipruto Kimetto, (b. Jan 22, 1984) a long-distance runner from Kenya set the marathon record of 2:02:57 (two hours, two minutes and 57 seconds) in Chicago, Illinois. He was the first man to ever run under 2:03.\nHe held the record for four years. It was then broken by Eliud Kipchoge (b. Nov 5, 1984), another Kenyan long-distance runner. Kipchoge is now the world record holder in the marathon with a time of 2:01:39, which he set Sept. 16, 2018, at the 2018 Berlin Marathon.\nKipchoge also ran the marathon distance at a special event in Vienna, Austria, and achieved a time of 1:59:40. The run did not count as a new marathon record, however, because it was not an open event and the standard competition rules for pacing and fluids were not followed, but he did become the first person to ever run a marathon in less than two hours. (https://en.wikipedia.org/wiki/Dennis_Kipruto_Kimetto and https://en.wikipedia.org/wiki/Eliud_Kipchoge)\nWhen someone does the seemingly impossible, everyone’s interest is heightened and they, too, want to improve. For the most part, to run long distances it takes the right genetics along with having the correct limb lengths and, of course, at least 70 percent Type 1/slow twitch/slow oxidative muscle fibers, but you also must train efficiently.\nThe most efficient way to improve is to gain muscular endurance. At the end of a marathon it is the legs that give out, not the lungs. Most will incorrectly try to increase their VO2 max, but it cannot be increased by top athletes as it cannot be raised after 12 or 18 months in endurance runners. This leaves only one way and that is to raise muscular endurance by maximally training strength endurance.\nIf one simply runs a set distance at a set body weight at the same pace, then you are not increasing your work. You must become more powerful. For example, by becoming stronger you can deliver greater ground force that can reduce ground contact time. A study by Leema Paavolainen concluded that reduced ground contact time is the most important for faster running times no matter the distance.\nThe study on 5K racers who had an average stride length of two meters found they would use 2500 strides to cover a 5K. A one one-hundredth of a second reduction in ground contact time would reduce their 5K time by 25 seconds. More on this topic can be found in Underground Secrets to Faster Running by Barry Ross.\nWhy is increasing strength so important? This is a simple physics equation. First, let’s look at what is work. In physics, work is defined as the product of the net force and the displacement through which that force is exerted, or W=Fd.\nLet’s look at power. Power is defined as work done divided by the time used to do the work (P=wt). This simply says that the more powerful you are, the faster you can do the work; the work in this case being 60, 100, or 25,000 meters or even a marathon.\nIf you are just running and not strengthening your body you have most likely developed a speed barrier where you can no longer cover your distant faster. That’s the definition of the biological Law of Accommodation—that your body adapts to a constant continued stimulus by decreasing its response. So just by running you won’t eventually run faster. To break that speed barrier, you must train other activities such as special exercises for the running muscles—the calves, hamstrings, hips and glutes, and of course, some upper body work for strength and balance. Westside uses weight sleds to build running muscles.\nFor strength endurance training instead of doing the same amount of work with just body weight, the runner should use three weights on a weight sled that is connected to your body with a strap. This does not effect your running technique when using 15, 25 and 35 pounds.\nThrough experimentation Westside found that long-distance runners lack maximal strength. For instance, one long-distance runner could parallel box squat 65 pounds for 100 reps, but could only squat 100 pounds for one rep. By doing interval training with a weight sled with three different weights, strength endurance was built. Westside established 25, 35 and 45 pounds in a three-week wave will build strength endurance.\nBy doing interval training with a weight sled with three different weights to build strength endurance. But experimenting Westside has established 25, 35 and 45 pounds in a three-week wave will build strength endurance.\nFor races up to 10,000 meters one can pull a weight sled for 30 minutes or just over the world record for that length race. For the very fit, two trips can be performed. Time between trips will depend on your level of preparedness, meaning letting your heart rate get back to your normal range and then repeat. Pull the sled two times a week, but remember to cut your running back by at least 30 percent.\nA 16-ounce bottle holds 16 ounces and no more, so when you include weight sled work you have to cut your running back. We know it will be hard to change your thinking, but you must. Your total work capacity is just like that 16-ounce bottle. The bottle can only hold 16 ounces at one time, but it can be full of different substances. For 20,000 meters—a half marathon—do two trips for 30 minutes or four trips for the advanced, and then push for two trips of 45 minutes. Remember, if your pace starts to slow down, you should stop. The key is to maintain top speed for as long as you can. If you slow down you lose … period.\nIf you run a full marathon, start with four trips using the interval method, meaning powerwalk for 30 minutes. Let your heart rate return to normal and repeat. Then, you should try to increase your speed on the second, third and fourth trips. Note: you must always use the same power walking style to correctly monitor your speed.\nFor runners with distances less than 30 minutes—10K and under—you should pull a weight sled for 30 minutes. Mark the distance you cover at the 30-minute time limit and try to cover a longer distance each trip. When this can be achieved you have improved your top speed maintenance velocity as well as increased your strength endurance.\nRoss, Barry. 2005. Underground Secrets to Faster Running. Lulu.com.\nSimmons, Louie. 2017. Strength Manual for Running—Raising Strength to Prevent Injuries. Westside4Athletes"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:ca59227f-c29c-4321-9366-2cc024ae4dfc>","<urn:uuid:3246222e-e61d-4f7c-b696-08c7b3d69b0e>"],"error":null}
{"question":"As someone interested in sustainable urban development, I'm curious how Marine Gateway and Chestnut Court compare in terms of their transit connectivity and community integration features?","answer":"Both developments excel in transit connectivity and community integration, but with different approaches. Marine Gateway is a major transit-oriented development that seamlessly integrates a transit hub within the community, serving approximately 750 residents and 2,000 jobs along with restaurants, retailers, and a movie theatre. Chestnut Court, meanwhile, is located at two major bus thoroughfares providing easy public transportation access, and features a computer learning center, job training, after-school tutoring, and senior care services. Both projects emphasize community spaces - Marine Gateway includes pedestrian plazas, while Chestnut Court incorporates communal outdoor spaces with a recreational courtyard, playground, and basketball court. The projects demonstrate how transit accessibility can be combined with community amenities to create vibrant urban spaces.","context":["Two Perkins+Will projects, Marine Gateway and the PPL Center/Downtown Allentown Revitalization District, have been named winners of the Urban Land Institute’s (ULI) 2017 Global Awards for Excellence, widely considered one of the land use industry’s most prestigious awards programs.\nMarine Gateway is a major transit-oriented development in Vancouver. Designed by Perkins+Will in partnership with PCI Developments, the project—which is located in a former industrial, underused area—includes retail, office, residential space, pedestrian plazas, and a seamlessly integrated transit hub within the heart of the community.\n“We are honored to receive this international recognition from the ULI for Marine Gateway. It is a project that we are very proud of,” says Andrew Grant, president of PCI Developments. “The site previously had no housing and only 60 jobs. Now, Marine Gateway is a vibrant, transit-oriented, complete urban community home to approximately 750 residents and 2,000 jobs in conjunction with high quality restaurants, retailers, and a movie theatre serving the local community.”\n“Marine Gateway sets a benchmark for transit-oriented design and raises the bar on the urban living experience,” says Ryan Bragg, principal at Perkins+Will. “We are delighted that this innovative and transformative project has been honored by such a distinguished award from ULI.”\nPPL Center/Downtown Allentown Revitalization District\nThe PPL Center at the Allentown Arena Block Development is a large mixed-use project in Allentown, Pennsylvania’s downtown core. Anchored by a multipurpose arena, the development includes street-level restaurants and retail, commercial offices, a hotel, banquet and meeting rooms, a physical fitness and rehabilitation center, a renovated historic building, and parking.\n\"This global recognition validates the tremendous turnaround that downtown Allentown achieved through a unique public-private partnership,\" said Sy Traub, chairman of the Allentown Neighborhood Improvement Zone Development Authority (ANIZDA). \"The best part is it's still early in downtown Allentown's transformation. We're still growing and attracting more developers and businesses.\"\n“It’s a great honor to have been part of this project, along with our partners at Hammes and ANIZDA, and to see the continued reinvigoration of this vibrant city as a result of our contributions,” says Don Dethlefs, principal at Perkins+Will and chair of the firm’s Sports, Recreation, and Entertainment practice. “We are grateful for this recognition from ULI.”\nImproving Cities, Bettering Lives\nThe ULI Global Awards for Excellence recognize projects that achieve the highest standard of excellence in design, construction, economics, planning, and management, and that enhance the livability, sustainability, and resilience of the communities in which they are located. The criteria for the Awards include leadership, contribution to the community, innovations, public/private partnerships, environmental protection and enhancement, response to societal needs, and financial viability.\n“Cities are about people—the way we interact, get around, and go about our daily routines. Great cities are made of great places that make the urban experience easy and enjoyable,” said ULI CEO Patrick L. Phillips. “These projects…are improving people’s quality of life.”\nWinners were selected from a pool of 25 finalists by an international jury of ULI members representing a range of industry expertise, including finance, land planning, development, public affairs, and design.","Chestnut Court is a vibrant new mixed-use complex that contributes to the dramatic revitalization of West Oakland. Replacing a deteriorated public housing project, Chestnut Court skillfully inhabits its one square block site by responding to the neighborhood’s varied urban context. The three-story mixed-use Grand Avenue building provides townhouses above community service, child care and retail spaces. The façade addresses the busy street and neighboring loft and industrial buildings by using corrugated metal siding, exposed concrete piers and large scale windows. On the side streets, the project’s buildings are designed at a smaller scale to relate closely to existing small private homes. A new mid-block private street provides access to tuck-under parking and acts as a quiet, pedestrian connector to the common outdoor spaces, including a generous recreational courtyard with seating, a playground and basketball court. There is a strong sense of community through the site design and communal spaces. The complex provides supportive services for residents including a computer learning center, job training and placement, financial planning, after-school tutoring and senior care. Residents of Chestnut Court have easy access to public transportationthrough its location at two major bus thoroughfares.\nEach dwelling unit in the complex is designed to be as individually identifiable as possible, most with front doors opening onto the street and each with private outdoor space. Unit interiors have efficient floor plans, and ample natural lighting and ventilation. Porches and entries to the townhouses mirror the surrounding neighborhood context and encourage neighborhood interaction. The design provides residents with a sense of ownership which serves as a strong deterrent to crime. Since the completion of Chestnut Court, surrounding homes have been improved and sold, evidence of the continued neighborhood renewal.\nThe design process for Chestnut Court incorporated extensive community involvement including a bus tour of existing complexes completed by the developer with the same and other architects, several meetings with both the surrounding neighbors and potential tenants and meetings with the city of Oakland. In addition, there were design meetings with the developer’s maintenance and management staff. Issues of sustainability and energy efficiency were addressed during the entire design process.\nChestnut Court is an Energy Star project incorporating well sealed ductwork, double glazed low-E windows and 2x6 exterior walls with R-19 insulation. All of these measures contribute to the project exceeding California’s Title 24 energy requirements by over 15%. Energy-efficient appliances were installed throughout, including Energy Star refrigerators/freezers, dishwashers and office computers, monitors and printers. Three fourths of lighting fixtures feature fluorescent bulbs and all emergency exit signs are LED-type. The central hot water heating system is 94% thermally efficient. All units are double aspect, allowing for cross ventilation and daylighting. Most of the townhouses also have operable skylights for additional daylighting and stack ventilation. Because of the Bay Area’s mild climate and the use of natural ventilation the need for mechanical cooling was eliminated. A 31.5 kW photovoltaic system generates 65% of the electricity for the common spaces. The solar system reduces the development’s electrical bills and will serve the property for at least thirty years, providing a clean, long-term source of energy.\nAppliances selected to minimize water use include front-loading washing machines in the common laundry area and water efficient dishwashers within the units. The project’s central water heaters have peak demand output, which combined with efficient return plumbing, expedites delivery of hot water to residents, reducing waste. Drought tolerant and resistant plants were selected to reduce the use of landscape irrigation.\nDurable, sustainable materials at Chestnut Court include: high volume fly-ash concrete foundation footings, cementitious siding, recycled content carpet, recycled content rubber playground surfacing, composite flooring, and stained concrete floors in the entry areas. A construction waste reduction and recycling plan was instituted and resulted in a 50% reduction in waste. Construction materials recycled included wood, drywall, excess and scrap carpet pad, metal studs, piping, landscaping materials, and additional metals including rebar. Materials were separated on-site before being transferred to the county’s recycling facilities.\nTo increase building durability and safeguard indoor air quality, exterior moisture protection was addressed through careful detailing. This included the use of a self-adhesive sheet membrane at all wear points (windows, doors, corners, etc.) in combination with galvanized sheet metal flashings. Humidity in bathrooms is minimized through exhaust fans on humidistat sensors. To limit material off gassing in the units low VOC paints and Interface carpeting was used.\nLessons Learned from the architect - Creating double aspect and double height units provides exceptional natural ventilation and daylighting and improves the overall indoor environmental quality. It is a green strategy that really comes down to good design and remembering how things were done before there was the luxury of mechanical heating and cooling and electric lighting.\nUsing tuck under parking is very resource efficient. Rather than using materials to cover cars plus driving lanes, you are covering only the cars. In this project every unit has covered parking. Without using a tuck under strategy for 58 of the 72 cars, it would not have been feasible.\nAlthough it’s not a goal exclusive to green, it’s really important to create social places for people to gather. By creating eight unit clusters that share an entry patio area and pleasant common gathering spaces, we create a strong sense of community, safety and social sustainability for the residents.\n|Green Features||Chestnut Court|\n|Access to Public Transportation||Chestnut Court is located on two major bus thoroughfares.|\n|Compact Development||The project density is 26 units per acre.|\n|Passive Heating and/or Cooling||All units are double aspect, allowing for cross ventilation. Most of the townhouses also have operable skylights for stack ventilation.|\n|Daylighting||All units are double aspect, allowing for daylighting. Most of the townhouses also have operable skylights for additional daylighting.|\n|Superinsulation||2x6 exterior walls with R-19 insulation.|\n|High Performance WIndows||Double glazed low-E windows.|\n|Energy Efficiency Heating and Cooling||The central hot water heating system is 94% thermally efficient. All cooling is provided by passive ventilation.|\n|Energy Star Appliances/Lighting||Refrigerators/freezers, dishwashers and office computers, monitors and printers are Energy Star.|\n|Renewable Energy||A 31.5 kW photovoltaic system generates 65% of the electricity for the common spaces.|\n|Water Efficient Landscaping||Drought tolerant and resistant plants were selected to reduce the use of landscape irrigation.|\n|Water Saving Appliances||Front-loading washing machines in the common laundry area and water efficient dishwashers within the units. Central water heaters have peak demand output combined with efficient return plumbing to expedites delivery of hot water and reduce waste.|\n|Recycled Content Materials||Recycled content carpet, recycled content rubber playground surfacing, a construction waste reduction and recycling plan resulted in 50%less waste.|\n|Low VOC Materials||To limit material off gassing in the units low VOC paints and Interface carpeting was used.|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:8577bebb-998a-4528-a061-db2e1e31832f>","<urn:uuid:584e22ce-7ec1-4f9c-9168-ae60b90234c0>"],"error":null}
{"question":"I'm fascinated by traditional sweets - could you explain how Finnish tar-based treats compare to Native American maple syrup in terms of their cultural significance and historical origins?","answer":"Both Finnish tar treats and Native American maple syrup have deep cultural roots, but their origins differ significantly. Finnish edible tar (terva) has been used for centuries, originally as a medicinal product and ship coating before becoming a nostalgic food flavoring that Finns associate with childhood sweets. Meanwhile, maple syrup was discovered by indigenous peoples in North America, with legends attributing its discovery to an Algonquin or Iroquois chief. Maple syrup became a major sweetener for Native Americans, making up about 12% of the Iroquois diet. While tar remains a distinctly Finnish taste that most outsiders find difficult to appreciate, maple syrup production expanded when European settlers adopted and improved the Native American techniques, becoming a widely appreciated sweet throughout northeastern North America.","context":["Every nation has a few favourite national foods that seem bizarre or even disgusting to outsiders. The USA has saltwater taffy, Japan has green tea soft drinks, and Canada has jellied moose nose. But Finland, the same nation which loves salted liquorice, might be a contender for the strangest: food made from or flavoured with tar.\nMost people probably think of tar as the stuff used to make roads, or as an ingredient in cigarettes. Not many people realise that there are actually several different types of tar, all of which are produced using organic materials. While some of them are dangerous to ingest, others can be made safe to eat.\nThe edible tar that Finns use is called terva in Finnish and is made from tree sap extracted from burning wood, most commonly pine. It has been used for centuries to coat ships and as a medicine. An old Finnish proverb says, ‘If sauna, vodka, and tar won’t help, the disease is probably fatal’. Tar kilns dating back to the Stone Age have been found throughout Scandinavia.\nWhile these uses have since died off, it is now used in Finland as a flavouring for alcohol, ice cream, sweets, chewing gum, lemonade, and meat. It even has non-edible uses, such as shampoo, cosmetics, soap, and air freshener.\nEven if tar can be edible, it still raises the question of why Finns still enjoy it over the thousands of other sweets available. It makes sense if you consider that it comes from the same source used to make maple syrup.\nFinns claim to love the smoky flavour and the familiar smell they can’t find in other types of food or spices. Much like salted liquorice, most Finns consider tar to be a highly nostalgic taste they associate with the sweets they used to eat when they were children. Yet there might be another reason too: Finns just really love weird things and enjoy being different to other nations.\nIt is difficult to find tar-flavoured food in most places. In Finland and other parts of Scandinavia, however, foods labelled with terva are everywhere. You can easily find tar sweets in the supermarket or tar ice cream at kiosks.\nLike most strange foods, tar is a highly acquired taste, and it is difficult to get into it unless you’ve been eating it since childhood – much like Marmite. Most people try tar once, find it disgusting, and vow never to eat it again.\nIf, however, you do want to try tar flavouring, or think you might enjoy it, it’s best to try a milder flavour and work your way up to something more intense. Tar ice cream is usually considered one of the best introductions to tar-eating, as it is much sweeter, with a taste like caramel or toffee. Many ice cream shops will allow you a sample-taste before you buy, so you can check if you’ll like it before you spend your money on it.\nUnless this initial taste puts you off tar forever, you can purchase Finnish pine tar online and use it as a flavouring, or to make your own soap and shampoo. Tasting strange foods is a memorable part of travelling, and a way to experience other cultures, and saying you have eaten tar is quite a story.","The Maple Moon or Moon of the Worm\nMarch is a month of transition between winter and spring, often with an unpredictable season almost all its own. The temperatures in Upstate New York can range from an unusually warm 80 F down to sub zero Fahrenheit. This pulsating tension between the cold winter and warmer weather patterns and increasing daylight coincides with the vernal equinox, the Pascal Moon, and the Easter season to the European mind.\nBefore the French explorers of the 16th century and English, French, and Dutch settlers of the 17th century, the indigenous peoples knew the full moon near the equinox as the Worm Moon. This was when the worms started bringing castings to the surface, and robins started to reappear after their winter's absence.\nThere were other names for the moon by some tribes. The Crow Moon honored the late winter flocking of crows. In the far north, the Crusty Moon recognized the particular hard crusting of snow in late winter. Some tribes came to call it Sap or Maple Moon. This latter name evolved from the rising flow of the sap as days start to warm and winter changes to spring in fits and starts.\nEarly origins of Maple\nThe exact origins of the discovery of maple sap and its distillation, or processing, into syrup is impossible to determine with any firm historical accuracy. While a few authorities think the processing of the sap was taught to the Indians by the Europeans, they are in the minority. Most historians believe that various indigenous tribes had a knowledge of this sweet prior to contact with the Europeans. Lack of firm archeological proof and a lack of written records from the various tribes leave the debate open to conjecture and dispute, though there is much to support that the Indians did know about, and use this sweet, albeit in a much cruder fashion than is common today.\nMaple trees observed during his explorations of Quebec were written about by Jacques Cartier in 1540. Recognition of the Indians using the refined sap as sugar and syrup dates from about 1557 in writings of Andre Thevet. Details of collection and distillation of sap by the Micmac Indians of eastern Canada were noted by Marc Lescarbot in 1606.\nBefore the Europeans came, the eastern woodlands were populated by numerous tribes with similar customs. From eastern Canada, Quebec, and New England to the Great Lakes states, they celebrated many of the same moons and seasonal festivals, and ate mostly the same types of game. These varied but slightly from region to region. They often, however, spoke distinct languages in various language groups.\nIndian Legends on the Origins of Maple Syrup\nThere is a common myth, with many tribal variations, that the Creator originally made life too easy for his People, with maple trees having a syrup that flowed year round. One day, Glooskap (this name has many variations) arrived at a village and found it strangely quiet. No children or dogs came to greet him, the gardens were over grown with weeds, and the cooking fires were dead. He found the villagers lying in the maple grove, with the delicious sap running into their mouths from the trees.\nGlooskap had special powers. Using a birch bark bucket, filled with water from lake, he rose above the trees and filled the trees with water until the sap ran thin. Then he encouraged his People of the village with a fiery speech. In this exhortation, he berated them for being lazy, and said as punishment the Creator was going to have the sap run only in the late winter. But, he urged them to take heed that when this happened, they would still be able to enjoy this special sweet, though only at this special time of year.\nAnother legend tells that an Algonquin or Iroquois Indian chief, Woksis, discovered this sweet sap in the following manner. One day, at the time the time of the melting snow, as he prepared to go hunting in a meager season of want and little game, he took his ax out of a maple tree where he had struck it a few inches into the bark the night before. His squaw happened to have a wooden or birch bark basket underneath, which collected the sap. Thinking that her warrior husband had filled it already with water, the squaw Moqua used the sap to cook some meat, most likely venison, though one source says moose meat. Upon his return, he was surprised by the sweet odor of the cooking meat. When eaten, the meat was sweet. They soon realized that this sweetness came from the sap of the maple tree.\nWhile details are sketchy, this evolved into an annual festival of sorts, celebrated in traditional ways by the Onondagas in Central New York as recently as the 1940s. While this time of year was usually called the Worm Moon, some tribes began to call it the Maple Moon.\nSoon they began to have a maple festival to celebrate this sweet that was available only during this time of change from winter to spring. Maple sap and syrup became a major source of sweetening, rivaling honey. Both of these sweets were an important food to the Iroquois., comprising about 12% of their diet.\nIndian Methods of Sap Collection and Syrup Production\nLacking metal working capabilities prior to the European contact, the Iroquois methods of obtaining and evaporating the sap were crude. They hacked or gouged the tree with hatchets or axes, which often killed the tree. They used bowls, of ceramic or white birch bark to collect sap. Different bowls of pottery or wood, usually troughs of hollowed out trunks, were used for boiling the sap. They placed hot stones from the fires into the containers of sap. This brought the sap to a boil. The hot stones were periodically replaced to continue the process. Occasionally, if conditions were ideal, they froze the sap, peeling off the frozen surface daily. They threw away the ice and ate the residue underneath.\nMaple season was fleeting and unpredictable, and it remains so to this day. High quality syrup production requires warm days to about 45 F or so alternating with nights below freezing. If days are exceptionally warm, or too many nights remain above freezing, the quality of the sap collected and the syrup produced suffers. There are large variations of the sap run, from nine days to 57 days, the average being 37 days of collection.\nEuropean Adaptations and Expansion of Maple Production\nDuring the almost two centuries of contact the Iroquois and Algonquins had with the French, English, and Dutch, the Europeans learned about this maple production, and started to make improvements with their superior technologies. The fickleness of nature cooperating by providing sufficiently warm days and sub-freezing nights resulted in the attempts at moving maple syrup production into Virginia by Thomas Jefferson and Benjamin Rush, among others, to be modestly successful at best, and finally abandoned. Maple production was much better quality and more reliable in New England, New York, and Quebec. While maple syrup production has occurred at one time or another in some 30 (present) US states, it was, and is, more common and of better quality in the north.\nBy the time of American Independence and subsequent dispersal of most of the Indians from the northeast, the Europeans had evolved methods of improved production of the maple sap and its sweet products that only very gradually changed over the next century and a half. It became a northeastern tradition of the short transitional season between winter and spring that provided a sweet loved by most Americans to this day.\nThe Maple Weekends in March in New York that have become increasingly popular in recent years owe their existence to the accidental discovery of this tasty treat by an Indian chief several centuries ago. As such, it is an important part of our historical heritage, as well as the specific natural conditions in our region that make it possible.\nReferences - Books\nLawrence, James M., and Martin, Rux. Sweet Maple: Life, Lore & Recipes From the Sugarbush. Shelburne, Vermont: Chapters Publishing Ltd., 1993. Co published by Vermont Magazine, Montpelier, Vermont, 1993.\nKlees, Emerson. Legends and Stories of the Finger Lakes Region. Rochester, NY: Friends of Finger Lakes Publishing, 1995\nSchery, Robert W. Plants for Man. Englewoods CLiffs, N.J.: Prentice-Hall, Inc., C.1952, 4th printing 1959.\nThe Old Farmers's Almanac, editions for 2008, 2009, 2010. Yankee Publishing, Dublin, NH.\nReferences - Internet\nThe Natural world Full Moon Names and Dates\nWakarusa (Indiana) Maple Syrup Festival\nOne Iroquois Legend\nA Sure Sign of Spring in New York State\nMaple Syrup production is largely restricted to the northeastern United States and eastern Canada. This is the natural range of sugar and black maple, the two most commonly tapped species. Silver and red maple sap is higher in water content and provides a poorer quality end product.\nThere is little doubt that the Iroquois and other woodland Indians knew about the maple sap. There are several legends of just how they discovered this sweet, an important seasonal addition to their diet. As they lacked metal tools prior to European contact, their means of collection and refining maple sap were crude.\nThe European settlers gradually improved upon Indian methods of collecting and refining sap in many ways. These evolved into \"traditional\" ways of producing syrup that were pretty standard for perhaps a century or more. Only in the latter half of the 20th century did most producers go \"hi-tech\" in production methods that are commonly used today. However, some small producers and museums still produce small amounts of syrup using largely pre-mechanized methods. This is largely for the benefit of tourists and visitors, placing the methods of production in historical context.\nMaple Producers and Festivals in New York State\nNew York State is the second leading producer of maple syrup, second only to Vermont. According to statistics from the New York State Maple Producers Association, about 1500 producers statewide, with nearly 1.5 million taps made 332,000 gallons of syrup in 2008. The average cost per gallon of finished syrup was $33.50 in 2007. The final value of the crop was about $7.5 million, with an impact of $30 million on the New York State economy.\nAccording the published statistics in the Utica Observer-Dispatch of March 18, 2009, maple syrup production in selected counties was as follows in 2005:\nOneida County: 32 producers with 2,100 gallons of syrup.\nHerkimer County: 19 producers with 1,400 gallons of syrup.\nLewis County: 141 producers with 30,000 gallons of syrup.\nMany small maple sugar producers have in recent years had small scale maple festivals at this time of year. Producers and historical museums often sponsor special events and demonstrations. The Farmer's Museum in Cooperstown has Sugaring Off Sundays, with breakfast (pancakes and maple syrup, of course) and maple syrup production demonstrations. The Herkimer Home outside Little Falls had its 34th annual maple celebration on the first weekend in April 2009. Other museums or producers have had such programs usually in late March and early April.\nNew York State Maple Producers Association.\nWhat began in the late 1990s as a one day event promoting maple products by a small group of Wyoming County maple producers has evolved into a festival celebrated across New York State. This effort has been coordinated by the New York State Maple Producers Association. Over 100 large and small producers from over 40 counties participate on the last two weekends in March. Typically, there are pancake breakfasts, sales of syrup and candy, and demonstrations on past or current production methods. A list of participating producers is available from their web site listed in references below.\nWith this regional agricultural product, the maple industry in New York State is on the verge of expanding quite rapidly. Such coordination of an industry that is historically and commercially important is important to its success as an industry. If people in this area are committed to promoting tourism, whether to local residents or outside visitors, this is a model to be studied as largely successful in the general field of local agriculture.\nThere is discussion of local maple producers banding together even more and forming a cooperative in Northern New York for bottling and packaging of their maple products. This would provide the largely rural maple producers a more effective means of getting their products to market, as well as providing jobs to an area with limited employment.\nThe American Maple Museum\nIn Crohgan, New York (northeast of Lowville on State Route 812), this museum is one of the few maple oriented places that is open outside of maple sap season. The museum presents one of the largest collections of vintage equipment used in maple production over the years. They open Memorial Day to late June on Friday, Saturday and Monday, and daily except Sunday July 1 to around Labor Day. Their web site is a good source of information on all aspects of historical and current maple sap collection and processing.\nThe maple industry in New York State is on the verge of tremendous expansion. If such a cooperative comes into existence, it could expand the impact of maple sugar products on the local and regional agricultural economy. In any event, the maple sap season of late February to mid April is a seasonal activity which clearly marks the transition from winter to spring in the Upper Mohawk Country of New York State.\nNew York State Maple Producers Web Site, Maple Weekend http://www.mapleweekend.com/index.html\nUtica Observer-Dispatch, March 18, 2009\nMaple Museum, Croghan\nLawrence, James M., and Martin, Rux. Sweet Maple: Life, Lore & Recipes From the Sugarbush. Shelburne, Vermont: Chapters Publishing Ltd., 1993. Co published by Vermont Magazine, Montpelier, Vermont, 1993\nDISCLOSURE OF MATERIAL CONNECTION: The Contributor has no connection to nor was paid by the brand or product described in this content."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:f5e148a3-e8b9-4109-b1ae-b668b80f4db7>","<urn:uuid:2f6f3abd-3f65-49a8-8fda-8fb7eecf0a4c>"],"error":null}
{"question":"Can you compare the year of establishment between the Distinguished Service Medal (DSM) and the Austrian Officer's Military Service Decoration II Class?","answer":"The Distinguished Service Medal was instituted on October 14, 1914, while the Austrian Officer's Military Service Decoration II Class was established earlier, being issued from March 12, 1890 until 1918.","context":["With this blog I am going to continue the discussion of the Austrian and Austro-Hungarian officer service crosses. In this blog I will commence the discussion of the Officer’s Military Service Decoration, second class (Militärdienstzeichen II Klasse für Offiziere) which was issued from 1890-1918.\nDate Issued: March 12, 1890 – 1918\nReason Issued: From 1890 until 1913 to reward officers of the Austrian army and navy who had served forty years of active service in a faithful and honorable manner. After August 7, 1913 the cross was given to reward officers of the Austrian army and navy who had served thirty-five years of active service in a faithful and honorable manner\nClasses or Types: This cross was issued in one type.\n- Only the highest grade of the service cross which had been earned could be worn.\n- In the early crosses the eagles are more gothic in design, they have a more lightly feathered body and longer necks and tails.\n- Crosses with mother of pearl or Tortious shell reverse were privately made. The mother of pearl or Tortious shell prevented the brass of the cross from discoloring the uniform (Austrian full dress for many officers was white)\n- In 1890 it was determined to reverse the title of the military service crosses. Thus the crosses for the most years served became the first class and the other classes were arrayed below it in descending order.\n- Time in service was counted toward receipt of this award in two ways: piece time service was counted one year for one year, during a military campaign each year of service was counted as two years.\n- Officers who served more than forty years received a pension equal to the salary they drew upon retirement.\n- As of 19 November 1917, in addition to the officers of the army, military doctors were now entitled to the second class officer’s service decoration.\nHallmarks: None known\nDesign: A clawed cross in the Leopold style with arms that widen toward the ends. The cross has a loop or stylized wedge shaped eye at the top to which is attached an oval ring for attaching the cross to the ribbon.\nObverse: A cross with a finely granulated surface and raised edges. The edges of the arms of the cross are tapered. The arms of the cross have a 2 mm raised smooth edge. The inner portion of the raised edge is of black enamel, which follows the contour of the cross. In the center of the cross is a gilt double-headed imperial eagle. Above the eagle heads is the imperial crown. In the right talon is a sword and in the left an orb. On the breast of the eagle is the Habsburg coat of arms. Below the coat of arms is the chain of the Order of the Golden Fleece.\nReverse: The reverse of the cross is usually plain. It may, however, have decorative element, a mother of pearl finish or an inscription if it is a presentation cross.\nWeight: 13.7 grams\nSize: 34-35 mm in diameter\nType of Material:\n- Gilded silver with an attached gilt eagle\n- Gilded silver with an attached gilt eagle and a mother of pearl reverse\n- A zinc cross with a bronze center eagle\nVariations: There are several variations of this decoration:\n- Type I decoration: as described above\n- Type II decoration: A zinc cross with a bronze center eagle\n- Type I obverse: As described above\n- Type II obverse: As described above except that it has a roman style eagle with the individual eagle heads on the obverse of the cross crowned\n- Type I reverse: As described above with the following exception: it has a rivet in the center for attaching the eagle to the cross\n- Type II reverse: As described above with the following exception: The reverse is sheathed in mother of pearl\n- Type III reverse: As described above with the following exception: The reverse is sheathed in mother of pearl with an inscription\n- Type IV reverse: The reverse is plain metal\n- Type V reverse: The reverse is plain metal with an inscribed dedication\n- Type VI reverse: The reverse is decorated with a fine inscribed line which follows the contours of the arms of the cross\n- Type VII reverse: The reverse is decorated with a fine inscribed line which follows the contours of the arms and the center medallion of the cross\n- Type VIII reverse: The reverse of the arms are decorated with a beaded line that follows the contour of the medal and has a finely pebbled area within the beaded design. The reverse center medallion is round and plain.\n- Type I suspension: As described above\n- Type II suspension: A stylized wedge shaped eye\n- Type I eagle: As described above\n- Type II eagle: A roman style eagle with the individual eagle heads on the obverse of the cross crowned\nDesigner: After 1908 Josef Zimbler\n- Hauptmunzamt Wien (Imperial Mint, Vienna)\n- Josef Zimbler of Vienna\nNumber Issued: Between 1890 and 1918 approximately 6,200 second class crosses in their various incarnations were awarded.\nHope you enjoyed this blog. Until next time when I will continue my description of the Officer’s Military Service Decoration, second class 1890-1918, I hope you find joy in our shared interest","During both world wars there were several types of decoration for gallantry or efficient service which could be awarded (as there still are today). These awards were always later published in the London Gazette, sometimes with a citation detailing the reasons for the award. The receiver was then entitled to use the post nominal letters of that award after their name. For ease of reading, I have split the awards to men and women from each of the three counties up, and these are also split into categories: Pre WW1, WW1 and WW2. Among the numerous awards received by men and women from West Wales are:\nThe Victoria Cross (VC) is the highest military decoration which is, or has been, awarded for valour \"in the face of the enemy\" to members of the armed forces of various Commonwealth countries, and previous British Empire territories. It takes precedence over all other orders, decorations and medals. It may be awarded to a person of any rank in any service and civilians under military command. It is usually presented to the recipient, or their next of kin, by the British monarch during an investiture held at Buckingham Palace, or by the Governor-General for awards made by other Commonwealth countries. It is the joint highest award for bravery in the United Kingdom with the George Cross, which is the equivalent honour for valour not in the face of the enemy.\nThe Distinguished Service Order (DSO) was instituted on 6 September 1886 by Queen Victoria in a Royal Warrant published in the London Gazette on 9 November. The first awards were dated 25 November 1886. It is typically awarded to officers ranked Major (or its equivalent) or higher, but the honour has sometimes been awarded to especially valorous junior officers. 8,981 DSOs were awarded during World War I, each award being announced in the London Gazette. The order was established for rewarding individual instances of meritorious or distinguished service in war.\nThe Military Cross (MC) was instituted in 1914 for commissioned officers of the substantive rank of Captain or below and for Warrant Officers for \"an act or acts of exemplary gallantry during active operations against the enemy on land to all members, of any rank …\"\nThe Distinguished Flying Cross (DFC) was instituted on 3 June 1918, shortly after the formation of the RAF. It was originally awarded to commissioned officers and to Warrant Officers. During the Second World War it was also awarded to Royal Artillery officers serving on attachment to the RAF. Since the Second World War, the award has been open to army and naval aviation officers and since 1993 to other ranks as well.\nThe Distinguished Conduct Medal (DCM) was instituted in 1854, during the Crimean War, to recognise gallantry within the other ranks. The medal was the other ranks' equivalent of the Distinguished Service Order when awarded for bravery to commissioned officers, although it ranked well below that order in precedence. Many holders of the DCM were originally recommended for the VC, but had their recommendations downgraded.\nThe Distinguished Service Medal (DSM) was instituted on 14 October 1914 as the 'Other Ranks' equivalent to the Distinguished Service Cross, which was awarded to commissioned officers and Warrant Officers in the Royal Navy, although it ranked below that decoration in order of precedence, between the George Medal and the Military Medal.\nThe Military Medal (MM) was established on 25 March 1916. It was the other ranks' equivalent to the Military Cross, which was awarded to commissioned officers and Warrant Officers (although WOs could also be awarded the MM), although it took precedence below that decoration as well as the Distinguished Conduct Medal, also awarded to non-commissioned members of the Army. Recipients of the Military Medal are entitled to use the post-nominal letters \"MM\".\nThe Meritorious Service Medal (MSM) was first instituted for the British Army in 1845. To be awarded the MSM, an individual must have \"good, faithful, valuable and meritorious service, with conduct judged to be irreproachable throughout\". Other ranks must have at least twenty years service, must already hold a Long Service and Good Conduct Medal, and for the Army and the Royal Air Force must have reached the equivalent rank of sergeant. Officers of any service can also be considered for the medal immediately after being commissioned, provided they meet the other criteria, but not later.\nMention in Despatches (MID) is purely what the name suggests, a mention in the official despatches sent back to by a General which chronicle events during the war. Being 'mentioned' allowed the recipient to use the letters MID after his or her name, and is a well respected honour.\nThe Most Excellent Order of the British Empire is an order of chivalry which was established by King George V on 4 June 1917, and is composed of five classes in civil and military divisions. In descending order of seniority, these are:\nKnight Grand Cross or Dame Grand Cross of the Most Excellent Order of the British Empire (GBE)\nKnight Commander or Dame Commander of the Most Excellent Order of the British Empire (KBE or DBE)\nCommander of the Most Excellent Order of the British Empire (CBE)\nOfficer of the Most Excellent Order of the British Empire (OBE)\nMember of the Most Excellent Order of the British Empire (MBE)\nThere are several other decorations, but for a full and comprehensive listing please see the Wikipedia page on Orders, Decorations and Medals of the United Kingdom.\nTo read details of the known gallantry awards received by men and women from Ceredigion, Carmarthenshire and Pembrokeshire, please visit the links to the left of this page.\nDONATIONS. If you find this website of use, please think about donating to help cover the costs of the huge amount of work and the continual costs of keeping the website on-line. Donations can be made using the Paypal link below, or by contacting the author via the Contact page.\n4 May 2017. Welcome news this morning that a new CWGC headstone has been erected in Laugharne for Domingo Mobile, a sailor who I found to be buried there a couple of years ago. Please see the Forgotten Soldiers section of the website for further details.\n8 March 2017. Some more good news today. Another un-commemorated Welsh sailor, Samuel Arthur Griffiths, of Tredegar, has today been accepted for commemoration by the CWGC as a result of my research. Please see the Forgotten Soldiers section of the website for further details.\n8 February 2017. Some more good news today. Another un-commemorated soldier, Llewelyn Owen Roberts, of Penmaenmawr, has today been accepted for commemoration by the CWGC as a result of my research. Please see the Forgotten Soldiers section of the website for further details.\n7 February 2017. Some more good news today. Another un-commemorated soldier, Isaac Owen, of Seven Sisters, has today been accepted for commemoration by the CWGC as a result of my research. Please see the Forgotten Soldiers section of the website for further details.\n20 December 2016. Some good news today that another uncommemorated soldier, Private Thomas Owen Davies, of Machynlleth, has been accepted for commemoration by the CWGC following my research. Please see the Forgotten Soldiers section of the website for further details.\n23 November 2016. Some good news today with the acceptance of another Welsh soldier, Percy Griffin Williams, of the Welsh Horse Yeomanry, for commemoration by the CWGC following my research. Please see the Forgotten Soldiers section of the website for details.\n15 November 2016. I would like to thank the people of Laugharne, especially the members of the Laugharne and District Historical Society, for their welcome during their recent History Event on Saturday when I visited to make a talk about how researching the Laugharne War Memorial inspired me to create this website and to begin my writing career. It was a very interesting day and was well attended by the locals.\n26 Sep 2016. After a lot of hard work I have finally managed to identify a soldier from Gwaun-cae-Gurwen, Morgan Price James, who since the early 1920’s has been commemorated by the CWGC under the wrong name, James Morgan. Please see the Forgotten Soldiers section of the website for details."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"}],"document_ids":["<urn:uuid:cb573e42-cf37-4d8b-bc56-a37d5c677816>","<urn:uuid:acfea126-3f02-49d3-8c87-c452d6d54b15>"],"error":null}
{"question":"Can u explain why OFDMA is important feature in WiFi 6??","answer":"OFDMA (Orthogonal Frequency-Division Multiple Access) is important because it greatly improves efficiency by dividing channels into sub-channels called Resource Units (RUs), allowing multiple devices to use subcarriers simultaneously. This shows more than 4x improved throughput compared to Wi-Fi 5 in densely deployed environments. While downlink OFDMA is required for Wi-Fi 6 certification, uplink OFDMA remains optional.","context":["In branch locations, exciting new Wi-Fi standard calls for higher-speed routers\nWi-Fi use continues to grow, and users ranging from restaurant guests to office employees expect a good experience everywhere. High-bandwidth applications such as streaming video and Wi-Fi video calls require high capacity and low latency, and the explosive growth of a new generation of IoT devices will also add to the crowded wireless space. In light of all this, the emergence of Wi-Fi 6 — and routers that support it — is important.\nWhat is Wi-Fi 6?\nWith the introduction of IEEE 802.11ax, the Wi-Fi Alliance also announced a new label to help end users understand the dizzying array of Wi-Fi technologies. Rather than describing each new Wi-Fi release with the IEEE standards name, a simpler generational name will be used.\n- Wi-Fi 1: 802.11b — The original Wireless Ethernet standard\n- Wi-Fi 2: 802.11a — The first Wi-Fi in the 5 GHz bands\n- Wi-Fi 3: 802.11g — Higher speeds than 802.11b\n- Wi-Fi 4: 802.11n (aka HT) — Still faster speeds, now in both 2.4 and 5 GHz bands; MIMO introduced\n- Wi-Fi 5: 802.11ac (aka VHT) — Multi-gigabit Wi-Fi, but only the 5 Ghz band; MU-MIMO introduced\n- Wi-Fi 6: 802.11ax (aka HE) — The newest generation of Wi-Fi, with emphasis on efficiency\nEach new Wi-Fi generation strives to be backwards compatible with the previous generation. Clients using older standards are still supported; however, older clients are slow, ponderous users of precious airtime and should be phased out in favor of newer, higher-speed devices. Newer standards are more power friendly as well.\nEfficiency of Wi-Fi 6\nWhile Wi-Fi 5 (802.11ac) focused on using more bandwidth, Wi-Fi 6 (802.11ax) focuses on using the existing bandwidth more efficiently. Wi-Fi 6 is also called HE (High Efficiency) to reflect its focus on better usage of existing spectrum. Multiple enhancements to the physical layer increase the amount of data that can be in the air, and improvements in sharing the air with other equipment make better use of the available bandwidth.\nWi-Fi 6 requires new hardware to support its features. However, a router can support Wi-Fi 6 and be backwards compatible with the previous generations of Wi-Fi. Wi-Fi 4 and 5 clients can connect to a router with Wi-Fi 6 enabled, with no disruption to new Wi-Fi 6 clients.\nUnlike Wi-Fi 5, which only supported the 5 GHz bands, Wi-Fi 6 is supported in both the 2.4 GHz and 5 GHz bands. IoT devices are expected to adopt Wi-Fi 6 in the 2.4GHz bands especially for its power saving features.\nSmall packet sizes are common in Wi-Fi client traffic, with most traffic featuring packets less than 256 bytes. Wi-Fi 6 will noticeably improve time/latency sensitive applications as well as “chatty” applications with smaller packets by using OFDMA (more on OFDMA later).\nQuadrature Amplitude Modulation (QAM) and is the coding of bits into radio signals. Each dot in the images below represents a pattern of bits. The more dots possible, the more bits can be represented simultaneously.\nAdding 1024 QAM gives a 25 percent increase in data rate. With 256 QAM, we could encode 8 bits per symbol. 1024 QAM increases to 10 bits per symbol. The higher density symbol rate requires better air quality, so clean air providing high signal quality is now more important than ever.\nSOURCE: Michael Bernhard, Institute of Telecommunications, University of Stuttgart\nBandwidth of Wi-Fi 6\nWi-Fi 6 supports increased bandwidth of 80+80 and 160 MHz. The 80+80 is two 80 MHz channels that can be separated by other bands. The 160 is a single wide band. Wi-Fi 6 also has a \"hole punching\" capability which will exclude contentious 20Mhz bands within the larger bands. Previously, if the AP detected interference anywhere in the channels that made up the 80+80 or 160 bands, the AP would drop back down to a narrower width. With Wi-Fi 6 hole punching, only small parts of the large band will be removed.\nValue of OFDMA\nThe most exciting development in Wi-Fi 6 is Orthogonal Frequency-Division Multiple Access (OFDMA). In current generations of Wi-Fi, data frames have been transmitted consecutively. Each device contends for the medium and, when seized, the medium is held exclusively by that device. Between each transmission, all devices obey a SIFS (Short Inter-Frame Spacing) and a contention period. The contention period allows devices to listen for another device claiming the medium; contention time is lost time during which the medium could have been used.\nIn OFDMA, a channel is divided into sub-channels called Resource Units (RUs). An RU is a group of subcarriers. Multiple devices can use the subcarriers simultaneously.\nVisualize a restaurant dining room. The kitchen is the AP, and the tables are wireless clients. With Wi-Fi 5, the focus was to get as much data to the client as possible, but the communications were serialized. Imagine a single waiter, running back and forth from the kitchen to the tables. The waiter has a large tray and wants to serve as much food to one table as possible, so the diners at that table may receive all courses of their meal at once. With Wi-Fi 6, the focus is to use the spectrum efficiently, by sending data to multiple clients, and allocating the amount of data based on need. In this situation there are multiple waiters that leave the kitchen at the same time. Each waiter has smaller trays (because the kitchen can only produce food at a fixed rate), so they only provide each table with one course at a time. However, more tables get food on a more consistent basis.\nDownlink OFDMA, an AP sending to a station, is required for Wi-Fi 6 certification. Uplink OFDMA, a station sending to an AP, is optional. OFDMA shows more than 4x improved throughput vs 802.11ac in densely deployed environments. Future updates to the Wi-Fi 6 specification may provide OFDMA on the uplink as well as downlink.\nSending More Data with 8x8 Spatial Streams\nWi-Fi 5 (802.11ac) introduced 4x4 spatial streams. Wi-Fi 6 is expanded to eight spatial streams officially (Wi-Fi 5 unofficially supported 8x8). Multiple Input Multiple Output (MIMO), combined with spatial multiplexing, allows more data to be sent in each transmission by sending different data on each spatial stream. Each spatial stream requires an additional antenna and additional transmit/receive chain, and thus adds to expense but increases reliability and data throughput. A 2x2 MIMO system would have two radio chains for receive and two for transmit. A 4x4 would have four and an 8x8 would have eight antennas, thus making an 8x8 router officially classified as an arachnid.\nIn previous power saving states, the station would signal to the AP that the station is going into a sleep mode. The AP would cache the packets addressed to that station. The station would need to wake periodically to check if the AP had traffic. The Traffic Indication Map (TIM) is part of a beacon, so each sleeping station would need to wake every so often to receive a beacon to check if there was pending traffic.\nThe Target Wait Time (TWT) is much more battery efficient. The station tells the AP when the station will wake up. The station no longer needs to periodically wake to listen for the AP’s beacon. By putting the station in charge, the station can stay asleep longer and preserve battery life. This battery-preserving feature will be a boon to future generations of IoT. The 802.11ax TWT was leveraged from 802.11ah.\nCo-channel interference (CCI) is when multiple APs are sharing the same channel. CCI reduces efficiency because the APs must defer transmitting until certain other devices aren’t using the channel, a process called clear channel assessment (CCA). That deferral is wasted time — time that could have been better spent sending actual traffic to clients.\nBSS coloring is another innovation from IEEE 802.11ah that was adopted into Wi-Fi 6. With BSS coloring each basic service set (BSS) is assigned a color, and all APs participating in one BSS are assigned the same color. (There is an automatic process to determine unique color and to recover from color collisions.) When an AP is ready to transmit, it first listens for other transmitters on the air. If the AP hears another frame, it will check the color. If the color is the same as the AP itself, the transmission is fully deferred the usual time. If the color is different than the AP and the signal strength of the frame is below a certain threshold, the radio can transmit; if the signal strength is above that threshold, the radio will defer the usual time.\nGoing back to the restaurant analogy from the OFDMA section, imagine each BSS is a table. The restaurant itself is the shared spectrum. Each person at the table is chatting with others at their table. The table has the color. During the conversation at their table, a person feels free to speak over someone at another table, if their voice is low enough. But it would be rude to speak over someone at your own table.\nBSS coloring will also help improve battery life because a radio could stop decoding a received frame with a color not matching its own. The radio only needs to wake long enough to receive the few leading bits from the frame header, then can return to sleep.\nImproving Security with WPA3\nWPA3 is a new authentication mechanism and is likely one of the best new features of Wi-Fi 6. The WPA2 preshared key authentication protocols have come under cryptographic attack and are vulnerable to brute force attacks on weak passwords. WPA3 uses an improved mutual authentication mechanism, Simultaneous Authentication of Equals (SAE), which has better protection against brute force attacks.\nWPA3 now requires Protected Management Frames (PMF). Certain management frames are vulnerable to spoofing, allowing a malicious actor to forge those management frames to disrupt the network. PMFs are not new and have been a feature since 802.11w. However, WPA3 now requires PMF to be enabled. In order to pass the Wi-Fi 6 certification, WPA3 support is required, so greater security is now enforced by the certification itself.\nClients Supporting Wi-Fi 6\nClients supporting Wi-Fi 6 have been slowly rolling out the last two years. The Samsung S10 was the first Android phone with Wi-Fi 6. The iPhone 11 also supports Wi-Fi 6. Intel’s AX200 chipset ships in most new laptops and has very good Wi-Fi 6 support. For a full list of clients, visit wi-fi.org/product-finder.\nWPA3 support does not require new hardware and is supported in Windows 10 with the 1909 update. Apple Mac OS and iOS also support WPA3.\nCradlepoint Router Support for Wi-Fi 6\nThe first generation of Cradlepoint routers supporting Wi-Fi 6 is rolling out now. DL-OFDMA is supported, which will help in the crowded wireless environments of today’s offices and retail spaces. The higher speeds of 1024 QAM will greatly benefit bandwidth-intensive applications (large file transfer or video, for example). The extra security of WPA3 will increase peace of mind."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"}],"document_ids":["<urn:uuid:bdd88d14-5e35-4496-aa19-bf6bda68ae3b>"],"error":null}
{"question":"As a graduate student in biostatistics, how do the data collection approaches compare between epidemiological studies and genetic selection research?","answer":"In epidemiological studies, data collection typically involves purposeful collection with sample sizes ranging from tens to hundreds of thousands of subjects, often through specifically designed studies. In genetic selection research, the data collection process is focused on tracking fitness and reproductive outcomes across generations, with particular attention to the frequency of specific alleles in populations over time. The effectiveness of the data collection is measured differently - epidemiological studies aim to gather enough data to study risk factors and disease outcomes at an aggregate level, while genetic selection research requires data that can demonstrate changes in allele frequencies and relative fitness differences between genotypes across successive generations.","context":["Having started as an economist and then transitioned into data science, I’ve been very interested in how to a) teach data science to economists, and b) what the disciplines can learn from each other.\nA few weeks ago, I was assisting with some training (with Data Science Dojo) on behalf of the World Bank in Bucharest. The participants were mostly ministry of health employees from South America and Eastern Europe with a few externals too. With our usual bootcamps, the participants are mostly analysts or software engineers whereas the Bucharest participants were from more of an academic background, mostly epidemiologists and economists. I could see the objection forming on the lips of the economists “but it’s not causal!” And I could hear a few mumblings from the epidemiologists when it came to discussing precision and accuracy. To avoid too much confusion over false friends and discipline sub-cultures, I put together two tables: one comparing economics / traditional statistics to predictive analytics, and another comparing epidemiology to predictive analytics. Epidemiology isn’t my discipline but I had a little help from my friends (thanks Lizzie and Rosie!) and a doctor / epidemiologist on the course.\nEconomics / Traditional Statistics vs Predictive Analytics\n|Traditional Statistics||Predictive Analytics|\n|Terminology||Independent Variables / Predictor\nDependent / Outcome Variable\nModel = algorithm (+ parameters)\nModel = algorithm + parameters + data\n|Focus||Causal estimation – unbiased estimates of a treatment effect||Prediction of an overall outcome|\n|Data||Often deliberate data collection (own or national surveys)||More likely to use data collected in everyday operations|\n|Algorithm Choice||Depends on the data you have (e.g. time series, instrumental variable)||Considers performance on prediction. Also considers interpretability and computing time.|\n|Approach for choosing variables||Focus is to get unbiased estimates so can include IDs, time dummies etc.\nMore theoretical approach to choosing control variables. Check significance of adding individual feature.\n|Focus is performance on unseen data so can’t include IDs and time dummies.\nInclude all but then prune back according to how much extra predictive power the feature adds.\n|Evaluate model||Test for broken assumptions. Test for significance of added features.||Look at the mean and standard deviation of multiple estimations of predictive performance.|\n|Avoidance of overfitting||In an ideal scenario, pre-registering our hypotheses.||Test the model’s predictive performance on unseen data.|\n|Example||Which drug works to treat the malignant tumours?||Is the tumour malignant?|\nEpidemiology vs Predictive Analytics\n|Terminology (False friends!)||Accuracy (estimate represents the true value)\nPrecision (similar results achieved with repeated measurement)\nBias (systematic source of error; source: selection or information)\n|Accuracy (model evaluation metric)\nPrecision (model evaluation metric)\nBias (systematic source of error; source: overfitting model to training data)\n|Focus||Risk factors and disease outcome\nPredict disease incidence at the aggregate level\n|Prediction of an overall outcome\nPredict at the individual level\n|Data||Often purposeful collection (10s – 100,000s)||More likely to use data collected in everyday operations (100s – billions +)|\n|Algorithm Choice||Depends on the data you have (independent – Cox regression, Kaplan-Meier survival analysis) or not (linear, logistic, hierarchical)).||Considers performance on prediction. Also considers interpretability and computing time.|\n|Approach for choosing variables||Theoretical approach – research questions, is biological mechanism plausible for main effect and control variables? Use causal diagrams.||Focus is performance on unseen data so can’t include IDs and time dummies.\nInclude all but then prune back according to how much extra predictive power the feature adds.\n|Evaluate model||Look at the significance of the coefficient on the variable.\nLook at the confidence intervals around the coefficient.\n|Look at the mean and standard deviation of multiple estimations of predictive performance.|\n|Avoidance of overfitting||Test the model’s predictive performance on unseen data.|\n|Example||Assess odds ratio of lung cancer in smokers vs. non-smokers||Is the tumour malignant?|\nSome of the differences are pretty superficial – different terminologies for the same concepts or the same terminology for different concepts. Some were due to more fundamental differences in focus, for example, the economists caring more about whether a particular policy caused a particular effect whilst data scientists (in predictive analytics) caring more about the overall predictive power of the model. This then translates into different data – if you really care about identifying a causal estimate, often that means paying to set up a study and collect detailed data with a small number of people. Here the decision is often pretty binary ‘should we roll out this policy?’ and at a high level (e.g. making a decision on behalf of an entire borough or even nation). If you’re more interested in how to personalise the decision for each individual that you interact with, then you may have millions of decisions to make and your model needs to give an appropriate answer (which may be different) for each of them with the data available in the course of everyday operations (as a survey to every individual would be unfeasible!). Because you’re most interested in obtaining an unbiased estimate on the variable of interest in an economics study, you can bring in other control variables which would never get included in a predictive analytics model, for example, fixed effect and time dummies. In economics, panel techniques are a wonderful trick to control for unobserved variation but in predictive analytics including such variables would be akin to cheating as you’re not necessarily going to have to predict on the same individual.\nSo there are definitely good reasons to do with the focus of each discipline to explain the techniques diverging. There are, however, some parts where I think the disciplines could learn from each other. Two aspects of a recent freelance project I completed illustrates this quite well I think. I was helping a membership company encourage its members to renew their subscription.\n- Combining techniques: A colleague had previously built a predictive model to better identify members whose subscriptions were coming up for renewal but were at risk of terminating their membership. This helped the sales team focus their efforts on those they were at risk of losing. (Of course, it would be even better if we could create a model to predict those who were at risk of not renewing but would be responsive to a call but we needed slightly different data for that!) I then used panel techniques (which come from econometrics) to try to get closer to a causal estimate of what contributes towards the average member renewing their membership. Combining the techniques more commonly confined to different disciplines allowed us to target who and then have a somewhat better idea of what might encourage these individuals renew their membership.\n- Holdout data: for the model trying to understand what contributes towards a member renewing, I withheld a proportion of my data to test the model against. Usually, in predictive analytics, because the focus is predictive power, the model is evaluated on how well its predictions perform on this unseen ‘holdout’ dataset (e.g. accuracy, precision etc, or more familiarly for economists, R squared). However, because I was more interested in getting unbiased estimators on the possible ‘treatment’ variables, the overall predictive power matters less. (Some phenomena are just difficult to explain with the amount of data available. To give you a sense of this – when I worked on identifying what contributes to wellbeing – often we’d be happy with R squareds within the 0.3 region which would be pretty bad performance if you were trying to predict wellbeing!) Because of this focus on unbiased estimates, I instead looked at the coefficients to see whether they changed significantly when running the same model on this holdout data. I conducted paired t-tests of the coefficients of the models using the original training dataset and the holdout dataset. There was no significant difference at a 95% confidence interval between the paired coefficients. I have heard Spencer Greenberg speaking briefly about the use of holdout data in the field of psychology but couldn’t find too much online about how to best use holdout data helpfully in a different way given the different focus on unbiased coefficient estimation. So I’m very open to discussion on this!\nJust a brief note on sample size and expense – I know one of the restrictions researchers (in economics and other social sciences) work within is budget for data collection. Because the data collection is often tailored for the study in causal estimation studies, it is expensive and there often isn’t the appetite to collect much more than the required minimum sample size to detect the expected effect size due to budgetary reasons. Holdout data is usually about 30% of sample so you’d need to increase the sample size by 42% to get sufficient data to do a training / holdout split. I can definitely see there being pushback on this suggested change in technique because of increasing the cost of data collection for something that the discipline has not so far recognised as important. However, I would argue the added expense is justified. We have already made the decision to try to figure out whether a programme or policy is worth scaling up or continuing and justified the overheads of the evaluation.The additional amount for the data collection is likely to be much smaller than the 42% increase in the sample size as the overheads of the evaluation remain the same (the training and recruitment of data collectors, the data collection itself, the project management and the analysis). Spending a relatively small proportion more would enable us to be much more confident that the results were not purely by chance. The current solution in academia (a slightly different field to economics for impact evaluation) of pre-registering a small number of hypotheses and only researching those feels unsatisfactory in that it restricts us to our current knowledge base at the time of proposing the study and does not do justice to the exploratory nature of the research process. We often have a much better understanding of complex phenomena after exploring the data. Trying to solve overfitting through pre-registration means that we have to commission further studies to explore the insights we picked up in exploring the data we already have. Holdout data acts as another dataset to test those explorations.\nI find it fascinating that these sub-cultures of using statistical techniques in slightly different ways have developed in different disciplines and would be very interested in talking more to people from these different disciplines to see what we can cross-fertilise!","The aim of selection is to increase the frequency of desired alleles and decrease the frequency of undesired genes in a population, ideally producing animals that breed true for the genotypes and phenotypes selected for.\nOne influence on the effectiveness of selection on gene frequency changes is the initial gene frequency in a population. Consider two alleles at locus A: A1 is wanted and A2 is not. This graph plots the frequency of A2 in each successive generation, showing the effect of selection against that unwanted allele A2 over many generations:\nThe steeper the slope of the line, the faster the change in the frequency of A2 from one generation to the next, and the quicker it is removed from the population.\nIn the above graph, A2 exists at a very high frequency at the beginning of the selection programme — it occupies over 90% of the A locus in the entire population. It is a slow process to remove this allele at first, as so many animals carry it. This is shown by the slow-to-get going slope of the line from generations 1 through 5.\nOnce A2 does drop in frequency, A1 by default increases in frequency, and as more and more animals inherit A1, selection against A2 accelerates as more and more A1 alleles in the population become available to select for.\nAnother influence on the effectiveness of selection on gene frequencies is the fitness of individuals within a population. ‘Fitness’ is the ability of an animal to have offspring. The fittest animals are those that are not only selected for their genotypes and phenotypes, but which also produce the most offspring with those genotypes and phenotypes.\nConsider the following graph:\nThis is the same graph as above, but with an extra line. Here, the solid line represents large differences in fitness amongst the genotypes of the breeding population. The broken line represents small differences in fitness amongst the genotypes of the breeding population.\nFor the solid line, if A1A1 genotypes are the fittest relatively, A1A2 genotypes may produce only three-quarters as many offspring in comparison, and A2A2 genotypes may produce only half as many offspring as A1A1 again. The differences in fitness are large.\nFor the broken line, if A1A1 genotypes are again the fittest relatively, A1A2 genotypes may produce almost as many — seven-eights perhaps — while A2A2 genotypes may produce three-quarters as many offspring as A1A1 animals. The differences in fitness are small.\nChanges in gene frequencies are fastest when the differences in fitness are largest. This is because the most fit animals — the A1A1 genotypes in this example — produce the most offspring that in turn are selected to produce the next generation of offspring. The more A1A1 genotypes in each generation, the higher the frequency of the A1 allele at the A locus amongst the next generation.\nConsider the extreme case of a lethal allele. Here the fitness difference is very large — homozygous and heterozygous animals with either no or just one copy of the allele survive and reproduce, while homozygous recessive animals with two copies die. Natural selection against that allele is very effective, in that the allele will exist at a very low frequency in the population, and homozygous recessive animals will be rare occurrences.\nCompare that example with a gene responsible for smaller fitness differences — one that has a very small effect on the ability to conceive for example. Even the negatively-affected animals will still grow and reproduce at almost the level of fitness as the unaffected ones. There is very little difference in fitness between the genotypes and the allele will continue in the population with little influence from natural selection on its frequency. It is harder to effect change when there are only small differences in fitness amongst the genotypes.\nNext week will cover the third influence on selection and gene frequency change: the degree of dominance with respect to fitness."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"}],"document_ids":["<urn:uuid:07fa2e40-68bd-462a-82ec-573a99931b4b>","<urn:uuid:abd764f2-9079-4938-a7b2-4866a379f1de>"],"error":null}
{"question":"How does the contemporary reception of The Rite of Spring ballet compare with its controversial 1913 premiere at the Paris Opera, given that the Paris Opera Ballet continues to embrace innovative works in its 2023-2024 season?","answer":"The Rite of Spring's 1913 premiere was met with intense controversy, leading to riots and fistfights in the audience who were shocked by its primitive choreography and complex music. However, today's Paris Opera Ballet demonstrates a complete shift in attitudes, actively embracing innovative and contemporary works. Their 2023-2024 season features cutting-edge choreographers and modern pieces alongside classical ballets, showing how what was once considered shocking is now celebrated in the same institution.","context":["Something different in the works today, which debuted in May of the blissful spring of 1913 We gonna get our “art” music on.\nIgor Stranvinsky – The Rite of Spring\nListen to it here: http://grooveshark.com/#!/playlist/Igor+Stravinsky+Rite+Of+Spring/67058600\nRead about it here: http://en.wikipedia.org/wiki/The_Rite_of_Spring#Premiere\nI do highly suggest reading at least a little about this piece, for quick facts I can tell you this was music to accompany a ballet and\nThe première involved one of the most famous classical music riots in history. The intensely rhythmic score and primitive scenario and choreography shocked the audience that was accustomed to the elegant conventions of classical ballet.\nThe evening’s program began with another Stravinsky piece entitled “Les Sylphides.” This was followed by, “The Rite of Spring”. The complex music and violent dance steps depicting fertility rites first drew catcalls and whistles from the crowd. At the start, some members of the audience began to boo loudly. There were loud arguments in the audience between supporters and opponents of the work. These were soon followed by shouts and fistfights in the aisles. The unrest in the audience eventually degenerated into a riot. The Paris police arrived by intermission, but they restored only limited order. Chaos reigned for the remainder of the performance. Stravinsky had called for a bassoon to play higher in its range than anyone else had ever done. Fellow composer Camille Saint-Saëns famously stormed out of the première allegedly infuriated over the misuse of the bassoon in the ballet’s opening bars (though Stravinsky later said “I do not know who invented the story that he was present at, but soon walked out of, the première.” ). Stravinsky ran backstage, where Diaghilev was turning the lights on and off in an attempt to try to calm the audience.\nWith art music the conductor and the orchestra can make a lot of difference…unfortunately with grooveshark’s labeling system I have had an nearly impossible time giving credit to these performers….I did do an extensive search to find performances from the same group and the “best” one I could find.\n|Igor Stravinsky – Rite of Spring\nLeast favorite track/tracks:\nOverall (1-5 stars): 4\n|Igor Stravinsky – The Rite of Spring: 3 stars…if I have to give a rating\nPrecon: A lot of stuff that’s gonna go over my head, but if I was a music major I might jimp. I was hoping it would at least sound nice, but the more I read about it, the more it seems like a boundary pushing type thing so that’s probably out the window. Oh well, let’s see how it goes.\nFavorite Track: Augurs of Spring\nThis is pretty cinematic, which makes sense. For Augurs of Spring I’m seeing a scary factory scene in an old cartoon. Or maybe a Hitchcock movie.\nMagic the Gathering Card: Rites of Spring\n|Igor Stravinsky: Rite Of Spring\nPreconceived Notions: Classical. Heard of him. Haven’t heard this. Not super excited about it, but since I don’t want to appear as if I’ve been raised by wolves, I should focus my attention. I’d probably rather be watching the ballet.\nWell, after reading the Wikipedia, it turns out I MUST have heard at least part of it because it’s featured in Fantasia…one of my least favorite movies ever.\nI hear a lot of what would eventually become “bastardized” parts of Spielberg soundtracks, so clearly an influence on John Williams. Oh and also a bunch of sound a-like moments to West Side Story, so clearly Bernstein was a fan too. I think Bernstein would have been a huge fan of the oboe’s role in this work. I’m guessing Bernard Hermann was also a fan.\nAfter Listening: I appreciate that each sequence tells a distinct story. I can’t stand when classical pieces just flow together with no clear break. I suppose this is also mostly due to the fact that this was a ballet, and well, you need to tell a story, more often than not, for a ballet to work. It’s an emotionally evocative piece for sure, and, slightly on the dark side, if I’m just going by how I felt listening to it. There’s something ominous about the bass drum and frightening about the combination of trumpets and high-pitched strings. It’s interesting that we’re listening to this work now, days after I’ve seen John Carter because I feel like they’re hampered by the same issue. Both this and Burroughs work are technically “originals”. Or as original as any art influenced by other art/artists can be. And yet, because we’re so much farther along the pop culture scale, I’ve already seen West Side Story, heard Jaws and Star Wars a million times and so, also, cannot help but making the comparison. It’s impossible for me to say whether one of these things is better or more of an artistic accomplishment because they’re kind of intertwined. I’m at least glad to be aware of the originals now. And pleased that I didn’t get as lost in the story as I thought I might. However, if I dream of tutued hippopotami tonight, I’m definitely blaming Igor. On a side note, reading his bio on Wikipedia, I got the same feeling I had when I saw Midnight In Paris. That guy lived a charmed life.\nNo least or favorite tracks, since, if you take one away I’m pretty sure the whole thing suffers. Also, like I said, they all made me feel something, imagine something, so that has to count in the positive column for this.\n|Preconceived Notions: This one is mine, I was trying to introduce the group to “classical” or more accurately in this case “art” music. I know, I know, quit rolling your eyes…I’m just trying to change it up. I had assumed everyone here has at least heard pieces by Beethoven, Mozart, Bach and the like – so there was no need to rehash that. Likewise Wagner, Schubert, Chopin, and even Debussy are highly stylized in their own rights – but similar enough to what I think RC’s general exposure to art music has been. I picked Stravinksy for this little experiment for two reasons 1.) He’s a good transitional composer between highly tonal works (like Beethoven on through the impressionists) and the more atonal guys I like to listen to in the 20th century (Schonberg, Ives, Bartok, etc…), and 2.) because there’s a chance this particular group might identify the beginnings of the modern film score in Stravinsky’s work.\nAfter Listening: We can get into the awesome polyrhythmic devices here, but not in any detail that is really worth going on and on about- if you don’t have that frame of reference. And honestly, I’m worried already that people hear terms like that and think I’m trying to lecture or take on an air of pompousness. I’m not, to describe what’s at the core of this work however, you will have to take a measure of analysis beyond chords and melody lines though. And to avoid writing a novel no one will care about the basic construction of this piece, it is built around the idea that little segments of musical notes are cut up and blasted at you (and then at each other in interplay) in various places in the musical arrangement (for example the infamous oboe opening), while the rest of the supporting orchestra remains very harmonically stagnant. The stagnation creates an unease in the listener who wants the piece to revert to some type of tonal resolution (aka something that sounds “final” or “completed”). For example if you listen to sections like Sacre 1.2 Augurs of Spring you should hear the origins of the theme from Jaws. In other sections of increased tempo Stranvinsky presents some consonant harmonic backing- but it serves to present the segment as frantic – Sacre 1.5 for example has sections that are very reminiscent of Star Wars films. What I’m getting at here is that Stravinsky used a multitude of musical devices to evoke powerful emotions, so much so that many of our contemporary film composers owe him a huge debt for breaking ground with pieces like this. Again a full scale (pun intended) musical analysis of this has been done and done again by people far more qualified in the field than me and my fading concepts of theory…so I’ll stop about here.\nOverall 5.0 It is sort of pointless to break out these sections to rate one over the other, as a whole they were part of an accompanying ballet and presented in audio form only may also be challenging to the listener enough, without parting them out. This is to say, that this music is so vivid and evocative that the ballet or other visual medium (aka the parts of this used in Disney’s Fantasia) helps frame the work for many in a context that’s relatable. We’ve done a lot of concept albums in record club – some with a literal story, some with just the grain of a unifying theme…and to that end “art” music really is the 1st and ultimate concept music. When Stravinksy presented these musical ideas a 100 years ago there were riots in the aisles, nowadays they are employed as soundtracks to popular films. And while one is certainly free to dislike The Rite of Spring, it’s a very good lesson in transitional artists and the evolution of musical ideas. I mean, I dream of the day we as culture toss on a Schonberg composition…and riot over a Bruno Mars show. That’s probably never gonna happen…but ya gotta keep fighting the fight- and if you need marching music for that fight….The Rite of Spring isn’t a bad place to start.\nExtra Credit: The composer himself conducts a piece of Firebird – (which is generally considered a more mature work than Rite of Spring)","The Paris Opera Ballet 2023-2024 season at the Palais Garnier and Opéra Bastille theatres is sure to satisfy both lovers of classical ballet and those who wish to see innovative 20th and 21st century choreography.\nThe full-length ballets – The Nutcracker, La Fille Mal Gardée, Don Quixote, Giselle, and Swan Lake – are joined by programs dedicated to Jerome Robbins and Jiří Kylián, as well as one that features women choreographers; Crystal Pite’s The Seasons’ Canon shares the evening with world premieres by Marion Motin and Xie Xin.\nHighlighting contemporary dance for the Company next season is Ohad Naharin’s Sadeh21.\nParis Opera Ballet 2023-2024 Season Trailer\nParis Opera Ballet 2023-2024 Season Schedule\nOpening Gala | September 21, 2023\n- The Seasons’ Canon by Crystal Pite\n- The Last Call by Marion Motin\n- Horizon by Xie Xin\nOn the stage of the Palais Garnier, the magnificent Défilé du Ballet presents the entire Company. The School’s students join the Étoiles adorned for the occasion in sumptuous tiaras and tutus designed by Chanel.\nThree female choreographers are honored in this Gala with a decidedly contemporary approach. Created in 2016, Crystal Pite’s The Seasons’ Canon is already a classic in the Opera’s repertoire. Marion Motin’s The Last Call and Xie Xin’s Horizon are both first creations for the Company’s dancers.\nXie Xin / Marion Motin / Crystal Pite | September 23 – October 12, 2023\n- The Seasons’ Canon by Crystal Pite\n- The Last Call by Marion Motin\n- Horizon by Xie Xin\nCrystal Pite’s The Seasons’ Canon, which premiered successfully in 2016 at the Paris Opera, is bathed in stormy light. Her overwhelming choreography in “canons” unleashes chain reactions and mirrored movements. Organically swarming human bodies merge with Vivaldi’s string music enhanced by Max Richter’s electronics.\nIn The Last Call, her first creation for the Opera Ballet, Marion Motin tells the story of a phone call that upends a man’s life. Between distortion and vitality, the choreography plunges the audience into a supernatural dimension.\nLastly, Chinese artist Xie Xin signs her first creation for the dancers of the Paris Opera. Her piece Horizon plays on illusions and mirages between natural elements.\nJerome Robbins | October 24 – November 10, 2023\n- En Sol by Jerome Robbins\n- In the Night by Jerome Robbins\n- The Concert by Jerome Robbins\nA fellow traveller of George Balanchine and choreographer of West Side Story, Jerome Robbins is a major figure of American neo classicism. Three of his works in the Paris Opera Ballet repertoire highlight his inimitable blend of lightheartedness and wit.\nSet to the jazzy tones of Maurice Ravel, En Sol is a knowing nod to Broadway musicals in a sunny beach setting.\nIn the lyrical setting of Chopin’s Nocturnes, In the Night places classical technique at the service of a moving narrative. Three couples embody three moments of love: discovery, blossoming and turmoil, against the backdrop of a starry night.\nSubtitled ‘The Perils of Everybody’, The Concert features characters who appear to have escaped from a cartoon strip in a series of expressive and humorous sketches.\nJiří Kylián Evening | December 8-31, 2023\n- Stepping Stones by Jiří Kylián\n- Petite Mort by Jiří Kylián\n- Sechs Tänze BY Jiří Kylián\nFilled with eerie images on the border of reality and dream, Jiří Kylián’s work blends oneirism and wry humour.\nSet to music by John Cage and Anton Webern, Stepping Stones pays tribute to the memory and heritage of dance. On stage, Egyptian cats are the guardians of tradition.\nPetite Mort poetically explores the double theme of death: the lesser one symbolizing orgasm and the greater one that brings life to a close. Pas de deux and swordplay alternate against a backdrop of Mozart concertos.\nTwo new pieces by Kylián enter the Ballet’s repertoire this season: Sechs Tänze extends the Mozartian universe and caricatures it in a series of dances with a quirky sense of humor, while Gods and Dogs explores the borderline between normality and madness: when dogs become gods and vice versa. In a midnight blue light, the dancers perform in front of delicate strings that recall those of a Beethoven quartet.\nThe Nutcracker | December 8 – January 1, 2024\n- The Nutcracker by Rudolf Nureyev\nRudolf Nureyev restaged The Nutcracker at the Paris Opera with sets and costumes emphasising the tale’s uncanny nature. Snowflakes, flowers and enchanted landscapes form the backdrop to a dazzling choreography. Guided by the wooden puppet who has become Prince Charming, the young Clara confronts her desires and anxieties in an initiatory tale.\nSadeh21 | February 7 – March 2, 2024\n- Sadeh21 by Ohad Naharin\nCrossing the breadth of the stage one by one and then together, the dancers develop Ohad Naharin’s fascinating body language in a streamlined set. From an initial abstract grey to the evocation of a sandy beach, the monochrome decor changes color over the course of 21 studies in movement.\nIn Hebrew, “sadeh” means “field”, in the sense of field of study or field of action. Here and there, a narrative thread accompanies the audience through a labyrinth of virtuoso motions. Sadeh21‘s movements – elastic, swift and unpredictable – create powerful and moving images.\nIn this piece created in 2011 and now entering the Paris Opera Ballet’s repertoire, Ohad Naharin continues to explore his body language, Gaga, in magnetic and surprising episodes where bodies first collide before dancing together to soaring music.\nLa Fille Mal Gardée | March 15 – April 1, 2024\n- La Fille Mal Gardée by Frederick Ashton\nIn 1960, the English choreographer Frederick Ashton’s virtuoso and humoros version of La Fille Mal Gardée set roosters, old ladies and umbrellas dancing. A gallery of irresistible characters perform to the sound of popular songs and opera buffa arias.\nA fine example of the “ballet d’action” theorised in 1760 by Jean-Georges Noverre, a choreographic genre that emphasizes expressiveness, La Fille Mal Gardée dazzles and entertains thanks to its sheer freshness. Bet it in the farmyard or the cornfield, the hearts of Lise and Colas search for and eventually find each other. In the manner of a musical, the original script, reworked by Ashton, carries us away with its whimsy and smiles.\nDon Quixote | March 21 – April 24, 2024\n- Don Quixote by Rudolf Nureyev\nInspired by Marius Petipa’s choreography, Rudolf Nureyev’s Don Quixote is a true celebration of dance with a Spanish flavor. The soloists and the corps de ballet are carried away in ensembles and pas de deux to the strains of a spirited score.\nWritten in the 17th century, Cervantes’ novel recounts the adventures of Don Quixote, an idealist and bookworm who one day decides to ride across Spain with the naive Sancho Panza. In Nureyev’s ballet they meet Kitri and Basilio. The two lovers use every trick in the book – from a puppet performance to a fake suicide – to be reunited, despite Kitri’s father’s resistance.\nIn the end it is Don Quixote who delivers the happy ending after battling windmills and crossing paths with Cupid, Dulcinea and the Queen of the Dryads. The costumes and colorful sets sublimate a vivacious and entertaining work.\nGiselle | May 2 – June 1, 2024\n- Giselle by Jean Coralli and Jules Perrot\nDiaphanous tutus, pointe shoes, white gauze, tulle: Giselle marks the pinnacle of romanticism. In a bucolic landscape, a young girl dies of love and is transformed into a spirit that haunts the forest.\nTaken in by the Wilis, she enters an ethereal world where dance is the language of the soul. Her lover Albrecht, distraught, pursues this ghost at the risk of his life. The ballerinas, with their aerial presence, defy him just as they do gravity. The mist-shrouded set reveals spectral visions enhanced by Adolphe Adam’s bewitching score.\nSwan Lake | June 21 – July 14, 2024\n- Swan Lake by Rudolf Nureyev\nRudolf Nureyev brought his own interpretation of Swan Lake to the Paris Opera in 1984. The encounter between a dreamy prince and a bird-woman continues to fascinate with its elegant choreography and poetic story.\nRudolf Nureyev’s striking psychological insight magnifies the love story between Siegfried and Odette, the white swan bullied by the sorcerer Rothbart and Odile, the black swan. Ezio Frigerio designed the set as an enclosed space, a mental space in which the prince gives free rein to his fantasies.\nBluebeard | June 22 – July 14, 2024\n- Bluebeard by Pina Baush\nCreated in 1977, Pina Bausch’s Bluebeard, which enters the Company’s repertoire this season, transforms Bartók’s opera into a wild and intense ritual: that of a man confronting his thirst for power, his desires and his fantasies.\nPerrault’s original fairy tale is the inspiration for this major Tanztheater piece. Men and women dive headlong into a choreography that exposes the violence and absurdity of human relationships. The compulsive nature of desire becomes a principle of writing: locked in a series of gestures repeated to the point of exhaustion or explosion, Pina Bausch’s tragic characters draw us into a breathless world where seduction and domination converge.\nFeatured Photo for the Paris Opera Ballet 2023-2024 Season of Valentine Colasante and Paul Marque in Don Quixote from the company’s website. Photo by Julien Benhamou.\nLeave a Reply"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:2850f6c2-880f-4a64-b019-33d6423589cb>","<urn:uuid:7cd5a0d4-26c2-4005-b658-4f43b3e14913>"],"error":null}
{"question":"What are the contrasting applications and maintenance requirements between hydraulic and pneumatic systems in industrial testing and manufacturing?","answer":"Hydraulic systems are typically used in heavy-duty applications like testing aircraft landing gear, building-truss testing, and vehicle leaf spring testing, requiring less maintenance due to fewer parts but needing proper fluid filtering and leak prevention. Pneumatic systems are better suited for smaller precision tasks like surgical tools, positioning equipment, and repetitive movements in manufacturing. While pneumatics need regular checks for air leaks and hose corrosion, they are generally easier to maintain and operate, though they cannot handle the heavy loads that hydraulic systems can manage.","context":["Learn how fluid power with closed-loop motion control enables speedier, simplified nondestructive product testing.\nOne of the fastest growing uses for hydraulic and pneumatic actuators and closed-loop motion control is in product testing systems. Why? Fluid power offers distinct advantages over electric motors in many testing applications because hydraulics can meter small fluid volumes in and out of an actuator for precise control of pressure and force. This uses less energy than a motor that needs significant amounts of current to maintain force or torque. What's more, in applications requiring predictable force or movement of heavy loads, load cells may not be as practical as the pressure sensors of fluid-power actuation for determining net force.\nMotion actuators for testing are typically configured to simulate real-world conditions. For example, some apply force to aircraft landing gear to evaluate new runway materials and aircraft designs that affect wear and tear. Hydraulic actuators in building-truss testers apply loads to simulate harsh environmental conditions such as wind and snow loading. In these applications and others, including the testing of products as diverse as vehicle leaf springs, flexible pipe sections, and medical prostheses, precisely controlled motion actuators apply varying stresses over hours or days to simulate conditions that such items encounter over a lifetime of use.\nIn addition to precise position and speed control, coaxing the best performance out of the motion sources for nondestructive testing applications requires a motion controller capable of implementing closed-loop control of the pressure or force applied to the device under test. Simply controlling actuator position is insufficient, because it isn't possible to detect subtle physical changes in the test subject unless the net force required to flex the device is closely monitored. In a fluid power system, the net force being applied by an actuator can be discerned by monitoring the pressure difference between pressures on each side of the piston.\nFor example, consider a hydraulic tester designed to repetitively flex leaf springs while measuring the force to do so. The tester's motion controller determines force by connecting to pressure sensors, and precisely measures actuator position by connecting to a magnetostrictive linear displacement transducer (MLDT). In a typical test operation, position control is used to closely position the actuator before a controlled force is applied by the motion controller. Engineers should look for an electronic motion controller that is both easy to program and can smoothly transition between controlling position and regulating pressure or force.\nIn this scenario, the motion controller drives the hydraulic cylinder by sending analog signals to a proportional servo valve capable of making precise cylinder pressure adjustments (via sinusoidal or other waveforms) to control actuator force or position. An accumulator stores hydraulic pressure, ensuring that consistent supply pressure is available to operate the servo valve during spring compression cycles.\nNondestructive testing programs often apply repetitive stress cycles to devices being tested. A motion controller that supports directly executed cyclic motion operations makes it quick and easy to set up testing profiles. However, cyclic loading isn't necessarily simple. Proper motion controller operations are required to simulate complex real-world motion scenarios for one or more motion axes.\nOn the other hand, in non-cyclic testing applications, the motion controller should easily generate other motion patterns for stressing the device under test. For example, spline functions can produce smooth motion curves that can replicate seemingly random stimulus on the device under test — as in a racecar suspension tester that simulates the stresses of track driving.\nSpline functions emulate flexible strips that can be bent between fixed points and used to draw smooth curves. With them, implementing smoothly curving motion profiles is as easy as providing the motion controller with position coordinates (as a function of time or the position of another axis) and instructing it to connect the dots. The motion controller is simpler to program because it doesn't require the system designer to calculate velocities and acceleration rates. Finally, system performance improves because a single spline function replaces many point-to-point steps.\nUsing splines, complex motion profiles can be specified graphically using either a visual curve tool or an Excel spreadsheet: The machine designer defines the positions and lets the spline algorithm compute the acceleration and velocity necessary to move smoothly from one point to another. As the spline function executes, the motion controller calculates the acceleration and velocity needed to move from the present point to the next point in the motion profile, such that the accelerations are continually varying at a linear rate for smooth motion curves.\nLeveraging PC-based application software\nA wealth of relevant testing and data acquisition software is available for PCs, so it is important for the motion controller to easily interface with a PC running .NET assembly and ActiveX control and software packages, such as LabVIEW from National Instruments or Visual Basic from Microsoft.\nConsider a flexible pipe testing application for the oil and gas industry. Here, a test designer must setup different test stimuli to be applied to the pipe, view plotted test results, and log the data. One solution is to enter test parameters (such as positive and negative deflection angles, maximum and minimum tensions to apply, and number of repetitions) in an Excel spreadsheet, and then display the graphs using an interface developed with LabVIEW. In one such implementation, built for a flexible-pipe supplier to the energy industry, system integrator Jason Woyak of Flow Dynamics and Automation Inc., Birmingham, built an interface within Excel using Visual Basic for Applications (VBA). The interface outputs motion coordinates to the motion controller obtained directly from a spreadsheet.\nVBA is an implementation of Visual Basic, an event-driven programming language and associated integrated development environment (IDE) that is built into most Microsoft Office applications. By embedding the VBA IDE into applications, developers can build custom control interfaces using Visual Basic. Note: The communications interface with the motion controller itself relies on software provided by the motion-controller vendor. For example, a .NET assembly and ActiveX software package called RMCLink from Delta Computer Systems uses the motion controller's built-in Ethernet interface to connect to the PC. To use LabVIEW to display test results, a virtual instrument extracts the appropriate information from the motion controller's registers. For example, the RMCLink software contains virtual instruments for use by LabVIEW users.\nMotion controller enables non-destructive testing\nInterrogating the motion controller to monitor motion parameters during testing is an important capability. Reconsider the leaf spring tester, used by spring manufacturer Rockwell American, Seagoville, Tex. Here, the application's motion controller accurately follows operator selectable, internally generated target force profiles using an HMI. Each spring movement is controlled by continually adjusting drive output to the hydraulic valve 1,000 times per sec.\nMinimum and maximum spring deflections are monitored in real-time during the force cycling and compared against allowable limits, to determine any change in spring properties. For each spring tested, these limits are found when the motion controller is commanded to enter force control, as initiated by the operator via the HMI touchscreen. At the beginning of the testing cycle, the system compresses the spring to minimum and maximum force setpoints while recording and storing the corresponding minimum and maximum spring deflections.\nIf the hydraulic actuator's position exceeds operator-specified tolerances during the continuous force control cycle testing, the spring properties may be changing, the spring may be ready to break, or one leaf in the spring may have already broken. If this happens, the motion controller's continuous monitoring of position tolerances during force cycling leads to an automatic system shutdown. Because of these controls, the machine can run continuously with minimal supervision.\nMotion controller facilitates certification\nA motion system able to store test data can also document compliance with regulatory requirements. For example, consider a prosthetics manufacturer with an ISO-imposed requirement for testing elastic ankle joints to ensure they can flex under realistic conditions through at least two million cycles. Key to proving that they are tested realistically is making sure that during each cycle, the joint displacement is within a certain limit when a particular force is applied.\nOrion Test Systems and Engineering Inc., Lake Orion, Mich., manufactures such a tester, which uses two pneumatic cylinders controlled by a two-axis motion controller. One cylinder is positioned to press on the heel, and one to push on the toe, of an artificial foot. In this system, rather than measuring differential pressure in the cylinder, a load cell affixed to each cylinder measures the force being applied, while a MLDT affixed to each piston measures each actuator's position. Cylinders alternate their motion to flex the joint; during each cycle, the motion controller increases the force being applied on each cylinder until it reaches a predetermined setpoint and then measures the joint deflection to ensure that it doesn't exceed maximum allowable force.\nBecause data on the amount of deflection is collected every cycle by a PLC, the tester can measure the onset of fatigue before catastrophic failure occurs. The motion controller is able to cycle the tester between two and three times per sec — a rate twice as fast as the previous controller used in this application — doubling the testing facility's throughput.\nPneumatics was selected over hydraulics for this tester to keep the test system's weight as low as possible. The compressibility of air complicates tuning, but the Delta RMC75E motion controller's real-time plotting and tuning tools make tuning easier.\nMotion systems in unlikely places\nThe ability of motion systems to acquire data, make decisions, and produce outputs enables engineers to use them in unusual applications. For example, Catalina Cylinder Corp., Garden Grove, Calif., makes aluminum cylinders used to transport gases such as oxygen and carbon dioxide. Catalina's engineer, John Kishel, had the idea that perhaps a hydraulic actuator — under closed-loop control by a motion controller — could be a source of pressurization for the gas cylinders under test.\nHere's how it works: The system uses a hydraulic cylinder acting as a pump, with the cylinder's rod end entering a tube that squeezes water into the gas cylinder. The gas cylinder is tested according to a motion profile dictated by the program running on the motion controller. Very high pressures are achieved quickly, even though the cylinder moves relatively slowly. Further, because the hydraulic cylinder moves slowly, the pressurization system has a long life. Kishel confirms that by using a smart motion controller, the system can achieve its target pressure to within 1% at 3,000 psi, enabling Catalina's testing process to achieve more precise control and a higher degree of pressure-related repeatability than other techniques.\nHigh-precision components enable testing and lab automation\nTiny slide suits precision optics, pipetting applications\nA new microslide linear actuator from Haydon Kerk Motion Solutions outputs 0.0006 in./step resolution to 3 lb-ft. Optimized for applications requiring precision motion in a small footprint, such as microfluidics and optical positioning, the slide measures 0.87 in. wide by 1.0 in. high, with a 2.5-in. maximum stroke length. Its 15000 Series 0.59-in. can-stack motor can be commanded using a simple pulse and direction signal. The microslide is easily configured for application-specific requirements including custom mounting, varying stroke lengths, magnetic or optical position sensors, and custom wire harnesses. For more information, visit haydonkerk.com.\nDisc couplings enable highly accurate systems\nSingle and double-disc style couplings from Ruland Mfg. deliver accuracy in test and measurement industries. Comprised of two black anodized aluminum hubs and multiple flat stainless steel disc springs, disc couplings have low inertia and are torsionally stiff, suitable for precise zero-backlash systems with speeds to 10,000 rpm. Single disc styles are suitable where compact installation is required; double disc styles add a center spacer to increase the misalignment capabilities. Thin disc springs allow for substantial misalignment between shafts while remaining rigid under torque loads. Couplings are available in both clamp and setscrew styles with bores from 3 to 30 mm. For more information, visit ruland.com.\nPrecise motion control supports microscopy\nPhysik Instrumente offers ultrasonic-ceramic motor drives with self-clamping properties, providing better stability in long-term imaging applications than conventional motor-driven stages. These motors are employed in long-travel microscope stages. If higher resolution is needed, the positioners can be supplemented with X-Y-Z piezo-flexure positioning stages capable of subnanometer resolution. Digitally controlled piezo objective lens positioning systems with autofocus provide more rapid step and settle than conventional analog control. High-speed piezo steering mirrors scan laser beams in two coplanar axes, avoiding polarization rotation errors induced by stacked single axis mirrors. Download a complete guide at microscopestage.net/microscope_positioning_systems.htm.","Hydraulic and pneumatic systems are integral to the operation of cars, trucks, buses, aircraft, and other vehicles. These systems power everything from braking and steering to heating and air conditioning. However, there are some essential differences between hydraulics vs. pneumatics.\nHydraulic systems compress liquid, are used for industrial machinery, cost about $10,000, and produce around 6,500 PSI. Pneumatic systems compress gas or air, are used for smaller tools, cost approximately $1,500, and generate about 120 PSI. Overall, hydraulics are better for large jobs, while pneumatics can handle the small ones.\nIn this article, we’ll discuss the ins and outs of hydraulics and pneumatics, what each system is used for, and their pros and cons!\nWhat Is a Hydraulic System?\nThe first type of system we’re going to dive into is hydraulics.\nA hydraulic system, or hydraulic power system, uses pressurized fluid to power the moving parts of a machine. Hydraulics pumps relatively incompressible liquids at extremely high pressures using valves and actuators. The average operating pound-force per square inch of a hydraulic system is 6,500 PSI.\nHydraulic systems are often paired with at least one other kind of power system. For example, some cars use hydraulics to power their steering and braking and use electric motors and gasoline to power the engine. Note that these systems are typically seen on heavy-duty vehicles like construction equipment, aircraft, or elevators.\nHydraulics use engineering and physics principles (think Pascal’s Law) to transfer force from one end to another- effectively, like a seesaw. If one end of the seesaw is pushed down, the other end moves up as a result. This allows for machinery to lift cumbersome pieces of equipment without much effort.\nSubstance Used in a Hydraulic System\nThere are a few different substances that can be used in a hydraulic system to create force or motion.\nThe fluids hydraulics use include water, mineral oil, water emulsion, or ethylene glycol. In order to translate the fluid into power, you need a pump- this is usually a piston pump powered by a motor.\nHydraulics also require a filter to remove particles from the hydraulic fluid before they clog any components of the system.\nParts of a Hydraulic System\nBecause hydraulics involves storing and pressurizing liquid material, hydraulic machines are usually incredibly large and intricate.\nThe main components in a hydraulic system are:\n- Hydraulic pump\n- Reservoir for hydraulic fluid\n- Directional control valve\n- Flow control valve\n- Pressure relief valve\n- Other connecting pipes and wires\nThese parts work like a well-oiled machine (no pun intended) to ensure that your piece of equipment has adequate power.\nWhat Are Hydraulics Used For?\nLike I mentioned above, hydraulic machines are typically big and more complex and are used to power large industrial equipment.\nSome areas where hydraulics are used include:\n- Lifts (fork, elevator, wheelchair, and car)\n- Amusement parks\n- Gasoline pumps\n- Cars (braking and steering systems)\n- Hairdresser/office chairs\n- Boat rudders\n- Other industrial equipment (like on a construction site)\nThese are just a few of the places you might see a hydraulic system at work in your everyday life!\nPros of Hydraulics\nThere are a few advantages a hydraulic system has over a pneumatic one.\nA hydraulic system is usually better at doing the heavy lifting- there are a variety of sizes to accommodate your industrial needs. This has led to hydraulic systems becoming the preferred choice in a wide range of commercial applications.\nOther pros include:\n- Multitasking abilities (they cool, power, and grease a piece of machinery at any given time)\n- More power generated from comparatively smaller actuators\n- Constant torque and force regardless of speed\n- Longer operating time and more reliability due to the design\n- Fewer parts and less maintenance required\nThese are all critical benefits when deciding what system is suitable for your specific needs.\nCons of Hydraulics\nWhile there are many advantages to using hydraulics, they do have some disadvantages.\nA hydraulic system has the potential to leak fluid everywhere, which is why it’s imperative to make sure everything in your machine is adequately sealed and in good working order.\nOther cons include:\n- The expense (the machines can be pricey and more energy is required to operate them).\n- Filtering oils, which can get messy\n- Being prone to leaks, which results in a lack of proper fluids rendering the entire machine nonfunctional\n- Fire hazard (created by oil leaks)\n- Loud operating sounds if air bubbles get into the system\nThe concept of hydraulics is also relatively complex and requires someone with a decent understanding of engineering to set up and use the machine properly. If you don’t know what you’re doing, the pressure in your machine can cause severe damage.\nCost of a Hydraulic System\nThe overall cost of a hydraulic system can get pretty expensive.\nIt’s not uncommon for an industrial-sized hydraulic system to cost upwards of $10,000.\nThe reasons behind this are that the machine needs to be custom-built, with most parts and pieces assembled on site. Additionally, the oil or substance used can get pricey.\nYou must also consider what mammoth machines hydraulic systems are; the energy required to power them is unmatched.\nWhat Is a Pneumatic System?\nThe second type of system is powered by pneumatics.\nPneumatic systems, also called compressed-air systems, use air or gas under pressure to provide mechanical energy for engines or other machines. Pneumatic systems power small, oscillating saws in the OR or medium-sized power tools in your garage. The average operating pound-force per square inch of a pneumatic system is 95 PSI.\nPneumatics utilizes an air compressor to reduce the amount of air to increase its pressure. The compressed air is then pushed through a filter into the tubing. Here it is controlled by valves and an actuator, which converts it into power for your devices.\nOverall, a pneumatic system is easier to operate, less expensive, and smaller in stature than a hydraulic system. That being said, it can’t handle as much weight or pressure. Because this system uses a compressed gas at lower pressures than hydraulics in order to operate, it’s best suited for smaller and lighter projects.\nSubstance Used in a Pneumatic System\nTypically, there are 3 inert gases used in pneumatics.\nThe substances used in a pneumatic system include compressed air, nitrogen, and carbon dioxide.\nCompressed air is usually used in commercial settings; it’s freely available and less combustible than regular oxygen. Nitrogen is the least reactive and most commonly used because it can be easily stored. Lastly, carbon dioxide is less popular because it quickly turns from gas to liquid and can cause suffocation in a closed space.\nParts of a Pneumatic System\nPneumatics is far less complicated than hydraulics; therefore, the parts are smaller and easier to learn.\nThe main components in a pneumatic system are:\n- Air hoses\n- Gauges (or regulators)\n- Check valve\n- Pressure relief valve\nAll of these parts work together to power your tools.\nWhat Are Pneumatics Used For?\nAs described above, pneumatic systems are typically used for small tools and machinery because of their limited pressure capabilities.\nPneumatic systems are great for equipment actions that include gripping, positioning, clamping, or repetitive movements. They are also able to tension or press.\nSome areas where pneumatics are used include:\n- Tire pressure gauges\n- Nail guns\n- Vacuum cleaners\n- The anti-slam feature on doors and drawers\n- Air compressors\n- AC systems\n- Drills and saws utilized by surgeons\nPneumatics can also be used as a direct-acting system on small loads that require exact precision, making them an attractive option across all industries.\nPros of Pneumatics\nWhile pneumatic systems are usually smaller, there are some advantages they have over hydraulics.\nSome pros include:\n- Lower PSIs reached, so safer to use (especially for novices)\n- More cost-effective (the machines and the energy used to power these machines are less expensive)\n- Smaller and can be portable (come in many sizes and pressure capabilities)\n- Utilizing compressed air results in less of a safety hazard\n- The power supply of compressed air or gas is much cleaner than oil (great for sterile environments like surgery)\nOverall, if you’re looking for a reliable energy source that needs fewer than 120 PSI, choose a pneumatic system.\nCons of Pneumatics\nFor the many advantages, there are a few downsides to using pneumatics.\nThe first disadvantage is that a pneumatic system will not be able to supply the high pressure needed to power large machinery. Therefore, it’s unsuitable for heavy loads or large projects because pneumatic systems can’t handle them.\nOther cons include:\n- Limited PSI capabilities\n- Sensitive to temperature change\n- Prone to air leaks if not secure (this can cause energy loss)\n- Hoses can corrode (if they’re not made of stainless steel) if they’re exposed to the outside conditions\nCost of a Pneumatic System\nBecause pneumatic systems are generally tiny in comparison to hydraulic systems, they are much less costly.\nAn average pneumatic system costs around $1,500.\nFor that small cost, you’ll be able to power your garage equipment and small machinery easily!\nThe Main Differences Between Hydraulics and Pneumatics\nWhen you compare hydraulic vs. pneumatic, you’ll notice a few key differences between how they operate and what they’re capable of.\nThe main difference is that pneumatics use compressed air and gas for force, while hydraulics use relatively incompressible liquid. Hydraulic systems are much more substantial and have a capability of over 5,000 PSI, perfect for industrial settings.\nPneumatic systems are used for smaller tools that require 100 PSI or less, ideal for sterile environments.\n- Top Chicago Pneumatic Air Compressors | List & Reviews\n- Central Pneumatic Air Compressor Not Building Pressure?\nWhen considering hydraulic vs. pneumatic, it’s essential to consider the applications and advantages of each.\nIf you’re looking at larger tasks, like construction projects that require heavy-duty tools and equipment, then a hydraulic system may be the best option. Hydraulic systems are more expensive than pneumatics, but they can generate around 6500 PSI of pressure and cost $10,000.\nFor smaller jobs with less demand on power generation capabilities (like saws or drills in home workshops), a pneumatic system might work better. Pneumatics are cheaper and produce less PSI.\nSo, which one is right for your job?"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:b9e91dd0-9ce9-4898-a4df-f93c7a1865e4>","<urn:uuid:346c9595-24da-49b2-84f9-4281ab63d3eb>"],"error":null}
{"question":"What year did Samuel Avital discover Charlie Chaplin's work, and how did it influence him?","answer":"Avital discovered Charlie Chaplin's work in the early 1950s through the film 'Limelight.' The film showed him that there was more to theater than just talking, as Chaplin could express deep human emotions through silence. This discovery influenced him to pursue wordless theater, leading him to move to France in 1956 to study mime.","context":["Samuel Avital speaks many words about the art he has spent his entire life perfecting.\nStrange, because Avital’s art is performed wordlessly. He is a mime, practicing, as he once wrote, “the ultimate language of silence.”\nThe Moroccan-born Lafayette resident is celebrating 40 years as the director of Boulder-based Le Centre du Silence, a mime school he opened in 1971. He is also the founder of the now-defunct Boulder Mime Theatre and host of the International Summer Mime Workshop. He has performed all over the world and studied under the masters of mime: Etienne Decroux, Marcel Marceau and Jean-Louis Barrault. Still spry at 79, he hasn’t performed since 2000, and he focuses his energy on teaching Kabbalah and his craft, which have intertwined into a discipline he teaches called BodySpeak.\n“[Avital] has, for me, the most focused and the most inclusive artistic point of view that I’ve encountered,” says Mark Olsen, a close friend and former student who now heads the graduate acting program at Penn State University. “A lot of artists seem to be dogmatic and territorial about their art. It’s as if the boundaries of what they’ve chosen to be their artistic expression is what defines them. Samuel is different. His artistry, his gift, is inspiration, in igniting that fire within.”\nAvital was born in Morocco in 1932 and left his family for Israel when he was 14. The transition from a very traditional lifestyle in Morroco to a more modern one at an Israeli kibbutz was very abrupt and difficult for him, and he found solace in theater and other performing arts. It was in Israel that Avital discovered the man whose work would open Avital’s eyes to the possibilities of mime — Charlie Chaplin.\n“In the process of performing, speaking-theater was not enough for me. So I looked for an avenue,” Avital says in the documentary The Silent Outcry. “Somehow, the words seemed very inadequate to express myself. I had come with such fantastic luggage [the culture shock] that needed to be expressed. There was one fabulous thing that I saw at that time in the early ’50s, the Charlie Chaplin film Limelight. ... Limelight made me think that there was more to theater and this new medium that I was discovering than just talking, because this man, with silence, could express very deep human emotions.”\nAvital’s interest in wordless theater led him to move to France in 1956. He lived the starving-artist life as he dedicated himself to studying mime. In 1964, he came to the United States. He performed off-Broadway in New York and began teaching at Southern Methodist University in Texas in 1969. Two years later, he moved to Boulder.\nIn 1971, Avital started the Boulder Mime Theatre, and he led his students in flamboyant, silent parades from the Boulder Public Library to the courthouse every week through the mid-’80s, when the city informed him he would have to purchase insurance for his students and permits to perform on the mall.\nAvital saw his performances as an artistic service to the community, and he did not take kindly to the sudden-onset bureaucracy.\n“Thirteen years, I didn’t have a permit!” Avital exclaims, gesturing strongly and frequently as he talks. “I was bringing tourism here, and now, suddenly, they wanted a permit! You know what, thank you. I know now that is the end of this activity, that the Boulder Mime Theatre is no more.”\nWhat most people think of as mime — the guy in white face paint and black beret stuck in the invisible box — is actually pantomime, Avital says. The difference, he explains, is that though pantomime is performed in silence, it still performs with words.\n“In pantomime, you’re still talking,” Avital says. “I’m translating the word that you have in your head through mime.”\nHe demonstrates what he means. With wide, expressive eyes, he points to his chest, then presses his palms together, brings them up to his shoulder, lays his head on his hands and closes his eyes.\n“I. Am going. To sleep,” he explains, adding that it was his former teacher, mime master Etienne Decroux, who told students, “If you want to sleep, sleep! Don’t tell me about it. Sleep! Take the position. Do it! Instead of talking about it with your movements, do it!”\nThe craft Avital spent his life perfecting and teaching is mime in its purest form, a physical performing art relatively unknown outside the circles of its practitioners. The simplest definition is that mime is storytelling without words. Avital hasn’t performed since 2000, and the few videos of his performances, with sharply defined movements and bluntly conveyed meanings, appear akin to modern dance, albeit modern dance overtly concerned with storytelling.\nBut mime and dance are not the same.\n“I want you to think about heaven and earth, gravity and counter-gravity,” Avital says. “I want you to think that the dancer, mostly, wants to reach the heaven, to escape gravity to express emotion.”\n“The mime brings it to here, the clown brings it to here, right here,” Avital says, pointing to his heart.\nAfter disbanding the Boulder Mime Theatre, Avital focused on his teaching. He began teaching Kabbalah, a form of Jewish mysticism, in the ’90s, and he saw parallels between what he was teaching and his art. He intertwined the two and created a discipline he named BodySpeak, which he calls the “summation of my life, spiritual and artistical.”\nBodySpeak tries to make artistic expression easier, to clear the mental blocks that can hinder creativity, to erase the gap between thinking and doing.\n“This is an artistic principle, the actor, the musician, the painter, this is one of the great challenges of any artist. I have an idea, and I don’t know what to do with it! I have this thing, I paint, and I sculpt, and it’s not the idea I meant it to be. If they adopt [BodySpeak], they will quicken this creativity.”\nHe encourages his students to embrace what makes their artistic approach unique.\n“That’s why it’s both dangerous and fantastic, this approach, because I don’t allow the person to allow me to tell them what to do. I want them to be the authority, to write their own script. But I give them the tools,” Avital says.\nAvital himself is uncompromising in his vision, even eschewing nonprofit status for his various endeavors in order to avoid the meddling of a budget-conscious board of directors. He says he has never received grant money from any institution. His approach to art is spiritual, but he refuses to be anybody’s idol, instead insisting they create their own fiercely independent artistic identity.\n“By no means is he that weirdly guru kind of cult-like mystic,” Olsen says, recalling the end of the first Avital workshop he attended. “I felt so blessed to be a part of his life and work and all that I had learned from him. … I attempted to kiss his hand, and he gave me a quick slap on the arm. He said, ‘Don’t ever do that. What the hell do you think you’re doing?’ He really stopped me from the kind of guru-worship. He wouldn’t stand for it. He didn’t want that kind of cloudy, moon-faced adoration.”"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:91194a9c-3e60-409c-a573-098d0bb23d46>"],"error":null}
{"question":"What is the surprising finding about heart tissue age compared to other tissues in the human body?","answer":"The heart tissue looks younger than the rest of the body's tissues, appearing on average nine years younger, though researchers don't know why this occurs.","context":["Every cell in your body has a little clock ticking away in it, researchers reported on Sunday. And while most of you is aging in a coordinated way, odd anomalies that have the researchers curious: Your heart may be “younger” than the rest of your tissues, and a woman’s breasts are older.\nTumors are the oldest of all, a finding reported in the journal Genome Biology that might help scientists better understand cancer, explain why breast cancer is so common and help researchers find better ways to prevent it.\nLess surprising, but intriguing: embryonic stem cells, the body’s master cells, look just like newborns with a biological age of zero.\nThe new measurements might be useful in the search for drugs or other treatments that can turn back the clock on aging tissue and perhaps treating or preventing diseases of aging, such as heart disease and cancer, says Steve Horvath, a professor of genetics at the David Geffen School of Medicine at UCLA.\n“The big question is whether the biological clock controls a process that leads to aging,” Horvath said.\nHorvath looked at a genetic process called methylation. It’s a kind of chemical reaction that turns on or off stretches of DNA. All cells have the entire genetic map inside; methylation helps determine which bits of the map the cells use to perform specific functions.\nHe found a pattern of specific methylation events that could be associated with cellular aging. “Methylation levels either increase with age or they decrease with age,” He says. “I identified 353 of these markers that are located on our DNA. I managed to aggregate their information so they arrive at a very accurate clock.\"\nHe’s not sure what each methylation marker does on its own.\n“It’s really the aggregate that is making the difference,” Horvath said in a telephone interview. \"The whole is more than the sum of its parts.”\nHe looked at blood and tissue samples from hundreds of people, from unborn babies to someone 101 years old. He looked at tumors from people with 20 different types of cancer, samples of non-cancerous tissue from the same patients and perfectly healthy people.\nOn average, tumors were 36 years older than the rest of the body, a finding that supports the idea that cancer is a disease in which the biological clock runs amok.\nSurprisingly, most people’s hearts look younger than the rest of their bodies, the researchers found. ”That looked one average nine years younger,” Horvath says. “It’s really striking. I don’t know why, but it looks younger.”\nAnd some cells looked older. “The tissue that looked oldest was female breast tissue,” Horvath says. Normal, healthy female breast tissue looked about two to three years older on average. Non-cancerous tissue taken from breast cancer patients – samples from right next to a tumor – looked about 12 years older.\nHorvath believes the findings suggest there may be ways to reverse the aging of tissue that leads to disease. There’s a way that scientists make embryonic-like stem cells from ordinary cells. These new stem cells are called induced pluripotent stem cells, and they are genetically altered to look like the baby cells that are created soon after conception.\nEven though they’re made using old cells, Horvath says that, measured using his process, they look like they’ve truly been converted back into brand-new cells."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:b0e88206-914a-4f9e-980a-9efc1feb8874>"],"error":null}
{"question":"How does the early onset of head trauma affect the risk of developing CTE in athletes?","answer":"The risk of developing CTE is higher when an athlete experiences head trauma at a younger age. The damage from hits is cumulative and doesn't necessarily require concussions to cause harm. This was exemplified in Paul Pender's case, where the damage may have begun while he was still playing high school football.","context":["Can Boxing Be\nMade Less Dangerous?\nBy Bobby Franklin\nRecently, I watched a news story from 1995 about heavyweight contender Jerry Quarry. The very popular Quarry who had twice fought Muhammad Ali and Joe Frazier was being inducted into the International Boxing Hall Of Fame. This was considered a great honor and Jerry was there to bask in the glory. Well, he wasn’t exactly there. While his body was, his mind was no longer working, and the formerly very articulate Quarry was in such bad condition he was unable to sign autographs without the assistance of his brother James.\nIt was heartbreaking watching this footage. Not only was Jerry unable to sign his name he also needed assistance dressing himself. When asked questions he just stared off into space. This is something you might see in an elderly person who is suffering from Alzheimer’s Disease, but Jerry Quarry was far from elderly; he was only fifty years old. He would be dead in less than three years. He was also broke.\nSeven years after his passing, Jerry’s brother Mike would die from the same disease. Mike was only 55 and had been suffering for many years. At the time the cause was called boxing induced dementia. For years it had been confused with Alzheimer’s Disease, but it is quite different. Today, it is known as CTE (Chronic Traumatic Encephalopathy). It is caused by trauma to the head and is most common in boxing and football. It has also been found in military combat veterans, soccer players, ice hockey players, and victims of domestic violence.\nUnfortunately, a true diagnosis cannot be ascertained until after death, when the brain can be dissected and studied closely. Dr. Ann McKee, Director of The Boston University CTE Center, has led the research into this terrible affliction. Doctors are becoming aware of the importance of looking at symptoms and patient history so as to be able to differentiate between Alzheimer’s and CTE.\nIn 2003, after former Middleweight Champion Paul Pender passed away from what was thought to be complications related to Alzheimer’s Disease, his widow Rose asked to have Paul’s brain examined by Dr. McKee. Rose was concerned that if it was Alzheimer’s it could be genetically passed on to their children. The results showed no signs of the beta-amyloid protein found in Alzheimer’s but did show clumps of Tau Protein which is now known to form because of repeated blows to the head. The hits do not have to cause concussions as the damage is cumulative. Also, the younger the athlete when the head trauma begins, the higher the risk of developing CTE. In Pender’s case the damage may have begun while he was playing high school football.\nThanks to the courage of Rose Pender and the dogged research of Ann McKee and others, much is being learned about this terrible disease. I highly recommend the documentary “The Brain of a Boxer” which delves into the story of Paul Pender and Rose’s search for an answer to why her husband suffered so. The tragic part about this is how it is very preventable and how little is being done to stop it from happening.\nIn recent years I have had a number of conversations with people who love boxing but also are very conflicted because of the injuries caused to those who partake in it. These conversations usually circle around how to make the sport less dangerous. To be sure, there are things that can be done to lessen the danger, but seeing as the whole point of the sport is to inflict injury to the opponent’s brain it is unlikely, short of not allowing head blows, to stop participants from ending up victims to CTE.\nWhile it is true not all athletes who participate in contact sports will end up suffering from CTE, the risk is very high that a large number of them will. In the early years of the 20th Century President Theodore Roosevelt intervened when severe injuries and deaths were mounting in college football. There were calls to abolish the game. At TR’s urging, the rules were changed and football became safer. It is once again very dangerous, but rule changes could improve things. That is not likely in boxing as there is no way for the sport to be practiced without imposing head injuries. Rendering the opponent unconscious is the point of the sport and the thing that most excites the fans.\nThe Quarry brothers are just one of many examples of boxers who have ended up suffering from the blows they received years earlier in the ring. Former heavyweight champions Floyd Patterson and Ingemar Johansson both were diagnosed with pugilistica dementia when they died. Mickey Walker and Sugar Ray Robinson, two of the greatest fighters of all time, also had it. And most ironic of all was Muhammad Ali, a man who used to brag that he would never end up like the others. He was perhaps the biggest victim of the sport. It is a myth that he would have been fine if it hadn’t been for Parkinson’s Disease. Ali, like the Quarrys, began boxing at an early age and stayed in the sport long after his skills had eroded. In the last decades of his life his mind and body succumbed to the punishment he took. One of the most gifted athletes in history ended up physically and mentally destroyed by the sport he so loved.\nEveryday we face danger. Crossing the street and driving a car can lead to severe injury or death. However, unless one is crazy, we take precautions when doing these things. We also don’t do these things with the intent of causing harm to others. In boxing, while there may be some precautions taken, the aim is to cause injury. There’s just no getting around that.\nYears ago it was thought people watched auto racing because they wanted to see the crashes. It was found out that wasn’t sure. People watched because they enjoyed witnessing the skill of the drivers and the roar of the cars. When it comes to boxing, fans show up to see the accidents."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"}],"document_ids":["<urn:uuid:703f3c11-9fc4-49e7-b8e2-2588253c3efc>"],"error":null}
{"question":"What factors determine the actual lifespan of asphalt shingles in different climate conditions?","answer":"The lifespan of asphalt shingles is determined by several climate-related factors. While they typically last about twenty years, their durability varies depending on the climate and weather patterns of the region. They perform well in conditions with small hails, heavy rains, moderate wind and snow, but lose significant endurance (20-40%) in extremely hot or dry climates. Additionally, in tropical climates with high humidity and precipitation, asphalt shingles need to be treated with algaecides. Regular maintenance and proper installation are also crucial for maximizing their lifespan.","context":["The region in which you live will have a major impact on the type of roofing solution you choose for your property. Although personal preference, aesthetic value and price are some of the important factors, they are not the only factors, which have to be considered. It is necessary for you to understand that specific climates need specific type of roofing solutions. Roofing materials should be wisely chosen to provide maximum comfort and protection for your home.\nWhen it comes to roofing options, you would certainly want to ensure that you are choosing a material that best suits your climate. Choosing a roofing solution that withstands the climatic conditions of your region will make an efficient roofing choice. Considering the average climatic condition of where you live will help you in making a better decision.\nMost of the web sites and home-improvement stores sell similar types of roofing materials in every type of climate and regions. However, if you are planning to install your own roof, it is important to analyze the best possible options that precisely suit the climatic conditions of your region. Here are a few roofing recommendations that help you to choose the right roofing option. Although some may overlap, please do follow along.\nBeat the Heat with Heat Repelling Roofing Materials\nHot and dry climates require roofing options, which neither absorb nor draw heat inside. In such regions rubber roofing should be completely avoided. This is because, rubber and other similar materials will make your indoors painfully hot and uncomfortable. Metal can also be a bad choice, although it reflects the light away. This because, sun rays severely heat up metal surfaces. Dark shingles will also draw in a lot of heat. Clay tiles make a best choice for hotter climates. Although they are a little expensive, they are worth that additional expense. Clay tiles are efficient in blocking the heat. They are also fairly resistant to wind. However, clay tiles should be installed by professionals, as they require special tools and techniques to be installed.\nAsphalt Shingles for Slightly Extreme Climates\nAsphalt shingles are suitable for different types of weather conditions. These include, small hails, heavy rains, moderate wind and snow. However, they do not make a great choice for extremely dry or hot climates. This is because, under such conditions they lose their endurance by 20% to 40%. They still make a good choice for warm climates. Choosing the right shingles, which reflect heat and are light in color, will do the trick.\nWood Shakes and Shingles\nWood shakes and shingles are natural and traditional roofing materials, which are not suitable for climates which have constantly high temperatures. They make a great choice for moderate climates. Extreme heat will crack or split them. Besides, heavier rains will completely destroy them, particularly if they are made of low quality materials.\nSlate Roofing Surviving Extreme Weather Conditions\nBeing one of the ancient types of roofing solutions, slate roofs offer unbeatable benefits. They are tough, durable, aesthetically pleasing and offer endurance that is second to none. These roof tiles have high density and are non-combustible. They also prevent the growth of mold and fungus. All these properties make them the best choice for extreme weather conditions, without worrying about frequent repairs or replacement. Although they might cost a bit higher, you will soon forget the investment once you start reaping the long-term benefits.\nRoofing Options for Tropical Climates\nIn regions where humidity is persistent and precipitation is higher, it is always wise to avoid using roofing materials that facilitate mold growth or breeding of algae. Asphalt shingles make an ideal choice for such regions. They are inexpensive and durable. However, while using in tropical climates, asphalt should be treated with algaecides.\nRight from natural materials to man-made products, roofing options are available in a variety of styles and types. Today you have much more choices than ever before. While each come with their own shortcomings and advantages, making a wise choice will help you in adding a distinct element of elegance to your space, while ensuring the required protection.","How Long Do Asphalt Shingles Last?\nIf you have recently had an asphalt shingle installation, you will naturally want to know how long your roof will last. If you have an asphalt shingle composition roof, you can expect your roof to last about twenty years. This estimate, of course, depends on the climate and prevailing weather patterns of where you live. If your area has a history of hurricanes or severe weather events, this may impact the overall roof lifetime of your roof system. It will also be important to consider the amount of roof maintenance that your roof receives. It is important to conscript a professional roofing company for regular roof inspections. With great roofing maintenance and a a proper roof installation, you can expect great roof longevity.\nAre Asphalt Shingles Good?\nAsphalt shingles are exceedingly popular in North America. That is because they are endlessly versatile in terms of colors and shape. Asphalt shingles are also relatively easy to install and quite affordable. For these reasons, property developers and homeowners have welcomed asphalt shingles on to their homes and properties. They also have a good standard roof lifetime. While asphalt shingles don’t last as long as a metal or tile roof, they remain a popular and affordable standard in the roofing industry.\nWhat Are the Best Asphalt Shingles?\nQuality is very important when it comes to asphalt shingles. Please read over the following list of recommended shingles to learn more about high-quality asphalt shingles.\n- GAF Marquis WeatherMax shingles.\n- CertainTeed XT 25.\n- Owens Corning Supreme AR.\n- Tamko Heritage Vintage.\nWhile these shingles are certainly highly recommended, your local professional roofer will likely have some exceptional selections for you to choose from. You should be a discerning consumer and learn about your roofing material before it gets installed on your roof.\nWhat is the Difference Between Architectural Shingles and Asphalt Shingles?\nAre you wondering what the difference is between architectural shingles and asphalt shingles? If so, you are not alone. Many people look at shingles and wonder what the differences are. Please allow this distinction to be made here. Three-tab shingles have one shingle tab size and shape that consists of three separate tabs that are twelve inches wide. These tabs are coated with asphalt in order to shed water. Architectural shingles are characterized as laminate or dimensional. They come in different sizes and shapes and are considered a premium roofing product.\nHow Long Do 30-Year Architectural Shingles Really Last?\nWhile 30-year architectural shingles have a defining title, it is important to consider roofing maintenance and the prevailing climate and weather patterns of your area. According to leading resources online, the expected service life of a thirty-year product is approximately twenty-five years. Of course, the best way to find out the current condition of your roof is to consult with a professional, insured\nAre Asphalt Shingles Energy Efficient\nIf you are looking for energy-efficient roofing material, you may want to pass over asphalt shingles. This is because even in a lighter color, asphalt shingles do not perform well in comparison with other roofing materials in the industry. Asphalt shingles are very good at absorbing heat and are poor at reflecting it.\nWill Asphalt Shingles Seal in Cold Weather\nIf shingles are installed in cold weather, they will not immediately seal until warmer temperatures are present. The sealant will need to activate. If temperatures are at or below forty degrees Fahrenheit, it will impact the sealant. Your professional roofing contractor will have experience with shingle installations and will have some thoughts about installing shingles in different weather patterns and temperatures.\nWho Invented Asphalt Shingles\nAre you wondering who invented asphalt shingles? In terms of revolutionary inventions, asphalt shingles are a modern marvel. The official inventor of asphalt shingles is American Henry Reynolds. Henry Reynolds hailed from Grand Rapids, Michigan. The asphalt shingles he produced first were used in 1903. Asphalt shingles were generally used in America by 1911. Asphalt shingles were so successful that by 1939 eleven million squares of shingles were being produced. Since then, asphalt shingles have come to revolutionize and dominate the roofing industry in North America.\nWhy Do Asphalt Shingles Curl\nAre your asphalt shingles curling? If so, you will need to contact a professional roofing contractor. That is because you could have a problem with inadequate venting. The air that is taken in your roof is displaced through higher parts of your roof. Without proper venting moisture and heat could become trapped in your attic. The heat that is added additionally to the bottom side of your shingles can cause them to wear prematurely. They will fade and curl.\nIf you would like to discuss your asphalt shingles in Baltimore, MD, our team is here to assist. Please reach out to our crew at (410)-288-1633."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"}],"document_ids":["<urn:uuid:a44eed58-0017-4a57-845b-824e41a9b10c>","<urn:uuid:5b4ffd56-52c8-48ab-abd6-fa038c376f30>"],"error":null}
{"question":"What makes calcium and noble gases different in terms of chemical reactivity?","answer":"Calcium is a highly reactive metal that readily forms compounds, while noble gases are extremely non-reactive. This difference stems from their electron arrangements - calcium has two electrons in its outer shell that it can readily give up to form compounds, while noble gases have stable duplet or octet electron arrangements (2 or 8 electrons in their outer shell) that make them very reluctant to react with other elements.","context":["blood calcium: n the level of calcium in the blood plasma, generally regulated by parathyroid gland activity in conjunction with the degree of calcium ingestion, absorption, use, and excretion. Normal value is 8.5 to 11.5 mg/100 ml of blood serum.\nThis metal ion is bound to Asp74, Asp90 and Ile91 [site I; note that Horton et al. use a different nuering system]. A second metal ion is bound to Asp74 and Asp90 (site II) as well as to the scissile phosphate; in its coordination sphere there is a water\n2020/8/11· FAMILIES OF ELEMENTS CONCEPT The term \"family\" is used to describe elements that share certain characteristics—not only in terms of observable behavior, but also with regard to atomic structure. All noble gases, for instance, tend to be highly nonreactive: only a few of them coine with other elements, and then only with fluorine, the most reactive of all substances.\nThe most popular subjects of study in recent years have been the search for weakly interacting dark matter (e.g., its annihilation radiation), and the study of extremely high-energy particles that cannot be produced in present-day accelerators. In Estonia, we\nThose elements make up the alkali earth metal family. Yes, calcium is defined as a metal because of both its physical and chemical traits. They all have an outer shell with two electrons and are very reactive. Those elements in the second column have two of 2.\nMagnesium Calcium Vitamin D3 K2 and Turmeric Tablets Joints Bone Suppo x 180 180 tablets in a foil fresh pouch. 100% Money Back Guarantee - if you are not entirely satisfied with your purchase your item is free & you will receive a full refund. Bone Support\nIn other words, staying active is a crucial part of maintaining good health and wellness. Here are the CDC physical activity guidelines for children, adults, adults over 65, and pregnant or postpartum women. Encourage your family to be more active, and challenge\nMost of the active site residues do not undergo conformational changes upon binding either calcium or inositol phosphates. The structures are consistent with bidentate liganding of the alytic calcium to the inositol phosphate intermediate and transition state.\nWe are a family owned and operated company and it is our goal to provide you with the most effective fertilizer for the working Americans’ crops. AgriTec International was founded on the idea of working smarter, and we provide scientifically proven liquid fertilizers to boost plant health and production.\nCalcium stearate is recognized as physiologically safe, and is insoluble in most solvents. Compared to waxes, it has a relatively high softening point, and, consequently, do not become greasy at higher temperatures. Calcium stearate is primarily used as an acid\n2020/4/6· Reactive metal is a group of metal elements that can form a reaction with acids, water, mineral acids and powerful oxidizing acids. This group can be identified with the activity or reactivity series, which determines the most reactive metals from highest to lowest.\nCalcium salts (e.g., calcium carbonate, calcium citrate) are used as supplements in the prevention and treatment of osteoporosis when dietary intake of calcium is insufficient. 147 148 Adequate intake of calcium and vitamin D (which increases absorption of calcium) is universally recommended for all individuals to diminish age-related bone loss and prevent osteoporosis. 147 148\nMetals, Nonmetals, and Metalloids are three classes of elements. The majority of elements in the periodic table are metals which are characterized by being shiny and solid (except Mercury) yet still malleable (or able to be molded and shaped). Metals are excellent conductors of electricity and heat. Nonmetals are primarily listed on the right side of the periodic table and have more of the\n2019/11/25· Potassium and calcium Again, these necessary minerals will compete for absorption by the body, meaning you get less of each when you take them together, warns Dr. Cooperman. People who labor or exercise in humid climates or have digestive issues can fall short on potassium; if you need to take both supplements, be sure to space them out by a few hours, he advises.\nIt is the most chemically active nonmetallic element and is the most electronegative of all the elements. It is a meer of Group 17 (the halogens halogen [Gr.,=salt-bearing], any of the chemically active elements found in Group 17 of the periodic table; the name applies especially to fluorine (syol F), chlorine (Cl), bromine (Br), and iodine (I).\nMost elements can be considered metals. They are grouped together in the middle to the left-hand side of the periodic table. The metals consist of the alkali metals, alkaline earths, transition metals, lanthanides, and actinides.Properties of Metals The metals share\nMagnesium is a silvery white metal. The surface of magnesium metal is covered with a thin layer of oxide that helps protect the metal from attack by air. Once ignited, magnesium metal burns in air with a characteristic blinding bright white flame to give a mixture of white magnesium oxide, MgO, and magnesium nitride, Mg 3 N 2 .\nCalcium will always be low in a multivitamin because it takes up a lot of room in the capsule. B12 is easy to get from food, and I think supplement companies go overboard on B12 which has negative consequences. However, if your family is vegan, you will want\nWe investigated calcium-binding motifs of peptides and their recognition of active functionalities for coordination. This investigation generates the fundamentals to design carrier material for calcium-bound peptide-peptide interactions. Interactions of different peptides with active calcium domains were investigated. Evaluation of selectivity was performed by electrospray ionization mass\nNatural Heavy Metal Detoxifiion: A daily strategy for all patients James Meschino DC, MS In modern society we are constantly exposed to heavy metals such as cadmium, lead and mercury. These heavy metals have no essential biochemical roles in our body\nThe acid-free formula is non-toxic and doesn’t pose any risks to your skin—or to the metal of the tools you’re trying to clean. Simply soak the rusty tools or parts in a bath of Metal Rescue and in anywhere from 5 minutes to 24 hours you’ll have shiny, rust-free\nleading brands of estonia First Business Address in Estonia Estonian Chaer of Commerce and Industry Contact data Address: Toom-Kooli 17, 10130 Tallinn, Estonia Phone: +372 604 0060 E …\nCalcium Carbonate is the carbonic salt of calcium (CaCO3). Calcium carbonate is used therapeutically as a phosphate buffer in hemodialysis, as an antacid in gastric hyperacidity for temporary relief of indigestion and heartburn, and as a calcium supplement for preventing and treating osteoporosis.\nChamomile has many appliions beyond a comforting cup of tea. Chamomile looks similar to a daisy with its white petals and yellow disc florets.The flowers have a strong aroma and bloom in the early to mid summer months. It''s found in populated ares of Europe, Asia, North America and Australia near roads, landfills or in cultivated fields as a weed.\n2020/1/29· The most metallic element is francium.However, francium is a man-made element, except for one isotope, and all isotopes are so radioactive they almost instantly decay into another element. The natural element with the highest metallic character is cesium, which is found directly above francium on the periodic table.","Stability of Noble Gases\nWhat is Chemical Compound\n- A chemical compound is a substance that is formed by more than one elements that bond together chemically in a fixed proportions.\n- In periodic table, there are only 118 elements, and about 1/3 of them are synthetic elements.\n- Only a few substances exist as element (Not Compound) in nature.\n- The table below shows some examples of substance exist as element in nature.\n|Element exist as monoatomic gas||Element exist as diatomic Molecule(gas)||Element exist as solid|\n|Carbon (Graphite & Diamond)|\n- In nature, we can find millions of substances, which means most of the chemical substances exist as compound in nature.\n- In short, elements tend to form compound in nature.\nWhy Elements Tend to Form Compound?\n- A compound is formed by 2 or more elements hold together by a force called chemical bond.\n- Before studying why elements like to bond together, we need to know why certain elements such as Helium and Neon do not form any bonds with other elements.\nWhy Noble Gases Don't Form Compound\n- In previous chapter, we have discussed that Group 18 elements (Noble Gases) exist as monoatom in nature.\n- They are inert in nature and do not react with any other elements (or themselves) to form any chemical compounds.\n- In other words, they are chemically very very stable (or chemically very very non-reactive).\nDuplet and Octet Electron Arrangement\n- The charge on the nucleus and the number of electrons in the valence shell determine the chemical properties of an atom.\n- The stability of noble gas is due to their electrons arrangement.\n- The diagram above shows the first four elements of Noble Gas.\n- We can see that the outer most shell (valence shell) of Helium has 2 electrons. We call this duplet electron arrangement. We should take notes that the maximum number of electrons can be filled in the first shell is 2 electrons, which means 2 electrons in the first shell is considered FULL.\n- The valence shell all other Group 18 elements (including Xenon and Radon which is not shown in the diagram) has 8 electrons, and we call this octet electron arrangement.\n- When the electron arrangement of an atom is duplet or octet, the energy of the electrons is very low, and it is very difficult (even though it is not impossible) to add or remove electrons from the atom.\n- This explain why noble gases are reluctant to react with all other elements.\nThe Octet Rule\n- So far we have learnt that the electon arrangement of noble gases are octet duplet, and this is the most stable electron arrangement of an atom.\n- Atoms of other main group elements which is not octet tend to react with other atoms in various ways to achieve the octet.\n- The tendency of an atom to achieve an octet arrangement of electrons in the outermost shell is called the octet rule.\n- If the outermost shell is the first shell, then the maximum number of electrons is two, and the most stable electron arrangement will be duplet.\n- A configuration of two electrons in the first shell, with no other shells occupied by electrons, is as stable as the octet electron arrangement and therefore is also said to obey the octet rule.\nHow Atoms Achieve Duplet or Octet Electron Arrangement?\n- Atoms can achieve duplet or octet electron arrangement in 3 ways:\n- throw away the excess electron(s)\n- receiving electron(s) form other atom if they are lack of electron(s)\n- sharing electron\n- 2 types of chemical bonds are commonly formed between atoms, namely\n- Ionic Bond\n- Covalent Bond\n The Ionic Bond\n- By releasing or receiving electron(s), the atoms will become ions and consequently form ionic bond between the ions.\n- Ionic bonds are always form between metal and non-metal. For example, sodium (metal) react with chlorine (non-metal) will form an ionic bond between sodium ion and chloride ion.\n- The compounds formed is called the ionic compound.\n- Some time, an ionic bond is also called electrovalent bond\n- The Covalent Bond\n- By sharing electron(s), the atoms will form covalent bond between the atom and the molecule formed is call the covalent molecule.\n- Covalent bond is always formed between non-metal with another non-metal."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"}],"document_ids":["<urn:uuid:8bd85c42-afc6-4612-8aa1-44504e135d85>","<urn:uuid:7fcfee44-e31b-4231-8489-63e67b50d717>"],"error":null}
{"question":"Siendo investigador en relaciones internacionales, quisiera conocer qué otros países además de Estados Unidos y Australia fueron invitados a participar en el ejercicio Talisman Sabre 2019. ¿Podría especificarlos?","answer":"Forces from Canada, New Zealand and the UK were invited to participate or observe. Additionally, delegations from India and the Republic of Korea were invited to observe the exercise, with a total of 18 nations from across the Indo-Pacific invited to an international visitors program.","context":["image-1 = images/TS4/1.jpg\ndescription-1 = A US Navy MH-60S helicopter lands on HMAS Adelaide flight deck off the coast of Queensland during Exercise Talisman Sabre 2019. (Credit - Defence)\nstatus-1 = 1\nimage-2 = images/TS4/2.jpg\ndescription-2 = HMCS Regina participates in the Exercise Talisman Sabre 2019 submarine familiarisation exercise during Operation Projection / Exercise Talisman Sabre in the Pacific Ocean on 11 July 2019. (Credit - Defence)\nstatus-2 = 1\nimage-3 = images/TS4/3.jpg\ndescription-3 = US Coast Guard, USCGC Stratton conducts manoeuvres with Royal Australian Navy ships, HMAS Canberra and HMAS Parramatta during Talisman Sabre 2019. (Credit - Defence)\nstatus-3 = 1\nimage-4 = images/TS4/4.jpg\ndescription-4 = Aviation Boatswain’s Mate (Equipment) 3rd Class Olivia Fobbs, from Los Angeles, provides signals prior to the launch of an F/A-18F Super Hornet assigned to Strike Fighter Squadron (VFA) 102 aboard the Navy’s forward-deployed aircraft carrier USS Ronald Reagan (CVN 76). Ronald Reagan, the flagship of Carrier Strike Group 5, provides a combat-ready force that protects and defends the collective maritime interests of its allies and partners in the Indo-Pacific region. (US Navy photo by Mass Communication Specialist 2nd Class Tyra M. Campbell)\nstatus-4 = 1\nimage-5 = images/TS4/5.jpg\ndescription-5 = Sailor assigned to Air Department observes flight operations on the flight deck of the Navy’s forward-deployed aircraft carrier USS Ronald Reagan. (US Navy photo by Mass Communication Specialist 2nd Class Tyra M. Campbell)\nstatus-5 = 1\nimage-6 = images/TS4/6.jpg\ndescription-6 = An F/A-18E Super Hornet assigned to Strike Fighter Squadron (VFA) 195 launches off the flight deck of the Navy’s forward-deployed aircraft carrier USS Ronald Reagan. (US Navy photo by Mass Communication Specialist 2nd Class Tyra M. Campbell)\nstatus-6 = 1\nimage-7 = images/TS4/7.jpg\ndescription-7 = Lance Corporal Kevin Swords of the 1st Battalion 1st Marines HWS Company, US Marine Corps, cuts steaks to cook for troops' evening meal at Camp Growl during Exercise Talisman Sabre, Shoalwater Bay, Queensland. (Credit - Defence)\nstatus-7 = 1\nimage-8 = images/TS4/8.jpg\ndescription-8 = The evening meal before the exercise gets into full swing is a time to relax and talk over ideas for the troops living at Camp Growl during Exercise Talisman Sabre, Shoalwater Bay, Queensland. (Credit - Defence)\nstatus-8 = 1\nimage-9 = images/TS4/9.jpg\ndescription-9 = US Army soldiers from the 1-27th Infantry Regiment, 2nd Inf. Brigade Combat Team, 25th Inf. Division from Schofield Barracks, Hawaii arrive in Rockhampton, Queensland, Australia for Talisman Sabre 2019. (Credit - Defence)\nstatus-9 = 1\nimage-10 = images/TS4/10.jpg\ndescription-10 = US Army soldiers from the 1-27th Infantry Regiment, 2nd Inf. Brigade Combat Team, 25th Inf. Division from Schofield Barracks, Hawaii unload their baggage from an airplane after arriving in Rockhampton. (Credit - Defence)\nstatus-10 = 1\nimage-11 = images/TS4/11.jpg\ndescription-11 = Private Charlie Lebois works with the 1st Armoured Regiment during a tactical resupply as part of Exercise Talisman Sabre at the Shoalwater Bay Training Area.(Credit - Defence)\nstatus-11 = 1\nimage-12 = images/TS4/12.jpg\ndescription-12 = Trooper Thomas Laird from the 1st Armoured Regiment stands guard during a tactical resupply during Exercise Talisman Sabre at the Shoalwater Bay Training Area.(Credit - Defence)\nstatus-12 = 1\nExercise Talisman Sabre 19: The road so far – Part 4\nScroll to read and see more\nland & amphibious | 15 July 2019 | Louis Dillon\nWith Exercise Talisman Sabre 19 officially kicking off last week, Defence Connect will provide continuous imagery updates from the biennial exercise.\nTS19 is a bilateral combined Australian and US training activity, and is designed to practice the two countries’ respective military services and associated agencies in planning and conducting combined and joint task force operations, and improve the combat-readiness and interoperability between Australian and US forces.\nOccurring every two years, Talisman Sabre is a major exercise reflecting the closeness of our alliance and strength of the enduring military relationship.\nTS19 is the eighth iteration of the exercise and consists of a field training exercise incorporating force preparation (logistic) activities, amphibious landings, land force manoeuvre, urban operations, air operations, maritime operations and Special Forces activities.\nNearly 35,000 military personnel from the US and Australia are set to take part in what will be the biggest ever Talisman Sabre.\nHistorically, Talisman Sabre exercises have been conducted across northern and eastern Australia, and within Australia’s exclusive economic zone. Additional participants from third-party nations may participate or observe the exercise if invited.\nForces from Canada, New Zealand and the UK have received such an invite, with delegations from India and the Republic of Korea will also observe the exercise, with a total of 18 nations from across the Indo-Pacific invited to an international visitors program.\nPlease scroll through the image gallery above for a look at the exercise so far."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"}],"document_ids":["<urn:uuid:c3399edd-0afa-4ca2-a0bb-18606edb2f0b>"],"error":null}
{"question":"What are the main differences between Catholic and Lutheran confession practices? Curious about the theological variations!","answer":"In Catholic practice, confession is a formal sacrament of conversion, with specific times for confession (Saturdays at noon) and special services during Lent and Advent with personal hearing of sins and general absolution. Lutheran churches also practice confession and absolution, but with a different emphasis - they focus particularly on the absolution aspect, which they consider God's word of forgiveness, rather than treating it as one of seven sacraments.","context":["Christ instituted the sacraments of the new law. There are seven sacraments: Baptism, the Eucharist, Penance, Confirmation (or Chrismation), the Anointing of the Sick, Holy Orders and Matrimony. The sacraments touch all the stages and all the important moments of Christian life.\nBaptism is birth into the new life in Christ. In accordance with the Lord's will, it is necessary for salvation, as is the Church herself, which we enter by Baptism. Since the earliest times, Baptism has been administered to children. If you would like your child to be baptised, or to receive baptism as an adult, please contact the Parish Office to arrange a date.\nThe forgiveness of sins committed after Baptism is conferred by a particular sacrament called the sacrament of conversion, confession, penance, or reconciliation. There is always a priest hearing confessions on Saturdays at noon. If you need urgent confession you can arrange an appointment calling one of the priests directly. During Lent and Advent there are communal penance services with personal hearing of sins and general absolution.\nThe Eucharist is the heart and the summit of the Church's life, for in it Christ associates his Church and all her members with his sacrifice of praise and thanksgiving offered once for all on the cross to his Father; by this sacrifice he pours out the graces of salvation on his Body which is the Church.\nTo register for First Holy Communion classes, please contact the parish office. For classes timetable, click here.\nOnce per year, in springtime, we receive the visit of an Irish bishop who celebrates the rite of Confirmation on the students of the Confirmation programme. To register for the Confirmation programme, please contact the parish office.\nThe marriage covenant, by which a man and a woman form with each other an intimate communion of life and love, has been founded and endowed with its own special laws by the Creator. St. Anthony's Parish functions as the \"English language Catholic Chaplaincy\" for the Brussels area and in this capacity has organised a pre-marriage programme for a number of years.\nIf you are planning to get married within the Catholic Church, it is mandatory to follow a pre-marriage course. St Anthony's functions as the \"English language Catholic chaplaincy\" for the Brussels area and because of the nature of the chaplaincy and the public it serves, the programme is compressed into a single day, typically taking place on a Saturday between 11:00 and 17:00. The programme is run 3 times a year and notices will be placed in Words several weeks in advance. Contact the Parish office for further details.\nIf you wish to celebrate your wedding in our church please contact the Parish Office.\nThe whole Church is a priestly people. Through Baptism all the faithful share in the priesthood of Christ. This participation is called the \"common priesthood of the faithful.\" Based on this common priesthood and ordered to its service, there exists another participation in the mission of Christ: the ministry conferred by the sacrament of Holy Orders. If you feel the call of God for priesthood contact our priests who can give you advice or indicate where you can find a seminar.\nAnointing of the sick\nThe sacrament of Anointing of the Sick has as its purpose the conferral of a special grace on the Christian experiencing the difficulties inherent in the condition of grave illness or old age. If you know someone sick who must urgently receive the holy sacraments of Penance or the anointing of the sick call the office. Praying for the sick takes an important part in the liturgy of the Holy Mass and all parishioners are encouraged to pray for the people suffering in our parish and beyond.\nThe Christian funeral confers on the deceased neither a sacrament nor a sacramental since he has \"passed\" beyond the sacramental economy. It is nonetheless a liturgical celebration of the Church. If someone close to you has died recently please contact the office in order to organise a Christian funeral.","- 1 Who can take communion in Lutheran church?\n- 2 What age do you get confirmed in the Lutheran church?\n- 3 How old are you when making communion?\n- 4 Can a Catholic take communion at a Lutheran church?\n- 5 What is the difference between Lutheran and Catholic communion?\n- 6 Do Lutherans believe you have to be baptized to go to heaven?\n- 7 What version of the Bible do Lutherans use?\n- 8 Do Lutherans get baptized?\n- 9 What is the Lutheran Church position on abortion?\n- 10 What are the requirements to receive communion?\n- 11 What Sunday is Communion?\n- 12 What age is first confirmation?\n- 13 Are Lutherans Catholic or Protestant?\n- 14 Do Lutherans believe in confession?\n- 15 Do Lutherans call it mass?\nWho can take communion in Lutheran church?\nThe Evangelical Lutheran Church in America ( ELCA ) and its congregations practice open communion —meaning that Holy Communion is offered to all those who are baptized.\nWhat age do you get confirmed in the Lutheran church?\nStudents often begin taking catechism classes at about age twelve and are usually confirmed at age fourteen. Some Lutheran pastors and theologians are now beginning to ask whether it is permissible to adopt the practice of the Eastern church and to confirm /chrismate at baptism, including infants.\nHow old are you when making communion?\nIn churches that celebrate First Communion, it typically occurs between the ages of seven and thirteen, often acting as a rite of passage.\nCan a Catholic take communion at a Lutheran church?\nCatholics believe these become the body and blood of Christ; some Protestants, notably Lutherans, say Christ is present in the sacrament. Protestants are currently allowed to receive Catholic communion only in extreme circumstances, such as when they are in danger of death.\nWhat is the difference between Lutheran and Catholic communion?\nCatholic offers a mass prayer for those who have died whereas Lutheran offers mass prayers for those who have gone before us in eternal life.\nDo Lutherans believe you have to be baptized to go to heaven?\nAccording to the Lutheran church, baptism isn’t necessary for salvation. A baby’s entrance into Heaven doesn’t depend on whether his parents had the time to get him baptized prior to his death.\nWhat version of the Bible do Lutherans use?\nThe Lutheran body to which I belong, The Evangelical Lutheran Church in America (ELCA) has a strong preference for the New Revised Standard Version (NRSV). Our Liturgical resources all use the NRSV, the Lutheran study Bible we use and the accepted text to use at seminary and I assume the colleges as well is the NRSV.\nDo Lutherans get baptized?\nLutherans teach that at baptism, people receive regeneration and God’s promise of salvation. Lutherans baptize by sprinkling or pouring water on the head of the person (or infant) as the Trinitarian formula is spoken. Lutherans teach baptism to be necessary, but not absolutely necessary, for salvation.\nWhat is the Lutheran Church position on abortion?\nThe Lutheran Church –Missouri Synod views abortion as contrary to God’s Word. The church released a statement on their website saying that abortion “is not a moral option, except as a tragically unavoidable byproduct of medical procedures necessary to prevent the death of another human being, viz., the mother.”\nWhat are the requirements to receive communion?\nCatholics are required to fast for one hour before Communion (it used to be 12 hours) and to be in “a state of grace” — that is, not aware of having committed a serious sin. Technically, the latter requirement prohibits divorced Catholics who have remarried without obtaining an annulment from receiving Communion.\nWhat Sunday is Communion?\nWorld Communion Sunday is a celebration observed by several Christian denominations, taking place on the first Sunday of every October, that promotes Christian unity and ecumenical cooperation. It focuses on an observance of the eucharist.\nWhat age is first confirmation?\nOn the canonical age for confirmation in the Latin or Western Catholic Church, the present (1983) Code of Canon Law, which maintains unaltered the rule in the 1917 Code, specifies that the sacrament is to be conferred on the faithful at about 7-18, unless the episcopal conference has decided on a different age, or\nAre Lutherans Catholic or Protestant?\nAlong with Anglicanism, the Reformed and Presbyterian (Calvinist) churches, Methodism, and the Baptist churches, Lutheranism is one of the five major branches of Protestantism. Unlike the Roman Catholic Church, however, Lutheranism is not a single entity.\nDo Lutherans believe in confession?\nBeliefs. The Lutheran Church practices ” Confession and Absolution” [referred to as the Office of the Keys] with the emphasis on the absolution, which is God’s word of forgiveness. Indeed, Lutherans highly regard Holy Absolution.\nDo Lutherans call it mass?\nScandinavian, Finnish, and some English speaking Lutherans, use the term ” Mass ” for their Eucharistic service, but in most German and English-speaking churches, the terms “Divine Service”, “Holy Communion, or “the Holy Eucharist” are used."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"}],"document_ids":["<urn:uuid:aa8a557a-0892-416d-82f2-3364aa4976d6>","<urn:uuid:63d655d1-4f74-41dc-8f2a-bfbc0986f496>"],"error":null}