{"question":"Can non-reciprocal relationships be classified as true friendships according to both ancient Greek philosophical frameworks?","answer":"No, according to both philosophical frameworks, non-reciprocal relationships cannot be classified as true friendships. This is explicitly stated in reference to Aristotle's view, where friendship is defined as a relational attitude that must be reciprocal - it is 'incoherent to say that one has a nonreciprocal friendship.' Similarly, in Epicureanism, friendship is described as involving mutual dealings and is contrasted with justice through its reciprocal nature, as evidenced by the third group of later Epicureans who viewed friendship as a 'symmetrical contract' where each friend commits to loving the other.","context":["Version: v1, Published online: 1998\nRetrieved February 26, 2024, from https://www.rep.routledge.com/articles/thematic/epicureanism/v-1\n11. Social values\nAncient ethics does not problematize altruism as such, but it does seek the moral foundations of two specific forms of altruism: justice, that is, respecting the interests of your fellow citizens; and friendship. Given that Epicurean hedonism is egoistic – that all your choices as an agent aim at your own pleasure – is it possible to put someone else’s pleasure before your own?\nEpicurus analyses justice not as an absolute value but as a contractual relation between fellow citizens, its precise character engendered by current social circumstances (Key Doctrines 31–7). Sometimes it proves mutually advantageous to abstain from forms of behaviour which harm others, in return for a like undertaking from them. So long as such a contract proves socially advantageous, it is correctly called ‘justice’. It imposes no moral obligation as such, and the ground for respecting it is egoistic – that even if you commit an injustice with impunity the lingering fear of being found out will disrupt your tranquillity (Key Doctrines 17, 35).\nWith regard to his own philosophical community, Epicurus attached positive value to justice and to the specific laws which enforced it not because philosophers need any restraint from wrongdoing but because they need protection from the harm that others might inflict. ‘Do not take part in politics’ was an Epicurean injunction, political ambition being a misguided and self-defeating quest for personal security. But the school nevertheless upheld the need for legal and political institutions, and sought to work within their framework.\nWhere the political life fails to deliver personal security, friendship can succeed. The very foundation of the Epicurean philosophical community was friendship, of which the mutual dealings of Epicurus and his contemporaries were held up as an ideal model by their successors. Unlike justice, friendship is held to have intrinsic value – meaning not that it is valuable independently of pleasure, but that it is intrinsically pleasant, not merely instrumentally pleasant like justice. Moreover, the pleasure lies in altruistic acts of friendship, not merely in the benefits received by way of reciprocation.\nLater Epicureans were pressed by their critics for a more precise reconciliation of friendship with egoism, and developed the position as follows (Cicero, On Ends I 66–70). According to one group, it is indeed for our own pleasure that we form friendships, and it is as a means to this, not ultimately for our friends’ sake, that we share their pleasure and place it on a par with our own. A second group veered away from egoism: although friendship starts out as described by the first group, the outcome is something irreducibly altruistic, whereby we come to desire our friends’ pleasure purely for their sake. A third group sought to restore egoism: the second group is right, but with the addition that friendship is a symmetrical contract, analogous to justice: each friend is committed to loving the other for the other’s own sake.\nSedley, David. Social values. Epicureanism, 1998, doi:10.4324/9780415249126-A049-1. Routledge Encyclopedia of Philosophy, Taylor and Francis, https://www.rep.routledge.com/articles/thematic/epicureanism/v-1/sections/social-values.\nCopyright © 1998-2024 Routledge.","The Science and Philosophy of Friendship: Lessons from Aristotle on the Art of Connection\n“Friends hold a mirror up to each other; through that mirror they can see each other in ways that would not otherwise be accessible to them, and it is this mirroring that helps them improve themselves as persons.”\nBy Maria Popova\n“A principal fruit of friendship,” Francis Bacon wrote in his timeless meditation on the subject, “is the ease and discharge of the fulness and swellings of the heart, which passions of all kinds do cause and induce.” For Thoreau, friendship was one of life’s great rewards. But in today’s cultural landscape of muddled relationships scattered across various platforms for connecting, amidst constant debates about whether our Facebook “friendships” are making us more or less happy, it pays to consider what friendship actually is. That’s precisely what CUNY philosophy professor Massimo Pigliucci explores in Answers for Aristotle: How Science and Philosophy Can Lead Us to A More Meaningful Life (public library), which also gave us this provocative read on the science of what we call “intuition.”\nPhilosophers and cognitive scientists agree that friendship is an essential ingredient of human happiness. But beyond the dry academic definitions — like, say, “voluntary interdependence between two persons over time, which is intended to facilitate socio-emotional goals of the participants, and may involve varying types and degrees of companionship, intimacy, affection and mutual assistance” — lies a body of compelling research that sheds light on how, precisely, friendship augments happiness. Pigliucci writes:\nHappiness is influenced, as one might expect, by all of the “big five” personality traits: agreeableness, conscientiousness, extraversion, neuroticism, and openness. … As research conducted by Meliksah Demir and Lesley Weitekamp also clearly shows, however, friendship augments happiness above and beyond the basic effect of personality.\nThe way friendship enhances well-being, it turns out, has nothing to do with quantity and everything to do with quality — researchers confirm that it isn’t the number of friends (or, in the case of Facebook, “friends”) we have, but the nature of those relationships:\nIn particular, what makes for a good happiness-enhancing friendship is the degree of companionship (when you do things together with your friends) and of self-validation (when your friends reassure you that you are a good, worthy individual).\nThis is where Aristotle comes in: He recognized three types of love — agape, eros, and philia — which endure as an insightful model for illuminating the nature of our relationships. Pigliucci describes the taxonomy:\nAgape is a broad kind of love, the kind that religious people feel that God has for us, or that a secular person may have for humanity at large. Eros, naturally, is more concerned with the type of love we have for sexual partners, though the Greeks meant it more broadly than we do. Philia is the type of love that concerns us here because it includes the sort of feelings we have for friends, family, and even business partners.\nBut this poses the obvious question of what separates love, or eros (itself a complex phenomenon nearly impossible to define, despite history’s ample attempts) from friendship, or philia — a conundrum young E. B. White and James Thurber famously considered and Sartre ultimately failed at resolving. Pigliucci explains:\nThe obvious answer is that typically (though certainly not necessarily) you have sex with your eros partner but not with your philia friends. More subtly, however, philosophers have pointed out that love is an evaluative attitude, while friendship is a relational one. It makes perfect sense that you could be in love with someone who doesn’t reciprocate your feeling, but it is incoherent to say that one has a nonreciprocal friendship.\nAristotle further classified friendships into three distinct categories: of pleasure, of utility, and of virtue:\nIn friendships of pleasure, you and another person are friends because of the direct pleasure your friendship brings — for instance, you like and befriend people who are good conversationalists, or with whom you can go to concerts, and so on. Friendships of utility are those in which you gain a tangible benefit, either economic or political, from the relationship. Exploitation of other people is not necessarily implied by the idea of utility friendships — first, because the advantage can be reciprocal, and second, because a business or political relation doesn’t preclude having genuine feelings of affection for each other. For Aristotle, however, the highest kind of friendship was one of virtue: you are friends with someone because of the kind of person he is, that is, because of his virtues (understood in the ancient Greek sense of virtue ethics [and] not in the much more narrow modern sense, which is largely derived from the influence of Christianity.)\nBut what it really boils down to is that friendship affords us a more dimensional way of looking at ourselves and at the world, thus enhancing our understanding of the meaning of life. Once again, Pigliucci takes us back to Aristotle:\nAristotle’s opinion was that friends hold a mirror up to each other; through that mirror they can see each other in ways that would not otherwise be accessible to them, and it is this (reciprocal) mirroring that helps them improve themselves as persons. Friends, then, share a similar concept of eudaimonia [Greek for “having a good demon,” often translated as “happiness”] and help each other achieve it. So it is not just that friends are instrumentally good because they enrich our lives, but that they are an integral part of what it means to live the good life, according to Aristotle and other ancient Greek philosophers (like Epicurus). Of course, another reason to value the idea of friendship is its social dimension. In the words of philosopher Elizabeth Telfer, friendship provides “a degree and kind of consideration for others’ welfare which cannot exist outside\nAnswers for Aristotle is excellent in its entirety. Complement it with some heartening famous friendships, like those between Isaac Asimov and Carl Sagan, Ernest Hemingway and F. Scott Fitzgerald, Julia Child and Avis DeVoto, Ursula Nordstrom and Maurice Sendak, and Arthur Conan Doyle and Harry Houdini.\nPublished September 19, 2013"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:5d979e37-bbb0-48d4-ae96-926e8e38ba36>","<urn:uuid:02d4390b-e25b-4c0c-8de1-6206f2a2fd7d>"],"error":null}
{"question":"What are the educational resources available at the Tutankhamun Exhibition versus the Roman Town House for learning about ancient history?","answer":"The Tutankhamun Exhibition offers structured educational resources including free introductory talks in the Exhibition's Schools Room, free worksheets at two different levels, a thriving schools programme, and comprehensive information about Ancient Egypt. In contrast, the Roman Town House offers educational value through direct experience of Roman architecture, including real Roman mosaics and hypocaust systems, with information provided through entry display boards and an optional phone-based guided tour. Both sites are useful for children engaging with their school curriculum.","context":["The Tutankhamun Exhibition has become recognised by Groups from over much of England. Visitors can experience the mystery and wonder of the discovery of Tutankhamun's tomb first hand. The Exhibition - the most comprehensive and innovative on the boy pharaoh outside of Egypt - actually recreates the tomb, treasures, and mummy of Tutankhamun.\nThe Tutankhamun Exhibition is the successor to the famous 1972 London exhibition at the British Museum. However, because the Exhibition uses unique, accurate and perfect facsimiles of the king's treasures, it has been possible to recreate the ante-chamber and burial chamber of the tomb exactly as it was when it was discovered by Howard Carter in 1922; thus capturing a moment in time forever. The Tutankhamun Exhibition is a permanent exhibition situated in the centre of Dorchester, the county town of Dorset. The Exhibition has a thriving schools programme.\nThe Exhibition starts with a wealth of information on various aspects of Ancient Egypt including the Rosetta Stone and Mummification; the historical & political background to the life of Tutankhamun; and the search for, and discovery of, his tomb. Next is a unique recreation of Tutankhamun's mummy. The body has been replicated using special techniques to exactly re-create the original, which now lies out of sight in the sarcophagus in Tutankhamun's tomb in the Valley of the Kings.\nThe reconstruction of the Ante-Chamber is filled with its treasures just as it was in 1922 and even the pleasant odours of the unguents & oils have been reproduced. The Burial Chamber depicts the coffins being raised from the sarcophagus and offers school pupils an unparalleled experience. These unique factors have made The Tutankhamun Exhibition famous in its own right. It has been extensively featured on numerous national and international television programmes including a five part documentary on Tutankhamun by the BBC - The Face of Tutankhamun, and on special school programmes, such as Landmarks and the Eureka series.\nWith the inclusion of Ancient Egypt in the National Curriculum, and in particular the emphasis on Tutankhamun, the Exhibition has become a 'must' for schools, a wonderful resource to which children can really relate. For those thinking of bringing a party, it is advisable to book well in advance, otherwise it may not be possible to obtain the dates you require.\nOn arrival groups can have a free introductory talk in the Exhibition's Schools Room. Daphne Main, our schools and groups officer, introduces the various topics covered by the Exhibition and puts this into the context of Ancient Egypt.\nFree of Charge. Please telephone in advance and identify yourself on arrival\nA free worksheet is available for children on arrival. There are two levels, and samples are available on request. Feel free to copy and/or alter the worksheet.\nThe Tutankhamun Exhibition is in the centre of Dorchester, Dorset's county town, in High West Street. It is pedestrian signposted from major car parks. We are 200 metres from the coach/car park at the 'Top of Town' roundabout. Coaches cannot stop outside the Exhibition.\nBy Road - Dorchester is centrally situated on the intersection of the A35 and the A37, and is within comfortable distance of the M5, M3, and M27. By Rail - Intercity from Waterloo to Dorchester South Station, or from Bristol to Dorchester West Station.\nIf you have any particular needs or requirements please e-mail or phone us, we are always pleased to help.\nFor pre-booked groups of 15 or more:\n|For pre-booked groups of 15 or more:|\nOne adult is allowed with every ten children.\nWe have special joint rates for groups wishing to visit the Tutankhamun Exhibition and one of Dorchester's other great attractions The Dinosaur Museum, Terracotta Warriors Museum or the Dorset Teddy Bear Museum.\n|Joint rates for the Tutankhamun Exhibition and other are:|\nOne adult is allowed with every ten children.\nThis special exhibition on ancient Egyptian mummification is on show in a new gallery within the Tutankhamun Exhibition. Admission to Mummies is free to groups when visiting the Tutankhamun Exhibition.\nAll year, daily, Apr-Sep10.00-17.00 (16.00 Oct-Mar). Closed 13-26 December. Open all other Bank Holidays.\nThe Exhibition is suitable for those with impaired mobility. Two steps at access point - temporary ramps available. Other special needs: Hearing Impaired - Although there are several audio programmes, all information is clearly labelled. Partially Sighted - Some difficulty may be experienced with the low level of atmospheric lighting.\nThe ideal size of a group is 30-35.\nIn general 90 minutes per group should be allowed for a visit, but this can be varied to meet individual requirements. After the introductory talk, the group is free to explore the Exhibition at their own pace. Everything is fully labelled and there are audio presentations. The Exhibition contains a great deal of information on ancient Egypt in general, as well as Tutankhamun in particular.\nThe Exhibition has a large gift shop with a wide range of souvenirs, statues, jewellery, papyrus, and many more Egyptian themed items. There is an extensive book section with a wide selection of titles for adults and children. Mail order is available online at www.tutankhamun-exhibition.co.uk\nRefreshments can be had from many establishments within Dorchester, or there is a pleasant park - The Borough Gardens - suitable for picnics nearby.\nWe suggest that visitors use the public toilets at the coach park before visiting The Exhibition as toilets are not available on site.\nIt is advisable to telephone to see whether the date and time of your proposed visit is available. We will then make a booking. Once you have confirmed this booking we will send you written confirmation of the details plus other information.\nPayment should be made on arrival preferably by a cheque made payable to World Heritage Ltd., alternatively by cash or credit card.\nGoverning Body: World Heritage Ltd\nEducation Officer: Daphne Main\nAddress: The Tutankhamun Exhibition, High West Street, Dorchester, Dorset DT1 1UW.\nTelephone: 01305 269571\nEmail: [email protected]","The Roman Town House...\n“What,” as John Cleese once said, “have the Romans ever done for us?”\nWell, apart from the roads, the aqueducts and the sewers, they also built villas and houses like this one, on the edge of Dorchester.\nBetween 43 AD, when they kicked the Ancient Britons off nearby Maiden Castle, and 410 AD, when they upped sticks and went back to Italy, Dorset’s Roman conquerors did their best to make themselves at home.\nThis particular des’ res’ just inside the walls of Roman Durnovaria is thought to have been built in the first decade of the 4th Century and comes complete with servants’ accommodation, mosaics and under-floor heating or hypocaust.\nDespite these “mod-cons”, over the centuries this Durnovarian Roman Town House was buried beneath the town that became Dorchester.\nWhiz forward to the 1930s and Dorset County Council bought Colliton Park as the site for its new offices. And it seemed like just the spot, until excavators started to unearth Roman columns and other bits and bobs.\nCue the full-scale archaeological dig. Major finds. Protected status. And lo and behold the Council had to change their plans because the Romans had already “bagsied” the site.\nThis confluence of events across some 1600 years means that today, anyone can walk around this very real Roman home. But it also means that it is in the most unlikely of locations, hidden away behind the main offices of the Dorset County Council.\nBest reached either through the County Library Car Park or by walking down “The Grove” and then turning right into Northernhay, this is not the most adrenaline filled trip you’ll ever do. But it is nonetheless well worth the visit. Partly because you won’t see this sort of thing for free very often and partly because if you have children it is a great place for them to engage with their school curriculum and learn things about the Romans through first hand experience.\nPompeii this isn’t, but anyone who goes to the Dorchester Roman Town House will go away being able to say that they have seen a real Roman Mosaic, that they understand what a hypocaust is and how it works and that they have walked through the remains of rooms that were built and lived in by real Romans in a real Roman town.\nAnd if you want to bring the whole experience to life that little bit more, and glean even more information than is provided on the entry display boards, all you have to do is dial a reasonably affordable number on your mobile phone and you can have your own guided tour of this remarkable archaeological dig by recorded message on your phone! How cool’s that!\nAs a visit, you could spend as little as 10 minutes or as long as a few hours and still gain something from the experience. And because it is free it’s an easy stop to fit in with other things to see and do in Dorchester and the surrounding area. If you want to slip a quiet moment into a spot of retail therapy in the town centre then this is a good place to do it and only a few minutes walk.\nYou are also in easy striking distance of the Dorset County Museum where there’s lots more interesting stuff about the Romans and others who’ve been lucky enough to live in this part of Britain. There are also other Romano-British sites to visit at Maumbury Rings, Poundbury and Maiden Castle.\nBut then that’s the beauty of a Town House, Roman or otherwise, you’re that much closer to everything that’s going on!\nBetween 43 AD, when they kicked the Ancient Britons off nearby Maiden Castle, and 410 AD, when they upped sticks and went back to Italy, Dorset’s Roman conquerors did their best to make themselves at home ...\""],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:1c776883-6dd3-4070-bb41-c67b74188bac>","<urn:uuid:0fa0aacb-7d5d-43c7-9889-671cd08ffbdf>"],"error":null}
{"question":"Could you explain how Psychiatric Nurses and Speech Pathologists differ in their approaches to treating patients with brain injuries?","answer":"Psychiatric Nurses and Speech Pathologists have different roles when treating patients with brain injuries. Psychiatric Nurses focus on the mental health aspects, reviewing patient status, providing prescribed treatments, issuing medicine, and teaching coping skills. Speech Pathologists, on the other hand, specifically concentrate on helping these patients regain their communication skills and manage any swallowing difficulties that may have resulted from the brain injury. They work on improving the patient's ability to speak clearly and provide communication strategies or alternative communication devices if needed.","context":["Welcome to our main Psychiatric Nurse Practitioner guide – part of our series of nurse career guides. This article deals with the specialist area of Psychiatric Nursing or Psych Nurse as it is sometimes known. Everything you need to know about this specialist nursing career.\nBelow you will find detailed information – job description, salary data and training – how to become a psychiatric nurse. All easy to follow … we hope!\nPsychiatric Nurse Practitioners help people who are experiencing a wide range of mental health issues. A difficult, but important and rewarding career.\n- 1 What Does a Psychiatric Nurse Do?\n- 2 Psychiatric Nurse Practitioner Salary Range\n- 3 Psychiatric Nurse Practitioner Training\n- 4 Working as a Psychiatric Nurse\n- 5 Career Outlook\nWhat Does a Psychiatric Nurse Do?\nPsychiatric nurses, or psych nurses, work with psychiatric patients of all backgrounds and ages. They help children, adults, and teens cope with psychiatric disorders, such as depression, substance abuse, or schizophrenia. In the medical field, a psychiatric nurse is called a psychiatric mental health nurse, or PMHN.\nPsych nurses use their nursing expertise in the mental health community. Therefore, they must be good at communicating and relating and be well versed in behavioral science.\nPsych Nurse Responsibilities\nWhen working as a psych nurse, you may perform the following tasks :\n- Review a patient’s status\n- Provide care based on a prescribed treatment approach\n- Issue medicine and check side effects and responses\n- Teach patients specific coping skills\n- Offer counseling to patients\n- Work with medical team members\n- Prescribe medicines\n- Offer psychotherapy services\n- Assess and diagnose mental health conditions\nPsychiatric Nurse Practitioner Salary Range\nPsychiatric Nurses can be one of the highest paid nurse specialties. The amount they make will depend on several factors – education level, experience, workplace and location.\nThe BLS Bureau of Labor Statistics does not have dedicated salary data for Psychiatric Nurses as a category. These nurses can in fact have different levels of education and training.\nA registered nurse who specializes and works as a psych nurse will earn similar amounts to other RN’s – average salary $73,550. Further educational qualifications and training will lead to significantly higher salaries.\nIf you obtain a degree as an advanced practice nurse in the psychiatric field, you will make more money as a certified nurse practitioner (CNP) or clinical nurse specialists (CNS). Psychiatric Nurse practitioners can expect to earn an average salary of $107,480.\nA pay differential increases what you make as a psych nurse, and it is included in the hourly rate for working evening or night shifts, or for charge duties. Higher salaries are usually offered to nurses that hold BSN or MSN designations. You may also receive a sign-on bonus, depending on the nursing demand in your area. In some venues, you may be able to make overtime pay.\nThe state you work in can also have a significant effect on your wages. If you live in California, Massachusetts, Hawaii, Oregon, or Alaska, you will be paid a higher salary than if you live in other states in the US. Always bear in mind the cost of living differences when comparing earnings in different states.\nHowever, making a big salary should not be your primary reason for accepting a psychiatric nurse practitioners job. You also have to regard benefits, such as tuition assistance, health insurance coverage, and paid time off. Also, traveling psych nurses make more money than nurses who work in a healthcare facility.\nPsychiatric Nurse Practitioner Training\nTo begin your career journey, you must complete a nursing program first. Most beginning nursing programs feature a clinic rotation in the psychiatric section, which permits you to experience working in this area. You can receive further insight by volunteering at a mental health agency that helps patients with psychiatric needs.\nTo become a registered nurse or an RN, you must enroll in either a two-year program in nursing or take part in a three-year hospital-based program. You can also attend a four-year college that issues four-year bachelor degrees in nursing.\nAfter you receive nursing training, you need to sit for an RN licensing exam. This exam is referred to as the National Council Licensure Examination, or NCLEX, for short. Once you have passed the exam, you are ready to apply for nursing jobs.\nTo become a psych nurse, you need to become certified through a credentialing organization, such as the well-known American Nurses Credentialing Center, or the ANCC.\nHow to Obtain Certification\nThe five-year certification requires the following:\n- An RN license, currently active\n- Two years’ experience practicing as a registered nurse (RN)\n- At least 2,000 hours of practice in clinical psych nursing within a three-year timeframe\n- Continuing education of at least 30 hours within three years\nBecoming an Advance Practice Psych Nurse\nIf you want to expand your reach as a psychiatric nurse, you need to learn more about becoming an advanced practice psych nurse. This nursing specialty is also referred to as a psychiatric mental health nurse practitioner, or PMHNP-BC or a PMHCNS-BC, a psychiatric mental health clinical nurse specialist. It just depends on where you live.\nIf you want to work as an advanced nurse in psychiatry, you need to obtain a master’s or doctoral degree in the nursing field. You can obtain a certificate for the advanced designation through the ANCC.\nIf you choose to proceed to graduate school, make sure the institution is accredited. It should be accredited by the National League for Nursing (NLN) or the American Association of Colleges of Nursing, also known as the AACN.\nTop Grad Programs for Psych Nurses\nUsually, the publication, U.S. News & World Report, is the best source for top grad programs for psychiatric nurses. Popular schools include the University of Pennsylvania in Philadelphia, Rush University in Chicago, and Vanderbilt University in Nashville. Yale University in New Haven, Connecticut and Johns Hopkins University in Baltimore are two other well-respected schools.\nDepending on the state where you live, the continuing education requirements for psych nurses vary. Therefore, you need to contact your state board and nursing organization on how you should keep your RN certification and license current.\nTaking the Initial Steps\nAs you can see, you can find a good deal of opportunity working in the mental health field as a nurse. You just need to enroll in a nursing program first and receive your RN license. Once you have worked as a nurse and honed your skills, you can specialize in the psychiatric field.\nExpress Your Interest\nEven if you have been working in the field of nursing for awhile, you will find that concentrating on a mental health career in nursing is an entirely satisfying goal. Maybe you currently work in a hospital setting. If so, let your employer know that you’re interested in the mental health field. Taking this step will give you the motivation needed to pursue both your professional and educational goals.\nWork and Learn – Online Training\nOnline programs give nurses the ability to pursue a psych nursing certificate while they are working, as well. You can take advantage of today’s technology and become a better nurse. Incorporate a nursing educational program in your daily schedule so you can be more of value to your employer or advance yourself in your nursing career.\nWorking as a Psychiatric Nurse\nIf you work as a psych nurse, you will find that you need to be able to multitask well in a healthcare setting. You also need to handle stress well. After all, you are helping people with emotional problems. Therefore, you need to maintain a professional demeanor and keep your own emotions in check.\nPsychiatric Nurse Practitioner Work Settings\nYou can choose from various venues when working as a psych nurse. Some of the health care facilities you can choose from include the following:\n- Hospitals, including VA hospital and medical centers\n- Primary care facilities\n- Government facilities, such as prisons or agencies connected to the court system\n- Private physician practices\n- Substance abuse treatment centers\n- Community mental health clinics\nWhere You Can Find Psych Nursing Jobs\nAccording to statistics, psych nurses are needed the most in the western and southern states in the US. The following states, in particular, need to fill psych nursing spots:\nThe Bureau of Labor Statistics (BLS) projects job growth figures of 16% across all nursing careers through 2024. This will be higher for Psychiatric Nurse practitioners.\nA shortage currently exists of psych nurses in the field. That is because mental health is becoming an increasing concern in the US. According to statistics, about 44 million adults were diagnosed with a mental illness in 2015. This total represents almost 18% of the adults in the country, and excludes people diagnosed with substance abuse problems.\nPsychiatric nursing is a high demand nursing role, and will continue to be of importance over the next five years. Now is the time to direct your career path so you can make a difference, whether you are currently studying to be a nurse or working as a nurse practitioner.\nIf you want to help people with substance abuse issues or mental disorders as a nurse, you will find that your opportunities in this area are excellent. You just need to make a commitment along these lines.\nOnce you know what courses to take and how to incorporate skill training in your schedule, you can look forward to a brighter and more productive tomorrow.\nPsychiatric Nurse Practitioner Resources\nCheck out our other main nursing career guides and of course the nursing salary pages for lots of information.","Speech pathologists study, diagnose and treat communication disorders, including difficulties with speaking, listening, understanding language, reading, writing, social skills, stuttering and using voice. They work with people who have difficulty communicating because of developmental delays, stroke, brain injuries, learning disability, intellectual disability, cerebral palsy, dementia and hearing loss, as well as other problems that can affect speech and language. People who experience difficulties swallowing food and drink safely can also be helped by a speech pathologist.\nWhere do speech pathologists practice?\nSpeech pathologists work across a range of health settings including hospitals, schools, community health centres, residential and aged care facilities, disability services, mental health facilities, juvenile justice centres and private clinics.\nServices provided by government or not for profit organisations may be free of charge though there is often a waiting list for public services. Private services are provided by speech pathologists who may work in a sole practice or with other speech pathologists and in multidisciplinary practices.\nWhen should I see a speech pathologist?\nThere are many reasons why a person might benefit from seeing a speech pathologist. A formal referral is not generally required to see a speech pathologist. Some typical issues that may lead a person to see a speech pathologist include:\n- A child that has difficulty being understood by other children in the child care centre\n- A high school student who stutters and wishes to speak more fluently and with confidence.\n- A person experiencing difficulty speaking clearly after a brain injury\n- A person with dementia who needs assistance communicating with family and carers and making choices about their future\n- A person who is experiencing difficulties swallowing safely following a stroke.\nWhat services do speech pathologists provide?\nSpeech pathologists offer a broad range of services to support people in managing their communication skills and capacity to swallow safely. Examples of the type of work speech pathologists undertake with people are:\n- Providing communication strategies and augmentative or alternative communication devices for a person who cannot communicate verbally\n- Teaching a person who has had a stroke to swallow safely without choking and/or regain their communication skills\n- Helping children who have difficulty with their speech such aschildhood apraxia of speech\n- Helping pre-school and school aged children who have difficulty understanding others or difficulty sharing their thoughts, ideas and feelings\n- Helping children and adults who stutter to speak more fluently and with confidence\n- Providing advice to parents/carers who have babies or toddlers with feeding and swallowing difficulties.\n- Helping individuals with voice disorders including difficulties with voice quality, pitch or loudness.\nHow are speech pathologists qualified?\nIn order to practise as a Certified Practising Speech Pathologist (CPSP), speech pathologists must meet the following requirements:\n- Complete a recognised undergraduate or masters level qualification\n- Complete continuing professional development as set out by Speech Pathology Australia\n- Demonstrate that they have practised as a speech pathologist in the previous five years for a minimum of 1000 hours to meet Recency of Practice requirements.\nSpeech pathology is a self-regulated profession. Speech Pathology Australia is recognised by the Department of Education and Training as the assessing authority for speech pathologists in Australia.\nFor more detailed information about speech pathology, please visit the Speech Pathology Australia website.\nFind a speech pathologist\nSpeech Pathology Australia has a Find a Speech Pathologist service that can be accessed here."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:5b0660fb-c2b8-4a1f-87d4-9b05a8130c0d>","<urn:uuid:2c073f8e-3e84-4268-9372-11d28375cf84>"],"error":null}
{"question":"How can organizations effectively implement a commissioning process for both physical building systems AND their digital twin models? Could you provide a step-by-step methodology for ensuring both aspects are properly verified? Please explain the key verification points needed.","answer":"To implement effective commissioning for both physical and digital assets: 1) Start by stating clear requirements for both building systems and model data, 2) Break requirements into individually testable parts, 3) Continually verify and test model objects and larger systems through all phases, 4) During physical equipment checks, verify location and quantities in the model and input/verify key equipment attributes, 5) Add commissioning data to the model and log on-site adjustments, 6) Use industry standard templates to ensure structured commissioning of model data, 7) Test-run procedures using models and documentation, and 8) Perform completion tests to verify both functional requirements and digital asset structure/contents.","context":["Lifecycle BIM and commissioning have the same goal - the successful operation of buildings. In this article we will explore the interdependencies of the two. We will argue that Commissioning needs BIM. Then we will argue that BIM needs commissioning.\nWhat is commissioning and why should you care?\nA commissioned ship is a ship deemed ready for service. It has done its sea trials and it is ready for open waters.\nFor the AEC project organisation commissioning means to “Bring into working condition”. For the building owner commissioning means you “Get what you pay for”\nA more formal definition of building commissioning is this :\nWhen a building is initially commissioned it undergoes an intensive quality assurance process that begins during design and continues through construction, occupancy, and operations. Commissioning ensures that the new building operates initially as the owner intended and that building staff are prepared to operate and maintain its systems and equipment. Source : California Commissioning Collaborative\nAs you may recognise, commissioning has many similarities with the soft landings methodology we have previously covered. Some sort of commissioning process have been common for mechanical equipment in buildings for a while. Lately we have seen a more broad focus on commissioning as an integrated part of the facility acquisition process. Commissioning has been recognised as one of the most effective means to ensure that all building systems will perform as designed after handover. The goal is to detect and correct problems that would eventually surface as more costly maintenance or safety issues.\nCommissioning challenges today\nEven if in theory commissioning make much sense in practice the uptake has been limited. Most of the uptake, especially in the US, has been driven by LEED certification requirements, where fundamental commissioning are mandatory and enhanced commissioning give you extra points.\nPart of the reason for the slow uptake is that there is generally a lack of awareness in the industry. Owners have not had the skills and competence to know how to set requirements. Responsibilities have been fragmented and without a specific budget the commissioning has been done by the project team members themselves as part of normal quality assurance activities.\nTo fill its purpose an objective third party consultant should be used as an commissioning agent to give unbiased advice, suggestions and verifications. To get this third party consultant up to a level where s/he can give sound advice takes time and is therefore an investment. Similarly training and involving the operations team is an investment. We live in a world where operations are often outsourced and suppliers are regularly replaced. Owners do not know how long the technicians will be working on their property and may be uncertain if the extra investment make sense.\nThe commissioning process is hard to get right. With a complex building with a lot of technology and systems that need to interoperate there are thousands of checks, tests and fine tunings that needs to be performed as a continuing process. It is generally challenging to keep track of the responsibilities, statuses and results of all these tasks. Deviations and issues needs to be communicated between the trades, resolved, verified and brought to closure. The owner needs to take an active part in this process and there is a big risk of miscommunication.\nIt is hard to get an overview of the status and the result of tweaking one setting will affect another. It is hard to capture knowledge from the field and transfer it to the people that will later operate the asset.\nHow BIM can help commissioning\nThere are multiple ways BIM can improve commissioning. We already mentioned the common goal of delivering a building ready for operation.\nIn addition to BIM being a process, a BIM is a lifecycle information repository of a construction project. The structured and integrated nature of the model will help the project team move from document-centric to data-centric ways of working. Done right BIM will connect data to processes and connect people to those processes at the right time.\nWhen using BIM during design there is easier for both the commissioning agent and the operational team to get involved as early as needed. They now have a way to explore the systems and how they are proposed to work together. They will be able to test the design intent before any equipment has been ordered. The building should be designed for end use and operational use. Owners and users representatives can now verify that.\nHaving access to a model should make it easier for the commissioning agent to get familiar with the building and its systems quicker and therefore the path to value is quicker.\nThe commissioning process itself can be streamlined by using specialised software that keeps track of all the equipment, systems and all the checks and tests that should be run and then what the status of all those are. Having such a shared tool that is accessible on mobile units give all the participants a common platform to resolve issues, see status of tests and handle exceptions.\nIf this shared commissioning tool is running “on top” of the model you reach yet another level of productivity. With a well structured model you have a complete inventory of the equipment to be ordered and installed on the project. You also know how these components are supposed to work together in systems and you have the design intent and construction documentation readily available as links. You can use this both when planning for inspections and when doing the real tests on site\nWhenever you do a test, fill out a checklist or coordinate an issue you have access to the component and system specs and by working in the shared repository you automatically update the component and system history.\nA lot of time in commissioning is spent on tracking down information and making decisions based on limited data. With an updated BIM for commissioning repository you can easily visualise the status of functional tests to see what needs a retest and see if larger systems are ready for test, alternatively what is holding it back.\nLifecycle BIM challenges today\nNow let's switch our focus on the status of lifecycle BIM. Owners have been told that if they design and construct assets using BIM methodologies, then at handover they will have a complete digital twin of their facility that contains, among others\n- A complete asset and component register of what has been installed and where\n- A functional and logical description of how equipment work and interoperate in systems\n- Embedded properties and parameters that describe both design requirements and delivered capacity and performance\n- Links to procedures, operations manuals, product datasheets etc\n- A history of the life of the component and systems so far.\nToday what you can typically expect from a BIM based handover is a combination of federated discipline models and some sort of semi-structured handover set of data and documents. The data and documents can be in a standard format, e.g. COBie or it could be according to some standard data format specified by the client or generated by a data management tool. Whether links are kept between the model objects and the handover data varies a lot. Often there has been no requirements to link data and documents to the model and creating the links after the fact is a very tedious process. If you start creating the links manually you often find that the models are as-designed and not as-built so working in this situation where the map do not fit the terrain is challenging.\nEven if the situation is improving in the industry, the generic state is that models non-verified and as-designed, data is bad and largely unusable, links are missing and the overall quality of the handover set is at a state where you wonder if you can trust it.\nHow commissioning can fix Lifecycle BIM\nIf the handed over models are not ready for operational use maybe we should explore the use of commissioning methodologies to improve the quality and readiness of the digital asset as well? As with “conventional” commissioning it involves stating what you want, breaking the requirements down into parts that can be individually tested and then continually verifying, testing and tweaking both the model objects and the larger systems during the phases\nThen as the procurement, product install and start up processes progresses use the commissioning process to make sure you get a good “digital twin” of the actual asset. When you do your test and checklist, part of the check should be to verify that the location and quantities of equipment is correct and you should input and/ or verify key equipment attributes and physical tagging when you are on site doing your physical checks.\nThe resulting model should be according to owners handover requirements - it should be as-built and as-requested. The only way to achieve that is adding extra commissioning data to the model and logging adjustments made on site for the designers to update the model.\nTo achieve this the owner should have a portfolio strategy for what is required for BIM based facilities management. Requirements in this strategy should inform the BIM execution plan and there should be templates based on industry standards that supports the process of ensuring structured commissioning of model data - commissioning the digital twin\nWith proper BIM requirements and a proper model the operations organisation will also be able to test run procedures and perform “what if” scenarios using the models and documentation as a foundation. With a list of typical tasks the maintenance and operations managers will easily be able to quality check the models and documentation and their suitability for real life use.\nPutting it together\nAs we have seen there are a common goal and synergies between lifecycle BIM and commissioning. Lifecycle BIM will help make the commission process more efficient and effective. Using commissioning principles on the model generation and delivery itself and integrating model data capture into commissioning tasks will fix model quality, help training and prepare for smooth handover and operations.\nBy combining the two you do not only get the traditional deliverables of building commissioning, but a digital asset that offers information on the future operations and maintenance of the facility. The can trust the contents of the model, it suits your needs and you have access to design intent, installed equipment data and history and performance data of the systems starting the asset history.\nThe same way you have completion tests to ensure that the product delivery functional requirements, you should have completion test to verify that the digital asset structure and contents fulfills requirements and fully reflects what is really installed in the facility\nComments and inputs are welcome. Please add comment below. If you are interested in more articles on lifecycle BIM and SMART FM, please sign up for our newsletter"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:c277222d-08a4-4214-826c-0a15f9d0fbf4>"],"error":null}
{"question":"What is the minimum retention period required for insurance records according to business recordkeeping guidelines and construction industry standards?","answer":"According to recordkeeping guidelines, insurance records should be kept permanently for general businesses, while in the construction industry the minimum retention period is 10 years. Insurance records and policies are specifically listed among documents that must be retained for at least a decade in construction businesses.","context":["Small Business Advice\nKeeping Business Records Organized\nDeciding what business records to keep and which business records to toss is not a straightforward decision. But our small business advice will give you some good guidelines for proper business recordkeeping.\nAs this year winds down, it's natural to look forward to the new year and begin planning for the future.\nBut December is also the time to look back at all of the records you've amassed during the past 12 months.\nWhat are you supposed to DO with all of this stuff? Do you keep the personnel records indefinitely? Can you ditch the tax information after 7 years? How long do you need to keep your partnership agreements or your audit reports?\nHere are guidelines to help you determine the answers to such questions and decide what you should keep and what you can toss if you're part of an association or a for-profit or not-for-profit business.\nCreating a Retention Policy\nTo establish a plan for throwing away documents at regular intervals (aka your retention policy), ask yourself the following questions:\n- How useful is this record to the company?\n- What would the consequences be if we didn't keep this record?\n- How often has the company been called upon to provide this information in the past?\n- What do we need to respond to the most recent requests for information?\n- Is this document required for governmental reporting?\n- Could this document be required in case of litigation?\n- Do we need this document for historical purposes?\nOnce you've answered these questions, you will have your criteria for keeping and discarding documents. And don't forget all of the electronic records you're keeping now. You'll need to answer the same set of questions about your company's e-mail, as well as all the information stored on computers and networks.\nAccording to experts in records management, businesses, associations and not-for-profits should permanently keep the following documents:\n- Audit reports\n- Board minutes\n- Cancelled checks for special contracts, important payments, asset purchases and payment of taxes--keep each check with the appropriate documentation to explain the purchase\n- Capital stock and bond records\n- Cash books\n- Charts of accounts\n- Computer backups\n- Constitution and bylaws\n- Contracts and leases (those that are still in effect)\n- Correspondence concerning legal and other important matters\n- Deeds, bills of sale and mortgages\n- Depreciation schedules\n- Insurance records\n- Minutes for directors', stockholders' and charter meetings\n- Payroll records\n- Property records, including blueprints and plans\n- Retirement information, including IRA and Keogh contributions\n- Stock and bond certificates--even the cancelled ones\n- Tax returns\n- Trademark, copyright and patent registration\n- Year-end financial statements\n- Year-end trial balances\nKeep 5-10 Years\n- Accident reports or claims in settled cases\n- Accounts payable ledgers and schedules\n- Accounts receivable journals and schedules\n- Allowances and reimbursements to vendors, employees and company officers for travel and entertainment expenses\n- Cancelled checks that were NOT for important purchases, legal matters or taxes\n- Client billings\n- Expired contracts\n- Expired leases\n- Inventory records\n- Invoices to customers\n- Invoices from vendors\n- Ledgers from subsidiaries\n- Sales records\n- Timecards and daily reports\n- Vendor invoices\n- Voucher register and schedules\nKeep 1-5 Years\n- Bank statements\n- Company publications\n- Employee personnel records (after termination of employee)\n- Employment applications for people not hired\n- Fundraising information and reports\n- General correspondence with customers and vendors\n- Grant applications\n- Internal audit reports\n- Monthly financial reports\n- Newsletters and other collateral materials\n- Petty cash vouchers\n- Policies and procedures\n- Purchase orders\n- Receiving sheets\n- Safety records\nThe length of time that you need to keep records depends to a great extent on your industry and the type of company or not-for-profit you run. For expert guidance about your particular industry, check with the Web site of the Association of Records Managers and Administrators (ARMA).\nOne final tip about records: electronic files now keep track of more business information in a smaller space. Even ephemeral means of communication such as e-mail can be kept for decades.\nFor that reason alone, never type anything into an e-mail that you wouldn't feel comfortable reading into evidence at a trial. Especially when dealing with bosses, supervisors, co-workers and employees, keep any clever, cutting or off-color remarks out of letters, memos and e-mails--even the interoffice variety.\nAnd when in doubt about tossing a particular record, check with your attorney or accountant just to be safe.\nShare this article\nAdditional Resources for Entrepreneurs","The Fair Labor Standards Act (FLSA) requires all employers to maintain accurate records of their employee’s wages, hours worked, and more. As the United States Department of Labor (DOL) ramps up its efforts to pursue contractors in violation of the FLSA, it’s becoming clear that contractors must be proactive in their efforts to maintain compliance.\nIn this editorial, a Chattanooga construction lawyer from Cotney Construction Law will detail some important recordkeeping tips for contractors. As a bonus, we’ll also discuss some tips pertaining to OSHA’s regulation 29 CFR 1904, which involves recordkeeping for employee injuries.\nTip #1: Understand the FLSA Recordkeeping Requirements\nAs a contractor, your workload doesn’t always give you the time you need to deftly handle your own recordkeeping, but you can’t afford to be caught in possession of incomplete financial records. Our Chattanooga construction lawyers can review your books and help you avoid a violation of the FLSA. We can ensure that your records include all the employee information required by the FLSA including:\n- Time tracking (hours per week)\n- Daily and weekly earnings\n- Hourly rate (including overtime)\n- Total overtime pay\n- Total wage deductions\n- Total wages paid every pay period\nTip #2: Develop a Comprehensive Document Retention System\nRegardless of the size of your firm, developing a comprehensive system for document retention is the most effective way to maintain compliance with FLSA recordkeeping requirements. As you take on multiple projects, the size of your workforce will fluctuate and change, so you need to work closely with employees in managerial roles to ensure that you are receiving accurate employment records.\nDocument retention involves the preservation of employee records, including time cards and work time schedules. If a government inspector requests these documents and you fail to produce them or provide access to them, you could be issued additional penalties for wage violations. You should never, under any circumstances, destroy employee records without first speaking to a Memphis contractor lawyer. Willful destruction of recordkeeping data can result in a fine of up to $10,000.\nWhen it comes to document retention, your safest bet is to, as long as space permits, keep records indefinitely to protect yourself from any potential issues with the FLSA down the road. In fact, your recordkeeping efforts should go above and beyond what FLSA requires. Contractors should maintain records in accordance with the following guidelines:\nRetain for a minimum of two years:\n- Daily Sales Summary\n- Accounts and Notes Receivable Trial Balance\n- Prepaid and Accrued Expense Journal\n- All Other Trial Balances\nRetain for a minimum of four years:\n- Employment Applications\n- Petty Cash Vouchers and Summary\n- W-4 Forms\nRetain for a minimum of seven years:\n- Vendor Invoices\n- Purchase Orders\n- Customer Invoices\n- Credit Memos\n- Office Receipts\n- Register Sales Slips\n- Receiving Reports\n- State and Local Sales and Gross Receipts Tax\n- Income Tax Returns\n- Safety Records\n- Inventory Records\n- Employee Personal Records (after termination)\nRetain for a minimum of ten years:\n- Insurance Records and Policies\n- Vendor Invoices\n- Bank Drafts and Paid Notices\n- Bills of Lading\n- Bank Statements and Reconciliations\n- All Correspondence and Customer Files\n- U.S. and State Unemployment Tax Returns\n- Social Security and Withholding Tax Returns\n- Duplicate Deposit Tickets\n- Employee Earning and History Records\n- Subsidiary Ledger\n- Journal Vouchers\n- Notes Receivable Ledger\n- Accounts Receivable or Payable Ledger\n- Financial Statements\n- Property Records\n- Capital Stock Books\n- Cash Received Journal\n- Audit Reports\n- Cash Disbursement Journal\n- Canceled Checks\n- Depreciation Schedules\n- U.S. Revenue Agents Reports & Related Papers\n- Purchase Journal\n- State Franchise Tax Returns\n- Interdepartmental Sales Journal\n- State Annual Reports\n- Payroll Journal\n- Corporate Minutes Book\n- General Journal\n- Government Contracts and Supporting Records\n- General Ledger\n- Construction Contracts and Supporting Records\n- Expense Ledger\n- Employment Contracts\n- Sales and Cost of Sales Ledger\n- Papers Pertaining to Litigation\n- Deeds, Mortgages and Bills of Sale\nTip #3: Don’t Mix Business and Personal Finances\nClearly, the recordkeeping needs of a contractor require an exhaustive effort from more than one person, especially in medium- to large-sized firms. With multiple revenue streams, a revolving door of workers, and numerous clients, the cash flow of a contracting business is fluid and continuous. You don’t want to further confuse matters, so never mix your business and personal finances. This is one of the most effective ways to avoid a compliance issue, and by keeping these finances separate, you actually help simplify your books.\nTip #4: Embrace New Recordkeeping Practices\nLet’s face it, as your company grows, you will need to adopt new procedures for keeping your business running smoothly. This could mean a number of things for your business. It could mean hiring an accountant or dedicated bookkeeper to maintain your records, or it could mean partnering with a Memphis construction attorney to review your records and represent you in cases pertaining to FLSA violations. What matters most is that you are proactive in safeguarding your business against avoidable disputes and litigation. This may require an investment of time and money, but it will only help elevate your bottom line as time goes by.\nTip #5: Don’t Forget About OSHA\nIn addition to the recordkeeping requirements outlined in the FLSA, contractors must also be cognizant of the Occupational Safety and Health Administration (OSHA) recordkeeping requirements outlined in 29 CFR 1904. As previously discussed in our article Record Keeping Mistakes, this regulation “requires employers with more than 10 employees, unless exempt, to record, report, and post illnesses and injuries that occur on job sites.”\nWhile the documentation pertaining to illness and injury records is markedly different than the documents related to your company’s finances, the same level of diligence is required to prevent a violation.\nIt’s imperative that contractors know which forms are utilized for reporting and recording workplace injuries and illnesses. You should be familiar with Forms 300, 300A, and 301. Form 300 is a “Log of Work-Related Injuries and Illnesses.” Form 300A is a “Summary of Work-Related Injuries and Illnesses” that must be posted in the workplace between February 1st and April 30th. Contractors should keep these two forms for a minimum of five years. Form 301 is an “Injury and Illness Incident Report” that is also the first form you should fill out in the incident of a work-related injury or illness.\nAnother important distinction that contractors must consider is the difference between injuries and illnesses that are reportable and recordable. Only report and record work-related incidents that result in death, loss of consciousness, days off, limited work activity, change of position, and medical treatment (excluding first aid).\nYou may also have to record certain conditions that can only be diagnosed by a medical professional. This includes cancer and irreversible diseases, bone injuries, hearing tests and eardrum punctures, contaminated needlestick injuries or cuts, and tuberculosis infections. If you need legal advice about what recordkeeping practices are best suited for your company, consult one of our Memphis contractor lawyers.\nDisclaimer: The information contained in this article is for general educational information only. This information does not constitute legal advice, is not intended to constitute legal advice, nor should it be relied upon as legal advice for your specific factual pattern or situation."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:3bba59f0-1cab-4dd0-82dc-ab0d9d6eaeeb>","<urn:uuid:8ecc11cf-9ab3-4c60-99d1-a45da4d7506d>"],"error":null}
{"question":"How do procedural fairness and modern algorithmic fairness approaches compare in their treatment of bias? Can you outline the key similarities and differences between these two frameworks in the context of machine learning systems?","answer":"Both procedural fairness and modern algorithmic fairness approaches aim to address discrimination, but they differ in important ways. Procedural fairness focuses on making algorithms fair through their inherent design features, regardless of outcomes - like equalizing false positive rates across racial groups. However, this often creates tension with accuracy, as seen in the COMPAS algorithm where equalizing error rates between racial groups would reduce overall prediction accuracy. Modern algorithmic fairness research, as discussed in recent work, takes a broader approach by examining unfairness at every step of the algorithmic pipeline, from data collection to analysis, while considering both statistical and individual notions of fairness. This approach also explores causal relationships and long-term impacts, going beyond just procedural fixes to consider the entire system's fairness.","context":["Our lives are increasingly affected by algorithms. People may be denied loans, jobs, insurance policies, or even parole on the basis of risk scores that they produce.\nYet algorithms are notoriously prone to biases. For example, algorithms used to assess the risk of criminal recidivism often have higher error rates in minority ethic groups. As ProPublica found, the COMPAS algorithm – widely used to predict re-offending in the US criminal justice system – had a higher false positive rate in black than in white people; black people were more likely to be wrongly predicted to re-offend.\nFindings such as these have led some to claim algorithms are unfair or discriminatory. In response, AI researchers have sought to produce algorithms that avoid, or at least minimize, unfairness, for example, by equalizing false positive rates across racial groups. Recently, an MIT group reported they had developed a new technique for taking bias out of algorithms without compromising accuracy. But is fixing algorithms the best way to combat unfairness?\nIt depends on what kind of fairness we’re after. Moral and political philosophers often contrast two types of fairness: procedural and substantive. A policy, procedure, or course of action, is procedurally fair when it’s fair independently of the outcomes it causes.\nA football referee’s decision may be fair, regardless of how it affects the game’s outcome, simply because the decision was made on the basis of an impartial application of the rules. Or a parent’s treatment of their two children may be fair because it manifests no partiality or favoritism, even if it has the result that one child’s life goes much better than the other’s.\nBy contrast, something that is substantively fair produces fair outcomes. Suppose a football referee awards a soft penalty to a team that is 1-0 down because she thinks the other team’s lead was the result of pure luck.\nAs a result, the game finishes in a 1-1 draw. This decision seems procedurally unfair – the referee applies the rules less stringently to one team than the other. But if a draw reflects the relative performance of the two teams, it may be substantively fair.\nAlternatively, imagine that a mother and father favor different children. Each parent treats the disfavored child unfairly, in a procedural sense. But if the end result is that the two children receive equal love, then their actions may be substantively fair.\nAI researchers concerned about fairness have, for the most part, been focused on developing algorithms that are procedurally fair – fair by virtue of the features of the algorithms themselves, not the effects of their deployment. But what if it’s substantive fairness that really matters?\nThere is usually a tension between procedural fairness and accuracy – attempts to achieve the most commonly advocated forms of procedural fairness increase the algorithm’s overall error rate. Take the COMPAS algorithm for example. If we equalized the false positive rates between black and white people by ignoring the predictors of recidivism that tended to be disproportionately possessed by black people, the likely result would be a loss in overall accuracy, with more people wrongly predicted to re-offend, or not re-offend.\nWe could avoid these difficulties if we focused on substantive rather than procedural fairness and simply designed algorithms to maximize accuracy, while simultaneously blocking or compensating for any substantively unfair effects that these algorithms might have.\nFor example, instead of trying to ensure that crime prediction errors affect different racial groups equally – a goal that may in any case be unattainable – we could instead ensure these algorithms are not used in ways that disadvantage those at high risk. We could offer people deemed “high risk” rehabilitative treatments rather than, say, subjecting them to further incarceration.\nAlternatively, we could take steps to offset an algorithm’s tendency to assign higher risk to some groups than others – offering risk-lowering rehabilitation programs preferentially to black people, for instance.\nAiming for substantive fairness outside of the algorithm’s design would leave algorithm designers free to focus on maximizing accuracy, with fairness left to state regulators, with expert and democratic input. This approach has been successful in other areas. In medicine, for instance, doctors focus on promoting the well-being of their patients while health funders and policymakers promote the fair allocation of healthcare resources across patients.\nIn substance or procedure\nOf course, most of us would be reluctant to give up on procedural fairness entirely. If a referee penalizes every minor infringement by one team, while letting another get away with major fouls, we’d think something had gone wrong – even if the right team wins.\nIf a judge ignores everything a defendant says and listens attentively to the plaintiff, we’d think this was unfair, even if the defendant is a jet-setting billionaire who would, even if found guilty, be far better off than a more deserving plaintiff.\nWe do care about procedural fairness. Yet substantive fairness often matters more – at least, many of us have intuitions that seem to be consistent with this.\nSome of us think that presidents and monarchs should have the discretion to offer pardons to convicted offenders, even though this applies legal rules inconsistently – letting some, but not others, off the hook. Why think this is justified? Perhaps because pardons help to ensure substantive fairness where procedurally fair processes result in unfairly harsh consequences.\nMany of us also think that affirmative action is justified, even when it looks, on the face of it, to be procedurally unfair, since it gives some groups greater consideration than others. Perhaps we tolerate this unfairness because, through mitigating the effects of past oppression, affirmative action tends to promote substantive fairness.\nIf substantive fairness generally matters more than procedural fairness, countering biased algorithms through changes to algorithmic design may not be the best path to fairness after all.","Machine learning and data analysis have enjoyed tremendous success in a broad range of domains. These advances hold the promise of great benefits to individuals, organizations, and society as a whole. Undeniably, algorithms are informing decisions that affect all aspects of life, from news article recommendations to criminal sentencing decisions to healthcare diagnostics. This progress, however, raises (and is impeded by) a host of concerns regarding the societal impact of computation. In a short but intensive cluster at the Simons Institute, we discussed the concern of algorithmic fairness: will algorithms discriminate or make more equitable decisions? Unfortunately, we can consistently observe that, left to their own devices, algorithms may propagate and possibly even amplify existing biases. Addressing discrimination by algorithms (as well as other societal concerns) is not only mandated by law and ethics, but is essential to maintaining the public trust in the computation-driven revolution we are experiencing.\nThe study of fairness is not new, and is truly multidisciplinary: philosophers, legal experts, economists, statisticians, social scientists and others have been concerned with fairness for generations. Nevertheless, the scale of decision-making in the age of Big Data, as well as the computational complexities of algorithmic decision-making, implies that computer scientists must take an active part in this research endeavor. Indeed, computer scientists are rising to the challenge, as manifested by an explosion of research in recent years. Many of the approaches discussed in our cluster, while influenced by other disciplines, also inherently rely on computer science insights. The theory of computing (TOC) community was early within computer science to identify the importance as well as the intellectual appeal of algorithmic fairness, and early theory works have proven to be quite influential. In this cluster, we discussed recent works as well as many exciting avenues for future research. The picture that unfolded is of a rich and challenging area of research that is ripe for contributions from a wide variety of theory subareas. In the following, we will mention a small collection of the discussed topics at a very high level.\nPast successes of TOC, such as cryptography, game theory and differential privacy, have demonstrated the importance of introducing the right models and the right definitions. Models and definition for algorithmic fairness have been the topic of much research in recent years, and occupied a considerable part of our discussion in the cluster. For example, we discussed statistical notions of fairness pertaining to large populations in comparison with individual notions, as well as promising definitions that lie in between. We noted that algorithmic fairness is subtle: natural definitions can be abused and some stand in contradiction to each other. In addition, one shouldn't expect a single definition of algorithmic fairness to apply to all contexts and to all societies. Having said that, versatile models and powerful definitions have been introduced and studied, leading both to novel algorithms as well as instructive lower bounds. Some of the questions we studied are:\n- How can unfairness be identified and mitigated in each step of the algorithmic pipeline (in data collection and processing as well as data analysis)?\n- To what extent is fairness aligned with accuracy and utility, and to what extent are the two in conflict?\n- What are potential (undesirable) interactions between computational components with respect to the fairness of the larger systems they compose?\n- Can effective notions of fairness be based on the rich literature of causality? Can there be meaningful fairness guarantees without complete understanding of the relevant causal structure?\n- What are the impacts of algorithmic choices in terms of long-term fairness?\nEach of these questions relates to promising recent works, and suggests many exciting directions for future research. If nothing else, one should read this short summary as a passionate call for contributions to the understanding of algorithmic fairness and the societal impact of computation more generally. This field needs the techniques of TOC as well as its famous optimism in the face of complexities, as part of a multidisciplinary and holistic effort.\nA larger cluster on this topic will be held at the Simons Institute in Summer 2019. More information is forthcoming shortly."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:98551582-9d74-4f97-962a-55a2099f4428>","<urn:uuid:599b8480-aedc-47f1-af2a-02be3e593dd9>"],"error":null}
{"question":"How do current ocean management practices affect both marine ecosystems and fishing communities, and what challenges do these communities face in implementing safety measures?","answer":"Current ocean management practices have led to widespread degradation of marine ecosystems. Overfishing, pollution, and invasive species are causing combined impacts, particularly severe in coastal waters. In the Caribbean, for example, multiple threats have severely degraded coral reefs. Coastal pollution, especially nutrients from waste and fertilizers, creates dead zones where fish cannot survive. For fishing communities, implementing safety measures presents several challenges. Many interventions are costly for individuals, such as purchasing lifejackets or upgrading fishing vessels. Complex regulations requiring significant infrastructure may be difficult to enforce, particularly in low-income areas. Fishers may resist changes due to time requirements and potential impacts on their ability to generate income and support their families. Additionally, while some interventions are simple and cost-effective, others require external resources and support that may not be readily available in these communities.","context":["Nature.org asked Spalding exactly what these findings mean for the ocean and coastal resources upon which much of the world depends — and if there's anything we can do about their degradation.\n\"We need to start placing demands on our leaders to call for better management of our oceans.\"\nMark Spalding, Nature Conservancy scientist\nJust how much are humans affecting oceans?\nOur impact is everywhere. When we look out across the ocean, it's tempting to imagine that it's still a vast wilderness, a final frontier where humans have little impact.\nIn reality the oceans are vulnerable, particularly in coastal waters — hard up against a great storm of human disturbances. But they are also vulnerable far from land, where fishing fleets are extracting all they can.\nThere's been a lot of attention on oceans lately. How is this report different?\nThe report stands out because it captures the combined impact of major threats to the oceans — such as overfishing, pollution or invasive species — and how they affect different ecosystems such as coral reefs or mangrove forests. It's the first comprehensive review.\nIt is often not single impacts that cause problems, but a nasty concatenation. For example, a torrent of impacts has affected the Caribbean coral reefs, wave on wave: pollution, overfishing, coral bleaching and diseases. Although still beautiful and fairly productive, most of the Caribbean coral reefs are a shadow of their former selves.\nConservation on land has a long history and has captured the public imagination for decades, but in the oceans we have done very little. In many ways it seems the challenges for ocean conservation are far greater.\nI think what we're seeing is a small degree of re-balancing as conservation scientists are realizing just how much we need to do to try and sustain oceans — the largest ecosystems on Earth.\nWhat are the most affected areas of the world's oceans? And which human activities seem to be causing the most damage?\nNot surprisingly, the worst affected oceans are those that touch densely populated coastlines. We're talking about the northern Atlantic — both on the U.S. seaboard and more especially around northern Europe — and the western Pacific around Japan, Korea, China and into Southeast Asia.\nBut just as important in many ways is the unequivocal spread of human impacts across the high seas.\nUnsustainable levels of fishing are a major driver of these problems. Despite increasingly complex equipment and the opening up of new fisheries year on year, total fish catches around the world are stable or declining, and have been for a number of years.\nThe crazy part is that if we could only collectively get our act together and properly manage our fisheries, we could allow sufficient recovery and enable higher fish catches for less effort and leave our ecosystems in a better place to adapt to other impacts.\nCoastal waters are of course are greatly impacted by pollution. Nutrients are a major problem — they wash off the land, from human and animal waste and from agricultural fertilizers, and encourage algal blooms that block out light from the seabed. Or they produce toxic algae that are ingested by shellfish, making them a hazard to humans.\nAnd in extreme cases, such as in the waters off the Mississippi River, the blooms suck oxygen out of the water, leaving a dead zone the size of New Jersey where no fish can live.\nIs there any hope that the oceans can be rehabilitated? What would we have to do, or stop doing, to help the oceans and ocean habitats repair themselves?\nThe big picture can seem pretty gloomy, but we need to keep a sensible perspective. At large scales, the map points us to areas that still have a relatively low impact — surely targets to try and prioritize urgent and large-scale conservation efforts that could include large protected areas, regulations to ensure that fisheries are fairly and sustainably managed, coastal development plans to prevent pollution, and shipping and aquaculture controls to prevent the damaging release of invasive species, to name a few.\nFantastic work is also going on all around the globe, perhaps especially in some of the heavily impacted areas that show us that nature can and will bounce back if we give it the space.\nHundreds of protected areas and no-take fishing areas are undergoing remarkable recoveries, supplying larvae and adult fish to adjacent waters. New efforts at restoring salt marshes, shellfish beds and mangrove forests are beginning to pay dividends in providing a whole array of services not only to natural systems, but also to coastal populations.\nI really don't think there can be one top priority. Instead, there's a raft of problems and dozens of tried and tested methods to deal with them. The Conservancy is already a world-leader in some innovative and exciting approaches, including working with fishers and with governments.\nWe're encouraging broad-scale efforts at protection with our coral reef resilience work, and also at fine-scale restoration with our shellfish restoration work.\nWhat's the most important finding from this study? What can we, as consumers and recreational users of the world's oceans, do to help prevent further degradation of the oceans?\nI would love to see every one of us develop a greater sense of ownership of the oceans. With that comes stewardship.\nThe oceans aren't the private domain of remote industrial fishing vessels, or of oil and gas companies. We need to start placing the demands on our leaders to call for better management of our oceans.\nThat can sound like a call to restrict activities, but in fact it's quite the opposite — if the oceans are well-managed, they can provide more for us, and for our children.\nThere are personal things one can do as well. For instance, try to buy fish you know has been sustainably harvested. And if you ever find yourself headed for a beach holiday try to aim for a hotel that promotes the natural environment and encourages conservation.\nMark Spalding is a senior marine scientist at The Nature Conservancy, where he leads work to analyze global marine biodiversity, conditions and threats. He has published a number of influential books, reports and papers, particularly relating to tropical coastal environments such as coral reefs, mangroves and seagrasses.","Individuals and families living and working in fishing communities are at high risk of drowning due to their increased exposure to water. Many fishers rely on the income made from their catch to support an entire household. This leads to their involvement in dangerous fishing practices, such fishing in bad weather or in unsafe waterbodies, using unsafe fishing vessels, not having appropriate safety equipment accessible, and allowing fishing vessels to be operated by untrained or fatigued staff. These high-risk practices are particularly prevalent in low-income countries and rural/remote areas, where water vessel and water safety regulations may not be effectively enforced.\nThe children of fishers who live in close proximity to water are also at high risk of drowning as they may be left unsupervised for extended periods of time while their carers are fishing. Therefore, drowning reduction programs must target both adults and children simultaneously in order to effectively prevent drowning in this context.\nReducing drowning among fishers\n- Educate individuals on the risks and hazards of water, enabling them to identify and avoid dangerous weather conditions and unsafe waterbodies\n- Encourage large commercial fishing boats adhere to safety regulations, protecting the occupants on board and ensuring smaller private boats are not endangered\n- Encourage boat occupants adhere to safety regulations such as wearing life jackets and not exceeding maximum occupancy\n- Provide fishers with CPR and rescue skills to enable them to act effectively in an emergency\n- Improve swimming skills and water safety skills so that individuals can stay afloat if they fall overboard or are swept off the shore\n- Ensure hazardous and shallow waterways are clearly marked Avoid consumption of alcohol and other drugs when fishing or on the water\nReducing drowning in children and infants\n- Provide good adult supervision around the home and in day care. Carer education may be required to establish the elements of good supervision.\n- Reduce exposure to water through the use of barriers\n- Educate older children on the hazards of water, water rescue and CPR\n- Improve swimming survival skills so that children can remain afloat should they enter the water\n- Remove potential hazards such as nets and lines near the water’s edge\n- There are a number of approaches for preventing drowning developed for the general population which could be effectively implemented in fishing communities.\n- Many are cost-effective and simple.\n- Many can to be implemented within communities without external resources or support.\n- Some interventions are costly and these costs may be borne by individuals, such as purchasing lifejackets or refurbishing fishing vessels.\n- Some interventions are complex and require significant infrastructure to run, such as enforcing commercial boating regulations.\n- Fishers may be resistant due to associated time requirements and changes to the way they work.\n- May impact on how effectively fishers are able to generate income and support their families.\nDue to their heightened water exposure, it may be appropriate to first identify and target fishing communities when implementing drowning reduction strategies in an area. Be prepared to think and work towards creative solutions as the context of fishing communities is different to that of the general population. To enhance the likelihood of the adoption of potential drowning prevention strategies, it is critical to involve the fishing community from the earliest stages of project development.\nHigh risk practices among fisherman (Greece): Frantzeskou, Elpida, et al. \"Risk factors for fishermen’s health and safety in Greece.\" International maritime health 63.3 (2012): 155-161.\nFishermen’s perceptions of risk (PDF 351KB)\nMeasuring and improving safety for recreational boating: Amanpreet Virk and Terri Pikora, Developing a tool to measure safe recreational boating practice. Accident Analysis and Prevention 43(1):447-500 2001\nSet objectives and interventions"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:45d47dc6-9c5a-4430-8d2f-6620868d9be9>","<urn:uuid:5290588e-d569-47ac-b566-b5e1cb615d22>"],"error":null}
{"question":"How does mobile scanning technology enable real-time project monitoring in construction sites, and what safety considerations are involved when using similar mapping techniques in complex environments?","answer":"Mobile scanning technology enables real-time project monitoring by creating dynamic digital twins of buildings throughout their lifecycle, allowing stakeholders to track progress, spot problems early, and make quick decisions about alterations. The non-invasive nature of mobile scanning allows surveying of occupied premises and live construction sites. In terms of safety considerations, especially in complex environments, proper protective gear is essential - including helmets and harnesses. Additionally, mapping processes must account for potential hazards, establish clear navigation routes, and ensure emergency preparedness. The collected data can be used to assess risks, identify unstable areas, and determine which locations require specialized equipment or training to access safely.","context":["Scanning hard-to-reach, overhead or “limited access” spaces has historically posed many challenges for those working in the construction sector. Stuart Cadge, from leading indoor mobile mapping specialist, GeoSLAM, explains how innovations in mobile mapping technology are paving the way for a new dawn in surveying.\nArchitects, project managers and surveyors are constantly under pressure to finish projects on time and within budget. Not surprising, considering that most contractors anticipate that up to 30% of their projects will be subject to costly delays. This issue is not limited to large-scale construction schemes, as similar constraints affect smaller building renovation projects too.\nBut creating a dynamic “digital twin” of a building’s features throughout a project’s lifecycle can help stakeholders remain up to date with a scheme’s progress, enable problems to be spotted early on, and speed up the decision-making process should alterations be required.\nOnce a 3D scan of an asset – whether complete or part-finished – has been conducted with a handheld, lightweight mobile mapping tool, project teams can generate highly detailed 3D models and 2D plans. These digital representations of a project can then be updated, re-scanned and interpreted at any stage in an asset’s lifecycle.\nNow, 3D mobile mapping technology has gone one step further. New mobile mapping tools use Simultaneous Localisation and Mapping (SLAM) technology, providing the ability to rapidly scan even difficult-to-reach places such as multi-level spaces, large multi-room hotels or enclosed basements.\nThe speed and non-evasive nature of mobile scanning also allows for the surveying of occupied premises, such as live construction sites, or in-use buildings surveyed for renovation or redevelopment.\nThe high ceilings in Turner Construction’s offices were problematic for traditional scanners\nThe model of the suspended ceiling voids\nConstruction projects routinely require a series of surveys and the subsequent creation of a model. One such recent example involves Turner Construction, the US-based global multinational construction services company which employs more than 5,200 people and completes 1,500 projects every year worth in the region of $10 bn.\nThe firm embarked on an extension project of its Atlanta, Georgia, office, and the latest mobile mapping tools offered a welcome alternative to traditional yet more cumbersome survey methods.\nBefore works were able to begin on site, the Turner Construction team needed to conduct a survey of the suspended ceiling voids. However, no previous 3D model of the space existed, and as a result, Turner was tasked with surveying the notoriously difficult space from scratch.\nDue to the building’s high ceilings and the limited space available in the void to manoeuvre equipment, traditional scanners would have struggled. However, thanks to the incorporation of SLAM technology, the Turner Construction team were able to put a GeoSLAM ZEB-REVO to use and complete a scan in just 10 minutes. Weighing just 1kg, the ZEB-REVO was deployed on an extendable pole into the ceiling void to capture scan data easily while overcoming the location’s relative inaccessibility.\nThe ZEB-REVO scanner completed the scan in a fraction of the time\nUnlike conventional methods of surveying, which can often take a great deal of time, the ZEB-REVO can be quickly and effortlessly moved without the need for time-consuming set-ups. It is also able to mitigate occlusions (object shadows), saving time on the overall modelling as the team already had a complete picture to work from – rather than having to interpolate between shadows that are usually seen in terrestrial scanning.\nIf traditional techniques had been used, it would have taken more than eight hours to complete the scan – 48 times longer than by using a ZEB-REVO. Added to that, surfaces had an average measurement accuracy to within two centimetres – more than sufficient for modelling the data in a BIM model.\nThe accuracy of the mobile data collected allowed for a full MEP layout to be built in just one working day, showing features all the way down to under four centimetres.\nTime and budget constraints will always pose challenges for those working on construction projects, regardless of their role or level of seniority. But, if the past few years have proven anything, it is those who choose to harness the latest digital technologies who will be rewarded with significant cost and time savings across the board.","Explore the intricate world of cave mapping, from advanced technologies to safety considerations. Learn how cave maps contribute to scientific research, navigation, and conservation efforts while overcoming challenges like limited visibility and complex environments.\nCreating cave maps and plans involves a combination of technologies and tools that help capture accurate data about the cave’s features and layout. The process can include both traditional methods and modern technological advancements. Here are some technologies and tools commonly used in creating cave maps and plans:\n- Surveying Equipment: Traditional surveying equipment such as compasses, clinometers, and measuring tapes are often used to gather data about cave passages, dimensions, and angles. These tools are essential for collecting basic measurements on-site.\n- Digital Surveying Instruments: Modern digital surveying instruments like laser rangefinders, total stations, and theodolites can provide more accurate and precise measurements. These devices can quickly capture distances, angles, and elevations, enabling the creation of detailed cave maps.\n- 3D Laser Scanners: 3D laser scanners are used to capture detailed point cloud data of cave interiors. They emit laser beams to measure the distance between the scanner and cave surfaces, creating highly accurate 3D representations. This data can be used to create detailed 3D models and maps.\n- Photogrammetry: Photogrammetry involves capturing a series of overlapping photographs from different angles and processing them to create 3D models and maps. This technique is especially useful for capturing complex cave formations and features.\n- Global Navigation Satellite Systems (GNSS): GNSS technology, including GPS, can help geolocate cave entrances and specific points within cave systems. This information is important for accurately positioning cave maps within the broader geographical context.\n- Mapping Software: Specialized cave mapping software is used to process the collected data and create accurate maps and plans. Software like Therion, Compass, Walls, and CaveMap can help compile survey data, generate maps, and manage cave exploration information.\n- Data Processing and Visualization Tools: Software tools like AutoCAD, Blender, or GIS (Geographic Information Systems) software can be used to process, manipulate, and visualize the collected data. These tools can help in creating detailed maps with annotations, labels, and various layers.\n- Drones: Drones equipped with cameras can provide aerial views of cave entrances and surrounding terrain. This can aid in creating maps that show the cave’s relationship to its environment.\n- Underground GPS and Navigation: Some cave exploration teams use specialized GPS devices designed for underground use. These devices work by sending signals through the cave passages to help explorers navigate and gather accurate location data.\n- Lighting and Photography Equipment: Good lighting is essential for capturing clear photographs and surveying cave interiors. High-quality cameras with low-light capabilities are used to document cave formations and passages.\n- Protective Gear and Safety Equipment: While not technology per se, safety equipment such as helmets, harnesses, and proper clothing are critical for cave exploration, as they ensure the safety of the surveyors.\nThe choice of technologies and tools depends on the complexity of the cave system, the level of detail required in the mapping process, and the available resources. Often, a combination of traditional and modern methods is used to produce comprehensive and accurate cave maps and plans.\nWhat methods are preferred for data collection during cave explorations?\nCave explorations require careful data collection to accurately map and understand the cave systems. The preferred methods for data collection can vary based on the specific goals of the exploration, the complexity of the cave, available technology, and safety considerations. Here are some commonly preferred methods for data collection during cave explorations:\n- Survey Stations and Tape Measurement: This involves setting up survey stations at key points in the cave and using tape measurements to determine distances, angles, and elevations between stations. Traditional compasses and clinometers are often used to measure angles and inclinations.\n- Total Stations and Theodolites: These instruments are used to measure angles and distances more accurately than manual methods. They provide precise measurements for creating detailed cave maps.\n- 3D Laser Scanning: 3D laser scanners capture millions of data points to create a detailed 3D representation of the cave’s interior. This method is especially useful for complex cave systems and intricate formations.\n- Photogrammetry: Capturing photographs from various angles and processing them using photogrammetry software can create 3D models and maps. This method is suitable for documenting cave passages and formations.\n- Digital Cave Mapping Software: Specialized software like Therion, Compass, and Walls allow cave explorers to input survey data and generate accurate cave maps. These programs also help manage survey data and maintain consistency in mapping conventions.\n- GPS and GNSS Receivers: Global Navigation Satellite Systems (GNSS) can be used to mark cave entrances and significant points. Underground GPS devices that communicate through the cave system’s rock can help with navigation and geolocation.\n- Drones: Aerial drones equipped with cameras can provide a bird’s-eye view of cave entrances and terrain, aiding in mapping and understanding the cave’s geographical context.\n- Notebooks and Sketching: Traditional field notebooks and sketching are still valuable methods for recording observations, sketches, and notes about cave formations, passages, and features.\n- Underground Instruments: Instruments specifically designed for underground use, such as clinometers with built-in compasses, can help gather accurate measurements while navigating through tight passages.\n- Data Loggers and Sensors: Data loggers and sensors can be used to monitor environmental parameters such as temperature, humidity, and airflow within the cave, contributing to a comprehensive understanding of the cave ecosystem.\n- Safety and Exploration Gear: Exploration teams must be equipped with proper safety gear, including helmets, harnesses, and adequate lighting to facilitate data collection in challenging cave environments.\nThe choice of methods depends on the specific needs of the exploration and the available resources. Often, a combination of methods is used to ensure accurate and comprehensive data collection, leading to more precise cave maps and a better understanding of the cave system’s characteristics. Safety is always a paramount consideration during cave explorations, so methods that minimize risks to explorers are typically favored.\nWhich specialized techniques are employed to map the intricate structure of cave systems?\nMapping the intricate structure of cave systems requires specialized techniques that can capture the complex geometry, features, and formations found within caves. Here are some specialized techniques employed for mapping intricate cave systems:\n- 3D Laser Scanning: 3D laser scanners emit laser beams that bounce off cave surfaces and return to the scanner, creating a highly detailed point cloud of the cave’s interior. This method captures the intricate shapes of cave passages, formations, and features with high accuracy. The point cloud data can be processed to generate 3D models and maps.\n- Photogrammetry: Using overlapping photographs taken from different angles, photogrammetry software can reconstruct 3D models of cave interiors. This technique is especially effective for capturing the fine details of cave formations and irregular surfaces.\n- Reflective Targets: Placing reflective targets in strategic locations within the cave allows laser rangefinders or total stations to measure distances more accurately. These targets bounce the measurement signal back to the instrument, enhancing precision in data collection.\n- Structure from Motion (SfM): Similar to photogrammetry, SfM involves capturing a series of images from various angles and using software to create 3D models. This technique is particularly useful for mapping cave passages and formations that may not be easily accessible.\n- Multi-Station Traverse Surveys: In complex cave systems, multi-station traverse surveys involve setting up multiple survey stations and measuring angles and distances from each station to others. This method is used to capture intricate networks of passages and connections.\n- Loop Closure Surveys: Loop closure surveys involve returning to previously surveyed points and ensuring that the measurements form a closed loop. This technique helps identify errors in the survey data and ensures accuracy in the mapping process.\n- Cave Diving Mapping: In underwater cave systems, cave divers use specialized equipment to map passages, formations, and features. Techniques like line laying and reel-based measurements help create accurate underwater cave maps.\n- Underground GPS and Wireless Communication: Underground GPS technology and wireless communication systems can help locate survey stations accurately, even in challenging cave environments. This aids in maintaining consistent reference points for mapping.\n- Integration of Sensor Data: Integrating data from various sensors, such as environmental sensors, water flow sensors, and magnetometers, can provide a more comprehensive understanding of cave systems, their hydrology, and potential connections.\n- Data Fusion and Visualization: Combining data from different sources, such as laser scans, photographs, and traditional survey measurements, can lead to more detailed and accurate maps. Advanced visualization tools can help researchers and explorers understand the complex structure more effectively.\n- Modeling of Complex Formations: Specialized software can be used to model and map intricate formations like speleothems (cave formations like stalactites and stalagmites). This requires careful measurement and data processing to accurately represent their shapes.\nMapping intricate cave systems often involves a combination of these techniques to capture the diverse features and complexities present within the cave. The goal is to produce detailed, accurate, and informative maps that contribute to scientific understanding and safe exploration.\nHow are cave maps used not only for scientific research but also for cave safety?\nCave maps serve multiple crucial purposes, ranging from scientific research to cave safety and management. Here’s how cave maps are used in both aspects:\n- Geological and Hydrological Studies: Cave maps provide valuable insights into the geological and hydrological characteristics of cave systems. Scientists can study the relationships between cave passages, formations, and the flow of water, which contributes to a better understanding of the underground environment.\n- Biodiversity Studies: Cave ecosystems are unique and often support specialized flora and fauna. Cave maps aid researchers in identifying potential habitats, niches, and connections that support cave-dwelling organisms. This information is vital for conservation efforts.\n- Climate and Paleoclimate Research: Studying the mineral deposits, sediment layers, and formations in caves can reveal historical climate data. Cave maps help scientists reconstruct past climate conditions and understand climate variability.\n- Speleogenesis Studies: Speleogenesis refers to the formation and development of caves. Detailed cave maps enable researchers to analyze how different processes, such as erosion, dissolution, and sedimentation, contribute to the cave’s formation.\n- Karst Landscape Studies: Cave maps are integral to studying karst landscapes, which are characterized by sinkholes, underground drainage systems, and cave networks. Understanding these landscapes helps geologists, hydrologists, and ecologists manage resources and mitigate hazards.\n- Navigation and Exploration: Cave maps are essential for safely navigating complex cave systems. Explorers and cavers use maps to plan routes, avoid getting lost, and ensure they can find their way back to the entrance. This is especially crucial in large, intricate caves.\n- Emergency Preparedness: In case of accidents, cave maps aid rescue teams in locating and accessing cavers quickly and efficiently. Detailed maps can include information about potential hazards, escape routes, and access points.\n- Risk Assessment: Cave maps help assess potential risks associated with specific cave passages, such as unstable formations, tight squeezes, or flooded areas. This information is important for determining which areas are safe to explore and which require specialized equipment or training.\n- Conservation and Protection: Cave maps aid in identifying areas of ecological sensitivity. By knowing where fragile formations or sensitive habitats exist, cave managers and explorers can take measures to minimize their impact and protect the cave’s unique features.\n- Resource Management: For caves with commercial or recreational use, maps are essential for managing visitor traffic, preventing overcrowding, and maintaining a sustainable balance between exploration and conservation.\n- Access Control: Cave maps can be used to manage access to sensitive or fragile areas within caves. By restricting access to certain passages, cave managers can prevent accidental damage and preserve the cave’s natural state.\nIn essence, cave maps are indispensable tools that serve not only as scientific records but also as critical resources for safe exploration, conservation, and management of cave systems. They help strike a balance between the need for scientific understanding and the imperative to protect these fragile and unique underground environments.\nWhat are the challenges and limitations encountered in the process of cave mapping?\nThe process of cave mapping is complex and often fraught with challenges and limitations due to the unique nature of cave environments and the technical difficulties involved. Some of the key challenges and limitations encountered in the process of cave mapping include:\n- Inaccessible Areas: Many cave systems contain passages that are too narrow, too flooded, or otherwise inaccessible to human explorers. Mapping such areas requires specialized equipment and techniques, such as remote-operated vehicles (ROVs) or cave diving, which come with their own set of challenges.\n- Navigation Difficulties: Navigating through the labyrinthine passages of a cave can be extremely challenging, leading to confusion and the potential for getting lost. This challenge is compounded in large, complex cave systems.\n- Limited Visibility: Many caves are completely dark or have limited natural light, making it difficult to accurately measure distances, angles, and features. Explorers rely on artificial lighting, which may not provide consistent or adequate illumination for precise mapping.\n- Technical Equipment Limitations: The use of technical equipment like laser scanners, total stations, and cameras can be hindered by factors such as battery life, signal interference, and the need for specialized training to operate these tools effectively.\n- Data Integration: Combining data from different sources, such as laser scans, photographs, and traditional survey measurements, can be challenging. Ensuring data accuracy and alignment during integration is critical for creating coherent and accurate cave maps.\n- Time-Consuming Process: Mapping intricate cave systems is time-consuming and requires meticulous attention to detail. This can lead to extended fieldwork periods, especially when mapping large or complex caves.\n- Survey Errors: Even with advanced equipment, errors can occur during the survey process. Small inaccuracies in measurements, misalignment of instruments, or surveying mistakes can lead to distorted maps and inaccurate representations.\n- Environmental Considerations: Caves often harbor delicate formations that can be damaged by human presence. Surveyors need to take great care not to disrupt these formations while collecting data, which can slow down the mapping process.\n- Scale and Perspective: Translating the three-dimensional reality of caves onto two-dimensional maps can distort scale and perspective. This can make it challenging to accurately represent the true dimensions and relationships within the cave.\n- Lack of Reference Points: In the absence of clear reference points like geographic landmarks, mapping cave systems can be more challenging. Establishing reliable reference points for accurate positioning can be difficult, especially in remote areas.\n- Communication Challenges: In caves with limited or no wireless communication, transmitting data in real-time can be problematic. This can hinder the ability to receive guidance or assistance from experts outside the cave.\n- Safety Concerns: The safety of cave explorers is paramount. Technical challenges and the potential for unexpected hazards, such as cave-ins or flooding, can pose risks to surveyors and limit their ability to thoroughly explore and map certain areas.\nDespite these challenges, advancements in technology and surveying techniques have significantly improved the accuracy and comprehensiveness of cave mapping. Researchers and explorers continue to develop innovative solutions to address these limitations and expand our knowledge of the intricate world beneath the surface."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:eb50ae4b-1494-4ac3-b8d5-94b1f1074356>","<urn:uuid:10dc5356-b30d-47ad-a829-71483faabba4>"],"error":null}
{"question":"What are the differences between second-degree and third-degree burns in terms of symptoms and required medical care?","answer":"Second-degree burns extend into the dermis (second layer of skin) and show symptoms like reddening of injured skin and blistering. They may heal within 2-3 weeks with proper care. Third-degree burns are more severe, reaching the fat layer under the skin and showing symptoms like stiff/waxy skin, leathery appearance, dark brown color, and undeveloped blisters. While second-degree burns can sometimes be treated at home if small, third-degree burns always require immediate medical attention. Third-degree burns may not even cause pain if nerve endings are damaged, have no set timeline for healing, and often require surgery to prevent scarring.","context":["First Aid - Burns\nCommon causes of burns include exposure to fire, hot metals,\nchemicals, electricity, and radiation. The first-aid treatment of\nburns depends on the severity of the injury. Burns are classified,\nin order of increasing severity as:\n- First Degree, which involves only the\nsurface of the skin, is characterized by reddening.\n- Second Degree, which involves reddening of\nthe injured skin and blistering.\n- Third-degree: The injury has a white or\nThe danger from burns depends more on the extent of the burns\nthan on the degree. Superficial burns over a large area are more\ndangerous than complete charring of a part of a limb. On any one\nperson, different parts of the body may show varying degree of\nTo calculate the extent of burns the \"Rule of Nines\" is used. The\nfigure below explains the \"Rule of Nines\".\nThe object of first aid in burns is to prevent shock,\ncontamination of the burned tissue, and pain.\nManagement of Extensive Burns\nKeep the patient quiet and reassure him.\nWrap him up in a clean cloth.\nDo not remove adhering particles of charred clothing.\nCover the burnt area with a sterile or clean dressing and bandage. In the case of burns that cover a large part of the body it is sufficient to cover the area with a clean sheet or towel.\nKeep the patient warm but do not over heat.\nIf the hands are involved, keep them above the level of the victim's heart.\nKeep burnt feet or legs elevated.\nIf the victim's face is burnt, sit or prop him up and keep him under continuous observation for breathing difficulty. If respiratory problems develop, an open airway should be\nmaintained (See Artificial Respiration).\nDo not immerse the extensively burnt area or apply ice water over it because cold may intensify the shock reaction. However a cold pack may be applied to the face or hands or feet.\nDo not open the blisters on the victim's skin.\nTreat for Shock.\nSeek medical assistance, especially if:\nBurns cover move than one body part\nBurns are on the hands, feet, or genitals\nRemove quickly from the body anything of constricting nature like rings, bangles, belt and boots. If this is not done early, it may be difficult later on as the limbs begin to swell.\nIf medical help or trained personnel cannot reach the scene for an hour or more and the victim is conscious and not vomiting, give him a weak solution of salt and soda (one level teaspoonful of salt and half a level teaspoonful of baking soda to each quart of water, neither hot nor cold) at home and\nen-route to the hospital. Allow him to sip slowly.\nGive about four to five ounces to an adult over a period of 15 minutes, two ounces to a child between one and twelve years of age and one ounce to an infant below one year. Discontinue the fluid if vomiting occurs. Do not apply ointments, grease or any other material over the wound.\nManagement of Minor Burns and Scalds\nClean the area gently with clean water.\nSubmerge the burnt area in cold water.\nDo not apply cotton wool directly over the burnt area.\nDo not apply any greasy substance.\nGive the patient warm drinks.\nHomoeopathic Remedies for First and Second Degree Burns\nApply Cantharis Q or Urtica\nUren Q (mixed with water 1: 4 parts of water) as lotion and\nkept it wet without being removed. Internally Cantharis\n30 along with Mixture of Kali Mur 3x or\n6x & Nat. Mur 3x or 6x at frequent intervals. Biochemic\nNat Phos 3x or 6x mixed in water can be applied locally to\nprevent blisters with great success.\nLater on if there are occurrences of secondary\ninfection in wounds apply Calendula Q\nmixed with Water or cream.\nFor post burn CICATRICES: Causticum 30C, 200C, 1M\nManagement of Chemical Burns\nWash off the chemical with a large quantity of water by using a shower or hose if available as quickly as possible. This flooding with water will wash away much of the irritants. Wash the injury for at least 10 minutes.\nCut out contaminated clothing.\nDo not touch the burnt area.\nTreat as for Burns.\nTake the victim to a physician immediately.\nQ for local application(1:4 water ratio). Carbolic\nAcid 30C, Picric Acid 30C, and Causticum 30C internally. From X-Ray & Radium:\nBro 30C, Sol 30C.\nManagement of Electric Burns\nBurns that result from exposure to electricity should be treated\nin the same manner as burns from exposure to fire.\nSame as for First & Second Degree Burns.\nManagement of Sunburns\nSunburn, in most cases, is a first-degree burn. Extremely deep\nsunburn may cause second-degree burns, with blistering. Do not open\nany blisters. Apply cool compresses to relieve pain. Consult a\nphysician in cases of severe sunburn.\nBelladonna 30C, Pulsatilla 30C, Urtica Uren Q, 6C, 30C; Calendula\n30C, Nat. Carb 30C, Ant Crud. 30C,1M, & Sol 30C.\nUpdated on: 01 Feb 2010","Burn injury: When to seek emergency medical care\nWhat are burns?\nSevere skin damage that causes the cells to die is called a burn. It can range from minor to major injuries. Depending on the severity of the burn, the course of treatment changes.\nSome tips when dealing with burn injuries are:\n- Small scalds with some redness can be treated at home, while burns with blisters, deeper depth, larger surface area, or affecting major joints like spine or ankle need medical attention.\n- Never apply ice to a burn. It can damage the affected area even more and slow down the healing process.\nWhat are the symptoms of a burn?\nThe severity of a burn depends on the extent of the damage i.e. the depth of the skin it affects. A minor burn can be distinguished from a more serious one that requires medical attention through the classification of burns. The following are the types, ranging from minor to severe:\nIt causes minimal skin damage since only the outer layer (epidermis) is damaged. First-degree burns heal within 7-10 days without leaving a scar. It is accompanied by:\n- Minor swelling\nSecond-degree burn (Partial thickness):\nThe damage extends beyond the epidermis into the second layer of skin (dermis), and the burn is more serious. Depending on its extent, it may heal within 2-3 weeks. There may be pigment changes in the skin. It is accompanied by:\nThird-degree burn (Full-thickness):\nThe damage reaches the fat layer under the skin, making it an extremely severe burn injury. They require immediate medical attention, and there is no set timeline for their healing. The pain may not be felt if the nerve endings are damaged. Surgery may also be required to prevent scarring. The symptoms may be:\n- Stiff, waxy skin\n- Leathery skin\n- Dark brown color\n- Undeveloped blisters\nThis is the most severe burn category. The damage extends well beyond the skin and may even affect muscles and bones. Similar to third-degree burns, there may be no pain felt if the nerve endings are damaged. Symptoms are:\n- Blackened skin\n- Charred skin\n- Absence of pain\nWhile a first-degree or second-degree burn may be treated at home, third-degree and fourth-degree burns require medical attention. Even in the case of the former two, if the affected area is large or the burn is on a major joint like the spine, ankle, elbow, etc, it is advisable to seek medical help.\nWhat are the causes of burns?\nBurns can be caused by several substances. Some of them based on the category of burns are:\n- First-degree burn:\n- Scalds from hot liquid/surface\n- Minor electrical burns\n- Second-degree burn:\n- Severe sunburns\n- Accidents with hot boiling water\n- Accidents with flame\n- Third-degree burn:\n- Exposure to fire\n- Burns from electricity or lightning\n- Prolonged exposure to hot liquids/objects\n- Chemical burns\nFourth-degree burns are caused due to similar circumstances as third-degree burns. The extent of the damage increases though, and so does the long-term outlook for recovery.\nHow to manage burns?\nFirst aid for minor burns\nMinor burns that cause pain, blisters, superficial redness or are smaller than 3 inches in diameter do not require emergency care. With proper care at home, they resolve within a few weeks.\n- Cooldown the burn under cool, running water for 20 minutes total duration. Avoid the use of cold water or ice (ice slush) as they restrict blood circulation and increase the depth of the burn.\n- Do not break the blisters. If the blister breaks, clean with clean water and mild soap (optional).\n- Use lotion or moisturizer only once the burn is cooled to prevent drying and pain relief.\n- Apply plastic (cling) wrap to burn wound to prevent heat loss.\n- For chemical burns, clean with copious amounts of water to dilute chemical exposure.\n- Use sterilized gauze bandage to loosely wrap the burn to keep the air off and protect blistered skin.\n- If needed, over-the-counter medicines may be used for pain relief.\nWhen to see a doctor\nSeek immediate care for major burns that are deep or larger than 3 inches in diameter, covering the face, hands, feet, groin, or major joint. Also, burns that appear charred or patchy or that leave the skin dry and leathery need immediate attention.\nThe doctor may prescribe the following depending on the severity of the burn:\n- IV fluids to prevent dehydration and organ damage.\n- Burn cream to maintain moisture lock, prevent infection and facilitate healing.\n- Tetanus shot and antibiotics to prevent infection.\n- Pain medicines.\nWhat is emergency care for serious burns?\nThe treatments rendered in the first 4 hours of the incident can make a lot of difference in saving the life of the patient. Initial assessment, management of burn, evaluation of burn size, and fluid replacement plays a major role in the first 24 hours after burn injury. The ABCDE approach mentioned below is a priority response to address the complications of burns quickly and efficiently. The emergency care for serious burns is required to:\n- To stop the burn\n- For essential ABCDE monitoring, the following is required:\n- Airway maintenance\n- Breathing and ventilation\n- Circulation and cardiac status\n- Disability, neurological deficit, and gross deformity\n- Examine associated injuries and maintain warm Environment\n- To determine the extent of the burn, use the Rule of 9’s to assess the body surface area that has gotten burned. This helps to guide treatment decisions.\nIn some cases, surgical procedures may be necessary:\n- Decompression to ease breathing.\n- Reconstruction and skin grafting to assist healing and enhance cosmetic appeal.\n- Nasogastric tubing for feeding.\nWhat are the complications of burns?\nComplications generally arise with third-degree or fourth-degree burns, wherein the body is exposed to outside infections through broken skin, risks blood loss, etc. Some of them are:\n- Risk of infections: Severe burns make the body vulnerable to bacterial infections like tetanus and can even cause sepsis. Both of them are life-threatening conditions.\n- Hypovolemia (low blood volume): Blood vessel damage can lead to loss of fluids in the body. Due to the loss of blood and fluids, the heart may not be able to pump enough blood to all the body parts.\n- Hypothermia (low body temperature): While this seems uncharacteristic for a burn, the increased loss of blood can cause the body temperature to drop to dangerous levels.\n- Bone and joint problems: Deep burns can affect the movement of certain joints. When scar tissue forms over the burns on a joint, it may cause the skin, muscles, or tendons to tighten or shorten, which displaces them.\n- Scarring: Third-degree and fourth-degree burns may require skin grafting and surgeries.\nHow to prevent burns?\nIt is essential to follow prevention routines at home to avoid burn injuries. Children, especially, are vulnerable to burns. Proper precautionary measures can help to prevent burn injuries for everyone at home.\n- Never leave items on the stove unattended.\n- Keep children out of the kitchen.\n- Do not wear synthetic or loose-fitting clothes in the kitchen.\n- Discard electronics with damaged or exposed wires.\n- Keep chemicals, matches, lighters, etc. out of the reach of pets and children.\n- Wear gloves and other protective gear while using chemicals.\n- Keep the temperature of the geyser between 49°C – 54°C.\n- Wear sunscreen and avoid peak sunlight.\n- Smoke away from the bed and curtains.\nThe severity of burns depends on their extent i.e. the area of damaged skin and the depth. As a rule of thumb, if the burn is deep or larger than 3 inches in diameter, covering the face, hands, feet, groin, or major joint, it is essential to seek medical attention. This generally occurs in the case of third-degree or fourth-degree burns. Always take the necessary precautions at home to prevent the possibility of any minor or life-threatening burn injuries.\nRead more about Burns symptoms, causes and treatment\nIf you find any of the above mentioned of Burns then\nBook an Appointment with the best dermatologist in hyderabad\n- “Burns: Types, treatments, and more”. Healthline. Reviewed by Modern Weng. Accessed on 30 August 2019. https://www.healthline.com/health/burns\n- “What are the types and degrees of burns?”. Web MD. Reviewed by Carol DerSarkissian. Accessed on 30 August 2019. https://www.webmd.com/first-aid/types-degrees-burns#1\n- “Management of burns”. World Health Organization. Accessed on 30 August 2019. https://www.who.int/surgery/publications/Burns_management.pdf\n- “Burns/ management of burn wounds”. The Royal Children’s Hospital, Melbourne. Accessed on 30 August 2019. https://www.rch.org.au/clinicalguide/guideline_index/Burns/\n- “Burns: first aid”. Mayo Clinic. Accessed on 30 August 2019. https://www.mayoclinic.org/first-aid/first-aid-burns/basics/art-20056649"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:6c1b8c4d-76c5-4b80-beab-a726cef01a5d>","<urn:uuid:105f8551-791c-4148-8446-281a3c8144b9>"],"error":null}
{"question":"What were the economic impacts of COVID-19 on Cambodian migrant workers' remittances in 2020, and how has ASEAN subsequently addressed social protection for migrant workers?","answer":"In 2020, remittances from Cambodian migrant workers declined significantly by 16.6% to $1,272 million, contrasting with the 6.7% annual growth seen during 2014-2019. Around 260,000 Cambodian migrant workers lost their jobs and returned home due to the pandemic. In response to these challenges, ASEAN has taken steps to strengthen social protection for migrant workers. In August 2022, under Cambodia's leadership, ASEAN included social protection in its Joint Communiqué of the 55th ASEAN Foreign Ministers' Meeting, with Cambodia leading the development of ASEAN Regional Guidance on social protection. This cooperation aims to benefit approximately 6.9 million migrant workers in the ASEAN bloc by providing better access to social protection benefits.","context":["Remittances from Cambodian migrant workers showed a whopping decline of 16.6 percent to $1,272 million in 2020 following the outbreak of Covid-19, a stark contrast to the 6.7 percent annual growth during 2014-2019, revealed the first ‘Asean Migration Outlook’ report.\nAccording to the report, released recently by the Asean secretariat, an estimated 260,000 Cambodian migrant workers lost jobs in the wake of the pandemic and returned to the country from various parts of the world, mostly from Thailand, as of December 2021. The return migration to Cambodia was the second highest in the region after the Philippines.\nThe report said the return of the migrants led to a rise in poverty in the Asean region and it coincided with a fall of 3.6 percent in remittances. More than 2.4 million people returned to six Asean countries of migrant origins – Cambodia, Laos, the Philippines, Myanmar, Indonesia and Vietnam – in the months following the first outbreaks.\nThe Philippines reported that 1.169 million migrant workers have been repatriated from all over the world since the pandemic began until September 2021. Although some of these migrant workers may have returned after completing their contracts, it is likely that the majority returned prematurely due to Covid-19.\nA survey of returned Philippine migrants found that 67 percent returned due to the Covid-19 crisis, 23 percent said they were planning to return to the Philippines regardless of the pandemic, while10 percent did not want to answer.\nIn 2019, over one million Cambodians were outside the country; among them, approximately 719,000 Cambodians worked in Thailand. About 40 percent of them were employed in construction, 17 percent in manufacturing, and 16 percent on farms.\nGlobal migrant remittance inflows too declined by 2.4 percent in 2020 due to the economic crisis induced by the Covid-19 pandemic, after growing an average of 3.4 percent the previous five years. The fall in remittances is largely because of job losses and a decrease in wages.\nIn Asean, migrant remittance inflows fell an even sharper 3.6 percent, after growing an average of 5.2 percent the previous five years. Migrant remittance inflows fell in 2020 for seven of the eight Asean countries with available data (there was no data for Brunei Darussalam and Singapore), with Vietnam being the only country that managed positive growth, although much lower than usual.\nAccording to analysts, underdeveloped digital banking, travel bans, and insufficient alternatives for the underbanked contributed to the falls in remittances in Cambodia, Indonesia, and Myanmar. The Philippines and Thailand benefitted from digital solutions and a more favourable policy environment, so remittance inflows declined less in these countries.\nThe substantial fall in remittances is especially concerning in Cambodia, Lao PDR, and Myanmar, where remittances play a bigger role in lower-income households, and where the loss of migrant worker jobs abroad can lead to poverty back home.\nA telephone survey of 1,054 migrant returnee households in Cambodia revealed that two-thirds of returning migrant worker households suffered a severe drop in income. Their average income was only $150 a month, and more than half were in debt. As much as one-third of these returnees reported no income at all; although over 65 percent received some kind of support: 20 percent received cash support, nine percent received food assistance, and 10 percent received healthcare services.\nAlthough the past two years have witnessed large job losses, massive migrant worker returns, and a sharp drop in deployment, labour migration in the region is expected to recover and possibly surpass pre-pandemic levels, said the report.\nThe reasons are manifold: the expected strength of economic recovery in the region; the continuing wide disparity in socio-economic wellbeing between origin and destination countries in the region; demographic pressures; and sectoral or role-based gaps in the labour markets.\nAfter the economic meltdown in 2020 and tepid growth in 2021, Asean, as a whole, and most individual countries are projected to return to or close to their pre-pandemic growth levels beginning in 2022 and achieve their pre-pandemic levels of output by 2022 or 2023.\nAsean is expected to grow a little under five percent in 2022 and just over five percent in 2023, based on the Asian Development Bank (ADB) forecasts in April 2022. The projected economic recovery is particularly noteworthy for Malaysia and Thailand, which attract the largest number of intra-Asean migrant workers.\nMalaysia’s economy is projected to grow by 5.7 to 5.8 percent in 2022 and by 4.5 to 5.7 percent in 2023, according to 2022 World Bank and IMF forecasts. Thailand is forecasted to grow by 3.9 to 4.1 percent in 2022 and by 4.3 to 4.7 percent in 2023.\nThe report showed that compared to some other Asean countries, Cambodian migrants, on return received free Covid-19 tests and access to quarantine facilities at health centres with free food.\nIn Cambodia, the Ministry of Labour and Vocational Training, through technical and vocational education and training (TVET) institutions, offered short-term and long-term technical and vocational training to returning migrant workers and provided information on domestic job opportunities through the National Employment Agency, Provincial Department of Labour and Vocational Training, and provincial job centres.\nAccording to the report, the opportunities for re-migration will, however, depend, firstly, on how quickly destination countries within and outside the region are able to recover and open their doors to foreign workers, and, secondly, on the revival of the recruitment industry, which suffered massively over the past two years. Fortunately, forecasts of early recovery have been optimistic.\nIn his foreword to the report, Dato Lim Jock Hoi, Secretary-General of Asean, said that the safe and orderly migration of workers within and beyond the region is key to realising the Asean Community that is politically cohesive, economically integrated, and socially responsible.\n“Although the Covid-19 pandemic resulted in job losses as well as the return of migrant workers to their home countries, Asean is once again witnessing their redeployment as our recovery efforts gain momentum,” he said.","ASEAN foreign ministers during the 55th ASEAN Foreign Ministers' Meeting on August 3. Photo: Hong Menea/Phnom Penh Post\nASEAN recognises Social Protection in its JOINT Communiqué\nSitting in a small restaurant in bustling Bangkok, being served by a 21-year-old Cambodian waiter triggered a lot of emotions for me. The waiter came from Banteay Meanchey, a province bordering Thailand. He has been working there alongside a few friends from the same province, unaware of the potential dangers and his vulnerability of being away from home if his job stopped tomorrow. This is not a unique story as Thailand is both a key destination for migrant workers from neighbouring countries, and a country of origin for migrant workers to other countries. There are migrant workers across ASEAN- from Cambodia to Thailand, from Thailand to Malaysia, and from Malaysia to Singapore. Whilst labour migration contributes to both the country of origin and country of destination, the lack of protection and rights for these migrant workers have been a major concern.\nEarlier this month it was good to see social protection gaining policy momentum in Southeast Asia with ASEAN members having the courage to challenge the conventional assertion that universal social protection systems are not affordable. In Phnom Penh on 5th August 2022, under Cambodia’s Chair, ASEAN included social protection in its Joint Communiqué of the 55th ASEAN Foreign Ministers’ Meeting. Now Cambodia is entrusted with the key role to lead the development of ASEAN Regional Guidance on the Role of Social Work and Service Workforce Strengthening in social protection. This illustrates Cambodia’s and ASEAN’s growing commitment to elevate social protection to new levels of multinational investment and cooperation. Potentially, it will benefit millions of people by addressing this previous under-investment and lack of coverage in the Southeast Asian bloc.\nThis milestone marks a significant upturn in interest and commitment to social protection. Amongst Southeast Asian member states, only Singapore, Brunei, Malaysia, and Thailand are considered to have strong social protection systems. As long ago as 9th October 2013 the ASEAN Declaration on Strengthening Social Protection was adopted with commitments to build interlinked and mutually reinforcing regional political, economic and cultural communities. The ASEAN Joint Communiqué in 2020 again referred to these commitments so it was disappointing that in the 2021 Joint Communique there was no mention of social protection despite the tremendous impact of COVID-19 on the livelihoods of millions of people within the region. This was a regrettable step backward in ASEAN’s joint effort.\nHowever, now in 2022 Oxfam hopes this cooperation among the ASEAN member states will benefit millions of migrant workers and their families. It means that 2.8 million registered migrant workers in Thailand (2019), 1.98 million migrant workers in Malaysia (2019), 1.4 million migrant workers in Singapore (2019), or 6.9 million migrant workers in ASEAN bloc, will have a greater chance of accessing social protection benefits. This workforce makes an important economic contribution to both sending and host countries. In Cambodia, migrant workers sent their families a total of US$3 billion in remittances in 2021 alone. In Thailand 2020, financial remittance was reported to be US$7.88 billion and the Philippines reports US$34.88 billion annually. At the same time, host countries benefit from billions of dollars in tax revenue and the increased labour force.\nThere will is a long journey ahead with difficult negotiations but with this cooperation, ASEAN member states can work towards better, more coordinated social protection policies and legislation that provides migrant workers and their families with access to social protection.\nThis cooperation will also make ASEAN better prepared for the increasing risk of climate change and global epidemic.\nA 2021 World Bank study found that COVID-19 has added 88 million to the estimated total of 150 million people globally now living in extreme poverty. This means that 150 million people are living on less than US$1.90 per day. Here in Cambodia we have been hit hard with a report of economic growth in 2020 contracting 3.1% and those living in poverty increasing to 17.8% in 2019-2020 (compared to 13.5% in 2014).\nThis economic challenge increases with climate change which is now ‘’on our doorstep’’. In a recent study, scientists estimate that up to 132 million people will be falling into extreme poverty in 2030 due to climate change. Cambodia is highly vulnerable to the risks and impacts of climate change- ranking 46th out of 163 countries.\nA stronger social protection system and multinational cooperation across ASEAN will help to prepare for the unprecedented climate change and pandemic impacts. In the worst-case scenario, farmers can access compensation for lost crops, youth and women can access unemployment benefits when they lose their jobs and senior citizens can access pensions and healthcare in the absence of available support from their families.\nThis cooperation will contribute to ASEAN being better prepared for the rapidly ageing population who are the most vulnerable and the least protected.\nThailand’s ageing population is expected to reach 22.8% in 2035, Singapore's over 65s will be 26.6% of the population in the same year. Vietnam estimates to have 20% of its population ageing by 2038 and here in Cambodia, we are not immune with the Kingdom’s population older than 65 years estimated to be 7.7% of the total population by 2035.\nOxfam and partners are committed to working with The Royal Government of Cambodia and countries in the ASEAN bloc to advance these commitments and make them a reality for the people of the region.\nLet us make ASEAN a better home, our home, a home for all."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:0ec98370-d40f-4e92-a96f-50847bc70d13>","<urn:uuid:744adc5c-1270-4013-90eb-efd5cc844d76>"],"error":null}
{"question":"How do water management strategies differ between sustainable design principles and Berkeley's municipal regulations?","answer":"Sustainable design principles emphasize onsite solutions like planning infiltration swales during trenching, storing roof runoff for grey water use, and implementing small onsite treatment plants for water recycling. Berkeley's municipal regulations are more specific and compliance-focused, requiring adherence to EBMUD Section 31 Water Efficiency Regulations, Bay-Friendly Basics Landscape Requirements for areas over 2,500 square feet, and mandatory sewer lateral replacements during remodeling or property sales.","context":["Sustainability is the process applied to our quest to sustain economic growth while maintaining our long-term environmental health. Sustainability means designing structures that take advantage of technological advancements to create eco-friendly products. Inert-gas-filled insulated windows, engineered-wood products made from scrap wood shavings, sawdust and assorted wood fibers, and thermal break window frames that keep the cold and hot air out are all examples of sustainable products. These products provide the owner and occupants with the following benefits:\n- Reduced maintenance and replacement costs over the life of the building\n- Energy conservation\n- Improved occupant health\n- Productive working environment\nSustainable products incorporated into the building should follow these selection guidelines:\n- Recycled content\n- Natural, plentiful, or renewable materials\n- Products manufactured by a resource-efficient process\n- Locally available products\n- Salvaged, refurbished, or remanufactured products\n- Reusable or recyclable products\n- Durable products\nUsing sustainable materials can also improve the indoor working environment and save money. Consider these advantages:\n- Materials that emit few or no carcinogens or irritants, as demonstrated by the manufacturer’s long-term testing results\n- Minimal chemical emissions from volatile organic compounds (VOC) that out-gas (continue to emit chemical vapors after installation)\n- Moisture-resistant materials that are not easily susceptible to mold growth\n- Materials that are easily maintained and require simple nontoxic cleaners\n- Equipment systems that promote healthy indoor air quality (IAQ) by identifying indoor air pollutants\n- Products and systems that help reduce water consumption\nThe sustainable approach to design would include requirements to do the following:\n- Simplify construction details.\n- Utilize repetitive details and components.\n- Standardize design components.\n- Incorporate accurate dimensions in the design, as some product and material sizes many have been reduced.\n- Simplify building systems so future expansion projects can take advantage of simplified designs or components.\n- Consider occupant safety and worker productivity gains in the new design.\n- Investigate more efficient and environmentally sensitive ways to bring underground utilities into the site with the least disruption to the existing terrain.\n- Consider other ways of disposing of site drainage onsite rather than offsite.\n- Adjust new site contours to provide for a balanced site where no offsite fill or off-site disposal of surplus soils is required.\n- Optimize dimensions to utilize a standard product size.\n- Minimize plumbing pipe and HVAC ductwork bends to reduce liquid and air friction.\n- Select fittings and fasteners that permit quick assembly.\n- Select sealants with the least environmental impact and longest life.\n- Investigate ways to accumulate salvaged and waste materials for recycling.\n- Consider donating surplus materials to a nonprofit organization such as Habitat for Humanity.\n- Deconstruct all existing structures with substantial recoverable materials and dispose of them to recyclers.\nWhen designing a new green structure, a number of goals must be set. The site must meet or exceed standards for sedimentation control and erosion:\n- Prevent the loss of soil during excavation and construction due to surface water drainage; keep dust down and cover large stored piles of earth to prevent wind erosion.\n- Prevent the silting up of existing storm drains in the immediate area by constructing erosion and silt fence enclosures around areas to be excavated.\n- Prevent the siltation of existing nearby streams or waterways by installing erosion and silt fencing around those streams adjacent to areas to be excavated.\n- Protect topsoil piles for reuse. (Topsoil piles are generated early in the construction process as soil is stripped during rough grading operations; respreading is one of the last operations, commencing as landscaping is put in place.)\nThe site utilities should reduce soil erosion during excavation of trenches and contain storm water runoff:\n- Plan infiltration swales and basins during trenching operations to contain surface water.\n- Retain or recharge existing water tables by minimizing site disturbances; leave as many trees as possible; use existing vegetation and retain natural contours.\n- Consider a design to store roof runoff when the building has been completed; it can be used as gray water or reclaimed wastewater.\n- Investigate a small onsite, state-of-the-art treatment plant to recycle reclaimed water.\nAn open-space and landscaping program can accommodate the following:\n- Protect trees during construction; they enhance property values and lower cooling loads.\n- Consider indigenous landscaping; it supports natural wildlife and plantings and lowers the level of irrigation as well as the need to fertilize and apply chemical treatment.\n- Minimize pesticide use by installing weed cloth; use mulches and planting species that create dense planting beds.\nSite -circulation and transportation programs should meet these objectives:\n- Encourage carpooling.\n- Provide areas for people to store bicycles during working hours.\n- Encourage the use of public transportation by instituting a program of incentives.","Green Building Requirements\nBuilding Sustainably Green buildings provide healthy, comfortable building interiors that maximize savings through the efficient use of energy and water and limit construction impacts on the natural environment. The City of Berkeley requires that new buildings, alterations, and additions meet the requirements of the California State Green Building Code (CAL Green). Documentation of compliance with CALGreen must be provided with plans submitted for building permits; see CALGreen New Residential Checklist and CALGreen Addition Alteration Residential Checklist. Green building requirements for projects requiring a Zoning Use Permit (UP) or Administrative Use Permit (AUP) are listed below, for more information see Green Building Requirements.\nIn addition, Berkeley has supplemental green building policies that ensure that we continue to divert waste from landfills, reduce energy and water usage in our buildings, and help our community meet our environmental and Climate Action Plan goals.\nGreen Design A green building takes a holistic approach to design, siting, construction, and operation to enhance the well being of its occupants and minimize the negative impacts on the community and natural environment.\nEnergy An energy-efficient building reduces greenhouse gas emissions, lowers utility bills, and improves comfort.\n- Energy Conservation Analysis: Required for large (10,000 sq.ft. or more) commercial projects and recommended for multifamily and mixed-use projects. A free analysis is available through PG&E's Savings By Design program. For multifamily projects, receive energy design assistance and cash incentives, see Heschong Mahone Group.\n- Energy Conservation Measures RECO/CECO: RECO/CECO requires existing buildings to make updates to save energy and water when properties are remodeled or sold. Residential projects must comply with RECO and commercial projects must comply with CECO.\nWater: Controlling stormwater runoff protects the San Francisco Bay and our local creeks and watersheds. Construction activities are the largest source of stormwater pollution in the Bay. Water conservation helps save water while saving money and energy.\n- Reduction of Stormwater Pollution: All construction projects must manage stormwater pollution. The Stormwater Requirements Overview summarizes the onsite stormwater treatment and required checklists for projects based on the quantity of impervious surface that they create or replace.\n- Protecting Health of Creeks: Requirements vary depending on project scope and distance from the creek. The City has developed a Creeks Map that depicts open and culverted creeks available at the Creeks Ordinance website.\n- Fixing Leaks in Sewer Laterals: Required for remodeling projects and when properties are sold, see Sewer lateral replacement.\n- East Bay Municipal Utility District (EBMUD) Section 31 Water Efficiency Regulations: All applicants for new and expanded service are required to comply, see EBMUD Water Efficiency Checklist.*\n- Bay Friendly Basics Landscape Requirements: Required for all new and renovated irrigated landscape over 2,500 square feet. The Bay-Friendly Basics represents the 9 required practices from the Bay-Friendly Landscape Scorecard, see Bay Friendly Checklist.*\n*California Water Efficient Landscape Ordinance (WELO) requirements are met through compliance with Bay Friendly and EBMUD Water regulations, no additional action is needed.\nWaste: Conservation and reuse of building materials and recycling construction and demolition debris saves valuable resources and landfill space.\nZoning submittal requirements, see Green Building Requirements\nSearchable database by address (Parcel Popper), see Building Permit History and Parcel Conditions\nSearchable database of City codes, see Municipal Code and Zoning Ordinance\nFrequently requested forms and documents, see Permit application forms, submittal guidelines & forms\nGuides on a range of topics to help you green your building project, see Green Building Permit Guides\nCity of Berkeley Office of Energy and Sustainable Development\nGreen Building in Alameda County\nBuild It Green\nU.S. Green Building Council (USGBC)\nEast Bay Municipal Utility District (EBMUD)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:87dc776d-1577-43c5-924a-15b33db12340>","<urn:uuid:4cfceb16-f1b3-42e8-acc4-0dd0b056f753>"],"error":null}
{"question":"How does intermittent fasting enhance fat burning compared to regular dieting? I'm familiar with IF but curious about the scientific mechanism behind it.","answer":"Intermittent fasting enhances fat burning through increased activity of specific genes. According to research from Yale/Copenhagen, fasting activates genes that encode for uncoupling proteins and enzymes that increase fat oxidation. These uncoupling proteins create 'holes' in the muscle cells' mitochondria, making them less energy-efficient. As a result, the mitochondria must burn more calories to produce the same amount of energy (ATP), leading to increased calorie utilization during the fasted state.","context":["What is Intermittent Fasting?\nIntermittent fasting is not a diet, it’s a pattern of eating. It’s a way of scheduling your meals so that you get the most out of them. It does not say anything about which foods you should eat, but rather when you should eat them.\nIt is simply the practice of going an extended period of time taking in zero calories—basically drinking only plain water and either black coffee or tea. Many variations of IF exist, but the most preferred method which is nothing but the Leangains Protocol—involves fasting for 16 hours(men) and 14 hours(women), then eating all of the food during an eight-hour window commonly called the “feeding window.”\nFrequently Asked Questions:\nTo help you decide, Let’s go over some answers to some common questions about IF and some useful tips so you can get the most out of the program.\nQ. What sets IF apart from other dieting methods?\nIF offers something very unique, in terms of enjoying physically and psychologically satisfying meals while losing weight. The absence of hunger and cravings are also a welcome feature when using IF for weight loss. Contrary to popular belief, the fasting phase has a suppressive effect on hunger. Hunger pangs may come, but they disappear quickly, only to be replaced by a sense of well being and total absence of hunger.\nQ. Are there any benefits in following IF?\nResearch has shown that fasting for relatively long periods may result in greater fat burning, even when total daily calorie intake remains the same. Most people find that they’re able to have a few more of their favorite “cheat” foods during the feeding window and still see results. This is why IF is such an appealing diet for many people.\nOther reasons why so many individuals love IF are that’s it’s relatively easy to get used to and stick with, and it’s a diet you don’t have to discontinue—ever. You can do it long-term with no adverse health effects. Instead, you’ll actually see health benefits.\nLike every diet approach out there, there’s differences among individuals in what works and what doesn’t, but so far, there seems to be a lot more “hits” than “misses”, when it comes to the success rates of people using IF for weight loss. Let’s go over one by one.\n- High degree of focus and concentration. For example programmers and writers, that may want to increase their productivity during work hours. Due to the increase in catecholamines during the fast, productivity goes up and you’ll feel more involved in whatever you’re doing.\n- There are the health benefits not to be forgotten. Improving insulin sensitivity and other health indicators, such as cardiovascular health for example, is undoubtedly of interest to a large number of people, whose main priority is to stay healthy and reduce risk factors for different types of metabolic and cardiovascular diseases.\n- IF also offers neuroprotective benefits, which may protect from brain degenerative diseases like Alzheimer’s, for example. These benefits are unique to this diet approach and cannot be achieved, to the same degree, with traditional calorie restriction and exercise.\nQ. Does Sleeping At Night Count As Hours Toward The Fast?\nYes, it does. So, for example, if you have a protein shake right before bed, then wake up eight hours later, you’re already eight hours into your fast with only eight more to reach your goal of 16.\nQ. What Can I Eat Or Drink While Intermittent Fasting?\nObviously, you don’t eat anything or consume any calories during your fasting hours. Water, of course, is perfectly fine. Other than that, opt for zero-calorie, unsweetened beverages. My personal favorites include black coffee—with no milk, cream, sugar, butter, or anything else in it—and plain, unsweetened teas like black tea or green tea.\nWhen it comes to calorie-free drinks with artificial sweeteners (like flavored waters and diet soda), there’s some uncertainty. There’s some evidence to show that some artificial sweeteners cause an insulin response, which would then blunt your ability to burn fat and contradict the point of being in a fasted state, but that’s up for debate in the scientific community.\nTo be on the safe side, I recommend not drinking artificially sweetened beverages during a fast. If you’re absolutely dying for something other than water or plain coffee or tea during the last few hours of a fast, opt for a sparkling water that’s very lightly flavored with something like natural lime.\nQ. Do I Need To Cram A Day’s Worth Of Meals Into Eight Hours?\nRegarding the “feeding window,” or the joyous time during which you get to eat, you want to reach the same calorie and macronutrient totals as you were before—provided you were already on a solid diet plan that corresponded to your goals, of course.\nYou definitely don’t want to undereat during your feeding window, or you’ll compromise your performance in the gym and your ability to build or maintain muscle mass. Get in all of your nutrients, particularly protein.\nIn theory, you’ll be eating the same number of calories and macros per day, just with a different meal schedule than a typical eat-every-few-hours nutrition plan. Of course, you can always tweak calories and macros if and when your physique and training goals change.\nQ. How Exactly Does Intermittent Fasting Enhance Fat Burning Compared To A Standard Diet?\nThe Yale/Copenhagen group published several papers showing that one of the key mechanisms in fasting-induced fat loss has to do with an increase in the activity of genes that increase the number of calories the body uses and the amount of fat it burns.[1,2]\nWhen you fast, your body turns on genes that encode for certain uncoupling proteins and enzymes that increase fat oxidation. The uncoupling proteins basically “poke holes” in the mitochondria inside muscle cells. The mitochondria are where most of your energy is derived from, especially at rest. By poking holes in them, your mitochondria produce less energy and thus have to burn far more calories to produce the same amount of energy in the form of ATP.\nIn other words, you may use more calories as a fuel source during the fasted state, which can aid your weight-loss efforts.\nMany other studies suggest that fasting may also provide numerous other health benefits like lowering cholesterol and triglyceride levels, increasing HDL (good) cholesterol levels, and even promoting greater longevity.[3,4]\nQ. What Should I Eat As My First Meal Following A Fast?\nThat’s a good question. IF allows you to be somewhat loose with your eating, but that doesn’t change the fact that high protein intake is important along with healthy, wholesome food choices. Coming off of a fast, I recommend a high-protein meal as opposed to one loaded with carbs.\nWork from the lab at Yale found that when you fast and then refeed with a low-carb meal, the activity of the genes that increase calorie and fat burning are further increased with the meal. However, when you refeed with a high-carb meal, the activity of many of these genes is decreased. I recommend a high-protein meal—for example, eggs or a protein shake—as your initial food consumption following a fast.\nQ. How About BCAAs? Can I Sip On Those During My Fast?\nI get why people do this: to help preserve muscle mass while in the fasted state. But when you’re consuming branched-chain amino acids (BCAAs), you’re not truly fasting.\nAs you probably know, amino acids combine to form protein. There are 20 aminos that are used as the building blocks of protein, including the nine essential amino acids (leucine, isoleucine, valine, tryptophan, threonine, phenylalanine, methionine, lysine, and histidine), as well as the 11 nonessential amino acids (arginine, serine, cysteine, glycine, proline, alanine, tyrosine, aspartic acid, asparagine, glutamic acid, and glutamine). If you consume just one of these amino acids, you’re essentially consuming some small amount of protein and therefore are technically not fasting.\nOne exception for using BCAAs during fasting is if you train in a fasted state. Here, you can sip on BCAAs (along with the other aminos) during your workout. When you’re exercising, BCAAs are a powerful source of energy for the muscles. And since you’re just sipping on a drink with BCAAs in it, you’re not pounding down a bunch of them. The benefits of BCAAs for your workout outweigh any potential negatives on fasting.\nAmino acids that aren’t proteinogenic can be consumed during fasting. For example, it’s OK to have beta-alanine, betaine, D-aspartic acid and—even though they’re not technically amino acids, but many people classify them as such—carnitine and creatine. These are fine to sip on during the day, especially if you’re training in a fasted state.\nQ. What are the various forms of intermittent fasting?\n- ADF (alternate day fasting, 36/12 hrs fast/feed)\n- The Warrior Diet (20/4 hrs fast/feed)\n- Eat Stop Eat (24 hrs fasting, 1-2x/week)\n- The Fast-5 Diet. (19/5 hrs fast/feed)\n- Leangains (16/8 hrs fast/feed)\nWithin each of these systems, there are more or less specific guidelines regarding nutrition, ranging from the very vague (ADF) to the strict (Leangains).\nWhat is Leangains protocol?\nThe Leangains protocol consists of two phases: A fasting phase and a feeding phase and depending on the gender the timing varies.\nFor Men: 16 hours of fasting, followed by 8 hours of feeding\nFor Women: 14 hours of fasting, followed by 10 hours of feeding\nDuring feeding period, three meals are usually eaten. Depending on the day, the composition of those meals varies. on workout days, carbs are prioritized before fat, while on rest days fat intake is higher. Protein remains fairly high on all days. That’s a very basic and general description of the protocol.\nWhat seperates Leangains from other IF patterns?\nLeangains is specifically tailored to fitness and strength training, and for those wanting to get as lean and strong as possible. In comparison to other intermittent fasting based diets much more emphasis is put on proper pre- and post-workout nutrition.\nWhat are the different protocols in Leangains?\nDepending on the user’s convenience there are several protocols like No pre-workout meal, one pre-workout meal, two pre-workout meal, etc.\nYou can easily calculate your meal timings using the IF Calculator.\nJust go the page by clicking the above link, select the “No. of Meals”, “No. of Pre-workout Meals”, “Fasting Start Date & Time” and everything including Training timings, Pre-workout meal timings, Post-workout meal timings and even the BCAA Intake timings will be laid out perfectly for you.\nAre there any guidelines to follow Leangains protocol?\nHere are a few guidelines that is considered as success factors for performance, fat loss and excellent diet compliance.\n- On workout days, break the fast with meat, veggies and a fruit. If you’re planning to train shortly after this meal, add a few carbs in the form of a starch source – potatoes or whole grain bread, for example. Make it a fairly medium sized meal but don’t force yourself. Train within 3 hrs of having eaten this meal and have a much larger meal after your workout.\n- Eat less calories on rest days than on workout days – do this by cutting down on carb intake, and make meat, fibrous veggies and fruits as the foundation of your diet for this day. The first meal of the day should be the largest, in contrast to workout days where the post-workout meal is the largest. Largest doesn’t necessarily mean largest in terms of volume; I suggest getting at least 40% of your calorie intake in this meal, and the dominant macronutrient should be protein.\n- In the last meal of the day, include a slow digesting protein source; preferably egg protein (or any other source of casein based protein). Meat or fish is also ok if you add veggies or supplement with fiber. This meal will keep you full during the fast and exert an anti-catabolic effect on muscle protein stores by ensuring that your body has an ample supply of amino acids until the next meal."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:77c0394b-18c8-425e-aeda-21cb10e83eff>"],"error":null}
{"question":"What determines the various colors of the aurora displays, and which ancient folklore beliefs were associated with these different manifestations?","answer":"The aurora's colors are determined by the type of atmospheric atoms struck and the altitude of the collision. Oxygen produces green light up to 250 kilometers and red light above that height, while nitrogen creates blue light through electron recombination or red otherwise. The most common colors include green (oxygen-dominated), pink (combination of light green and red from oxygen and nitrogen), pure red (either oxygen or nitrogen), yellow (green plus red), and pure blue (high-energy nitrogen). These colorful displays appeared differently in various cultural beliefs - in Scotland they were called 'the merry dancers,' while Norwegian folklore interpreted them as the souls of old maids dancing. Some Eskimo tribes in Labrador believed these lights were torches carried by the dead playing ball games in the sky with walrus skulls. In Wisconsin, some Native American tribes saw them as a bad omen, believing they were the ghosts of slain enemies seeking revenge.","context":["The northern lights and the southern lights are natural phenomena that occur in the night skies over the polar regions of the planet. Today, we know they are caused by gas molecules in the atmosphere colliding with solar particles. This releases energy as light and creates colourful displays of light that display in fold-like shapes, streamers, rays, arches and many other amazing forms.\nThe northern lights are also known as ‘Aurora borealis’ and the southern lights as ‘Aurora australis.’ In Roman mythology Aurora was the goddess of the dawn, so Aurora borealis means ‘dawn of the north,’ and Aurora australis means dawn of the south.\nThey can be very beautiful and awe-inspiring and at the same time mysterious and even frightening. Many different cultural and ethnic groups who lived in places where they are seen have developed many myths and legends to try and explain and make meaning of them in their own terms.\nThe Fox-fires of Lapland\nIn the language of the Finnish people the northern lights are known as “Revontulet.” In English this means “Fox Fires” and comes from a very old Finnish myth which says that the lights were produced by magical snow foxes whose swishing tales sent snow spraying into the skies.\nNorth of Finland, Norway and Sweden live the Lapp people in Lapland. This is a huge area within the Arctic Circle which ranges across parts of all three of these Scandinavian countries. The Lapps are closely related to the Finnish people. Their traditions say that the lights are the shining souls of the dead.\nWhen the lights are in the skies people are expected to behave in a solemn and respectful way. Children were also expected to be solemnly too out of respect for the departed ones. To show disrespect would bring down bad luck, sickness and the risk of death.\nThe shamans of the Lapps painted runes representing the fires on their on their drums to help them attract and capture their magical energy. They were also believed that the lights had soothing powers over conflicts and arguments.\nThere was also a belief that if you whistled when the lights were active they would come to you and take you away with them.\nThe ride of the Valkiries\nNorwegian folklore tells that they were the souls of old maids who danced and waved across the skies.\nWhile in other parts of Scandinavia and Germany the belief was that it was the Valkiries who had taken to the air when the lights appeared.\nIn Scotland, which also has strong Norse links, the lights were sometimes referred to as “the merry dancers.”\nWarriors battling in the skies\nIn other parts of the world the aurora borealis was believed to be heroes or warriors battling in the sky. In many places further from the Arctic and Antarctic Circles the lights are a rare occurrence and when they did appear they were seen as signs of coming war or sickness and were harbingers of doom.\nAmong some Eskimo tribes of Greenland the lights were connected with dancing. In some parts of Greenland the lights were thought top be the souls of children who had died at, or soon after birth.\nIn Labrador, young Eskimos believed the lights were the torches lit and carried by the dead as they played a kind of ball game in the skies with the skull of a walrus. They would dance as the lights played across the skies.\nSpirits of animals\nIn eastern parts of Canada, the Salteaus Indians, along with the Kwakiutl and Tlingit tribes of south eastern parts of Alaska the lights were thought to the spirits of humans. Tribes living along the Yukon River thought that the lights were the spirits of animals such as elk, deer, salmon, seal and whales.\nWhile to some Native American tribes of Wisconsin, North America, they were a bad omen as they believed the lights were the ghosts of the enemies they had killed who were now seeking revenge.\nMany cultures around the world looked up at them and made their own meanings and stories to explain them but here the last word goes to the Algonquin Indians. They believed the northern lights were the fires of the great creator god, Nanahbozho. After creating the world he retired to the far north. There he builds great magical campfires which light up the northern skies to remind them of the everlasting love he holds towards them.\nReferences Causes of Color - Legends and myths of the aurora Folklore Accessed 04 September 2013 this is FINLAND - Beliefs on indigenous people Accessed 04 September 2013 Aurora (astronomy) - From Wikipedia, the free encyclopedia","Aurora: The Dancing Light\n“The Valkyrior are warlike virgins, mounted upon horses and armed with helmets and spears. When they ride forth on their errand, their armour sheds a strange flickering light, which flashes up over the northern skies, making what Men call the “aurora borealis”, or “Northern Lights”.” (A notion popular to the Norse Mythology)\nThese mysterious yet heart capturing light performances put on by our planet for us to glimpse, in coordination with the sun’s rage is what we know are the renowned “Auroras”. For us to fully understand this statement we have to go into the physics of why the auroras happen, which we will learn in this article. We are used to seeing the plain night sky with no action, just like a blank theatre screen. But once in a while, the theatre lights up giving the best show which no technology on earth could provide, making people travel thousands of miles just to witness this beauty.\nThe auroras happen near the northern and southern poles. The Auroras occurring in the northern hemisphere are known as the “Aurora Borealis” and the ones in the southern pole are known as the “Aurora Australis”. The land masses which lie close to the equator or have a high light pollution have a dim chance of observing this phenomenon.\nBasically the aurora is perfectly co-ordinated stage performance put on by the Earth and the sun. The earth is a huge magnet and like all magnets, has its own magnetic field. The sun is a violent hot ball of gas and radiation, spewing out matter and energy at high speeds (Solar winds). Radiation mainly consists of electromagnetic waves and the matter emitted is electrons and protons, which carry charge, and as we know moving charges induce a magnetic field around them. Therefore interaction between the solar winds (which we notice are magnetic) with earth (which is also a magnet) would a peculiar effect of either attraction or repulsion or even a more complex mutual motion. This matter and energy, on interacting with the earth’s magnetic field and the upper atmosphere produce what we see as the spectacular auroras.\nLet us go step by step in understanding the above principle in a more detail manner\nThe Earth is a Magnet?\nWe know that the earth is huge sphere (almost) having three layers. The top layer is the one on which we live and is called the crust. It consists of neutral mineral oxides, sulphides and many other ores. It is mostly sand and rock and is 60km deep. Moving deeper we have the mantle which is a sea of molten rock and minerals and is 3200km deep. Next we have the core of the earth consisting of the earth’s parent metal “Iron” in molten form on the outside and solid on the inside. This layer is called the core.\nBasically the solid core is a ball of iron and since the temperature is very high at the core, there exist certain ions (charge carrying particles) which keep moving around creating an electric loop. Whenever there is current in a loop a magnetic field coexists arising from the centre of the loop. Any magnet will certainly consist of a magnetic field and it really does the magnetic north at the geographic north and the magnetic south at the geographic south (although they are not aligned perfectly). The field lines flow from north to the south (magnetic poles) and the pattern of the field lines are as shown below.\nSun’s Coronal Mass Ejection\nThe sun’s behaviour is very complex since it produces extravagant amounts of energy. It is mainly fuelled by a process known as “nuclear fusion” of hydrogen to form helium. During this, lots of high energy photons and other subatomic particles are released at high speeds. The light halo that surrounds the sun (best visible during a solar eclipse) is called the “Corona”. It is the outermost layer of the sun and it is this layer which spews out the “solar winds” into the solar system. At certain times, there is a sudden outburst of mass and radiation mostly occurring at certain active regions on the sun’s surface (due to variable magnetic field reconnection between two active regions). This event is known as a solar flare and the projected particles travel at speeds of one million miles per hour.\nWhen the Solar Winds Strike the Earth\nWhen these solar winds reach the earth, they follow the magnetic lines of the earth’s magnetic field and interact with the main gases of our atmosphere (nitrogen and oxygen) present at high altitudes. The high energy particles excite the nitrogen and oxygen atoms to a high energy state and are accelerated along the magnetic field of the earth in complex paths.The electrons from the solar wind have their own electric and magnetic fields and vary as they go along the earth’s magnetic field causing it to collide with different combination of atoms. This causes the auroras to dance in the sky. The excited particles are accelerated through the earth’s magnetic field and come back where the lines become vertical i.e., the poles. The atoms cannot hold this extra energy for long and will return to their ground state throwing out the excess energy in the form of photons (which is basically light).\nThe colour of the light usually depends on the type of atom struck and the energy content of the solar wind and the altitude at which they collide.\n- Oxygen – Green (up to 250 kilometres) or Red (above 250 kilometres)\n- Nitrogen – Blue if electron is recombined or Red otherwise\nThe most frequent colours are the ones which require a lesser amount of energy. The frequencies of colours are\nI. Green – Oxygen dominated\nII. Pink – Light green + Red (Oxygen and nitrogen)\nIII. Pure Red – Either Oxygen or Nitrogen\nIV. Yellow – Green + Red\nV. Pure Blue – High energy Nitrogen.\nAuroras of Different colours\nThe Auroras are usually oval shaped forming around the magnetic poles mostly near the arctic (aurora borealis) and Antarctic regions (aurora australis). The most famous places where people could catch the auroras are the obviously the north and south poles. But apart from these countries like Norway, Canada, Alaska, Finland, Southern parts of South America, Australia, New Zealand are a few places where the auroras are popularly witnessed. To see a live aurora, one should first get out as far as possible from the city and distinguish any close by light to get the best view. The light pollution could diminish the display of the aurora and the solar activity must be carefully monitored to know the timing of the auroras. This can be done via online astronomical information sites."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:899e6c8d-ee91-42d9-b3f7-d4f684e1210e>","<urn:uuid:66d5e863-4cfb-4391-8e36-2bb834238b79>"],"error":null}
{"question":"What is the special visual style used in BABYLON'S FALL and how does it affect the game's appearance?","answer":"BABYLON'S FALL uses an original 'Brushwork Filter' that gives the game world an appearance reminiscent of medieval oil paintings come to life.","context":["BABLYON’S FALL is an action RPG produced by Square Enix and developed by PlatinumGames.\nBecome a Sentinel, a chosen warrior powered by the mysterious Gideon Coffin grafted to your back. The Gideon Coffin is a symbol of your servitude to the Domitinian empire, but it's also the only thing that will keep you alive as you claw your way through the titanic Tower of Babylon and confront the untold terrors that lurk within.\nIn BABYLON’S FALL, experience the refined, high-quality PlatinumGames action seen in titles like NieR: Automata in a high-octane hack-and-slash adventure. As a Sentinel, you'll gain the ability to wield a mighty arsenal of up to four weapons; one in each of your human arms, and two more held by the spectral tethers that extrude from your Gideon Coffin. Experiment with different weapon and armor combos and explore the virtually limitless array of strategic possibilities.\nBABYLON'S FALL also features unique visuals created with an original “Brushwork Filter” that gives the world a look reminiscent of living medieval oil paintings.\nFinally, the greatest allure of BABYLON’S FALL is its 4-player online multiplayer action, which will be supported with regular updates post-launch and at no additional cost.\nBABYLON’S FALL, a collaboration between Square Enix and PlatinumGames, is available on PlayStation®5, PlayStation®4, and Steam.\nIn PlatinumGames’ first live-service title, you can matchmake with up to 16 players via the “Sentinel Force HQ” hub area, and form a party of up to 4 before taking on various quests.\nEach Sentinel Force HQ has a QuestBoard where you can choose from a wide selection of exciting and perilous adventures. While at HQ, you can also tweak your loadout and stock up on items to make sure you’re in perfect form for your next foray into the Tower of Babylon!\nCompleting quests will reward you with powerful weapons and armor, allowing you to take on even more formidable foes. Collect loot, and experiment with different loadouts to create a build that suits your unique playstyle!\nThe deep and satisfying hack-and-slash action of BABYLON’S FALL will also receive post-launch updates.\nBattle System: Weapons\n◆Powerful attack combinations using four separate weapons\nThe highly tactical battle system lets players wield up to four weapons at the same time; one in each hand and two more manipulated by the ethereal Gideon Arms, which also enable mighty Spectral Attacks.\nSentinels can switch between three attack modes with different actions and attacks: Standard, Power, and Technical. This lets them adapt to enemies, partners, and the battlefield as needed.\nBalanced weapons with great versatility. Attack speed can be increased by up to three levels by landing continuous combo attacks.\nSword Spectral Attacks allow you to throw the blade to strike at medium range.\nThese ranged weapons can be fired while moving. Their firing speed increases as combo finishers are landed, and they can also fire powerful charged shots.\nBow Spectral Attacks unleash an especially deadly shot that can also be charged.\nRods fire potent magical blasts that can be charged, and can also create enhancing or debilitating fields, giving rod users a large repertoire of tactical choices.\nRod Spectral Attacks consume SP to unleash magic of cataclysmic potency.\nHammers can deliver powerful charged attacks, and taking a blow while charging will increase the damage dealt even further. While wielding this rage-powered weapon, hammer users can also use a Battle Cry to generate threat and turn enemies toward themselves.\nHammer Spectral Attacks can be charged to smash with unbelievable power.\nShields can be used to reduce damage taken from attacks or parry them and counter. The power of the next parry increases based on the amount of damage absorbed.\nEquipping a Gideon Arm with a shield allows you to summon a Shield Wall, absorbing all incoming damage in a wide frontal arc. Equip both Gideon Arms with shields and you can even reflect enemy projectiles.\nBattle System: Gutwork\nVarious ranged actions can be performed using the special “Gideon Gut” tethers that stretch from the Gideon Coffins on Sentinels’ backs, like launching yourself at enemies or lifting and throwing objects. There are also some Gutwork actions that are unique to specific factions.\nGrab pillars of debris and fling them at foes for big damage.\nSnare an enemy with Gideon Gut and gradually debilitate them.\nRapidly close the distance to a tethered enemy.\nHook the Gideon Gut to a dead or staggered enemy to siphon their soul, regenerating your HP and SP.\nThe unique world of BABYLON’S FALL is depicted using an original “Brushwork Filter” that gives it a look reminiscent of medieval oil paintings come to life.\nAs you uncover the secrets of the Tower of Babylon, you will proceed through a number of beautiful and impressive new worlds.\nThe lowest level of the Tower of Babylon, where citizens of the empire live. Because of constant Gallu attacks, citizens are restricted from leaving their homes, and the Cloister feels deserted despite the high population.\nThe outer edge of the area of the Tower of Babylon still under human control, surging with refugees, dissidents, criminals, and all others abandoned by the empire. Much of it is submerged underwater leaking from the Frozen Cloister.\nA cloister located near the center or the Tower of Babylon that resembles a volcano. Containing dark forests and lava-filled caves, it is home to scenery one would not expect to find atop a tower.\nA snow and ice-covered cloister located in the upper part of the Tower of Babylon, above the clouds and below freezing point. It is a dangerous area that, in addition to being completely under enemy control, carries the constant threat of falling to your doom.\nState of Play Trailer revealed"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:61812f04-1d4f-4e84-bedd-e12c76ae4532>"],"error":null}
{"question":"How did Nathan Birnbaum and Florence Bascom differ in their approaches to education and mentorship in their respective fields in the early 20th century?","answer":"While both were involved in education, their approaches differed significantly. Florence Bascom had a dedicated focus on teaching geology at Bryn Mawr College starting in 1895, where she built a significant collection of minerals, rocks, and fossils for the college and trained hundreds of students, many of whom became successful geologists themselves. In contrast, Nathan Birnbaum's educational influence was more ideological and spread across different movements - from Zionism to Jewish cultural autonomy to Orthodox Judaism. While he wrote and lectured extensively, his work was primarily focused on cultural and religious education through his writings and lectures, rather than formal academic teaching.","context":["- Nathan Birnbaum is also the birth name of comedian George Burns.\nMay 16, 1864\nVienna, Austrian Empire\n|Died||April 2, 1937\n|Pen name||Mathias Acher\nDr. N. Birner\n|Occupation||Writer and journalist|\nNathan Birnbaum (Hebrew: נתן בירנבוים; pseudonyms: \"Mathias Acher\", \"Dr. N. Birner\", \"Mathias Palme\", \"Anton Skart\", \"Theodor Schwarz\", and \"Pantarhei\") (16 May 1864 – 2 April 1937) was an Austrian writer and journalist, Jewish thinker and nationalist. His life had three main phases, representing a progression in his thinking: a Zionist phase (ca. 1883 – ca. 1900); a Jewish cultural autonomy phase (ca. 1900 – ca. 1914) which included the promotion of the Yiddish language; and religious phase (ca. 1914–1937) when he turned to Orthodox Judaism and became staunchly anti-Zionist.\nNathan Birnbaum was born in Vienna into an Eastern European Jewish family with roots in Austrian Galicia and Hungary. His father, Menachem Mendel Birnbaum, a merchant, hailed from Ropshitz, Galicia, and his mother, Miriam Birnbaum (née Seelenfreund), who was born in northern Hungary (in a region sometimes called the Carpathian Rus), of a family with illustrious rabbinic lineage, had moved as a child to Tarnow, Galicia, where the two met and married.\nFrom 1882 to 1886 Nathan Birnbaum studied law, philosophy and Near Eastern studies at the University of Vienna. In 1883, at the age of 19, he founded Kadimah, the first Jewish (Zionist) student association in Vienna, many years before Theodor Herzl became the leading spokesman of the Zionist movement. While still a student, he founded and published the periodical Selbstemanzipation!, often written in large part by Birnbaum himself. In it he coined the terms \"Zionistic\", \"Zionist\", \"Zionism\" (1890), and \"political Zionism\" (1892).\nBirnbaum played a prominent part in the First Zionist Congress (1897) where he was elected Secretary-General of the Zionist Organization. He was associated with and was one of the most important representatives of the cultural, rather than political, side of Zionism. However, he left the Zionist Organization not long after the Congress. He was unhappy with its negative view of Diaspora Jewry and the transformation of the Zionist ideals into a party machine.\nHis next phase was to advocate Jewish cultural autonomy, concentrating in particular on the Jews of eastern Europe. He advocated that the Jews be recognized as a people among the other peoples of the Austrian Empire, with Yiddish as their official language. To this end he ran (in Buczacz, eastern Galicia) on behalf of the Jews (and with the support of the local Ukrainians) as candidate for the Austrian parliament. Although gaining a majority of the votes, his election was thwarted by corruption of the electoral process by the local Polish faction.\nHe was chief convener of the Conference for the Yiddish Language held in Czernowitz, August 30 –September 3, 1908. This was the first Yiddish language conference ever to take place. At the conference he took the place of his colleague and fellow Yiddish activist Sholem Aleichem who was critically ill.\nFrom about 1912 onwards, Birnbaum became increasingly interested in Orthodox Judaism, and became a fully observant Orthodox Jew in about 1916. He continued particularly to act as advocate for the Jews of eastern Europe and the Yiddish language. From 1919 to 1922 he was General Secretary of the Agudas Yisroel, a widely spread and influential Orthodox Jewish organization. He founded the society of the \"Olim\" (Hebrew for the \"Ascenders\"), a society with a specific program of action dedicated to the spiritual ascent of the Jewish people.\nNathan Birnbaum, decrying political Zionism, 1919:\nAnd is it at all possible that we, who regard Judaism as our one and only treasure, should ever be able to compete with such expert demagogues and loud self-advertisers as they [the Zionists]? It is surely not necessary that we should. We are, after all, still the mountains and they the grain, and all we need to do is to gather all our forces in a world organization of religious Jews, and it will follow of itself, and without the application of any great political cunning on our part, that we shall have it in our power to prevent what must needs be prevented and to carry out what we have to carry out. But there is no need first to create this world organization of religious Jews. It is already in existence. The world knows its name, it is Agudas Yisroel [The Union of Israel].\nHe continued to write and lecture. His most well-known publication of this period of his life was \"Gottes Volk\", 1918 (German) – \"God's Folk\", 1921 (Yiddish)—translated into Hebrew as \"Am Hashem\" (1948\nLast years and legacy\nIn 1933, at the time of the Nazi rise to power, Birnbaum and his wife, together with their son Menachem (an artist) and family, who at that time were all living in Berlin, fled to Scheveningen, the Netherlands, with the help of businessman and diplomat Henri B. van Leeuwen (1888-1973). There Birnbaum, van Leeuwen, and banker Daniel Wolfe published the anti-Zionist newspaper Der Ruf (\"The Call\"). (Menachem and his family were murdered by the Nazis in 1944.) At the same time, their son Solomon (Professor of Yiddish and Hebrew paleography) and his family fled from Hamburg to England. Their other son Uriel (artist and poet) and his family fled from Vienna to the Netherlands in 1939. Van Leeuwen, also an Orthodox Jew, became a Dutch anti-Zionist leader and Bergen-Belsen survivor.\nNathan Birnbaum died in Scheveningen in 1937 after a period of severe illness.\n- \"In bondage to our fellow Jews\", 1919, from Nathan Birnbaum, Series of Essays on Agudas Yisroel, London, 1944, reproduced in Michael Selzer, editor, Zionism Reconsidered, Macmillan, London, 1970.\n- Selbstemanzipation! Periodical. Vienna, 1885-1894. (ed., numerous articles). See above in text.\n- Die jüdische Moderne; (Schulze) Leipzig, 1896,\n- Ausgewählte Schriften zur jüdischen Frage, 2 Bände, 1910.\n- Den Ostjuden Ihr Recht!; (Löwit) Vienna, 1915,\n- Gottes Volk; (Löwit) Vienna, 1918,\n- Um die Ewigkeit. Jüdische Essays; (Welt) Berlin, 1920,\n- Im Dienste der Verheissung, Frankfurt 1927.\n- Der Aufstieg (periodical); Berlin and Vienna, Jan. 1930 - Dec. 1932.\n- Solomon A. Birnbaum (ed): The Bridge, London, 1956.\n- Confession, New York, 1946. Translation (abridged) of Gottes Volk.\n- From Freethinker to Believer in: Lucy Dawidowicz: The Golden Tradition, New York, 1967. Translation of Vom Freigeist zum Glaubigen, Zürich, 1919.\n- Shloimy Birnboim (ed) Ais Laasys - Giklibene Ksuvim fun Nusn Birnboim, Lodz, 1939. (Yiddish). Selected essays.\n- Die Freistatt (periodical). Eschweiler, 1913-1914. Numerous articles.\n- An'iberblik iber maan lebn in: Orlean, Y.L. and Hasofer, N. (eds):Yubileyum Bukh zum zektsiktn Giburtstug fun Dr. Nusn Birnboim. Yeshurun, Warsaw, 1925. Yiddish.\nThis article draws heavily on the corresponding article in the German Wikipedia (Retrieved 05:22, Feb 12, 2005 (UTC)). That, in turn, gives the following references:\n- Michael Kühntopf-Gentz, Nathan Birnbaum. Biographie; Diss. Tübingen 1990. (In German.)\n- Angelika M. Hausenbichl, Nathan Birnbaum. Seine Bemühungen um das jüdische Theater und die jüdische Kultur; Dipl.Arb. Wien 2001. (In German.)\n- dies., Wirklich nur Politiker?; in: David. Jüdische Kulturzeitschrift 54, Wien (09/2002). (In German.)\n- Joshua A. Fishman, Ideology, Society and Language. The Oddysey of Nathan Birnbaum; Ann Arbor (Karoma Publ.) 1987. (In English.)\n- Solomon Birnbaum, Nathan Birnbaum; in: Leo Jung (ed.), Men of the Spirit, New York (Kymson Publ.) 1964. (In English.)\n- S. A. Birnbaum, Nathan Birnbaum and National Autonomy; in: Josef Fraenkel (ed.), The Jews of Austria, London 1967, 1970. (In English+German.)\nAn essay on Nathan Birnbaum's activities within Orthodox Judaism - including information on the Olim (\"Ascenders\") - may be found at: \"Der Aufstieg\": Dr. Nathan Birnbaum ZT\"L, Ascent and Agudah By Rabbi Yosef Gavriel Bechhofer.\n- Jess Olson: Nation, Peoplehood and Religion in the Life and Thought of Nathan Birnbaum, Ph.D. Dissertation, Stanford University, USA, 2006.\n- Jess Olson: Nathan Birnbaum and Tuvia Horowitz in: Jewish History 17, (pp 1–29), 2003.\n- Birnbaum, Nathan in: Encyclopaedia Judaica, vol. 3, (pp. 714–716), 2nd. edn, Thomson/Gale, 2007. (also 1st edn., vol. 3, pp. 1040–1042, 1971).\n- Shanes, Joshua: Birnbaum, Nathan in: The YIVO Encyclopedia of Jews in Eastern Europe, Vol. I, (pp 186–187), New Haven, 2008.\n- Kaplan, A.E. & Landau, M. (eds): Vom Sinn des Judentums, Frankfurt/M. 1925.\n- Orlean, Y.L. and Hasofer, N. (eds):Yubileyum Bukh zum zektsiktn Giburtstug fun Dr. Nusn Birnboim. Yeshurun, Warsaw, 1925. Yiddish.\n- Wistrich, R.S.: The Metamorphosis of Nathan Birnbaum in: The Jews of Vienna in the Age of Franz Joseph, (1990).\n- Wistrich, R.: The Strange Odyssey of Nathan Birnbaum in: Laboratory for World Destruction.Germans and Jews in Central Europe, Lincoln, Neb./Jerusalem, 2007.\n- Nathan Birnbaum, “In bondage to our fellow Jews”, 1919 from Nathan Birnbaum, \"Series of Essays on Agudas Yisroel\", London, 1944 reproduced in Michael Selzer, editor, “Zionism Reconsidered”, Macmillan, London, 1970.\n- Bridger, David (1962). The New Jewish Encyclopedia. New York, Behrman House. ISBN 978-0-87441-120-1.\n- The New Jewish Encyclopedia. \"The Religion Book:Zionism\". answers.com.\n- \"Birnbaum, Nathan\" (2007). Encyclopaedia Judaica. 2nd ed. Vol. 3. Detroit: Macmillan Reference USA. pp. 714-716.\n- Olson, Jess (2013). Nathan Birnbaum and Jewish Modernity: Architect of Zionism, Yiddishism, and Orthodoxy. Stanford, Calif.: Stanford University Press. pp. 17–21.\n- \"Self-Emancipation!\" 1885–1894, with some interruptions, renamed 1894 \"Juedische Volkszeitung\"\n- Alex Bein, Herzl Year Book vol. II, p. 6, New York, 1959\n- Fishman, Joshua A. (1987). Ideology, Society & Language: The Odyssey of Nathan Birnbaum. Ann Arbor, MI: Karoma Publishers Inc. pp. 30–31.\n- First Yiddish Language Conference. Louis Fridhandler, Two roads to Yiddishism (Nathan Birnbaum and Sholem Aleichem)\n- and translated into English under the title \"Confession\" (1946), slightly abridged\n- Jews backing academic boycott against Israel\n- The personal papers of Nathan Birnbaum are kept at the Central Zionist Archives in Jerusalem. The notation of the record group is A188.\n- First Yiddish Language Conference Tshernovits\n- First Yiddish Language Conference By Nathan Birnbaum.","Florence Bascom, geologist, holding a compass\nFlorence Bascom Papers, Sophia Smith Collection, Women's History Archives at Smith College\nFlorence Bascom was one of the first female geologists in the United States and her fellow scientists thought she was one of the nationís most important geologists. She lived from 1862 until 1945 and is well known for her work at Bryn Mawr College where she taught for many years.\nBascom studied mineral crystals by looking at them with a microscope. She also studied metamorphic rocks, how mountains form, and how rocks from mountain erode into sand.\nAt the time she went to college, it wasnít easy for a woman to go to study for advanced degrees in the United States. But that didnít stop Florence Bascom! She earned two bachelorís degrees and a masterís degree from the University of Wisconsin and a Ph.D. in geology from Johns Hopkins University. She was the second woman to ever earn a Ph.D. in geology in the United States.\nFlorence started teaching geology at Bryn Mawr, a womenís college, in 1895. She collected minerals, rocks, and fossils for the college and taught hundreds of students over the years, many of whom became successful geologists too!\nShop Windows to the Universe Science Store!\nOur online store\nincludes issues of NESTA's quarterly journal, The Earth Scientist\n, full of classroom activities on different topics in Earth and space science, ranging from seismology\n, rocks and minerals\n, and Earth system science\nYou might also be interested in:\nHow did life evolve on Earth? The answer to this question can help us understand our past and prepare for our future. Although evolution provides credible and reliable answers, polls show that many people turn away from science, seeking other explanations with which they are more comfortable....more\nSometimes rocks are metamorphosed over large areas that are the size of many states or even several countries. This is called regional metamorphism. How could this happen? What force has the power to...more\nGeology is the study of rocks and geologists are the people who study them! There are many different types of geologists. Some of the common types are listed below. Mineralogists study minerals. Petrologist...more\nFlorence Bascom was one of the first female geologists in the United States and her fellow scientists thought she was one of the nationís most important geologists. She lived from 1862 until 1945 and...more\nNiels Bohr was a Danish physicist who lived between 1885-1962. He investigated atomic structure, modifying Rutherford's old model of an atom. Bohr also claimed that an atom's chemical properties are determined...more\nMarie Curie was a physicist and chemist who lived between 1867-1934. She contributed greatly to our understanding of radioactivity and the effects of x-rays. She was born Maria Skłodowska in Warsaw,...more\nAlbert Einstein was a German physicist who lived between 1879-1955. Probably the most well-known scientist of the twentieth century, Einstein came up with many original theories and invented modern physics....more\nRobert Goddard was an American physicist who lived between 1882-1945. He was a pioneer of modern rocketry who discovered that liquid fuel is more efficient than solid fuel. Although Goddard's first rocket...more"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:cb4f126d-3c85-4cc8-991a-fd8b9350a1af>","<urn:uuid:7265da0f-ac28-49ed-afe1-0288258df6c3>"],"error":null}
{"question":"Does building schools in Haiti post-earthquake and attributing natural disasters to God share a common problem of oversimplified solutions to complex issues?","answer":"Yes, both cases demonstrate oversimplified approaches to complex problems. The Haiti school-building project revealed that well-intentioned charitable acts often ignore deeper systemic issues, including economic exploitation, racial dynamics, and education inequality between elite and poor communities. Similarly, attributing natural disasters to divine intervention offers a simplistic explanation that ignores scientific understanding of natural processes and fails to address real causes and solutions. Both situations show how initial certainty and simple explanations - whether through charitable action or religious attribution - can break down when confronted with the complexity of reality.","context":["How (not) to Build a School in Haiti\nMartinique, again: during which I attend the screening of a documentary on Haiti.\nI write this as I am still in Martinique, having arrived on the 22nd of April, and I have less than a fortnight left before I leave. Last time was very different, with uncertainty being one of the main aspects of the trip – in spite of the many ways in which it propelled my work and contributed to my second stay here.\nAt the end of April, a yearly documentary festival was taking place at Madiana, a cinema located within walking distance from the Université des Antilles (University of the French Antilles) campus in Schoelcher. The festival, titled Les Révoltés de l’Histoire, consisted of a range of films that were screened over four days. I attended How (not) To Build a School in Haiti on Sunday the 30th of April.\nInterrogating Aid and NGO Work in Haiti\n[The trailer can be found below]\nThe documentary, created by Jack C. Newell, takes place soon after the earthquake of 2010. In it, the filmmaker follows a semi-retired construction company owner (Tim Myers) to Haiti, who (along with Newell) was inspired by an NPR story about the effects of the earthquake and consequent rice aid in L'Artibonite, an area where many depend upon growing and selling rice for a living. In this story, the presenters mention the difficulties met by families in affording school tuition for their children. The school is run almost singlehandedly by Enselm Simpliste, who hopes to be able to continue providing an education for his students. Teaching takes place in the room of a church, and NPR concentrates on the lack of funds for school materials as well as teachers' salaries. Newell himself admits, in the film, that NPR's story sparked the seductive idea of his documentary: following and documenting the highly important, and hopefully fruitfully charitable, project of supporting the education of children in a rural area in Haiti. The NPR story touched him, just as it touched Myers and many others.\nThe entire project takes a year and nine months, during the course of which there are numerous obstacles in the way. During the documentary, the viewer is given more information on the difficulties and ethical problems of building the school, tied to Haiti’s weak infrastructure and the problems that result from NGO aid in the country. Despite the well-intentioned idea, like others that underpin many NGO projects in the country, the concept of “aid” is placed under a lens of doubt. Newell’s documentary explores the ways in which this school-building project sheds light on issues rooted in exploitation - one that begins with Haiti’s independence in 1804.\nA Caribbean Reception\nThe director added in a short opening, thanking the viewers and stating that the title itself alludes to the impossibility of saying whether the project was “good” or “bad”. Furthermore, he states that this was the documentary’s first screening in the Caribbean, which, perhaps, alludes to the targeted audience and explains the reception that it was given in Martinique. Whilst the documentary seems to want to shed light on Haiti’s economic, social and political issues following the earthquake, the reality that remains hidden seems to be less so for the Martinican audience. One of the presenters of the screening at the film festival was Dr Max Casimir, a Haitian doctor resident in Martinique, and his mediation of/ responses to audience questions was supplemented by members familiar with Haiti (one a Martinican nurse and the other a Haitian physically handicapped as a result of the earthquake).\nOne of the criticisms put forward that the difficulties of a white man coming to Haiti, in a supposedly charitable endeavour, was inadequately foregrounded. To one Martinican present, the racial dynamic is addressed slowly in the documentary. Though it is raised quickly in the trailer, the documentary does not go beyond this form of underlining, where it is acknowledged but perhaps not treated deeply during the Americans’ time in Haiti. The audience member expressed their frustration at the disparity between their understanding of these dynamics and the Americans’ lack of them. This leads to another question, obvious to those present: do the Americans in the documentary, for the many times that they state they are white American men, become fully aware of the implications of that in Haiti?\nAnother is the lack of light shed on the elite: whilst schools, like the one for which the building in question is being created, are very often unregulated and exploitative, the elite live contentedly with the benefits of education accorded through expensiveFrench and American schooling. For others, even though they pay for their children’s education, the idea of education giving the children the possibility of accessing a better job market is lost as these schools can be a sham, due to internally inflated grades that do nothing in the face of national tests. Finally, Dr Casimir mentions that the real American actions in Haiti (explored, for example, by The Guardian and The New Yorker), which, Dr Casimir states, were political, economic and military, were unspoken in the film.\nThe audience members’ reactions were not entirely critical, and several appreciated the desire to bring to light questions concerning the idea of charity, aid and what it really meant to desire to help someone in a completely different reality, whose needs are kept invisible to outsiders in order to enforce systems that exploit them. The documentary includes excerpts of discussions with others, such as Millery Polyné and Laurent Dubois, and Jonathan M. Katz underlines the self-congratulatory aspect of charity, which, it is implied, begins even before the act occurs, and even at the moment of seeing the image or hearing the story that sets off our desire to provide help. The danger is clear: could this documentary be self-congratulatory? By seeing it as purely a “good” film, are we participating in another self-congratulatory moment, this time based on uncovering new truths about Haiti’s economic situation?\nI admit that I felt sceptical of the upbeat, fast-paced opening of the documentary: a “let’s do this!” attitude that was too simplistic, too assuming, an in-an-out operation where information would be delivered snappily, milestones reached quickly, action, action, result. The film slows down and changes tone, however, as it enters more deeply in the construction project. More doubts grow out of every seemingly well-intentioned act, exacerbated by the frustrations of a foreigner leading a project where everyday negotiations tie into much greater problems. By the end, I understood the director’s inclusion of the opening video, during which he also explains the discussions that took place prior to naming the documentary, and the way in which the initial title, “How to”, then clearly became “How not to”, and then reverted at times to “How to”. For, when the project revealed itself not to be a wonderful gift to the local community, the school had already started to be built: what to do then? And so, the director points out, even the title “How not to” still acts prescriptively.\nNo spoilers will be given here, as I truly hope that this documentary is spread more widely and watched as much as possible, but the film includes short statements on the afterlives of the people involved in the project, ambiguous in whether they continue a cycle or bring about change. And so the ending is unclear, leading us back to the beginning, where the filmmaker faces us and pleads that the documentary be discussed and debated. The ending of the film only re-raises the questions that emerged throughout the documentary, rather than answering them. As a result, the importance of ongoing questioning is placed at the forefront, perhaps, then, indicating Newell’s awareness that he, even in this film, could be wrong – that he may never find himself, and shouldn’t find himself, in the same situation of certainty that he had initially felt when he set out to film a man building a school for children in Haiti.","Argument from natural disasters\nThe argument from natural disasters is the claim that natural disasters are not all naturally caused and are therefore caused by God in an attempt to gain our attention. The argument is a variant of the more general argument from suffering.\nNatural causes are ruled out: \n- \"Still, anyone with a little age and experience, or any one simply willing to carefully consider matters, finds it a bit hard to believe that what's been occurring of late is merely the natural cycle of things. The succession and intensity of these incidents have rightly caused people to sense something isn't right in the earth, and the scientific data alone can't effectively elucidate the cause.\"\nThe explanation for natural disasters is therefore God: \n- \"In other words, God himself didn't hesitate to take the responsibility, saying, \"I'm the reason you have experienced this terrible chain of horrific episodes – the storms – the drought – the scorching heat – the crop failures – the winds that blew everything away. I did it! And I did it because I wanted to get your attention about the way you have forgotten me and my business and focused exclusively on your own.\"\"\n- \"God loves us too much to leave us that way without using whatever means necessary to move our gaze from downward to upward.\"\n\"Whenever an important event, a revolution, or a calamity turns to the profit of the church, such is always signalised as the Finger of God.\"\n- — Voltaire\nSuch claims also occur in Islam. An Iranian cleric, Hojjat ol-eslam Kazem Sediqi, claimed: \n- \"Many women who do not dress modestly lead young men astray and spread adultery in society which increases earthquakes [...] What can we do to avoid being buried under the rubble? There is no other solution but to take refuge in religion and to adapt our lives to Islam's moral codes\"\nIf true, natural disasters are a form of collective punishment, which is generally considered to be unjust.\nThere are several instances of natural disasters caused by God in the Bible.\n- Dought, Haggai 1:9-11 \n- Floods, Genesis 1:17\n- Sinkholes, Numbers 16:31\n- Earthquakes, Exodus 19:18, Matthew 27:51\n- Brimstone and fire, Genesis 19:24\n- Ten plagues of Egypt, Exodus ch.7- ch.11\n- Prophesy of seven disasters, Revelation 16 \nThe Qur'an describes similar disasters sent by God:\nNatural processes cause disasters\nThe processes that cause natural disasters are mostly understood. Their timing is difficult to predict due to the chaotic nature of the processes.\nArgument from ignorance\nThere is no direct evidence that God is involved in natural disasters. Because of the difficulty of explaining disasters, people might assume God was responsible because they had no other explanation. This is an argument from ignorance. As scientific knowledge improves, this basis is a god of the gaps.\nFlawed means of communication\nThe use of disasters as a means of communication does not fit with the idea of a loving God that has more effective means of communication available. Apart from the harm it causes, a disaster is likely to be misinterpreted as a different God or a natural process. A perfect God would use an effective means of communication.\nThis sadistic form of communication implies God is unworthy of worship.\nNatural disasters do not seem to correlate with sin or unbelief\nAreas of belief and piety are at least as disaster prone as areas of non-belief or sin.  It seems as though God rewards non-belief.\nThis point was satirised by a series of \"Boobquake\" events in 2010 that encouraged women to immodestly dress in revealing clothes to test if this resulted in a disaster:\n- \"With the power of our scandalous bodies combined, we should surely produce an earthquake.\"\nThe event resulted in no increase in earthquake activity.  The event was jokingly criticised for not having a control group.\nA Christian leader who claimed disasters were a punishment from God for homosexuality has his home destroyed by a natural disaster in 2017.\n- ↑ 1.0 1.1 Mark H. Creech, Natural Disasters: Does God Want our Attention?, Christian Post, June 3, 2013 \n- ↑ Iranian cleric blames quakes on promiscuous women, BBC, 20 April 2010 \n- ↑ Jeanet Sinding Bentzen, Origins of Religiousness: The Role of Natural Disasters, Univ. of Copenhagen Dept. of Economics Discussion Paper No. 13-02 \n- ↑ Tinamarie Bernard, Boobquake results: 200,000 women rock the world, not Mother Earth, Examiner, April 27, 2010 \n- ↑ Louisiana floods destroy home of Christian leader who says God sends natural disasters to punish gay people, The Independent, 18 August 2016\n- Boobquake event on Wikipedia\n- Lisa Wald, The Science of Earthquakes, USGS\n- Televangelist Blames Hurricane Matthew On Obama"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:973ac237-697f-49f6-86e9-62f10b2950c9>","<urn:uuid:61a89090-50c3-455b-a838-a30644ccb55d>"],"error":null}
{"question":"How does the concept of temporal-spatial transformation in hand movements parallel the brain's neuroprotective mechanisms, and what implications does this have for understanding motor control systems?","answer":"The temporal-spatial transformation in hand movements demonstrates an inherent symmetry where both spatial shape and temporal execution are transformed by the same mathematical function, suggesting a unified control system. This systematic organization is mirrored in the brain's neuroprotective mechanisms, where multiple coordinated responses activate during stress. These include the rapid expression of heat shock protein 70 within 1-2 hours of ischemia, activation of anti-apoptotic B-cell lymphoma 2 gene family members, and the upregulation of neurotrophin-3 for neuronal survival. This parallel between movement control symmetries and cellular protective mechanisms suggests sophisticated organizational principles in human motor systems.","context":["First Evidence of Affine Symmetry in Hand Movement\nMeasurements reveal powerful symmetries in the way humans move their hands, a result that may have important implications for robotics\n\"A fundamental problem in neuroscience is to understand how human movements are planned and executed.\" So begins an interesting paper today by Quang-Cuong Pham at the Collège de France and Daniel Bennequin at the Institut de Mathématiques de Jussieu, both in Paris.\nEvolution has had many millions of years to refine the process of movement so it's easy to imagine that nature must have discovered many useful shortcuts that help in planning and executing.\nIndeed, researchers have found evidence that the human motor system seems to exploit various kinds of symmetries in the way it executes movement.\nFor example, when humans draw the same shape in different sizes, they do it in the same duration. In other words, they take the same time to draw a short line as a long one. This is known as the isochrony principle.\nAccording to Quang-Cuong and Bennequin, this is good evidence that there is some kind of central control over movement planning. So in an effort to better understand this mechanism, they have devised an interesting experiment to directly measure some of its qualities. And today they publish the results.\nThese guys recorded the hand movements of four people as they scribbled onto a sheet of paper slowly and then as they did it again quickly. This experiment recorded not only the shape of the hand movements but the speed as well.\nQuang-Cuong and Bennequin compared the fast and slow scribbles, looking for line segments with similar shapes. They then used a computer to find mathematical functions called affine transformations that changed one line shape into the other.\nAffine transformations are special because although they distort shapes, they preserve features such as parallel lines and the ratio of distances along these lines.\nHaving found the appropriate affine transformation for a pair of line segments, Quang-Cuong and Bennequin then applied the same transformation to the time it took to draw the line, with surprising results.\nTheir main finding is that the same function that transforms the shape of one line segment into another also transforms the temporal structure of the line into the other.\nThat's a fascinating result. It shows there is some kind of invariance at work in the control and planning of hand movements in humans.\nWhat it doesn't show, however, is how and why this symmetry arises. Is it the result of the way the brain processes movement data (ie a software trick) or linked to the mechanics of body movement (ie a hardware trick)?\nOr perhaps there is some other reason. One intriguing possibility is a link to the Webber-Fechner law, which we've discussed on this blog before. This law describes the relationship between the physical magnitude of a stimulus and its perceived intensity, which follows a power law.\nWhat's interesting here is that the law has a formal mathematical correspondence with the theory of communication which describes the way information is transmitted.\nThat may be coincidence or it may be a clue to a deeper link between perception and interaction and the nature of information\nCould it be that the affine symmetry in hand movement is a consequence of the laws that govern the way information is transmitted and received?\nPerhaps. Clearly, there is more work to be done here and the scene is set for an explosion of result sin this area since there are all kinds of new ways to record and study body movement.\nThis kind of work ought to be of huge interest to the robotics community. If powerful symmetries lie behind the way humans move, then there may be huge gains to be had by copying the same trick for robotic movement.","1.3 Pathophysiology of acute ischemic stroke .1 Mechanisms of ischemia .1 Mechanisms of ischemia\n1.3.2 Cellular pathophysiology\nLow respiratory reserve and complete dependence on aerobic metabolism make the brain tissue particularly vulnerable to a compromised vascular supply to the brain that is called ischemia (Deb et al., 2010). The brain’s response to acute ischemia depends on the severity and duration of compromised vascular supply. It has been suggested that there are different ischemic thresholds for cerebral dysfunction and cell death. When blood flow drops from the normal value of 50 to 55 ml/100 gram/minute to about 18 ml/100 gram/minute, the brain has reached the threshold for synaptic transmission failure, however, these cells have the potential for recovery.\nThen, when blood flow drops to about 8 ml/100 gram/minute, cell death can result (Bandera et al., 2006; Braeuninger and Kleinschnitz, 2009). However, due to the presence of collateral circulation, different degrees of severity can be observed in the affected region of the brain. Consequently, part of the brain parenchyma named the\n“core”, undergoes immediate death, while other parts, the “penumbra”, may be partially injured but still have the potential to recover (Deb et al., 2010).\nOn the cellular level, the local depletion of oxygen or glucose leads to a failure of the mitochondria to produce high-energy phosphate compounds, such as adenosine triphosphate (ATP) that can trigger cell death. Although this energy failure does not immediately precipitate cell death, 5 to10 minutes of complete occlusion can lead to irreversible brain injury, and even a partial occlusion for a prolonged period can cause harmful effects (Karaszewski et al., 2009). Furthermore, as approximately\n70% of the metabolic demand in the brain is due to the Na+/K+ ATPase pump that maintains the ion gradient responsible for neuronal membrane potential, an inadequate energy supply leads to malfunctioning of the ion gradient, which results in a loss of potassium in exchange for sodium, chloride and calcium ions (Lo et al., 2003; Deb et al., 2010). This is accompanied by an inflow of water, resulting in rapid swelling of neurons and glia leading to cytotoxic edema (Kim et al., 2011). An ischemic cascade also stimulates the release of excitatory neurotransmitters in the brain. An uncontrolled release of glutamate in ischemic area, for example, enhances the excitotoxic synaptic transmission that leads to further sodium and calcium ion influxes, which uses the already depleted ATP to maintain a calcium balance, and the disordered activation of protease, lipase, and nuclease enzymes ultimately leading to cell death (Lo et al., 2003; Henson et al., 2010), (Figure 1.1).\nFigure 1.1: Major pathways implicated in ischemic cell death. (After ischemic onset, loss of energy substrates leads to mitochondrial dysfunction and the generation of reactive oxygen species (ROS) and reactive nitrogen species (RNS). Additionally, energy deficits lead to ionic imbalance and excitotoxic glutamate efflux and build up of intracellular calcium. Downstream pathways ultimately include direct free radical damage to membrane lipids, cellular proteins, and deoxyribonucleic acid (DNA)\n(Reprinted by permission from Macmillan Publishers Ltd: [Nat Rev Neurosci] (Lo et al.,), copyright (2003).\nOn the other hand, an ischemic cascade also activates neuroprotective mechanisms as a defence against cell death (Liu et al., 2009). The first protein to be released after ischemia is heat shock protein 70 (HSP70), and its messenger ribonucleic acid (mRNA) is expressed within 1 to 2 hours of ischemia. Studies on animals showed, that the HSP70 inducer is efficacious in limiting the infarct volume, and inhibiting monocyte/macrophage activation (Giffard and Yenari, 2004; Liu et al., 2009).\nOther neuroprotective mechanisms may be activated to compensate the effects of ischemia. Anti-apoptotic B-cell lymphoma 2 (Bcl-2) gene family members suppress the release of sequestered proteins and modulate calcium fluxes (Thomenius et al., 2003). The prion protein may have a neuroprotective effect, it is up-regulated during hypoxia, and inhibits neuronal cell death (Weise et al., 2006). In addition, neurotrophin-3 is the growth factor that is especially essential for the survival and maintenance of neurons, and its expression could play a role in neuronal survival after brain ischemia (Galvin and Oorschot, 2003). Interleukin-10 gene is another neuroprotective mechanism, its expression is elevated in most central nervous system diseases and aids in neuronal and glial cell survival via blocking the effects of pro-inflammatory cytokines and by promoting the expression of cell survival signals (Strle et al., 2001).\n1.4 Classification, clinical diagnosis and syndromes of acute ischemic stroke Acute ischemic stroke classifications are largely based on clinical findings and pathophysiology. The most common schemes that have been developed to classify subtypes are the Trial of Org 10172 in Acute Stroke Treatment (TOAST) and the Oxfordshire Community Stroke Project (OCSP).\nThe TOAST classification system is mainly based on the etiology of the attack and includes five categories (Jackson and Sudlow, 2005; Kirshner, 2009). Moreover, the diagnoses are based on clinical features and on data collected by tests such as brain imaging by computed tomography (CT) or magnetic resonance imaging (MRI), cardiac imaging (echocardiography), duplex imaging of extracranial arteries,\narteriography, and laboratory assessments for a prothrombotic state (Adams et al., 1993); (Table 1.1).\nTable 1.1. TOAST classification scheme of acute ischemic stroke\nSubtype classification criteria Large artery\n- Cortical, cerebellar, or brain stem dysfunction.\n- Cortical, cerebellar, or brain stem lesions > 1.5 cm upon brain imaging.\n- Diagnosis supported by > 50% stenosis of a major brain artery or branch cortical artery upon angiography or duplex imaging.\n- History of TIA in the same vascular territory, and/or exclusion of a cardioembolic source.\nCardioembolism - Cortical, cerebellar, or brain stem dysfunction.\n- Cortical, cerebellar, or brain stem lesions > 1.5 cm upon brain imaging.\n- Identified source of cardioembolism (e.g., AF or valvular disease).\n- Previous TIAs in > 1 vascular territory.\nLacunar - No evidence of cortical dysfunction.\n- Cortical, cerebellar, or brain stem lesions < 1.5 cm upon brain imaging.\n- Less than 50% stenosis of major brain artery or branch cortical artery upon angiography or duplex imaging.\n- Known lacunar syndrome.\n- History of diabetes or hypertension Other\n- Diagnosed nonatherosclerotic vasculopathy, hypercoagulable state, or hematologic disorder.\n- Inability to classify after extensive evaluation.\n- Evidence of ≥ 2 stroke subtypes (e.g., AF and stenosis >\nAbbreviations: AF: Atrial fibrillation; TIA: Transient Ischemic Attack; TOAST: Trial of Org 10172 in Acute Stroke Treatment.\nIn addition, acute ischemic strokes are also categorized according to the OCSP classification system. The OCSP classification depends on the signs and symptoms present at the time of maximal deficit after a stroke attack, and it includes total anterior circulation infarct (TACI), partial anterior circulation infarct (PACI), lacunar infarct (LACI), and posterior circulation infarct (POCI) (Bamford et al., 1991;\nJackson and Sudlow, 2005). Additionally, this classification is a reasonably valid way of predicting the site and size of cerebral infarction, the functional recovery and rates of fatality after an attack. Therefore, it can be used very early after ischemic stroke onset, before the infarct appears on the scan (Bamford et al., 1991); (Table 1.2).\nTable 1.2. OCSP classification scheme of acute ischemic stroke Subtype\nSubtype classification criteria\nTACI - Charaterized by hemiparesis, dysphasia, and homonymous hemianopia.\n- Large cortical MCA infarct or > 50% of the MCA territory plus ACA or PCA territory.\n- Subcortical infarct > 1.5 cm\nPACI - Presentation with 2 of the following: hemiparesis, dysphasia, or homonymous hemianopia.\n- Isolated dysphagia.\n- Cortical MCA infarct < 50% of the MCA territory.\n- Border zone cortical infarct between ACA and MCA or PCA and MCA territories.\nLACI - Pure motor stroke, pure sensory stroke, sensorimotor stroke, or ataxic hemiparesis.\n- Subcortical infarct < 1.5 cm.\nPOCI - Brainstem or cerebellar dysfunction and/or isolated homonymous hemianopia.\n- Cortical infarct in PCA territory.\n- Brainstem or cerebellar infarct.\nAbbreviations: ACA: anterior cerebral artery; LACI: lacunar infarct; MCA: middle cerebral artery;\nOCSP: Oxfordshire Community Stroke Project; PACI: Partial anterior cerebral infarct; PCA: posterior cerebral artery; POCI: posterior circulation infarct; TACI: total anterior circulation infarct.\nIschemic stroke clinical symptoms depend on the area of the brain and the arterial territories affected (Figure 1.2). It is usually present with an acute loss of brain functions; these functions usually involve the area of motor, sensory, language, vision, visuo-spatial perception or consciousness. And the common signs of stroke include: acute hemiparesis or hemiplegia, acute hemisensory loss, complete or partial hemianopia, monocular or binocular visual loss, or diplopia, dysarthria or aphasia, ataxia, vertigo, or nystagmus, and sudden decrease in consciousness (Blumenfeld, 2002).\nFigure 1.2. Major vascular territories of the brain and important anatomic structures.\nAbbreviations: ACA: anterior cerebral artery; MCA: middle cerebral artery; PCA: posterior cerebral artery.\n(Adapted with permission from Blumenfeld HJ. Neuroanatomy through clinical cases. Sunderland [MA]: Sinauer Associates; 2002:375).\nMotor weakness is the most frequent clinical manifestation of ischemic stroke. About two thirds of patients present with uniform hemiparesis involving face, hand, shoulder, foot, and hip. In addition, monoplegia, which occurs in approximately 19%\nof strokes, usually indicates small infarcts of the motor cortex or centrum semiovale.\nIn majority of cases, faciobrachial weakness is caused by superficial middle cerebral artery (MCA) infarcts, and distal hemiparesis indicates cortical involvement (Blumenfeld, 2002). Furthermore, sensory abnormalities are the second most frequent manifestation of stroke that occur in 50% of stroke patients, and involve the hemiface, arm, trunk, and leg. Stroke is the most common cause of pure sensory loss.\nIn addition, cortical strokes typically produce impairment of discriminative sensations with relative preservation of protopathic sensations (Sullivan and Hedman, 2008). Dysarthria occurs in nearly 8.7% of ischemic strokes. Pure dysarthria is frequently associated with cortical lesions, whereas dysarthria with other neurological signs is more frequently caused by pontine involvement (Kumral et al., 2007)."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:df0f550d-3c79-4d5a-a3bb-8bf40634c077>","<urn:uuid:0b5554d1-27ca-4e37-bd18-a6694d214092>"],"error":null}
{"question":"How do family hierarchies and pedigrees compare in terms of their structure and purpose?","answer":"Family hierarchies and pedigrees serve different but related purposes in representing family relationships. Family hierarchies are typically viewed as a hierarchical structure in terms of cousinship, ancestry (as depicted in a family tree), and inheritance, focusing on the social and legal relationships between family members. Pedigrees, on the other hand, are specifically used as graphic representations of genetic inheritance patterns and are tools used by genetic counselors to help trace inherited disorders in families. While both use tree-like structures, pedigrees use standardized symbols to show specific information about genetic traits and diseases, including affected individuals, carriers, and patterns of inheritance through generations. They also include specific notations for things like adoptions, pregnancies, and different types of twins.","context":["A hierarchy (Greek: hierarchia (ἱεραρχία), from hierarches, \"leader of sacred rites\") is an arrangement of items (objects, names, values, categories, etc.) in which the items are represented as being \"above,\" \"below,\" or \"at the same level as\" one another and with only one \"neighbor\" above and below each level. These classifications are made with regard to rank, importance, seniority, power status or authority. A hierarchy of power is called a power structure. Abstractly, a hierarchy is simply an ordered set or an acyclic graph.\nA hierarchy can link entities either directly or indirectly, and either vertically or horizontally. The only direct links in a hierarchy, in so far as they are hierarchical, are to one's immediate superior or to one of one's subordinates, although a system that is largely hierarchical can also incorporate alternative hierarchies. Indirect hierarchical links can extend \"vertically\" upwards or downwards via multiple links in the same direction, following a path. All parts of the hierarchy which are not linked vertically to one another nevertheless can be \"horizontally\" linked through a path by traveling up the hierarchy to find a common direct or indirect superior, and then down again. This is akin to two co-workers or colleagues; each reports to a common superior, but they have the same relative amount of authority.\nHierarchies have their own special vocabulary. These terms are easiest to understand when a hierarchy is diagrammed (see below).\n(N.B., while hierarchies are commonly studied using graph theory, the general terminology used is different, and words such as \"direct\" may have different general meanings)\nMost hierarchies use a more specific vocabulary pertaining to their subject, but the idea behind them is the same. For example, with data structures, objects are known as nodes, superiors are called parents and subordinates are called children. In a business setting, a superior is a supervisor/boss and a peer is a colleague.\nDegree of branching refers to the number of direct subordinates or children an object has (equivalent to the number of vertices a node has). Hierarchies can be categorized based on the \"maximum degree\", the highest degree present in the system as a whole. Categorization in this way yields two broad classes: linear and branching.\nIn a linear hierarchy, the maximum degree is 1. In other words, all of the objects can be visualized in a lineup, and each object (excluding the top and bottom ones) has exactly one direct subordinate and one direct superior. Note that this is referring to the objects and not the levels; every hierarchy has this property with respect to levels, but normally each level can have an infinite number of objects. An example of a linear hierarchy is the hierarchy of life.\nIn a branching hierarchy, one or more objects has a degree of 2 or more (and therefore the maximum degree is 2 or higher). For many people, the word \"hierarchy\" automatically evokes an image of a branching hierarchy. Branching hierarchies are present within numerous systems, including organizations and classification schemes. The broad category of branching hierarchies can be further subdivided based on the degree.\nA flat hierarchy is a branching hierarchy in which the maximum degree approaches infinity, i.e., with a wide span. Most often, systems intuitively regarded as hierarchical have at most a moderate span. Therefore, a flat hierarchy is often not viewed as a hierarchy at all at first blush. For example, diamonds and graphite is a flat hierarchy of numerous carbon atoms which can be further decomposed into subatomic particles.\nAn overlapping hierarchy is a branching hierarchy in which at least one object has two parent objects. For example, a graduate student can have two co-supervisors to whom they report directly and equally, and who have the same level of authority within the university hierarchy (i.e., they have the same position or tenure status).\nThe first use of the English word \"hierarchy\" sited by the Oxford English Dictionary was in 1880, when it was used in reference to the three orders of three angels as depicted by Pseudo-Dionysius the Areopagite (5th-6th century). Pseudo-Dionysius used the related Latin word (hierarchia) both in reference to the celestial hierarchy and the ecclesiastical hierarchy. His term is derived from the Greek for \"Bishop\" (Hierarch), and Dionysius is credited with first use of it as an abstract noun. Since hierarchical churches, such as the Roman Catholic (see Catholic Church hierarchy) and Eastern Orthodox churches, had tables of organization that were \"hierarchical\" in the modern sense of the word (traditionally with God as the pinnacle or head of the hierarchy), the term came to refer to similar organizational methods in secular settings.\nA hierarchy is typically depicted as a pyramid, where the height of a level represents that level's status and width of a level represents the quantity of items at that level relative to the whole. For example, the few Directors of a company could be at the apex, and the base could thousands of people who have no subordinates.\nThese pyramids are typically diagrammed with a tree or triangle diagram (but note that not all triangle/pyramid diagrams are hierarchical), both of which serve to emphasize the size differences between the levels. An example of a triangle diagram appears to the left. An organizational chart is the diagram of a hierarchy within an organization, and is depicted in tree form below.\nThe first requirement is also interpreted to mean that a hierarchy can have no circular relationships; the association between two objects is always transitive. The second requirement asserts that a hierarchy must have a leader or root that is common to all of the objects.\nMathematically, in its most general form, a hierarchy is a partially ordered set or poset. The system in this case is the entire poset, which is constituted of elements. Within this system, each element shares a particular unambiguous property. Objects with the same property value are grouped together, and each of those resulting levels is referred to as a class.\n\"Hierarchy\" is particularly used to refer to a poset in which the classes are organized in terms of increasing complexity.\nA nested hierarchy or inclusion hierarchy is a hierarchical ordering of nested sets. The concept of nesting is exemplified in Russian matryoshka dolls. Each doll is encompassed by another doll, all the way to the outer doll. The outer doll holds all of the inner dolls, the next outer doll holds all the remaining inner dolls, and so on. Matryoshkas represent a nested hierarchy where each level contains only one object, i.e., there is only one of each size of doll; a generalized nested hierarchy allows for multiple objects within levels but with each object having only one parent at each level. The general concept is both demonstrated and mathematically formulated in the following example:\nA square can always also be referred to as a quadrilateral, polygon or shape. In this way, it is a hierarchy. However, consider the set of polygons using this classification. A square can only be a quadrilateral; it can never be a triangle, hexagon, etc.\nNested hierarchies are the organizational schemes behind taxonomies and systematic classifications. For example, using the original Linnaean taxonomy (the version he laid out in the 10th edition of Systema Naturae), a human can be formulated as:\nTaxonomies may change frequently (as seen in biological taxonomy), but the underlying concept of nested hierarchies is always the same.\nA containment hierarchy is a direct extrapolation of the nested hierarchy concept. All of the ordered sets are still nested, but every set must be \"strict\"—no two sets can be identical. The shapes example above can be modified to demonstrate this:\nThe notation means x is a subset of y but is not equal to y.\nTwo types of containment hierarchies are the subsumptive containment hierarchy and the compositional containment hierarchy. A subsumptive hierarchy \"subsumes\" its children, and a compositional hierarchy is \"composed\" of its children. A hierarchy can also be both subsumptive and compositional.\nA subsumptive containment hierarchy is a classification of objects from the general to the specific. Other names for this type of hierarchy are \"compositional hierarchy\", \"taxonomic hierarchy\" and \"IS-A hierarchy\". The last term describes the relationship between each level—a lower-level object \"is a\" member of the higher class. The taxonomical structure outlined above is a subsumptive containment hierarchy, as are all systematic naming schemes. Using again the example of Linnean taxonomy, it can be seen that an object that is part of the level Mammalia \"is a\" member of the level Animalia; more specifically, a human \"is a\" primate, a primate \"is a\" mammal, and so on. A subsumptive hierarchy can also be defined abstractly as a hierarchy of \"concepts\". For example, with the Linnean hierarchy outlined above, an entity name like Animalia is a way to group all the species that fit the conceptualization of an animal.\nA compositional containment hierarchy is an ordering of the parts that make up a system—the system is \"composed\" of these parts. Most engineered structures, whether natural or artificial, can be broken down in this manner.\nThe compositional hierarchy that every person encounters at every moment is the hierarchy of life. Every person can be reduced to organ systems, which are composed of organs, which are composed of tissues, which are composed of cells, which are composed of molecules, which are composed of atoms. In fact, the last two levels apply to all matter. Moreover, each of these levels inherit all the properties of their children.\nIn this particular example, there are also emergent properties—functions that are not seen at the lower level (e.g., cognition is not a property of neurons but is of the brain)—and a scalar quality (molecules are bigger than atoms, cells are bigger than molecules, etc.). Both of these concepts commonly exist in compositional hierarchies, but they are not a required general property. These level hierarchies are characterized by bi-directional causation. Upward causation involves lower-level entities causing some property of a higher level entity; children entities may interact to yield parent entities, and parents are composed at least partly by their children. Downward causation refers to the effect that the incorporation of entity x into a higher-level entity can have on x's properties and interactions. Furthermore, the entities found at each level are autonomous.\nAlmost every system within the world is arranged hierarchically. By their common definitions, every nation has a government and every government is hierarchical. Socioeconomic systems are stratified into a social hierarchy (the social stratification of societies), and all systematic classification schemes (taxonomies) are hierarchical. Most organized religions, regardless of their internal governance structures, operate as a hierarchy under God. Many Christian denominations have an autocephalous ecclesiastical hierarchy of leadership. Families are viewed as a hierarchical structure in terms of cousinship (e.g., first cousin once removed, second cousin, etc.), ancestry (as depicted in a family tree) and inheritance (succession and heirship). All the requisites of a well-rounded life and lifestyle can be organized using Maslow's hierarchy of human needs. Learning must often follow a hierarchical scheme—to learn differential equations one must first learn calculus; to learn calculus one must first learn elementary algebra; and so on. Even nature itself has its own hierarchies, as demonstrated in numerous schemes such as Linnean taxonomy, the organization of life, and biomass pyramids. Hierarchies are so infused into daily life that they are viewed as trivial.\nWhile the above examples are often clearly depicted in a hierarchical form and are classic examples, hierarchies exist in numerous systems where this branching structure is not immediately apparent. For example, all postal code systems are necessarily hierarchical. Using the Canadian postal code system, the top level's binding concept is the \"postal district\", and consists of 18 objects (letters). The next level down is the \"zone\", where the objects are the digits 0–9. This is an example of an overlapping hierarchy, because each of these 10 objects has 18 parents. The hierarchy continues downward to generate, in theory, 7,200,000 unique codes of the format A0A 0A0. Most library classification systems are also hierarchical. The Dewey Decimal System is regarded as infinitely hierarchical because there is no finite bound on the number of digits can be used after the decimal point.\nOrganizations can be structured using a hierarchy. In an organizational hierarchy, there is a single person or group with the most power and authority, and each subsequent level represents a lesser authority. Most organizations are structured in this manner, including governments, companies, militia and organized religions. The units or persons within an organization are depicted hierarchically in an organizational chart.\nIn a reverse hierarchy, the conceptual pyramid of authority is turned upside-down, so that the apex is at the bottom and the base is at the top. This model represents the idea that members of the higher rankings are responsible for the members of the lower rankings.\nWithin most CGI and computer animation programs is the use of hierarchies. On a 3D model of a human, the chest is a parent of the upper left arm, which is a parent of the lower left arm, which is a parent of the hand. This is used in modeling and animation of almost everything built as a 3D digital model.\nIn this system, the three (or four with Algonquian languages) persons are placed in a hierarchy of salience. To distinguish which is subject and which object, inverse markers are used if the object outranks the subject.\nIn music, the structure of a composition is often understood hierarchically (for example by Heinrich Schenker (1768–1835, see Schenkerian analysis), and in the (1985) Generative Theory of Tonal Music, by composer Fred Lerdahl and linguist Ray Jackendoff). The sum of all notes in a piece is understood to be an all-inclusive surface, which can be reduced to successively more sparse and more fundamental types of motion. The levels of structure that operate in Schenker's theory are the foreground, which is seen in all the details of the musical score; the middle ground, which is roughly a summary of an essential contrapuntal progression and voice-leading; and the background or Ursatz, which is one of only a few basic \"long-range counterpoint\" structures that are shared in the gamut of tonal music literature.\nThe pitches and form of tonal music are organized hierarchically, all pitches deriving their importance from their relationship to a tonic key, and secondary themes in other keys are brought back to the tonic in a recapitulation of the primary theme. Susan McClary connects this specifically in the sonata-allegro form to the feminist hierarchy of gender (see above) in her book Feminine Endings, even pointing out that primary themes were often previously called \"masculine\" and secondary themes \"feminine.\"\nIn all of these random examples, there is an asymmetry of 'compositional' significance between levels of structure, so that small parts of the whole hierarchical array depend, for their meaning, on their membership in larger parts.\nIn the work of diverse theorists such as William James (1842–1910), Michel Foucault (1926–1984) and Hayden White, important critiques of hierarchical epistemology are advanced. James famously asserts in his work \"Radical Empiricism\" that clear distinctions of type and category are a constant but unwritten goal of scientific reasoning, so that when they are discovered, success is declared. But if aspects of the world are organized differently, involving inherent and intractable ambiguities, then scientific questions are often considered unresolved.\nFeminists, Marxists, anarchists, communists, critical theorists and others, all of whom have multiple interpretations, criticize the hierarchies commonly found within human society, especially in social relationships. Hierarchies are present in all parts of society: in businesses, schools, families, etc. These relationships are often viewed as necessary. However, feminists, Marxists, critical theorists and others analyze hierarchy in terms of the values and power that it arbitrarily assigns to one group over another.\nReligion- and mythology-based\n(There is currently no text in this page)\n|It has been suggested that the text on Power structure be merged into (added to) this article or section. (Discuss)|\nA hierarchy (in Greek: Ιεραρχία; this comes from ιερός-hieros, sacred, and άρχω-arkho, rule) is a way of ranking and organizing things or people. Beneath the top of the hierarchy, each part of it is below some other part.\nThis turns out to be like a pyramid. There is a single person or thing at the top level.\nAn example with people would be the structure of a company. There is the top manager, and there are a few levels of middle and lower management. At the bottom are the common workers. Another example would be an army that might have a general, followed by colonels, corporals, and sergeants, then privates.","Presentation on theme: \"Through a family tree, you can identify the relationships among your cousins, aunts, uncles, grandparents, and great-grandparents. Something to remember.\"— Presentation transcript:\nThrough a family tree, you can identify the relationships among your cousins, aunts, uncles, grandparents, and great-grandparents. Something to remember as we go through this list of heritable traits…dominant does not necessarily mean “predominant” in a population.\nSECOND TOES LONGER SECOND TOE SHORTER SECOND TOE DOMINANTRECESSIVE\nNUMBER OF FINGERS SIX FINGERS: POLYDACTYLY FIVE FINGERS DOMINANT !!!! RECESSIVE\nSection 12.1 Summary – pages 309 - 314 A pedigree can be used as a graphic representation of genetic inheritance patterns. It is a tool used by genetic counselors to help trace disorders which are inherited in families.\nFEMALE MALE UNIDENTIFIED SEX AFFECTED CARRIER RELATIONSHIP PARENTS AND CHILDREN (one boy, one girl) in order of birth FRATERNAL TWINS IDENTICAL TWINS DECEASED ENDED RELATIONSHIP PREGNANCY ADOPTED IN TO THE FAMILY ADOPTED OUT OF THE FAMILY ADOPTED BY ONE FAMILY MEMBER FROM ANOTHER Generations\nThe pedigree below shows a genetic disease or abnormality. How can we determine if it is dominant or recessive, autosomal or sex linked? If the trait is dominant, we would use the following designations: A = the trait a = normal If the trait is recessive, we would use the following designations: A = normal a = the trait While we know the phenotypes of the individuals, we don’t know the genotypes of the three unaffected individuals.\nAssume for the moment that the trait is dominant (we don't know yet). The pedigree shows that three of the individuals have the recessive phenotype and one individual has the dominant phenotype. Write the genotype of the affected individual in her symbol in the pedigree below. To do this, simply make up the allele in question…pretend the allele “A” codes for the disease, as on the previous slide. Since you don’t know if she is heterozygous, or homozygous, simply put a ? For the second allele. If possible, write the genotype of the three recessive individuals in their symbols. As you attempt to write the genotypes, keep in mind that the pedigree may not be possible for a dominant trait; it may not be possible to write the genotypes. Is it possible that the pedigree here is for an autosomal dominant trait? A? aa NO!\nWrite the genotypes in the symbol for each person in the pedigree below assuming that it is for a dominant trait. A? aa Is it possible that this pedigree is for an autosomal dominant trait? What can you conclude from these two examples about the parents of a child that has a dominant characteristic? One parent must also carry the dominant trait. YES! What must the genotypes of the affected individuals be in this pedigree? Aa\nDetermine if the pedigree below can be for a trait that is autosomal dominant. Use \"A\" and \"a\" as you did for the previous pedigrees. A? aa Is it possible that this pedigree is for an autosomal dominant trait? In conclusion, can two individuals that have an autosomal dominant trait have unaffected children? YES!\nAssuming that the trait is recessive, write the genotype of each individual in the symbol (use the same symbolic designations as before) A = normal a = the trait aa A? Is it possible that the pedigree below is for an autosomal recessive trait? NO!\nAssuming that the pedigree below is for a recessive trait, write the genotype in the symbol for each person. aa Is it possible that this pedigree is for an autosomal recessive trait? If a trait is autosomal recessive, what can you conclude about the children if both parents are affected? All children will be affected! YES!\nDetermine if the pedigree below can be for a trait that is autosomal recessive. Using the same alleles as previously, volunteer to show proof either way. aa Aa A? Both parents are unaffected, but they produced an affected offspring, so they must be heterozygous for the condition. The only genotype we can be unsure of is the male child in this pedigree. He may be homozygous dominant, or heterozygous. Either way, he does not have the autosomal recessive illness.\nDetermine if the pedigree below can be for a trait that is autosomal recessive. aa A? Aa A? Aa A? Start by filling in the individuals you absolutely know the genotypes of. What other genotypes can you be absolutely sure of? Then fill in the ones you partially know, but can’t be sure if they’re heterozygous, or homozygous dominant. Is it possible that this pedigree is for an autosomal recessive trait? YES! Notice that two generations were skipped in this instance!\nDetermine if the pedigree below can be for a trait that is X-linked recessive. Use the following designations: X A = normal X a = the trait Y = Y chromosome Start by filling in the individuals that you absolutely know the genotypes for. XaXaXaXa XAYXAY XAYXAY Can this pedigree possible show a sex-X-linked recessive disorder? NO!\nWrite the genotype within the symbol for each person in the pedigree below. XaXaXaXa XAYXAY XaYXaY Is it possible that this pedigree is for an X-linked recessive trait YES!\nWrite the genotype in the symbol for each person in the pedigree below. XaXaXaXa XAYXAY XAXaXAXa Is it possible that this pedigree is for an X-linked recessive trait? YES! Write the genotype in the symbol for each person in the pedigree below. Is it possible that this pedigree is for an X-linked recessive trait? XaXaXaXa XAYXAY XaXaXaXa NO! What conclusions can you make based on the results of these pedigree crosses?\nAffected mothers will always pass their X-linked condition on to their sons, but only if the father is also affected, will their daughters inherit the X-linked recessive condition. Carrier mothers have the ability to pass the condition on to their sons, but may only pass the allele on to their daughters, making them “carriers”. Determine if the pedigree below can be for a trait that is X-linked recessive. We will continue to use the designations \"X A and X a \". XAXaXAXa XaYXaY XaYXaY Is it possible that this pedigree is for an X-linked recessive trait? YES! What genotypes are you absolutely sure of? Can you know what the female’s genotype is?\nWhich parent did the son get the X a gene from? XaYXaY XaYXaY XAXaXAXa Males ALWAYS get their X chromosome from their mothers. The Y chromosome is ONLY donated by their fathers…so only mothers can pass sex-X-linked conditions on to their sons. Fathers will not pass their affected X allele on to their sons, only their daughters. The chance of a female getting the X-linked recessive condition depends upon BOTH parents donating a recessive X to her. It is for that reason that males are more commonly affected by sex-X-linked conditions than females.\nDetermine if the pedigree below can be for a trait that is X-linked recessive. First, fill in the known genotypes. XaXaXaXa XaYXaY Can these parents produce this offspring, if the trait is sex-X- linked? XaXaXaXa NO! In this particular cross, the female can only receive the X a allele from mom, and the X a allele from dad, so she MUST be affected.\nFor this pedigree, tell if the trait can be autosomal dominant, autosomal recessive, or X-linked recessive. Autosomal Dominant? #9 is impossible, because he would have to have gotten the dominant trait from one of his parents, and neither of them have it. Autosomal recessive? Possible Sex-X-Linked? Possible. #1 could be a carrier, and pass the disorder on to her her son\nFor this pedigree, tell if the trait can be autosomal dominant, autosomal recessive, or X-linked recessive. If the pedigree cannot fit a mode of inheritance, tell why. Autosomal dominant? Possible Sex-X-Linked? Impossible. 7 and 8 would only produce recessive children Autosomal recessive? Impossible, because 11 and 12 are not possible, as 7 and 8 would only produce recessive children.\nContrary to popular belief, inbreeding does not result in \"monstrous\" offspring. Marrying and mating with close relatives, as often occurred in royal families did increase the chances that recessive harmful alleles (like hemophilia) would be inherited. Inbreeding has caused many breeds of dogs to have harmful genetic traits. Dalmatians are often deaf, and other dog breeds have high frequencies of epilepsy, blindness, and hip dysplasia. It is true, that mutts are often hardier and have less health problems than the pure breeds."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:3a2a0aa4-9944-4228-ab1a-51b62398f2fb>","<urn:uuid:5afdba14-a6de-4bbd-8484-d6399acfa2f1>"],"error":null}
{"question":"Can you explain how the perception of safety differs between supplements and pharmaceutical drugs, and what is the scientific reality behind Red Yeast Rice as a specific example?","answer":"While supplements are often perceived as safe because they are natural, this is a misleading dichotomy. In reality, there is no biological difference between supplements and drugs - they both target the same biological systems and can be both beneficial and harmful. Red Yeast Rice exemplifies this, as it contains Monacolin K, which is chemically identical to the active ingredient in statin drugs. Red Yeast Rice can have the same side effects as pharmaceutical statins, including myopathy, muscle tissue breakdown, and liver toxicity. Additionally, unregulated supplements like Red Yeast Rice may contain harmful contaminants like citrinin, which can cause kidney failure. The perception of supplements as universally safe stems from the 1994 DSHEA legislation that classified them as food, despite evidence of risks including 23,000 ER visits per year in the US due to supplements and 20% of drug-induced liver injury being caused by supplements.","context":["Can Red Yeast Rice Lower Cholesterol?\nBy Zoe Halbert, CPD UT Austin with Alexa Sparkman MA, RDN, LD\nRed Yeast Rice is a traditional Chinese ingredient and medicine found in both food and supplement form. Recently it has been receiving a lot of attention due to claims that red yeast rice lowers cholesterol dramatically. High cholesterol, specifically high LDL cholesterol, is a major risk factor of cardiovascular disease, the number one cause of death in the United States.\nThere are many ways of managing high cholesterol including medications and lifestyle factors, such as diet and exercise. Red yeast rice is now said to be another option. It is produced by culturing rice with many strains of a yeast called Monascus purpureus. The yeast produces Monacolin K, which is chemically identical to the active ingredient in statins, cholesterol-lowering drugs.\nSo, are these claims about red yeast rice true?\nSeveral studies have showed evidence that Red yeast rice supplements are effective at lowering blood cholesterol and can be a viable alternative for patients that don’t tolerate statins.3-7 Since research is still in its early stages, experts still aren’t sure what the ideal dose should be. The amounts taken in some studies have varied from 1.2 to 2.4 grams per day. These dosages have been both safe and effective at lowering cholesterol considerably.\nDespite the evidence supporting the blood cholesterol lowering effect of red yeast rice, there is insufficient evidence to support recommending the product to patients in the United States due to lack of regulation. The FDA claims red yeast rice products that contain more than trace amounts of Monacolin K are considered unapproved new drugs and cannot be sold legally as dietary supplements. Therefore, any red yeast rice supplements found in health stores In the U.S. will have very little of the active ingredient needed to lower cholesterol. More so, the amount of Monacolin K in a supplement can be very unpredictable. A 2017 study that analyzed different brands of red yeast rice supplements showed that the amount of Monacolin K ranged from 0% to 0.58%.\nThough the United States has not approved the legal sale of red yeast rice with therapeutic amounts of Monacolin K, other nations have. The European Food Safety Authority has approved red yeast rice for maintaining cholesterol levels, and recommends the consumption of 10 mg of Monacolin K per day for adults.\nWhat about consuming red yeast rice as a meal ingredient?\nRed yeast rice can be used in cooking and is very common in some traditional Chinese dishes. It can be very difficult to find the ingredient in supermarkets In the United Sates though. There is insufficient evidence of red yeast rice as a food ingredients having an effect on lowering cholesterol.\nDoes red yeast rice have any side effects or safety concerns?\nThe same side effects that can occur in patients taking statins can also occur in patients who take red yeast rice products that contain Monacolin K including myopathy, muscle tissue breakdown, and liver toxicity.1 Monacolin K can interact with alcohol and medications that target the liver. Another concern is that some unregulated red yeast rice products may contain a contaminant called citrinin, which can cause kidney failure.2 It is important to speak with your physician before taking any new supplement.\nThe Bottom Line:\nRed Yeast Rice supplements containing Monacolin K have been proven to lower cholesterol effectively. However, dosages have not been standardized and therapeutic doses are not sold legally in the United States. Without regulation, products coming from other countries may contain harmful contaminants. Just remember natural doesn’t mean free from potential harm. All supplements should be taken with the same care used for any medication.\n- Red Yeast Rice.” National Center for Complementary and Integrative Health, U.S. Department of Health and Human Services, 22 Feb. 2017, nccih.nih.gov/health/redyeastrice#hed1. Accessed 24 Sept. 2017.\n- “Red Yeast Rice.” WebMD, WebMD, www.webmd.com/cholesterol-management/red-yeast-rice#2. Accessed 24 Sept. 2017.\n- Nguyen, Thu, et al. “Red Yeast Rice.” Foods, vol. 6, no. 3, Jan. 2017, p. 19., doi:10.3390/foods6030019.\n- Cohen, Pieter A, et al. “Variability in strength of red yeast rice supplements purchased from mainstream retailers.” European Journal of Preventive Cardiology, vol. 24, no. 13, 2017, pp. 1431–1434., doi:10.1177/2047487317715714.\n- Becker, David J. “Red Yeast Rice for Dyslipidemia in Statin-Intolerant Patients.” Annals of Internal Medicine, vol. 150, no. 12, 2009, p. 830., doi:10.7326/0003-4819-150-12-200906160-00006.\n- Verhoeven, Veronique, et al. “Red yeast rice lowers cholesterol in physicians – a double blind, placebo controlled randomized trial.” BMC Complementary and Alternative Medicine, vol. 13, no. 1, 2013, doi:10.1186/1472-6882-13-178.\n- Johnston, T.p., et al. “Preventing cardiovascular heart disease: Promising nutraceutical and non-Nutraceutical treatments for cholesterol management.” Pharmacological Research, vol. 120, 2017, pp. 219–225., doi:10.1016/j.phrs.2017.04.008.\nGum, Sang Il, et al. “The physico-Chemical alteration of lovastatin and enhanced antioxidant effect of Bacillus subtilis fermented-Red yeast rice product.” Food Chemistry, vol. 232, 2017, pp. 203–209., doi:10.1016/j.foodchem.2017.04.023.\nSpigoni, Valentina, et al. “Effects of a New Nutraceutical Formulation (Berberine, Red Yeast Rice and Chitosan) on Non-HDL Cholesterol Levels in Individuals with Dyslipidemia: Results from a Randomized, Double Blind, Placebo-Controlled Study.” International Journal of Molecular Sciences, vol. 18, no. 7, Dec. 2017, p. 1498., doi:10.3390/ijms18071498.\n10. Peng, Diane, et al. “Original Research.” AJN, American Journal of Nursing, vol. 117, no. 8, 2017, pp. 46–54., doi:10.1097/01.naj.0000521973.38717.2e.\n11. Cohen, Pieter A, et al. “Variability in strength of red yeast rice supplements purchased from mainstream retailers.” European Journal of Preventive Cardiology, vol. 24, no. 13, 2017, pp. 1431–1434., doi:10.1177/2047487317715714.\n12. “Scientific Opinion on the substantiation of health claims related to Monacolin K from red yeast rice and maintenance of normal blood LDL cholesterol concentrations (ID 1648, 1700) pursuant to Article 13(1) of Regulation (EC) No 1924/2006.” EFSA Journal, vol. 9, no. 7, 2011, doi:10.2903/j.efsa.2011.2304.","Supplements vs drugs - the birth of a misleading dichotomy\nIn my last email, I illustrated the supplement double standard - a tendency to think that supplements are effective and have no side effects. In this email, I will explore how this perception came to be. Why we erroneously think of supplements as being different than drugs.\nDrugs and supplements defined\nDrugs are defined as compounds that are novel and synthetic. They are synthesized in a lab and not found in nature. Drugs include prescription medications and over-the-counter medications such as Advil or Nexium.\nA supplement, on the other hand, is a medication found in nature - a natural medication. It covers any of the following:\n* vitamins and minerals\n* botanical or herbal products: including algae and macroscopic fungi\n* amino acids\nOne and the same\nApproximately 50% of drugs, however, are derived from natural sources. Aspirin, penicillin, cortisone, statins, taxol, colchicine, and opioids to name a few. This makes the dichotomy of medications into natural (supplements) vs non-natural (drugs) misleading. There is no biological difference between supplements and drugs. They both end up targeting the same biologic systems, they both can be beneficial and harmful, and they both should be treated with equal respect and caution. (I will expound on the biologic similarities between supplements and drugs in my next email)\nThe legal dichotomy of medications\nIn reality, the natural vs non-natural dichotomy was a product of the law. It was about regulation, ownership, and patentability. Supplements are not patentable because they already exist in nature and drugs are patentable because they do not exist in nature. Lets explore why this medication dichotomy became popularized, and how it changed the way we view medications.\nA brief history of DSHEA\nAppreciating their immense complexity and potential, the FDA wanted natural medications to fall under its jurisdiction; to be further researched, scrutinized, and regulated like drugs. The supplement industry wanted deregulation. In the 1990’s the fight was coming to a head. In favor of deregulation, senator Orin Hatch, hatched The Dietary Supplement Health and Education Act (\"DSHEA”). With help from industry and a large media campaign the act was passed in 1994 (Watch Mel Gibson in this hilarious commercial from the campaign trying to protect the right to his “vitamins”). This took medications found in nature out of the hands of the FDA, leaving the ndustry to regulate itself.\nDSHEA says supplements are safe\nTo justify deregulation, DSHEA had to declare that supplements are safe. To do this, it granted natural medications with the same status as food. Food is safe and does not need scientific approval to be produced or used, neither should medications sourced from nature. It even gave natural medications a new name, “dietary supplements”, reflecting their new status as food. Now if a company wants to release a new supplement, no safety or effectiveness testing is required. Instead, the supplement company will police itself. It is solely responsible for determining the quality and safety of its products. The fox is guarding the henhouse.\nDSHEA does not allow any disease claims\nThere was a price to pay for deregulation. If a supplement could actually treat a disease, it must be potent and have side effects and should be regulated. Thus, supplements cannot claim to treat disease. This was necessary in order for DSHEA to maintain its declaration that supplements are safe.\nTurmeric cannot claim to prevent cancer. Zinc cannot claim to treat colds. CoQ10 cannot claim to prevent heart disease. In fact, the following disclaimer is supposed to be added to supplement labels and marketing: “These statements have not been evaluated by the Food and Drug Administration. These products are not intended to diagnose, treat, cure, or prevent any disease.”\nUnfortunately, many supplement companies are noncompliant with this restriction. They make specific disease claims or neglect to include the disclaimer. The FTC is unable to police the marketing of some 87,000 supplements in the US - and companies know this.\nDSHEA allows structure/function claims\nInstead of disease claims, DSHEA allows supplement companies to make structure/function claims. Let me explain what this means. When food is deficient, the structure of the body is compromised. Bones don’t grow, muscles atrophy, etc. Thus, one can claim that food “supports” these structures of the body. Likewise, when food is deficient, the functioning of the body is compromised. The heart won’t pump properly, the immune system will not fight off infection, etc. Thus, one can claim that food “supports” these functions of the body.\nWith respect to the marketing, DSHEA requires a new language for supplements. Words like “prevents” or “treats” are to be avoided. Instead they should be replaced by “supports“ or “boosts”. Specific diseases are not to be mentioned. Instead they should be replaced by organ systems. For example, DSHEA prohibits “Our supplement treats arthritis”; but would allow, “Our supplement supports joints”. DSHEA would prohibit, “Our supplement prevents the flu”, but would allow ,“Our supplement boosts the immune system”.\nIt turns out, the ambiguity of the structure/function claim works to the advantage of supplement companies. It has led to a supplement language that is far more appealing and casts a wider net than the one used by drug companies. Wouldn’t you rather take a medication that “boosts the immune system” than one that claims to prevent the flu? A medication that only prevents a flu sounds limited. Why not have the entire immune system “boosted”? The structure/function claim was the loophole supplement companies were looking for.\nThe consequences of DSHEA\nAlthough DSHEA protects the consumer right to access products from nature, the costs may be too great. The specifics of the act and the way in which industry and the public has responded, has led to several problems:\n1. Supplements are perceived as safe when in fact they are not. There are 23,000 ER visits per year in the US due to supplements and 20% of drug induced liver injury is caused by supplements. This is only the tip of the iceberg because side effects are not formally tracked.\n2. Supplements are perceived as being able to prevent and treat disease. Some companies make specific disease claims breaking the law while others use the ambiguous nature of structure/function claims to their advantage. Consumer confidence is confirmed by public surveys and financial statements - we spend $38 billion per year on supplements in the US, and growing.\n4. The quality of supplements is poor. DSHEA has no requirements for quality control nor has it any punitive measures for poor quality. Without quality control, products can contain anything. This probably explains why 50% of supplements sampled on shelves contain none of the ingredients on the label. In addition, some supplements are ironically tainted with prescription drugs. (see FDA site listing known tainted supplements for weight loss ).\n4. Private research on natural medications has stagnated. Companies are no longer required to prove safety and effectiveness. They rarely spend money on good clinical trials. Instead, they spend money on marketing the loopholes of DSHEA. So we don’t know that much more about the true safety and effectiveness of these natural medications today than the day DSHEA was passed in 1994.\n5. DSHEA promotes unscientific thinking. In particular, the appeal to nature fallacy: if something is natural it is safe, if it is unnatural it is unsafe. This leads to the public’s misunderstanding of science.\n6. DSHEA leads to a negative perception of drugs. If supplements are safe and effective, why use synthetic drugs with all their side effects? White Willow bark has the same active ingredient as Aspirin; yet, only Aspirin is forced to be adorned with warning labels.\nDSHEA is responsible for officially separating medicinal compounds into supplements and drugs in the US. It has done so primarily based on regulation, ownership and patentability - creating a misleading dichotomy. It’s consequences include: a false belief that supplements are effective and safe, an increase in the usage of unsafe and ineffective supplements, poor supplement quality, a stagnation of private research, and the promotion of unscientific thinking.\nBiologically, there is no difference between a supplement and a drug. It does not matter whether a medication is regulated or unregulated, patentable or unpatentable, natural or synthetic. What matters is if it works. There is no “supplement” form of medication. There is only medications that work or medications that do not work."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:331f6ee5-5605-4f48-8639-f9fca1f14c89>","<urn:uuid:1af62df7-a9ef-45e0-85dc-7d6bc141492d>"],"error":null}
{"question":"What are the key principles and practical limitations of using genetic markers in criminal investigations, and how do they compare to the accountability challenges in command responsibility cases?","answer":"Genetic markers serve as unique DNA sequences for identifying individuals in criminal cases through techniques like STR and SNP analysis, enabling investigators to link suspects to crime scenes with high accuracy. However, they face practical limitations including false positives, sample quality issues, and complex interpretation challenges with mixed samples. Similarly in command responsibility cases, while commanders have clear legal duties to prevent crimes by their subordinates, practical limitations can affect accountability - as seen in cases like Bemba where remote command situations created challenges in oversight and investigation. Both domains struggle with balancing accountability needs against practical constraints, though genetic markers provide more objective scientific evidence compared to the more subjective assessment of commander duties and responsibilities.","context":["In Bemba, Command Responsibility Doctrine Ordered to Stand Down\nFew acts carry a weightier burden than the acceptance of authority over persons permitted to kill. The gravity of the commander’s responsibility stems from practical as well as moral concerns, and is reflected in legal doctrine dating back centuries. But [the Bemba] Appeals Chamber appeared to lighten this burden…\nFew acts carry a weightier burden than the acceptance of authority over persons permitted to kill. The gravity of the commander’s responsibility stems from practical as well as moral concerns, and is reflected in legal doctrine dating back centuries. But a 2018 judgment of the International Criminal Court Appeals Chamber appeared to lighten this burden, reversing, in Bemba, convictions of an accused it described as “Commander-in-Chief” of the “military branch” of a political party over which he also presided.1 The ruling’s construction of Article 28(a) of the ICC’s Rome Statute erodes not only the foundations of command responsibility doctrine, but also societal aspirations, given voice in the Statute’s preamble, “that the most serious crimes of concern to the international community as a whole must not go unpunished…”2 Recognizing the likelihood the question again will confront some future ICC chamber, this comment argues for an interpretation that is grounded in the purposes of the command responsibility doctrine and of the Court itself.\nMen who take up arms against one another in public war do not cease on this account to be moral beings, responsible to one another and to God.\nSo wrote Professor Francis Lieber in his milestone Instructions, issued in 1863, during the United States’ Civil War.3 The statement pointed to the heavy individual burden that permission to kill imposes, particularly when that permission is conferred within a system professing to place high value on the life of every human and on the liberty and security of every person. By the time of Lieber’s compilation, the moral onus already had found expression in the laws and customs of war, extensive even then and since amplified, through practice, codification, and commentary. Today, even as this body of law permits killings in combat, it also constrains them, by application of principles like necessity and by humanitarian injunctions against unnecessary suffering. At least since the post-World War II trials at Nuremberg and Tokyo, moreover, a person who acts outside these constraints risks individual punishment for violations of international criminal law.4\nLeadership status does not relieve a person of this risk of punishment. Quite to the contrary. For in accepting authority over troops given permission to kill, a commander accepts the duty to be responsible for her troops’ actions as well as her own. The moral dimension of command responsibility is apparent. Supervision of permitted killings, no less than the killings themselves, stands in tension with societal valorizations of human life; indeed, tension may be greater for the reason that the commander has power to control the behavior of many persons beyond herself. A dimension of military practicality also inheres in the doctrine of command responsibility. Both the effectiveness of military operations and the protection of one’s own military forces depend on military discipline, and it is the commander’s duty to instill and maintain discipline in all persons under her authority, through training, oversight, and, when warranted, reprimand. Indicative of this moral and practical significance are command responsibility’s deep roots: many commentators date the doctrine to 1439, and some to a couple millennia before that.5 Its many legal expressions range from a 1907 treaty according “rights…of war” only to persons in a unit that is inter alia “commanded by a person responsible for his subordinates” to the 2017 terms of reference for the Syria investigative mechanism.6 As with other modes of international criminal liability, persons have endured trial, conviction, and punishment on charges of command responsibility ever since the post-World War II period.\nIt bears stressing that convictions have hinged upon the commander’s own behavior; that is, on his own failure to act as military, moral, and legal considerations require him to do. An oft-quoted passage by Professor Yoram Dinstein encapsulates the point:\nIt must be accentuated that command responsibility is all about dereliction of duty. The commander is held accountable for his own act (of omission), rather than incurring ‘vicarious liability’ for the acts (of commission) of the subordinates.7\nIt is not a matter of strict liability, for guilt may not lie simply because of command status. Conviction is based, rather, upon proof that a commander breached his duty by failing to act when he knew, or should have known, that subordinates were about to, or already had, committed violations of the laws of war. Allowing conviction upon proof of a mens rea lower than actual knowledge avoids what Professor Roger S. Clark called “an invitation to the commander to see and hear no evil,” which would undermine “serious effort to make the command structure responsive to the humanitarian goals involved.”8\nDrafters at the 1998 Rome Diplomatic Conference embraced these views, so that Article 28(a) of the ICC Statute states:\nA military commander or person effectively acting as a military commander shall be criminally responsible for crimes within the jurisdiction of the Court committed by forces under his or her effective command and control, or effective authority and control as the case may be, as a result of his or her failure to exercise control properly over such forces, where:\n- That military commander or person either knew or, owing to the circumstances at the time, should have known that the forces were committing or about to commit such crimes; and\n- That military commander or person failed to take all necessary and reasonable measures within his or her power to prevent or repress their commission or to submit the matter to the competent authorities for investigation and prosecution.\nThat is not what happened in last year’s appellate ruling in Bemba, however. The accused, a Congolese national, stood trial on two counts of murder and rape as crimes against humanity, plus three counts of murder, rape, and pillage as war crimes based on his liability as a commander for acts that his militia’s troops had committed in the Central African Republic. In 2016, a Trial Chamber entered convictions on all counts and sentenced him to eighteen years’ imprisonment. Two years later, the Appeals Chamber, by a vote of 3 to 2, applied a de novo standard of review and fully acquitted the accused.\nCentral to this result was the appellate majority’s discussion of the element set forth in Article 28(a)(ii), concerning the commander’s failure to “take all necessary and reasonable measures within his or her power to prevent or repress their commission…” The words “all” and “necessary” militate in favor of setting high expectations on what it is “reasonable” to expect of a commander. But the appellate majority placed the bar quite low. For example, Paragraph 191 faulted the Trial Chamber for:\n[a] failure to fully appreciate the limitations that Mr Bemba would have faced in investigating and prosecuting crimes as a remote commander sending troops to a foreign country had an important impact on the overall assessment of the measures taken by Mr Bemba.\nAt odds with doctrine that holds willful blindness is no defense to a charge of command responsibility, the statement goes far to excuse a commander for absenting himself, figuratively and literally, from the field.\nParagraph 170, meanwhile, declared, without citation to authority:\nCommanders are allowed to make a cost/benefit analysis when deciding which measures to take, bearing in mind their overall responsibility to prevent and repress crimes committed by their subordinates.\nThe concept of “cost/benefit analysis” derives from economics, of course, and tends to prefer quantitative assessment. It thus seems ill-suited to evaluating the qualitative concerns about protection—force protection, as well as protection of civilians and persons hors de combat—that underlie command responsibility doctrine.\nThe apparent welcome of defense assertions of “costs” said to outweigh the “benefits” is curious for yet another reason. The Trial Chamber’s found a failure to satisfy the Article 28(a)(ii) duty of care after positing a list of measures that it ruled the accused could have taken to prevent or repress the crimes his subordinates committed. But the appellate majority rejected this line of reasoning on the ground that the accused had not been given notice that such possibilities would be taken into account. Rejection on this basis likely will astound a myriad of attorneys who have litigated complex criminal cases, and of judges who have presided over them. Removal of this method of legal reasoning provokes questions about what methods the majority would allow to the ICC’s courts of first instance. As yet there are no answers. But one thing is known: the majority’s construction treats an accused commander like an ordinary defendant, and in so doing disregards a duty of care that is justified by military practice as well as humanitarian concerns, and prescribed in law. Purporting to do so to ensure a fair trial, it ignores that there is no unfairness in holding a commander to the duty that he himself accepted when he assumed command. The doctrine of command responsibility, and not the responsible commander, has been made to step down.\nThis is no mere cavil. Given the Statute’s directive to concentrate on the “most serious crimes,” coupled with resource constraints and the sheer numbers of potential defendants, the actual committers of atrocities seldom will appear before the ICC. In the dock instead will be their commander, who led, acquiesced, or turned a blind eye to their criminality—or failed to punish them after crimes occurred. To tolerate such derelictions of duty is to condone indiscipline and so to increase the risks of the very harms that the doctrine of command responsibility is intended to dispel. In the court that was established to entrench a new era of accountability, the result may be that no one can be held to account.\nEndnotes — (click the footnote reference number, or ↩ symbol, to return to location in text).\nThe Prosecutor v. Jean-Pierre Bemba Gombo, ICC-01/05-01/08 A, Judgment on the appeal of Mr Jean-Pierre Bemba Gombo against Trial Chamber III’s “Judgment pursuant to Article 74 of the Statute” (AC, Jun. 8, 2018), available online, archived. ↩\nRome Statute of the International Criminal Court, Adopted by the United Nations Diplomatic Conference of Plenipotentiaries on the Establishment of an International Criminal Court, Jul. 17, 1998, UN Doc. A/CONF.183/9, as amended [hereinafter Rome Statute], available online. ↩\nSee Principles of International Law Recognized in the Charter of the Nürnberg Tribunal and in the Judgment of the Tribunal, Principle 1, II Yearbook of the International Law Commission 374 (1950), available online.\n(“Any person who commits an act which constitutes a crime under international law is responsible therefor and liable to punishment.”).\n(quoting 1439 edict first quoted in Essays on the Modern Law of War 283 (2d ed. Mar. 1, 1999), paywall);, Ed.,\n(quoting Sun Tzu circa 500 AD). ↩\nHague Convention No. IV, Respecting the Laws and Customs of War on Land, 36 Stat. 2277, Treaty Series 539, Art. I (Oct. 18, 1907), available online.\nTerms of Reference of the International, Impartial and Independent Mechanism to Assist in the Investigation and Prosecution of Persons Responsible for the Most Serious Crimes under International Law Committed in the Syrian Arab Republic since March 2011, ¶ 6, available online,\n(stating that the mechanism “focuses on evidence pertaining to mens rea and to specific modes of criminal liability, including under the principle of command or superior responsibility established under international criminal law.”). ↩\nSee , supra note 5, at 437–38 (writing that Article 28(a)(ii) could be construed to enlarge potential liability, yet noting, via quotation of An Introduction to the International Criminal Court 85 (1st ed. Jul. 5, 2001), paywall, doi, that “other superiors” liability under Article 28(b) requires a mens rea higher than that for military commanders). ↩\nSuggested Citation for this Comment:\nIn Bemba, Command Responsibility Doctrine Ordered to Stand Down, ICC Forum (May 27, 2019), available at https://iccforum.com/responsibility#Amann.,\nSuggested Citation for this Issue Generally:\nWhat Does the Bemba Appeal Judgment Say About Superior Responsibility Under Article 28 of the Rome Statute?, ICC Forum (May 27, 2019), available at https://iccforum.com/responsibility.","Genetic Markers in Criminal Investigations: DNA Analysis\nThe utilization of genetic markers in criminal investigations has revolutionized the field of forensic science. By employing DNA analysis techniques, law enforcement agencies have been able to solve crimes that were previously unsolvable and bring justice to victims and their families. One notable example is the case of John Doe, a serial killer who managed to evade capture for over a decade until his arrest in 2015. Through the meticulous examination of genetic markers found at various crime scenes, investigators were able to link multiple murders to Doe, leading to his eventual conviction.\nGenetic markers are specific sequences within an individual’s DNA that can be used as unique identifiers. These markers can vary between individuals due to natural variations in the human genome such as single nucleotide polymorphisms (SNPs) or short tandem repeats (STRs). The discovery and understanding of these genetic markers have paved the way for advancements in forensic DNA analysis, enabling investigators to establish connections between suspects and crime scene evidence with unprecedented accuracy.\nIn recent years, DNA analysis has become an indispensable tool in criminal investigations. It allows for the identification of perpetrators based on even trace amounts of biological material left behind at a crime scene. Furthermore, it aids in excluding innocent individuals from suspicion by providing conclusive proof of their non-involvement.\nImportance of Genetic Markers in Criminal Investigations\nGenetic markers play a crucial role in criminal investigations, aiding law enforcement agencies in identifying and linking suspects to crime scenes. DNA analysis has become an invaluable tool for forensic scientists, providing compelling evidence that can strengthen or exonerate individuals involved in criminal cases. To illustrate the significance of genetic markers, consider the following hypothetical scenario: A brutal murder has taken place, leaving behind no witnesses or tangible evidence. However, blood stains found at the crime scene offer hope for investigators seeking justice.\nFirstly, let us explore the emotional impact of genetic markers in criminal investigations:\n- Closure: Genetic markers provide closure to grieving families by assisting in the identification of perpetrators responsible for heinous crimes.\n- Justice: These markers act as beacons of truth and accountability, ensuring that criminals are held accountable for their actions.\n- Relief: The presence of strong genetic evidence can alleviate concerns about wrongful convictions, giving confidence to both victims and society at large.\n- Deterrence: The knowledge that genetic markers can conclusively link individuals to crimes serves as a powerful deterrent against potential offenders.\nTo further understand the practical implications of genetic marker analysis, we can refer to the table below which outlines some common types of genetic markers used in forensic DNA analysis:\n|Type of Marker||Application|\n|Short Tandem Repeats (STRs)||Highly polymorphic regions on chromosomes commonly used for profiling purposes.|\n|Single Nucleotide Polymorphisms (SNPs)||Variations occurring at single base pair positions within a genome; useful for determining ancestry and predicting physical traits.|\n|Insertion/Deletion Polymorphisms||Indels involve changes where segments of DNA are either inserted or deleted; they serve as important genetic landmarks.|\n|Mitochondrial DNA (mtDNA)||Inherited only from the mother, mtDNA analysis can be useful when traditional DNA samples are degraded or scarce.|\nIn summary, genetic markers hold immense importance in criminal investigations as they provide crucial evidence to link suspects and victims to crime scenes. The emotional impact of genetic marker analysis cannot be overlooked, offering closure, justice, relief, and deterrence. In the subsequent section, we will delve into the various types of genetic markers used in forensic DNA analysis.\n[Next Section: Types of Genetic Markers Used in Forensic DNA Analysis]\nTypes of Genetic Markers Used in Forensic DNA Analysis\nGenetic Markers in Criminal Investigations: DNA Analysis\nIn criminal investigations, genetic markers play a crucial role in identifying and linking suspects to crime scenes. Through the analysis of DNA samples found at the scene or on evidence, investigators can establish connections between the perpetrator and the crime. One notable example is the case of John Doe, where DNA recovered from a murder weapon matched that of a suspect already in custody for an unrelated offense. This breakthrough not only provided concrete evidence against the individual but also brought justice to the victim’s family.\nForensic DNA analysis relies on different types of genetic markers to determine identity and establish relationships between individuals. These markers provide unique variations within human genomes that are inherited and passed down through generations. The following bullet point list highlights some commonly used genetic markers:\n- Short Tandem Repeats (STRs): STRs are regions within DNA sequences that contain repeated nucleotide units. The number of repeats varies among individuals, making them highly informative for identification purposes.\n- Single Nucleotide Polymorphisms (SNPs): SNPs are single base pair differences within DNA sequences that occur throughout the genome. They can be useful for determining ancestry or identifying specific traits.\n- Mitochondrial DNA (mtDNA): Unlike nuclear DNA, which is inherited from both parents, mtDNA is solely maternally inherited. It is often utilized when analyzing degraded or mixed samples as it exists in high copy numbers per cell.\n- Y-Chromosomal Markers: Y-chromosomal markers are specifically useful for male lineage tracing since they are present exclusively on the Y chromosome.\nThese diverse genetic markers allow forensic scientists to build a comprehensive profile based on characteristics unique to each individual.\nBy accurately comparing an individual’s genetic profile with those obtained from crime scenes, genetic markers are instrumental in establishing a suspect’s identity. Through the use of DNA databases and advanced analysis techniques, investigators can match samples to potential suspects or generate leads for further investigation. This section will delve deeper into how genetic markers aid in linking individuals to specific crimes and provide insights into the subsequent steps involved.\nIn the upcoming section, we will explore the significance of genetic markers in connecting suspects to criminal activities without relying solely on DNA evidence. By examining various aspects such as familial relationships, geographical patterns, and phenotypic traits, these markers offer valuable information that assists law enforcement agencies in their pursuit of justice.\nRole of Genetic Markers in Establishing Suspect’s Identity\nGenetic markers play a crucial role in criminal investigations, aiding forensic scientists in establishing the identity of suspects and linking them to crime scenes. These markers are unique regions within an individual’s DNA that can be used to differentiate between individuals. In this section, we will explore some common types of genetic markers utilized in forensic DNA analysis.\nOne example of a genetic marker frequently employed in criminal investigations is short tandem repeats (STRs). STRs consist of repetitive sequences of nucleotides, typically composed of two to six base pairs. By analyzing the number of repeats at specific STR loci, forensic experts can create a DNA profile unique to each individual. For instance, consider a hypothetical case where investigators find bloodstains at a crime scene matching those found on a suspect’s clothing. Through STR analysis, they identify multiple alleles at different STR loci within the blood samples from both the crime scene and the suspect, providing strong evidence for their involvement.\nTo further grasp the significance of genetic markers in criminal investigations, let us examine their role through an emotional perspective:\n- Genetic markers offer solace to victims’ families by providing irrefutable evidence linking perpetrators to crimes.\n- They bring closure and justice by helping law enforcement agencies solve cold cases that have remained unsolved for years.\n- The use of genetic markers helps exonerate innocent individuals who may have been wrongly convicted based on other forms of evidence lacking specificity.\n- Ultimately, genetic markers serve as powerful tools against criminals and contribute to making communities safer.\nThe importance and effectiveness of genetic markers become evident when considering real-life cases where these techniques were pivotal in solving crimes or identifying culprits. To illustrate this point:\n|Case Study||Crime Type||Outcome|\n|Case A||Homicide||Perpetrator identified using mitochondrial DNA sequencing despite no eyewitnesses or fingerprints present.|\n|Case B||Sexual assault||DNA analysis of semen samples matched to a suspect, leading to conviction and closure for the victim after years of trauma.|\n|Case C||Burglary||STR analysis on blood left at the crime scene linked multiple burglaries together, ultimately identifying and apprehending the serial burglar responsible.|\n|Case D||Missing person||Genetic markers were crucial in positively identifying skeletal remains found years later, allowing grieving families to find closure and provide a proper burial.|\nBy utilizing various genetic markers such as STRs and mitochondrial DNA sequencing, forensic investigators can establish links between suspects and crimes with remarkable accuracy. However, it is essential to acknowledge that certain limitations and challenges exist when working with these markers. In the subsequent section, we will delve into these aspects further, exploring how they affect criminal investigations using genetic markers.\nLimitations and Challenges of Genetic Markers in Criminal Investigations\nGenetic markers play a crucial role in establishing the identity of suspects in criminal investigations. By analyzing an individual’s DNA, investigators can compare genetic profiles found at crime scenes with those of potential suspects to determine if there is a match. This section will explore how genetic markers are used to identify suspects and discuss their significance in criminal investigations.\nOne notable case that highlights the importance of genetic markers is the Golden State Killer investigation. In this case, authorities utilized DNA evidence collected from multiple crime scenes over several decades to track down the perpetrator. By comparing the suspect’s DNA profile with publicly available genealogy databases, they were able to identify a distant relative whose DNA closely matched that found at the crime scenes. Through further investigative work, they eventually narrowed down their search to Joseph James DeAngelo, who was subsequently arrested and convicted for his crimes.\nThe use of genetic markers in identifying suspects offers several advantages in criminal investigations:\n- Accuracy: Genetic analysis provides highly accurate results, making it less prone to human error or subjective interpretation.\n- Speed: Advances in technology have significantly reduced processing time, allowing for quicker identification of potential suspects.\n- Objectivity: The use of genetic markers eliminates bias and relies solely on scientific evidence rather than personal opinions or assumptions.\n- Cold Cases: Genetic profiling has also proven instrumental in solving cold cases where traditional investigative techniques had reached dead ends.\n|Advantages of Using Genetic Markers|\n|Solving cold cases|\nIn summary, genetic markers serve as invaluable tools in establishing the identity of suspects during criminal investigations. The ability to analyze DNA samples and compare them with existing databases allows investigators to make precise identifications quickly and accurately. However, despite these significant benefits, there are ethical considerations surrounding their usage that need careful consideration.\nTransition into subsequent section: The successful utilization of genetic markers in criminal investigations raises important ethical considerations surrounding their use.\nEthical Considerations Surrounding the Use of Genetic Markers\nSection Title: Limitations and Challenges of Genetic Markers in Criminal Investigations\nTransition from the previous section H2:\nDespite its potential, the use of genetic markers in criminal investigations faces several limitations and challenges. These factors must be carefully considered to ensure accurate interpretation and ethical implementation of DNA analysis.\nExample Case Study:\nOne notable case that exemplifies these challenges is the investigation into a series of unsolved murders occurring over a span of several years. The investigators collected DNA samples from crime scenes but were unable to identify any suspects through traditional methods. However, with advancements in genetic marker analysis, they decided to employ familial searching as an alternative approach.\nFamilial searching involves comparing a crime scene sample against a database not only for direct matches but also for partial matches indicating possible relatives. In this case study, the investigators identified a partial match between the crime scene sample and an individual already present in the database. This led them to apprehend the perpetrator’s brother, who was later found guilty based on additional evidence. Although familial searching can provide valuable leads, it raises significant ethical concerns regarding privacy rights and informed consent.\nTo further explore the limitations and challenges faced by genetic markers in criminal investigations, consider the following points:\n- False Positives: As with any scientific technique, there is always a possibility of false positives or erroneous results due to laboratory errors or contamination during sample collection.\n- Genetic Variability: Human populations exhibit vast genetic diversity, which poses difficulties when trying to establish unique genetic profiles for identification purposes.\n- Sample Quality: DNA degradation or low-quality samples obtained from crime scenes may hamper analysis accuracy and limit successful identification.\n- Interpretation Complexity: The interpretation of complex mixtures containing multiple contributors can be challenging and prone to subjective bias.\n|False Positives||Genetic Variability||Sample Quality||Interpretation Complexity|\n|Can lead to wrongful accusations||Varying genetic profiles complicate identification||Low-quality samples hinder analysis accuracy||Subjective interpretation can introduce bias|\nIn conclusion, the use of genetic markers in criminal investigations is not without limitations and challenges. False positives, genetic variability, sample quality issues, and interpretation complexity all contribute to potential hurdles that must be addressed. Overcoming these challenges requires a balance between scientific advancements and ethical considerations.\nTransition into the subsequent section about “Future Implications and Advancements in Genetic Marker Analysis”:\nLooking toward future implications and advancements in genetic marker analysis, researchers are continuously striving to overcome these limitations for more accurate and reliable results.\nFuture Implications and Advancements in Genetic Marker Analysis\nIn the previous section, we explored the ethical considerations surrounding the use of genetic markers in criminal investigations. Now, let us delve into the future implications and advancements in genetic marker analysis that have the potential to revolutionize forensic science.\nTo highlight one specific example, consider a hypothetical case study where DNA evidence collected from a crime scene matches with an individual who has never been previously convicted or implicated in any criminal activities. This scenario raises questions about how this newfound information should be used ethically and legally, as it could potentially impact not only the suspect but also their family members.\nThe utilization of genetic markers in criminal investigations can stir various emotions among individuals involved. To better understand these emotional responses, here are some key points to ponder:\n- Privacy Concerns: The use of DNA testing for investigative purposes may raise apprehensions regarding privacy infringement and potential misuse of personal genomic data.\n- Stigma and Prejudice: Accurate identification through genetic markers might expose individuals to societal stigma or discrimination based on their genetic predispositions.\n- Justice vs. Privacy Balance: Striking a balance between obtaining crucial evidence for solving crimes and respecting an individual’s right to privacy becomes increasingly complex when considering familial DNA searching methods.\n- Psychological Toll: Being subjected to intense scrutiny due to one’s genetic profile can lead to emotional distress and psychological burden on both suspects and innocent family members.\nIt is important for policymakers, legal experts, and scientists alike to recognize and address these emotional dimensions when navigating the implementation of genetic marker analysis techniques within criminal investigations.\nAdvancements and Future Implications\nAs technology continues to advance rapidly, so does our ability to analyze genetic markers accurately. Here is a table outlining some notable advancements and their potential future implications:\n|Advancement||Potential Future Implication|\n|Rapid DNA Analysis||Faster identification of suspects and quicker resolution of criminal cases|\n|Forensic Phenotyping||Enhanced ability to predict physical characteristics, aiding in suspect identification|\n|Genetic Genealogy||Improved methods for identifying previously unknown perpetrators through familial DNA searching|\n|Next-generation Sequencing Technologies||Comprehensive analysis of complex genetic information, potentially unveiling more detailed profiles for investigative purposes|\nThese advancements have the potential to significantly impact the field of forensic science by improving efficiency and accuracy in solving crimes. However, ethical considerations must always be at the forefront when implementing these technologies.\nAs we move forward with genetic marker analysis in criminal investigations, it is crucial that we continually assess the balance between justice, privacy rights, and societal implications. By doing so, we can ensure that these powerful tools are utilized responsibly and ethically to enhance our understanding of crime scenes without compromising individual rights or perpetuating bias within the criminal justice system.\nOverall, this section has provided insights into both emotional responses evoked by genetic marker analysis and future implications of advancements in this field. It is imperative to proceed with caution while leveraging these techniques as they hold immense promise but require careful consideration to mitigate any unintended consequences."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:c7e8c994-9c59-414f-af3a-ecda7c501d45>","<urn:uuid:b4a0f3df-9282-4d46-88c9-07368a555f3b>"],"error":null}
{"question":"Can you explain what was the eco-hackathon project about at RCA and what kind of solutions students proposed for Fast Fashion?","answer":"The eco-hackathon was a two-day intensive project organized by Innovation Design Engineering graduate Jacob Jelen in collaboration with Solve.Earth, focused on generating innovative business ideas to reduce over-consumption and waste in the fashion industry. Students from various programs like Service Design, Innovation Design Engineering, Global Innovation Design, Textiles, Moving Image and Painting participated. At the end, students pitched ideas that addressed different aspects of manufacturing and retail, including solutions for reusing waste material and off-cuts, as well as encouraging consumers to wear clothes longer and to recycle, share or swap garments.","context":["Collaboration, Sustainability, Co-Design and Sensory Engagement at AcrossRCA 2018\nAcrossRCA is an annual programme of cross-disciplinary, collaborative projects and workshops that is specifically designed to enable students to gain perspectives on their practice from outside their own disciplines, make connections and find future collaborators. The programme helps foster innovation and creates a lasting impression for many students, shaping their time at the College and their careers beyond.\nThis year AcrossRCA featured 37 projects, as well as several shorter drop-in sessions, offering an extensive range of opportunities for participation. Sustainability and circular economies were the focus for several projects that considered how design can disrupt and innovate for change, while having real world impact. Many of the projects are led by current students and recent alumni, creating a peer-led environment.\nInnovation Design Engineering (IDE) graduate Jacob Jelen, organised a two-day intensive eco-hackathon in collaboration with Solve.Earth, to innovate ideas for sustainable businesses addressing the environmental impacts of ‘Fast Fashion’. The hackathon focused on generating innovative business ideas that could reduce over-consumption and waste in the fashion industry.\nStudents came together from diverse Programmes including Service Design, Innovation Design Engineering, Global Innovation Design, Textiles, Moving Image and Painting, but also brought expertise from varied backgrounds prior to coming to the RCA such as bio-tech, data science, architecture and materials science. With the expertise of Solve.Earth’s founder Dr Gareth J Thompson, participating students explored the potential that start-up companies have to innovate rapidly and cause dynamic change, disrupting markets and creating global impact.\nAt the end of the hackathon, students pitched to a panel of judges. Their ideas addressed many aspects of the manufacturing and retail process, from reusing waste material such as off-cuts to encouraging consumers to wear clothes for longer and to recycle, share or swap garments.\nAlso considering sustainability, Design Products students Kenneth Arnold and Joseph Rouse, along with Textiles student Céline Ducret led a design challenge using the principles of circular economies for the Royal National Lifeboat Institution (RNLI). With input from the RNLI’s sustainability officer Anna Frizzell, students developed prototypes for the reuse of a decommissioned life boat. They came up with inventive applications from a bongo, marine-themed children’s toys and collection of jewellery celebrating the textures and surfaces of the sea-worn material.\nAs well as introducing students to each other, AcrossRCA also provides an opportunity for students to make excursions and create work in response to different environments and communities outside of the College, opening up new avenues for enquiry and modes of making. Recipes for Stockwell was a design challenge, run by the Helen Hamlyn Centre for Design (HHCD), that offered students the chance to work with a live research project – Our Stockwell – which is tackling childhood obesity through inclusive design.\n‘We were keen to give students the opportunity to work on a live research project,’ explained Gail Ramster, HHCD Senior Research Associate. ‘Our research associate Carmel Keren is mid-way through this one-year programme of work, developing ideas with the local community in Stockwell that would help them to live more active, healthier lives.’\nFor the AcrossRCA project, students were given the opportunity to work on briefs that have emerged from Carmel’s community engagement. They developed and rapidly prototyped concepts to see how people reacted and if they were taking ideas in the right direction. ‘It offered a little taster for the students of designing with communities and of our process at the HHCD, where people are always at the centre of our design research. And it was really useful for us too, to receive all the energy and creativity that multidisciplinary teams of students can offer, even within one short week,’ Gail commented.\nArchitecture alumni and current Designer in Residence at the Design Museum, Hester Buck, led a week-long workshop – Activism and Outrage: A celebration of post-war social housing. Students responded to the Savills report, which proposes a ‘Complete Streets’ model for redeveloping post-war housing estates in London.\nThe workshop took place within the Designers in Residence studio at the Design Museum as well as through walks around local housing estates, where they met groups who have collectively claimed the common ground of their ‘incomplete street’. The outcomes of the project will be exhibited at the Design Museum and form part of a small publication, as part of the 2018 Designers in Residence final exhibition in December.\nOpportunities for students to explore projects further afield were offered by Maritime Traces: Expedition – a field trip to Great Yarmouth and the Norfolk coast run by Visual Communication graduates Emma Harry and Laura Copsey, and Me Here to You There – led by Information Experience Design (IED) student Daisy Buckle, which explored ways to communicate the experience of walking and sensing the environment in Hyde Park and Ashbridge Estate, a National Trust woodland in the Chiltern Hills.\nAnother thread running through AcrossRCA activities this year was a focus on the role that our senses and bodies play in design and communication. Ordinary Pleasures was a workshop exploring how bodily knowledge can be accessed through theory, practice and tacit learning. The workshop was led by Visual Communication graduate Barbara Mueller with support from IED research student Claire van Rhyn. It involved visits to Stuart Carey’s ceramics studio and Wangxia Ni’s Dim Sum kitchen in order to explore new experiences and gain new hands-on knowledge.\nParticipants then recollected and rebuilt objects based on bodily remembrances, which were curated in an immersive exhibition open to the public. The varied outcomes included: a performance in which Solanne Bernard (MA Sculpture) applied honey to visitors' lips to draw attention to the act of slowly eating a raspberry; Camilla Bliss (MA Sculpture) filled a lycra tube with flour to let visitors experience weight by putting this work around their bodies; and Kevin Chiam (IDE) invited visitors to apply malleable patterns to generic vessels.\nThe workshop SenseAbility explored the future of immersive storytelling through the creation of multisensory accessory design. It was led by IDE Visiting Lecturer Wan-Ting Tseng, IDE alumnus Jack O’Leary McNeice with additional expert input from perfumer Sarah McCartney, scent engineer Harry Sherwood and future storyteller Anna Nolda Nagele. The works created through the workshop were exhibited at the end of the week and engaged all of the senses, with a focus on touch and smell.\nFind out more about RCA Programmes and how to apply."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:3c7788c7-9165-4804-809f-6959ec7ffe41>"],"error":null}
{"question":"How do pressure relief valve operations compare between standard RV water heaters and Atwood models?","answer":"Standard RV water heaters have pressure relief valves that open and release pressure when water temperature reaches 210 degrees Fahrenheit, and will drip when pressure exceeds 50 psi, automatically closing when pressure falls below this threshold. For Atwood models, valve dripping is described as normal expansion in a closed water system, with tanks featuring an internal air gap to reduce dripping. When this air is absorbed over time, Atwood recommends restoring it by turning off the heater and water supply, opening the nearest hot water faucet, and pulling the relief valve handle to allow water flow until it stops.","context":["An RV hot water heater would likely not exist if it weren't for the American pioneers, who could be attributed to building the forerunner of the modern RV.\nTheir 18th-century covered wagons were used as transportation, living quarters and storage facility for their provisions. The lowly covered wagon is a far cry from today's RVs that are big enough to include many more amenities, including bathrooms fitted with RV water heaters.\nThere is now a large and growing percentage of people who permanently live in an RV. Some love to experience camping out, while others travel for a break. Many travelers want their RVs fitted with appliances, but space is always an obstacle. Fortunately, RV water heaters have evolved to help make life for the motorhome enthusiast a breeze.\nThere are various models, tankless and those with tanks. RV tankless water heaters are perfect for motorhomes since you save not only energy but space and money as well. You will never run out of hot water as long as there is a supply with an RV on demand water heater.\nRV Water Heater Replacement Video Demonstration Tips\nMost heaters installed on recreational vehicles use propane gas for heating the water. A heater with a tank usually has 6 to 10 gallons capacity. It is also possible for the heater to run on gas and/or 120 volt AC. An RV hot water heater usually has a gas pilot light that needs to be lit every time you set up camp. It is possible to have an RV electric water heater that is set on with automatic direct spark ignition system controlled by an electric switch accessible from inside the recreational vehicle.\nFor heaters with a tank, an RV water heater bypass valve kit may be installed. This option allows for winterization of the unit which saves on the use of anti-freeze solution. It also facilitates easy drainage and cleaning of the hot water tank. Note that the by-pass kit works best if installed in proximity to the cold water inlet where it blocks a possible back flow from the heater.\nRV hot water heaters have pressure relief valves designed to open and release pressure when the water temperature hits 210 degree Fahrenheit. A relief valve will open for water to drip from when the supply is more than 50 psi (pounds per square inch). Once the pressure falls below 50 psi, the valve closes automatically. Do not be alarmed when the relief valve drips as this is normal and is not indicative of a faulty valve.\nShower gas model for camping\nThere are numerous brands and models of RV water heaters in the market either with tank or tankless. Some models are powered by electricity while some are powered by propane and gas. RV tankless water heaters are preferred by most RV-ers as hot water is supplied on demand basis thereby saving on fuel or electric consumption. Here are some name brands and models for RV hot water heaters.\nAriston has a 2.5, 4 and 6 gallon compact electric point-of-use water heater. The unit can be fitted under a sink or close to where you want it like in the RV's toilet and bath. The long wait for heated water is eliminated as hot water is available in an instant while the hot water from the main water supply source is en route. This unit can easily supply hot water from 1 to 3 faucets. Price starts at $160.\nThe RV 500 is the first on demand RV tankless hot water heater. This unit was specifically designed for recreational vehicles and other motor homes. It is a propane RV water heater and has a 20-pound tank of propane can heat up to 940 gallons (3,760 liters) of hot water for the one showerhead. The flow is steady at 1.5 gallons per minute and the heater can easily provide warm shower with incoming water as low as 40 degrees Fahrenheit. The unit is cost effective and highly efficient, but costs around $999.\nThe Eccotemp Portable water heater is a tankless and propane-powered heater. Once the water flows, the burner is turned on. This RV hot water heater can provide an endless supply of hot water on demand. You can hang it on the RV's shower head or on a tree and hot water shower is instantly provided. The unit includes a gas regulator and hose, shower hose with an on/off nozzle, mount for the shower head, a garden hose adapter and a vent shield, all for around $135.\nIn case of heater breakdown there is no need to worry as RV water heater parts like pilot assemblies, pilot lights, circuit boards, thermocouples, thermostats and more are available online.\nRelated RV Articles:\nRV Water Tank Storage\nHow to Sanitize Hot RV Fresh Water Tanks\nFor off the grid living, you need three types of RV water tanks - fresh water for cooking/drinking, gray water for bathroom/cleaning and RV black water tank for waste from toilet.\nRV Water Filter\nInformation on the Best RV Water Purification System\nFrom RV water filter cartridges, canisters to installing in-line or whole RV RO systems; living off the grid has become cheap...\nRV Water Softeners\nPurification and Softening the Hard Tap Water\nFor RV vehicles, portable softeners can be installed as in-line or whole-filtration systems. With RV water softener systems you can choose to purify cleaning or just drinking...\nFor more information go from RV Hot Water Heater to Reviews\nReturn from RV Tankless Water Heater to Homepage","Atwood RV Water Heaters\nAtwood RV Water Heater Maintenance Tips!\nThese are proven methods for maintaining an Atwood RV Water Heater. Even though it is Atwood specific the principles hold true for Suburban RV Water Heaters as well. Atwood/Dometic provides the proper methods to maintain their water heaters and they should be followed for many good reasons. Listen to my Pod Cast and hear what you need to know.\nUnpleasant Odors: A “rotten egg odor” (hydrogen sulfide) may be produced when the electro galvanic action of the cladding material releases hydrogen from the water. If sulfur is present in the water supply the two will combine and produce an unpleasant smell.\n- Turn off main water supply. Drain the water heater tank and reinstall drain plug. Remove the pressure-temperature relief valve. Mix solution of four (4) parts white vinegar to two (2) parts water. (For a 10 gallon tank, use six (6) gallons vinegar to four (4) gallons water). With a funnel, carefully pour solution into tank.\n- Cycle water heater with the above solution, letting it run under normal operation 4-5 times.\n- Remove the drain plug and thoroughly drain all water from the tank. Flush the water heater to remove any sediment. You may flush the tank with air pressure or fresh water. Pressure may be applied through either the inlet or outlet valves on the rear of the tank or through the pressure/temperature relief valve coupling located on the front of the unit. To flush tank with air pressure: Insert your air pressure through the pressure-temperature relief valve coupling. With the drain valve open, the air pressure will force the remaining water out of the unit. To flush tank with water pressure: Fresh water should be pumped into the tank with either the onboard pump or external water pressure. Continue this flushing process for approximately five minutes, allowing the fresh water to agitate the stagnant water on the bottom of the tank and forcing the deposits through the drain opening.\n- Replace drain plug and pressure-temperature relief valve.\n- Refill tank with fresh water that contains no sulphur.\nThe Atwood water heater is designed for use in a Recreation Vehicle. If you use your vehicle frequently or for long periods of time, flushing the water heater several times a year will prolong the life of the storage tank.\nDripping Pressure Temperature Relief Valve: Weeping or dripping of a pressure-temperature relief valve while the water heater is running DOES NOT mean it is defective. This is normal expansion of water as it is heated in the closed water system of a recreation vehicle. The Atwood water heater tank is designed with an internal air gap at the tank to reduce the possibility of weeping and dripping. In time, the expanding water will absorb this air. To replace the air follow these steps: To restore the air:\n- Turn off water heater.\n- Turn off incoming water supply.\n- Open the closest hot water faucet in the coach.\n- Pull handle of pressure-temperature relief valve straight out and allow water to flow until it stops.\n- Allow pressure-temperature relief valve to snap shut, close the faucet then turn on the water supply.\nFlushing & Winterizing Water Heater Tank: To insure the best performance of your water heater and add to the life of the tank, periodically* drain and flush the water heater tank. Before long term storage or freezing weather drain and flush the tank.\n1. Turn off main water supply (the pump or water hook up source).\n2. Drain Water Heater Tank by removing the drain plug. If the water flows sporadically or trickles instead of a steady stream of water, we recommend the following action; first open the Pressure Temperature Relief Valve to allow air into the tank and secondly, take a small gauge wire or coat hanger and poke through the drain opening to eliminate any obstructions.\n3. After draining the tank, because of the placement of the Drain Plug, approximately two quarts of water will remain in the tank. This water contains most of the harmful corrosive particles. To remove these harmful corrosive particles flush the tank with either air or water. Whether using air or water pres- sure, it may be applied through the inlet or outlet on the rear of the tank or the Pressure Temperature Relief Valve. (If using the Pressure Temperature Relief Valve the Support Flange must be removed). The pressure will force out the remaining water and the corrosive particles. If you use water pressure, pump fresh water into the tank with the assistance of the on-board pump or use external water for 90 seconds to allow the fresh water to agitate the stagnant water on the bottom of the tank and force deposits through the drain opening. Continue adding water and draining until the particles have been cleared from the water remaining in the tank.\n4. Leave the Drain Plug out and close the Pressure Temperature Relieve Valve. The approximately two quarts of water remaining in the tank after draining will not cause damage to the tank should freezing occur.\nRV Water Heater Tank Flusher: An easy way to flush any RV Water Heater tank is this inexpensive flushing tool that hooks up to any fresh water hose and works effectively and quickly to flush out the tank. Flushing any RV Water Heater is messy and can waste a lot water, this flusher reduces the waste and mess and saves time. Simple to use and simple to store.\nGeneral Water Heater Information: Altering Atwood Water Heaters If the water heater has been altered the warranty will be void. Use of Aftermarket Heating Element Devices (Hot Rods) can lead to an out of control heating of water in the tank and a catastrophic wet side explosion. These devices lack critical safety controls. Personal damage and product damage may result. Aftermarket heating element devices are not necessary with an Atwood Water Heater and will void the warranty. Atwood water heater tanks are constructed of a high strength aluminum. The interior of the tank consists of a .0015 thickness of type 7072 aluminum (pure aluminum and zinc) that is fused to the core during the rolling process. This material protects the tanks from the effects of heavy metals and salts found in waters throughout the country. It is anodic to these heavy metals and acts much like an anode in a steel glass lined tank except it will last much longer. Aftermarket Anode Rods are not required and should not be used and will void warranty.\n• The Atwood Water Heater is designed for recreation vehicles.\n• To function properly, the water system and water heater must be turned on.\n• Periodically* check gas pressure; it should read a minimum of 11 inches of water column (with at least 50% of BTU demand on system).\n• The use of Manufacturers’ Aftermarket Heating Element devices (Hot Rods, etc.) may result in damage to components or water heater and will void the warranty.\n• Periodically* drain and flush water heater.\n• Before storing RV, always drain and flush the water heater.\n• An undrained water heater tank will crack in freezing conditions.\n* Periodically: At least once each camping season, more often if you camp frequently.\nAnode Rods: Atwood/Dometic does not recommend the use of an Anode Rod in their Water Heaters. The tanks are designed to resist corrosion and by using one during the warranty period will void the warranty. After the water heater is out of warranty you can use one if you choose to. The anode rod for the Atwood has not been around for a real long time, relatively speaking. I have not heard anything bad about using one and I have also heard that some RV'ers swear by them and will not go without. I would use one if I had an RV with an Atwood Water Heater in it. I own a Suburban Water Heater myself. The Anode Rod gets installed in place of the drain plug, they both have the same thread and use a 7/8\" socket. 10 Gallon Atwood Water Heaters require a longer Anode Rod (10\"). 6 Gallon require a 4.5\" Anode Rod.\n7/8\" Socket to remove Drain Plug w/ 1/2\" male pipe thread - Atwood Drain Plug Part #91857\nT & P Tool to remove the Pressure Relief Valve - Part #10552\nPressure Relief Valve (1/2\" Thread) for most Atwood Water Heaters - Part #10423\nPressure Relief Valve (3/4\" Thread) for Atwood XT water Heaters- Part #10473\nTank Flusher used to Flush Water Tank Almost Painlessly - Part #A10-4010VP\n7/8\" Socket to remove drain plug to install an Anode Rod. Sold @ Your Local Tool Store.\nFor questions, please contact Us @ 1-800-789-5588 Listen now Radio Arizona RV!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:83d8d202-cbd1-412b-9da6-c42d993dced4>","<urn:uuid:d12d9602-d257-46a9-905b-c7dd769f8c64>"],"error":null}
{"question":"How does object storage differ from file storage in cloud architectures, particularly regarding performance and flexibility?","answer":"Object storage allows storage of anything of any size with flexible access methods and sharing capabilities, but has higher latency and slower access times and requires strong governance. In contrast, file storage provides a highly scalable, durable structure of files that can grow on demand and is easily shared, but also has slower access times and higher latency and requires a high-bandwidth network.","context":["As we talk to executives about the cloud, we often encounter a common misconception: that cloud means a computing platform. That is not surprising because the computing part that carries the application is what everyone sees as the role in the cloud that is “doing” something.\nHowever, there’s another component of the cloud that’s equally, if not more, important: storage. This is the cloud layer that holds and controls all the data that applications create and consume.\nCloud storage is critical because modern cloud architecture patterns require applications to store data in a separate persistent service rather than locally within the application. In other words, good cloud practices encourage the creation of a “stateless” architecture that prevents data from being lost or compromised in case that any part of an application or computing layer fails.\nMaking cloud computing decisions is easy—cloud provides relatively few possible computing options. But the cloud storage domain is much more complex; several storage and persistency choices exist. Moreover, they all have very different structure, function and usage.\nDetermining which is “the best” cloud storage option for your business\nThe fact is, selecting storage is not something you can do on a whim. It requires an independent strategic approach to cloud storage that considers trade-offs across (at least) five dimensions:\nStorage cost per storage unit\nStorage and retrieval performance\nStorage availability and durability\nAdaptability of storage structure and access\nHow you manage those trade-offs depends on:\nWhat kind of data is in question (e.g., short-living web sessions, transactional data, or long-term archival) and how you will use it.\nIf you require super-fast performance\nIf you need a high volume of consistent streaming\nIf you’re looking to store data for a long time with little to no access to it needed\nFor example, let’s say you have a typical text document. If it’s something you use regularly, you’ll want to store it in a document management place like OneDrive or DropBox, which gives you immediate access to the document. On the other hand, if it’s a contract that few will ever read again but needs a place for long-term safe-keeping, a slow, limited-access archival service is best. Moreover, the difference in price points between these two options is significant.\nSo which type of cloud storage is best?\nLet’s look at the eight main options and their pros and cons:\n|Disk||Fast access to data and exclusive usage by each compute instance||Limited growth without interruption after initial provisioning|\n|Caching||Can be shared among multiple compute instances and provides rapid access to data||Requires application development knowledge to use effectively|\n|File||Provides a highly scalable, durable structure of files, can grow on demand, is easily shared||Slower access time and higher latency; requires high-bandwidth network|\n|Object||Allows storage of anything of any size, access in virtually any way, and sharing||Higher latency and slower access time; requires strong governance|\n|Archiving||Costs a fraction of what other storage types do||Slow storage and retrieval process; requires advanced notice for retrieval|\n|Relational||Allows for easy entry, storage, query, and analysis of data—and supports complex joins||Vertical scaling requires planned downtime when expanding the database|\n|Non-relational||Highly flexible, may scale horizontally on the fly, and easily supports dynamic data||Requires different approach to data management architecture and lacks complex data structures|\n|Data warehouse||Can scale very quickly without the downtime issues with a relational database||Isn’t as fast as relational database engines; can’t handle very complex structured data queries|\nThe bottom line\nWhen you create a cloud solution, you need to sort through many cloud storage and persistency services to determine which one is right for you. Selection requires more planning and consideration than most organizations initially anticipate, and certainly more than what’s necessary to make a correct cloud computing choice. When it comes to cloud storage, think carefully about your requirements. The success and longevity of your cloud solutions might depend on it."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:6058e487-54a0-4bd1-885c-14997c60cc6b>"],"error":null}
{"question":"What are the main differences in how Neon Tetras and Cherry Shrimp handle their eggs and care for their young? Specifically, how do their reproductive strategies compare in terms of egg placement, protection, and parental care?","answer":"Neon Tetras and Cherry Shrimp have vastly different approaches to egg care and offspring protection. Neon Tetras scatter their eggs, which are the size of sand and not sticky, among plants or spawning mops. The parents show no parental care and will actually eat their own eggs, requiring immediate removal after spawning. The eggs are extremely light-sensitive and must be kept in darkness until they hatch in 24-36 hours. In contrast, Cherry Shrimp females carry their eggs under their abdomen for 2-3 weeks, actively protecting and oxygenating them by fanning them with their swimmerets. Female shrimp maintain care of their eggs until they hatch, and the eggs gradually change color from clear to dark brown or black as they mature. Cherry shrimp do not eat their eggs, allowing the mother to continue caring for them throughout development.","context":["Neon Tetra (Paracheirodon innesi)\nFrom The Aquarium Wiki\n56,781.177 mL 56.8 Litres (15 US G.)\n1.181 in 2-3 cm (0.8-1.2\")\n4.6 - 7.6\n531.27 °R 299.15 K\n538.47 °R22 -26 °C (71.6-78.8°F)\nThis animal is available captive bred\n- Neon, Neon Tetra\nAdditional scientific names\n- Hyphessobrycon innesi\n- An Amazonian South American Tetra from blackwater or clearwater stream tributaries of the Solimões River.\n- Females tend to have a more \"triangular\" belly, as well as having the blue band bend upwards to some degree. Males have a noticeably flatter belly, compared to the females.\n- Breeding occurs in the morning after a rainfall. Temperature should be 24-26°C (75-78°F). Water should be soft, 0-6 GH. If you cannot put fish into a separate breeding tank with soft water a 50% water change can sometimes simulate rainfall. Prepare mature fish by feeding them a high protein diet for several days. Afterwards, select a breeding pair or small group and transfer them into the breeding tank. The tank should be prepared with a spawning mop or plants like java moss to allow the eggs to fall through and into. The tank should be kept in full darkness for a period (overnight) and then the light levels should be slowly increased (position the tank by an east facing window).\n- Spawning should occur during the morning. The eggs are the size of sand and not sticky. The adult neon tetras will eat the eggs, so remove them after spawning. Cover the tank again to maintain darkness. The eggs and young fry are very light sensitive. After 24-36 hours the eggs should hatch and fry should be swimming in another 4 days. They should be fed infusoria, newly hatched brine shrimp, or fry food. They prefer soft water and are sensitive to water changes, so begin with very small (5-10%) water changes often and maintain a gently flowing sponge filter in their tank. Once they are large enough to eat micro pellets they can be acclimated to a general tank.\n- Gets along fine in a community tank. Prefers to be a middle to bottom swimmer. Should not be kept with larger predatory fish such as Angelfish as the Neons may get eaten. Keep them in schools of 6 or more of their own kind, in smaller numbers they will be shy and nervous fish.\n- The Neon Tetra is an unfussy eater accepting most foods. In an aquarium use flake and granular foods along with micro pellet, supplemented with small live and frozen foods such as artemia and daphnia. Some bite snails' tentacles (maybe mistaken for worms).\n- Feed once or twice a day. Due to a natural fear of predators, this fish may be resistant to eating food from the water's surface. To overcome this hold your fish food underwater for a moment and release the food. As with all fish, you should only feed the fish what they can eat in 5 minutes.\n- While Neons like a pH under 7, they can adjust to a more alkaline pH, but will be unlikely to breed. Most Neons are mass bred and are well adjusted to a higher pH. They do not like a varying pH or a high GH value, so ensure an adequate KH level. They live in stagnant pools in the wild and so do not like much current inside the tank because they are not physiologically adapted to cope with it. Some current is necessary because of internal filter currents but try to keep this to a minimum.\n- Peaceful and a good community fish. Will school in groups of 6 or more. Although they school with their own species if there are enough of them, they will also school with Cardinal Tetras (Paracheirodon axelrodi) and Green Neon Tetras (Paracheirodon simulans), or any of the other small, torpedo-bodied characins, if there are not enough Neon Tetras. If they are kept in groups of under four then they may stop swimming and go pale and die after a couple of days. Other fish use this fish as a spotter fish; that is, if there is a predator about these fish will spot it first. Therefore, other more timid fish, such as Rams, will come out into the open more if you put these fish in your tank. Useful to the aquarist as an indicator fish. If they are closely packed together, then they are alarmed and feel threatened. Usually if they are settled, they will disperse over your tank.\n- Like a Cardinal Tetra, the Neon has a brilliant blue upper body and a red underside. However, unlike the Cardinal, the Neon's red underside ends halfway to the head, becoming a white belly. They are very distinctive and commonly available.\n- There are other selectively bred varieties available, including a Gold variety with a pale creamy gold body and faint lateral blue line, and one called \"Diamond Head\" which has far more iridescent blue on its head than the regular variety.\n- Neon Tetras are known to suffer from a species-specific parasite, aptly named Neon Tetra Disease. This disease is also called Pleistophora. It is highly contagious and any fish thought to be suffering from it should be removed. It can be, but is rarely, passed on to other species. The main cause of the disease occurring in neon tetras is when a parasite found in a dead, rotting organism is eaten by the neon. Symptoms of the disease include:\n- Loss of normal colouration\n- Curved spine\n- Strange swimming patterns\n- Unfortunately, NTD cannot be cured, however, you should remove the infected fish from the tank as soon as possible so you can prevent infection of your other fish. This disease is caused by a protozoan parasite, the sporozoan, Pleistophora hyphessobryconis.\n|In a petstore holding tank:||In a planted tank:|\n- Fishbase (Mirrors: )","Cherry shrimp with eggs is a sight to behold! These tiny creatures are fascinating to watch, and it’s even more rewarding to help them hatch and grow into healthy adults. If you’re thinking about breeding cherry shrimp, here are seven quick steps to help you get started:\nIf you’re a passionate aquarium enthusiast, you’ve probably seen the adorable and vibrant cherry shrimp.\nThese small, fascinating creatures are not only a delight to observe in your aquarium but also offer the opportunity for a rewarding breeding experience.\nOne of the most captivating moments in a cherry shrimp owner’s life is witnessing shrimp eggs hatch into baby shrimp.\nIn this article, we’ll take you through the essential steps to ensure a successful hatching process and guide you toward happy hatchlings. So, let’s dive into the world of cherry shrimp breeding!\nDo Red Cherry Shrimp Give Birth or Lay Eggs?\nYes, cherry shrimp lay eggs. They do not give birth to live young. The female cherry shrimp will carry her eggs under her abdomen for about 2-3 weeks until they hatch.\nThe eggs are initially clear but will turn dark brown or black as they mature. The female will fan the eggs with her swimmerets to keep them oxygenated and clean.\nOnce the eggs hatch, the baby shrimp (called “shrimplets”) will be free-swimming. They are about the size of a grain of rice and are very vulnerable to predators. Providing the shrimplets with plenty of hiding places, such as plants and rocks, is important.\nA female cherry shrimp can lay 20 to 30 eggs at a time. She can breed multiple times throughout the year. The number of eggs shrimp lays will depend on her age, health, and water conditions.\n7 Quick Tips to Successful Cherry Shrimp Breeding\n1. Understanding Cherry Shrimp and Their Reproduction\nLet’s understand the basics before we embark on this exciting journey of nurturing baby shrimp. Cherry shrimp, scientifically known as Neocaridina heteropoda var. red, are a popular freshwater shrimp species that come in various colors, with the red cherry shrimp being particularly popular among enthusiasts.\nCherry shrimp are known for their fascinating reproductive behavior. Female shrimp carry eggs under their tail, known as a “saddle,” these shrimp’s eggs can develop into tiny, adorable hatchlings under the right conditions.\n2. Creating the Optimal Environment\nTo encourage successful breeding, providing the right conditions in your shrimp tank is crucial. Maintaining stable water parameters, including temperature, pH, and hardness, is essential. Aim for a temperature around 72-78 degrees Fahrenheit (22-26°C) and a pH level of 6.5-7.5.\n3. The Mating Process and Fertilization\nWhen the time is right, female cherry shrimp release pheromones to attract males for mating. Once a male shrimp mates with a female, he fertilizes the eggs under her tail. The fertilized eggs turn a darker color, indicating successful fertilization.\n4. Eggs Development and Care\nThe female shrimp will carry the fertilized eggs under her tail for about three to four weeks. It’s important to provide the shrimp with a healthy diet of biofilm, algae, and plankton to ensure the eggs receive proper nutrition.\n5. The Exciting Hatching Process\nAs the eggs develop, you’ll notice subtle changes in their egg color and appearance. The eggs will darken and eventually turn a dark black or brown color. This is a sign that the eggs are close to hatching. Patience is key during this phase, as the hatching process can take a few hours to a day.\n6. Welcoming the Newborn Shrimp\nOnce the eggs hatch, you’ll be greeted with tiny, translucent baby shrimp. These young shrimp are incredibly delicate and require a gentle environment. Maintain stable water parameters and provide hiding spots for the baby shrimp to find safety.\n7. Ensuring Survival and Growth\nVarious factors, including water quality, temperature, and food availability, can influence newborn shrimp’s survival rate. Keep in mind that baby shrimp are quite small and might require specialized shrimp food or crushed flakes to ensure they receive adequate nutrition.\nHow to Tell if Cherry Shrimp is Pregnant?\nIf you have cherry shrimp in your aquarium and suspect one of them may be pregnant, there are a few signs you can look out for. First, check the shrimp’s abdomen. A pregnant cherry shrimp female will have a rounder and larger abdomen than the males.\nAnother sign to look for is the presence of a saddle. A saddle is an orange or yellowish patch on the back of the female shrimp. This saddle is a cluster of green eggs waiting to be fertilized.\nOnce the shrimp eggs are fertilized, they will develop into a darker shade and become visible inside the saddle. Finally, keep an eye out for tiny white dots that appear on the female shrimp’s abdomen. These dots are the eggs, and they will hatch into baby shrimp after a few weeks if suitable conditions are suitable.\nHow Long Do Red Cherry Shrimp Carry Their Eggs?\nCherry shrimp, a popular freshwater aquarium shrimp, are known for their ability to reproduce in captivity. After mating, the female cherry shrimp will carry the eggs underneath her body until they hatch.\nThe time that cherry shrimp carry their eggs can vary, ranging from two to four weeks. During this time, the female shrimp carefully tends to the eggs, ensuring they receive sufficient oxygen and protection from predators.\nIt is fascinating to observe the development of the shrimp eggs as they gradually change color, indicating that the hatching process is nearing. Once the eggs hatch, tiny juvenile shrimp emerge, completing the reproductive cycle.\nCherry shrimp are highly prized for their vibrant red color and peaceful demeanor, making them popular among aquarium enthusiasts.\nHow Often Do Cherry Shrimp Lay Eggs?\nCherry shrimp, or Neocaridina shrimp, are freshwater shrimp commonly kept in aquariums. They are known for their bright red coloration, hence the name “cherry” shrimp. When it comes to reproduction, cherry shrimp lay eggs regularly.\nA mature female red cherry shrimp can lay eggs once every three to four weeks. The survival rate of these eggs greatly depends on the conditions provided in the aquarium. Once the eggs hatch, baby shrimp emerge and begin their journey to adulthood.\nCherry shrimp can breed every 3-5 months if favorable conditions are present. During the breeding cycle, the female shrimp releases hormones into the water, mate with the male shrimp, lay their eggs, and repeat the process. Overall, the reproduction rate of cherry shrimp is relatively high, making them popular among aquarium enthusiasts.\nHow Many Eggs Do Cherry Shrimp Lay?\nCherry shrimp, known as Neocaridina heteropoda var. “red,” are prolific breeders. They are known to lay many eggs, typically around 20 to 30 at a time. The female shrimp carry the eggs until they hatch, which usually occurs after two to three weeks.\nHowever, it’s important to note that not all eggs will hatch successfully. The survival rate of the shrimp larvae depends on various factors such as water parameters, food availability, and overall shrimp health.\nThe survival rate can be relatively high in optimal conditions, resulting in many cherry shrimp offspring. These tiny creatures are fascinating to observe and breed as their breeding habits and ability to reproduce ensure a continuous population in home aquariums.\nDo Cherry Shrimp Care for Babies?\nCherry shrimp, also known as Neocaridina heteropoda, care for their babies. After mating, the female cherry shrimp attaches the eggs to her swimmerets until they hatch.\nThis process usually takes around three to four weeks. Once the eggs hatch, the newborn shrimp are tiny replicas of their parents and are fully capable of fending for themselves.\nHowever, they stay close to their mother for some time, benefiting from her presence and protection. As they grow, the baby shrimp molt several times to accommodate their increasing size.\nTo ensure proper cherry shrimp care, the aquarium shrimp needs to have plenty of hiding spots, plants, and moss for the newborn shrimp to take refuge in.\nAdditionally, it is essential to provide a well-balanced diet for the small shrimp, including specialized shrimp food or algae. With proper care and a suitable environment, cherry shrimp can successfully breed red cherry shrimp and care for their babies in an aquarium.\nPregnant Cherry Shrimp Stages\nCherry shrimp, scientifically known as Neocaridina heteropoda var. red, are a popular freshwater shrimp species in the aquarium hobby. If you’re interested in cherry shrimp breeding, it’s important to understand the various stages involved in the pregnancy of female cherry shrimp. Here’s a breakdown of the key stages:\n- Saddle Formation: Female cherry shrimp exhibit a saddle-shaped structure called a “saddle” on their backs, resulting from eggs developing within their ovaries. This is a visible sign that the female shrimp is preparing for reproduction.\n- Mating: In the next stage, the female shrimp will be receptive to mating. Male shrimp will approach the female and transfer sperm to fertilize the eggs inside her. Successful mating will lead to the fertilization of the eggs.\n- Egg Development: After successful fertilization, the female cherry shrimp will carry the fertilized eggs with her until they hatch. The eggs will be visible beneath her abdomen, appearing as small clusters or berries.\n- Hiding and Protection: The female shrimp will become more protective and cautious as the eggs develop. She may retreat to hiding spots within the aquarium, such as plants, decorations, or crevices, to safeguard the developing eggs from potential predators.\n- Release of Shrimp Eggs: Once the eggs have matured and are ready to hatch, the female shrimp will release them into the water. These tiny shrimp eggs will be suspended in the water column or attached to surfaces using a sticky substance.\n- Hatching: The shrimp eggs will hatch into miniature larvae, which are initially very small and almost transparent. These larvae have yet to develop and have different dietary requirements than adult shrimp.\n- Feeding on Biofilm and Plankton: Newly hatched shrimp larvae will instinctively seek out biofilm and plankton present in the aquarium water as their primary source of nutrition. Biofilm is a slim layer of microorganisms that naturally grows on surfaces within the tank. Providing enough biofilm and plankton is crucial to the survival of the shrimp larvae during this early stage.\n- Growing and Development: Over the following weeks, the shrimp larvae will undergo multiple molts as they grow and develop. They shed their exoskeleton with each molt and emerge slightly larger and more developed.\n- Transition to Miniature Shrimp: As the larvae grow and molt, they will gradually resemble miniature adult cherry shrimp. Their coloration will become more distinct, and they will start displaying behaviors typical of adult shrimp.\nUnderstanding cherry shrimp’s breeding cycle and pregnancy stages is essential for successfully raising healthy generations of these fascinating aquatic creatures. Providing a suitable environment, sufficient food sources, and proper care will contribute to successfully breeding cherry shrimp in your aquarium.\nCaring for Cherry Shrimp with Eggs\nTaking care of pregnant cherry shrimp requires special attention and consideration. These vibrant-colored shrimp are known for their ability to reproduce quickly in the right conditions.\nTo ensure successful breeding, it is crucial to maintain proper water parameters in the shrimp tank. This includes keeping the water clean and providing ample algae as a food source.\nPregnant cherry shrimp may become aggressive towards other shrimp in the colony, so it is advised to separate them in a separate breeding tank. The gestation period of cherry shrimp varies, but it typically lasts around 30 days.\nThe female shrimp will mate and carry the fertilized eggs until they hatch during this time. It is vital to provide a suitable environment with sufficient hiding spots and shrimp food to support the development of the fry.\nBy understanding and implementing the necessary steps for pregnant cherry shrimp care, enthusiasts can enjoy a thriving and flourishing aquarium.\nCommonly Asked Questions About Red Cherry Shrimp Eggs (FAQs)\nHow often do cherry shrimp lay eggs?\nFemale cherry shrimp can lay eggs once every few weeks under the right conditions.\nWhat do baby shrimp eat?\nBaby shrimp feed on biofilm, algae, plankton, and specialized shrimp food designed for their tiny size.\nCan I keep cherry shrimp with other fish?\nWhile cherry shrimp can coexist with some peaceful fish, it’s important to choose tankmates that won’t prey on the shrimp or compete for their food.\nHow many eggs can a female shrimp carry?\nA female shrimp can carry 20 to 30 eggs under her tail.\nAre there any specific tips for ensuring a high survival rate among baby shrimp?\nProviding stable water parameters, offering hiding spots, and supplying proper nutrition are key to ensuring the survival and growth of baby shrimp.\nWhat are fertilized eggs?\nFertilized eggs are eggs that the sperm of a male shrimp have fertilized. In the case of cherry shrimp, the female shrimp will mate with a male shrimp, and the eggs will be fertilized during breeding.\nWhat do cherry shrimp with eggs look like?\nCherry shrimp eggs are small and transparent. They are usually attached to the female shrimp’s abdomen, forming a cluster. The eggs are spherical and can be easily distinguished from unfertilized eggs.\nHow long will it take for cherry shrimp eggs to hatch?\nIt generally takes 2 or 3 weeks for cherry shrimp eggs to hatch. The exact time might vary depending on the water temperature and other environmental conditions.\nHow can I breed red cherry shrimp?\nYou will need male and female shrimp to breed red cherry shrimp. Create a suitable tank environment with plenty of hiding places and a stable water temperature. The female shrimp will carry the eggs until they hatch, and the breeding process will occur naturally.\nWhat should I do with the eggs once my shrimp lays them?\nIt is best to leave the eggs undisturbed with the mother shrimp. She will move the eggs to a safe location and take care of them until they hatch. Attempting to move the eggs yourself may cause damage or stress to the mother shrimp.\nCan cherry shrimp lay unfertilized eggs?\nYes, it is common for cherry shrimp to lay unfertilized eggs. This can happen if a female shrimp has not mated with a male shrimp or the eggs were not successfully fertilized during the breeding process.\nHow can I help the eggs to hatch successfully?\nTo help the eggs hatch successfully, providing a stable and suitable tank environment is important. Maintain proper water quality, temperature, and provide hiding places for the mother shrimp and eggs. Avoid disturbances or sudden changes in the tank that may stress the shrimp or disrupt the hatching process.\nWhat happens to the male shrimp after the eggs are laid?\nAfter the eggs are laid, the male shrimp’s role is complete. He has no further involvement in caring for the eggs or the hatching process. The female shrimp will take care of the eggs until they hatch.\nCan I separate the eggs from the mother shrimp?\nIt is generally not recommended to separate the eggs from the mother shrimp. The mother shrimp knows how to care for the eggs and will provide the necessary nurturing conditions. Separating the eggs may lead to a lower chance of successful hatching or harm to the eggs.\nWhat should I do if the eggs do not hatch?\nIf the eggs do not hatch after the expected period, it is possible that they are not viable. In such cases, waiting and observing for a little longer is best. If the eggs remain unchanged for an extended period, likely, they will not hatch. At that point, you can remove the eggs from the tank.\nBreeding cherry shrimp and witnessing the hatching of their eggs is a truly rewarding experience for any aquarium enthusiast. Understanding the intricacies of shrimp reproduction, creating a suitable environment, and providing proper care is essential for a successful breeding journey. In the intricate underwater world of aquarium enthusiasts, the wonder of new life takes center stage with the captivating sight of cherry shrimp with eggs. These tiny creatures have proven to be a mesmerizing addition to any tank, offering their vibrant color and a sense of thriving vitality.\nAs we’ve explored the nurturing care and optimal conditions required for these shrimps to reproduce successfully, it’s evident that a delicate balance must be struck. The sight of those tiny eggs nestled among the dwarf shrimp speaks to the harmonious relationship we’ve developed with nature in our own living spaces. So, whether you’re a seasoned hobbyist or just dipping your toes into the aquatic realm, cherishing the miracle of cherry shrimp with eggs reminds you of life’s beauty and fragility in its most intricate forms.\nYou might also like\n- Shrimp Breeding Setup 101 (Setup, Size, Mates & Requirements)\n- Red Cherry Shrimp Breeding: 5 Hacks for Rapid Success!\n- Freshwater Shrimp Breeding 101: (A Comprehensive Guide)\n- Do Shrimp Eggs Hatch All at Once? The Answer Will SHOCK You!\n- Do Shrimp Molt Their Skin? 3 Surprising Facts About Molting!\n- What Do Cherry Shrimp Eat: 7 Astonishing Foods They Crave!\n- Ideal Neocaridina Shrimp Water Parameters: Boost Growth 3x Faster\n- Caring for Cherry Shrimp 101: A Comprehensive Beginner Guide\n- Pregnant Cherry Shrimp: 3 Easy Secrets to Healthy Babies!\n- How Many Times Do Cherry Shrimp Molt: A Comprehensive Guide\n- How Long Do Cherry Shrimps Live for: Shocking Truth Revealed!\n- Female Cherry Shrimp Saddle: 3 Proven Signs of Pregnancy!\n- Orange Sakura Shrimp 101: Price, Care, Breeding & More"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:dcd9cfab-1d75-4c94-aebf-9efe9ae3e50a>","<urn:uuid:51d69c4f-3ce4-4cad-8647-aac9ce0ce6d1>"],"error":null}
{"question":"空調系統的性能和維護要求是什麼? Does a ducted air conditioner's performance affect energy bills, and what maintenance signs should I watch for?","answer":"Ducted air conditioner performance directly impacts energy bills - reduced efficiency can cause sudden increases in energy consumption. Key maintenance signs to watch for include reduced cooling/heating performance, strange noises or odors, poor airflow, and water leaks. The system requires proper sizing - approximately 0.125 kW per square metre for living areas with standard 2.4m high insulated ceilings. Regular servicing, costing between $150-$300, is essential for maintaining efficiency and preventing breakdowns.","context":["What is Reverse Cycle Airconditioning?\nRefrigerative air conditioners use the same operating principle as refrigerators, they \"pump\" heat from one place to another. Like refrigerators, they have two connected coils - an inside coil and outside coil. The coils are connected by pipes filled with refrigerant which is pumped around the circuit by a compressor. As warm air passes over the indoor coil, heat is transferred to the refrigerant passing through the coil and pumped to the outdoor coil where it is dissipated into the atmosphere. This is the reason why air conditioners are also called heat pumps.\nSome refrigerative air conditioners also work in reverse to provide heat in winter. Rather than making their own heat from electricity, they use the electricity to pump heat from outside the building to inside. Even on fairly cold days, energy can still be extracted from the outside air and pumped inside.\nRefrigerative systems dehumidify as well as cool the air. This feature makes them highly suitable for hot, humid climates like coastal regions.\nBenefits of a reverse cycle air-conditioner\nThe most obvious benefit of Reverse cycle air-conditioners is that the one appliance can be used for heating and cooling.\nOne of the most efficient forms of heating is a reverse cycle air-conditioner particularly for Perth.\nReverse cycle air-conditioners combine refrigerative cooling, dehumidification and when running in reverse very efficient heating. With a Reverse cycle air-conditioner you have one unit providing the combined effects of both a home air-conditioner and a heater.\nOther benefits include:\n- quiet operation\n- wall mounted so it is away from small hands\n- Very precise climate control, a constant temperature (good for asthma sufferers, babies and the elderly)\n- filtered, pollution-reduced air\n- because there are no open flames, it’s safe for families with children\n- A reverse cycle air-conditioner works by transferring heat, making it more energy-efficient than normal electric heating. This not only helps our environment, but can also reduce your electricity bill.\nGovernment Heating Cost Comparisons!\nThe graphs below provide approximate running costs and greenhouse gas emissions for different types of heaters in an average home with an insulated ceiling.\nThe costs and emissions are estimates only and will vary from location to location and with different types of use. It is intended that the graphs give an indication of the comparative costs between different types of heaters under similar conditions.\n|CENTRAL HEATERS (150m² floor area)|\nApproximate Annual Running Costs\nApproximate Annual Greenhouse Gas Emissions\n|SPACE HEATERS (60m² floor area)|\nApproximate Annual Running Costs\nBuying a reverse cycle air-conditioner\nThink about the overall costs when choosing your cooling appliance. A unit with a higher purchase price and installation cost could deliver the lowest operating costs, making it cheaper in the long run.\nConsider the following factors when making your choice:\n- The energy star rating (the more stars, the more energy efficient).\n- The size of the area to be cooled.\n- The direction that your room faces, whether the room is insulated and the size of any windows in that room.\n- The amount of time that you will use the appliance each day.\n- The cost of the appliance.\n- The cost of installing it.\n- The running costs, usually expressed in terms of cents per energy unit used (kWh).\n- How long you expect the appliance to last.\nOverall, your air-conditioning specialist will be able to help you work out the right unit for your specific needs. It is important to note that purchase prices and installation costs vary according to different locations.\nAppropriate system size is particularly important with refrigerative air conditioners as choosing a system that's too small won't provide effective cooling and choosing one that's too large will result in frequent cycling (turning on and off), wasting energy and money and increasing the system's wear and tear. An oversized system may also be less effective at dehumidifying the air.\nRefrigerative air conditioners should be sized based on output capacity. The output is normally expressed in kilowatts (kW). If you're considering purchasing a room unit, an approximate base is to allow 0.125 kW per square metre of floor area to be cooled in living areas. This guide applies to standard 2.4 m high ceilings with insulation. As appropriate sizing depends on a number of other factors besides the area of room to be cooled, make sure you consult an air-conditioning specialist before purchasing your system. Your specialist will be able to give you a precise calculation of size based on your own specifications.\nWhen sizing your system it is important not to confuse the output capacity with the input capacity or coefficient of performance (COP). The COP of an air conditioner indicates how many units of heat are removed by the air conditioner per unit of electricity consumed. For example, an air conditioner with a COP of 2.5 will pump 2.5 kWh of heat outside for every unit (kWh) of electricity used. Typically, COPs vary from a low of about 1.7 to a high of about 3.3 for domestic air conditioners. For air conditioners capable of heating, different COPs apply for the heating mode and are usually between 2.0 and 3.2. Air conditioners with a high COP for cooling do not necessarily have a high COP for heating, although this is often the case.\nTypes of Refrigerative Air Conditioning\nSmall, portable units cool one room at a time and can be wheeled from room to room. A connection to the outside is required to remove the hot air. Some units can be placed in an open window so the hot coil is outside while other types have an internal hot coil and a flexible air hose which can be placed out a window or door.\nPortable units offer very low efficiency and often struggle to cool an area, you will also find them ridiculously noisy.\nFixed or fascia units\nFixed units can cool larger areas and come in two main types - single units and split systems.\nSingle units (RAC’s) are mounted through a wall or window with the hot coil on the outside and can only really cool the room in which they are situated. As the pumps and fans are all in one location, they can be quite noisy. They are old technology which can be hard to source now days.\nSplit systems (Split’s) have the cool coil inside a room and all the other equipment located outdoors up to 20 metres away. This makes them much quieter indoors than RAC's.\nMulti split systems can cool more than one open area with just a single outdoor unit, but they can carry similar constraints in regards to zoning as a ducted systems and can cost just as much to run. In general they are more expensive, however if you have limited roof space or restrictions on outdoor locations they may be a blessing.\nThese systems can cool a whole house by supplying cool air to multiple outlets. A good system will have a zone arrangement so that cool air can be supplied to only those areas required (for example, living areas during the day and bedrooms at night). This can significantly reduce the amount of energy consumed.\nDucted systems can be roof or ground-mounted and are usually split type systems with the hot coil and fluid pumps outdoors and a cold coil situated inside the ducting. Typically air is drawn from inside the house and then cooled and recirculated. Some systems allow fresh air to be mixed with the recirculated air.\nTake care as the unit itself is only around a third of the total cost. Make sure you are happy with the installation company, do the methods and components they use compare to the units quality. What about the design, plan the layout of ducts, thermostats, sensors, timers and other devices to get the best performance and efficiency from your system. Make sure these three are put together well on the day.\nThe above information is available at:","Welcome to our comprehensive guide on how often you should service your ducted air conditioner. Ducted air conditioning systems are a popular choice for many homeowners, providing efficient cooling and heating throughout the house. However, like any other appliance, regular maintenance and servicing are crucial to ensure optimal performance and longevity.\nWe will discuss the importance of servicing your ducted air conditioner, signs that indicate it’s time for a service, and answer frequently asked questions related to ducted air conditioner cleaning service. So, let’s dive in!\n- Regular servicing of your ducted air conditioner is important to ensure optimal performance and longevity.\n- It is recommended to service your ducted air conditioner at least once a year, but more frequent servicing may be required in certain cases.\n- Signs that indicate your ducted air conditioner needs servicing include reduced cooling or heating performance, increased energy bills, strange noises or odors, poor airflow, and water leaks.\n- The frequency of servicing may vary based on the environment. Coastal areas may require servicing every six months, urban areas every 9-12 months, and rural areas annually.\n- Hiring a professional technician for comprehensive servicing is recommended, as they have the expertise to identify and address underlying issues.\n- Regular servicing offers benefits such as improved energy efficiency, extended lifespan of the system, enhanced indoor air quality, and early detection of potential problems.\n- Neglecting regular servicing can potentially void the warranty provided by the manufacturer, so it’s important to adhere to the recommended schedule.\n- The cost of ducted air conditioner servicing can vary, but on average, a comprehensive service can cost between $150 and $300.\nHow Often Should You Service Ducted Air Conditioner?\nRegular servicing of your ducted air conditioner is vital to keep it running smoothly and efficiently. The frequency of servicing depends on several factors, including the manufacturer’s recommendations, usage patterns, and environmental conditions. In general, it is advisable to have your ducted air conditioner serviced at least once a year. However, in certain cases, more frequent servicing may be required.\nSigns That Indicate Your Ducted Air Conditioner Needs Servicing\nIt’s important to be aware of the signs that indicate your ducted air conditioner requires servicing. By paying attention to these signs, you can address any potential issues before they escalate and ensure that your system operates optimally. Here are some common signs to look out for:\n1. Reduced Cooling or Heating Performance\nIf you notice that your ducted air conditioner is not providing the same level of cooling or heating as before, it may be a sign that it needs servicing. Reduced performance can be caused by issues such as clogged filters, refrigerant leaks, or faulty components.\n2. Increased Energy Bills\nA sudden increase in your energy bills without any change in usage patterns could be an indication that your ducted air conditioner is not functioning efficiently. Regular servicing can help identify and rectify any issues that may be causing excessive energy consumption.\n3. Strange Noises or Odors\nUnusual noises, such as grinding, squealing, or rattling sounds, coming from your ducted air conditioner should not be ignored. Additionally, foul odors emitting from the system can indicate the presence of mold or other contaminants, which can affect indoor air quality.\n4. Poor Airflow\nInsufficient airflow from the vents can be a sign of a blockage in the ductwork or a problem with the fan or motor. Regular servicing can help identify and resolve these issues, ensuring proper airflow throughout your home.\n5. Water Leaks\nIf you notice water pooling around your indoor unit or dripping from the vents, it’s important to address it promptly. Water leaks can indicate problems with the condensate drain or other components, which can lead to further damage if left unattended.\nHow Often Should You Service Ducted Air Conditioner in Different Environments?\nThe frequency of servicing your ducted air conditioner can vary depending on the environment in which you live. Factors such as climate, air quality, and exposure to external elements can impact the system’s performance and maintenance needs. Here are some guidelines for different environments:\n1. Coastal Areas\nIf you live in a coastal area where saltwater and high humidity are prevalent, your ducted air conditioner may require more frequent servicing. The salty air can corrode the system’s components, leading to reduced efficiency and potential breakdowns. It is recommended to have your ducted air conditioner serviced every six months in coastal areas.\n2. Urban Areas\nUrban environments are often characterized by higher levels of pollution and dust particles. These pollutants can accumulate in the ductwork and filters, affecting the system’s performance. For residents in urban areas, it is advisable to have the ducted air conditioner serviced every 9-12 months.\n3. Rural Areas\nIn rural areas with cleaner air and fewer pollutants, the frequency of servicing can be extended. Having your ducted air conditioner serviced annually should be sufficient in most cases. However, it’s important to monitor the system for any signs of reduced performance or issues.\nHow long does a ducted air conditioner service take?\nThe duration of a ducted air conditioner service can vary depending on various factors, including the size of the system, its condition, and any additional repairs or maintenance required. On average, a comprehensive service can take anywhere from 1-3 hours.\nCan I service my ducted air conditioner myself?\nWhile there are some maintenance tasks you can perform yourself, such as cleaning the filters and checking for visible damage, it is recommended to hire a professional for a thorough servicing. Certified technicians have the expertise and equipment to identify and address any underlying issues that may not be visible to the untrained eye.\nWhat are the benefits of regular ducted air conditioner servicing?\nRegular servicing offers several benefits, including improved energy efficiency, extended lifespan of the system, enhanced indoor air quality, and early detection of potential problems. It also helps maintain the manufacturer’s warranty and ensures that your system operates at its best, keeping you comfortable throughout the year.\nCan skipping regular servicing void the warranty?\nYes, neglecting regular servicing can potentially void the warranty provided by the manufacturer. Most warranties require proof of regular maintenance to remain valid. It’s essential to check the terms and conditions of your warranty and adhere to the recommended servicing schedule.\nHow much does ducted air conditioner servicing cost?\nThe cost of ducted air conditioner servicing can vary depending on various factors, including the service provider, the size and condition of the system, and any additional repairs or maintenance required. On average, a comprehensive service can cost anywhere from $150 to $300.\nCan regular servicing prevent breakdowns?\nRegular servicing plays a crucial role in preventing breakdowns by identifying and addressing potential issues before they escalate. It helps maintain the system’s components, ensures proper airflow, and reduces the risk of major failures. Investing in regular servicing can save you from costly repairs or replacements in the long run.\nServicing your ducted air conditioner at regular intervals is essential for its optimal performance, energy efficiency, and longevity. By paying attention to the signs that indicate servicing is needed and adhering to the manufacturer’s recommendations, you can ensure a comfortable indoor environment throughout the year.\nRemember, it’s always best to hire a professional technician for a comprehensive service to identify and resolve any underlying issues effectively. Don’t neglect the maintenance of your ducted air conditioner and enjoy the benefits of a well-functioning and efficient cooling and heating system."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:d4fe6e7b-8224-4aa9-a55a-720282533bd2>","<urn:uuid:cd210a0c-efef-4526-a92a-034ec2e1cfdc>"],"error":null}
{"question":"How do the wool characteristics and applications differ between traditional Southdown sheep and other breeds used for luxury textiles? I'm curious about their respective uses in high-end products.","answer":"Southdown sheep produce one of the finest wools among British breeds, with a micron count of 23.5-29 microns, making it suitable for products like socks, mittens, hats, blankets, and sweaters. Their wool is particularly valued for its soft, springy texture and good durability. In comparison, other luxury animal fibers like cashmere from goats are used specifically for high-end products such as intricately woven shawls, stoles, luxury coats, jackets, and menswear suits. While both types produce quality fibers, they serve different market segments within the luxury textile industry.","context":["5 edition of The World Market for Blankets and Traveling Rugs of Wool or Fine Animal Hair found in the catalog.\nSeptember 28, 2006\nby ICON Group International, Inc.\nWritten in English\n|The Physical Object|\n|Number of Pages||116|\nWool constitutes 5% of the world textile fibre production. This wild and mountainous area gave its name to the fine soft goat's wool, or down, which first came to the West in the form of intricately woven cashmere shawls. stoles), rugs (especially travel rugs and \"throws\") and cloth for luxury coats, jackets and suits for the menswear. Fuzzy Blanket or Fluffy Blanket for Baby Girl or boy, Soft Warm Cozy Coral Fleece Toddler, Infant or Newborn Receiving Blanket for Crib, Stroller, Travel, Decorative (28Wx40L, XS-Flint Gray) out of 5 .\nAlpaca and llama fleece are classified as specialty or luxury fibers, but sheep fleece or wool tops the list of animal fibers used today. The camelids (alpaca and llama) are quite similar to each other in fiber and background, and though they bear some similarity to sheep, the differences between the fibers of these herding animals are outstanding. 1. Look for the ears! The key in differentiating between these two species is by ear shape and length: Llamas have longer, curved, banana-like ears, whereas Alpacas have shorter, straighter, and more pointy ears. 2. Size. The Llama is about twice the size of the Alpaca.\nWhile wool blankets can be made from practically any wool fiber, the type of wool made by alpacas can also be formed into sheets or other types of fine bedding. In addition, some manufacturers make rugs from this type of wool, and it's also possible to form this fabric into dolls and other types of toys. Palais Hand-Knotted Wool & Silk Rug Collection. Stocked Items Ready for Delivery in Days Shown in Indigo/Copper.\nstory of the western railroads\nPort of Houston, Texas\nDouble your money in Americas finest companies\nIBM UK Limited\nA Bill to Incorporate the Directors of the Columbian Library Company\nStudies in Spensers historical allegory.\nProceedings of the conference, June 2-7, 2001, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA.\nInstructional tests in arithmetic\nPictorial souvenirs of Britain\nJohn W. Burton.\nModern educational theories.\nWells, Fargo detective\nThe town and country almanack, for the year of our Lord, 1796.\nShip of dreams\neffect of positive and negative self-talk on level of confidence and results on simple recall tasks\nSnuggle up in style with World Market's affordable selection of blankets and throws. Handpicked from around the globe, our assortment includes crocheted blankets and multicolor, geometric, ombre and herringbone throws in soft fabrics and stunning hues. Discover a gorgeous, unique and versatile selection of indoor area rugs at World Market.\nWith patterns, prints and materials to enhance any space, our selection of indoor area rugs lend luxurious comfort and eclectic style to your home decor.\nValid through 8/26/20 at Cost Plus World Market stores within the United States and Not valid at the Tracy, CA outlet store. Not valid on Wusthof, SodaStream, alcoholic beverages, gift cards, eGift Cards, Always A Deal items, One-of-a-Kind Rugs, Sackcloth and Ashes Blankets, delivery surcharges, and shipping fees.\n- - Blankets (other than electric blankets) and traveling rugs, of wool or fine animal hair: No. kg: - - Blankets (other than electric blankets) and traveling rugs, of cotton: No. kg: - - Blankets (other than electric blankets) and traveling rugs, of synthetic fibers: No.\nkg: - - Other blankets and. The most common wool animal is the sheep. Sheep can be categorized into three major types when it comes to wool production: fine wool, medium and coarse wool, and hair-type. Fine wool sheep produce the smallest micron of wool and include the Merino types, Rambouillet and Debouillet.\nThis wool is commonly used in clothing production. North End Decor Faux Fur Cowhide Plush Pillow & Blanket Throw Pillows, White. out of 5 stars 8. $ $ 49 Shop LC Delivering Joy homesmart Cow Blanket Throw Warm Cozy Fleece Animal Print Couch Travel Office Soft.\nout MustMat Brown Cow Print Rug \" W x \" L Faux Cowhide Rugs Cute Animal Printed Carpet for Home. out of. Searching and Shopping for Fine Antique Rugs Online. Shopping for fine antique carpets or decorative rugs online should be easy. This is a no-brainer for internet savvy shoppers.\nBut that said, not all rug dealers make finding the perfect antique Oriental rugs easy. Searching and finding that one special rug, that specific antique carpet that captures your heart, is possible. Durable Loom Warp Thread (Natural/Off White), 8/4 Warp Yarn ( Yards), Perfect for Weaving: Carpet, Tapestry, Rug, Blanket or Pattern - Warping Thread for Any Loom out of 5.\nThe story of how it was renamed Metzger’s is just one chapter in a saga that spans Prohibition, World War II drama and a brief closure at the turn.\nThe Salish, indigenous North Americans who lived in the Pacific Northwest, were known for making blankets from dog hair. Nowadays, considered a luxury fiber by those who spin it, dog hair has yet to make waves on the commercial market.\nInstead, commission-based spinners craft individual keepsakes as long as you supply the hair. The main use of wool is in the production of clothing. However, it is also used to make carpets, upholstery, saddle cloths, and horse rugs. Inthe top wool producers were Australia, China, the United States, and New Zealand.\nThe world’s top wool producing countries. Australia is the highest wool producing country in the world. Trade intelligence is a service that provides global trade statistics for all countries across the globe. This includes export/ import data, analysis of this data on various parameters, country. Navajo rugs and blankets (Navajo: diyogí) are textiles produced by Navajo people of the Four Corners area of the United textiles are highly regarded and have been sought after as trade items for over years.\nCommercial production of handwoven blankets and rugs has been an important element of the Navajo economy. As one expert expresses it, \"Classic Navajo serapes at their. HLZHOU Soft Faux Fur Rug White Sheepskin Chair Cover Seat Pad Shaggy Area Rugs for Bedroom Sofa Living Room Floor(2 x 3 Feet （60 x 90 cm） White) out of.\nLOMAO Flannel Blanket with Pompom Fringe Lightweight Cozy Bed Blanket Soft Throw Blanket fit Couch Sofa Suitable for All Season (51x63) (Mustard Yellow) out. Rectangular wool area rugs are the most common shape, but it’s possible to find great circular rugs, too—these look great in a master bedroom.\nIf a round rug is just the thing, try black with a floral border for supreme elegance. Mexican Zapotec Wool Rugs - Home Decor Artisan Crafted, World Heritage. Home Decor - Area Rugs Mexican Zapotec Wool Rugs - from Novica in association with National Geographic bringing a range of handcrafted items from small scale crafts workshops, often run by a single craft worker in the developing world.\nWool is the textile fiber obtained from sheep and other animals, including cashmere and mohair from goats, qiviut from muskoxen, hide and fur clothing from bison, angora from rabbits, and other types of wool from camelids.\nWool consists of protein together with a small percentage of lipids. In this regard it is chemically quite distinct from the more dominant textile, cotton, which is mainly. Sheep are most likely descended from the wild mouflon of Europe and Asia; one of the earliest animals to be domesticated for agricultural purposes, sheep are raised for fleeces, meat (lamb, hogget or mutton) and milk.A sheep's wool is the most widely used animal fiber, and is usually harvested by shearing.\nOvine meat is called lamb when from younger animals and mutton when from older ones in. A carpet is a textile floor covering typically consisting of an upper layer of pile attached to a backing. The pile was traditionally made from wool, but since the 20th century, synthetic fibers such as polypropylene, nylon or polyester are often used, as these fibers are less expensive than wool.\nThe pile usually consists of twisted tufts that are typically heat-treated to maintain their. Rugs by Type Outdoor Rugs Shag Rugs Washable Rugs Jute Rugs Kitchen Rugs & Mats Kids & Tweens Rugs Handmade Rugs Accent Rugs Stair Treads One of a Kind Rugs 3'x5' 4'x6' 5'x8' 6'x9' 7'x9' 8'x10' 9'x12' 10'x14' Accent.The robe-sized blanket, from Pendleton, is the size preferred by Native Americans for ceremonial purpose and wrapping about oneself like a robe.\n82% pure virgin wool and 18% cotton. Felt bound. Size 64\" x 80\". Pendleton Big Medicine Robe Blanket: The rare white bison occurs only once in Reviews: The Best quality, handmade carpets, and rugs.\nChoose from a wide variety of colors, patterns, and sizes. Browse our great selection of premium designer handmade rugs and carpets. Free shipping worldwide.","They are a great breed that are docile and easy to manage. Next page -> How the Wool is Cleaned, Picked, and Carded. Encyclopaedia Britannica's editors oversee subject areas in which they have extensive knowledge, whether from years of experience gained by working on that content or via study for an advanced degree.... Be on the lookout for your Britannica newsletter to get trusted stories delivered right to your inbox. You can see from her stubby legs, Southdowns are small sheep … They have wool on their faces, ears and legs. If you would like to spin, knit, crochet, or weave with it, we have wool and yarn for sale in Our Shops. Rams and ewes are usually polled, that means they have no horns. “They’re not a wool sheep they’re a fat lamb sheep.” He will sell his 200 hinds over the next over two years. They are laid flat to dry. Since it has more barbs per inch than other wool types, it is also ideal to blend with angora or other slick fibers since it clings so well. Black Friday Sale! His work was continued by Jonas Webb of Babraham in Cambridgeshire, who developed the larger animal of today. Babydoll Southdown wool is one of the finest wools of all the British breeds. We have drawings of these Southdown ancestors and they most certainly didn’t look like the distinctive ‘teddy-bear’ faced Southdowns we recognise today. You will find it has good durability. The tear ducts should be free of wool just below the eyes. Southdown sheep are medium to large sized beautiful animals with distinctive appearance. Babydoll Southdown wool is one of the finest wools of all the British breeds. The wool is fine to medium, with a staple length of 4-6 cm (or 1.5-2.5 inches), average fleece weighs 3-5 pounds, and is coarse with a micron count of 58s-60s. See the Table of Selected Breeds of Sheep for further information. They are a great breed that are docile and easy to manage. The oldest of all British breeds of sheep, it has an ideal body conformation for meat production. An estimated 110,000 sheep were in Sussex as early as 1341. Babydoll wool is great for socks, mittens, hats, blankets, and sweaters. They are broken down into two types the Original Southdown and the Babydoll Southdown that are a bit smaller than the original breed. Let us know if you have suggestions to improve this article (requires login). https://www.britannica.com/animal/Southdown, Black-Faced Highland, also called Scottish Blackface, originally Scotland, now also U.S., Italy, Argentina, developed in N.Z., now also in U.S., Australia, developed in England, now in U.K., U.S., Australia, small wool yield; out-of-season lambs; horned and hornless varieties. The breed was standardized around 1780 by John Ellman who realized the breed potential and set out to increase the quality of the breed. Southdown duvets — Our hypoallergenic and moth proofed wool duvets will transform your sleep in countless ways. Thanks for looking! They are usually of white color with mouse colored faces. The micron count typically ranges from 23 to 29 which means many people can wear it comfortably next to the skin. Not to be confused with the Olde English 'Babydoll' Southdown sheep. Any wool covering in front of the eyes should be short so that at no time can the sheep be woolblind. By 1837 William Youatt regarded this boundary to have ceased to exist, showing that the distribution of the types of sheep across Sussex had changed again. Around 1341 there was and estimate of nearly 110000 Southdown sheep in Sussex and their wool quality came in second to that only of the Hereford sheep breed. developed in England, now also widespread in U.S. originally Central Asia, now also Africa, Europe, U.S. coats of very young lambs called Persian lamb, originally England, now U.K., North America, originally England, now also Australia, N.Z., North and South America, coarse, long wool is used chiefly for carpets, originally Spain, now also Australia, North America, South Africa. Sheep, ! Southdown are the breed in which all others in the “Down Family” can cite in their back round. It is short (about 2 to 3 inches) and springy, soft and bouncy, with a surprisingly strong underlying disposition. Southdown is a soft fiber with a micron count of 23-29 and as low as 19 on some Babydoll flocks. Many considered Southdown to be the English fleece closet to Merino in fineness. Its ability to wet felt is very low, although it is fantastic for needle-felting! Corrections? Fiber diameter: 23.5 to 29 microns Wool Type: Fine, dense, medium-wool fleece Length: Good staple length of 1.5 to 2.5 inches. However is generally known as a medium grade fleece with a blocky rectangular staple. They are usually of white color with mouse colored faces. This scarf was knitted using bulky Babydoll 2-ply yarn. But here…the socks I’ve made from 100% Babydoll wool get put in a lingerie bag, then thrown in the washer with the other laundry. 840. After washing, the scarf measured 64″ long and was 6″ wide. Southdown Sheep. Fleeces are considered medium wool type with a fibre diameter of 23.5 to 29.0 microns. Both breeds fleece … I wash with warm water and rinse with cool. The Southdown is still noted for fine wool, although the fleece of course belongs to the British shortwool type and is not as fine as that of the Merino. Premium Membership is now 50% off! Southdowns are popular in many parts of the world, especially in The Commonwealth and the United States. New Zealand or French Southdown wool does not exhibit the same qualities we are looking for. Although you may feel that all sheep are roughly equal, the wool they produce is not. There are technically 3 different types of Southdowns: American, Babydoll, and Miniature. Their wool was integral to what may have been the first ever recorded sheep-to-sweater type of exhibition. So rather than shrinking, it redistributed. If my calculations are correct, it widened exactly the same percentage as it shortened. It should be emphasized that the modern Southdown should have a moderate amount of wool about the face and eyes. Consequently, not all wool bedding is the same and it’s easy to make a costly mistake. Often the fiber is sold in wool pools, but it can be an interesting hand spinning experience. We sell our wool and other woolly items in Our Shops. Locks are disorganized and “downy” (it is, after all, the defining sheep breed of “down” type wools). Southdown Sheep Characteristics. AND WOOL TYPES I7 which was used in the development of all other Down breeds from the late eighteenth century onwards. AND WOOL TYPES I7 which was used in the development of all other Down breeds from the late eighteenth century onwards. “Most are sold privately through an agent but there is an annual deer sale in Taihape.” He said he will be sad to see the deer go. So it actually shortened in length, but became slightly wider! The stitches are still defined, just fluffier. Sheep, ! It is short (about 2 to 3 inches) and springy, soft and bouncy, with a surprisingly strong underlying disposition. From this, we know that there are only about 3,000 pedigreed Southdown ewes currently living in the UK, one of which we proudly present here. Its fleece is close and is the finest of the British breeds; but, though white and of good quality, the wool is short and the fleeces relatively light in weight. To give you some idea of how Babydoll wool stands up to machine washing and even machine drying, this was an experiment I did when first knitting with it. Our editors will review what you’ve submitted and determine whether to revise the article.\nHow To Type I On Ti-84, Ground Beef Side Dishes, Baby Led Weaning Food Size By Age, How To Find A Good Ent Doctor, Tartar Sauce Pioneer Woman, Dryer Heating Element Kenmore, Architectural Styles Timeline,"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:c56d31a9-026b-4db7-9ec9-1005098dc488>","<urn:uuid:9e7e80f4-2653-4647-b1aa-d776b34ea5fe>"],"error":null}
{"question":"In terms of radiation protection during a nuclear event: Are underground concrete structures inherently superior to above-ground metal buildings? Please explain the specific shielding properties and protection factors. What's the technical rationale behind shelter recommendations?","answer":"Both concrete and metal structures can provide protection from nuclear radiation, but underground concrete structures offer superior protection due to multiple factors. Underground locations provide enhanced shielding through earth coverage plus the concrete's thickness. While buildings constructed of metal and concrete offer good protection against thermal injuries, the key advantage of underground concrete shelters is the combination of dense construction materials and ground coverage that maximizes the three basic radiation protection principles: time (allowing longer shelter periods), distance (more material between person and radiation source), and shielding (multiple layers of protection). Additionally, underground concrete shelters typically have minimal windows and thick walls recommended by FEMA, with at least 10 square feet of space per person. However, if a dedicated underground shelter isn't available, any sturdy building with thick walls can provide some degree of protection.","context":["It is important to know how to shelter from nuclear fallout if you live in an area where the possibility of a nuclear attack is a real possibility. You must consider where to take shelter in case of a nuclear disaster and you must also be prepared to survive radiation poisoning after a nuclear explosion. Below are some useful tips that will help you with your preparations.\nPreparing for an impending nuclear attack\nA nuclear bomb blast is a very dangerous situation. Fortunately, there are some things you can do to prepare yourself for an impending nuclear attack.\nOne of the most important things you can do is learn how to protect yourself from radiation. You can take precautions by tucking your hands under your head, and cover your mouth and ears. Then, make sure to eat from sealed containers. Also, wipe down your surface after you eat.\nTaking these actions during the first few hours after a nuclear blast can reduce your risk of serious injury or death. At least one study estimates that half the world’s population could die from fallout. Survivors would also face widespread radioactive contamination.\nIf there is a regional nuclear war, all forms of life on Earth could be affected. Temperature changes, sea ice expansion, and fisheries declines would impact ecosystem services. In addition, firestorms can be very dangerous.\nEven in a major city, tens of thousands of people could be killed by a single nuclear weapon. There are eight nuclear-armed nations, including the United States, China, France, Israel, Russia, India, and Pakistan.\nThe size and number of warheads delivered determine how many immediate casualties are likely. For example, a 1-megaton explosion is enough to blind you for up to 13 miles. And a 300-kiloton bomb is capable of destroying a city in just a few seconds. This means that residents of the US might have just 30 minutes to seek shelter.\nThe Federal Emergency Management Agency (FEMA) suggests two ways to stay safe. First, you can shelter in a sturdy building. Second, you can listen for evacuation advice.\nLocations for fallout shelters\nA fallout shelter is a room or building that is designed to protect you from the effects of a nuclear blast. Normally, they are located in a public place such as an office building, a school or a university.\nThere are many different kinds of fallout shelters. Some are underground, while others are built inside buildings. When you are searching for a fallout shelter, it is important to consider several factors.\nFor example, you should look for buildings that are sturdy and have minimal windows. These types of buildings have thick walls, and are usually constructed of steel or concrete.\nYou should also look for a building that is in an underground location, as it will provide more protection. If you’re in an area where you are unsure of your safety, you may want to seek out a government bunker.\nAnother option is to build a fallout shelter at home. Whether you build it yourself or purchase a kit, you should make sure that you have enough supplies to survive for at least two weeks.\nIdeally, you should have a hand-crank radio to help you communicate during an emergency. If your communications systems are not up and running, you should try to stay in touch with trusted sources.\nIn order to ensure that you are prepared for a disaster, you should know where the best locations for fallout shelters are. Not everyone has the money to build a basement or an underground bunker. The next best thing is to have a basic understanding of what you need to survive a nuclear detonation.\nA good rule of thumb is to make sure that you have at least 10 square feet of room space. That’s about the minimum amount of headroom recommended by the Federal Emergency Management Agency.\nBasics of nuclear warfare\nNuclear warfare is the use of nuclear weapons to destroy targets, such as cities, in a military conflict. It can result in the death and destruction of millions of people, and is not without long-term catastrophic effects.\nThe earliest use of nuclear weapons in war came in 1945, when the United States dropped bombs on Hiroshima and Nagasaki. A new type of weapon involving fission and nuclear fusion was developed in the 1950s, and has been called a “thermonuclear weapon”.\nA small amount of matter is converted to huge amounts of energy, and this is the most important part of the nuclear bomb. The explosion produces a massive fireball. In some cases, the fireball will set fires, consume combustible materials, and destroy buildings.\nSome nuclear warheads can be detonated on the ground, while others are launched from submarines. Several types of nuclear weapons have been used in the United States Navy, and they include torpedoes, guided rockets, bombs, and nuclear-tipped missiles.\nDuring the Cold War, there were many different nuclear scenarios. Some were apocalyptic, like a world-wide nuclear catastrophe, and other were more mundane.\nFor example, a countervalue strike is a good way to target the enemy’s population. These attacks attempt to demoralize the enemy, thereby deterring a direct confrontation.\nA nuclear-armed missile can be launched from a submarine or from a high-altitude airplane. One type of warhead, the thermonuclear bomb, uses specialist high explosives to crush a hollow sphere of plutonium. This creates a critical mass, and then the weapon explodes.\nA number of smaller-scale civil defense programs were instituted in the United States in the 1950s, such as fallout shelter designation signs and dosimeters. There was also the public alert system, a device that alerted the public of a possible nuclear attack.\nIt is important to know how to shelter from nuclear fallout and radiation poisoning, as well as how to keep your body clean. In the event of a nuclear attack, immediate actions taken in the first few hours will minimize the risk of serious injury.\nShelter in an underground location is recommended. Depending on the location of the blast, there could be thousands of deaths. The number of casualties will depend on the size of the weapon and the number of people in the area that are exposed to the radiation.\nIf you are unsure about where to shelter, the CDC has provided guidance on how to shelter from a 10-kT nuclear detonation. A poncho roof is an effective way to increase the distance between the shelter and the fallout source.\nBuildings that have been constructed from metal and concrete have very good protection against thermal injuries. However, thin sheet metal and wood offer little protection.\nRadiation is also a risk to animals. Animals absorb large amounts of radioactive material from plants. Therefore, it is not a good idea to eat meat or other animal products that have not been prepared until well done.\nRadioactive materials may settle on skin, clothes and hair. When this happens, wash uncovered parts of the body to minimize the amount of radiation you receive.\nYou can also reduce your exposure to radiation by reducing the amount of time you spend in areas contaminated with radioactive fallout. This is especially true if you have been outside in the immediate hours following the explosion.\nWhen you find shelter, wipe your hands and the surfaces around your body with clean water and soap. Be careful not to scrub too hard because you can break the skin barrier.\nTime to eat food after a nuclear explosion\nWhen a nuclear explosion occurs, you may have to wait awhile before you can eat your food. The effects of radiation from the blast will vary depending on the size of the bomb and the distance from the blast. In some cases, you may have to shelter in place for up to a month.\nSome of the things you can do to increase your chance of survival after a nuclear bomb is to learn how to protect yourself. This includes taking the right steps to get clean, locating and contacting family members and learning how to survive until you can find a better shelter.\nYou may also want to buy some dosimeters so you can measure your exposure. Once you’ve learned to measure your exposure, you can start to take the necessary precautions to lower your dose.\nIf you’re outside when a nuclear explosion happens, you should lie down. This will protect your face and arms from the flying debris and the heat. As the shock waves subside, you can look for a place to shelter.\nYou should also listen to the radio for updates on the latest news about a nuclear attack. This will help you avoid being caught off guard and will keep you updated on how you should prepare for the event.\nIf you’re out and about during a nuclear disaster, you should avoid eating anything that has been left out on the ground. Also, you should take care not to touch your faces or drink water directly from a faucet. Wash your hands and face with soap and water before consuming food.\nYou should also keep a safe distance from the blast. Ideally, you should cover your head and stay away from windows. Keeping a distance of six feet or less is ideal.","Radiation & Health Effects\nRadiation and Health\n- Radiation is a form of energy.\n- Radiation comes from man-made sources such as x-ray machines, from the sun and outer space, and from some radioactive materials such as uranium in soil.\n- Small quantities of radioactive materials occur naturally in the air we breathe, the water we drink, the food we eat, and even in our own bodies. Radiation that goes inside our bodies causes what we refer to as internal exposure.\n- External exposure is from radiation from sources outside our body, such as radiation from sunlight and man-made and naturally occurring radioactive materials.\n- Radiation doses that people receive are measured in units called “rem” or “sievert.” (One sievert is equal to 100 rem.) Scientists estimate that the average person in the United States receives a dose of about one-third of a rem per year.\n- Eighty percent of typical human exposure comes from natural sources and 20 percent comes from artificial radiation sources, primarily medical X-rays\nHealth Effects of Radiation Exposure\n- Radiation affects the body in different ways, but the adverse health consequences of exposure may not be seen for many years.\n- Adverse health effects range from mild effects, such as skin reddening, to serious effect such as cancer and death. These adverse health effects are determined by the amount of radiation absorbed by the body (the dose), the type of radiation, the route of exposure, and the length of time a person is exposed.\n- Acute radiation syndrome (ARS), or radiation sickness, is usually caused when a person receives a high dose of radiation to much of the body in a matter of minutes. Survivors of the Hiroshima and Nagasaki atomic bombs and firefighters responding to the Chernobyl nuclear power plant event in 1986 experienced ARS. The immediate symptoms of ARS are nausea, vomiting, and diarrhea; later, bone marrow depletion may lead to weight loss, loss of appetite, feeling like you have the flu, infection, and bleeding. The survival rate depends on the radiation dose. For those who do survive, full recovery takes from a few weeks to 2 years.\n- Children exposed to radiation may be more at risk than adults. Radiation exposure to the unborn child is of special concern because the human embryo or fetus is extremely sensitive to radiation.\n- Radiation exposure, like exposure to the sun, is cumulative.\nProtecting Against Radiation Exposure\nThe three basic ways to reduce radiation exposure are through...\n- TIME - Decrease the amount of time you spend near the source of radiation.\n- DISTANCE - Increase your distance from a radiation source.\n- SHIELDING - Increase the shielding between you and the radiation source. Shielding is anything that creates a barrier between people and the radiation source. Depending on the type of radiation, the shielding can range from something as thin as a plate of window glass or as thick as several feet of concrete. Being inside a building or a vehicle can provide shielding from some kinds of radiation.\nOther Sources of Information about Radiation (click the links below for to access these Web sites):"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:0c5a0f06-5162-4bf8-b6f6-d3061afece25>","<urn:uuid:44ba0451-4f0e-435d-a919-ef3e902a7309>"],"error":null}
{"question":"What are the specifications of the Fatar keybed used in the Komplete Kontrol S49 MK2 MIDI controller?","answer":"The Komplete Kontrol S49 MK2 features a 49-note semi-weighted Fatar keybed with Aftertouch functionality. The keybed is designed to react like a traditional piano, providing a natural touch and feel through its semi-weighted keys. It includes Aftertouch capability for nuanced sound control and enhanced performance value.","context":["Sīkdatņu politika: Turpinot lietot mūsu mājas lapu, Jūs piekrītat mūsu lietošanas noteikumiem un sīkdatņu politikai. Uzzināt vairāk.\nNative Instruments Komplete Kontrol S49 MK2 MIDI Klaviatūra / Kontrolieris\nThe Native Instruments Komplete Kontrol S49 MK2 is a premium-grade, innovative MIDI keyboard controller, building on the success of the original Komplete Kontrol series. The Native Instruments Komplete Kontrol Mk2 sees an improved design and an upgraded layout, including dual high-resolution colour screens for quick and easy navigation. The 49-note Fatar keybed with Aftertouch provides exceptional realism and fluidity, thanks to its semi-weighted keys. The Komplet Kontrol MK2 Keyboard provides seamless integration with Maschine hardware and software, as well as many popular DAWs. It features a range of dedicated transport buttons as well as pre-mapped control of Komplete instruments and NKS instruments. Additionally, the Komplete Kontrol S49 MK2 MIDI Controller comes with Komplete 11 Select - a collection of some of the most popular virtual instruments and FX from Native Instruments.\nSemi-Weighted Fatar Keybed With Aftertouch\nThe Komplete Kontrol S49 MK2 is the latest addition to the Komplete Kontrol series from Native Instruments. The S49 MK2 retains all the functionality that made the original so sought-after while boasting a range of upgrades and improvements. At the heart of the S49 MKII’s design is the semi-weighted, touch-sensitive Fatar keybed with Aftertouch. This premium-grade keybed reacts like a traditional piano, with its semi-weighted keys providing a natural touch and feel. The Aftertouch features provides added realism when playing, delivering a nuanced sound for added performance value. In addition to the professional-grade keybed, the S49 MK2 also boasts ergonomic pitch and modulation wheels for changing the way your sounds react while being played.\nIntuitive Layout & Dual, High-Resolution Screens\nThe layout of the S49 MK2 has been vastly improved to provide a more ergonomic design that will improve your overall workflow. The intuitive layout provides you with everything you need right at your fingertips. The two high-resolution colour screens allow you to easily navigate and browse through your sounds, projects and more. The eight touch-sensitive encoders directly below the screen, provide you with the means to assign and control parameters as you see fit. It also features a 4-directional push encoder for easy sound browsing and navigating through projects. This makes controlling, accessing and selecting sounds and parameters easier than ever before.\nSeamless Maschine & DAW Integration\nOne of the most convenient features of the S49 MKII is the ability to seamlessly integrate with your selected digital audio workstation, and Maschine software/hardware. The S49 MK2 is ideal as the centrepiece of any production environment, providing a smart and easy way to control and play in your virtual instruments and samples. Tag-based preset browsing has now been implemented, allowing you to browse sounds quickly and even hear instant previews. The Komplete Kontrol S49 MkII also boasts pre-mapped control of Komplete instruments, as well as hundreds of Native Kontrol Standard (NKS) instruments. Its deep integration with Maschine software and hardware, as well as intuitive control over your favourite DAWs; makes the S49 MK2 one of the most versatile smart keyboard controllers on the market.\nLight Guide & Smart Play\nThe innovative light guide, adds RGB lights above each key to highlight drum cells, key switches, chords, scales and more. These lights are ideal for organising and differentiating between sounds, presets and play settings. The lights will change colour accordingly, showing you which key corresponds to which parameter/playing style. The Smart Play feature allows you to see scales and modes on the Light Guide. This allows you to play chord progression and arpeggios with single keys, or even map scales to white keys only. It also provides full VSTi support, allowing you to use and play your favourite virtual instruments directly from the keyboard itself.\n- Smart keyboard controller for all your virtual instruments\n- Pro-grade Fatar keybeds with aftertouch – 49 or 61 semi-weighted keys\n- Ergonomic pitch and mod wheels, plus touch strip for expression control\n- Pre-mapped control of KOMPLETE instruments and hundreds of Native Kontrol Standard (NKS) instruments from leading manufacturers\n- Full VSTi support\n- Tag-based preset browsing: Find sounds quickly and hear instant previews\n- Two high-res color screens for browsing, tweaking, mixing, and more\n- Light Guide: RGB lights above each key highlight drum cells, key switches, chords, scales, and more\n- Smart Play: See scales and modes on the Light Guide, play chord progressions and arpeggios with single keys, or map any scale to white keys only\n- Deep integration with MASCHINE software / hardware\n- Intuitive control over Logic Pro X, Ableton Live, and GarageBand. Cubase and Nuendo integration coming soon after initial release\n- 4-directional push encoder for one-handed sound browsing and project navigation • Two assignable pedal inputs\n- MIDI in / out\n- USB 2.0 bus powered\n- Includes KOMPLETE 11 SELECT\nKas lācītim vēderā?\n- Keyboard, USB cable, power supply.\n- KOMPLETE KONTROL software, MASCHINE Essentials, and KOMPLETE 12 SELECT Instruments and Effects collection – provided as downloads after hardware registration.\n- Driver (only required on Windows), Setup Guide and documentation supplied as downloads.\n|Galvenās funkcijas||MIDI I/O, Arpeggiator, Aftertouch|\n|Izmēri||84 x 29.7 x 8.4 cm|"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:de5b2b02-ca26-4f9d-85cb-57d9c4f2f814>"],"error":null}
{"question":"What are the optimal printing settings for waterproof paper, and what are the environmental waste management considerations for disposing of printed materials in an office setting?","answer":"For waterproof paper, it's recommended to print using 'normal' or 'standard' settings, as 'high quality' or 'dark' mode usually applies excess ink that the paper cannot absorb. If smearing occurs in normal mode, try 'light' or 'economy' mode settings. For best results, use manufacturer-supplied ink/toner cartridges rather than refilled or generic ones. As for office waste management of printed materials, it's crucial to ensure confidential documents are shredded before recycling. Paper recycling should be encouraged as it helps reduce deforestation impact. Offices can arrange for paper recycling boxes through recycling companies for proper disposal.","context":["Waterproof paper stands up well to rain and moisture. They are great for printing maps, taking notes in wet weather, and for use where your notes might be subject to contact with water. They can can be laminated, cut, and hole-punched. Read the Ultimate Map Tools article to learn how to print your own topographic maps for free.\nBoth sides of these papers have equal printing characteristics. For best results, one-sided printing is recommended. When large amounts of ink are applied, such as when printing maps or bold text, two-sided printing might result in ink bleeding through the paper. Also, when ink becomes wet from exposure it can be mobilized. This can allow it to absorb more deeply into the paper (resulting in bleed-through) or transfer to the back of a sheet above it in a booklet or stack of paper. If you do decided to print on two sides allow a few minutes drying time between sides. We recommend testing to see if your printing process will produce documents that will stand up to your anticipated conditions.\nWe recommend printing using the \"normal\" or \"standard\" settings of your printer. Printing in \"high quality\" or \"dark\" mode usually applies more ink than the paper can absorb. That will cause ink smearing or ink that does not dry. If the ink smears or does not dry in \"normal or \"standard\" mode see if you can print with a \"light\" or \"economy\" mode. For best results use the lightest printer setting that produces readable print.\nMost people who use the ink or toner cartridges supplied by the manufacturer of their printer have great success. Refilled cartridges and generic cartridges sometimes provide poor results. The ink or toner that you use can break down with exposure to direct sunlight, water or humidity. Ink usually fails before the paper during sun exposure. For best results use the ink and toner cartridges recommended by your printer manufacturer and be aware that exposure conditions will limit the life of your document.\nWaterproof paper might last outside for a few weeks (more or less), depending upon climate and sun exposure. They will not last through repeated or prolonged exposures to hot, cold, sun, wind or other harsh conditions.\nAll of these papers have been used for underwater writing while scuba diving. If you are diving more than a few feet deep you will need a paper that accepts pencil. The air pressure in ink pen refills is lower than the water pressure at more than a few feet deep. That will cause water to flow into your pen's refill and dilute the ink. Be sure to test your pen, printer and paper combination before going into the field or starting a project.\n|Waterproof Paper Brands|\n|Inkjet Printer||Very Good||NR*||NR*||Excellent|\n|Laser Printer||Very Good||Excellent||Excellent||Good|\n|Plain-Paper Copier||Very Good||Excellent||Excellent||NR*|\n|Write with Waterproof Ink||Excellent||Excellent||Excellent||Excellent|\n|Resistance of Waterproof Ink to Smudge\n(Immediate / after 8 minutes)\n|Write with a Pencil||NR*||Excellent||Excellent||Good|\n|Resistance of Pencil to Smudge||NA**||Very Good||Good||Excellent|\n|Tear Resistance||Good||Poor||Excellent||Very Good|\n|Folding Ability||Good||Excellent||Very Good||Very Good|\n|What is it?||synthetic paper||coated paper||synthetic paper||synthetic paper|\n|Weight of the paper?||10 mil plastic\nsimilar to 24# bond\n|similar to 20# bond||4 mil plastic\nSimilar to 20# bond\n|similar to 24# bond|\n|Recycling||with bulk plastics||with paper||with bulk plastics||with bulk plastics|\n|*NR = not recommended. **NA = not applicable. The information provided on this page is our opinion. Your experience using these papers could be very different from ours because you might use them with different types of printers, different types of ink, different writing tools or under different conditions. Also, your opinion of \"good\", \"excellent\" or \"poor\" performance might be different from ours. We provide the opinions above for general guidance. They are not meant to be a critique or promotion of any product.|\n- Item #77000 iGage Weatherproof Paper 8½\" x 11\"\n- Item #77001 iGage Weatherproof Paper 11\" x 17\"\n- Item #77100 Rite in the Rain Paper 8½\" x 11\"\n- Item #77101 Rite in the Rain Paper 11\" x 17\"\n- Item #77102 Rite in the Rain Duracopy 8½\" x 11\"\n- Item #77103 Rite in the Rain Duracopy 11\" x 17\"\n- Item #77200 National Geographic Adventure Paper 8½\" x 11\"\n- Item #77201 National Geographic Adventure Paper 11\" x 17\"\n- In stock\n- Scroll down for order info\nCustomers who bought this also bought:\nLight Fighter Map Case\nDesigned for the infantry soldier, the LFMC is impact resistant and sized to fit in a cargo pocket. This no-frills map case is made of polycarbonate finished in a glare and scratch resistant coating.","For any business enterprise, there is bound to be a considerable amount of waste left over at the end of the day. When it comes to waste disposal for business, it is best to do this in an ecological, legally responsible and environmentally friendly way. For big or small business, this article outlines some handy tips and techniques for different industries to correctly deal with junk disposal.\nBuilders or tradesmen\nThe most common form of waste in this industry is heavy waste and concrete materials. The most effective method to deal with builders’ waste clearance is to hire a skip. There are skip hire services that offer skips specifically for heavy waste such as concretes, bricks, rocks, pavements, tiles and soil. These skips also generally accept green waste and general waste, but it is best to check with the company before dumping such materials. It is generally unacceptable to dispose of liquids, batteries, food waste and tyres in these skips. But again, consult the company guidelines. Skips come in different sizes so carefully consider how much waste you think you will have to get the best value for money skip.\nFood waste and packaging material is the most common rubbish in this industry. Make sure your business is dividing trash into what can and cannot be recycled. All cardboard boxes should be flattened before recycling. Left over bread that can no longer be resold can often be given to farmers who have property with animals, so long as a release is signed stating that the bread won’t be for human consumption.\nThere are different ways to dispose of scrap metals. Check with the local council or tip facility to see what scrap metal can be recycled or crushed. For hazardous liquids and chemicals, these need to be disposed of in a safe and correct manner. For brake fluids and solvents, letting these dry out in a tin pan will make them easier to dispose of. Most paints and gasoline liquids can also be left to dry out. Once dried and solid, these substances should go into the hazardous waste system, and not general rubbish, as they can contribute to the major issue of groundwater and landfill contaminate.\nThe main thing when it comes to an office clearance is paper waste. It is important to make sure confidential documents are shredded before recycling them, for privacy and security reasons. Most offices are able to be supplied with a paper recycling box in which office documents can be placed. If not already in place, these can be arranged be recycling companies. Paper recycling is highly important and should be an encouraged practice for office waste removal, as there are many positive environmental benefits such as lessening the impact of deforestation.\nIf your business is using professional commercial clearance services for waste disposal or employing skip hire to dispose of excess waste, it is important to keep in mind some materials may not be accepted for health or environmental reason. This list is a rough guide to some unacceptable materials, but it is still necessary to consult with the company and make sure you understand their individual guidelines. Adhering to the regulations put in place by the company will make the waste management and disposal system run smoothly.\n- Regulated waste\n- Liquid waste\n- Hot or boiling waste\n- Hazardous substances\n- Large and heavy objects"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:ec3256b8-e085-449f-a112-7878731b2e26>","<urn:uuid:8f49c36c-3f16-4b27-b532-e87d8442b29e>"],"error":null}
{"question":"When considering both website security practices and email encryption standards, what are the potential vulnerabilities in user data protection and how do organizations address the limitations of each system?","answer":"Both website security and email encryption systems have specific vulnerabilities they must address. Websites collecting user data face risks of data attacks, leaks, and warm attacks, which they combat by storing information in highly secure networks with one-way connections and using uncrackable multi-bit encryption. For email security, TLS encryption has limitations - it only protects data during transmission, not before or after delivery, and requires both mail servers to support TLS for the encryption to work. TLS handshakes can fail due to algorithm issues, and even with encryption, receivers may suffer data breaches. Additionally, some companies' spam or anti-virus systems can affect message security, potentially leaving parts of messages unencrypted. Organizations address these limitations by implementing additional security measures like PGP, S/MIME, or secure portals for comprehensive protection.","context":["It is highly important for a website to handle its user data and to verify whether a user is genuine or a fake/spam. Spam users are virtual threats to a site comprising their financial asset and user discreteness. To avoid such chaos, the site collects information about users and keeps it to itself for verifying the users. On to that, it will never disclose this information for gains to other third party spammers at any cost.\nCollecting personal information\nThe users who comment in the site’s post are required to use their email and name as a proof of identity. However, it is done completely on their full approval. Else their info is not taken by force(which is a serious offense against the law). Not providing user info might be a way when some users won’t be able to use site’s full features. The users who provide their info via comments, their info is taken for site monitoring.\nCollecting the non-relevant data.\nThe user’s info is what matters the most. This can be used to monitor when a user is visiting a site openly or secretly. The email and name are the relevant data. The non-relevant data collected includes users’ IP address, browser name, browser identity, server type(or computer generation/type), technical information etc. This can be used to verify a users’ identity whether he or she is genuine or not. It can also be used to see if any of the users are visiting the website unknowingly.\nCookies might be common for every user. These are small files which are inserted into their hard drive to keep records and track information about them(sometimes when a user is suspicious). This is also done in order to monitor a users’ activity on the site. Cookies are kept on websites for users to accept when they visit one. A user has full control and approval before accepting on to a cookie from a site. If not accepted they will not be able to accept full features of the site, as much proper info from the site won’t be allowed on an unverified user.\nProtecting the information collected.\nThe site completely takes control of the highly confidential information and doesn’t allow it to be disclosed to others at any cost. A site will never compromise a user’s discrete data for logical gains to third parties. At all.\nHow the data is protected.\nThe data collected from users is considered a high priority similar to the website’s security. Such kind of data is kept in highly secure networks or offline storage devices with a one-way connection. Multi-bit encryption are used (like 128 or 256bit grade uncrackable encryption techniques) with the administrator’s signature to protect the user data.\nCompliance for sharing user data.\nThe user data collected as mentioned before is never disclosed to any third party at any cost. The site takes full responsibility to protect it from any kind of data attack, data leak or warm attacks. The data which is (or might be shared) will be 100% free from any linkage or linking to any of users’ email, name, IP address or any other personal information which might prove useful for third parties.\nAcceptance Of these measures.\nBy using a particular site (or this one) and accepting cookies, you thus verify that you accept to the terms of the site and its measures to keep user data. And these data under the user’s consent will be utilized for monitoring a user’s activity on the site and genuine.","TLS Encryption and Email Security\nHackers and stalkers have taken social sharing to a stage where it makes us vulnerable to their attacks. The internet helps them grow faster, learn from each other and makes the act of snooping over someone’s private data easier than earlier. As wise men say – safety is the number one priority. All we can do is to ensure there is a proactive breach-proof technology in place when it comes to transmission of data, and stay ahead of the game.\nWhen we provide multiple levels of assurance, we can improve the user experience along with providing secure communication. We believe that any TLS (Transport Layer Security) is better than no TLS. This is because all certificates, despite their different assurance levels, work to provide session safety and encrypt any data transmitted over the website. Depending on your requirements, we suggest you make a choice that serves your needs best. But first, you need to know what TLS encryption is and what it exactly does, so here you go:\nWhat is TLS Encryption?\nTransport Layer Security (TLS) is a protocol that implements privacy and data integrity within two communicating entities.TLS encryption is a cryptographic protocol that ensures network security over end-to-end communication. It is the most broadly deployed safety protocol used today by web browsers and other applications that need to privately transfer data over a network. It includes file transfers, VPN links, instant messaging, VOIP and sending messages over email.\nTLS is composed of two layers, the TLS Record Protocol and the TLS Handshake Protocol. The Record Protocol renders connection securely. The Handshake Protocol requires the server and client to verify each other first and barter encryption algorithms and cryptographic keys before any data is transferred.\nThe key features of TLS encryption include-\n- Encrypted messages– TLS makes sure that your messages that are sent over emails are secured from hackers. It encrypts the message before sending it so that it is impossible for a third party to interpret it.\n- Authentication– This is the process of checking the sender and receiver ID. It is done to verify that the messages are being sent from authenticated sources and the process has no spoofing.\n- Standardized websitesTLS encryption is now becoming a standard practice for websites. While Google Chrome is striking out non-HTTPS sites, people are also becoming wary of entering websites that do not have an HTTPS security protocol.\n- WidespreadTLS encryption is not limited to only websites and emails, VPN Voice over IPs, and many other such servers who provide end to end communication.\nTo maximize the utilization of TLS, you should ensure that both the parties have secure SSL/TLS Sessions. Most of the leading ISPs are supporting TLS these days for better transfer of emails.\nHow does TLS work for an email?\nThe mechanism and language (protocol) by which one email server sends an email message to another email server is called SMTP (Simple Mail Transport Protocol). For a long time now, email servers have had the choice of using TLS to transparently encrypt the message transmission from one server to the other. TLS used with SMTP, when possible, guarantees that the content of the email is guarded during communication between the servers.\nWant to know more on SSL and TLS ?\nTLS is initiated with a sequence called TLS handshake. The TLS handshake establishes a cipher suite for communication which specifies the encryption kit that will be shared for that communication. Once this data is encrypted, it is then signed with a Message Authentication Code which can be verified by the recipient to test the authenticity of the data transferred.\nThe target email server must support TLS for TLS communication to be used. The sending computer or server must be configured to use TLS links when possible.\nHere are two examples of emails sent with and without TLS encryption. This will help clarify the meaning and use of encryption:\n1. Without TLS encryption\n2. With encryption\nImage 2 is the perfect example of TLS encrypted email and how the receiver can see it.\nBoth mail servers are required to support TLS for the encryption process to work. The server and the client recognize which encryption keys to use before anything is broadcasted. The negotiation itself is guarded as well.\nWhy is TLS important?\nWhen you use a regular POP or IMAP link to download your email (the most common technique in practice), your username and password are carried in clear text over the Internet. This means, that anyone using the same wireless connection, the same channels, picketing traffic at your ISP or anyone in a position to see your Internet traffic can conceivably “hijack” your web traffic and find out your username and password. With this knowledge, they can easily read all your email, steal classified data and/or send out spam emails on your behalf.\nTLS encryption shields the transportation of the content in email messages. However, it does not defend the security of the information before it is transmitted or after it reaches its destination. For that, other encryption tools may be used, such as PGP, S/MIME, or storage in a secure portal.\nTLS encryption ensures that any information transmitted between the server and client does not fall prey to a man-in-the-middle attack, i.e. spammers attacking the data before it reaches the server. Encryption ensures that data which is being transmitted does not fall prey to attackers.\nOpportunistic TLS for Email Security\nAre you able to use TLS encryption optimally? If no, then Opportunistic TLS is the solution. To arrive at a clear idea, if the sending server sends an encrypted email but if the receiving server doesn’t accept encrypted messages, then email is sent unencrypted and hence available for email spoofing. Hence, the essential thing is to have an email provider that uses a secure connection. Trusted email service providers (ESPs) like Pepipost have security measures that do not allow unauthorized users from sending messages.\nGoogle’s Email Transparency report can let you find out the statistics of encrypted mail interaction with Gmail Server. The benefits of an opportunistic TLS are a higher sender reputation and 100% spam free delivery.\nFailure in TLS Handshakes\nThe failure rate of TLS handshakes is a topic of concern for system engineers across the world as it causes authentication and security issues. TLS handshakes can be of two types – one based on RSA and other on Diffie-Hellman. These both work on algorithms and if an algorithm fails, it leads to a failure in the TLS handshake. The bottom line is TLS encryption alone is not sufficient to keep your emails secure and authentic.\nConsidering as a whole, TLS encryption is very important for sending and receiving emails in a secured manner. But, it can fall into some traps and you may suffer a data breach or unsuccessful emails in certain cases. Therefore, it is not a complete solution in case of exceptional situations and you need to handle them on your own.\nBut, the good news is that there are measures/technologies in place that can alleviate the impact of TLS handshakes. TLS false start is one such program where the server and client can\nYou might send an email normally without a secondary level of protection. This could be fine if your email is a general email. However, it becomes a matter of concern if you have to send any confidential data over emails. Although most of the popular ISPs support TLS and ensure double protection of your conversations over an email, you cannot ensure the security at the receiver’s end. If the receiver suffers a data breach or hacking at his end, you cannot control your data from being lost or stolen, even though it was secured through TLS encryption.\nTLS Vs. SPAM\nTLS encryption is assumed to be a secured connection between two ends. It is free from spam most of the time. However, it does not ensure 100% security. There are some companies that have a special kind of spam or anti-virus implemented, which could affect the security of the email message. The whole message may not be encrypted and you may need to ensure the security of the messages while sending them over the internet. Therefore, you must check whether the TLS system is working properly in advance and ensure that there are no loopholes in it.\nAlso, interestingly you can identify SPAM from Email Headers."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:c33ccc5a-ad06-4cba-a6a9-427cd9e2d550>","<urn:uuid:e4a4a932-c2a7-4c42-9ec4-526adda36103>"],"error":null}
{"question":"How does the Mitrovica Rock School bridge ethnic divisions in Kosovo through its music education programs?","answer":"The Mitrovica Rock School connects Serb and Albanian teenagers through music in the divided city of Mitrovica, where Albanians live south of the river Ibar and Serbs live in the north. The school offers daily music lessons in various instruments, runs a mixed band program where ethnically mixed bands learn songwriting and performance skills, organizes training weeks with students from both sides, and provides mixed workshops. Through these programs, the school has produced 44 ethnically mixed bands, with 19 of them writing original songs. Since 2008, approximately 1,100 youth have participated in the school's activities.","context":["Reconciliation and rock & roll\nThe Kosovo conflict has left Mitrovica divided. Albanians live south of the river Ibar, Serbs in the north.\nThe Mitrovica Rock School connects Serb and Albanian teenagers through music. It brings back a music tradition that makes both sides proud. And it invests in the city’s young people.\nWe stand for quality education in popular music, teaching employable skills, and putting the “rock” back in “Rock City.”\nWe restore Mitrovica’s proud music heritage, together.\nWhat we do\n- Daily music lessons in vocals, guitar, bass guitar, keys and drums\n- Mixed band program: a talent-development program where ethnically mixed bands learn songwriting, band coaching, recording, promotional and performance skills from expert local and international trainers\n- Training weeks with students and teachers from both sides of Mitrovica\n- Mixed workshops: a free program where teachers focus on specific material not taught during the regular skills lessons\n- Sound engineering: an intensive free training program teaching live and studio sound engineering\n- Traineeships: on-the-job-training for senior students and talented organizers, aimed at teaching employable skills\nJelena, singer, songwriter and guitarist\n“This project encourages young people from both sides of the bridge to look past their differences and connect via music.”\nThe project Music Connects delivers thousands of music activities to Serb, Albanian, Macedonian, Roma and other youth. We will establish a recording studio in Mitrovica and train sound engineers in Mitrovica and Skopje, increasing cultural participation and cooperation and lowering the barrier for young bands to enter the region’s emerging music scene.\n- Successful Mitrovica Rock School programs: mixed bands, mixed workshops, daily lessons, training weeks, and concerts\n- The integration of minority groups into the program of Music School Enterprise, Skopje’s leading commercial rock school\n- The start-up of Roma Rock School, integrating Roma youth in Macedonian society through inter-ethnic music programs\n- Joint summer schools bringing mixed bands of all three schools together\n- A professional studio at the Mitrovica Rock School for use by musicians and bands from both sides, and a home studio at the Roma Rock School\n- Sound engineering training for selected participants at all three schools\n- Training at all three schools by Fontys Rockacademie\n- A documentary film by HATCHED-MV, to be submitted to film festivals in the region and the EU\nMusic Connects is supported by Creative Twinning, a program of the Netherlands Ministry of Foreign Affairs implemented by the Netherlands Enterprise Agency; the Stability Pact Fund through the German Embassy in Pristina; the Robert Bosch Stiftung; and the Austrian Development Agency.\nIn 2008, the Mitrovica Rock School started as a project at the request of local musicians. The original Mitrovica Rock School project was managed by Musicians without Borders and Community Building Mitrovica, with support from Fontys Rockacademie and IKV Pax Christi.\nWith support from the Matra program of the Netherlands Ministry of Foreign Affairs, the Mitrovica Rock School was able grow from a promising project to a successful organization, and in 2012 the Rock School registered as an independent NGO.\nIn its ten years of existence, some 1,100 youth have attended the Mitrovica Rock School. The school has produced 44 ethnically mixed bands, 19 of which wrote/write original songs."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:377a9cd5-bbc0-4363-94f3-d37a892db4a8>"],"error":null}
{"question":"What are the global impacts of both coral reef protection and MS pain management on affected populations worldwide?","answer":"Coral reefs provide protection to approximately 197 million people across more than 80 nations, with Indonesia (41 million), India (36 million), and the Philippines (23 million) having the largest protected populations. Meanwhile, MS pain affects people globally, requiring comprehensive management approaches including medication, physical therapy, and stress reduction techniques, with general practitioners and neurologists playing key roles in ongoing pain management and emergency care.","context":["Pain in multiple sclerosis\nMS-related pain comes from two main sources in the body:\nAlso referred to as neurogenic or central pain, this is caused by MS-related damage to the brain, spinal cord and nerves. Neurological pain can feel unusual – tingling, pins and needles, tight bands, burning and stabbing are common ways to describe this pain.\nAlso referred to as nociceptive pain, this is caused by damage or changes to the body’s bones, muscles and soft tissues. Examples include pain due to muscle spasms and pain as a result of inactivity or altered posture.\nPain can be chronic, lasting for more than 3 months, or acute, lasting for a shorter period of time. Acute pain is usually related to injury or a short term illness.\nWatch our educational webinar on Managing Pain with MS Nurse – Tim O’Maley.\nThis webinar explains the types of pain that MS may cause and explore both short term and long term management strategies.\nThere are a number of strategies that can be used to help manage MS pain:\nMedications commonly prescribed for MS-related pain fall into five main categories: anti-convulsants, anti-depressants, simple analgesics, strong analgesics, and anti-spasmodics. While medication can help reduce pain, it rarely relieves MS- related pain completely.\nPhysical activity and exercise\nLong periods of rest or inactivity due to pain can lead to a gradual loss of strength and fitness, and difficulty performing day-to-day activities. Regular physical activity and exercise can reverse these effects and help with pain. Physiotherapists and exercise physiologists can assist individuals to develop an exercise regime suited to their needs and ability.\nSlow breathing and relaxation techniques\nSymptoms of stress can actually make pain worse. Slow breathing or other relaxation exercises can help reduce tension and stress. Listening to music may also help, as can other relaxation and breathing practices such as meditation and yoga.\nWhile pain can be disruptive, setting realistic goals and planning can help many people achieve the things they want to do.\nStrategies such as challenging your thinking, problem solving and managing sleep patterns can all help with pain management.\nCreate a pain management plan\nIt is important to develop and maintain a pain management plan that takes into account: who can help with pain; what is being done to manage the pain; when these strategies should be reviewed; and what to do in an emergency.\nGeneral practitioners (GP) can help people with MS to manage their pain on a daily basis and assist with sudden or severe pain. They can also establish if the pain may be caused by something other than MS. People with MS should also consult their neurologist about any new pain, changes in their pain or unusual sensations.\nContact our NeuroAssist Team\nHere to help you understand MS and answer your questions.\nDownload the MSQ Managing Pain fact sheet\nIncludes information, resources and tips to help you manage pain.\nBook a Neurophysio consultation\nFind out how Neurological Physiotherapy and exercise can help with the management of pain.\nFind a support group\nOffering friendship, support and self-help in your local area.\nFind a group now","New study shows that coral reefs provide risk reduction benefits to hundreds of millions of coastal inhabitants around the world\nStronger storms, rising seas, and flooding are placing hundreds of millions people at risk around the world, and big part of the solution to decrease those risks is just off shore. A new study finds that coral reefs reduce the wave energy that would otherwise impact coastlines by 97 percent.\n“Coral reefs serve as an effective first line of defense to incoming waves, storms and rising seas,” said Dr. Michael Beck, lead marine scientist of The Nature Conservancy and a co-author of the study, “200 million people across more than 80 nations are at risk if coral reefs are not protected and restored.”\nPublished today in the journal “Nature Communications,” this study by an international team of researchers from the University of Bologna, The Nature Conservancy, U. S. Geological Survey, Stanford University and University of California – Santa Cruz, provides the first global synthesis of the contributions of coral reefs to risk reduction and adaptation across the Atlantic, Pacific, and Indian Oceans.\n“This study illustrates that the restoration and conservation of coral reefs is an important and cost effective solution to reduce risks from coastal hazards and climate change,” said Dr. Filippo Ferrario, lead author from the University of Bologna.\nKey results from the study:\n- Coral reefs provide substantial protection against natural hazards by reducing wave energy by an average of 97 percent (studies across all tropical oceans).\n- The reef crest, or shallowest part of the reef where the waves break first, dissipates 86 percent of wave energy on its own.\n- The median cost for building artificial breakwaters is USD $19,791 per meter, compared to $1,290 per meter for coral reef restoration projects.\n\"Coral reefs are wonderful natural features that, when healthy, can provide comparable wave reduction benefits to many artificial coastal defenses and adapt to sea-level rise” said Dr. Curt Storlazzi a co-author from USGS. “This research shows that coral reef restoration can be a cost-effective way to decrease the hazards coastal communities face due to the combination of storms and sea-level rise.\"\n“While there are many concerns about the future of corals reefs in the face of climate change,” Dr. Fiorenza Micheli of Stanford University said, “there are still many reasons for optimism about the future of coral reefs particularly if we manage other local stressors such as pollution and development.”\nThe study found that there are 197 million people worldwide who can receive risk reduction benefits from coral reefs alone or may have to bear higher costs of disasters if the reefs are degraded. These are people in villages, towns, and cities who live in low, risk prone coastal areas (below 10m elevation) and within 50 km of coral reefs.\nConservation efforts are most often directed to more remote reefs, however the study suggests there should also be a focus on reefs closer to the people who will directly benefit from reef restoration and management. In terms of number of people who receive risk reduction benefits from coral reefs, the top 15 countries include:\n1. Indonesia, 41 million\n2. India, 36 million\n3. Philippines, 23 million\n4. China, 16 million\n5. Vietnam, 9 million\n6. Brazil, 8 million\n7. United States, 7 million\n8. Malaysia, 5 million\n9. Sri Lanka, 4 million\n10. Taiwan, 3 million\n11. Singapore, 3 million\n12. Cuba, 3 million\n13. Hong Kong, 2 million\n14. Tanzania, 2 million\n15. Saudi Arabia, 2 million\nAdditionally, major investments are being made in artificial defense structures such as seawalls for coastal hazard mitigation and climate adaptation. The study shows that the restoration of coral reefs for coastal defense may be as low as 1/10 the cost of building artificial breakwaters. Reef defenses can be enhanced in a cost-effective manner through restoration, a key factor in protecting small island nations and regions with limited fiscal resources.\nDrs. Beck and Micheli were supported in this work by Pew Fellows Program in Marine Conservation, an effort that has awarded 135 fellowships to individuals from 31 countries for projects to address conservation challenges facing our oceans.\nThe Nature Conservancy is a leading conservation organization working around the world to protect ecologically important lands and waters for nature and people. To date, the Conservancy and its more than one million members have helped protect 130 million acres worldwide. Visit The Nature Conservancy on the Web at http://www.nature.org/.\nThe Pew Fellows Program in Marine Conservation awards recipients US $150,000 for a three-year project to address conservation challenges facing our oceans. The program has awarded 135 fellowships to individuals from 31 countries. The program is managed by The Pew Charitable Trusts in Washington, D.C. www.PewMarineFellows.org\nLeslie Gordon | newswise\nLitter is present throughout the world’s oceans: 1,220 species affected\n27.03.2017 | Alfred-Wegener-Institut, Helmholtz-Zentrum für Polar- und Meeresforschung\nInternational network connects experimental research in European waters\n21.03.2017 | Leibniz-Institut für Gewässerökologie und Binnenfischerei (IGB)\nThe Institute of Semiconductor Technology and the Institute of Physical and Theoretical Chemistry, both members of the Laboratory for Emerging Nanometrology (LENA), at Technische Universität Braunschweig are partners in a new European research project entitled ChipScope, which aims to develop a completely new and extremely small optical microscope capable of observing the interior of living cells in real time. A consortium of 7 partners from 5 countries will tackle this issue with very ambitious objectives during a four-year research program.\nTo demonstrate the usefulness of this new scientific tool, at the end of the project the developed chip-sized microscope will be used to observe in real-time...\nAstronomers from Bonn and Tautenburg in Thuringia (Germany) used the 100-m radio telescope at Effelsberg to observe several galaxy clusters. At the edges of these large accumulations of dark matter, stellar systems (galaxies), hot gas, and charged particles, they found magnetic fields that are exceptionally ordered over distances of many million light years. This makes them the most extended magnetic fields in the universe known so far.\nThe results will be published on March 22 in the journal „Astronomy & Astrophysics“.\nGalaxy clusters are the largest gravitationally bound structures in the universe. With a typical extent of about 10 million light years, i.e. 100 times the...\nResearchers at the Goethe University Frankfurt, together with partners from the University of Tübingen in Germany and Queen Mary University as well as Francis Crick Institute from London (UK) have developed a novel technology to decipher the secret ubiquitin code.\nUbiquitin is a small protein that can be linked to other cellular proteins, thereby controlling and modulating their functions. The attachment occurs in many...\nIn the eternal search for next generation high-efficiency solar cells and LEDs, scientists at Los Alamos National Laboratory and their partners are creating...\nSilicon nanosheets are thin, two-dimensional layers with exceptional optoelectronic properties very similar to those of graphene. Albeit, the nanosheets are less stable. Now researchers at the Technical University of Munich (TUM) have, for the first time ever, produced a composite material combining silicon nanosheets and a polymer that is both UV-resistant and easy to process. This brings the scientists a significant step closer to industrial applications like flexible displays and photosensors.\nSilicon nanosheets are thin, two-dimensional layers with exceptional optoelectronic properties very similar to those of graphene. Albeit, the nanosheets are...\n20.03.2017 | Event News\n14.03.2017 | Event News\n07.03.2017 | Event News\n28.03.2017 | Life Sciences\n28.03.2017 | Information Technology\n28.03.2017 | Physics and Astronomy"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:c0b2d958-f97a-4ea3-abac-e1836423e2cb>","<urn:uuid:0d8c10cc-705b-4691-b769-c9571859e8a9>"],"error":null}
{"question":"Why are prairie plots particularly beneficial for agricultural regions and biodiversity?","answer":"Prairie plots are beneficial because they support pollinators like bees which are crucial for fruit production, provide habitat for rare birds like bobolinks and meadowlarks, and add visual diversity to rural landscapes dominated by corn fields. In winter, they also provide cover and food for local wildlife.","context":["House on the (native) prairie\nA New Richmond couple has transformed their residential property into a restored native prairie, thanks to a Wisconsin Department of Natural Resources program.\nKele and Mike Monteith, who live off County Road K east of New Richmond, signed up for the DNR program about 10 years ago.\nThe North American Wetlands Conservation Act program required the landowners to leave the native grass and flower plantings alone, for the most part, and recommended minimal maintenance of the vegetation.\nThe Monteiths built their home 11 years ago on 26 acres, just a field away from the family homestead where Mike Monteith grew up.\nA short time later, DNR Area Wildlife Supervisor Harvey Halvorsen approached the couple suggesting that they consider planting prairie grass and prairie flowers on a chunk of their land. It didn't take them long to agree.\n\"I'm a believer that you can't build houses everywhere because there wouldn't be any wildlife around,\" Mike Monteith said.\nTo prepare the property for a prairie restoration process, Monteith said DNR officials sprayed the land to kill off all of the vegetation. Then crews came in to scatter the native grass and prairie flower seed.\n\"They provided the seed and they planted it,\" Monteith said. \"We just had to make a 10-year commitment not to plow it up. We couldn't do anything to the land but burn it or clip it.\"\nMonteith said he paid a little extra to add more flowers to his native prairie seed mix.\n\"The seed is kind of expensive and it's hard to find,\" he said. \"But if you don't make it part of the planting right away, it won't do as well.\"\nOnce the prairie was planted, Monteith said the waiting game began.\n\"It takes three or four years before you even see anything,\" he said of the slow process for the prairie to become established.\nBut once the plot near his home matured, the results were amazing, Monteith reported.\nAs each summer approaches, the prairie is alive with many wildflowers. As the warm months tick by, the native grasses reach to the sky and take over the plot.\nThe native prairie now helps attract a wide variety of butterflies, song birds and wildlife to the Monteith's yard. Rare bobolinks and meadowlarks can often be seen flying among the native plants.\n\"There are hardly any left around here,\" he said of the birds. \"They're prairie grass birds. You're not going to have them in town.\"\nThe Monteiths have had sandhill cranes, pheasant, deer and occasional bears frequent their native prairie as well. And the variety of butterflies is so impressive that Kele uses binoculars and a butterfly book to chronicle visitors to their land.\n\"We did this for the enjoyment of it,\" Monteith said. \"Listening to the birds singing in the morning ... seeing the wildlife.\"\nIn the wintertime, the stands of grass also provide cover and a food source for the local wildlife, Monteith noted.\nAs his 10-year agreement comes to an end this fall, Monteith said he's been approached by a local farmer asking if he can rent the land to plant corn or soybeans. The property owners have declined the offer.\n\"I'm not going to do anything with the prairie,\" he said. \"I like it the way it is. It's not about the revenue I can get from the land, it's about Mother Nature.\"\nAccording to Halvorsen, there is currently no local money available for landowners through the NAWCA program. DNR officials are trying to secure some additional funding so more private landowners can participate.\nPeople who own agricultural land can enroll cropland in the federal Conservation Reserve Program and accomplish a similar prairie restoration. They receive annual rental payments for 10 to 15 years from CRP as well.\nIf more prairie plots can be established across the region, Halvorsen explained, everyone benefits. Native flowers are important for the health of pollinators, like bees.\n\"Prairies, prairie wildflowers, and much fruit production depend on insect pollinators,\" he said.\nThe prairie plots also add to the color palette of rural areas in Wisconsin and Minnesota, Halvorsen said.\n\"It provides color and structure very different from the drab, monotypic, huge fields of corn seen everywhere,\" he said. \"I'd like to someday see patches or wide strips of prairie pollinator habitats interspersed within the landscapes of corn and soybeans.\"\nFor more information, contact Halvorsen at 715-684-2914, ext. 113, or Caitlin Smith with the New Richmond office of the U.S. Fish & Wildlife Service at 715-246-7784."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:eb892a17-b95a-42b3-be70-e0b5591ef0b3>"],"error":null}
{"question":"What's the most efficient way to maintain and care for a newly planted Empress Tree?","answer":"To maintain a new Empress Tree, ensure it gets at least 4 hours of direct sunlight daily. Water when the top 2-3 inches of soil becomes dry, but avoid overwatering. Keep weeds and grass 2-3 feet away from the tree in the first year. You can fertilize twice monthly during growing season using organic fertilizer high in nitrogen or balanced tree fertilizer, but only after the first year. If the tree grows less than 4 feet before winter dormancy, cut it to the ground at the start of spring (coppicing). When new shoots emerge, select the largest trunk and remove others. For branch management, pinch off suckers (buds above leaves) until reaching desired branch height.","context":["You have received a young Royal Empress Tree. Do not be alarmed if your tree has no leaves; your tree might have been trimmed for survival during shipping, or it is going into a dormant state. You may be surprised at what you see, so let us tell you what you have and what to do with them. Our foremost desire is for your satisfaction and success in growing your Royal Empress Tree!\nA great deal of care has been taken to package your tree. Still, it has been in a dark box for two to three days, likely handled roughly and possibly exposed to extreme temperatures. Your tree may look a little wilted or dry, but this is common and nothing to be concerned about.\nIf the roots look too dry, sprinkle some water on them. This will give it the water it was lacking when it was traveling through the mail. Once wet, place your tree into a light colored container with good soil and water it. Only put your tree in a container during extreme temperatures (90 degrees and above or freezing ground temperatures). If temperatures are above freezing or below 90 degrees you may then plant your tree(s) directly into the ground. The container should be large enough to accommodate its expansive and fast-growing root system. If not, gently trim back the tree’s roots so that it will fit.\nLeave your tree potted for at least 2 weeks so that it can adjust to your environment. Place it in partial sunshine (at least 4 hours of direct sunlight a day). Your tree will be able to handle direct sunlight once established. When planting, make sure that the roots are fully planted in dirt and that no air comes in contact with them. If you have received your tree(s) during the winter or fall, see planting instructions as listed below.\nPay close attention to keeping your tree cool, its roots moist and protected from direct sunlight, wind, and extreme temperatures.\nRoyal Empress Tree saplings are not like most other type of plants that you have seen. They are basically roots, nearly 95%, and primarily a single taproot. Dormant plants may have no discernable tops (stems and leaves) and may appear as long skinny brown carrots. Energy is stored in the root in the form of plant carbohydrates, sugars, starches, proteins, minerals, water and other organic compounds, similar to a potato or carrot. You may see a short stub of a stem or a brown dried-up stem on dormant seedlings. Actively growing seedlings may have one or more sets of leaves on a green stem. Your young sapling may arrive in a totally dormant state with no sign of buds, or they may have small buds forming on one end and small white roots forming on the opposite end.\nFall and Winter Planting Instructions:\nDormant Empress Tree Winter Planting Directions\nThank you for purchasing your Empress (Paulownia) Tree. In addition to being beautiful, the Empress Tree is one of the most environmentally beneficial trees on Earth. It’s incredibly efficient at absorbing carbon dioxide (greenhouse gases) and releasing large amounts of oxygen into the air we breathe.\nA great deal of care has been taken to package your tree(s). Still, it has been in a dark box for several days, likely handled roughly in transit, and possibly exposed to extreme temperatures.\nYour Royal Empress Paulownia tree is in a dormant state, similar to sleep. It was shipped this way to ensure a higher survival rate at this time of year.\nNo matter what climate you are in, do NOT place your fertilizer in your pot over winter. Instead, save your fertilizer for the springtime. Plant your tree after the last frost or when surrounding plants begin to bud out.\nDO NOT OVER-WATER your Empress Tree . When the top 2 to 3 inches of the potting medium is dry, add water. Do not allow soil to stay soggy. Empress trees will not tolerate over watering when potted. As a rule, let the soil surrounding the plant dry out before watering. If your tree is wet upon arrival, skip the initial watering for two days. Do not let the roots stay saturated when potted. Drooping branches and shriveled, brown leaves are signs of both under and over watering. If under-watered, the leaves will become dry and brittle. If over-watered, the leaves will become black and begin to shrink. They will be soft, not brittle. If this happens, stop watering your tree until it revives. If too much damage has been done, it will grow a new trunk from the base and grow a new tree.\nDig up an area 1 to 3 feet deep and at least 1 to 3 feet in diameter. This will loosen the soil and remove grass. Grass will compete with your tree for the surrounding soil’s nutrients. For best results, mix in potting soil or soil conditioner, especially if planting in clay or poor soil.\nAfter digging your hole, place the tree in the hole and spread the roots out evenly. Surround them with dirt so that no air pockets are present. You can gently press down on the dirt to remove any cavities. Water immediately after planting to get rid of any other air pockets.\nIn addition, you want to plant your tree so that the “root collar” is level with the ground (see Fig. 2). (The “root collar” is the height where the roots effectively become the stem of the tree. It is commonly seen as a line that is lighter bark on top, darker roots on bottom. This is the line where the soil initially came to when your seedling was grown.)\nWe recommend planting your new Empress Tree(s) at least 3 feet from sidewalks. Also, avoid planting your new tree(s) over septic systems. You need to plant at least 10 feet from building structures. Be sure to select a sunny area with free draining soil. Your new Empress tree(s) will not thrive in a spot that holds excess water. Avoid areas that stay soggy after heavy rains.\nImportant Summer Information:\nIf you are experiencing severe drought, avoid planting your tree(s) in the ground. It is suggested that you plant your tree in a 3-5 gallon, light-colored pot in the shade. Once the temperature drops or the drought breaks, you can transplant your tree to the area of your lawn that you want.\nLet your tree grow for one entire year. If your empress tree did not grow at least 4 feet before winter dormancy, we recommend that you cut it to the ground at the very start of spring (a process called coppicing). This may seem odd, but it will grow a very straight, beautiful tree. Your tree(s) will more than make up for the lost growth in the first few weeks. We have seen some Empress Trees grow as many as 20 feet in the first year after being cut back to the ground.\nDon’t worry about being exact. This process (coppicing) can be done any time of year, though we recommend spring. The new stump will have several trunks coming up from it. Select the largest trunk and pinch the others off. This one will grow at a very rapid rate and will grow into a very straight tree.\nEmpress Trees love fertilizer. Organic fertilizer high in nitrogen works well. You can use Miracle Gro or a balanced tree fertilizer. You can fertilize twice a month in the growing season. Stop fertilizing before the tree goes back into dormancy. Additional fertilizing should only be done after the first year.\nKeep weeds and grass two to three feet away from the tree in the first year. Pull the weeds initially, and then you can use a growing mat or mulch. Do not spray Roundup® on a young tree, and be careful that wind does not blow chemical drift on the tree. During the first year, weeds and grass rob moisture away from young trees and can cut their growth rate in half.\nThe Royal Empress Tree is not a desired food for deer. However, if nothing more appetizing is available, they have been known to eat the growth bud at the top of the stem. If you think this may be a problem, sprinkle some Deer Away® on the top of the tree until it grows 6 feet tall (beyond the reach of the deer).\nLarge leaves grow in pairs up the tree (one on each side). Every few inches up the tree, you will see a new set. These should be left on the tree to maximize photosynthesis. These leaves will fall off later. Above each leaf on the tree’s stem, you will see a little bud growing. This is referred to as a “sucker.” It is a permanent branch trying to grow. Pinch these off until you get to the height where you want your first branches to grow. The higher you let your branches start, the higher your clearance will be under the branches (see Fig. 3).\nYou should start seeing flowers blooming within the first or second year. You will see buds on the tree through the winter. Flowers will bloom at the very beginning of spring.\nInsects and Disease:\nThe best defense is a healthy tree. Empress Trees are very hardy. Good soil, proper feeding, and correct watering are the keys to its prosperity. If worms bite holes in the leaves, you can sprinkle Sevin-10 Dust® on them. These little bites do not affect the tree since it is growing at such a fast rate and putting on so many new leaves.\nThe tree is not poisonous. In fact, its leaves are fed to livestock as a high protein fodder.\nDuring late fall and winter, your tree will go dormant. The leaves will fall off and the stem will turn brown. Nothing will be happening above ground, but the roots will continue to grow below, especially during nice days. This winter root growth will help accelerate growth when spring comes.\nInteresting Facts about Your Paulownia Empress Tree\nEmpress wood is the second most valuable wood grown in the US, behind only Cherry.\nThroughout the Orient, the Empress tree is planted at the birth of a daughter. When she marries, the tree is cut down and used to build a wedding chest and gifts.\nAncient lore has it that the legendary Phoenix flew across the Orient and would only land on Empress Trees – bringing good fortune to the nearby household.\nEmpress lumber is farmed on plantations rather than taken from old growth forests. It thrives on marginal or even toxic soil.\nEmpress roots go down as far as 40 feet which helps to regulate the water table as well as remove soil salinity and ground pollutants. Empress trees are also used to clean toxic soil and absorb animal waste.\nGiant leaves drop each winter, releasing nitrogen and increasing soil fertility.\nIn the orient, Empress trees are planted between row crops and have improved yields by as much as 30%.\nYour cloned tree is non-invasive; its seeds are virtually sterile.\nEmpress trees save forests by producing sawn timber in 7-12 years and growing 2-4 times more lumber than most other commercial trees in the same time period. This is vital as the supply of exotic and hardwood trees rapidly diminishes.\nAfter being harvested, a new Empress tree grows back from the stump and uses the same well-established root system. This saves post-harvest clearing costs, land erosion and runoff. The same stump can re-grow 7-10 full sized trees.\nThe technology that created your Super Tree is the result of a major international research project that planted millions of Empress trees throughout China, India, and the Philippians."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:d95c9029-7604-43b6-84d9-df651edc184a>"],"error":null}
{"question":"How do astronomical factors influence Earth's climate patterns historically, and what capabilities do modern climate models have in simulating these long-term changes?","answer":"Astronomical factors significantly influence Earth's climate through variations in solar radiation. The Milankovitch cycles, which include precession (21,000-year cycle), obliquity (41,000-year cycle), and eccentricity (100,000-year cycle), explain long-term climate changes through variations in Earth's orbital geometry and axial tilt. These cycles affect the amount and distribution of solar radiation reaching Earth, with geological data supporting their impact on polar ice sheet advances and retreats over the past two million years. Modern numerical climate models can simulate these long-term changes through physical equations and complex calculations. These models work on a three-dimensional grid and can simulate past conditions (hindcasting) to test their reliability by comparing results with observational data. However, models have limitations due to computing resources, requiring compromises in spatial resolution, temporal resolution, and system complexity. They must also account for multiple components of the climate system, including the hydrosphere, cryosphere, land surface, and biosphere, through ensemble simulations that calculate mean values from multiple model runs to provide more accurate results.","context":["Global Climate Patterns, Global Climate Change\nThe long-term distribution of heat and precipitation on Earth's surface is called global climate. Heat from the sun keeps the Earth's average temperature at about 60°F(16°C), within a range that allows for biological life and maintains the planet's life-sustaining reservoirs of liquid water. Astronomical variations and atmospheric shielding cause incoming solar radiation to fall unevenly on the Earth's surface. Ocean currents and winds further redistribute heat and moisture around the globe, creating climate zones. Climate zones have characteristic annual precipitation, temperature, wind, and ocean current patterns that together determine local, short-term weather, and affect development of ecologically adapted suites of plants and animals. Changes in the astronomical, oceanographic, atmospheric, and geological factors that determine global climate can lead to global climate change over time. The term climate is reserved for regional patterns of temperature and precipitation that persist for decades and centuries. Local atmospheric, oceanic, and temperature phenomena like storms and droughts that occur over hours, days, or seasons, is generally referred to as weather.\nAstronomical factors affecting global climate change\nEnergy from the sun drives the Earth's climate. Changes that affect the amount of solar radiation reaching the planet, called insolation, and that alter the distribution of sunlight on its surface, can cause global climate change. Each minute, the Earth's outer atmosphere receives about two calories of energy per square centimeter of area, a value known as the solar constant. In spite of its name, the solar constant varies over time. Astronomers have, for example, observed a correlation between the solar constant and changes in the pattern of sunspots, or solar storms, on the Sun's surface.\nThe Earth's position with respect to the Sun over time affects its climate. During its annual circuit around the sun, the Earth's present elliptical orbit brings it closest to the sun in January (perihelion), and carries it farthest away in July (aphelion). The planet receives about 6% more solar energy in January than in July. The Earth's axis, a line through the poles, is tilted 23.4° with respect to the sun. Consequently, the Sun's rays strike the northern hemisphere most directly on June 21st, the summer solstice, and the southern hemisphere most directly in December 21st, the winter solstice. The equinoxes, on April 21st and September 21st, mark the dates when the Sun shines directly on the equator, and day and night are the same length around the globe. Orbital geometry and axial tilt together determine the Earth's pattern of seasons. Variations in this astronomical geometry would cause climatic variations.\nIn the 1920's, the Serbian astronomer, Milutin Milankovitch, proposed an astronomical explanation for long-term, cyclical global climate changes that caused the Pleistocene \"ice ages\". By observing variations in the Earth's orbital geometry and axial tilt, and calculating the time for a complete cycle of change to occur, Milankovitch predicted a pattern of varying insolation and global climate change. According to his theory, three socalled Milankovitch cycles—precession, obliquity, and eccentricity—repeat approximately every 21, 41, and 100 thousand years, respectively. The 21,000-year precession cycle occurs because the direction of the Earth's spin axis changes over time, much in the way a spinning top wobbles. This phenomenon, called the precession of the equinoxes, causes a particular season, northern hemisphere summer for example, to occur at different places along the Earth's orbital path, and hence, at a different time of year. During the 41,000-year obliquity cycle, the tilt angle of the Earth's axis changes, altering the intensity of the seasons. Changes in the shape, or eccentricity, of the Earth's orbit cause the 100,000-year Milankovitch cycle. The Earth's present orbit is almost circular, so the difference in insolation between aphelion and perihelion is fairly minor. When the orbit becomes more elliptical, the Earth receives more radiation at the perihelion, and less at the aphelion. The eccentricity cycle also modulates the precession and obliquity cycles; the most intense northern hemisphere summer, for example, would occur when the June solstice coincided with the perihelion of an eccentric elliptical orbit, and the axial tilt was at its highest.\nGeological data from the most recent portion of the Earth's history seem to support Milankovitch theory. The pattern of insolation variations that Milankovitch predicted generally matches the pattern of polar ice sheet advance and retreat since about two million years ago. Observations of northern hemisphere glacial features, deep sea cores that record the amount of water stored in glacial ice, and sea-level records all corroborate the timing of global cooling and warming predicted by Milankovitch theory. The correlations are more difficult to prove farther back in geologic history.\nGeological factors affecting global climate\nGeological changes on the Earth's surface can also affect global climate. The distribution of continental landmasses and ocean basins affects the pattern of global atmospheric and oceanographic circulation, and the shape, or topography, of the Earth's surface directs winds and ocean currents. According to the widely accepted, and well-supported theory of plate tectonics, the continents move, ocean basins open and close, and mountain ranges form over time. The continents have assumed new configurations on the Earth's surface throughout geologic history, and geologists know, from examination of fossil environments and organisms, that the movement of landmasses had significant climatic effects. For example, during the Cretaceous Period, about 100 million years ago, continents covered the poles, and a warm ocean called Teethes circled the equator. An intense period of volcanic activity added insulating gasses to the atmosphere. The Cretaceous was the warmest and wettest period in Earth history. There is no evidence of Cretaceous polar ice caps, shallow seas covered many continental interiors, and tropical plants and animals lived on all the continents. The collision of the Indian subcontinent with Asia, and formation of the Himalayan mountain range about 40 million years ago is another example of a plate tectonic event that caused significant climate change. The Himalayas obstruct equatorial winds and ocean currents, and contribute to major climatic phenomena, namely the monsoon seasons of southern Asia and the Indian Ocean, and the El Niño Southern Oscillation in the Pacific Ocean.\nChanges in atmospheric composition and anthropogenic global warming\nThe Earth's climate is strongly affected by the way solar radiation is reflected, absorbed, and transmitted by the atmosphere. Presently, about 30% of the incoming solar energy reflects back into space, the atmosphere absorbs about 20%, and the remaining 50% reaches the Earth's surface. The major gaseous components of Earth's atmosphere are nitrogen, oxygen, argon, and carbon dioxide. Other components include relatively small amounts of neon, helium, methane, krypton, hydrogen, xenon and ozone gases, water vapor, and particulate matter. Except for relatively uncommon natural events, such as volcanic eruptions, the composition of the atmosphere stays constant over long periods of time.\nThe structure and composition of the atmosphere function to maintain the Earth's surface temperature within the phase boundaries of liquid water, and to protect organisms from damaging ultraviolet radiation. Gases, like ozone, in the outer atmosphere reflect or absorb much of the incoming short-wavelength solar radiation. Much of the sunlight that reaches the Earth's surface is re-radiated into the atmosphere as longer-wave-length infrared energy, or heat. Gases in the middle and lower atmosphere, namely carbon dioxide and water vapor, absorb this infrared radiation, and the temperature of the atmosphere increases, a phenomenon known as the greenhouse effect. This heat, trapped in the atmosphere, drives atmospheric and oceanographic circulation, keeps the oceans liquid, and maintains global climate zones. The greenhouse effect makes the Earth livable for biological organisms, including humans.\nIn the last century, humans have burned large quantities of fossil fuels like coal, oil, and natural gas to operate factories, generate electricity, and run automobile engines. Because carbon dioxide is always produced during the combustion of a carbon-based fuel, these activities have significantly increased the concentration of that greenhouse gas in the atmosphere. Many scientists now believe that higher concentrations of carbon dioxide will enhance the greenhouse effect, and lead to global warming. If global warming should occur, a number of terrestrial changes could follow. Some simulations predict melting of the polar ice caps, increasing volume of water in the oceans, and inundation of coastal cities. Models also show changes in ocean currents and wind patterns and redistribution of the Earth's major climate zones. Such events would have severe consequences for human agriculture, fishing, and civil planning, as well as for the natural environment. The complexity of the inter-related systems that create global climate, however, makes predicting the climatic effect of increased atmospheric carbon dioxide extremely difficult. The issue of anthropogenic global climate change remains a subject of heated debate among scientists and policy makers.\nSee also Atmospheric circulation.\nAhrens, C. Donald. Meteorology Today. 2nd ed. St. Paul, MN: West Publishing Company, 1985.\nEagleman, Joe R. Meteorology: The Atmosphere in Action. 2nd ed. Belmont, CA: Wadsworth Publishing Company, 1985.\nLin, Charles. The Atmosphere and Climate Change. Dubuque, IA: Kendall/Hunt Publishing Company, 1993.\nLutgens, Frederick K., and Edward J. Tarbuck. The Atmosphere: An Introduction to Meteorology. 4th ed. Englewood Cliffs, NJ: Prentice Hall, 1989.\nNewton, David E. Global Warming. Santa Barbara, CA: ABC-CLIO, 1993.\nOpen University Course Team. Ocean Circulation. Oxford: Pergamon Press, 1993.\nPress, Frank, and Raymond Siever Understanding Earth. Chapter 14: Winds and Deserts New York: W.H. Feeman and Company, 2001.\nJones, P. D., \"The Climate of the Past 1000 Years,\" Endeavour. (Fall, 1990): 129–136.\nUnited States Naval Observatory. \"The Seasons and the Earth's Orbit-Milankovitch Cycles.\" Astronomical Applications Department. August 21, 2000 [cited March 14, 2002]. <http://aa.usno.navy.mil/faq/docs/seasons_orbit.html>.\n- Global Positioning System\n- Global Climate - Global Climate Patterns\n- Global Climate - Global Climate Change\n- Other Free Encyclopedias","What are numerical models?\nNumerical ocean and climate models are physical equations (such as conservation of energy, mass, momentum, …) that describe the state of the ocean or the climate system. Changes of different variables (such as temperature, salinity, pressure, etc.) on a three-dimensional grid are calculated by supercomputers from time step to time step. Imagine the grid like pixels on a digital photo. Models provide a simplified image of reality. Nevertheless, they provide valuable insights about the impacts of natural as well as human influences on the climate system, and help to understand the underlying processes. For instance, model simulations have proven that global warming of the last decades is caused by human emissions of greenhouse gases.\nApplications of models\n- Simulating future changes\nThe application of models to simulate the future impacts of climate change is crucially important for society. Models can provide insights about sea level rise, about changes of the ocean currents, and impacts on marine ecosystems. Therefore, models are essential tools to develop adaptation strategies.\n- Understanding the ocean and climate system\nModels can be used to investigate processes and interactions in the ocean and climate system, as well as their causes and effects. Examples are the influx of meltwater of the Greenland ice sheet and the effect on the ocean currents, regional impacts of fluctuations of the ocean currents, or the role of changing greenhouse gas emissions for sea level rise.\n- Extending observations in space and time\nOcean observations are complex and expensive and therefore sparse. The Atlantic circulation is monitored since the 1990s at a few key areas with moored sensors. Models can extend the measured data in space and time, and therefore contribute to interpret the observations. This is how changes in the ocean over the last decades were detected.\n- Improving the reliability of models\nThe quality of model simulations can be tested and improved by modelling past conditions of the ocean and climate, and comparing the simulations with observational data. This is known as hindcasting. Only if a model provides simulations of past events that resemble reality, it can be assumed that the model will also give reliable projections of the future.\nHow does an ocean model work?\n1. An ocean model consists of physical equations of:\n- ocean-atmosphere and ocean-land interactions (such as incoming solar radiation and outgoing radiated heat, evaporation and precipitation, river runoff, wind generated waves and currents, …)\n- movements of the ocean (such as horizontal currents and vertical convection)\n- three-dimensional processes of mixing and dissipation ranging in scale from molecules to entire ocean basins\n2. Boundary conditions at the ocean margins:\nThe model equations are solvable inside the ocean margins. Boundary conditions determine how the ocean interacts with the environment outside its margins. The margins are:\n- ocean basin geometry\n- bottom topography\n- ocean surface as the interface to the atmosphere\n3. Initial conditions of the ocean:\nInitial values of temperature, salinity, and current velocity must be inserted into the model.\n4. Forcings changing the condition of the ocean:\nTo get to the next time step, the following forcings are applied to the initial conditions of the ocean:\n- Shortwave and longwave radiation as well as heat exchange between ocean and atmosphere at the ocean surface change the water temperature\n- Evaporation and precipitation at the ocean surface change the salinity\n- Land surface runoff (e.g. melt water, river water, rain water) at the margins changes the salinity\n- Wind moves surface currents of the ocean\n- Tides move the ocean\nThe newly calculated conditions of the ocean become the initial conditions for the following time step.\nThe climate system consists of five components interacting with each other:\n- hydrosphere (oceans, rivers, lakes)\n- cryosphere (all frozen components of the earth system)\n- land surface\n- biosphere (the space on planet earth that is inhabited by organisms)\nTo model the climate system, several component models are coupled with each other – typically an atmosphere model, an ocean model, a land model and a sea ice model.\nModels are generally used to simulate the future climate until 2100. However, the future state of the climate is largely dependent on the development of human greenhouse gas emissions. Climate projections of the Intergovernmental Panel on Climate Change (IPCC) therefore use model scenarios that include emissions and concentrations of greenhouse gases, aerosols and chemically active gases, as well as land use/land cover. These scenarios are called Representative Concentration Pathways – RCPs. They range from strong reductions of greenhouse gas emissions (RCP2.6) to continuously increasing emissions to the end of the 21st century (RCP8.5). The following projections of global warming were published in the Special Report on the Ocean and Cryosphere:\n|Scenario||2031 – 2050||2081 – 2100|\n|RCP2.6||1.6 (1.1 – 2.0)||1.6 (0.9 – 2.4)|\n|RCP4.5||1.7 (1.3 – 2.2)||2.5 (1.7 – 3.3)|\n|RCP6.0||1.6 (1.2 – 2.0)||2.9 (2.0 – 3.8)|\n|RCP8.5||2.0 (1.5 – 2.4)||4.3 (3.2 – 5.4)|\nLimitations of models\nSimulations of modern climate models require substantial supercomputing resources. Due to limitations in those resources, compromises must be made in three main areas:\n1. Model resolution\nThe spatial resolution of a model is the size of its grid cells, measured in degrees of latitude and longitude or in kilometers. The temporal resolution of a model is the time step. High resolution models provide much more detailed information and more realistic simulations, but they require a lot more computing resources. Every halving of the grid spacing requires about ten times as many computations. Climate models used by the Intergovernmental Panel on Climate Change have a resolution of 1 – 2 degrees for the atmosphere and of 1 degree for the ocean.\nProcesses like ocean eddies or clouds are too small to be resolved in climate models. These processes are “parameterized”, meaning their effect is represented by a simplified process in the model. Parameterizations are crucial for realistic model simulations. Without parameterizations, a model ocean with a weak ocean current could locally warm up more and more through heat uptake. In the real ocean however, turbulent diffusion would dissipate the heat.\nFor more realistic regional simulations of climate change, high resolution regional models are integrated into global climate models. Through continuous development, regional models become available for more and more regions.\n2. Complexity of the climate system\nThe significance of the numerous different processes in the climate system depends on the considered time scales. On short time scales, the climate is influenced by volcanic eruptions. On time scales of days to thousand years, the ocean and the atmosphere determine the climate. On time scales of millions of years, the location of continents and the shape of ocean basins play an important role on the climate. Increasing complexity of a climate model results in higher computational costs. Therefore, some processes of the real climate system have to be omitted in a model. However, through technical advancement, climate models become increasingly more complex.\n3. Ensemble simulations\nAn individual model simulation represents just one possible pathway that the climate system could take. Therefore, small deviations in the model formulation or in the initial conditions can have huge impacts. The mean value of a multitude of model runs often fits better to observations than the result of a single model run, because errors can cancel each other out. Therefore, it is necessary to calculate the mean value of multiple model runs with slightly varying initial conditions (such as slightly different temperatures). This method is called ensemble simulation. Alternatively, a series of simulations can be carried out with different models, and the results are averaged (multi-model ensemble simulation). Both methods increase the computational costs.\nOcean model requirements to get climate change right\nFor realistic climate projections, the ocean component of a climate model has to fulfill the following requirements:\n- correct heat and carbon dioxide uptake\n- good representation of the ocean currents including the Meridional Overturning Circulation\n- vertical mixing processes and deep water formation in small, local regions comparable to observations\n- good parameterization of small scale processes that are not resolved in most climate models, such as ocean eddies\nData assimilation is a technique to combine observational data and model simulations to produce an optimal estimate of the state of a system. The observational data is used to correct the model simulations. An analogy for data assimilation is: “Driving with your eyes closed: open eyes every 10 seconds and correct trajectory” (Alan O’Neill, ESA). Data assimilation was first developed for weather forecasts. For realistic forecasts, weather models require initial conditions resembling the current atmospheric conditions as good as possible. Now, data assimilation is also used to provide the best possible initial conditions for climate models.\nFuture projections of climate\nModel projections of the new Special Report on the Ocean and Cryosphere of the Intergovernmental Panel on Climate Change reveal the risks of delayed action to reduce greenhouse gas emissions. Global warming through greenhouse gas emissions has already reached 1°C above the preindustrial level, resulting in serious consequences for people and ecosystems:\n- The oceans are warmer, more acidic, and less productive.\n- Glaciers, ice sheets and permafrost are melting.\n- Rising sea levels are causing more severe extreme events at the coasts.\nThe impact of climate change depends on the future development of greenhouse gas concentrations. The model projections show the benefits of fast and effective action toward sustainable development. More info here"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:9494f419-b65f-4de4-8b7e-7072441d28d2>","<urn:uuid:14cd063f-159e-44ac-a581-532b0854ae40>"],"error":null}
{"question":"MDF板材在家具制造中有什么优势 (what are the advantages of MDF boards in furniture manufacturing), and what potential health concerns should be considered when using them in indoor spaces?","answer":"MDF boards are highly versatile in furniture manufacturing, being formed through compression of wood fibers with organic bonding compounds under high pressure and temperature. They are ideal for producing kitchen furniture, room furniture, cabinets, wall panels, and interior finishing elements. However, health considerations must be taken into account, as building materials can impact occupant health. Like other building materials, MDF boards should have Health Product Declarations (HPDs) to ensure transparency about their chemical composition and potential health effects on building occupants. HPDs act as ingredient labels for construction products, helping identify any impacts they may have on human health, such as headaches, asthma, or other health issues.","context":["Based on the materials we get, such as freehand drawings, renderings or descriptions, our design office develops detailed designs (also known as preliminary designs). To implement the project, we use advanced programming tools that allow us to create 3-D models, including individual components and technologies used.\nThe preparation of veneer, due to its thickness, requires not only extensive experience, but also the use of appropriate, precise machines. The first stage of veneer preparation is milling. In order to avoid visible joining of leaves, manifested by a sunken varnish on the joining line, we use very precise high-speed milling cutters with diamond tools.\nBasic construction material when making furniture. Chipboards are made by pressing wood chips with the addition of resins. At present, most of the production is made of three-layer boards. Looking at the internal cross-section, the layer is made of coarser fraction chips and there are free spaces, while the outer layers consist of a small fraction and are much more compacted. This structure makes the board lighter, more durable with smooth outer surfaces. It merits remembering that in addition to the standard board, there are also versions with increased resistance to moisture and low inflammability. Boards with increased resistance to moisture can be used primarily in kitchen and bathroom furniture, but also in all furniture and buildings intended for use in tropical climates.\nHard-inflammable tiles are used inside rooms for office furniture, rooms, doors and partition walls, as well as in public buildings such as hospitals, airports, vacation houses, theatres, hotels, etc.\nThe second structural material of furniture after the chipboard. MDF boards are formed as a result of compression of wood fibres with the addition of organic bonding and curing compounds under high pressure and temperature conditions. MDF boards are designed for the production of kitchen furniture, room furniture, cabinets, interior finishing elements, wall panels, coffers, finishing strips, furniture and woodwork.\nLaminated boards are chipboards or MDF boards, covered on at least one side with decoratively printed papers, saturated with thermosetting resins in the laminating process. During this process, the structure of the board is also prepared. The total thickness of the decorative layer is approx. 0.1 mm.\nNotably, if an MDF is used as a primer, the word “MDF” should be included in the name, because by default, chipboard is used as the undercoat.\nIt is also necessary to distinguish the laminated board from the board covered with HPL laminate. These products have a completely different purpose, technical characteristics and price. Laminated boards due to the available wide range of colours and textures of décors are widely used in interior design, for home furniture, partition walls, wardrobes, office and hotel furniture, countertops, etc.\nWood is a natural material obtained from felled trees by formatting and drying. Wood has always been synonymous with luxury. In relation to the boards, it is lighter and more durable, but its disadvantage is greater sensitivity to moisture and temperature. Nowadays, almost every kind of wood is used for the production of furniture, with exotic wood becoming more and more popular, which gives the furniture an exclusive and unique look.\nPlywood is made with plies of wood veneers, which are glued alternately longitudinally and transversely. Because of the need to compensate for stresses, the plywood should consist of an odd number of layers. The most popular wood in the production of plywood is birch, alder and pine. Often, the noble wood species are used for the outer layers.\nIn furniture industry, plywood is used both in the production of leisure furniture and box furniture. The most popular furniture made of plywood includes dressers, desks, armchairs and sofas, tables, tables, chairs and benches. Countertops and fronts are also gaining popularity.\nHPL laminated is a composite material consisting of layers of paper impregnated with thermosetting resins, combined at high temperature and under the influence of high pressure.\nLaminates are used to refine panels, which are the basis for the construction of furniture, in particular particle board or MDF. The thickness of the laminate is between 0.6 and 0.8 mm. Laminate is a flexible mechanically strong material.\nDue to these features, HPL laminates are widely used in the production of living room, bathroom, kitchen, shop furniture, office furniture, hotel and reception desks, wall panels, countertops, desks, internal doors etc. An example confirming the strength of HPL laminates can be covered desk tops, which usually do not lose their veneer even after 5 years and look much better compared to laminate tops.\nThe material is popularly called according to the brand of the largest producer, namely “Corian”. A mineral plate is a material made of mineral particles joined with a resin (acrylic, epoxy or polyester) with the addition of a dye. The great advantage of this material is homogeneity – the cross-section looks exactly the same as the surface – and the availability of adhesive masses with filling properties and matching colour, so that elements can be joined together without visible “seams”. In addition, mineral plates can be easily formed after heating to 140°C, and after cooling they retain their shape. An additional advantage of this material is the lack of pores, therefore their surface prevents the growth of bacteria and formation of spots. Their relatively high price is compensated by the longevity and ease of repairing any damage. Minor scratches or tarnishing can be removed using re-grinding and in the worst case, starting from low gradations.\nIn the case of damage caused by a impact, you can mill the wheel in which the damage is located and paste a new piece of material. Mineral plates are becoming more and more popular and are widely used not only in kitchens or bathrooms but also in service and public facilities – in restaurants, hotels, offices, shops, banks, petrol stations and health centres.\nThe veneer is a very thin, 0.5 mm to 0.8 mm piece of natural wood, obtained during “pushing” the trunk, i.e. cutting off thin layers from the trunk. Each of the layers is commonly called a “leaf”. The leaves from one trunk are combined in packs, which makes the pack contain leaves with the same properties, in particular the same drawing of rings and shade. The combination of leaves in a larger plane requires not only a lot of experience, but also very precise tools. The veneer is used primarily for finishing the furniture surface, because veneered furniture has an interesting appearance, but also longer durability compared to ordinary veneers.\nThe piles are similar to the veneer panels of natural wood, however, they differ in thickness, because the veneers are 1 to 3 mm thick and have a rather technical application. Piles are usually obtained from soft wood in the peripheral cutting process.","Could your furniture, flooring or finishes impact occupant health? The components of some common materials have been linked to headaches, asthma, long-term reproductive effects and even cancer. That’s why the focus of sustainability has turned decidedly indoors – specifically, toward occupants – now that Health Product Declarations (HPDs) have been recognized in LEED v4.\nHPDs are a standard format for reporting product content and associated health information of building products and materials. Think of them as an ingredient label for construction products and interior furnishings to help identify the impacts they may have on human health.\nIf it sounds straightforward, it’s not. The market is flooded with building products that claim to be “green” or “healthy,” making it difficult to sift through myriad environmental claims. Compounding the problem is the overabundance of third-party product certification programs available (such as Cradle to Cradle, ENERGY STAR, FSC, GREENGUARD and BIFMA’s level) – none of which use a consistent method for evaluating a material’s composition or human health impacts.\nWhy Use HPDs?\nBreeze Glazer, LEED AP BD+C, Sustainable Design Leader, Research Knowledge Manager and Senior Associate at Perkins+Will’s New York office, says there are currently so many building product certifications on the market that it’s difficult to know which one to use for a particular application. “I think it makes sense to get to that single level of standardization for reporting out the chemical composition and health issues related to materials,” he observes.\nThat’s part of the reason the USGBC made the move to reward product disclosure by including credits in the Materials & Resources (MR) category of LEED v4 for projects that utilize products with HPDs. It streamlines the decision-making process and gives project teams an apples-to-apples comparison of building products for LEED projects.\nWhat Does This Mean for FMs?\nFirst, it creates transparency in the product specification process. By disclosing ingredients in products and furnishings, material specifiers can know with certainty what chemicals are being put into a building. Second, it opens the door to understanding the impact those products and chemicals have on building occupants and helps building owners and operators make more informed decisions.\nFor example, while it’s commonly known that flame retardants contain chemicals that are harmful to humans, what may be surprising is how prevalent and dangerous they really are. A recent study from Perkins+Will titled “Healthy Environments: Strategies for Avoiding Flame Retardants in the Built Environment” reveals the link between flame retardants and a host of negative health effects.\n“Diabetes, neurobehavioral and developmental disorders, cancer, reproductive health effects, and alteration in thyroid function have all been associated with exposure to flame retardants,” the report reveals. Additionally, the Perkins+Will study cites research indicating that 31 flame retardants have been discovered in building and household products, 51 in the indoor dust or air and 33 in people.\nBut aren’t flame retardants required by building codes, and don’t they save lives? Yes and no.\nTechnical Bulletin 117 (TB117), the de facto flammability standard in North America, has been applied to furniture and textiles since 1975, which requires products with fillers such as foam to withstand exposure to an open flame for 12 seconds (better known as the Steiner Tunnel Test). As a result, furniture and textile manufacturers have treated their products with petroleum-based flame retardants for years.\nHowever, the Chicago Tribune exposed a major controversy with regard to the safety and effectiveness of flame retardants in 2012. The newspaper’s report revealed a deceptive campaign by the tobacco and chemical industries to promote the use of flame retardants in spite of flawed research that showed little evidence of their effectiveness. A month after the Tribune series appeared, California Gov. Edmund G. Brown Jr. directed the Bureau of Electronic and Appliance Repair, Home Furnishings and Thermal Insulation to revise TB117 for improved fire safety without the need for flame retardant chemicals. As a result, a new regulation – TB117-2013 – is now in effect that can be met without the use of flame-retardant chemicals, although it does not ban them from use.\nThankfully, a number of alternative, petroleum-free products are available on the market which effectively inhibit the spread of fire without the harmful effects on human health. (For a list of flame retardant alternatives, visit: transparency.perkinswill.com.)\nWhy Using HPDs Makes Sense\nFacility executives have a greater responsibility than ever before to understand the effects of the products they purchase and install in commercial buildings.\n“As we learn more about the health effects of the chemicals that go into these products, we have to broaden our awareness,” explains Suzanne Drake, LEED AP ID+C, EDAC, Senior Interior Designer, Associate at Perkins+Will. “In addition to durability and performance, we also have to ask the questions, ‘What’s in the stuff? What’s the likelihood of it impacting my client in their day-to-day use of it? How does this affect the installer? How does it affect the people who make it? How does it affect the people who have to get rid of it when we’re done with it?’ We have to broaden what we’re looking at to encompass a bigger picture.”\nWhile the focus on material health may seem to add another layer of complexity to the design and construction process, what’s clear is that the industry has embarked on a journey to the next frontier in sustainability.\n“One thing is for sure, we have entered a new age of market transparency, and it has changed the conversation about building materials for good,” writes Bill Walsh, founder and executive director of the Healthy Building Network in a 2013 blog post. “We are now having the right conversation about how to better understand the products we build with; how to make better, more informed decisions; and how to catalyze the resources of the building industry to promote the best environmental health outcomes and societal well-being for all.”\n3 ways to account for occupant health in your purchasing process\n||The Pharos Project\n|Read the HPD Open Standard to familiarize yourself with how participating manufacturers report product contents and health information.\n||Click on “Search Products” to view HPDs from top manufacturers of products from concrete to cleaning solutions.\n||Google, Perkins+Will and other industry titans use Pharos to inform material selection. Choose from the Building Product Library for product-specific information, the Chemical and Material Library for substances of concern and endangered wood species, or the Certification and Standards library to learn more about how the environmental and health impacts of building materials are classified.\nRobert Nieminen is a contributing editor for BUILDINGS."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:94f05ea4-ecc7-451f-be16-62875f2191dc>","<urn:uuid:f6680c7e-013f-43d7-8f13-91fed26af5a0>"],"error":null}
{"question":"Could you explain what types of room acoustic problems speaker placement helps with, and how fabric acoustic treatments can be used alongside speaker placement to improve sound quality? I come from recording studio background and want understand this better.","answer":"Speaker placement addresses two main acoustic challenges: stereo imaging/soundstaging and accurate bass response. For imaging, speakers are typically arranged in an equilateral triangle with the listening position, allowing for depth, width and height in the sonic space. For bass, placement must account for room modes and SBIR (speaker-boundary interference response). Fabric acoustic treatments can work together with proper speaker placement - particularly sound-absorbing fabrics like velour and wool serge used in curtains and wall panels. These fabrics help control reverberation time, improve sound clarity, and enhance speech intelligibility. The combination of optimal speaker placement and strategic fabric acoustic treatments allows for maximizing the sound potential of an audio system.","context":["Speaker placement seems as much art as science. A lot of ink has been spilled covering the countless speaker placement strategies being used and favored in the audiophile and pro audio communities. As such, there is already an excellent selection of resources on GIK’s website about room setup and speaker placement, but this is an interesting enough topic that I wanted to dig a little more deeply into some of my favorite speaker placement strategies in the face of the two main problems we must consider for quality sound reproduction.\nTwo competing problems\nSince the introduction of stereophonic playback systems, one of the main concerns with good speaker placement is stereo imaging, or soundstaging. Different people will use these terms differently, and there is a lot of overlap between the two ideas. The essence of it is that a high-quality stereo playback system can convey astounding realism, with sonic depth, width, and height, creating a sonic space for a vivid listening experience.\nThe other primary problem with speaker placement is getting an accurate bass response, which is always a challenge in the small rooms most of us are working with. Reflected bass waves interact with one another, combining together and producing the peaks and nulls associated with comb filtering, along with the more general modal and SBIR issues in the room.\nBefore we dive deeper into these two factors with speaker placement, I want you to notice something: These problems with speaker placement, bass trapping and quality stereo imaging, are also the exact same two problems we prioritize in our acoustic treatment strategies. Therefore, it’s important to remember that treatments work together with placement inside the room to help maximize the sound potential of the audio system. Let’s take a closer look at these two factors.\nSoundstage & Imaging\n“Everyone who has been fortunate enough to hear [stereophonic sound] has remarked that … the sound takes a special character of relief and localization which [monophonic sound] cannot produce…. The singers place themselves, in the mind of the listener, at a fixed distance, some to the right and others to the left. It is easy to follow their movements, and to indicate exactly, each time that they change their position, the imaginary distance at which they appear to be. This phenomenon is very curious… and has never been applied, we believe, before to produce this remarkable illusion.”\n— Clément Ader, “The Telephone At The Paris Opera,” Scientific American, December 31, 1881.\nI find it interesting that these first people to experience stereophonic sound reproduction in 1881 heard it via headphones, or more accurately, by holding a pair of old-school telephone “cups” up to their ears. To this day, listening with headphones can provide a vivid soundstage leading to a great listening experience. But I think few would argue that listening with a great set of speakers in a great room has a higher ceiling for quality sound reproduction and a superior listening experience.\nBut unlike listening with headphones, in which the speakers are fixed relative to the listener’s ears and the only acoustics at play are with the headphone drivers and the ear canal, using speakers in a room requires some thought and planning to get the best results, particularly in terms of the soundstage.\nThe basic starting point for setting up speakers is to put the two speakers into an equilateral triangle with the listening position, or the point in the room where the listener’s head resides while listening. There are many variations on this theme. Some prefer to make the focal point of the driver slightly behind the listening position. Others prefer to have the speakers wider, with a 45-45-90 isosceles triangle rather than the 60-60-60 equilateral triangle. Some prefer to “toe” the speakers in, so they are facing directly toward the listener. Others prefer to leave them pointing straight toward the rear of the room. And, different speaker manufacturers will have different recommendations for using their products, one common variable being how far from the front wall the speakers should be for optimal imaging.\nFor most speakers in a small room, unless they send out high frequencies from the rear of the speaker, placing the speakers as close to the front wall as possible gives the best results. Taking a simple rectangular room allows us to illustrate these strategies as shown here.\nNote a few characteristics of the room:\nThe listening position is approximately 3/8 of the length of the room (38%)\nThe speakers are in a 60-60-60 equilateral triangle with the listener’s head\nThe speakers are approximately ¼ the room width away from the corners. Keep this in mind; the importance of this will be explained in Part 2 of this article when we discuss multiple subwoofers.\nSometimes, particularly in project studios or listening rooms, there will be two sets of speakers to deal with, commonly a larger set of studio monitors capable of deep bass, and a smaller set of lower-fi monitors to represent a more “realistic” playback system most users will have in their homes. One setup possibility is shown here, with the smaller speakers in a 60-60-60 equilateral triangle setup, and the larger speakers in a 45-45-90 configuration, which can sometimes give a wider soundstage.\nThere are a few interesting things about this setup for a room this size and shape. Like the above room, the smaller speakers are set at about the 1/4 way point, and the larger speakers are directly in the corners. These placements are deliberate and will have consequences in the low end, not just in the imagine, which will be explained in part 2.\nAt the end of the day, the only way to know which setup works best for you, with your equipment, in your room, is to experiment. And of course, improving the quality of the soundstage is one of the key acoustic treatment strategies, usually enacted by placing thick absorbers at all nearby reflection points.\nBass, Room Modes, SBIR, and More\nThe other problem is that every room has a bass personality, and it imposes that personality on every sound in the room. There are many variables as to what this “bass personality” consists of, mostly having to do with simple geometry. The size and shape of the room are factors, as each dimension in a rectangular room will have various room modes associated with those dimensions. SBIR is also a problem, which is related to the distance between a speaker and a nearby boundary, usually the front wall or side walls. To combat SBIR, we typically want the speakers to be either less than a foot away, or more than three feet away, from any wall.\nThese are only two (modes & SBIR) of the many low frequency issues that will be in every room. Excess bass waves moving around the room interfering with one another will cause a wide variety of peaks and nulls at different frequencies in the room. This final response isn’t always predictable in terms of modes or SBIR; I’ve been surprised and puzzled by problems at measured frequencies that don’t seem to correspond to mode or SBIR calculations.\nAgain, experimentation in your room makes the most sense, especially if your room is less predictable (ie, it’s not a simple rectangular room).\nThe Art Of Compromise: Subwoofers\nFor conventional, full-range speakers, we must compromise between these two factors. Since all the drivers are in the same cabinet, putting them in the place for optimal imaging may not be the best place for accurate bass. In this case, speaker placement is almost always a compromise between these two competing problems.\nOne solution here is to use a system with subwoofers, so we can place the bass units where they give best results, and the satellites where they provide optimal imaging. In subwoofer/satellite systems, placement is very, very important. If placement is bad, then it’s quite difficult to get good sound from such a system. But if placement is optimized, you can get very very good results, optimizing both factors together without a compromise between the two. And, using multiple subwoofers can take it even further.\nIn Part 2 of this article, we’ll continue this conversation and explore various subwoofer placement strategies.\nWhen In Doubt, Ask For Help\nAs always, we are happy to help you strategize about how to get the most out of your speakers with good placement strategies and patented GIK Acoustics treatments. Contact us for free acoustical advice.\nJames Lindenschmidt is GIK Acoustics’ resident audiogeek. He records music, designs studios & listening rooms, and consults with clients to make better audio. He also writes and makes mead, at least until the revolution comes.","Acoustical applications of fabrics\nMain Curtain and Window Curtains at Baruch College Photo: Todd Kaplan\nRose Brand has partnered with our friends at Stages Consultants to create a blog series about the acoustical applications of fabrics. In this 3-part series, we’ll discuss some of the more common approaches for using fabrics in performance spaces and also the things to consider when choosing a fabric for your project.\nWhy Are Acoustics Important?\nOne of the basic goals of room acoustics is controlling reverberation, or the persistence of sound in a room after the source is silenced. While sometimes the goal is to create “live” spaces with longer reverberation times for a concert hall, more often you are looking for ways to make a room’s acoustics less reverberant, especially in theatre and studio spaces. Adding sound absorbing material to a room will reduce its reverberation time and the perceived loudness of sound. Shorter reverberation times enhance sound clarity, improve speech intelligibility, and reduce loudness. This allows better communication between performers and audiences at comfortable volumes. It also improves source localization, including surround sound effects.\nFabric is among the most versatile and effective sound absorption options available. Each fabric has different characteristics, such as type of fiber and weave that determine how much sound it absorbs and whether it provides even sound absorption from low (bass) to high (treble) frequencies, or whether it is only effective over a limited range. The way a fabric is used can also change its acoustic performance. A flat panel of fabric against a hard wall is different from a curtain with 50% or 100% fullness against the same wall. A fabric panel with backing, or one that’s set off from a surface with an airspace, will also perform differently.\nTypical Use in Theatres\nTypical fixed fabric elements in theatres include audience seating, wall panels, wall coverings, and a portion of draperies. Portions of draperies and dedicated acoustic elements are devices that may be extended in the room or removed depending on scenic needs and desired acoustical effect.\nAcoustic Panels and Wall Coverings\nWhen you think about acoustic wall panels, you may imagine a thick sound absorptive panel with an open-weave fabric covering like you see in many office conference rooms. Acousticians love these panels — low-cost, reliable performance, and most clients can find panels they like. However, in performance spaces you’re not always looking for maximum absorption or the same acoustic performance over every square foot of wall space. A larger variety of fabrics and in different applications is helpful in tuning a performance space.\nUsing fabric to cover walls is a great way to increase the absorption in a room or even cover a reflective panel. Attaching lightweight materials like a tulle or muslin will make walls more absorptive than paint at high frequencies, but have little impact on mid and low-frequencies. Heavier and thicker fabrics start to provide more substantial high frequency absorption and, depending on how they’re used, they can begin to affect mid and low frequencies, even without a porous backing.\nSection of Upholstered Wall\nCurtains and Banners\nWhile we’ve occasionally motorized a set of acoustic wall panels to allow them to be extended or retracted within an auditorium, most often we use fabric as tracked curtains or vertical banners to provide a range of absorption in a room and vary reverberation and loudness. Velour and Wool Serge fabrics are most effective curtain and banner options, and can be doubled or combined with a backing fabric like Canvas or Commando Cloth to achieve the acoustic performance needed in a particular room.\nWindow Curtains at Baruch College Photo: Todd Kaplan\nFabrics with Acoustic Absorption Data Available from Rose Brand\nIn Part 2, we’ll take a more careful look at Rose Brand products and how they perform in different configurations.\nStages Consultants provides world class acoustics and theatre design consulting for performing arts buildings. We bring to every project the knowledge, creativity, design skills and leadership offered by only the most experienced members of our profession - with the individual client oriented service that a small firm can deliver best. You can learn more about them and their services at www.stagesconsultants.com."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:f5ead8bb-d548-43bf-b967-900e66f87e65>","<urn:uuid:39f8dd73-8ba9-4000-9d44-5bd8b9ea19d5>"],"error":null}
{"question":"What are the two leading theories about the fluid responsible for creating Martian gullies, and how do they fundamentally differ in their mechanisms?","answer":"The two main theories propose very different mechanisms for gully formation on Mars. One theory suggests that liquid water, either from underground eruptions or thawing surface ice, created the gullies. The other theory proposes that carbon dioxide, not water, is responsible - either through violent gas eruptions from CO2 clathrates (as suggested by Dr. Carr) or through CO2 sublimation causing sand fluidization (as demonstrated by researchers at Universidad Nacional Autónoma de México). In the CO2 sublimation model, carbon dioxide deposits get covered by windblown dust during cold periods and then sublimate during warmer periods, causing sand to flow downhill at angles below the critical threshold needed for normal sand movement.","context":["Gullies coming down the south-facing wall of a trough in the Sirenum Fossae/Gorgonum Chaos region of the martian southern hemisphere. Each channel and its associated fan--or apron--of debris appears to have started just below the same hard, resistant layer of bedrock located approximately 100 meters (about 325 feet) below the top of the trough wall. The layer beneath this hard, resistant bedrock is interpreted to be permeable, which allows ground water to percolate through it and--at the location of this trough--seep out onto the martian surface. The channels and aprons only occur on the south-facing slope of this valley created by faults on each side of the trough. The depression is approximately 1.4 km (0.9 mi) across. Image: NASA/JPL/Malin Space Science Systems. Caption: MSSS\nThese theories are very different -- one involves eruptions of liquid water from underground, the other the thawing of buildups of surface ice -- but they have one major thing in common: they both do agree that the gullies are indeed water-produced.\nBut there are at least one, and maybe two, serious alternate theories proposing that the gullies are not water-produced -- and one of them states that the \"fluid\" that created them isn't even liquid!\nThe first was described in some detail by Dr. Michael Carr of the U.S. Geological Survey at the press conference in which the discovery was first announced.\nCarr is arguably the world's leading authority on the subject of water on Mars, but he is seriously skeptical about these gullies being water-produced for the two reasons given above.\nHe thinks there is a serious chance that the substance responsible is not subsurface water, but subsurface carbon dioxide.\nIt's been recognized for a long time that Mars' subsurface -- because the planet's temperatures are so much lower than Earth's -- almost certainly contains large amounts of stored CO2, in several different possible forms: as solid frozen \"dry ice\"; a \"clathrate\" mixture of CO2 incorporated into water ice; liquid CO2 (which can exist at pressures above 5 bars); and/or gaseous CO2 \"adsorbed\" by Mars' cold soil (that is, chemically stuck to its grains).\nThere is still a lot of debate about how much there is, but Jeffrey Kargel and Kenneth Tanaka have calculated that the total amount of CO2 outgassed by Mars' geothermal vents over its history \"could form a global mean layer thickness of CO2 clathrate over 200 meters -- and possibly over 1300 meters -- thick, if all the CO2 is present in hydrate form.\"\nIn reality, a great deal of that amount must either have escaped from Mars completely over the eons due to its low gravity, or been converted into carbonate minerals. But that's still a lot of underground CO2.\nSince there's also a good deal of subsurface water ice on Mars, most CO2 beneath the surface is probably mixed with it as a solid frozen \"clathrate\".\nThis substance can only exist under a fair amount of pressure -- equivalent to that found under about several meters of Martian soil and/or rock -- and it must be sealed off from even any small vents to the near-vacuum of Mars' surface. However, a layer of ordinary water-ice permafrost surrounding a body of clathrate can seal it off in this way.\nAccording to Carr's theory, if such a body of clathrate is suddenly exposed to Mars' surface by a landslide on a slope, the CO2 will explode violently out of the clathrate as gas -- and the resultant powerful blast of gas could sweep a cloud of ice and rock fragments and soil down the slope, plowing a gully which could bear a surprisingly close visual resemblance to the narrow one produced by an eruption of fluid, rather than the broader trail left by an ordinary avalanche.\nThis kind of traveling cloud of \"gas-suspended\" debris occurs fairly often in volcanic eruptions, where it's known as a \"nuee ardente\" (burning cloud). One such cloud from Mount Pelee killed all but one of the 30,000 inhabitants of the downslope city of St. Pierre in 1902.\nCarr's Martian version, needless to say, wouldn't be glowing ash and pebbles; it might be more accurately called a \"refrigerated cloud\". According to this theory, these eruptions would occur only on Mars' colder slopes simply because only they would be cold enough for permafrost, and an underlying layer of CO2 clathrate, to be close to the surface and thus likely to be exposed by landslides. (It should be kept in mind that these runoff gullies are quite rare on Mars.)\nHowever, Carr told SpaceDaily that he still has considerable doubts about the feasibility of his tentative theory on the grounds of \"kinetics\". The key question being whether a Martian gas blast would be powerful enough to avoid immediately dissipating into the near-vacuum atmosphere of Mars to carry debris the distances being seen in the new images.\nFor this reason, a variant on this theory has been suggested by Dr. Kenneth Tanaka.","In 1999, the Mars Global Surveyor spacecraft sent back some extraordinary images of the surface of the Red Planet. They showed gullies that had been carved into Martian hillsides in the mid-latitudes of the planet.\nThe same sort of gullies form on Earth and here their existence is the result of water erosion. Various planetary geologists immediately suggested that a similar process must be at work on Mars. Their thinking was that some fluid must be responsible.\nThat’s an exciting idea but one that is fraught with problems. Recent evidence from Mars rovers suggest that liquid water once flowed on the surface of Mars but way back in the planet’s past. By contrast, the gullies spotted by the Global Surveyor are probably only a few million years old and over this timescale, the Martian atmosphere has been too cold and thin for liquid water.\nTo counter this, the geologists say that some other heating mechanism could cause liquid water to flow from an underground aquifer. But the gullies look to be the result of repeated flows so if this explanation is correct, there has to be a mechanism that refills the aquifers. On Earth, that mechanism is rain. On Mars, such a mechanism is patently absent.\nThere is another possibility, however. Perhaps the gullies are caused by the flow of sand and dust. Similar gullies are known to occur on dunes on Earth but only when the angle of the hillside is above some critical threshold. The trouble with Martian gullies is that most of the hillsides are not steep enough for this process to occur.\nToday, Yolanda Cedillo-Flores and Héctor Javier Durand-Manterola at the Universidad Nacional Autónoma de México suggest a solution to this conundrum. Their idea is that the gullies are formed when carbon dioxide in the ground sublimates, causing the sand to become fluidised.\nThis solves a number of problems. For a start, it allows the sand to flow on hillsides that are much less shallow than the critical threshold. It also explains how the gullies form by the action of repeated flows over long periods of time. Their idea is that carbon dioxide is deposited on the ground during cold periods and covered with windblown dust. The carbon dioxide then sublimates during warmer periods, causing the sand to flow downhill.\nThis theory also explains why the gullies form mainly at mid-latitudes and not at the equator or the poles. At the poles, it rarely gets warm enough to regularly heat sand-covered carbon dioxide and at the equator it is too warm for it to form. So the mid-latitudes are the best places for gullies to form.\nCedillo-Flores and Durand-Manterola attempt to seal the deal by recreate in their lab the conditions for martian gully formation by injecting air into a bed of sand. Sure enough, this process leads to the formation of martian-like gullies at angles well below the critical threshold (see picture above).\nThere are some important difference between the experimental gullies and the ones that form on Mars, such as their length. But the researchers say that this can be explained by the difference between the way air is injected into sand and the way carbon dioxide sublimates.\nBest of all, the new theory requires no special hypotheses about the Red Planet. “Our model does not require exotic conditions; only the ones found at present on Mars,” say Cedillo-Flores and Durand-Manterola.\nThat’s a convincing explanation for the formation of martian gullies. And it will be a substantial blow to those looking for evidence of liquid water on the surface of Mars (and the possibility of life it suggests).\nWater may still be present on Mars but it is looking increasingly clear that there are better places in the Solar System for astrobiologists to focus their attention.\nRef: arxiv.org/abs/1004.5417: Martian Gullies: Produced By Fluidization Of Dry Material\nIt will soon be easy for self-driving cars to hide in plain sight. We shouldn’t let them.\nIf they ever hit our roads for real, other drivers need to know exactly what they are.\nMaximize business value with data-driven strategies\nEvery organization is now collecting data, but few are truly data driven. Here are five ways data can transform your business.\nCryptocurrency fuels new business opportunities\nAs adoption of digital assets accelerates, companies are investing in innovative products and services.\nYann LeCun has a bold new vision for the future of AI\nOne of the godfathers of deep learning pulls together old ideas to sketch out a fresh path for AI, but raises as many questions as he answers.\nGet the latest updates from\nMIT Technology Review\nDiscover special offers, top stories, upcoming events, and more."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:7c8c7cca-b4e4-4bc0-8c36-9a2f983b174c>","<urn:uuid:1402fe74-2932-4deb-960c-819a35f05f0a>"],"error":null}
{"question":"What type of hay provides more calories for horses?","answer":"Early- to mid-maturity hay provides more calories than late-maturity hay. Additionally, legume forages like alfalfa or clover provide more calories than grass hays of the same maturity due to their higher energy and often lower fiber content.","context":["My five-year-old Quarter Horse mare is too thin (BCS: 4). She stands only 15 hands (152 cm) and weighs about 900 lb (410 kg). I use her for barrel racing, exercising her 5-10 hours per week and then competing on the weekends. I feed her three quarts of feed each morning and evening—two quarts of that is typical concentrate and one quart is low-starch concentrate. She gets 6-8 hours of turnout each day. I’ve tried rice bran and that didn’t work. What else can I do to support weight gain?\nNutritionists use a great deal of information when conducting an evaluation, so providing as much as possible—even erring on the side of too much information—is always best.\nTo better understand your mare’s situation, it would help to have the following information: (1) the type of forage the mare consumes while she’s stalled, the quality of that forage, and how much, in pounds or kilograms, of that forage; (2) the amount of feed she’s given as a weight, not a volume; (3) whether you’ve tried other high-calorie products aside from stabilised rice bran; and (4) whether you’ve offered digestive supplements such as yeast, probiotics, or buffers.\nFurther, is this mare’s weight stable, though less than her ideal weight and condition, or is she in a state of chronic weight loss? Would you describe her as thin and undermuscled, or would she be considered fit, as a racehorse might be? High-performance horses, like racehorses and other hard workers, often have a lower body condition score than pleasure-type horses but are maintained at their ideal weight with ample internal energy reserves.\nGiven the information you provided, the following suggestions might be of some use.\nMake sure your mare is up-to-date on dental, deworming, and vaccination schedules to ensure there are no underlying health concerns causing her to struggle with body condition.\nTo achieve weight gain, the mare’s intake of digestible energy (DE) needs to be greater than her energy expenditure. An increase in feed intake will help to facilitate weight gain. It is not unusual for hard-working horses to require 10-15 lb (4.5-6.8 kg) of feed per day. Feeding her based on her target weight is recommended, as it takes significantly more calories to achieve weight gain than it does weight maintenance. I would estimate her target weight to be the range of 1050-1150 lb (475-525 kg).\nWhen horses are consuming large amounts of feed, it is important to balance the forage to concentrate ratio, making sure at least 50% of the diet comes from forage. Providing your mare with the highest quality forage, as pasture, hay or forage alternatives such as beet pulp and hay cubes, is my first recommendation. This should be given on a free-choice basis.\nEarly- to mid-maturity hay will provide more calories than late-maturity hay. Legume forages, like alfalfa or clover, are another way to maximize the amount of calories provided as forage due to their higher energy and often lower fiber content compared to grass hays of the same maturity. Most horses perform well on a grass-legume mix consisting of 20-50% legume.\nSupporting gut health is key in these instances when large amounts of concentrate feed is needed for weight gain. Kentucky Equine Research (KER) has found that horses at risk of developing digestive discomfort benefit from the daily digestive buffer RiteTrac.\nRiteTrac is an equine-specific digestive supplement that also contains a time-released hindgut buffer, EquiShure, to offer superior protection to the entire digestive tract.\nBarrel racing requires significant energy output predominately from muscle glycogen stores that require a steady supply of nonstructural carbohydrates (NSC). Cereal grains (corn, barley, oats) offer concentrated sources of nonstructural carbohydrate (NSC), providing a direct fuel source for speed work. Traditionally, cereal grains have been considered the go-to feed for adding condition to a horse. When fed in moderation cereal grains offer significant nutritional value to the performance horse. You may consider adding 1-2 lb (0.45-0.9 kg) of oats or processed corn or barley to your current concentrate feed or offering her a performance feed higher in calories and NSC.\n|Stabilized Rice Bran–Just the Facts, Please|\n|Hot Blood, Warm Blood, Cold Blood in Horses|\n|Feeding Oil to Horses: Choose Wisely|\n|Causes of Poor Appetite in Horses|\n|Signs of Imminent Foaling in Mares|\n|Trailering Your Horse: Five Nutrition Tips|\n|Gastric Ulcers in Horses: Injectable Treatment in Development|\n|Old Horses and Gastrointestinal Disease|\n|What Is the Effect of Early Weaning on Young Horse Development?|\n|Pasture Safety: Toxic Plants and Horses|"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:dd36c24c-d4f1-4fd3-87ff-b83fd9aa043c>"],"error":null}
{"question":"Could you explain how both the Roman Empire and the Qin Dynasty ultimately collapsed, particularly in terms of their financial and administrative challenges?","answer":"The Roman Empire collapsed largely due to economic unsustainability. The treasury was depleted by greedy and extravagant emperors, while the Empire struggled to raise enough taxes to cover essential expenditures like border protection, grain provision, and infrastructure maintenance. They even had to pay tributes to barbarians to prevent invasions. The Qin Dynasty's fall, though shorter-lived, came through different circumstances. It began with Qin Shi Huang's obsession with immortality leading to his death, followed by the poor leadership of his son Hu Hai, who was manipulated by officials Li Si and Zhao Gao. The tyrannical rule and oppression of lower classes led to widespread revolts. Despite attempts by the final emperor Ziying to restore authority, the dynasty ultimately fell due to these internal conflicts and popular uprising.","context":["|Global Knowledge Gateway||\nThe Rise and Fall of the Aerarium: Lessons in Public Finance from the Roman Empire\nby Eli R. Khazzam, Senior Professional, Economic Development & Emerging Technologies. | July 22, 2014 |\nThe notion of public sector finance—of treasuries, taxes, and distribution of public resources—is not a product of the modern age. The ancient Romans also struggled with developing efficient systems for government to raise revenue and manage expenditures. Is there anything we can learn from their example to help us think about the problems governments have today regarding sovereign debt and the ability to finance the needs of society?\nAncient Rome: From Republic to Empire\nIn the era of the Roman Republic, the fiscal affairs of government were in the hands of the Senate. The state treasury was known as the aerarium, which was divided into two parts: the common treasury and the sacred treasury. The common treasury was designated for deposits from regular taxes and drawn upon for state expenditures. The sacred treasury was reserved only for times of extreme crisis.\nHowever, in the transition from Republic to Empire, the treasury structure changed. By the time of Julius Caesar, the sacred treasury was being used for the deposit of booty brought in from conquests throughout Europe and the Mediterranean. Then, when Augustus assumed power, he divided the aerarium into a common treasury and a fiscus. The common treasury was controlled by the Senate and designated for raising income and providing expenditures for jurisdictions already inside the Empire, while the fiscus was used for monies from lands conquered by the Emperor’s armies outside of the Empire’s borders. The fiscus essentially became the emperor’s private treasury. Augustus eventually established a third treasury, the pension-like aerarium militare, which was designated for providing rewards for soldiers upon dismissal from services.\nAs time progressed and power was further consolidated in the hands of the emperors, the separate treasuries were combined into one. This was due in part to the emperors’ cravings for greater control and perhaps the perceived necessity of centralizing the administrative functions of the Empire. The integration of the treasuries also coincided with the enormous economic burdens that were falling upon Roman civilization: the need to protect its borders; provide grain and basic resources for its inhabitants; and to maintain its vast infrastructure of roads, aqueducts, and other structures necessary for the movement of goods. In the hands of often greedy and extravagant emperors, much of the treasury was depleted and the Empire could not raise enough taxes to cover its expenditures. The treasury was being depleted as the Empire had to pay tributary to different groups of barbarians just to keep them from invading its borders. Ultimately, the Empire collapsed as it was not able to sustain itself economically.\nFast Forward to Modern Civilization\nModern civilization is more conscious than our Roman counterparts. Societies do have expectations of good governance in the public sector. They expect diligent decision making and the efficient use of resources. They expect citizen engagement, public scrutiny, and oversight of those charged with fiscal responsibility. In the end, they expect accountability and better outcomes for the public at large.\nWhat basic lessons can we take away from the Roman aerarium? In the 21st Century, the complexity of modern civilization has forced many governments to assume overwhelming costs: military, infrastructural, and social. The ever-increasing public debt that many sovereign nations have assumed reflects a growing disproportion between government’s capacity to raise revenue and meet its obligations for the distribution of public goods (e.g., defense, roads, schools, social services, etc.). We can neither seem to reduce these obligations nor compensate for them with alternative or additional revenue streams.\nWorse yet, when nations come under stress (e.g., from wars, natural disasters, and other catastrophes), many public expenditures cannot keep pace with government’s capacity to raise revenue. In times of crisis, presidents and prime ministers, often make emergency decisions that involve the marshalling of vast resources. But what happens when governments no longer have the ability to do so? Shouldn’t we be far more fiscally disciplined about our long-term prosperity and security? How do we, as a vast modern civilization, save money for the future? The rise and fall of the Roman aerarium may contain lessons for both the problem and solution.\nWhat are your thoughts?\nLike what you see here? Subscribe to The Latest, our customizable update sent every two weeks.\nDo you have a perspective you'd like to share with the global profession? Email Gateway@ifac.org to inquire about becoming a Gateway contributing author.","According to ancient history, China saw the rise and fall of many dynasties, among them was the Qin Dynasty. Of all the dynasties written in history, the Qin dynasty was notably the most important dynasty to have existed. This is because it had the largest impact on China as a whole.\nThe dynasty was famously known as the first dynasty of a unified country, China. It was also the dynasty that had the first-ever declared emperor of China. This was the first dynasty famed to have unified China for the first time in history.\nDuring the reign of the dynasty, China became a multinational state with centralized political power. There was a standardized unit of measurement, currency, and writing system. Qin dynasty is also known for the building of the famed great wall of China and the Terracotta army. This dynasty is said to have had a large influence on the next dynasties to come.\nWhat Is the Qin Dynasty?\nhow long did the qin dynasty last? The name Qin is said to be the ancestral name for the modern-day European name China. Some scholars, however, dispute this fact. The dynasty rose from the State of Qin, one of the seven warring states. It was established by Shi Huang, the self-proclaimed first Emperor of China, in 221BC after the defeat of the Zhou dynasty. Under the leadership of Shi Huang, then known as King Zheng of Qin, the dynasty is said to have conquered all the warring seven states. This led to the first-ever recorded unification of China, making the Qin dynasty the first dynasty of a unified state. The Qin dynasty, however, had the shortest reign which ended in 207BC.\nThe reign of the dynasty was characterized by a centralized government that was highly bureaucratic and followed the philosophical teachings of Legalism by the scholar Feizi. As a result, the regions formed by the first emperor were not ruled over by nobility, rather appointed officials who were dedicated to the task. The hierarchy of these officials who all reported to the first emperor was what formed the government. This allowed the emperor to have control over all of the states. This method of leadership would be later employed by other dynasty rulers.\nThe dynasty was also characterized by standardizing, to create a more united atmosphere where all the people shared a common idea. All aspects of life were standardized, from the language to the writing system, to the currency. Individual rights were undervalued especially if they went against the government of the emperor. The reign of the dynasty was significant in laying the foundation for many of the developments that came later in China.\nWhy Is the Qin Dynasty Important?\nAs mentioned, the Qin dynasty is the most significant of all dynasties recorded in Ancient Chinese history. It was the first dynasty to reign over a united country. This is thanks to King Zheng who conquered all seven states ending the warring states period. He later gave himself the title of Emperor, hence becoming the First Emperor of China, Qin Shi Huang. In his reign, he carried out a lot of reforms to solidify the unity.\nTo begin with, he did away with the Feudal form of governing and instead employed a more bureaucratic form of government, following the Legalism doctrine. He restructured the local counties taking away control from nobility and appointing officials, dedicated to the task to administrate under him. The political power and military affair were all under his control.\nHe also overcame the cultural barriers of the different states to establish a unified empire by standardizing various aspects of life. To begin with, he standardized the writing system by making Qinzhuan the standard font. He also standardized the units of measurements and weights and choose the round gold coin with a square hole as the common currency across the country.\nTo promote a singular belief and idea as a country, Qin Shi Huang enforced the Legalism doctrine and discouraged any other schools of thought that went against it. This led to the infamous tale of “the burning of books and burying of scholars”. According to the tale, Qin Shi Huang was said to have burnt many books that went against the philosophical teachings of Legalism. He is also said to have buried about 460 scholars alive for speaking against Legalism.\nHe also paid a lot of attention to infrastructure. He established improved irrigation systems and built better roads. He was responsible for the building of the Lingqu canal that helped with his expansion towards the south. Under his rule, the greatest attraction of the world, the great wall of China was built. He had the great wall built to defend his kingdom from barbarians and enemies from the north.\nAlthough he was a tyrant ruler, the economy of China thrived under his reign. He contributed to the development that would later be witnessed in China.\nWhat Are the 5 Achievements of The Qin Dynasty?\nBeing the most significant dynasty in the history of China, the Qin dynasty has many notable achievements from its reign. Among them, the top five are:\nThe First Dynasty in History to Unify China.\nDuring the Warring States period, the seven states namely, Qin, Yan, Zhao, Wei, Qin, Chu, and Han, were at war over who would dominate over the rest. It was Qin Shi Huang’s (then called King Zhe of Qin) campaign to conquer the six other states that led to China’s first unification. He first started with Han, then Zhao, followed by Yan and then Wei. The final states to be conquered by him were the powerful Qin and Chu. It took him less than 10 years, to put an end to the war that had been going on for over 5 centuries.\nStandardized the Writing System.\nBefore the unification, there was a variation of local character styles that made up the “Six Scripts of China”. This made communication, trade, and taxing difficult in the new unified Qin dynasty. For that reason, the Qin dynasty’s Prime Minister Li Si, in 220BC, set the standardized form of the Small Seal Script originally used by the Qin State, as the standard writing system for all states. The Qinzhuan was set as the standard font. This ensured that the writing system in China was uniform across the whole country. It went a long way in unifying the different Chinese cultures thanks to easier communication.\nEstablished China’s First Meritocratic Administrative System.\nIn his reign, and with the help of Li Si, Qin Shi Huang got rid of the feudal system of governing that was there initially. He divided the Qin dynasty into 36 prefectures, which were made up of several counties. The counties were in turn divided into several towns which were in turn divided into small rural administrative units. These units were governed by an official who was appointed on merit, unlike in past dynasties that were based on heredity. The centralized government further reinforced the unification of the country. This system would be used later as the basis of China’s administration for over 200 centuries to come.\nEngineered the Dujianyang Irrigation System.\nDuring the time of the Qin dynasty, there was the Min river which was the largest tributary of the Yangtze River. The Min river passed through Sichuan province and would annually flood the banks along with it. Due to this, the engineer Li Bing who was the administrator of the Qin State at the time started and oversaw the engineering of the Dujianyang irrigation system under the rule of Qin Shi Huang. The system harnessed the water from the river by dividing and channeling it, leading to the floods making Sichuan a very prosperous agricultural province. This was done in 256BC and the system is still in use even today.\nInitiated the building of the Great Wall of China.\nAs part of the unification process, Qin Shi Huang ordered that the fortifications that separated the different states be brought down. He ordered a great wall, connecting the fortifications along the northern frontier of the empire, be constructed instead. The wall was being built as a defense against, Qin dynasty’s northern enemies, the Xiongnu. This wall was considered the precursor of the Great wall of Chin\nHow Many Emperors Did the Qin Dynasty Have?\nGiven that the Qin Dynasty had the shortest reign of all the dynasties to have ever existed, there weren’t a lot of successions before its fall. The dynasty only has three known emperors, two of which ruled for short periods. The three were, Qin Shi Huang, who established the dynasty, his son Hua Hai (Qin Er Shi), and Hua’s nephew Ziying (Qin San Shi).\nAlthough Qin Shi Huang was the reason behind the unification of China, he was a tyrant. He used brutal techniques and the legalist doctrine to exact and expand his power. Under his rule, the people especially those from the lower class were oppressed and extorted. When he died, prime minister Li Si and Chief Eunuch Zhao Gao altered his will and placed his impressionable son Hu Hai on the throne so they could use him as a puppet. Hua was, however, killed by Zhao who was later executed by Ziying when he came into power. He was, however, unable to stop the revolt that was taking place then and hence ended up being killed.\nWhy Did the Qin Dynasty Fall?\nThe fall of the great Qin Dynasty, begun with Qin Shi Huang’s paranoia about death. This was after he had survived three assassination attempts. As a result, he became obsessed with immortality and tried contacting every alchemist and sorcerer, to find the elixir of life. Ironically this he how he died.\nPrime Minister Li Si and Chief Euchun Zhao Gao put Huang’s gullible son as his successor for their gain. He was also a bad ruler executing random innocent people and when that would be. Both the unfair and tyrant rule of Shi Huang and Hu Hai’s rule gave rise to the revolting of the poor. They attacked the government officials and declared themselves King. Hua’s nephew witnessed the unrest of the people. After the death of Hua, Ziying took his place, attempting to establish his authority and that of the throne. Unfortunately, he failed and was executed. His death meant that was the end of the Qin Dynasty.\nHow Did the Qin Dynasty Influence Chinese History?\nAlthough a tyrant, many of the controversial policies that unified China and maintained his reign, are still used even today. His actions as the first emperor of China have had a great impact on Chinese history. The following are some of the ways:\nA centra rule.\nUsing the principles of Legalism, the Qin dynasty built a centralized power structure that was an effective way to govern. A lot of the dynasties after it borrowed from it.\nUniform Writing System.\nShi Huang improved communication by establishing the standard writing script. It made it easier for scholars to share information and different cultures to interact. Later on, it made it possible and easier for other dynasties to communicate with nomadic tribes.\nImprovement of trade and commerce.\nBy standardizing the units of weight and measurements as well as the currency, the Qin Shi Huang improved the commerce and trade of many regions. Later dynasties were able to easily come up with a tax system thanks to the common currency and units of measurements. Even the building of roads helped connect the provinces better\nThe Terracotta Warriors.\nIn preparation for his death, Shi Huang had the peasant build him a mausoleum and a vast number of life-like terracotta warriors who carried real weapons. These warriors were said to be there to protect him even after his death. The tomb was discovered in the 19th century. Since then, it has become one of the main tourist attraction sites for China.\nDespite having the shortest reign, the Qin dynasty managed to have the greatest impact on China’s development. The effects of its reign are still felt even today. Although he was a tyrant in the end his contributions were great.\nMy name is Yelang, I love my country. I love Chinese history, Chinese cultureandChinese food, I want to share my story to friends all over the world. Truly, without any political bias, let you know my motherland. For this reason, I have traveled all over China's 20 + provinces and visited more than 100 + cities. At the same time, I read a lot of books and articles, and let you know through the website of sonofchina. At the same time, I hope to get to know friends all over the world and know different countries in the world through sonofchina.So, if you have any questions, please let me know."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:84ec87d6-4b40-48ef-b15c-6d9c2d14802b>","<urn:uuid:e081abb7-4e91-4b75-97f4-70316a576175>"],"error":null}
{"question":"Does IMSAR's NanoSAR require more expensive material than Barcelona UAV for manufacturing? What is used in each?","answer":"Yes, IMSAR's NanoSAR requires more expensive materials as it uses sophisticated radar electronics components, while the Barcelona UAV is manufactured using only PLA filament, a basic 3D printing material. The Barcelona UAV's total manufacturing cost is just 18.63€ (excluding printer cost) using PLA material on a RepRap 3D printer. In contrast, the NanoSAR system uses advanced radar electronics and multiple receive antennas that need to be positioned along the aircraft length for Moving Target Indication capabilities.","context":["Launch Stories provides warfighters, sponsors, partners, and taxpayers with an inside look at the technologies and research developed by small businesses working with the Air Force.\nSponsored by the Air Force Research Laboratory (AFRL), this new forum highlights the advanced tools and innovations that drive US competitiveness and make service members safer, better informed, and more efficient than ever. These are their stories.\n(If you are interested in partnering with the Air Force to develop a new technology or explore new markets, you can find more information here.)\nCongress established the Small Business Innovation Research (SBIR) program in 1982 to strengthen the role of smaller businesses in federally-funded research and development. This program stimulates technological innovation, uses small businesses to meet Federal R&D needs, and increases private sector competition, productivity, and economic growth.\nThe Small Business Technology Transfer (STTR) program, a sister program to SBIR, was established by Congress in 1992 to encourage small business partnerships with Universities, Federally Funded Research and Development Centers, and qualified non-profit research institutions.\nThe process for submitting a story is divided into a few easy steps. Estimated time to set aside to write, input, collect support materials and emailing your project information is about four hours.\nDownload the provided Launch Stories Submission Word document below to start your submission process.Launch Stories Submission\nGather supporting imagery and video for your story as described in the Launch Stories Submission document.\nSubmit your completed Launch Stories Submission document, along with any supporting imagery to email@example.com.Submit\nUpon receiving your information, the Air Force Research Laboratory will review it for technical accuracy. Once cleared for public release, your story will be posted online.\nDon’t have an account? Register today to upload your own story.Register\nThank you! Your registration is pending review. Once your account has been approved, you will receive a confirmation email.\nImagine you are a soldier in a small tactical force operating in a hostile territory. The enemy force is near, but their exact location and movements cannot be seen from your current position. Your only asset for performing Intelligence, Surveillance, and Reconnaissance (ISR) missions is a small Unmanned Aerial Vehicle (UAV). With the Moving Target Indication (MTI) capabilities of IMSAR's NanoSAR, you can detect, locate, and track enemy forces from the small UAV.\nDiscovering the movements and patterns of life of enemy forces provides a critical advantage to military personnel. The technology required to detect, locate, and track moving targets has previously only been available to large military units with significant assets and resources. But the knowledge of enemy movement is most crucial to tactical forces on or near the front lines. Providing the needed information to the forces that need it most requires the same capabilities on smaller platforms. Moving Target Indication (MTI) capabilities from a small Unmanned Aerial Vehicle (UAV) would provide much-needed information to soldiers without putting them in harm's way.\nAircraft agnostic radar mounting pod.\nScanEagle integration. (Photo courtesy of INSITU)\nNanoSAR Shadow integration\nAdvanced radar capabilities, like wide area Moving Target Indication (MTI), improve battlefield awareness for all military units. Without the ability to detect, locate, and track moving targets from small, unmanned assets, tactical military forces have to rely on other methods to gather Intelligence, Surveillance, and Reconnaissance (ISR) information on enemy force movements. The other methods typically require more personnel and more expensive resources and place the personnel or expensive resources in harm's way. The decision results in either failing to gather needed ISR information or risking personnel and equipment. Currently, the primary sensor on small Unmanned Aerial Vehicles (UAVs) is an Electro-Optical/Infrared (EO/IR) sensor. Detecting targets of interest with EO/IR cameras is both labor intensive and error prone because canvassing a large area through the narrow field of view provided by optical imagery is a needle-in-a-haystack problem. Simultaneously tracking multiple targets with EO/IR assets also requires sophisticated coordination between camera operators.\nIMSAR leveraged its existing NanoSAR Synthetic Aperture Radar (SAR) system to bring advanced capabilities to tactical Unmanned Aerial Vehicles (UAVs). The NanoSAR is the world's smallest SAR in terms of Size, Weight, and Power (SWaP). The radar electronics assembly of the NanoSAR system measures 5.5\" by 3.5\" by 2\", weighs less than 1 lb., and consumes less than 30 Watts of power in a typical configuration. The Air Force Research Labs (AFRL) provided the funding and other support required to develop a Moving Target Indication (MTI) mode for the NanoSAR system, which allowed the NanoSAR to successfully demonstrate MTI functionality without significant increases in SWaP.\n\"Having these multi-mode radar systems on small UAVs are enabling our researchers to explore new capabilities faster and at a much lower cost than ever before.\" — Todd Jenkins\nThe NanoSAR performs Moving Target Indication (MTI) by positioning multiple receive antennas along the length of the aircraft and comparing the return from each. The return from stationary ground targets will follow a predictable pattern while independently moving targets deviate from that pattern and can be isolated. The isolation of moving targets is accomplished using complex algorithms known as Space-Time Adaptive Processing (STAP). Once a moving target is identified, the geo-location of that target can be determined by using the range information inherently available from radar signals and the bearing information from multiple antenna returns. The MTI radar rapidly scans a wide area of interest to detect moving targets within the sensor footprint, and the detections are automatically correlated into a track for each target. This allows the radar system to simultaneously monitor the movement of dozens of targets of interest within a several kilometer diameter circle and present meaningful target histories to the analyst consuming the final data. All of this radar information can be obtained despite the presence of rain, fog, smoke, or other visually degraded environments. The detection and track information can be used to cross cue available EO/IR assets for target identification. EO/IR operators can toggle between targets of interest to gather specific information on those targets while the MTI radar continues to keep track of each moving target within the scene.\nWith the development of the Moving Target Indication function of the NanoSAR system, capabilities formerly available only to large military units with large Intelligence, Surveillance, and Reconnaissance assets are now available to tactical military units with small Unmanned Aerial Vehicles (UAVs). The tactical units can now have virtually the same battlefield and situational awareness as the larger units without risking personnel or more expensive equipment.\nThe ability to perform MTI with the NanoSAR system has increased the desirability of the NanoSAR system within the small Unmanned Aerial Vehicle (UAV) market. A previous version of the NanoSAR has already been deployed on the RQ-7B Shadow, the Army's program of record. IMSAR anticipates that the MTI-capable version of the NanoSAR will also be integrated and deployed on the RQ-7B Shadow and on the Navy's/Marine's program of record, the RQ-21A Blackjack.\nThe lower cost of procurement and operation of small radars on small drones replaces more expensive and larger systems. Every military is seeking greater capability at a lower cost. The U.S. and its allies are more competitive by conserving precious budgetary resources.\nBy shepherding the development of advanced radar modes, the Air Force Research Labs have laid the groundwork for technology that will go into nearly every branch of the government that protects our freedoms: Air Force, Navy, Marines, Army, and the Coast Guard. Rather than independent development in each organization, significant savings in time and money are realized. There is significant potential savings in procurement, training and support by using a common radar across multiple services.\nIMSAR was founded in 2004. In 2008 IMSAR changed the industry when they demonstrated the NanoSAR A, the world’s smallest SAR. Since then, the company has become the world leader in miniature SAR technology for manned and unmanned platforms.\nAdvanced Radar Concepts For Small (Tier I/II) RPAs\nFor more exciting Air Force launch stories, visit launchstories.org\nRATE THIS STORY","Taking Off with 3D Printing\nWe have recently been contacted by Jonatan Domènech Arboleda, a student from the School of Industrial and Aeronautic Engineering of Terrassa (part of the Universitat Politècnica de Catalunya, Spain). Jonatan has just completed a remarkable project, a 100% 3D printed Unmanned Aerial Vehicle (UAV) also known as the Barcelona UAV.\nKeen to share his creation with other 3D printing enthusiasts, Jonatan reached out to us. Looking at the UAV project in more detail quickly made us realize that this project would be worth sharing with our audience. The UAV is not only a nice piece of engineering but also an excellent demonstration of what 3D printers are already capable of today. Jonatan did all his 3D prints on a RepRap using PLA filament. No fancy materials or industrial type 3D printers.\nWe hope that sharing this 3D printing project will open a few eyes when it comes to the capabilities of 3D printers and maybe inspire a few readers to start similar ambitious projects.\nHere is what Jonatan has to say about his project:\n1. What Led You to Develop the 3D Printed UAV?\nThe idea to develop the 3D printed UAV came originally from Jordi Santacana, the director of CATUAV (a local company specialized in UAV aerial imaging). In the summer of 2013 he participated at a Silicon Valley conference on 3D printing and came back to Barcelona with the idea of adapting this technology for UAV applications.\nIt was the mix of a dedicated student, the University environment and entrepreneurship that made it possible to develop the 1st 100% 3D printed UAV in Barcelona. On a global scale this only the 2nd 3D printed UAV in Europe and the 5th in the world.\nThe study demonstrated the feasibility of using rapid manufacturing technology, more specifically consumer 3D printing, in Unmanned Air Vehicle design.\nThe Barcelona UAV has been designed with Autodesk software, 3D printed with PLA material on a RepRap BCN 3D+. Table 1 shows its final specifications.\nTable 1: Barcelona 3D printed UAV specifications\nThe major aim of the project was to obtain the best weight performance of any UAV design. Comparing the Barcelona UAV with the reference UAVs and the best weight performance technology currently available (high density foam such as used in the Multiplex Easy Star II RC plane) it becomes clear how successful this project has been:\nTable 2: Referenced UAV comparative results to Barcelona UAV\nFigure 1: Comparative graphic between referenced UAV\nThe Advanced Manufacturing Research Center of the University of Sheffield, and BOEING developed a 3D printed UAV (see Figure 2) that has the 2nd best weight performance, but it is a flying wing glider. Taking into account that the other references have been evaluated including the engine weight, VAST AUAV or SULSA can be considered as having the 2nd best weight performance.\nFigure 2: AMRC 3D printed UAV\nThe Massachusetts Institute of Technology, Lincoln Laboratory, developed the so-called VAST AUAV in 2013 (see Figure 3). This project was co-sponsored by the US Air Force and RAPID 3D IMAGING. This interesting UAV has a carbon fiber reinforced polymer (CFRP) fuselage beam. It is therefore safe to assume that if VAST was 100% 3D printed, it would be heavier than it is with its current mixed technology design. This leaves the SULSA as having the 2nd best weight performance in the balanced comparison of the weight performance for existing 100% 3D printed UAVs.\nFigure 3: VAST AUAV\nSULSA was developed by the University of Southampton, a UAV that is the 1st 3D printed plane and the 2nd best weight performance in the world. SULSA, with 6.174,68 € budget, has been sponsored by a UK-based 3D-printing firm, 3T RPD2.\nFigure 4: SULSA\nThe Barcelona UAV has only 28% of SULSA’s weight and taking into account the wingspan, it is 37% of SULSA’s weight/wingspan ratio which underlines the amazing result of this project.\nIn order to compare the Barcelona UAV with the MULTIPLEX Easy Star II (an entry level model airplane), it is necessary to compare the ratio of the weight / total span (wing + fuselage) because of the similar sizes, see Table 3.\nTable 3: Barcelona UAV comparison with the best weight performance in traditional technology\nThe Barcelona 3D printed UAV has the same weight performance than injection technology of high density foam, ELAPRON®. Since this evaluation has balanced the alternatives, the fuselage, wing and tail cost have been compared in order to tiebreaker them.\nThe Multiplex Easy Star II costs 78.90€, including taxes but excluding avionics. The Barcelona UAV costs 18.63€, including taxes and energy cost but excluding the RepRap BCN 3D+ printer cost. Taking into account that RepRap has a 3D printing service in the Barcelona UPC Campus with a cost of 0.12 €/cm3, the cost of producing the Barcelona UAV is 44.71€, including taxes. Therefore the Barcelona UAV cost is only 57% that of the Easy Star II.\nThis is an amazing result of this project because it demonstrates the feasibility of 3D printing technology in UAV applications. This document has demonstrates that the 3D printing service of the Barcelona UPC Campus is the best option for 7 or less units and in case of more than 7 units of the 3D printed UAV the best option is to buy your own low cost 3D printer.\n2. How Did You Design the UAV? Did You Have to Learn Any New 3D Modeling Skills?\nThe Barcelona 3D printed UAV has been designed using Autodesk software, with a student license. You need such a powerful software in order to fully apply your knowledge. Having a clear target also greatly helps to sharpen your 3D modeling skills. For this project the target has always been to design a new UAV design, in view of manufacturing it using 3D printing technology.\nOver time, I tested various CAD software. Today, I find AUTOCAD, INVENTOR and 3DS MAX to be useful design tools, since each has a great community of users that you can learn from to further develop your own skills.\nCAD skills alone were not sufficient for this project though. The complete design cycle includes thinking, selecting, manufacturing, testing and reiterating. I had to apply the full breadth of my know-how to build the UAV:\n- Aircraft design, in order to design the UAV.\n- C++ programming, in order to optimize firmware configuration and G-Code parameters to obtain the high performance required for this specific application.\n- Statistics, in order to analyze the results of the printing in function of the configured parameters. More precisely, the weight in function of the Z axis height and printing speed.\n- Fluid mechanics, in order to analyze the deposition behavior of the fused material from the 3D printing process and to design cooling requirements for PLA parts in contact with the engine.\n- Materials science, in order to compute structural requirements for the used materials and sizing the design.\n- Flight mechanics, in order to compute the operational requirements for the remote control of the UAV.\n- DIY skills, in order to join parts and assembly the UAV.\n3. What 3D Printer and what Material Did You Use to Print the Parts of the UAV?\nCompared to the overall size of the UAV, the build volume of the RepRap BCN 3D+ is relatively small. Therefore, wings and fuselage had to be printed in sections that were then assembled to form the full size UAV. I experimented with various joining or welding techniques and ended up using a heat welding process. Using a standard soldering iron and left-over PLA material, I was able to join the different sections. As it turns out, the molten PLA distributed evenly into the joints, giving the bond a very high tensile strength.\nA Few Thoughts on Materials\nIn my opinion, materials research will contribute to the most important developments in 3D printing over the coming years. Materials with different flexibility, mechanical properties, color and recyclability will be soon available for 3D printing users.\nWith the proliferation of dual extruder 3D printers, material flexibility will constitute an important development since this will allow for the creation of anisotropic parts. The possibility of 3D printing a blade using root flexibility for the first material and tip flexibility for the second and a controlled mix of them along the longitudinal axis, will become an improvement for fluid mechanic engineering.\nMechanical properties of the material can be modified by adding CF nanotubes or similar reinforcements. Nowadays there are already ABS materials with high mechanical properties. The minimum perimeter thickness, near 500 μm, and the maximum part size of 3D printing technology are still the main limitations. Therefore improving the Young modulus or stiffness of 3D printing materials will lead to new applications.\nColor of the filament is an interesting feature for 3D printers with multi extruders because RGB or CYMK basic colors can be mixed to generate any color tone. This feature will increase 3D printing applications.\nTo my mind, recyclability is the most important performance for 3D printing technology for the simple reason that it allows users to have a lower cost rapid manufacturing tool. When prototyping you always generate waste and unused parts. Having the possibility to recycle this waste material would be desirable both from a cost and environmental point of view.\nFor the Barcelona UAV I used PLA, a biodegradable material. I believe this is essential for any applications where parts may go lost outside. Still, even with PLA you have to careful since its biodegradability also depends on the properties of the additives used in manufacturing the filament.\n4. Could You Have Developed the UAV Without 3D Printing?\nNo, this would not have been feasible with standard technologies since many of the UAV parts constitute complex shapes that would either have been too costly or even impossible to mold.\n5. What Did You Learn About 3D Printing by Working Through This Project?\n3D printing constitutes the 3rd Industrial revolution. In the future, consumers will buy .stl files via the internet and print their objects at home or via a 3D printing service. This will affect traditional industries, supply chains, distribution and employment in totally new ways. Therefore, 3D printing technology must be analyzed and understood from a global and not only a local point of view.\nCompared to other rapid manufacturing systems, 3D printing technology is a low cost way of transferring things from the world of the ideas to the real one. Therefore, 3D printer device selection played an important role in my project. The main requirements were cost, multi material availability, double extrusion capability, open-source philosophy and supplier proximity. The aforementioned performance requirements allow a designer to create something economically feasible, while using new materials and mixing different material properties to customize parts to very specific requirements. Firmware configuration is also important in order to improve the technology for a given specific application.\nIn order to test a new system’s power and limitations you always need a bit of respect and a will to test things out. Respect is required since the 3D printer is not a toy and it constitutes an important device in the design cycle. Testing is required since this is the only way to completely understand the full depth of the technology that you have at your finger tips.\nThe project also made me understand the direct relationship between time, weight and cost. 3D printing is the only technology where investing time in weight reduction has a direct impact on cost reduction and manufacturing time reduction. Traditional technologies increase cost in function of the weight and manufacturing time reduction.\nLast but not least, I learned a ton about joining 3D printed parts as this played an important role in assembling the UAV prototypes. As build volumes of 3D printers are still relatively small, the UAV had to be printed in sections which were then joined.\n6. Based on What You Know About 3D Printing Now, Where Do You See the Biggest Limitations and Greatest Opportunities?\nThe biggest limitation is the PLA material because of its stiffness, mechanical properties and its density. New PLA materials with specific properties must be developed while maintaining the biodegradability.\nThe biggest opportunity I see is that a design can be digitally distributed and 3D printed anywhere in the world thereby giving you access to a worldwide network of beta testers. Anyone with a 3D printer and 0.5 kg of PLA can manufacture their own homemade UAV.\n7. What’s Next for the 3D Printed UAV?\nSince the completion of the Barcelona UAV project, I have been thinking about the following development and improvements:\n- The use of conductive materials. Using a 3D printer with a dual extruder, one could imagine printing the UAV wings and fuselage of one material while using conductive material to print the wiring required for the avionics.\n- Anisotropic parts, because propeller blades or wings could be designed with specific flexing behavior according to aerodynamic optimization.\n- Specific Infill for lightweight parts, because the existing patterns are only focused on support material and mechanical properties. This study has designed a lattice 3D honeycomb interesting for this development.\n- An advanced joining system, because the UAV requires parts joining and heat welding is a simple technology. This new system must be a heat technology able to be configured by temperature adjustment and surface selection, inside or outside the slices.\nI am currently finishing my studies and while I have no concrete plans for the future of the 3D printed UAV yet, I sure think about it.\nBy the way, upon graduation I’ll be looking for a nice job!\nYou can find more information on the 3D Printed UAV project on its Google+ page: https://plus.google.com/u/0/101621941783722657636/posts\nIn case you want to try your hand at printing your own UAV, Jonatan has made all the files available on Thingiverse: http://www.thingiverse.com/thing:334271\nDo you have any questions or feedback about the 3D printed UAV project? If so, please let us know by leaving a comment below. In case you have your own 3D printing project that you would like to be featured here on the blog, don’t hesitate to get in touch!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:c2ce7e7f-2c3a-4193-879f-7ffcb8f387cb>","<urn:uuid:d612d47a-2db1-4054-8e6f-89e037c238db>"],"error":null}
{"question":"Which has earlier historical origins: the Library of Congress website or the digital version of Codex Vaticanus?","answer":"The Library of Congress website debuted earlier, launching in 1994, while the digital version of Codex Vaticanus was made available online more recently, as indicated by the 2015 note mentioning that it had just been posted online at that time.","context":["- Records: More than 164 million items including legal materials, films, maps, sheet music and sound recordings\n- Books and Print Materials: 38+ million cataloged books and other print materials in 470 languages\n- Manuscripts: 70+ million\nMajor Content Collections\n- American Memory: more than 100 collections containing 9 million digitized items such as American State Papers recording Congressional acts from 1789 to 1838 (laws granting individual petitions, such as for a divorce, are documented here), Civil War images, Slave Narratives from the Federal Writers’ Project, WWI Military Newspapers, and panoramic maps of US and Canadian cities\n- Library of Congress Online Catalog: contains 17 million catalog records for books, serials, manuscripts, maps, music and more\n- Geography and Maps: more than 5.5 million maps, 80,000 atlases, 6,000 reference works, 500+ globes, and a large number of other cartographic materials in other formats\n- National Jukebox: recordings from 10,000 78rpm disc sides issued by the Victor Talking Machine Co. between 1900 and 1925\n- Prints & Photographs: more than 14 million photographs, fine and popular prints and drawings, posters, and architectural and engineering drawings\n- Veterans Oral Histories: interviews of veterans who served in World War I through modern wars\n1897 | LOC building is opened to the public\n1976 | LOC creates the American Folklife Center\n1987 | James Hadley Billington sworn in as 13th Librarian of Congress\n1994 | LOC website debuts\n1996 | 23 digital collections produced for American Memory Project as part of the Library of Congress/Ameritech National Digital Library Competition\n1998 | Prints and Photographs Online Catalog debuts\n2000 | Congress institutes the National Digital Information Infrastructure and Preservation Program\n2002 | Veterans History Project goes online\n2007 | Chronicling America newspaper site launches\n2009 | LOC gets on Twitter, Facebook and YouTube\n2010 | LOC acquires Twitter archive\nThe Library of Congress might not be the first place most genealogists go to flesh out a family tree. But with millions of materials available in its many collections, your search here could turn up a record mentioning your ancestor. But you also might find community histories, maps, oral history interviews, photos and more to help you form research theories and illuminate your ancestors’ lives. You can use the main search screen (shown on the next page) to search all records, or click specific collections to search. Browse to collections of interest by topic, time period, place, or type of materials here. Note that a particular group of records may be part of more than one collection. For example, Civil War maps are searchable in American Memory and in Maps.\nYou can use either capital or lowercase letters when searching (case doesn’t matter), and enter words in any order. Avoid using punctuation and special characters (such as diacritics) that could throw off your search.\nTo get more results, use the Search All field on the home page to search everything in the catalog at once rather than searching a single collection. Also use fewer words, because many “inventory level” records include only information from a caption or caption card, so, for instance, an individual’s first name may not be included or fully spelled out (Amelia Earhart nets 56 results; Earhart gives you 61). Check spelling and spacing of search word(s), try alternate spellings, spell out abbreviations, or use wildcards to enable the search to include variations on a word (child* retrieves child, children and childlike). Besides names, search for your ancestor’s street, neighborhood, town, school, church, military unit, fraternal organization, employer or other group. Results may come in different formats including LOC web pages, prints, photos, sound recordings, text, and more.\nNot sure what search terms to use? Try browsing highlighted collections or by topics to gather clues about the kinds of images that are in a collection or the kinds of words that are in the descriptions. Finding too much? Narrow results by using the Refine Your Search filters to the left of your search results. By default, LOC.gov shows you matches for items available online. Use the filters to see all items (includes descriptions for the library’s non-digitized materials that match your search), and to narrow results to a particular format (such as photos or books), date range or LOC collection. You can view your search results in a List, Gallery (large icons), or Grid (small icons) by clicking their corresponding icons above your results.\nUse advanced search features within each collection to drill down and get better results. In the Prints and Photographs catalog, click Advanced to select options to “match all words” or to “match exact phrase.” Select “No variants” to eliminate words with alternate endings from your search results. If your interest is Veterans History, click on Veterans History (you’ll end up at loc.gov/vets) and select Search the Veterans Collections. You can then search or browse for names, as well as additional categories, to find oral history interviews that shed light on your military ancestor’s experience.\nIf you can’t visit the LOC to access non-digitized items, visit your local library to ask about using Interlibrary Loan. Here’s where to click on the Loc.gov home page to find what you need:\n2. Click for access to print, pictorial and audio-visual collections and other digital services.\n3. Click to search the LOC online catalog, with descriptions of the library’s books, serials, manuscripts, cartographic materials, music, sound recordings and visual materials. Find examples of genealogical searches on the LOC tips page.\n4. Contact an LOC librarian to ask subject-based questions. Some Reading Rooms have an online chat capability.\n5. Click here to search the American Memory collection, which now features more than 100 themed collections of manuscripts recordings, images, maps, sheet and more.\n6. Use this link to access a catalog describing about 95 percent of the LOC’s pictorial holdings. About 1.2 million are digitized online.\n7. Search digitized newspapers and a directory of US newspapers at Chronicling America project.\n8. Search for oral histories, photos and other materials relating to veterans.\n9. Access a portion of the library’s audio collections, including recordings in the National Jukebox.\n10. Browse or search for military, town and county, and other historical maps.\n11. Search manuscripts—personal, organizational and other papers.\n12. Find answers to most-asked questions about the LOC, plus news and visitor information.\n13. Find links to other LOC entities, such as the Copyright Office, Legislative information and more.\n14. Use these links to quickly print, save or share (via social media or email) your finds.\n15. Scroll down for links to LOC blogs, apps and other educational resources.\nTo see if information about your ancestors is included anywhere in American Memory, enter your family name in the search box at the top of each American Memory page. You’ll will want to consult the bibliographies, research guides, and web links available through the Library’s Local History and Genealogy Reading Room.\nHow to Find Free Photos & Maps on the Library of Congress Website\nTop search strategies\n- Search for surnames.\n- Do place-based research. To find American Memory collections devoted to particular city, state or regional subjects, you can search the collections in a variety of ways. To find information about a specific place, enter the name in the search box at the top of the page. An All Formats search for San Francisco, California nets more than 23,000 results. Specifying materials that are available online takes it down to 13,400 results. Also try searching just the American Memory collection (which has a Cities and Towns category) and the Maps collection.\n- Map it. The Library of Congress has custody of the largest and most comprehensive cartographic collection in the world, with more than 5.5 million maps, 80,000 atlases and more. Even though the online maps represent a fraction of what the LOC has, there’s a lot to explore here. Search for towns and counties where ancestors lived. Search for Civil War battles they fought in to see battlefield maps.\n- Search transcriptions. The LOC groups its manuscript division materials into collections such as African-American Odyssey; WPA Federal Writers’ Project, 1936-1940; American Women: A Gateway to Library of Congress Resources for the Study of Women’s History and Culture in the United States; and others. These materials may be available as both digital images and as searchable text; visit the page for each collection for details about it and to browse content.\n- Picture it. Searching the Prints & Photographs collections will turn up photographs, prints and drawings, posters, and architectural and engineering diagrams whose catalog descriptions match your search terms. Learn more about the types of images the collections contains. The collection includes many portraits, although not all are identified. In some cases, the images belong to other libraries, and you’ll see only a small version. If you’d like to use the image in your research, check the Rights and Reproductions link for ownership information.\n- Searching for prints or photographs? Check the Library of Congress’ Thesaurus for Graphic Materials to find standardized terms the library uses to index images related to your research interests.\n- Many American Memory collections contain sound recordings, video, high-resolution images, and enhanced text that require special viewers. Most plug-ins to view or listen to these items are free downloads.\n- The Ask a Librarian form lets you ask a general question via an online form. A librarian in your subject area will email you an answer within five days. Pages for some collections offer online chatting for instant help; look for a chat icon.\n- Once you find an item of interest, check its catalog record page. There you’ll see a More Like This section with links to similar items. You’ll also see a list of subjects the item is cataloged under (click one to search for all items with that subject) and a list of all the collections that item is part of (which may suggest other collections you should check).\n- Most digital images in your search results will have a Share/Save tool at the top of the page. These let you share the item on social media and save a bookmark in your web browser. To save an image to your computer, click the link for the file format and size you want. If it opens in your web browser, right-click (control-click on a Mac) and select Save Image As.\n- American Folklife Center\n- American Memory Project\n- Ask a Librarian\n- Bibliographies, Research Guides, and Finding Aids\n- Browse digitized collections by topic\n- Chronicling America\n- Collections Access, Loan & Management Division: Find information on borrowing items through interlibrary loan, as well as researching in person.\n- Copying and Duplication Services\n- Hispanic Reading Room\n- Library of Congress Subject Headings\n- LOC iTunesU courses\n- Manuscript Reading Room\n- Mobile Apps\n- Online Catalog\n- Prints and Photographs Online Catalog\n- Recorded Sound Reference Center\n- Research and Reference Services\n- RSS Feeds and Email subscriptions\n- US Copyright Office\n- Veterans History Project\nFinding Photos of Your Family History video class\nState Research Guides ebook\nWashington, DC, research guide","Thursday, February 19, 2015\nOld Testament Books List for Codex Vaticanus\nImage: The opening of the Psalms in Codex Vaticanus\nNote: The digital age is truly amazing. Codex Vaticanus has been posted online. Now, you do not have to travel to Rome’s Vatican library to view the codex, or purchase an expensive facsimile, or live near a library which has a facsimile. Add this to access to Codex Sinaiticus, which has been available online for a couple of years now, and anyone can examine the two codices that have had the biggest impact in dethroning the received text.\nI began poking around the codex this morning. I had recently been interested in finding out how Vaticanus ordered the Biblical books (both OT and NT) and what apocryphal books it included in the OT. I had not been able to find a complete listing in secondary sources and had not yet been able to visit a library to look at a facsimile. Now, I can access it with the click of a mouse.\nMy interest in how Vaticanus orders the OT books is related to the development of canon in the fourth century AD (when the bulk of Vaticanus was apparently written—some sections were obviously written and added later [they appear in a completely different writing script which apparently dates to c. fifteenth century] to fill in gaps in the text, which the online version now also allows one to see in the opening of Genesis and the book of Revelation). There was obvious fluidity in the selection of the Old Testament books and also fluidity with the texts of those individual books. This is a factor that I do not think advocates of the modern critical text have adequately taken into consideration when they give such weight to Vaticanus and Sinaiticus in determining the NT text.\nHere is the list and some notes on the OT books in Vaticanus. I have not yet taken a close look at the entire text (e. g., examining additions to Esther and Daniel), so some of the info below might need to be nuanced, but here is a preliminary list.\nVaticanus Old Testament Books List*\n3 Esdras (LXX 1 Esdras)\n2 Esdras (Ezra-Nehemiah)\nSong of Songs\nPrologue to Ecclesiasticus\nEsther (with additions)\nEpistle of Jeremiah\nSome Notes on the Old Testament canonical order and content of Codex Vaticanus:\n1. The opening order: Genesis—2 Chronicles follows the LXX order with Ruth inserted between Judges and 1 Samuel.\n2. The apocryphal book of 3 Esdras (LXX 1 Esdras) is then followed by 2 Esdras (Ezra-Nehemiah).\n3. Next is the poetic and wisdom literature from the Hebrew Bible, following the LXX order.\n4. Next is the apocryphal wisdom literature of Wisdom and Ecclesiasticus. Note that Ecclesiasticus is preceded by a prologue. Note: Apocryphal Psalms of Solomon not included.\n5. Next is Jewish diaspora literature, including canonical Esther (with additions), followed by the apocryphal books of Judith and Tobit. Note: Apocryphal books of 1-4 Maccabees not included.\n6. Next are the twelve Minor Prophets (Hebrew Book of the Twelve) following the LXX order.\n7. Finally, there are the Major prophets. The “Jeremiah corpus” includes the apocryphal Baruch and the Epistle of Jeremiah. The Old Testament ends with canonical Daniel (with additions)."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:08cd7a96-8835-43f7-9130-2bb270a8852b>","<urn:uuid:8e131bc7-4ccf-41c9-b2cc-cc9f94e5844e>"],"error":null}
{"question":"What are the current satisfaction rates for rhinoplasty procedures, and how has the mentorship tradition in facial plastic surgery influenced its development?","answer":"Studies show an overall patient satisfaction rate of 83.6% for rhinoplasty procedures, though men specifically report a lower satisfaction rate of 56.1%. The development of rhinoplasty techniques has been significantly influenced by a tradition of mentorship and teaching, with knowledge being passed down through generations of surgeons. This is exemplified by figures like M. Eugene Tardy Jr., who learned from Ira Tresley, who in turn learned from Samuel Fomon, creating a continuous chain of expertise and advancement in the field.","context":["- My Take: Standing on the Shoulders of Giants\n- News & Trends\n- New in My Practice | Cosmeceuticals: ISDIN’s Melatonik Serum\n- New in My Practice | Devices: QuantifiCare’s LifeViz Body System\n- Beauty Counter MD\n- New Products\n- Women in Aesthetics: Mary Fisher\n- In Focus: Think Different\n- Improve Collections, Improve Your Bottom Line\n- Thrive in the Face of Competition\n- Set Your Practice Apart: The Power of Specialization\n- A Recipe for Success\n- “I Have a Lot of Friends I Could Send You,” and Other Lies Patients Tell\n- Making a Difference: How Aesthetic Physicians Can Act Locally to Help Others\n- Cosmetic Injectables Update: More Developments in Neurotoxins\n- Business Advisor: Beat the Clock: Improve Patient Wait Times\n- Aesthetic Marketing Management: Your Guide to Attention-Grabbing Headlines\n- Financial Planner: Three Mistakes to Avoid When Choosing Your Advisors\n- Three Ways: Building a Brand: What are the Most important components?\n- Virtual Voice: RealSelf Survey: 36 Percent of US Adults are Considering Cosmetic Treatments\n- Coming & Going\nMy Take: Standing on the Shoulders of Giants\nBy: Steve Dayan, MD\nComing of age in suburban Chicago, my interests centered around football and the opposite gender. Occasionally between penciling in my social calendar and studying, I peered up at my bookcases to see the three-volume series, Medicine and the Allied Sciences (1920) authored by my uncle, or at least that is what I was told. My grandfather’s brother, a descendant of enlightened German ancestry and a professor at the University of Illinois, was well known for teaching a popular review course in general medicine. I understood he was a passionate teacher with a skill for making the complex simple. He became a surgeon. Later, when deciding to pursue a career in facial plastic surgery, I learned he was instrumental in bringing rhinoplasty into the US. His name was Samuel Fomon, PhD, MD. Along with Irving B. Goldman, MD and Maurice H. Cottle, MD, he founded the American Academy of Facial Plastic and Reconstructive Surgery (AAFPRS). Many rhinoplasty instruments bear his name. (I may have unapologetically dropped his name during fellowship interviews—there has to be some benefits to being a new found legacy.) To this day, I consult those same books and others he has written. Recently, I was brought closer to him at a conference in Curitiba, Brazil. I mentioned my uncle during a talk and was approached afterward by Dr. João Maniglia, a Brazilian Facial Plastic surgeon. He mentioned that he had learned from Uncle Sam and happened to have an instructional video that my uncle created in the 1950s. João got it from his brother Tony, a prominent Otolaryngologist and former Chairman at Case Western Reserve, who received it from my uncle’s widow. I was thrilled to see it, and João graciously gave me a digital copy. João then went on to tell me stories of the giants from whom he learned. In parallel, I also was introduced to more than 100 doctors who learned rhinoplasty from João. It dawned on me that João is to Brazilian Facial Plastic Surgery what Sam Fomon was to US Facial Plastic Surgery.\nI was fortunate to learn from a multitude of great pioneers in rhinoplasty including M. Eugene “Gene” Tardy, Jr., MD who spent time under Ira Tresley, MD who learned from my Uncle Sam. I did my fellowship with Stephen Perkins, MD, who descends from Drs. Gaylon McCollough and Jack Anderson. And I was fortunate to be a resident at the University of Illinois witnessing Dr. Dean Toriumi’s meteoric evolution. Without their pioneering efforts and willingness to teach and share, I am not sure I’d be where I am today. These great leaders, if not directly, then indirectly, paved the way for many of us.\nAll of this prompted me to wonder how well we truly appreciate where we come from and the impact it has on who we are. There is increasing evidence that a collective memory is passed on genetically.1 Traumas and learned behaviors by your ancestors may lead to inexplicable reflexive thoughts and actions coded within the nucleotides of your DNA. For eons, embedded heuristics have compounded as family units didn’t stray far from their locations or tribes. It is only in a post-modern era that heterogenous peppering occurs as we increasingly drift from our nuclei to different cities, countries, or continents. Genotypes, phenotypes, and perhaps social behaviors are by-products of centuries of external environmental pressures. Who you are is based on thousands of years of adaptive evolution. If you really want to better understand who you are, the way you think and act, there is no better way than to return to your roots. Visit from where you come, walk the streets of your ancestors, sit in the cafes of your kin, pray in the pews of your past.\nI am the heterogenous product of a diverse union. My maternal lineage features Eastern European polymaths and upper class socialites. My paternal side extends from community leading Kabbalists and Middle Eastern street merchants. Last year I had the opportunity to visit the old ghetto in Marrakech, Morocco where my father was born and reared. I visited the grave sites of my great grandparents and the final resting place of cousins and family members I didn’t know I had. The elderly graveyard attendant with less teeth than hair shuffled me through a family history that I was embarrassed to say he knew better than I. In the markets, I talked with shopkeepers who recognized my surname and told me tales of my tribe. A visiting Canadian woman told me she knew where my family lived and took me there. It is hard to believe my father and eight siblings lived in that small of a dwelling. I watched locals haggle for bread, argue aggressively, and hug and kiss passionately. I saw families celebrating over shared meals, and I visited respected sages from schools with no name. I left Morocco with a different perspective on who I am, who my family is, and where I am intended to go.\nWe are products of a past and exist in the present as stewards of knowledge gained from the collected experience of prior generations in our professional or personal presence. We are tasked with the privilege to deliver forward.\n1. Ridley, Matt. (2003). Nature via nurture: genes, experience, and what makes us human. London : Fourth Estate\n—Steve Dayan, MD\nCo-Chief Medical Editor\nWho influenced you?\nTell us about the giants who influenced your career, so we may recognize them. Email: email@example.com\" or Tweet @ModAesthetics #mentors #giants","What is Rhinoplasty (nose job)?\nRhinoplasty is the medical term for the procedure commonly known as a nose job, a surgical procedure where the shape of the nose is altered. Surgery to improve the nose has been in practice for thousands of years but this was typically done as a reconstructive procedure for broken or otherwise damaged noses. The first purely cosmetic rhinoplasty is attributed to a German plastic surgeon named Jacques Joseph who published a report on fixing a patient’s hump nose in 1904.\nRhinoplasty has remained a popular procedure since the mid-1900s and consistently places in the top 10 most performed aesthetic surgeries.\nHow does it work?\nWhether you want your nose reduced in size, increased or just reshaped, the surgeon first needs to cut through the skin of the nose in either an ‘open’ or ‘closed’ rhinoplasty. In closed rhinoplasties, the surgeon makes cuts inside the nostril which will hide any scars following the surgery. Depending on the scope of the corrections however, it might not be possible to do a closed rhinoplasty. In this case the surgeon will make a cut in the skin between your nostrils and pull the tip of your nose back, revealing the cartilage beneath. Open rhinoplasty has the benefit of a better view of the cartilage being worked on and can give better control of the cuts being made.\nOnce the opening cuts have been made, the following steps depend on what the patient wants done to their nose. If the patient wants reshaping and not a change in overall size, then cartilage can be moved around and the bone broken and re-set in a different shape to give the desired nose shape. Reduction in size can involve the cutting and removal of cartilage and/or the chiselling away of bone. Nose size can also be increased by grafting on extra cartilage from the ears and bone from the hips, although artificial grafts can also be used.\nOther corrections like narrowing the tip of the nose or changing the way the tip points can be done with stitches to the cartilage.\nWhat is it like?\nThe surgical procedure is typically done under general anaesthetic so the patient will be unconscious throughout. The surgery will last around 2 hours. Once the desired changes to bone and cartilage structure have been made, the cuts used to access them will be stitched up. For an open rhinoplasty this will leave a small scar between your nostrils but once healed they aren’t usually very noticeable.\nWhen the anaesthesia wears off you will have gauze packed into both nostrils and a splint on your nose. The gauze will prevent breathing through your nose but is removed when leaving the hospital. You can typically leave either the same day of the surgery or the day after. The splint will have to remain in place for at least a week.\nThere may be a follow up assessment session where the splint is removed and healing and shape are checked. A second, corrective rhinoplasty may be required if the first did not work as desired and this happens in as many as 15% of nose jobs.\nWhat is the recovery time?\nFor at least a week following the procedure you will be required to wear a splint over your nose. It is typically recommended to take this week off work as well.\nSwimming should be avoided for three weeks following the surgery, and strenuous activity and contact sports should be avoided for at least a month.\nYou may also be advised to avoid heavy sneezing and blowing your nose as well as wearing glasses.\nAll the recovery period times can vary and you should follow the advice of your doctor.\nWhat are the risks and side effects?\nAs a surgical procedure, rhinoplasty comes with some serious possible risks and side effects. There’s a small chance that following surgery you could develop permanent breathing problems, have and altered or lost sense of smell, develop an infection or blood clot or experience excessive bleeding during or after surgery.\nLess severe side effects include considerable bruising and swelling around the nose as well as black eyes, pain and tenderness around the nose and nosebleeds.\nSome people can also experience allergic reactions to anaesthesia.\nHow much does it cost?\nRhinoplasty can cost between £4,500 and £7,000.\nSo is it worth it?\nRhinoplasty is a serious, expensive and permanent procedure so it’s important to weigh up you options before undergoing surgery. Thousands of people in the UK each year undergo this procedure and a study found that overall satisfaction with the results was 83.6% of patients, though men alone had a much lower satisfaction of 56.1% .\nIn terms of alternatives, injected fillers are becoming a popular method of non-surgical nose reshaping. While these offer an attractive prospect of nose correction with a tenth of the cost and none of the surgery they aren’t appropriate in all cases as they can only add size to the nose. They’re also a temporary measure and will wear off in a year or so.\nUltimately, rhinoplasty is the only option for permanent corrections to nose shape. The cost may be high but it should be a one-time thing compared to yearly filler top ups. There are some severe risks involved and the recovery period can last months but if you’re truly unhappy with your nose then rhinoplasty may well be worth it.\n3.Khansa, I., L. Khansa, and G.D. Pearson, Patient Satisfaction After Rhinoplasty: A Social Media Analysis. Aesthet Surg J, 2016. 36(1): p. Np1-5."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:f7c60e5c-0ffe-41a3-90b1-ecfd6a1a669b>","<urn:uuid:9268f80e-69a7-4d22-8564-1038808184ed>"],"error":null}
{"question":"What are the differences in counter-terrorism training approaches between Air Force Basic Military Training and Coast Guard MSRT, particularly in terms of Chemical, Biological, Radiological, Nuclear and Explosive (CBRNE) preparation?","answer":"The Air Force BMT includes basic CBRNE training during Week 4, where trainees learn to counter diverse threats including chemical, biological, radiological, nuclear and explosive weapons. In contrast, Coast Guard MSRT's CBRNE training is more advanced and specialized, occurring during the Advanced Tactical Operations Course. MSRT members receive extensive training in identifying and responding to CBRNE threats, and some team members become dedicated CBRN specialists within Direct Action Section units. Additionally, MSRT's counter-terrorism training is more comprehensive, including advanced tactical operations, hostile vessel boarding, and direct action capabilities, while Air Force BMT provides more foundational counter-terrorism awareness.","context":["Your career in the Air Force officially begins with Basic Military Training (BMT).\nBasic Military Training OverviewPREPARATION Zero Week:\nShock and Awe Week 1:\nFall In Week 2:\nBuilding a Foundation Week 3:\nFinding Your Strengths Week 4:\nPreparing for Combat Week 5:\nWelcome to BEAST Week 6:\nFinal Test Week 7:\nGraduation Airmen’s Week\nYour career in the Air Force officially begins with Basic Military Training (BMT). It is a challenging experience both mentally and physically but will ultimately transform you from humble recruit to confident Airman with the skills and confidence you need to excel as a member of the U.S. Air Force.\nThe actual process of joining the Air Force is fairly simple, and you'll be guided by your recruiter every step of the way. There are mandatory requirements and evaluations that you must pass to ensure you have what it takes to succeed as an Airman in the U.S. Air Force. The Delayed Entry Program App will give you an edge, and help prepare you for the challenges ahead.\nOnce you step off the bus, your journey officially begins. You’ll be assigned to a Military Training Instructor (MTI) who will give you direction and guide you through your transformation during the next seven and half weeks.\nDesigned to challenge you both mentally and physically, you’ll learn the basics of Air Force life and condition your body for the physical requirements needed to graduate.\nLearn about the Air Force’s proud history and rich heritage as you begin preparing for your role as an elite warrior in the world’s preeminent air and space power.\nYou’ll learn and embrace your role in countering diverse threats to national security, including terrorist attacks and chemical, biological, radiological, nuclear and explosive (CBRNE) weapons.\nYou’ll learn defensive fighting techniques and lifesaving skills so you’ll know what to do while under enemy fire and have the knowledge you need to save your life and those of your fellow Airmen.\nRegarded as the most challenging week of BMT, you’ll begin honing your skills through field training exercises and combat scenarios designed to bring out the wingman and warrior in you.\nFinal evaluations of your physical fitness and airmanship skills will begin to take place, and you’ll continue to learn more about the history and heritage of the Air Force.\nYou’ll celebrate your accomplishment in front of friends and family with the Airman’s Run and graduation ceremony.\nA final step before you head off to tech training, this week will be spent reinforcing core values and what it means to be an Airman in today’s Air Force.\nAll together now\nCut to code\nUp close and personal\nSalutes start early\nAll stretched out\nAlways at attention\nBlues in the bag\nNo pain, no gain\nProud to serve\nA little levity\nPugil stick fights\nCoordination is key.\nMaking An Entrance\nWeek 0 activities\nHere are some of the activities and requirements you’ll complete during week 0Download schedule\nWeek 1 activities\nHere are some of the activities and requirements you’ll complete during week 1Download schedule\nWeek 2 activities\nHere are some of the activities and requirements you’ll complete during week 2Download schedule\nWeek 3 activities\nHere are some of the activities and requirements you’ll complete during week 3Download schedule\nWeek 4 activities\nHere are some of the activities and requirements you’ll complete during week 4Download schedule\nWeek 5 activities\nHere are some of the activities and requirements you’ll complete during week 5Download schedule\nWeek 6 activities\nHere are some of the activities and requirements you’ll complete during week 6Download schedule\nWeek 7 activities\nHere are some of the activities and requirements you’ll complete during week 7Download schedule\nAirmen's week activities\nHere are some of the activities and requirements you’ll complete during Airmen's WeekDownload schedule Delayed Entry\nThe USAF Delayed Entry Program App allows for self-improvement and preparation prior to entering the rigorous environment of Basic Military Training (BMT).FEATURESTraining\nOne of the biggest challenges of BMT is Physical Training (PT) and proper nutrition. Learn about our standards to ensure that you meet our strict height and weight requirements for graduation before reporting to BMT.FEATURESStudying\nDuring BMT, you'll learn everything you need to know to begin your journey in the Air Force. But get a head start on memorizing some of the basics.FEATURESPacking\nWhat do you bring to BMT? Here's a checklist for all the necessary items you'll need and those that we'll provide.Get A Head Start.\nDownload The App.\n- Learn reporting statement\n- Flight assignment\n- Clothing and equipment issue\n- Dorm and drill basics\n- Individual duty assignment\n- Reporting and saluting\n- Entry control procedures\n- Medical and dental appointments\n- Fitness and nutrition\n- Educational benefits briefing (MGIB/Post 9/11)\n- Air Force History 101\n- ID card Issue\n- Individual drill\n- Flight drill\n- Dorm preparation\n- Air Force rank insignia\n- Weapon issue\n- Weapon parts identification\n- Human relations and cultural sensitivity\n- Career guidance\n- Warrior role\n- Weapon handling and maintenance\n- Air Force History II\n- Suicide awareness and prevention\n- Comprehensive Airman’s fitness\n- Basic leadership and character\n- Basic situational awareness\n- Military citizenship\n- Cyber awareness\n- Joint ethics\n- Mental preparation for combat\n- Law of armed conflict\n- Introduction to Air Force combatives\n- Antiterrorism/Force Protection Level I\n- Joint warfare\n- Second clothing issue\n- Dress and appearance (service uniform)\n- Interview sessions\n- CBRNE/chamber training\n- Principles of First Aid\n- Sexual Assault Prevention and Reporting (SAPR)\n- Foundational Expeditionary Skills Training (FEST)\n- Integrated defense\n- Cover and concealment\n- Tactical movement\n- Firing positions\n- Force Protections Conditions (FPCON)\n- Defensive fighting positions\n- SALUTE (Size/Activities/Location/Unit ID/Time/Equipment) reporting\n- Individual portraits and flight photos\n- Introduction to the Code of Conduct\n- AEF (Air Expeditionary Force) prep\n- Weapons evaluation (breakdown and assembly)\n- Basic Expeditionary Airman Skills Training (BEAST)\n- Refresher drills (FEST, First Aid, UCC and PAR)\n- Combat Arms Training and Maintenance (CATM)\n- Combatives application\n- Pugil stick application\n- Creating Leaders, Airmen and Warriors (CLAW)\n- Field exercises\n- Environmental awareness\n- Financial management\n- Sexually transmitted diseases\n- Combat stress recovery\n- Base referral agencies\n- Computer base training/Air Force Portal familiarization\n- Military entitlements and education opportunities\n- Career progression and Air Force quality of life\n- Written test\n- Evaluation of drill, reporting and courtesies\n- Physical Training (PT) evaluation\n- Airmanship and core values\n- Air Force fitness program\n- Technical school briefing\n- Squadron commander’s departure briefing\n- Town pass briefing\n- Airman’s Run\n- Honor graduate recognition\n- Airman’s Coin and formal retreat ceremony\n- Airman’s Parade\n- Commander’s Welcome Briefing\n- Character development training\nYour future is waiting.\nApply NowGET STARTED\nWant to learn more about Basic Military Training?\nBasic Military Training (BMT) is a seven-week course that will challenge you mentally and physically. But in the end, you’ll come out as a qualified Airman ready to serve.\nTake a minute to chat with an advisor and find out more.CHAT LIVE\nWant to learn more about pay & benefits?\nIn addition to a competitive salary and excellent healthcare, you’ll enjoy other benefits such as tuition assistance, 30 days of vacation with pay each year and more.\nTake a minute to chat with an advisor and find out more.CHAT LIVE","The United States Coast Guard sometimes gets treated like an after thought because of the common stereotypes.\nWhile personnel of the Coast Guard are technically not members of the Department of Defense (DoD) like the other major branches of the U.S. Armed Forces, they do serve an important purpose.\nFurthermore, the U.S. Coast Guard touts its own special forces unit that rivals the training and mission capacity of SOCOM.\nThe Coast Guard Maritime Security Response Team (MSRT) acts as first responders to domestic terrorist situations both on land and sea.\nCoast Guard MSRT members are highly respected and acknowledged within the military community as they often train alongside Navy SEALs.\nLearn more about the USCG MSRT including the selection and training process by reading the full article:\nRelated Article: How To Join The Coast Guard\nWhat is Coast Guard MSRT?\nThe United States Coast Guard primary focuses on maritime security, search and rescue, and law enforcement activities.\nNonetheless, the uniformed branch also produces its own specialized unit known as the Coast Guard Maritime Security Response Team (MSRT).\nCoast Guard MSRT serves as the full-time counter-terrorism assault team of the maritime law enforcement branch.\nThus, the special unit is highly trained as it provides first response for terrorist situations that require boarding a hostile vessel.\nUSCG MSRT operates in both domestic situations as well as abroad.\nThey are considered the first call when dealing with hijacked ships and neutralizing terrorist situations on open waters.\nPiracy and other threats at sea have contributed to more of a demand for Coast Guard MSRT in the last decade.\nAs a result, the U.S. Armed Forces has put extra emphasis on training the special unit as Maritime Security Response Teams often train alongside Navy SEALs.\nCoast Guard Maritime Security Response Teams were formally established by the federal government in 2006 yet have technically existed in different forms for many decades.\nCoast Guard MSRT represents the only unit within the military branch with counter-terrorism capabilities.\nTherefore, it may conduct action against hostile targets both at land and sea.\nCoast Guard MSRT also routinely trains and collaborates with other agencies like the FBI and Secret Service.\nIt has firm working relationship with border patrol agencies units such as BORTAC as well as Customs and Border Protection Special Response Teams (SRT).\nCoast Guard MSRT functions under the motto “Nox Noctis est Nostri” or “The Night Is Ours”.\nCoast Guard MSRT Job Duties\nThe U.S. Coast Guard Maritime Security Response Team (MSRT) is a special unit that provides many functions to the military branch and national security:\n- Counter-Terrorism (CT)\n- Direct Action (DA)\n- Advanced Interdiction (AI)\n- Hostage Rescue/Personnel Recovery\n- Counter Assault\n- Small Unit Tactics\n- Tactical Maritime Law Enforcement\n- Airborne Use of Force (AUF)\nCoast Guard Maritime Security Response Teams also work with K9 explosive detection teams.\nThey are trained to board medium to high risk vessels (level III & IV).\nCoast Guard MSRT members are generally selected through experienced maritime law enforcement candidates.\nThe USCG also considers members that currently serve on Coast Guard Maritime Safety & Security Teams (MSST) and Tactical Law Enforcement Teams (TACLET).\nMaritime Security Response Teams were originally part of the Coast Guard Deployable Operations Group (DOG), which was dissolved in 2013.\nHowever, the Coast Guard continues to fund and train MSRT units as the first line of defense against terrorism on open waters.\nRelated Article: 5 Maritime Security Jobs: Earn Big Working at Sea!\nCoast Guard MSRT Pipeline Snapshot\nCoast Guard MSRT receives training to act as the first response team to potential terrorist threats.\nThey are also capable of denying preemptive terrorist actions, executing security actions against armed hostiles, participating in port level security, and executing tactical facility entry.\nWhile USCG MSRT primarily focuses on the safety and security of homeland defense, teams may also get deployed worldwide to respond to incidents.\nAs a result, Coast Guard Maritime Security Response Team members are highly trained and versatile.\nHere is a quick overview of what you can expect in terms of Coast Guard MSRT training from start to finish:\nUSCG MSRT Training Pipeline\nStage 1: Coast Guard MSRT Preparatory School\nThe introduction to Coast Guard special unit training. You’ll focus a lot on conditioning to prepare for a physical fitness test.\nStage 2: Coast Guard MSRT Orientation\nRecruits spend a few weeks getting an introduction to what it is like serving the Coast Guard in this capacity. You should expect a lot of classroom learning during the orientation.\nStage 3: Basic Conditioning\nCoast Guard MSRT has comparable training standards and exercises to Navy SEALs. Therefore, you could consider this stage of conditioning similar to “Hell Week” for SEALs. If you are going to drop out, this is probably the week.\nStage 4: Combat Diving & Swimming\nMembers of the U.S. Coast Guard are experts divers and swimmers. As you can imagine, Maritime Security Response Team members get additional, advanced training in the water.\nStage 5: Land Warfare Training\nRecruits begin to transition more into the culture and lifestyle as they adapt to land training exercises. The focus is on handling weapons and marksmanship, as well as land navigation and patrolling.\nStage 6: Coast Guard MSRT Qualification Training\nThe final phase of training for Coast Guard MSRT recruits. The stage covers advanced tactical training and procedures. You’ll need to complete final exercises and exams to qualify.\nCoast Guard MSRT Selection & Requirements\nThe United States Coast Guard has general requirements for all service members.\nAdditionally, every member of the military branch must complete basic training.\nCoast Guard boot camp lasts 8 weeks and is considered one of the more strenuous of all the military branches.\nFurthermore, male and female recruits (regardless of age) are held to the same intense physical fitness standards.\nYou’ll need to meet the following minimum fitness standards to qualify for service:\n- 5 Pull-Ups\n- 5 Chin-Ups\n- 40 Push-Ups (Under 1 Minute)\n- 40 Sit-Ups (Under 1 Minute)\n- Swim 100 Yards in Full ODUs and Boots\n- Swim 500 Yards (Under 20 Minutes)\n- Run 1.5 Miles (Under 12 Minutes)\nMembers of the U.S. Coast Guard need to be exceptional divers and swimmers in addition to training on land.\nThe requirements for joining Coast Guard MSRT are extensive because of the physical and mental demands of the job.\nAdditionally, you must qualify for security clearance with the Department of Defense.\nIn order to qualify, recruits must endure a thorough background check that involves looking into your personal finances and character, along with criminal history.\nThose that require higher security clearances may also have family or friends under investigation during this process.\nRecruits that seek to join Coast Guard MSRT generally already serve the country in the military branch.\nThus, they already have experience and have developed a stellar reputation in terms of job performance and character.\nBecoming Coast Guard MSRT is very competitive and many facets of the selection process are kept under wraps because most of the duties the special unit performs are highly secretive.\nThere is only a small fraction of recruits that attempt to secure a spot within the prestigious team that gain acceptance.\nConsequently, you’ll need to work your butt off to join this elite force.\nThe selection criteria for Coast Guard MSRT is rigorous yet worth the adventure if you make the cut.\nRelated Article: List Of Coast Guard Bases In The US\nCoast Guard MSRT Training Process\nThe Coast Guard traditionally finds candidates for MSRT through its pool of Maritime Enforcement Specialists (ME).\nConsequently, if you are interested in becoming MSRT, you’ll want to get into the Maritime Enforcement rating.\nRecruits start training for this rating at Maritime Enforcement “A” School.\nUnfortunately, the wait for ME “A” School can take 3 years or more since the training program is in high demand.\nThe second stage screens potential candidates for Coast Guard MSRT with physically and mentally challenging exercises.\nThose that complete the approximate 2 weeks of training receive orders from the USCG MSRT Whetstone Division.\nThe stage of training focuses on combat shooting and team movement exercises.\nThe purpose of the training is to produce competition for select seats that offer an invitation to the next stage in training – the Basic Tactical Operations Course.\nRecruits learn a ton at the Special Mission Training Center (Camp Lejeune, North Carolina) if they are fortunate enough to receive an invite to advanced tactical training.\nThe Basic Tactical Operations Course lasts 2 months and trains recruits on a variety of skills.\nYou’ll learn advanced shooting techniques, breaching, mission planning, and close quarters combat (CQC) to name a few.\nSecond Half of USCG MSRT Training\nRecruits that complete the Basic Tactical Operations Course return to Whetstone Divsion where they endure more training while competing for spots at the Advanced Tactical Operations Course.\nYou will also need to complete the Advanced Tactical Operations Course at Camp Lejeune in order to quality for Coast Guard MSRT.\nDuring this stage of straining, you’ll spend a couple of months learning how to manage shipboard assaults.\nRecruits are also trained on how to identify Chemical, Biological, Nuclear, and Radiological (CBRN) threats.\nStudents advance after CBRN training to their first Coast Guard Maritime Security Response Team.\nThere, they must earn their qualification as an Advanced Tactical Operator.\nOnce the recruit becomes an official Advanced Tactical Operator, he or she may train on additional skills like breaching or precision marksmanship.\nAll in all, the Coast Guard MSRT training process lasts approximately 18 months without any major setbacks.\nCoast Guard MSRT Direct Action Section (DAS)\nThe United States Coast Guard does a good job of keeping a lot of the training for its specialized units secret.\nHowever, we do have some details about Coast Guard MSRT training from former team members that have been generous enough to share about their experience.\nThe Coast Guard keeps the training process private in the bests of interests of national security yet we do know that Maritime Security Response Teams often train with Navy SEALs.\nAs a result, the two special units utilize many of the same training exercises and expectations.\nNavy SEALs have some of the roughest training regiments in the world which says something about what Coast Guard Maritime Security Response Teams also endure.\nMost recruits that are interested in joining Coast Guard MSRT desire the Direct Action Section (DAS).\nThe Direct Action Section serves as the primary assault force of Coast Guard MSRT.\nThe typical team members of a DAS unit may include:\n- Team Leader\n- Precision Marksmen\n- Observation Members\n- Chemical, Biological, Nuclear, and Radiological (CBRN) Specialists\nDirect Action Section (DAS) Training\nOften, DAS units prepare for Coast Guard MSRT procedures through real-life training situations that involve simulations and role-playing.\nCoast Guard Maritime Security Response Teams are also well trained in handling explosives and diving procedures.\nThey utilize many of the concepts of the Navy SEALs notorious BUD/S (Basic Underwater Demolition/SEAL Training).\nFor comparison, Navy SEALs BUD/S training has only about a 1% survival rate which demonstrates precisely how difficult the selection and training is for specialized units in the water.\nThe Coast Guard Direct Action Section (DAS) trains extensively in advanced close quarters combat (CQC) and combat marksmanship.\nCoast Guard DAS units are highly trained to quickly and tactically board vessels that may be occupied or controlled by enemy targets.\nThus, they are well prepared for entry by air or sea and utilize a variety of methods to neutralize hostile targets.\nFrequently Asked Questions (FAQ)\nHere are some frequently asked questions about the Coast Guard Maritime Security Response Team (MSRT) unit:\nRelated Article: 18 Pros And Cons Of Joining The Coast Guard\nHow long does it take to join the MSRT?\nAll new members of the U.S. Coast Guard must complete basic training and other admission guidelines.\nCoast Guard boot camp takes 8 weeks before you progress to specialized training for your rating (military job).\nIt is recommended that those who are interested in Coast Guard MSRT pursue the Maritime Enforcement (ME) rating.\nIt generally takes another 18 months of training to complete the requirements for Coast Guard MSRT without any hiccups.\nAll in all, it generally takes a member of the Coast Guard at least 1.5 years to officially join MSRT.\nWhat kinds of operations is the MSRT involved in?\nThe Coast Guard Maritime Security Response Team (MSRT) is involved in many different activities of national security interest.\nWhile most of their duties involve domestic problems and disputes, MSRT units are sometimes deployed across the globe.\nIn general, USCG MSRT acts as the first line of defense against terrorist threats in the water.\nThese units are well trained in counter-terrorist and direct action measures to neutralize threats in the water, including hostage situations.\nCoast Guard MSRT personnel are incredibly well trained in a variety of weapons and explosives.\nIf there is a ship with enemy targets on board, the Coast Guard relies on MSRT to save the day.\nWhat other units does MSRT work with?\nThe Maritime Security Response Team closely trains with Navy SEALs.\nNavy SEALs has one of the most demanding and intense training regiments in the world, which says a lot about MSRT training expectations.\nCoast Guard MSRT also trains with other advanced units like:\n- Maritime Safety & Security Teams (MSST)\n- Tactical Law Enforcement Teams (TACLET)\n- Helicopter Sea Combat Squadrons\n- Navy Explosive Ordance Disposal (EOD)\n- Marine Corps Maritime Raid Force\n- Federal Bureau of Investigation (FBI)\n- Border Patrol BORTAC\n- Customs and Border Protection Special Response Teams (SRT)\nThe USCG Maritime Security Response Team (MSRT) is the only unit within the military branch that provides counter-terrorism support.\nCoast Guard MSRT closely trains with Navy SEALs and other elite special operations.\nThe Maritime Security Response Team acts as first responders to incidents in domestic and international waters.\nThey are leading experts on handling a crisis on a ship that may involve a hostage situation or piracy.\nCoast Guard MSRT are expert divers, swimmers, close quarters combat specialists, and explosion experts.\nHowever, it will take at least 1.5 years in training to become an official team member.\n- 15 Best Night Vision Goggles & Binoculars For 2022 (Military-Grade) - January 25, 2022\n- Sprint-Drag-Carry: ACFT SDC Explained - January 25, 2022\n- 5 Best Ghillie Suits For 2022 (Military-Grade) - January 16, 2022"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:b5be06a1-8ae9-45ad-bce9-4677003b78c2>","<urn:uuid:579bdcf6-d013-4285-a82e-fe4cf16c7065>"],"error":null}
{"question":"What are the innovative applications of 3D printing in NASA's space exploration, and what are the potential health risks associated with this technology?","answer":"NASA is innovatively using 3D printing to manufacture rocket engine parts, space pizza makers, and even physical photos from the Hubble Space Telescope. They are pioneering the creation of space cameras made almost entirely from 3D-printed materials, including a 2-inch camera for a cubesat and a 14-inch dual-channel telescope. This technology could significantly reduce manufacturing costs and time, as demonstrated by the 3D-printed camera requiring only four parts compared to conventional cameras needing 5-10 times more components. However, there are significant health concerns with 3D printing technology. NIOSH research has shown that exposure to 3D printer emissions can cause acute hypertension in rats and damage to lung cells, particularly when using ABS and polycarbonate materials. The emissions contain both small particles and chemical vapors that could potentially have adverse health effects, though the exact safe exposure levels are currently unknown.","context":["NASA is already using 3d printing to make rocket engine parts, a space pizza maker and even physical photos from the Hubble Space Telescope. But by the end of September, one NASA engineer expects to complete the first space cameras made almost entirely out of 3D-printed stuff.\n\"As far as I know, we are the first to attempt to build an entire instrument with 3D printing,\" Jason Budinoff, an aerospace engineer at NASA's Goddard Space Flight Center in Maryland, said in a statement.\nBudinoff is building a 2-inch camera for a cubesat — a miniature satellite. The camera will have to pass vibration and thermal-vacuum tests next year to prove that it's capable of space travel. Budinoff is also using 3D printing to build a 14-inch dual-channel telescope. [10 Ways 3D Printing Could Transform Space Travel]\nBoth instruments are being built to demonstrate how 3D printing (also called \"additive manufacturing\") can be used as a boon for space exploration. The new technique could cut down both the time and cost of traditional manufacturing.\nTo build the 3D-printed instruments, first a computer-controlled laser melts down a pile of metal powder. It then fuses the melted metal into a specific configuration determined by a 3D computer design. The instruments are built and assembled layer by layer — like slices of bread from a loaf. The layered approach makes it possible to build in tiny internal features and grooves that are impossible to build using traditional manufacturing.\nBut the instruments are not deep-space ready — at least not yet, according to Budinoff.\n\"I basically want to show that additive-machined instruments can fly,\"Budinoff said in the same statement. \"We will have mitigated the risk, and when future program managers ask, 'Can we use this technology?' we can say, 'Yes, we already have qualified it.'\"\nIn the future, 3D printers could reduce the overall cost of building space exploring instruments. For example, Budinoff's 3D printed camera only requires four separate pieces, whereas a conventional camera would require between five and 10 times the number of parts, according to Budinoff.\nBudinoff is also working on a way to build 3D-printed metal mirrors. Mirrors are crucial parts of telescopes, and it may be possible to create them with powdered aluminum. Aluminum is notoriously porous, which makes it difficult to polish. If Budinoff's theory is correct, then a process called \"hot isostatic pressing\" could convert the aluminum into a gleaming mirror.\nThe pressing technique involves taking a 3D printed aluminum mirror and placing it in a heated chamber under 15,000 pounds per square inch of pressure. The intense heat and pressure would lower the aluminum's surface porosity and create a polished mirror.\nThis kind of mirror could be especially useful for infrared instruments that must operate at extremely cold temperatures. Infrared sensors are usually made out of several different materials. But if all the parts were made out of aluminum, it would be easier to control the instrument's temperature.\nBudinoff will likely finish both instruments this year, and they will undergo spaceflight testing in 2015.","The NIOSH on 3D Printer Fumes and Health. Your Guide to 3D Printers and Health, Best Practices.\nThe NIOSH is a part of America’s CDC (Centers for Disease Control). The NIOSH itself is The National Institute for Occupational Safety and Health for the United States. It is the part of the government tasked with researching into the safety of workers in many professions. At 3DPrint.com we noticed a number of very interesting articles come out by NIOSH researchers about 3D printing. We were especially impressed with their thoughtful and thorough research on carbon nanotubes in 3D printer filaments. There is also a very informative post about 3D printers and safety on the NIOSH website. We’ve always been worried about 3D printing safety including fine particles and especially fumes from 3D printers. At 3DPrint.com we think that we are potentially creating significant health issues with some 3D printing practices. We, therefore, reached out to the NIOSH for some guidance. A group of NIOSH researchers took the time to respond to us with some best practices for 3D printer safety. We’re very thankful for their well thought out and clear answers to our questions. We must, as they have, qualify their statements as an initial response but we do believe that this is the clearest and most extensive look into 3D printing safety online.\n“It is important to note that there is a current lack of data on 3D printer emissions. In addition, the rapidly shifting description of the “workplace/production environment,” the availability of this technology beyond industrial applications, and the tremendous variety of feedstock polymers that are commercially available or can be made by consumers mean that additional research is needed to evaluate these emissions’ possible health effects.”\n1) If I 3D print with FDM at home should I get a fume hood or HEPA/Carbon filtration just in case?\n‘NIOSH focuses on worker health and our research is performed in the laboratory and in occupational settings, which can be quite different from homes. Consideration of whether to use a fume hood or filtration will depend on several factors, including the design of the 3-D printer, the type of filament being extruded (filaments are materials (plastic, nylon or other) that are fed into the printer in order to create the final object), the size and air movement in the room in which it is being used, and who is occupying the room (children, adults, people with pre-existing health problems).\nWhile there are no occupational exposure limits for the small particles emitted by 3-D printers, there are some exposure limits for specific chemical vapors that are emitted during printing. For occupational settings, these chemical exposure limits can be used to guide the selection of appropriate controls to reduce exposures to a safe level. In workplaces, NIOSH research has shown that appropriately designed and operated local exhaust ventilation with HEPA/carbon filtration reduces the amounts of particles and chemicals in air. It is important to understand that occupational exposure limits are intended to protect adults in workplace settings and, at this time, we do not know what levels of particles or chemical vapors would be safe for children and others in homes. Given this uncertainty, it is difficult to recommend specific levels that should be achieved when trying to reduce emissions in homes, though use of a printer in a well-ventilated area could help lower emissions.”\n2) What are the risks of 3D printing?\n“For FDM 3-D printers, there are risks related to the printer itself and potentially from the emissions. Risks related to the printer are similar to those associated with working with other types of machines and may include electrical shock from damaged power cords, burns from touching hot surfaces such as the extruder nozzle, and injury such as cuts from contact with sharp edges or contusions from contact with moving parts. At this time, our understanding of risks from particle and chemical vapor emissions from 3-D printers is limited.\nIn one study done by NIOSH, rats exposed for 1 hour to particle and vapor emissions from a FDM 3-D printer using ABS filament (a type of plastic material) developed acute hypertension, indicating the potential for cardiovascular effects. In another NIOSH research study, lung cells exposed to FDM 3-D printer emissions from printing with ABS and polycarbonate for about 3 hours showed signs of cell damage, cell death, and release of chemicals associated with inflammation, suggesting potential for adverse effects to the lungs if emissions are inhaled. These in vitro findings need to be confirmed with more extensive in vivo studies. It is important to understand that exposures used in toxicology studies may not be the same as those encountered by workers or in homes for a number of reasons, including the use of ventilation in workplaces or the amount of fresh air brought into homes by the heating and cooling system.”\n3) How would I best protect myself against 3d printing risks?\n“Risks related to the printer itself can often be eliminated by safe work practices and the design of the 3-D printer. For example, as with any electrical device used at work or in the home, daily inspection of the electrical cord can help to identify if the cord is damaged and should not be used. After an object is printed, allowing sufficient time for the extruder nozzle to cool down before removing the object from the build chamber will reduce the risk of burns. NIOSH researchers often observe smaller 3-D printers being used in workplaces that are also purchased by consumers for private use. Using a 3-D printer with a cover or doors that prevent the user from reaching in while machine parts are moving will help reduce the risk of injury.\n- At this time we do not know what levels of exposure causes adverse health effects, so we can’t recommend safe levels of exposure to 3-D printer emissions whether in the workplace or in homes. In occupational settings, we use the “hierarchy of controls” to protect workers from risks on their jobs. The hierarchy of controls specifies, from most preferred to least preferred, the types of controls that should be used to reduce occupational exposures:\n- The most preferred method is to substitute or eliminate the hazard. For example, in the case of FDM 3-D printing with filaments that contain carbon nanotubes, the emission of plastic-particles that contain carbon nanotubes can be eliminated by not using that type of filament if it is not necessary for the performance of the built object.\n- If a risk cannot be eliminated, engineering controls such as a fume hood or local exhaust ventilation (a system that specifically ventilates the printer rather than the air in a room) with HEPA/carbon filtration would be the next preferred method to reduce emission levels. Some 3-D printers are now being sold with built-in filtration units.\nAlternatively, a printer owner may purchase an after-market fan/filter systems to reduce emissions. However, NIOSH researchers have not yet evaluated how well these built-in or after-market filtration systems work. It is important to understand that for engineering controls such as fume hoods or local exhaust ventilation with filtration to be effective, these systems must be properly designed, built and operated.\nIn one workplace, NIOSH researchers showed that an appropriately designed and operated local exhaust ventilation with HEPA/carbon filtration reduced the amounts of particles and chemicals in air. NIOSH researchers have also observed that in some workplaces where the ventilation system is not built correctly that the chemicals are released back into the room air. Additionally, systems that use carbon filters to remove organic chemical vapors need to be monitored over time because the charcoal has a finite capacity to adsorb chemicals. Once this capacity is reached, the charcoal filter needs to be replaced or it will not capture additional organic vapor emissions.\n- If engineering controls cannot reduce the risk to an acceptable level, administrative controls may be used. An example of an administrative control is that NIOSH researchers have observed in some workplaces that employees do not enter the room where 3-D printers are operating unless it is necessary (e.g., to perform maintenance or to retrieve a built object).\nFinally, if none of these controls can reduce emissions to an acceptable level, the least preferred control is the use of personal protective technologies such as respirators or dust masks. In workplaces, respirators are the least preferred means of control because they do not remove the exposure, they only reduce the amount that might be inhaled; this depends on the proper selection of filters and cartridges that remove contaminants while breathing. Additionally, to be effective, respirators rely on the worker to properly wear and use the mask. To wear a respirator, a user must be medically cleared by a physician and it must be properly fitted and retested each year to ensure fit. The user must be properly trained on how to wear, remove, and maintain the respirator. NIOSH researchers have observed in some workplaces where 3-D printers are used that some employees with facial hair will put on a respirator, but the hair prevents the respirator from forming a tight seal with their face so the mask does not provide any protection to the worker.”\n4) If I had a 3D printer at a school what should my safety precautions be?\n“NIOSH focuses on worker health and our research is performed in the laboratory and in occupational settings, which can be quite different from environments such as homes or schools. For example, 3-D printers may be used with different frequency in schools and there may be only one printer operating in a large classroom as opposed to many printers in a small workspace. These differences will influence the types of controls implemented to reduce emissions.\nThere are no occupational exposure limits for the small particles emitted by 3-D printers but there are some exposure limits for specific chemical vapors that are emitted during printing. For occupational settings, these chemical exposure limits can be used to guide the selection of appropriate controls to reduce exposures to a safe level.\nIt is important to understand that occupational exposure limits are intended to protect adults in workplace settings. At this time, we do not know what levels of particles or chemical vapors would be safe for children in schools. Given this uncertainty, it is difficult to recommend specific levels that should be achieved when trying to reduce emissions in schools. In workplaces, NIOSH research has shown that appropriately designed and operated local exhaust ventilation with HEPA/carbon filtration reduces the amounts of particles and chemicals in air. If exhaust ventilation is not feasible, use of a printer in a well-ventilated area could help lower emissions.”\nYou May Also Like\nShould Vented Enclosures Become A Mandatory Safety Standard for FFF 3D Printers?\nWith innovation always comes unintended consequences. There’s been much-to-do with the possible health repercussions of 3D printing, particularly when it comes to the fine particles and fumes produced by the...\nHow Safe are the Titanium Powders Used in 3D Printing?\nHow safe is additive manufacturing? That’s a question that has been asked multiple times, and has been the subject of multiple research studies. In a recent study entitled “Titanium Powders...\nUL and Georgia Tech Continue Research Into Impact of 3D Printing Emissions on Indoor Air Quality\nIn 2015, non-profit safety science company Underwriters Laboratories (UL) and its Chemical Research Initiative, the Georgia Institute of Technology (Georgia Tech), and Emory University Rollins School of Public Health, worked together to conduct a two-year study...\nNew 3D Printing Safety Enclosure and Filtration System Designed for Ultimaker 3D Printers and XSTRAND\nThe Ultimate 3D Printing Store (U3DPS), based in Florida, was one of the first resellers in the US to carry engineering-grade XSTRAND 3D printing filament by Owens Corning. This exclusive material is...\nView our broad assortment of in house and third party products."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:e6bc4bef-14f2-45c3-9142-4f73ec032ced>","<urn:uuid:0a1cd8a3-01e6-42f3-83fd-9ed19b38da65>"],"error":null}
{"question":"What are the key benefits of mathematical modeling for scientific research, and how does it support robust decision-making in climate adaptation?","answer":"Mathematical modeling offers several key benefits for scientific research: it provides a fundamental and quantitative way to understand complex systems, complements theory and experimentation, and can replace experiments when they are too large, expensive, dangerous, or time-consuming. It's particularly valuable for 'what if' studies and has become indispensable in various fields including climate studies, seismology, and manufacturing. Regarding climate adaptation, mathematical modeling supports robust decision-making by helping manage deep uncertainty through multiple model runs to identify conditions where strategies succeed or fail. Rather than trying to predict exact futures, it allows stakeholders to debate how much robustness they can afford and helps create risk profiles and portfolios of measures with broader economic, social, and environmental benefits.","context":["Presentation on theme: \"MATHEMATICAL MODELING Principles. Why Modeling? Fundamental and quantitative way to understand and analyze complex systems and phenomena Complement to.\"— Presentation transcript:\nWhy Modeling? Fundamental and quantitative way to understand and analyze complex systems and phenomena Complement to Theory and Experiments, and often Intergate them Becoming widespread in: Computational Physics, Chemistry, Mechanics, Materials, …, Biology\nWhat are the goals of Modeling studies? Appreciation of broad use of modeling Hands-on an experience with simulation techniques Develop communication skills working with practicing professionals\nMathematical Modeling? Mathematical modeling seeks to gain an understanding of science through the use of mathematical models on HP computers. Mathematical modeling involves teamwork\nMathematical Modeling Complements, but does not replace, theory and experimentation in scientific research. Experiment Computation Theory\nMathematical Modeling Is often used in place of experiments when experiments are too large, too expensive, too dangerous, or too time consuming. Can be useful in “what if” studies; e.g. to investigate the use of pathogens (viruses, bacteria) to control an insect population. Is a modern tool for scientific investigation.\nMathematical Modeling Has emerged as a powerful, indispensable tool for studying a variety of problems in scientific research, product and process development, and manufacturing. Seismology Climate modeling Economics Environment Material research Drug design Manufacturing Medicine Biology Analyze - Predict\nExample: Industry First jetliner to be digitally designed, \"pre-assembled\" on computer, eliminating need for costly, full-scale mockup. Computational modeling improved the quality of work and reduced changes, errors, and rework.\nExample: Roadmaps of the Human Brain Cortical regions activated as a subject remembers the letters x and r. Real-time Magnetic Resonance Imaging (MRI) techno-logy may soon be incorporated into dedicated hardware bundled with MRI scanners allowing the use of MRI in drug evaluation, psychiatry, & neurosurgical planning.\nExample: Climate Modeling 3-D shaded relief representation of a portion of PA using color to show max daily temperatures. Displaying multiple data sets at once helps users quickly explore and analyze their data.\nReal World Problem Identify Real-World Problem : Perform background research, focus on a workable problem. Conduct investigations (Labs), if appropriate. Learn the use of a computational tool: Matlab, Mathematica, Excel, Java. Understand current activity and predict future behavior.\nExample: Falling Rock Determine the motion of a rock dropped from height, H, above the ground with initial velocity, V. A discrete model: Find the position and velocity of the rock above the ground at the equally spaced times, t0, t1, t2, …; e.g. t0 = 0 sec., t1 = 1 sec., t2 = 2 sec., etc. |______|______|____________|______ t0 t1 t2 … tn\nWorking Model Simplify Working Model : Identify and select factors to describe important aspects of Real World Problem; deter- mine those factors that can be neglected. State simplifying assumptions. Determine governing principles, physical laws. Identify model variables and inter-relationships.\nExample: Falling Rock Governing principles: d = v*t and v = a*t. Simplifying assumptions: Gravity is the only force acting on the body. Flat earth. No drag (air resistance). Model variables are H,V, g; t, x, and v Rock’s position and velocity above the ground will be modeled at discrete times (t0, t1, t2, …) until rock hits the ground.\nMathematical Model Represent Mathematical Model: Express the Working Model in mathematical terms; write down mathematical equa- tions whose solution describes the Working Model. In general, the success of a mathematical model depends on how easy it is to use and how accurately it predicts.\nComputational Model Translate Computational Model: Change Mathema- tical Model into a form suit- able for computational solution. Existence of unique solution Choice of the numerical method Choice of the algorithm Software\nComputational Model Translate Computational Model: Change Mathema- tical Model into a form suit- able for computational solution. Computational models include software such as Matlab, Excel, or Mathematica, or languages such as Fortran, C, C++, or Java.\nExample: Falling Rock Pseudo Code Input V, initial velocity; H, initial height g, acceleration due to gravity Δt, time step; imax, maximum number of steps Output ti, t-value at time step i xi, height at time ti vi, velocity at time ti\nExample: Falling Rock Initialize Set ti = t0 = 0; vi = v0 = V; xi = x0 = H print ti, xi, vi Time stepping: i = 1, imax Set ti = ti + Δt Set xi = xi + vi*Δt Set vi = vi - g*Δt print ti, xi, vi if (xi <= 0), Set xi = 0; quit\nResults/Conclusions Simulate Results/Con- clusions: Run “Computational Model” to obtain Results; draw Conclusions. Verify your computer program; use check cases; explore ranges of validity. Graphs, charts, and other visualization tools are useful in summarizing results and drawing conclusions.\nReal World Problem Interpret Conclusions: Compare with Real World Problem behavior. If model results do not “agree” with physical reality or experimental data, reexamine the Working Model (relax assumptions) and repeat modeling steps. Often, the modeling process proceeds through several iterations until model is“acceptable”.\nExample: Falling Rock To create a more realistic model of a falling rock, some of the simplifying assumptions could be dropped; e.g., incor-porate drag - depends on shape of the rock, is proportional to velocity. Improve discrete model: Approximate velocities in the midpoint of time intervals instead of the beginning. Reduce the size of Δt.","by Judith Curry\nThis post discusses Workshop presentations on methodologies and application examples of decision analytical strategies to support robust decision making on climate adaptation.\nThis post is a follow-on to the two previous posts:\n- UK-US Workshop on Climate Science to Support Robust Adaptation Decisions\n- UK-US Workshop Part II: Perspectives from the private sector on climate adaptation\nPerspective from the Grantham Institute\nSimon Buckle and Emily Critchley of the Grantham Institute for Climate Change have written an overview article on the Workshop for Imperial College- London’s blog entitled Climate science to support resilience. Excerpts:\nThe Workshop was an important opportunity to illustrate and discuss the diversity of methods already available that could supplement the insights gleaned from climate models and help inform robust decision making in the face of climate variability and change, whether by business, government or international organisations. These additional tools included, but were not limited to, formal methods of robust decision making, scenarios that capture a wider range of drivers beyond just greenhouse gas emissions, more effective exploitation of historical empirical data about climate variability globally and in specific regions, and the smarter use of climate models of all types to identify what can be said robustly on shorter (decadal) timescales and what cannot.\nCommenting on the workshop, Dr Yvan Biot, Senior Scientist at the UK Department for International Development, said that, “the future doesn’t just happen – it is for us to create. The techniques I have learnt in this Workshop will help us select those activities that are most likely to create a better and more secure future for poor people in developing countries.”\nThe provision of these “climate services” to inform the way that decision makers think about risk is likely to become increasingly important in coming decades. Discussion at the Workshop touched on the ethical dimensions and high professional standards required for the success of this emerging profession. The Workshop concluded that consideration should be given to developing a code of professional standards for practitioners, notably in terms of transparency, objectivity and full disclosure of data, assumptions and methods as well as an obligation to make available forecasts and projections on timescales that allowed those affected by risks to take action in time to mitigate their potential impact, which does not always happen at present.\nRobust decision making for climate adaptation\nBelow is a summary of 4 Workshop presentations on this topic:\nRobert Lempert – Rand Corporation: Information needs for developing robust adaptive strategies\nLempert laid out the challenge in this way. Climate-related decisions involve incomplete information from new, fast-moving, and sometimes irreducibly uncertain science; many different interests and values; long time scales; near certainty of surprise. How can we make plans more robust and adaptable while preserving public accountability? Supply and demand of scientific information may be mismatched. Decision support bridges supply and demand with a focus on decision processes.\nTraditional approach to risk management works well well when the future isn’t changing fast, isn’t hard to predict, doesn’t generate much disagreement. Predict then act methods can backfire in deeply uncertain conditions: uncertainties are underestimated, competing analyses can contribute to gridlock, and misplaced concreteness can blind decision makers to surprise. Believing forecasts of the unpredictable can contribute to bad decisions. Deep uncertainty occurs when the parties do not know or do not agree on the likelihood of alternative futures or how actions are related to consequences.\nRobust decision making manages deep uncertainty by running the analysis backwards: start with a proposed strategy, use multiple model runs to identify conditions that best distinguish futures where strategy does and does not meet its goals, identify steps that can be taken so strategy may succeed over wider ranges of futures. Stakeholders debate about how much robustness they can afford – which is more useful than debating what the future will be. Tradeoff curves help decision makers choose robust strategies. RDM creates demand for decision support methods and tools for managing and summarizing large and diverse sets of information in a decision-relevant context. See the presentation for detailed analysis of several case study applications.\nAdapting to climatic change (for example, in the design of coastal infrastructure) poses nontrivial conceptual challenges. Relevant examples include (i) the deep uncertainty surrounding projections of the coupled natural and human systems, (ii) the diversity of priors and value judgments across stakeholders and decision makers, and (iii) the choice of appropriate decision-analytical frameworks.\nClimate change adaptation imposes multi-objective trade-offs under dynamic and deep uncertainty. Current adaptation analyses often neglect: known unknowns – leading to overconfidence; endogenous dynamics of imperfect learning; and relevant decision criteria. Inverse decision analysis combined with mission-oriented basic science can help overcome these problems. Uncertain parameters interact in nonlinear ways. One at a time sensitivity analyses can miss important nonlinear interaction effects.\nPulwarty asks the questions: Adapting to what? What are strategies for appraising and evaluating climate adaptation plans? He emphasized the weather-to-climate continuum and the existing adaptation deficits. Climate change adaptation is so difficult because of the cumulative nature of hazards, extremes and disasters; difficulty of proactive decision making and taking advantage of learning and policy windows; and the challenges of information services to support adaptation in changing environments.\nThe following lessons have been identified (if not necessarily learned):\n- Acknowledge the cross-scale of climate, of early warning and adaptation response\n- Disciplinary challenges shape problem definitions, scenarios, and recommendations (e.g. primary consideration being climate model impacts versus vulnerability assessment)\n- Communication is critical but not sufficient. Need to understand the socialization of lessons learned by particular individuals and organizations through their own, direct brian and error experiences.\n- Rules for gathering, storing, communicating information are essential elements of operating procedures\nCriteria for robustness need re-evaluation. Understand adaptation as being driven by crises, learning and redesign – role of “surprises” in shaping responses. Generate risk profiles and a portfolio of measures-and broader economic, social and environmental benefits. Approach climate model output far more critically than at present, especially for impact assessment and scenario development at the local level. Develop information systems for critical thresholds across climate time and space scales.\nKey issues re improving the linkages between information and decision making: quality and pedigree of information available to decision makers at all levels; factors influencing whether or not such information will be used; factors influencing whether risk communications are trusted; prototyping strategies and practices for adapting the decision making systems to the different levels of decision makers.\nApplications to U.S. drought and water resource adaptation are discussed.\nIn a decentralized model of policy innovation, experiments in climate change adaptation arise from the operational levels of a system; from cohorts of practitioners or inventive individuals. In this model, innovations spread horizontally via communities of practice, with local adaptation rather than comprehensive adoption. This creates the potential for redundancy, and along with it, flexibility in the face of anomalous conditions. Like biodiversity in the natural world, this “innovation dividend” is a reserve of creative potential that enhances resilience in the face of future shocks. Diversity rather than efficiency is a goal value in the decentralized model, and yet it has been observed, particularly in cases concerning common good resources such as water, that allocative efficiency is enhanced. This can be explained by the fact that decision-making authority is set where the participants are optimally positioned to assess costs and benefits. This presentation will use this perspective to explore the ways in which the benefits of subsidiarity are being realized in the otherwise highly centralized Murray-Darling Basin Authority, which manages the arid river system formed from Australia’s three longest rivers.\nJC reflections: This series of presentations was in many ways the lynch pin of the Workshop. Robust decision making strategies are the critical link between the supply of climate information and the demand from decision makers to support climate adaptation policies.\nAll of the talks recognize the existence of substantial uncertainty, and the lack of utility of the traditional ‘predict then act’ model for decision making. Robust decision making provides a framework for making decisions under deep uncertainty, where the disagreement is deflected away from arguments about likely futures to the amount of resilience that can be afforded.\nThe need for a broader range of climate information than the global climate models was clearly identified in the first three talks, and Keller refers to the need for mission-oriented climate information. This highlights the point that I made in Part I, where ‘mitigation science’ (e.g. sensitivity, attribution) is not the same kind of climate information need to support climate adaptation. Exactly how to approach mission-oriented climate science to support adaptation decisions is discussed in some of the other presentations that will be discussed in future posts."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:e71b81ea-d0db-4b62-8027-2740496bc7e5>","<urn:uuid:2c18151e-0ab6-4b63-9ebf-4e7d25b581e0>"],"error":null}
{"question":"What are the key differences between how nursery rhymes and music therapy programs like Kindermusik affect a child's emotional regulation?","answer":"Nursery rhymes and music therapy programs like Kindermusik serve different but complementary roles in emotional regulation. Nursery rhymes help establish arousal and emotional regulation in toddlers who haven't yet developed proper mechanisms for regulating their feelings, with studies showing that toddlers remain calm longer when nursery rhymes are sung to them compared to speaking. Kindermusik, as a structured music therapy program, works more comprehensively by stimulating all parts of the brain through specialized activities, forming new connections and increasing brain network density through weekly repetition. It focuses on improving overall brain development from birth to age 7, integrating music into daily routines to enhance thinking, reasoning, and expression abilities.","context":["Nursery rhymes have been around for hundreds of years and in spite of the fact that the world has witnessed a lot of changes and many traditions have been discarded, nursery rhymes seem like they are here to stay forever because they’ve stayed with us through the years.\nSeveral scientific studies that have been carried out on the benefit of nursery rhymes for toddlers have continued to show that nursery rhymes can help to promote learning and literacy in children.\nThe report of one of such studies carried out by researchers at MacMaster University and published on Science Daily revealed that children benefit from nursery rhymes before they can even walk and talk.\nThe study carried out on one year-old baby revealed that babies who participated in interactive music classes showed earlier and more sophisticated brain responses to music, communicated better and even smiled better.\nNursery rhymes are very important for toddlers and here are 15 different reasons why:\n#1. It Boosts Early Language Development\nYou may think – what’s the point? My child is too young to understand what I’m saying but your child’s brain is storing up all of the information and using it to learn and develop their language and communication skills.\nThere have been several reports from parents who read nursery rhymes to their kids for several years before they could even speak and when they started speaking they could remember and kept repeating bits and pieces of the nursery rhymes that were sung to them as babies.\n#2. It Equips Your Child to Be a Better Reader\nYour child can hear the pronunciation and sounds in the nursery rhymes, and it helps them develop stronger vocabulary, writing, comprehension, and social conversational skills.\n#3. It Helps to Improve Motor Skills and Coordination\nNursery rhymes like “My head, my shoulders, my knees, my toes” and similar rhymes that require your child to demonstrate, dance or sing-along, can also help to improve coordination and motor skills.\n#4. It Helps Your Toddler Build Social Skills Early in Life\nYour child will have fun reciting, singing, and demonstrating with other kids and it helps them learn how to socialize and develop connections with others.\n#5. It Helps to Teach Your Kids How to Act\nWhen you act out rhymes or read rhymes with picture demonstrations to your child, it can open the door to creativity and teach them artistic skills like acting, dancing, singing, and so many others.\n#6. It Helps Them Develop Cognitive Skills\nNursery rhymes can also help to improve your child’s cognitive skills especially sharpening their memory, concentration, reasoning skills and spatial intelligence.\n#7. It Helps to Promote Excitement\nHave you ever seen the look on your child’s face and how excited and happy the get when you’re reading nursery rhymes with them? Kids love that stuff and it can be a very good way to keep them happy and improve their moods especially when they are being cranky or throwing tantrums.\n#8. It Teaches Them Teamwork\nYour toddler would also learn how to work as a team with others from a young age because they have to sing along and match the pace of other kids when singing nursery rhymes in crèche or kindergarten.\n#9. It’s a Perfect Way to Bond with Your Child\nSinging Nursery rhymes with your child is also a perfect bonding activity. It helps you spend time with your kid and helps your toddler get to know you better.\n#10. It Improves Your Child’s Perceptional Abilities\nNursery rhymes improve your child’s sensitivity to different tunes and sounds which they do not often notice in daily vocabularies used by their family or the people that they communicate with daily.\nYour child will also be able to notice the similarities between phrases and words, and think about the sequences of sounds of words that are said in the poem.\nAll of these help to improve your child’s perceptive abilities.\n#11. It Improves Your Child’s Attention\nChildren have to focus and concentrate when learning and singing rhymes and this can be a very great way to teach them how to concentrate.\n#12. It Can Create an Avenue for Storytelling\nNursery rhymes introduce your child to the concept of story-telling. Your toddler may be too young to understand the vocabularies in a storybook but the words in nursery rhymes are simple enough for them to understand so if you think that your child is still too young for bedtime stories, why not try bedtime rhymes?\n#13. It Helps to Develop Your Child’s Numerical and Mathematical Skills\nChildren start learning numeracy skills as soon as they are born and it often happens through everyday activities and play.\nSome poems can teach your child to count their fingers and toes describe the sizes of objects (big and small) or learn about distance (near and far), depth (deep and wide), speed (fast and slow) and order (first, second, last), etc.\n#14. It Can Help to Calm Your Toddler\nA recent study carried out in the University of Montreal revealed that toddlers remained calm for much longer when nursery rhymes and songs were sung to them compared with when they were spoken to.\nToddlers are attracted to the rhythms and patterns in the songs and also, the rhythms match the natural speed of their heartbeat, which helps to calm them down.\n#15. It Establishes Arousal and Emotional Regulation\nYour toddler is yet to develop the proper mechanism for regulating their feelings and emotions, which is why they cry so much as a way to communicate their feelings and let you know that they need you to help them change the way that they are feeling.\nAs your baby grows, they’ll begin to develop brain connections that will help them to understand and regulate their emotions but until then, you can use nursery rhymes and soft lullabies to soothe them or provide comfort when they are upset or afraid.\nNursery rhymes are a very great way to regulate arousal and control their emotions.","Music has a powerful and usually positive effect on our emotions, which is why fussy babies are very often soothed with a gentle lullaby. But music also has a profound effect on the way our brains work, especially your baby’s brain.\nBabies are born with billions of brain cells, just waiting to be nurtured. During the first few years these cells form connections with other cells and start to form the neurological highways that transport information.\nOver time, the connections between cells become stronger and easier to access. Children who grow up listening to music have strong music-related pathways, which studies have shown actually affect the way we think. Why is this?\nThe benefits of growing up with music\nMusic, especially classical music, can train the brain for certain types of thinking, because the pathways formed in the brain by listening to classical music are similar to the pathways used for spatial reasoning – the ability to recognise patterns or sequences.\nThis ability impacts on your child’s mathematical and analytical abilities later in life. It is used when your child builds a puzzle, paints a picture and learns to count - all of which are important for his ultimate mental development.\nHeidi Twiley, CEO of Kindermusik South Africa, says, “The building blocks that the brain uses to do its work are neurons and synapses. These develop at a phenomenal rate of 50 000 per second before birth. When babies are born, research tells that there are about 200 billion brain cells developed and waiting for stimulation to form connections. These connections can only form by specialised stimulation. When all parts of the brain are stimulated, new connections are formed and brain networks increase in density.”\n“Music is the perfect way to stimulate this development.” She adds, “Scientists have also discovered that a child’s brain grows to 90% of its adult capacity within the first two years of life. Brain patterns created during these early years affect individuals throughout their whole life.”\nWhat is the Mozart effect?\nThe “Mozart Effect” is a term used to describe the increase in brain development that occurs in children under 3 when they have been exposed to the music of Amadeus Mozart, a classical composer from the 18th century.\nWhere the idea came from\nThe idea of the Mozart Effect originated in 1993 when physicist Gordon Shaw, and concert cellist and expert on cognitive development, Frances Rauscher conducted an experiment on a few University of California students.\nThese students were exposed to 10 minutes of music written by Mozart, and showed an increase in their spatial-temporal reasoning. Four years later, Gordon and Frances reported that their experiments proved that instruction in the piano and singing enhance children’s abstract reasoning skills.\nGordon says, “We have this common internal neural language that we’re born with and so if you can exploit that with the right stimuli then you’re going to help the brain develop to do the things like reason.”\nGordon and Frances believe that music stimulates the area of the brain associated with spatial temporal reasoning, which helps with cognitive tasks. This, they say, increases a person’s intelligence for maths, engineering, chess and science.\nA further experiment\nAnother experiment that supports the theory was conducted by Bellarmine College in the US. Their Department of Psychology tested the effect of music on students by having them complete pen and paper mazes of increasing difficulty. There was a marked difference in the students’ ability to complete the maze after listening to the music, as opposed to not having listened to anything at all.\nIf experiments show that Mozart’s music boosts one’s ability to solve puzzles and that children are stimulated by this kind of music from a young age, there should logically be long-term, beneficial consequences.\nWhy classical music?\nClassical music has a different effect on brain function because it has a more complex musical structure than any other type. In fact, babies as young as 3 months can identify the structure and even recognise classical music that they have heard before. It’s this complex structure that primes the brain to identify and solve spatial problems, like puzzles, easily. Several studies have shown that children who had piano lessons for six months could solve puzzles easier and faster than before.\nHow to help your baby\nThere are several ways in which you can begin to nurture a love and appreciation for music in your baby. This will develop pathways in his brain that aid his spatial reasoning. Here are some suggestions:\nTry expose your baby to as much music as you can, even of different styles. If you’re fortunate enough to be able to play an instrument, play it when your baby is nearby. Don’t place him too close to the instrument, though, as he has very sensitive hearing and loud music can damage this.\nKindermusik is a well-known therapy, music and brain development programme for young children from birth to age 7. Heidi says, “Kindermusik works with babies from birth, because the first seven years are the most important forming years in brain development in children. Research proves that early integration of music into your child’s daily routine means improving their ability to think, reason, create and express.”\n“Each activity during class time exercises and develops a certain part of the brain, and within one lesson, all parts of the brain are stimulated, new connections formed and brain networks increase in density each week. Through repetition of activities during the following weeks, the newly formed connections are strengthened.”\nIt doesn’t matter how badly you think you sing, you baby loves your voice. Not only will it stimulate those musical pathways, but your baby also picks up the cadence and intricacies of language when you sing, because of the rhyme and rhythm in songs\nOnce your baby gets older encourage him to sing along with you. Once he begins to set words to music himself, his brain is able to retain those words for longer. This helps in the development of vocabulary. Ever wondered why you can still remember the lyrics to almost every nursery rhyme you sang as a child? This is why\nStart music lessons early\nYou needn’t wait until your child is in primary school to start learning how to play an instrument. Most 4 and 5-year-olds are well-equipped to start learning the basics of some instruments, and most certainly love making sounds!\nEncourage your child’s nursery school to play music\nMusical education at nursery school or daycare can certainly help with your child’s creativity. Sing-alongs and dance are often a favourite time of a toddler’s school day. There might also be a local, mobile music programme that can go to your child’s nursery school and teach him there.\nAn example of this is Be Sharp Beetles in Gauteng, which is a music and dance programme that takes instruments into nursery schools so that children can sing, dance and play.\nLiesel Grobler from Be Sharp Beetles says, “Music stimulates every aspect of a child’s development – gross and fine motor skills, listening skills, concentration, cognitive development, language ability, social skills and life skills.”\n“Rhymes and songs stimulate a child’s language ability. When you couple this with playing a musical instrument your child’s fine and gross motor skills are developed as the right and left hemispheres of her brain are linked up by the interaction of instrument and song.”\nBe Sharp Beetles currently services 75 schools around Johannesburg and has a studio in Northcliff. Alternatively, Kindermusik is available around the country for those not based in Johannesburg.\nAnd finally, now that you know how music helps your baby’s brain, it’s time to start singing and playing.\nKindermusik, www.kindermusik.co.za, (018) 468 5243, Heidi Twiley, 082 920 0629\nBe Sharp Beetles, Liesel Grobler, 082 922 8161, firstname.lastname@example.org"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:56e7f2af-e09b-4d47-a34b-eec82cb12a06>","<urn:uuid:b20b74a8-ab40-4bed-a94f-a57f5a40ca8c>"],"error":null}
{"question":"What are the current challenges of ocean plastic pollution, and how do coral reefs attempt to survive environmental threats?","answer":"Ocean plastic pollution presents a severe crisis with 8 million tonnes of plastic waste entering oceans yearly, with 95% being submerged microplastics. According to UNEP, at current rates, oceans will contain more plastic than fish by 2050. As for coral reefs' survival mechanisms, when faced with environmental threats like increased ocean temperatures, they employ a unique defense strategy called 'colorful bleaching.' During this process, corals produce a protective sunscreen layer that creates vibrant neon colors in pink, purple, and orange. This mechanism serves as a final attempt to attract symbiotic algae back to the coral, potentially allowing recovery if the stress event is mild enough.","context":["Ocean Plastic Pollution: An Ongoing Crisis\nJune 28, 2020, 7:06 am\nBy: Dr Samar Hamad\nThe negative impact of plastic pollution on marine environment and wildlife is undeniable. Oceans around the world are filled with plastic debris and marine species are ingesting and getting entangled in plastic waste leading to their starvation and/or suffocation. According to the United Nations Environment Programme (UNEP), 8 million tonnes of plastic waste enter the oceans every year. At this rate, Earth’s oceans will end up filled with more plastic than fish by 2050. The UNEP also indicates that 95% of the plastic waste is submerged under the water surface in the form of microplastics and microbeads, while the plastic debris that mostly seen along coastlines and floating on ocean surfaces represents a small portion (approximately 5%) of the actual amount of plastic waste dumped into oceans. Sustainable solutions are urgently needed to save the marine ecosystem (Earth’s largest ecosystem) and preserve the oceans for future generations.\nMeasures to Address Marine Plastic Pollution\nNumerous practices have developed to clean up existing plastic debris; however, it has been found that removing plastic waste (especially underwater microplastics) from oceans is an extremely difficult task. Hence, more effective measures have been developed to tackle the over-consumption of single-use plastic and the mismanagement of plastic waste in order to address the root causes of marine plastic pollution. Such measures primarily involve a combination of the following basic concepts:\n- Limiting single-use plastic: Using less plastic is the most efficient practice to eliminate ocean plastic pollution. Communities around the world are limiting their reliance on single-use plastic and encouraging the reusable versions of such products. Recent advancements in material science research and improved product designs have great impact on reducing the production of single-use plastic. Enforcing regulations to ban single-use plastics and economic incentives for reusable products can further limit the excessive use of single-use plastic and cut the over-consumption of plastic.\n- Managing plastic waste: In order to improve plastic waste collection and management, a circular economy approach – in which plastic products are used, recovered, and reused multiple times – must be adopted rather than relying on a linear economy (plastic products are made, used, and disposed). Building waste management and recycling infrastructure to allow easy access to recycling options and similar responsible waste disposal alternatives can significantly reduce the amount of plastic waste enters the ocean. Compostable and biodegradable plastics substitutes have become a popular alternative to reduce plastic waste. In addition, the technological innovations to improve products packaging design, considering reusing, recycling, and end of life stages of products have emerged to keep post-consumer plastics in a circular economy loop. However, producers and distributors must commit to adopt end-of-life waste management practices.\n- Promote marine conservation: Efforts must be put to develop infrastructure to stop plastic pollution and capture plastic waste at source. Campaigning to raise the public awareness regarding marine conservation is also essential to promote more ethical consumer practices and minimise marine plastic pollution.\nHolistic approaches to address marine plastic pollution must be developed based on appropriate policy frameworks and mechanisms with coordinated actions across multiple sectors and stakeholders in many regions around the world. They should aim to stimulate mitigation actions that tend to reduce the formulation of plastic waste at source and encourage the removal of plastic pollution before reaching coastlines. Such approaches tend to reduce plastic use and appropriately manage plastic waste to save the future of marine environment and wildlife.\nMore information available at:\nUN News. (2019). Microplastics, microbeads and single-use plastics poisoning sea life and affecting humans. Retrieved from: https://news.un.org/en/story/2019/11/1050511","Cecilia D’Angelo, a molecular coral biology lecturer at the University of Southampton. Jörg Wiedenmann, Elena Bollati & Cecilia D’Angelo/University of Southampton, Palawan colourful bleaching image by Ryan Goehrung/University of Washington\nBleaching events used to be few and far between, but they now occur nearly every year. After the coral is exposed, it often breaks down and dies, altering the ecosystem for the diverse array of life that relies on it. Corals stand little chance of bouncing back from these events — but a new study suggests they have an unusual survival method: taking on a vibrant neon color.\nWhen bleaching events occur, extended heat spikes cause corals to turn a ghostly white, often leading to their death. Even slight increases in annual ocean temperatures can wreak havoc on this relationship, expelling the algae from the coral’s tissue and exposing its white skeleton. These corals can still undergo some of their normal functions for a short period of time as they hope their algae come back — whereas drastic changes in ocean temperature almost always lead to coral death. Reports of colorful bleaching during the most recent mass bleaching event in the Great Barrier Reef in March and April gave scientists hope that patches of the system have a chance to recover. “Bleaching is not always a death sentence for corals, the coral animal can still be alive,” said Dr. They found that colorful bleaching events occur when corals produce “what is effectively a sunscreen layer” on their surface to protect against harmful rays and create a glowing display that researchers believe encourages algae to return. The Ocean Agency describes the process as a “chilling, beautiful and heartbreaking” final cry for help as the coral attempts to grab the algae’s attention. “Our research shows colorful bleaching involves a self-regulating mechanism, a so-called optical feedback loop, which involves both partners of the symbiosis,” lead researcher Professor Jörg Wiedenmann of the University of Southampton said in a press release. Climate Change\nDying coral reefs turn vibrant neon in apparent survival effort\nScientists say climate change is turning coastal Antarctica green\nStudy: Climate change makes a Dust Bowl heat wave more likely\nAir pollution is already spiking in China with virus lockdown lifted\nIndia’s carbon emissions fall for the first time in four decades\nMore in Climate Change\nResearchers at the University of Southampton’s Coral Reef Laboratory studied 15 colorful bleaching events worldwide between 2010 and 2019 — including one in the Great Barrier Reef, the world’s largest coral reef system — and recreated those ocean temperatures in a lab. But “colorful bleaching” has the opposite effect: the dying corals gain more pigment, and glow in shades of bright pink, purple and orange. Scientists first spotted the mysterious neon coral a decade ago, but they had been unable to figure out why it occurred. As the recovering algal population starts taking up the light for their photosynthesis again, the light levels inside the coral will drop and the coral cells will lower the production of the colorful pigments to their normal level.”\nColorful bleaching Acropora corals in the Phillipines. Dying coral reefs turn vibrant neon colors in apparent last-ditch effort to survive\nBy Sophie Lewis\nMay 22, 2020 / 4:48 PM\n/ CBS News\nScientists use mini-satellites to save coral reefs\nFor years, coral reefs around the world have been devastated by mass bleaching events as the oceans continue to warm due to climate change. “If the stress event is mild enough, corals can re-establish the symbiosis with their algal partner.”\nThe internal changes that allow colorful bleaching to occur. In 2017 alone, nearly half the corals on the Great Barrier Reef died — and experts say we are running out of time to save them. “Unfortunately, recent episodes of global bleaching caused by unusually warm water have resulted in high coral mortality, leaving the world’s coral reefs struggling for survival,” D’Angelo said. Scientists emphasized that while colorful bleaching is a good sign, only a significant reduction of greenhouse gases globally — in addition to improvement in local water quality — can save coral reefs beyond this century.\n“Now that we know that nutrient levels can affect colorful bleaching too, we can more easily pinpoint cases where heat stress might have been aggravated by poor water quality,” researchers said. Ryan Goehrung, University of Washington\nCoral reefs support more species per unit area than any other marine environment, including about 4,000 species of fish, 800 species of hard corals and potentially millions of other undiscovered species, according to the National Oceanic and Atmospheric Administration. Colorful bleaching Acropora corals in New Caledonia.\nRichard Vever/The Ocean Agency/XL Catlin\nCoral animals symbiotically coexist with tiny algae, providing them with shelter, nutrients and carbon dioxide in exchange for their photosynthetic powers. Together, these actions can secure a future for coral reefs.”\nFirst published on May 22, 2020 / 4:48 PM “The resulting sunscreen layer will subsequently promote the return of the symbionts. This study, published Thursday in the journal Current Biology, suggests the corals change color as a last-ditch effort to survive. “This can be managed locally, whereas the ocean heat waves caused by climate change will need global leadership. Disruptions to coral reefs have far-reaching implications for ocean ecosystems.\nIt’s not just warming oceans that cause colorful bleaching. Researchers say changes in nutrient levels within coral reefs due to fertilizer run-off from farms also lead to bleaching events — a problem that can be fixed at the local level. Experts believe only coral that has faced mild or brief disturbances, rather than extreme mass bleaching events, can attempt to save itself using this process."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:d9fa5132-a033-4df9-9ea1-409ff6fb198f>","<urn:uuid:369f1095-9589-4d83-9007-35418b336092>"],"error":null}
{"question":"Does the clock hypothesis concept appear in both Einstein's early work and modern quantum physics experiments?","answer":"Yes, the clock hypothesis appears in both contexts. It first emerged in Einstein's 1913 remark to Sommerfeld about the assumption that moving clocks indicate proper time. In modern physics, researchers are testing clock-related concepts through quantum experiments, specifically a quantum version of Einstein's twin paradox where a particle in superposition travels at different speeds to test if different amounts of time pass for each trajectory.","context":["Introduction of the clock hypothesis is usually associated with Rindler's Special Relativity (1960), and the current debates over it were sparked after Brown defended its necessity in his book Physical Relativity: Spacetime structure from a dynamical perspective (2005). According to Arthur's chapter Minkowski’s Proper Time and the Status of the Clock Hypothesis, one can trace the hypothesis to a remark Einstein made to Sommerfeld (published in 1913):\n\"In passing I note that, in their insistence that the clock hypothesis is a separate assumption in SR, Rindler and Brown could appeal to the authority of Einstein. For in the notes he made on Minkowski’s original “Raum und Zeit” paper, Arnold Sommerfeld attributes a remark to Einstein that may indicate the origin of the idea that the clock hypothesis is needed – at any rate it is the first statement of it that I have been able to find. Right after mentioning Minkowski’s remark that $d\\tau$ is not a complete differential, and noting that this shows that the proper times of two motions connecting two world points will generally differ (as discussed in Sect. 2\nabove), Sommerfeld adds:\n\"This assertion is based, as Einstein has stressed, on the (unprovable) assumption that the\nmoving clock actually indicates the proper time, i.e. that at each instant it gives the time that\ncorresponds to the instantaneous state of velocity, regarded as constant. The moving clock\nmust naturally have been moved with acceleration (with changes of velocity or direction)\nin order to be compared with the stationary clock at the world-point $P$.\"\"\nArthur and others (see e.g. Valente, What do light clocks say to us regarding the so-called clock hypothesis?) do not consider the clock hypothesis to be on a par with the standard two postulates of special relativity, but classify it with what philosophers call coordinating principles. Those relate theoretical notions to measured quantities, proper time to clock readings in this case, and are not part of the theory proper. They are needed for any theory to make it testable and not just a mathematical abstraction. Here is Arthur's summary of the positions:\n\"Rindler claims it is an assumption that it is necessary to make in order to get from “purely kinematic laws about acceleration” to the dynamics of really accelerated systems (1966, 28) and Harvey Brown claims something similar in his recent book (Brown 2005, 9)... On the other hand, Jim Hartle holds that Minkowski’s formula for the proper\ntime holds “even for accelerating clocks, i.e., when the velocity is dependent on the\ntime” (Hartle 2003, 62), and he makes no use of the clock hypothesis in his textbook.\nRoberto Torretti allows that the clock hypothesis “may be viewed as a conventional\ndefinition of what we mean by clock accuracy, and hence by physical time” (1996,\n96), but argues that “Special Relativity would doubtless have been rejected or, at\nany rate, deeply modified, if the clock hypothesis were not fulfilled – to a satisfactory\napproximation – by the timepieces actually used in physical laboratories”...\nOn these latter views, provided a given process approximates well enough an\nideal clock, the clock hypothesis seems to amount to little more than the desideratum\nthat, with the metric locally Minkowskian, the predictions of SR should agree\nwith experimental fact. So the question is, why should it be necessary to state it as an independent hypothesis? Two main sets of considerations have been adduced. As\nwe have seen, one kind of justification has been that, since many natural clocks are\nsubject to accelerations which result in their failing to satisfy the clock hypothesis,\nwe need to appeal to the hypothesis in passing from the kinematics of acceleration\nof ideal clocks to the dynamics of really moving clocks. A second kind of justification\nhas to do with the different status of Special Relativity within the General\nRelativistic context, where, as is shown by the example of Weyl’s unified theory of\nelectromagnetism and gravitation, the metric could be locally Minkowskian and yet\nthe rate of clocks could be path-dependent in such a way that the instantaneous rate\nwould depend on the way the clock had been accelerated hitherto, contrary to the\nclock hypothesis. This, it is argued, proves the independence of the clock hypothesis\nfrom the assumption that spacetime is locally Minkowskian.\"","More accurate clocks and sensors may result from a recently proposed experiment, linking an Einstein-devised paradox to quantum mechanics.\nUniversity of Queensland physicist Dr. Magdalena Zych said the international collaboration aimed to test Einstein’s twin paradox using quantum particles in a ‘superposition’ state.\n“The twin paradox is one of the most counterintuitive predictions of relativity theory,” Dr. Zych said. “It says that time can pass at different speeds for people at different distances to an enormous mass or traveling with different velocities.\n“For example, relative to a reference clock far from any massive object, a clock closer to a mass or moving at high speed will tick slower. This creates a ‘twin paradox’, where one of a pair of twins departs on a fast-speed journey while the other stays behind. When the twins reunite, the traveling twin would be much younger, as different amounts of time have passed for each of them.\n“It’s a mind-blowing effect – featured in popular movies like Interstellar – but it’s also been verified by real world experiments, and is even taken into consideration in order for everyday GPS technology to work.”\nThe team included researchers from the University of Ulm and Leibniz University Hannover and found how one could use advanced laser technology to realize a quantum version of Einstein’s twin paradox.\nIn the quantum version, rather than twins there will be only one particle traveling in a quantum superposition.\n“It’s a mind-blowing effect – featured in popular movies like Interstellar – but it’s also been verified by real world experiments, and is even taken into consideration in order for everyday GPS technology to work.” – Dr. Magdalena Zych\n“A quantum superposition means the particle is in two locations at the same time, in each of them with some probability, and yet this is different to placing the particle in one or the other location randomly,” Dr. Zych said.\n“It’s another way for an object to exist, only allowed by the laws of quantum physics.\n“The idea is to put one particle in superposition on two trajectories with different speeds, and see if a different amount of time passes for each of them, as in the twin paradox. If our understanding of quantum theory and relativity is right, when the superposed trajectories meet, the quantum traveler will be in superposition of being older and younger than itself.\n“This would leave an unmistakable signature in the results of the experiment, and that’s what we hope will be found when the experiment is realized in the future.\n“It could lead to advanced technologies that will allow physicists to build more precise sensors and clocks – potentially, a key part of future navigation systems, autonomous vehicles and earthquake early-warning networks.”\nThe experiment itself will also answer some open questions in modern physics.\n“A key example is, can time display quantum behavior or is it fundamentally classical?” Dr. Zych said. “This question is likely crucial for the ‘holy grail’ of theoretical physics: finding a joint theory of quantum and gravitational phenomena. We’re looking forward to helping answer this question, and tackling many more.”\nFor more on this study, read Physicists Put Einstein to the Test With a Quantum-Mechanical Twin Paradox.\nReference: “Interference of clocks: A quantum twin paradox” by Sina Loriani, Alexander Friedrich, Christian Ufrecht, Fabio Di Pumpo, Stephan Kleinert, Sven Abend, Naceur Gaaloul, Christian Meiners, Christian Schubert, Dorothee Tell, Étienne Wodey, Magdalena Zych, Wolfgang Ertmer, Albert Roura, Dennis Schlippert, Wolfgang P. Schleich, Ernst M. Rasel and Enno Giese, 4 October 2019, Science Advances."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:6ed6030c-9b82-47fd-956c-f5b3265978f7>","<urn:uuid:d1f86149-d0ce-494a-8277-5f622345de3e>"],"error":null}
{"question":"How does ferret skull development differ between males and females, and what are the common causes of vestibular dysfunction in animals?","answer":"In ferret skull development, females show earlier cessation of craniofacial growth compared to males, creating sexual dimorphism. As for vestibular dysfunction, common causes include middle/inner ear infections (treated with antibiotics), idiopathic vestibular syndrome (particularly in older animals), hypothyroidism, toxic reactions to ear medications, tumors in the inner ear or brain, and inflammation of the brain (encephalitis). The vestibular system, which helps maintain balance and coordinate eye movements, can be affected by problems in either the inner ear or brain.","context":["Animal Welfare Information Center\nUnited States Department of Agriculture\nNational Agricultural Library\nInformation Resources on the Care and Welfare of Ferrets\nReturn to Contents\nChristensson, M. and M. Garwicz (2005). Time course of postnatal motor development in ferrets: Ontogenetic and comparative perspectives. Behavioural Brain Research 158(2): 231-242. ISSN: 0166-4328.\nDescriptors: ferrets, postnatal motor development, motor behavior, rats, experimental animals, comparative study.\nHe, T. and S. Kiliaridis (2004). Craniofacial growth in the ferret (Mustela putorius furo)--a cephalometric study. Archives of Oral Biology 49(10): 837-848. ISSN: 0003-9969.\nNAL Call Number: RK1.A6989\nAbstract: OBJECTIVE: When suggesting the ferret as a valid laboratory model in craniofacial research, it is essential to know about its normal craniofacial growth. DESIGN: Sixteen ferret kits (eight male and eight female) were selected for the present investigation. Serial lateral and dorsoventral cephalograms were taken on each animal at a mean age of 25, 35, 55, 80 and 300 days. The cephalograms were then digitised and the coordinates of 33 landmarks were derived on each set of cephalograms. Thirty-four variables were then calculated on each set of cephalograms by computer image programs with the coordinate data. Results were analysed statistically, and the craniofacial growth pattern and related sexual dimorphism were described in three perspectives: lateral and dorsoventral viscero- and neurocranium, and lateral mandible. FINDINGS: In both sexes, the viscero- and neurocranium follow an orderly pattern of expansive growth in three dimensions. The growth of the mandible is mainly characterised by an anteroposterior elongation of the mandibular body, an enlargement of the coronoid process, and an increase in height of the alveolar process. The growth rate varies with site. Craniofacial growth in ferrets starts to slow down and finally ceases earlier in female than in male animals.\nDescriptors: ferrets, craniofacial growth, maxillofacial development, physiology, skull growth and development, cephalometry, mandible growth, sex factors, skull radiography.\nHe, T. and S. Kiliaridis (2003). Effects of masticatory muscle function on craniofacial morphology in growing ferrets (Mustela putorius furo). European Journal of Oral Sciences 111(6): 510-517. ISSN: 0909-8836.\nAbstract: Studying the effects of masticatory muscle function on craniofacial morphology in animal models with different masticatory systems is important for further understanding of related issues in humans. Forty 5-wk-old male ferrets were equally divided into two groups. One group was fed a diet of hard pellets (HDG) and the other group was fed the same diet but softened with water (SDG). Lateral and dorsoventral cephalograms were taken on each group after 6 months. Cephalometric measurements were performed by digital procedures. For SDG ferrets, the hard palate plane was more distant from the cranial base plane, and canines were more proclined compared with HDG ferrets. The SDG ferrets were also found to have smaller interfrontal and interparietal widths, and a slenderer zygomatic arch than the HDG ferrets. In the mandible, the coronoid process was generally shorter and narrower for the SDG ferrets. The effects of the altered masticatory muscle function on craniofacial morphology in growing ferrets seemed to differ from those previously reported in other animal models studied under similar experimental conditions. Such differences in the effects are presumably related to the differences in the mode of mastication, craniofacial anatomy and growth pattern in different animal models.\nDescriptors: ferret growth and development, mastication, masticatory muscles, maxillofacial development, skull growth and development, feed, nutrition, facial bones, mandible.\nHoefer, H.L. (2004). The biology and husbandry of the pet ferret. In: Small animal and exotics Book two: Pain management zoonosis Proceedings of the North American Veterinary Conference., January 17, 2004-January 21, 2004, Orlando, Florida, USA., Eastern States Veterinary Association: Gainesville, USA, Vol. 18, p. 1383-1384.\nDescriptors: ferrets, behavior, housing, husbandry, nutrition, clinical examination, diet, Mustela.\nMarini, R.P., G. Otto, S. Erdman, L. Palley and J.G. Fox (2002). Biology and diseases of ferrets. In: J.G. Fox, L.C. Anderson, F.M. Loew and F.W. Quimby (Editors), Laboratory Animal Medicine, 2nd edition, Academic Press: London, UK, p. 483-517. ISBN: 0122639510.\nDescriptors: ferrets, diseases, biology, parasites.\nReturn to Top\nReturn to Contents","Written By: Dr Thomas DVM Dipl.ACVIM(Neurology)\nThe vestibular system senses the position of the head and body in space, in relation to gravity and movement. This helps the animal maintain balance and coordinate eye movements with movement of the head. The receptors for the vestibular system are located in the inner ear, adjacent to the hearing receptors. Vestibular information is processed in the lower portion of the brain in the brainstem and cerebellum. Therefore a problem in the inner ear or one in the brain can affect the vestibular system. The phrase \"vestibular disease\" is a general term referring to any abnormality of the vestibular system, although some people use this term to mean idiopathic vestibular disease (see below).\nSigns of vestibular disease include ataxia, head tilt, and abnormal nystagmus. A wide-based stance and swaying of the head and trunk characterize ataxia. The patient may tend to lean and fall to one side. In severe cases, the animal may continuously roll to one side. Head tilt is an abnormal position of the head such that one ear is held lower than the other. Nystagmus is a rhythmic movement of the eyes, where the eyes move back and forth or up and down. In some cases of vestibular disease, there is a sudden onset of severe signs. This may initially be confused with a seizure.\nIdentification of vestibular dysfunction is based on recognition of the specific signs. The veterinarian diagnoses the cause of the disorder with a medical history and examination. In some cases, further diagnostic tests, such as x-rays, computed tomography, or magnetic resonance imaging is necessary.\nInfection of the middle/inner ear is a common cause of vestibular disease in the dog. Most cases can be diagnosed by a thorough examination of the ear with an otoscope. Ear culture, X-rays, computed tomography or magnetic resonance imaging is sometimes necessary. If bacteria cause the infection, treatment consists of appropriate antibiotics.\nThis is also a common cause of vestibular disease in the dog. Another name is geriatric vestibular syndrome. Older dogs (mean age 12.5 years) are primarily affected. There is a sudden onset of ataxia (which can be severe), head tilt, nystagmus and occasionally vomiting. The cause of this syndrome is unknown. Diagnosis is based on the signs and excluding other causes of vestibular dysfunction. Affected dogs improve spontaneously within 2 weeks, although there may be a mild, persistent head tilt. Nursing care is important during recovery. Unfortunately, affected dogs are sometimes euthanized because of the severe signs and concerns that the patient has a brain tumor or stroke.\nHypothyroidism can cause vestibular dysfunction in dogs. Signs may develop suddenly or over time. Diagnosis is based on laboratory evaluation of thyroid function and response to thyroid supplementation. Vestibular dysfunction typically resolves within 2 months of treatment.\nMedications placed in the ear are the most common cause of vestibular toxicity; although some orally administered drugs can also be a problem, especially at high doses. Ear drops or other substances should never be placed in a dog's ear except on the specific recommendation of a veterinarian.\nTumors in the inner ear or brain can cause vestibular problems. Older animals are more commonly affected and there may be pain on opening the mouth. Diagnosis is based on x-rays, CT, MRI, and/or biopsy.\nInflammation of the brain (encephalitis) can cause vestibular dysfunction. Causes include infections, such as distemper virus, and non-infectious causes. Diagnosis often requires analysis of spinal fluid. Some types of infection can be specifically treated with medications.\nWB Thomas DVM\nUniversity of Tennessee\nThomas WB. Vestibular dysfunction. Vet Clin Small Anim Pract 30:227-249, 2000.\nLinks for Vestibular Disease\nPage last update: 12/13/2011"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:0151a7b4-5b05-4dd5-b13f-f93835627bf4>","<urn:uuid:c0d86817-0f63-46a3-8fe6-6862bf03e7b3>"],"error":null}