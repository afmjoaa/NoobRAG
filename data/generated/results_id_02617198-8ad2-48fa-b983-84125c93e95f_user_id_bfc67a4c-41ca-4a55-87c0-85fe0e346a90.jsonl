{"question":"How does the sampling frequency requirement in audio mastering software like Blackbox compare to the fundamental Sampling Theorem in signal processing?","answer":"In Blackbox's audio mastering, the sampling quality settings (Fast, Low, Medium, High, Best) affect the quality of filters and rendering time, with higher sample rates like 96kHz requiring the 'Best' setting for proper low-end processing. This aligns with the fundamental Sampling Theorem, which states that the sampling frequency must be greater than twice the highest frequency in the input waveform for correct resolution. The theorem specifies that if an input waveform is sampled at Fs, then the highest input frequency that can be resolved without aliasing is Fs/2 (the Nyquist rate). This relationship ensures accurate reconstruction of the original signal from its samples.","context":["Blackbox is an analog style mastering chain with sophisticated automation to give clarity, loudness, warmth and punch to music. Blackbox uses expressive controls which allow the user to make a suggestion on how they want their audio to sound rather than having to know the intricacies of an audio mastering chain. Blackbox DSP modules simulate mastering hardware and its internal devices loosely emulate classic mastering gear like the MLA-3 and MBP II. The combining these expressive controls with content aware AI, Blackbox is able to finely tune its mastering chain to the audio content to get the most out of the sound.\nWindows - download the zip file and extract the binary executable. Put the executable file where you desire and create a shortcut to it if you wish. The Blackbox.exe is standalone so should just run from any location.\nMac - download the dmg file and extract the binary application. Put the application in the applications folder on your mac. Run the application. If you get a security warning saying it can't be run as settings only allow applications from Mac App Store, don't worry. Go to Apple -> System Preferences -> Security & Privacy and you should see a notification about \"BlackBox was blocked\", click on \"Open Anyway\" which should allow the program to run!\nOnce setup you can drag and drop audio directly to the interface or use the browse icon in the top right hand corner. After selecting the audio file you wish to process you can either process a small section of the track by highlighting and clicking process or you can process the entire track. There are some presets available to select from to aid you getting the desired sound.\nThere are several keyboard shortcuts in Blackbox which include:\nBlackbox box uses 8 crafted expressive controls to achieve desired outcomes. It's useful to know the scope of each of these controls and how they affect the signal.\nThe LFC, low frequency cut is a digital brickwall style filter that happens early on in the mastering chain. It is responsible for clearing out the rumble within a mix and gives a cleaner signal to the rest of the chain. Be careful not to go too high depending on your audio source as some fundemental frequencies often reside as low as 50hz. As a general rule you want to clean between 28hz and 44hz (this is slightly subjective).\nThe sub enhancer control affects several elements of the sub bass. It is primeraly a gain control but it also serves as a multiplier for bass part of the multiband compressor and as a tuner control for the sub decimator which focuses the fundemental bass frequencies.\nThe body level plays a similair role to the sub enhancer and focuses on the first set of harmonics. This is a useful control and in general should be used in the opposite direction as the sub enhancer. If you want a focused sub bass for loud club speakers then it is recommended that you lower the body level to create more room for sub frequencies. If however you are mixing for CD, Radio and smaller playback devices then it is recommended turning this control up whilst lowering the sub so the bass is more prominent.\nThe clarity control is dictated by the content of the audio. If there is a singer or and instrument like a guitar or maybe some plucky synths that are low in the mix and you want to bring them out then you can bring the clarity up a little. If they are to prominent and you want to push them back or maybe bring out some more stringy or brassy sounds then you may want to turn the control down a little.\nThe brightness control does what it says on the tin and brightens the whole mix. The upper frequencies will get pushed into the saturator and tamed a little by a compressor so its often required to bring the brightness down a little if a track has been produced digitally. If on the other hand you want the mix to have a more crispy air frequency you can push the control quite hard as it maintains perfect phase and shouldnt cause any more siblance than what is already present in the mixdown. This control can also be use creatively as it acts a little bit like a tuned shelf eq, turning it quite far down will give a warm vintage feel to the mix.\nThis is how much the sound is driven into the DSPs within blackbox. It is important to understand the loudness clarity trade off when you really push this setting however, Blackbox has some nifty algorythms for maintaining transients even when pushed hard. So if you like it loud and crunchy then crank the loudness setting up.\nThere are many tuned compressors in Blackbox and it is one of the reasons why the mixdowns are well balanced. The compressor control will lerp between a range of subtle settings to give more or less glue to the mixdown. The compressors settings should all auto adjust to compensate for the different compression ratios and keep the overall presence the same whilst creating room for elements to shine.\nQuality is directly related to the quality of the filters used by blackbox and the time it takes to render audio. Quality ranges from Fast, Low, Medium, High and Best. For context it takes approximately 16 times longer to render audio on the highest setting. It is recommended that you test with medium and then set it to high to render a 44.1 khz track. If you plan on using higher sample rates e.g. 96khz then it is highly recommended you use the Best setting as the low end may suffer on lower quality settings at these sample rates.\nThere are several other controls in Blackbox that help fine tune the output. These include\nThe ceiling control dictates the maximum peak value in decibels and can be used to conform to whatever standard is required for your production. There is also a true peak control which conforms to BS.1770 standard. Note that true peak may considerably reduce the volume of the track depending on its content. This prevents any analog system playing the signal above unity.\nThe loudness release control is in the settings screen. This a hyper parameter that affects the limiters in blackbox. Reducing this control will create a more agressive modern limiting profile and increasing this will produce a smoother mix.\nThe stereo cut frequency control is in the settings screen. This a hyper parameter that affects mid side processing in blackbox. In most cases it is a good idea to centralise the bass. This frequency dictates the center of the role off frequency where you want the bass to become more mono. In some cases you may wish to leave more stereo field on the bass so reducing this frequency down to its lowest setting will achieve this.\nBlackbox now features a Fast Fourier Transform Analyser window in Real Time Mode. The FFT has has been augmented to show perceived sonic levels in each frequency band.\nBlackbox features professional broadcast metering. You can now monitor levels in RMS, LUFS, Integrated Loudness and Dynamic Range.\nBlackbox export options allow you to save to AIFF and WAV formats at whatever processed sample rate you pick. If you choose to export to 16bit or 24bit you can addtionally add dithering signal which reduces aliasing / banding in the bit rate domain and thus smoothes out potential artifacts. Dithering has several options, None, Rectangular, Triangular and POW-r2 which dictate what kind of signal is applied. Once you have selected the appropriate options just click save and a window will appear prompting you for a file name. The extension will be added automatically. Once selected the save operation will start and in most cases will take under 10 seconds to complete.","Development of Sampling Theorem\nThe Sampling Theorem will be the single most important constraint you'll learn in instrumentation.\nHere we want to move as efficiently as possible toward an understanding of the Sampling Theorem.\nPeriodic function described by sum of sines and cosines:\nConsider a periodic function h(t), with period T. For any t: . Let the fundamental frequency be .\nNow say that we know that h(t) has no frequency component greater than N*f. In fact, for the sake of developing an example, say N=10.\nExactly how we can say or know this maximum frequency constraint is a matter of some interest. Suffice it to say for now that an anti-aliasing LP filter may be used to help insure that h(t) is band-limited. More later about alias frequencies.\nAs described in a math course you've taken (example text: Thomas, Calculus\nand Analytic Geometry, Addison-Wesley, 1960, pp 821-25), you can represent\nh(t) exactly with the Fourier series:\nwhere the n's are integers and there are (in this example) 21 coefficients, the a's and the b's, to determine.\nThe first coefficient, a0, is the DC average of the signal h(t): and can be calculated immediately, leaving the other 20.\nSo at this point you can assume we are dealing with a periodic function of zero average.\nNow we need to find the a's and b's. If you look in a calculus book, like Thomas,\nyou can find integral formulas of the sort:\nfor a 2*π period.\nA more \"brute force\" computational way to find the a's and b's would be to generate 20 independent equations by sampling. We can sample 20 times during one period. If we sample over more than one period, we may not end up with independent equations.\nEach equation will be of the form where m indexes the 20 samples.\nThe 20 equations can be formed into a 20x20 matrix C of coefficients times a 20x1 column vector of unknowns = a 20x1 column vector of h(tm) values.\nwith a solution\nThe elements of C will be various sine and cosine terms in n, ω and t.\nMatlab will be able to invert matrix C in a matter of milliseconds.\nSo much for finding the a,b coefficients, which will be real, not complex numbers. Each a,b pair says how much a particular frequency is weighted in the summation leading to h(t). How should we combine an, bn, for one measure of a particular frequency's contribution? It turns out is a good choice. The Cn's represent the spectrum of h(t).\nNow what about the spacing on the samples? If the spacing is uniform\nthere will be 2N segments of time, each segment the sample time (time between\nThe maximum frequency in h(t) is , therefore we have the Sampling Theorem:\nThe sampling frequency must be greater than twice the highest frequency in the input waveform in order for all frequencies in the input to be correctly resolved. If the sampling criterion holds, then the input waveform can be exactly reconstructed from it Fourier coefficients. Another way to say it: If an input waveform is sampled at Fs, then the highest input frequency that can be resolved without aliasing is Fs/2.\nAnother statement of the Sampling Theorem, from A. V. Oppenheim\nand A. S. Willsky, Signals and Systems, 2nd Ed. Prentice-Hall (1996)\nTerminology: The sampling frequency of a particular situation, which may exceed by quite a bit the maximum frequency in the signal, is the Nyquist frequency. Twice the maximum frequency of the signal is called the Nyquist rate, and is the minimum sampling rate that can resolve the signal. (O&W, 1st Ed, p. 519)\nSmallest frequency difference to be resolved\nExample: Imagine that sampling goes on for one second, at a rate of 20 Hz. 20 samples will be taken, and 10 frequency spectrum coefficients can be computed. Since the maximum resolvable frequency is 10 Hz, the 10 coefficients must represent frequencies spaced 1Hz apart. 1Hz is therefore the minimum resolvable frequency difference. What if the sampling goes on for 2 seconds, at 20 Hz? Then there will be 40 samples for 20 frequencies, still with a max of 10 Hz and therefore a 0.5Hz difference between steps in the spectrum. It should begin to make sense to you that, for a constant sample rate, as the sampling time increases, the frequency difference between intervals in the spectrum decreases. The relationship is\nSuppose you want to resolve manual frequency of knob rotation to the nearest 0.1Hz. How long will the subject have to turn the knob back and forth while you sample? 10 seconds. If you sample and audio signal at 40000 Hz rate for 0.1 seconds, the spacing on the spectrum will be what? 10 Hz.\nHow frequently does the FFT display on your digital scope update?\nDiscrete Fourier Transform Notation from C. Williams, Designing Digital\nFilters, Prentice-Hall (1986) p. 262. It is worth inspecting the\nformula that shows how Fourier coefficients H are computed in a computer:\nThe DFT is\nwhere both i and k range from 0 to N-1 and j is the imaginary number. The sampled values are in the list hk.\nThe H are usually complex numbers, and their magnitudes must be taken to find the Power Spectrum.\nThe inverse DFT is\nwhere hk is a list of numbers brought in by sampling a waveform: Or, in the case of the DFT, a list of numbers that reconstruct a waveform from its spectrum H.\nA standard reference is A.V. Oppenheim & S. Willsky, Signals and Systems, 2nd Ed., Prentice-Hall (1997). See chapter 3, \"Fourier Series Representation of Periodic Signals.\" Much of the development in their chapter uses the Euler identity, , where j is the imaginary number.\nWilliams points out (chpt 2) that the complex exponential is an eigenfunction for digital filters and therefore better, mathematically, for demonstrating properties of digital filters.\nIn fact, a faster algorithm, the Fast Fourier Transform (FFT), is normally computed, for example, in LabVIEW or MATLAB on in the math feature of the HP 54622A digital scope.\nMathematically, the FFT receives as input a vector of real numbers that represent evenly spaced samples in time, and returns as output a vector of the same size, likely of complex numbers, that represent coefficients of a spectrum. The \"user\" must be able to interpret what the frequency spacing is on the output vector. The \"power spectrum\" is the magnitude of the complex numbers.\nEXAMPLE: In the command line of MATLAB,\ntype vec = [ 1 2 3 4 3 2 -1 -2 0 1 2 -1 -3 -5 -2 1]; in MATLAB notation: 16 data points.\ntype vec_out = fft(vec); to generate a list of 16 complex numbers.\ntype pwer = abs(vec_out); to find the magnitudes of the complex numbers.\ntype plot( [0:15], pwer) to generate the plot below:\nNotice the plot is symmetic about \"frequency\" 8, except for the 0 data point. The 0 frequency data point is the DC average of vec * 16 = 5. The data from 8 above is a mirror image of the true spectrum, represented by the lower half of the plot.\nThe Sampling Theorem says that input waveforms with frequencies below the half sampling rate can be reconstructed exactly. Frequencies above the half the sampling rate become aliased as lower frequencies: For frequencies just above the half the sampling rate, up to the sampling rate, the aliased frequency falias = fnyq-|factual - fnyq|, a kind of mirror-image result. See Matlab example (alias03.m file) below, where the waveform to be sampled is in gray. It is a 12 Hz sinewave and would therefore require greater than 24 Hz sampling rate to preserve the correct frequency in reconstruction. The red line is the result of sampling at 20 Hz; the alias is therefore 10- abs(10-12) = 8 Hz.\nAn input at exactly the sampling rate is \"standing still\", as you will\nsee in the strobe demo.\nThe graph below shows the triangle waveform for aliased frequencies greater than Fsamp.\nThe F-obs waveform is periodic on F-samp. Here's an attempt to formalize the triangle\nwaveform: Say f-act = actual input frequency:\nDivide f-act by f-nyq and express the answer as integer + remainder:\nnext let B = INT mod 2 (even = 0, odd = 1)\nthen f-obs = REM + B * (f-nyq - 2 * REM)\nDemo of aliasing with strobe light. In a darkened room aim a strobe\nlight at a fan. The fan's 3 blades will have the number\"123\" written\nin different colors. Think of the strobe frequency as the sampling frequency.\nOne thing we would like to know: At what Hz are the fan blades rotating? (the\nfan has SLO MED FAST settings)\nExample from the web.\nIf we can set the strobe to the same rate as the fan rotation frequency, then the fan blades will appear to stand still and the one blade with \"123\" will be visible. The fan rotation frequency will be aliased to 0Hz because the sampling rate will equal the input frequency rate.\nBut if the strobe is at exactly half the fan frequency, the blades will also stop! Why? Because now the \"input\" of fan frequency is 2x the sampling rate, another zero point on the alias figure above. How can you make sure the strobe freq is set at the fan frequency? One way: bring the strobe down from an obviously high frequency, then the FIRST time the blades \"stop\" so 3 blades are seen, must be the correct frequency.\nWhat do you see if the strobe frequency is at 2x the fan frequency?\nNotice that when the strobe is set at the fan frequency slight changes in the strobe frequency up or down cause the fan blades to rotate slowly either CW or CCW. The slow rotations may be at the same slow frequencies, but in different directions: What does this phase difference mean for interpretation of aliasing?\nSo: Aliased frequencies may be bad news for electrical spectrum analyzers, but for mechanical rotation they can be a helpful measurement.\nAbout the strobe: General Radio 1531A, from 1971. The circuit used to drive\nthe 10 microseconds of the Xenon flash tube is similar to a defibrillator. Charging\na capacitor up to several hundred volts. Why no new strobe models on the market?\nFear of lawsuits about epilepsy, or the high voltage?\nThe inputs to a digital filter come from a tapped delay line (TDL). The delay time is the sampling time. The number of input taps to the filter is a measure of the filter's size. An example from\nis shown below, where x(n) is the sampled input waveform to be tapped and filtered.\nThe notation means \"delay of δ t\".\nNormally the TDL is in software. The taps pass through coefficients (bMi above) to a sum-of-products, whose output is the filter output, in the case above, y(n). Designing a digital filter means selecting the proper coefficients. If the coefficients are all positive some kind of LP filter results. If the coefficients alternate in sign some kind of HP filter results. Here is a website that reviews sum-of-product filter design, and here is one that generates C code digital filters of various types.\nCutoff frequency for anti-aliasing LP filter.\nExample: Suppose there is noise at all frequencies (white noise), but that your signal has information only below 1000 Hz. What would be a reasonable sampling rate and what should be the cutoff frequency for the anti-aliasing filter?\nPlacement of anti-aliasing filter: BEFORE A-D converter! (not feasible to be a software filter).\nApproximation due to sampling: See lecture notes on A-D conversion\n2008-09 see jdd/Reconstruct08b.m\n[FofT, FofT_cont, tim_sine] = Recnstrct08b(inp_mde, snsoid_type, spc_mde, calc_mde, wind_flg, samp_num, sine_max)\nto investigate reconstruction and FFT coefficients."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:613af0ac-61e5-4547-92e5-df4c68f2b133>","<urn:uuid:5a29466b-fce0-4abd-97d3-4e7f9bd06d23>"],"error":null}
{"question":"How do social media monitoring and keyword research complement each other in understanding market competition?","answer":"Social media monitoring and keyword research work together as complementary tools for understanding market competition. Social media channels can provide valuable keyword insights by showing what people are currently discussing, which can be discovered by typing words or phrases into platforms like Facebook. This social media data should be combined with competitor analysis by examining rivals' social media activities, content quality, follower interaction, and reviewing their keyword relevance and ranking behavior. Additionally, businesses can gain insights by consulting front-line employees about customer terminology and common questions to enhance their keyword strategy.","context":["Once your campaign is established you must review the analytics data and look for ways to optimise the campaign. Setting clear goals and measurements are absolutely critical to allow the campaign to be reviewed against each stated goal, in which you will consider ad performance, keyword performance, ad placement performance, campaign structure, and campaign targeting. This chapter highlights how to analyse and optimise your PPC campaign for success.\nThe first step in this process is determining who are the top four competitors that we want to use for this analysis. I like to use a mixture of direct business competitors (typically provided by my clients) and online search competitors, which can differ from whom a business identifies as their main competitors. Usually, this discrepancy is due to local business competitors versus those who are paying for online search ads. While your client may be concerned about the similar business down the street, their actual online competitor may be a business from a neighboring town or another state.\nTo do this, you want to analyze your analytics frequently by keyword and observe visitors’ behavior when they come to your website or landing page. Don’t fixate on just traffic alone. How much time are they spending on your site? What is the average number of pages they are viewing? What is the bounce rate? A high bounce rate like 80 percent will tell you that most of your visitors leave your site immediately upon landing on your site. They’re not engaged and see no content clues they arrived at their desired destination. This can be fixed by making changes to your landing pages as long as they are relevant to the keywords that brought them there.\nRepeat this exercise for as many topic buckets as you have. And remember, if you're having trouble coming up with relevant search terms, you can always head on over to your employees on the front lines -- like Sales or Services -- and ask them what types of terms their prospects and customers use, or common questions they have. Those are often great starting points for keyword research.\nChoosing which PPC strategies to deploy will largely depend on the type of business you have and the goals you’d like to achieve. By now, almost all of Google’s above-the-fold search engine result page (SERP) space is PPC advertising, which includes Google Shopping ads and PPC Adwords ads, as well as organic search results. Given this increasingly competitive and limited landscape, it’s important that you use the tools available to get a leg up on the competition. To help you navigate the field, here are 8 of the best PPC strategies your competition is not doing (and that you should be).\nIt has also become remarkably difficult to distinguish direct competitors from indirect threats - and when you do, you find competition often comes from surprising places. In fact, competition in the SaaS and tech industries is increasingly coming from indirect competitors, whose core technology enables them to invade adjacent verticals and industries.\nIf you want to see what people are talking about at any given moment, there's no better way than to check in with your social media channels. Most of us already do this throughout the day, but if you haven't tapped into your channels for keyword research, you're missing out on valuable insights. Here are just a few things you can uncover by typing a word or phrase into the Facebook search bar:\nThis can mean simply using pictures from the surrounding area or structuring the landing page around a theme that is relevant. A great example of this is Grubhub. If you access their site from Boston, you get completely different suggestions and images than you do if you access it from San Francisco. Not only does this engage the user on a personal level, it also draws them in to the page, keeping them clicking for longer.\nYou should invest in having a well-structured filing system, both in the office and digitally. Use neatly organised folders with clear and relevant names on them for all of your documents, bills and emails. By doing this, you can free up hours of the day to work on important tasks, such as drumming up more business through a new and exciting marketing strategy. You will also be setting an example for your team by having an organised office and computer.\n\"Since consumers know what they are looking for, you can optimize your content around the core needs and problems your target audience experiences. It is your job to build an SEO strategy by knowing what your customers are looking for. This will allow you to create relevant content that your customers want to read, and as a result, your content will rank higher in Google.\"\nIf you’re aiming for a steady cost per conversions (also known as Cost Per Acquisition) average, despite the potential challenge in calculating those costs, then Conversion Optimizer may be of help. This strategy works by setting a target Cost per Conversion at campaign level, and then AdWords uses your historical conversion data to optimize your bidding strategy to reach your targeted average.\nThis is the most basic way to start your keyword research—so basic, in fact, that it's easy to overlook. Let's say you're manufacturing solar panels and you want to target businesses that qualify for alternative energy tax credits. Start with a Google search just like your customers would. You can see which phrases pop up first when you type in \"alternative energy tax credits.\" This should give you a good indication of the most popular searches.\nGeotargeting is a practice frequently deployed by such restaurants and brick-and-mortar businesses looking to drive local foot traffic, but it isn’t exclusively the province of these verticals. Even sports teams have gotten in on the action, targeting fans that are at (or have been to) a particular stadium or event in order to drive ticket sales, app downloads, and more.\nYou may be wondering why these seemingly different strategies are included as one. The reason is that the strategy is the same: Getting the most out of your budget. The only difference is the tactics to achieve that strategy. Sure you may need to look at different metrics and dimensions of your campaigns to maximize your budget, but in the end you achieve the same thing.\nUsing the same keyword phrase over and over within a web page or blog post can actually hurt your ranking score in Google, which can perceive it as spammy. That wasn't your intention, but maybe you just couldn't think of a better word to use in its place. The Latent Semantic Indexing (LSI) Keyword Generator is like a thesaurus for SEO-minded content marketers. It offers keyword suggestions that are semantically linked to your main keyword, meaning they would naturally come up in conversation. Incorporating these keywords into your post allows you to add variety while still retaining SEO power.\nIt is crucial to separate business and personal finances – and to be very prudent in the first few years of running your business, especially when you start making profit. Keep tight record, develop regular forecasts, avoid overdrafts, watch interest rates, keep track of expenses, bank all income, self-fund if possible and check bank statement regularly. Re-invest your profits into the growth and development of the business, the reward will be well worth the investment.\nFor example, if a user from a high income neighborhood visits a car dealer’s site or clicks on a paid search display ad, that consumer may be directed to a landing page displaying a luxury vehicle, while consumers located in a lower income area may be targeted with a deal on an economy vehicle. The higher income consumers may be more interested in deals such as cash off or lower interest rates whereas those in lower income brackets may be more receptive to lower monthly payments.\nThe SEO Checker analyze the title, description, h1/h2/h3/h4/h5/h6 tags, their correct filling, and their relation with the content from the web page. We look at the size of all the content, and if all content files can be loaded and exist. We look for all the keywords on the page, how many times they appear, and if they appear in the title, description, or h1/h2/h3/h4/h5/h6 tags. We analyze your social media status, and look if you use the properly social media meta tags. Also we look for the site usability, site reputation, site speed, and much more.","Competitive analysis is used in marketing and strategic management to estimate the weak and strong points of your market peers.\n‘Keep your friends close, but your enemies closer’, Michael Corleone, the main character of ‘The Godfather’ said.\nEven if you do not consider your market competitors your enemies, this is highly important to your business success to gather the information of their pros and cons. Because every good idea grows from improving an area of someone’s weakness.\nMoreover, competitive business research is the right way to examine your market closer. The complex method allows you to analyse a business as if you were a part of their company, a marketer and a customer as well. Competitive analysis performance does not need any specific knowledge, but it needs your time and diligence.\nSo, let us help you complete the research of your competitor companies step by step.\nHow TO ANALYSE COMPETITORS?\nWe divided the whole process of a competitive survey into the three main stages according to the principal “from simple to complex”.\n1. Identifying YOUR COMPETITORS\nThe point of departure – Your analysis is to identify who your competitors are, and categorise them. This is the easiest section, nonetheless, the most crucial step for the later stages of your research.\nTo organise your time better, download the Competitive Analysis Template spreadsheet. Change this by adding or removing the columns that you feel are relevant to your requirements.\nBegin looking for your primary competitors on Google Advanced search or other search platforms that are popular in your country or city. Use the same keywords that your business targets. Then, check your rivals products on sales markets such as Amazon, Alibaba Group, or Asos if you offer fashion products. One more important channel is social media networks – Facebook and Instagram. These allow you to identify competitors which may not have websites but can be found using hashtags.\nWhen you have finished adding these to the spreadsheet, you need to break your competitors into tiers. The most popular approach for competitors mapping is to categorise them into three groups:\nPrimary (A). These are your direct competitors with the same products and audience, as well as business size.\nSecondary (B). These are competitors who offer similar products but to a completely different audience segment.\nTertiary (C). These are businesses, who are just tangentially related to yours. They may become your competitors if you decide to expand your product catalogue. Or they may also be your partners in affiliate advertising.\nPut their store names, links, locations, slogans, and segment notices into a competitor research spreadsheet to have an opportunity to monitor and change the data from time to time.\nAfter your competitors have been identified and categorised, you can move on to the next stage – examination. To come closer to these rivals and discern more details you need to analyse their site’s content as a customer and become their customer.\nThus, the ‘examination’ stage of competitive analysis consists of two steps: external (visual) and internal examination.\nExternal (Visual) Examination\nFirstly, we advise getting started analysing the information from the sites of your direct competitors. Just take a view of their online store content, and answer the following questions:\n- Check, if their design is attractive, clear and user-friendly.\n- Is their website optimised? Do they have a mobile application?\n- How do their navigation and filters work?\n- Are their product photos and other images high quality? Is there any stock content?\n- How do their product cards look like? Where are their CTAs placed?\n- What is the quality of their text content?\n- Do they have a blog?\n- How do their promotion banners look like?\n- Do they have links to social media? Where are they placed?\n- Are their social media pages or channels active? What content do they publish there? How do they interact with their followers?\n- How many reviews do they have? How often do they answer questions?\nPay attention to all the areas and features you wanted to have on your site. Make a site analysis checklist and please do not forget to make notes.\nTo get deeper expertise, fall back on secret shopping, which is necessary for improving the customer experience on your own website. Therefore, try to be a difficult customer if you want to find out all pitfalls of the purchasing process, and learn from their mistakes in future.\n- Do they have a cart?\n- Do they have abandoned card features?\n- Is it easy to make a purchase?\n- How long time does their reply take?\n- What is their SEO structure?\n- How do they speak with their clients?\n- Are transactional emails send immediately? How do they look?\n- How they solve problems with shipping?\n- How can you return the products? How long does this process take?\n- Do they have physical stores or showrooms?\n- What emails do they send after you have visited their website?\n3. Digging into\nTo better define your strategy and effectively maintain the competitiveness of your web resource, you need to start analysing some technical aspects of your company rivals. The main questions you should answer:\n- When was their online store found?\n- What kind of promotions do they have?\n- What position does the site take in the search results?\n- What contextual ads do they use?\n- What pricing strategy do they follow?\n- What is their current ranking behaviour?\n- How are their pages and content ranked?\n- What is their keyword relevance?\nTo minimise your efforts, check a few useful tools which could help discover and analyse the information about your competitors’ strategies.\n1. SimilarWeb allows you to analyse the multiple areas of digital marketing strategies of your competitors at no cost. Pasting any website link into the search bar, you will receive the full data of its activity:\n- Total visits\n- Traffic by countries\n- Traffic sources\n- Referring sites\n- Organic keywords\n- Paid keywords\n- Social traffic\n- Display advertising\n- Audience interests\n- Competitors and similar sites\n2. SEMrush also provides you with the same competitors’ insights. But it has its benefits. Firstly, you are able to simultaneously compare four-five competitors, secondly, the platform builds motion charts based on SEMrush reports data in your Google Sheets. So it will be easier for you to analyse the broad picture of your marketing position\n3. Alexa is an effective metrics and tool for spying on competitors rankings. With a paid account you can also estimate such information as popularity, demographics and behaviour data of your competitors: time on site, bounce rate and so on. All data will be put into a table and ranked automatically.\nThere are also a variety of other tools which may help you on each stage of the competitive survey.\nMarketing competitive analysis helps new businesses assess their opportunities and threats. Spend your time to find and categorise your rivals correctly. Perform a detailed examination of your direct competitors first. Pay attention and analyse such information as their market position, audience, website solutions, social media activities, and pricing strategy as well. Analyse their SEO structure. Become their secret customer to test their customer support, email marketing activities, and shipping solutions. Make notes using different tools to gather the data needed and see your competitors’ weak points.\nTransform their weakness to your strengths and improve their strong spots to your extra features, so you can build your ultimate digital marketing strategy."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:2b479064-5f05-44d2-8a22-1b8b239ff35a>","<urn:uuid:d9017bd5-c12f-490c-a897-75e0cb42e506>"],"error":null}
{"question":"What are the scientific principles behind hippotherapy, and how does it benefit patients in therapeutic settings?","answer":"Hippotherapy uses horses for rehabilitation, helping patients improve balance, flexibility, posture, and motor skills. The scientific basis involves the horse's movement affecting the patient's pelvis - studies have shown significant improvements in pelvic range of motion and functional abilities, particularly in children with cerebral palsy who lack normal pelvic movement. In therapeutic settings, horses are valued as therapy team members due to their unique characteristics - they are extremely perceptive to human emotions, experts at non-verbal communication, and will mirror human behavior. They are non-judgmental, have no prejudices or expectations, and respond immediately without assumption or criticism.","context":["A COMPARATIVE ANALYSIS: BIOMECHANICAL DIFFERENCES BETWEEN HIPPOTHERAPEUTIC MECHANICAL HORSES\nThomas Jefferson Senior High School\nFaculty Mentor: Dr. Carolyn Skurla\nDepartment of Mechanical Engineering\nHippotherapy is a form of physical therapy employing horses to rehabilitate people who need to improve their balance, flexibility, posture, and motor skills. Animals have been used as a part of therapeutic treatment since the 1700s, but more recently hippotherapy has become a focus of many researchers for its direct benefits. Most commonly, children and young adults with cerebral palsy (CP) are the focus of these studies. Children with CP lack normal pelvic movement. By riding a therapeutic horse it has been found that significant improvements in their pelvic range of motion and other functional abilities occur. The fundamental goal of this research is to quantify the movements and benefits of a mechanical horse compared to a live horse. In our research, we used three different hippotherapeutic mechanical horses to collect motion capture data. We compared movement data from the mechanical horses to that of a live horse. Using these results, engineers will be able to determine whether mechanical horses are as beneficial as live horse therapeutic riding.\nWHAT CAUSES EARTHQUAKES AND TSUNAMIS IN THE NORTHEAST CARIBBEAN?\nFaculty Mentor: Dr. Jay Pulliam\nDepartment of Geology\nThe Puerto Rico Trench is the deepest part of the Atlantic Ocean, with the lowest gravity anomaly on Earth, and is prone to earthquakes and tsunamis. It is located north of Puerto Rico and was formed by the North American tectonic plate subducting beneath the Caribbean tectonic plate. It is hypothesized that a tear in the North American plate caused--or perhaps just allowed--a portion of the trench to collapse, causing an increase of earthquakes since 2004. This project was designed to determine whether there is such a tear and, if so, whether it is partially responsible for the collapse of the Puerto Rico Trench. In 2007, researchers placed five ocean-bottom seismographs (OBSs) to the east of the Puerto Rico Trench. We examined six months worth of data from the OBSs and marked arrivals of the primary (P) and secondary (S) waves from regional earthquakes that occurred during the OBS deployment. These “picks” can be used to locate the origin, or hypocenter, of each event. Since most of the OBSs are on the far side of the Trench, they yield accurate locations when combined with the picks from the Puerto Rico Seismic Network (PRSN). Our results will help improve the accuracy of hypocenter estimates for regional events and lower the detection level for earthquake monitoring with PRSN stations alone. With more accurate locations and a more comprehensive catalog of events we will be able to determine whether these earthquakes are occurring along a line within the subducted North American plate, and therefore indicate tearing of the plate.\nAPPORTIONMENT OF THE HOUSE OF REPRESENTATIVES, NEUTRALITY RELATED TO LARGER AND SMALLER STATES\nDaniel D Sheng\nThe Hill-Huntington method, which uses a rounding procedure, is currently used to apportion the seats of the U.S. House of Representatives. However, research suggests that this method is biased in favor of either larger or smaller states. Other methods have been proposed as alternatives to the Hill-Huntington method. These means of apportioning belong to a group of methods known as divisor methods, where each method is associated with a strictly increasing divisor criterion. The notion of relative bias was explored, and data based on ten methods, including the identric-mean method, were examined in this project. An efficient and straightforward algorithm, programmed in Java, was developed for implementing these divisor methods. The algorithm showed a connection between traditional implementations of divisor methods and Huntington's ranking functions (priority values). In view of this research, there seems to be few reasons supporting the use of the Hill-Huntington method, instead of Webster’s method, to apportion the House of Representatives.\nANALYSIS OF STARCH SYNTHESIS IN QUALITY PROTEIN MAIZE\nLiberal Arts and Science Academy\nFaculty Mentor: Dr. Bryan Gibbon\nDepartment of Biology\nThe opaque2 (o2) mutant of maize has higher lysine content than the nutritional content found in normal maize due to increased lysine content as a result of reduction in the synthesis of zein proteins. However, this mutant strain is flawed, due to traits such as brittleness, that make it a poor choice for agricultural purposes. Quality protein maize (QPM) has both good nutritional quality and a hard endosperm that is uncommon in other strains of corn due to the presence of the o2 mutation. By comparing the activity of different starch synthesis enzymes in both the QPM and the o2 mutant strain, we will gain a better understanding of the factors that affect kernel structure. To investigate these activities, we performed zymogram analysis of developing maize endosperm. The starch enzyme activity was visualized by separating the proteins on a native gel and then transferring them to a substrate gel. After staining, the bands representing amylase, and the debranching and branching enzymes were visible. We have compared the zein protein profiles of many different maize lines and performed zymogram analysis of selected mutants, wild type and QPM lines. In the future, this knowledge may help to increase the nutritional quality of maize at a more rapid pace.\nSYNTHESIS OF NOVEL BIOREDUCTIVELY-LINKED VASCULAR DISRUPTING AGENTS FOR THE TREATMENT OF CANCER\nWestlake High School\nFaculty Mentor: Dr. Kevin Pinney\nDepartment of Chemistry & Biochemistry\nThe tumor microenvironment is characterized by disorganized vasculature and hypoxic conditions. These characteristics can be exploited by vascular disrupting agents (VDAs) and bioreductive drugs. VDAs disrupt the tumor vasculature by interfering with the dynamic process of microtubule formation in endothelial cells; bioreductive drugs intercalate with DNA which results in the destruction of cells. The objective of this project was to synthesize a novel molecule with a double mechanism of action comprised of a VDA linked with a bioreductive drug. This molecule will be introduced into the bloodstream in its inactive linked form. Upon entering hypoxic areas, the bioreductive trigger will be reduced and release the VDA. Once cleaved, the released VDA will deprive the tumor of oxygen and nutrients by inducing vascular shutdown. Concurrently, the reduced bioreductive drug will damage the DNA and destroy the cells.\nDESIGN AND SYNTHESIS OF A COMBRETASTATIN A-4 (CA4) ANALOG INCORPORATING A BIOREDUCTIVE TRIGGER\nFrisco Centennial High School\nFaculty Mentor: Dr. Kevin Pinney\nDepartment of Chemistry/Biochemistry\nDerived from the African bush willow tree, the combretastatin family of compounds represents an exciting avenue of research in chemotherapy due to their ability to serve as Vascular Disrupting Agents (VDAs). VDAs are able to induce necrosis in tumor cells by cutting off the blood supply, and thus the supply of oxygen and nutrients, essentially starving the cells to death. In order to accomplish this, VDAs selectively target the rapidly dividing immature endothelial cells lining the networks of blood vessels produced through tumor angiogenesis. CA4 and its analogs have been effective at inhibiting the assembly of the microtubules that form a portion of the cytoskeleton of cells. The cellular morphology induced by this drug includes a rounding up of the endothelial cells along the blood vessels, resulting in occlusion of the vessels and the prevention of blood flow. (Z)-2-(4’-Methoxy-3’-aminophenyl)-1-(3,4,5-trifluorophenyl)ethene is an excellent inhibitor of tubulin polymerization and is moderately cytotoxic in both the NCI-H460 lung cancer and the DU-145 prostrate cancer cell lines. To create a more selective therapeutic treatment for cancer, we have synthesized a CA4 bioreductive prodrug analog to preferentially target the hypoxic cells in tumors. Once inside the tumor microenvironment, this novel molecule is expected to afford its active (toxic) species through reductive activation catalyzed by reductase enzymes.\nSTUDIES IN DUSTY PLASMA: A POWER/PRESSURE DEPENDANT PHASE DIAGRAM FOR CONDUCTIVE GOLD/SILVER COATED MELAMINE FORMALDEHYDE IN A GEC RADIO FREQUENCY REFERENCE CELL.\nBrooks C. McMaster\nMemorial High School\nFaculty Mentor: Lorin S. Matthews\nDepartment of Astrophysics\nDusty plasma, a collection of ions, electrons and dust particles, has applications in everything from deep space analysis to semiconductor manufacturing and fusion experiments. In this experiment, the characteristics of conducting dust in a plasma were analyzed using a General Electronics Conference (GEC) radio frequency reference cell. When dust enters a plasma environment, it acquires a negative charge; the degree of this charge depends upon the kind of dust and ambient plasma conditions such as electron and ion density. By negatively charging an electrode at the bottom of the chamber, we can create a potential well, trapping the negatively charged dust and electrons above the electrode. The way in which the particles react to each other within this well, from forming a stable crystal to degenerating into liquid or gaseous collections, characterizes the phase of the system. Stable crystals are characterized as solid and dynamic systems are characterized as gaseous. In this experiment, 8.93 mm gold/silver coated melamine formaldehyde (mf) particles were use to construct a phase diagram for different plasma powers and pressures. A Langmuir probe was used to measure the floating and plasma potentials, electron temperature, and electron density. This analysis has not previously been done for conductive dust. The data will be compared to results obtained using non-conductive dust (uncoated mf) and a second GEC rf reference cell.\nSIMULATING THE INTERACTIONS BETWEEN PARTICLES OF DIFFERENT SIZE IN A DUSTY PLASMA\nDusty plasmas, ionized gas containing macroscopic particles, are present in several fields of science and play a role in the production of silicon chips, the development of fusion power and the study of galactic nuclei. Through experiment and simulation we can find ways to manipulate them and optimize the efficiency in industrial applications, and further our understanding of dusty plasmas in astrophysics. An essential property of dusty plasmas is the interaction between dust particles. To study this interaction, we used two different computer models to simulate a GEC cell, a device used to create plasma at the CASPER laboratory, located in Waco, Texas. We obtained plasma parameters, such as gas temperature and electric potential using a fluid model, and solved the forces between the dust grains using an N-body code, giving us the precise geometry of the dust crystals formed in the cell. We simulated dust particles of two sizes in the cell. The main forces acting on the grains included gravity and the electrostatic force. The dust levitated at the position where these two forces balance. Since the different size dust had different masses, the two dust clouds formed at different heights above the lower electrode. To make the dust clouds interact, we used thermophoresis, a force due to a temperature gradient in the background gas. To add thermophoresis, we heated the lower electrode, causing a temperature difference between the plasma closer to and farther away from the bottom electrode. In this paper, we present the results from our models.\nPHOTOCHEMICAL PROTEIN CROSSLINKING WITH NAPHTHALIMIDES\nDamage to the meniscus is difficult to repair due to avascular qualities of the cartilage. This problem has been examined through photo-oxidative tissue crosslinking. Previous results show that 4-substituted-1,8-naphthalimides photochemical crosslinking in collagen, a primary compound in menisci. In this project, we use 5 differently substituted napthalimides. We verify the conclusion, determined through previous experiments, that naphthalimide 5 catalyzed photochemical crosslinking of RNase in the greatest yield. Proteins such as RNase and lysozyme were coupled with various 4-substituted-1,8-naphthalimides to further investigate photochemical crosslinking of proteins. In addition, we investigated the inhibition of protein crosslinking using the neurotransmitter, dopamine. Because of dopamine’s ease of oxidation, it was expected that dopamine would react more vigorously with the activated naphthalimide than would the protein and thereby inhibit the naphthalimide catalyzed protein crosslinking. This hypothesis was also extended to the compound tyramine, which is less oxidizable than dopamine and therefore should not be as inhibitory to protein crosslinking. A biotin marker was then attached to dopamine and tyramine in order to examine the reaction of the biotin compound with the protein using western blotting.\nSEPARATION OF FATTY ACIDS AND POLLUTANTS USING SIZE EXCLUSION CHROMATOGRAPHY: CONTAMINANT CORRELATIONS WITH FATTY ACID PROFILES IN BOWHEAD WHALE BLUBBER\nSalina K. Lee\nBrazoswood High School\nLake Jackson, TX\nFaculty Mentor: Dr. Stephen Trumble\nDepartment of Biology\nTypical methods for the identification and quantification of ubiquitous pollutants in the environment include Gas Chromatography (GC) and Size Exclusion Chromatography (SEC), which isolate fatty acids or contaminants respectively in collected samples. This project uses an innovative technique of combining GC analysis with the Gel Permeation Chromatography (GPC) form of the SEC process to generate a separation of fatty acids and target contaminants that can be identified simultaneously within a single sample of Bowhead whale (Balaena mysticetus) blubber. Bowhead whale blubber collected from Barrow, Alaska, provides excellent samples for contaminant analysis due to the long lifespan of bowhead whales, during which target analytes accumulate within distinct layers of their blubber. The semi-volatile organic pollutant compounds examined in this project are: brominated flame-retardants, polychlorinated biphenyls (PCB) and polybrominated diphenylethers (PBDE). Once a definite fatty acid profile is generated from the blubber sample, a correlation curve will be plot from the GC and used for comparison with the contaminants also found within the sample. The eventual findings will help researchers further evaluate chemical contamination in the environment and link chemical exposure in arctic whales to develop a better understanding of the hazards to human health from similar chemicals. Trends and future perspectives of capillary GC and SEC will be developed for the continuation of environmental analysis.","Equine Time is Sydney’s first Equine Assisted Psychotherapy Programme. Equine Time started on the 6th May 2009 at Mowbray Park Farm, a natural horsemanship property at Picton on the south west outskirts of Sydney. Visit our website at equinetime.com.au.\nI first read about Equine Assisted Psychotherapy in the Australian Journal of Counselling Psychology Summer 2005 (Frewin and Gardiner). Having been a lover of horses since childhood I was fascinated by what I read, so I decided to learn more about Equine Assisted Psychotherapy. Since then I have attended several trainings to become an accredited Equine Assisted Psychotherapist with EAGALA (Equine Assisted Growth and Learning Association). EAGALA is an international association which aims to provide standards of practice, education, innovation, and support to professionals providing services in Equine Assisted Psychotherapy (EAGALA 2008).\nWhat is Equine Assisted Psychotherapy?\nEquine assisted psychotherapy is not a horse riding programme. The EAGALA model of EAP utilizes ground activities in a large enclosed space in which the horses run free. It is conducted by a licensed mental health professional, a horse specialist and a small herd of three to five horses. In a session the client is invited to undertake a groundwork activity with the horses. At the end of the session the client is invited to verbalise their experience and the equine specialist will reflect their observations of the horse’s behaviour during the session. The therapist then picks up on constructs that are important to the client, in line with the client’s therapy goals.\nThe horses are regarded as members of the therapy team. Their size and power demand respect. They are prey animals and will flee the instant something in their surroundings is out of balance. Horses have a natural curiosity, they have different personalities and they are extremely perceptive to human emotions. They are experts at non-verbal communication and body language. They will mirror human behaviour.\nHorses are social animals and live by the rules of the herd. As in human relationships equine relationships require effective communication and co-operation. Co-operation is important because each member of the herd relies on the others for their safety.\nHorses are non-judgemental, they do not have prejudices, they have no expectations, they are not influenced by appearance or life situation. They have no hidden agendas, they have no regard for external measures of success as humans do, they respond immediately without assumption or criticism. They hold people accountable for who they are in the relationship with them at that point in time (Aspen Ranch n.d., Kaleidoscope Learning Circle 2005, Kohanov 2001, Frewin and Gardiner 2005, O’Connor n.d.).\nWhy Equine assisted psychotherapy?\nThe research literature demonstrates the effectiveness of EAP for children with depression and anxiety (McCann 2001), children with difficult behaviours (Tetreault 2006), and children and adolescents “at-risk” with maladaptive behaviours (Trotter 2006). Significant improvement in behaviour was reported for incarcerated adolescents (Mann 1998) and for adolescents with disruptive behaviours (Greenwald 2001). Mann and Williams (2002) found a significant improvement in adolescents with conduct disorders, mood disorders and psychotic disorders who failed to make progress in traditional therapy settings. Other studies found significant improvement in adolescents with depression, anxiety and low self esteem (Crawly et al 1994, Bowers and MacDonald 2001, Kaiser et al 2004 and Schultz 2005, Bullock and Gable 2006). One therapist stated “I have learned more about a teen in one horse session, than in a month of individual work” (Barbara Lester, Woodbury Reports 2002).\nSeveral studies of EAP with adults have shown significant improvement in symptoms of anxiety (Scheidhacker et.al. 2002), unresolved grief (Klontz et al 2007), depression, anxiety and social disorders (Burgon 2003) and eating disorders (Christian 2005).\nRussell-Martin (2006) compared the improvement in the couple relationship between 10 couples who attended six sessions of solution-focused therapy and 10 couples who attended six sessions of EAP. She found that the EAP couples reported significantly higher improvement than the solution-focused therapy couples.\nLancia (2008) demonstrated significant improvement in symptoms of PTSD in war veterans.\nEquine assisted psychotherapy is being used for individual work, couple work and family therapy. Many of the studies are suggesting that treatment duration is minimised as the equine sessions bring issues to the surface more quickly than in talking therapy (Kersten & Thomas 2005a, Trevelyan 2005).\nExploration of some of the concepts from Personal Construct Psychology to underpin the therapeutic value of the EAGALA model of EAP.\nKelly’s Fundamental postulate states “a person’s processes are psychologically channelized by the ways in which they anticipate events”. A horse’s hypervigilence and instantaneous flight response can also be explained by this postulate. The survival instinct of the horse can assist humans to clarify their own processes.\nThe conditions necessary for the formation of new constructs are the use of a fresh set of elements, experimentation and the availability of validating data.\nA fresh set of elements means that the person is not restricted by their existing constructs. Greg Neimeyer used the word “novelty” to describe the quality of this fresh set of elements. The word novelty means “a new and unusual thing” (Websters Dictionary). An implied meaning of the word novelty is that the thing does not produce a fear response but instead gives rise to a person’s curiosity.\nEAP provides an environment that is likely to be outside the client’s experience and while Kelly names the therapist as a fresh element, the horses and the horse specialist are also fresh elements in the novel environment. Kelly cautions that the new context ought not involve “the self” or “members of the immediate family” until such time that the person finds some usefulness in the emerging constructs coming from the new environment. In the EAGALA model of EAP the observations made are “clean” observations of the horses behaviour during the session. The client is invited to reflect on their learning through awareness of the horses behaviour during the session. Much of the psychological processing occurs between therapy sessions as the person reflects on their specific learning and experiments with it in other situations which are likely to be with self or family. Kelly also states that the environment ought not be so complex that the person is unable to use their moment-to-moment anticipations. In the EAGALA model the activities given are stated as simply as “go and meet the horses and choose one”. A followup session may include “choose a horse and bring it back here”. The client may wish to work on the same task over several sessions.\nThe use of stories will also assist the development of the new constructs before the self is involved. In the EAP session the therapist may ask the client to tell a story about what just happened. It is likely that the person will tell the story about the horses. The self is only involved after the elements in the story have gained usefulness, and gradually the new construct from the story will replace the old constructs that have outlived their usefulness.\nKelly states that the playing out of artificial roles is very useful for the formation of new constructs. He states that “The patent artificiality of the role is the very feature which prevents the tender shoots of new ideas from being trampled in the frantic rush to maintain oneself in their previous role.” (p. 161) To attempt the role of being in control of a large and powerful animal that is free to run away is likely to be seen as an artificial role for most people. To believe that this is possible is beyond most people’s anticipations. When the horse responds willingly the client must reconstrue rapidly in order to maintain their anticipatory system.\n“An atmosphere of experimentation” (Kelly 1955/63 p 162) is important for the formation of new constructs. For Kelly, the word experimentation meant that one variable was attempted to be isolated from all other variables and this one variable is the one acted upon. The more careful we are to isolate one construct or anticipation to act upon the more likely we are to gain a precise outcome. When the client can see clearly the process involved and the result, their anticipation will be clearly validated or invalidated. The clear nature of the tasks set in the EAGALA model and the clear outcome provided by the horse allows for such experimental conditions to exclude as many extraneous variables as possible.\nIn an experimental situation the consequences of the experiment are limited. Kelly states “one does not play for keeps” (p.163). Thus a construct may be shifted from what the client believes to be reality as a possible representation of reality. Once this occurs the construct becomes more open to variation or replacement. The horses become metaphors for the client, and as such the client is able to loosen their construing to enable alternative possibilities.\nClients have the opportunity to make a new prediction and experiment with their behaviours to find the best fit. In the EAGALA model a client is offered the freedom to ‘trial’ various strategies with the horses and they quickly learn the relationship between prediction and response through the horse’s immediate response. These trials are experiments in role constructs and are particularly useful for people wishing to improve their relationships as the horses will act to maintain their own safety.\nKelly states “A construct is a framework for making predictions” (p 163). If the outcome doesn’t fit the prediction a person may begin to change their prediction. They may alternatively try to force the outcome so as to make it fit the prediction. Horses are very good at not responding to the way a person wants them to if force is used. The use of force makes the problem more difficult to solve. In a very short time a person will give up completely or begin to change the construct they are using to predict their desired outcome. Thus horses provide clear invalidation for constructs that are not in line with “shared control” and hence validate constructs in line with “shared control”. This construct is important for the well-being of human relationships.\nOften in an EAP session an observer has little insight into what learning is taking place for the client. “The therapist must be careful not to assume learning by results, or results by learning” (Kelly). What the client learns is what is important and necessary to their construct system, and not necessarily noticeable to the therapist. Sometimes the client may need to form intermediate constructs which to an observer may appear as unsuccessful trials. Kelly states that “the availability of validating data implies skill on the part of the therapist” (p. 164) and in an EAGALA model session the therapist may provide validating data, but essentially that is the role of the horses. The horses provide non-verbal validation and invalidation to the client in response to the non-verbal constructs of the client. “Those things that the client has been unaware of are now brought into awareness” (Kelly). Kelly states “the role-playing exchange is an excellent way of enabling the client to try out new constructs which have immediate access to validating material.” The horse’s response is immediate, and helps the client to see more clearly in a construct, its prediction, action and response. The direct link between a client’s action and the horse’s response can provide very precise evidence for the construct on trial. Horses do not confuse their response with some previous event, as humans are often inclined to do which makes for difficulty when a person seeks validation from other humans.\nKelly points out that it would be more helpful to the client for the therapist to ask the client what are the client’s questions. The EAGALA model of EAP offers the client the opportunity to ask their own questions in the experimental environment with the horses. Very often when the client has formulated their own question, they can find an answer that fits for them. Is it possible for a client to ask a question of a horse? Can a horse sense this and provide them with the answer they need?\nThe use of horses in psychotherapy is rapidly gaining acceptance throughout the world as people experience its therapeutic benefit. The body of research evidence is growing and practitioners are gaining a more precise understanding of the important aspects of the therapeutic process. To be accepted as a valid psychological therapy, the EAGALA model of equine assisted psychotherapy needs to be grounded in an historically trusted theory to ensure its ethical sustainability. Personal Construct Psychology provides a substantive foundation for the EAGALA model of equine assisted psychotherapy.\nAspen Ranch n.d. Why are horses therapeutic? Retrieved October 4, 2005, from http://www.aspenranch.com/equine.html.\nBowers M.J. and MacDonald P.M. (2001) The effectiveness of equine facilitated therapy with at risk adolescents: A pilot study. Journal of Psychology and Behavioural Sciences, 15, 62-76.\nBullock L.and Gable R. (2006) Programs for children and adolescents with emotional and behavioural disorders in the United States: A historical overview, current perspectives, and future directions. Preventing School Failure, 50(2), 7-13\nBurgon H. (2003) Case studies of adults receiving horse riding therapy. Anthrozoos, 16, 263-276.\nCrawly R., Crawly D. and Retter K. (1994) Therapeutic horseback riding and self concept in adolescents with special education needs. Anthrozoos, 7, 129-134.\nChristian J.E. (2005) All creatures great and small: Utilizing equine assisted therapy to treat eating disorders. Journal of Psychology and Christianity, 24, 65-67.\nEquine Assisted Growth and Learning Association (EAGALA) 2008 Retrieved 18 January 2008 from http://www.eagala.org.\nFrewin K. and Gardiner B. (2005) New Age or Old Sage? A review of Equine Assisted Psychotherapy, The Australian Journal of Counselling Psychology, Summer 2005.\nGreenwald A.J. (2001) The effect of a therapeutic horsemanship program on emotionally disturbed boys. Dissertation Abstracts International, 62.\nKaiser L., Spence L.J., Lavergne A.G. and Bosch K.L. (2004) Can a week of therapeutic riding make a difference? A pilot study. Anthrozoos, 17, 63-72\nKaleidoscope Learning Circle (2005) Building effective relationships through equine assisted learning. Retrieved June 14, 2006, from http://www.myklc.com.\nKelly G.A. (1955/63) A theory of personality the psychology of personal constructs. Norton N.Y.\nKersten G. and Thomas L. (Eds.). (2005a) Equine assisted mental health resource handbook. (7th Edition) Santaquin, UT: EAGALA, Inc.\nKohanov L. (2001) The tao of equus: A woman’s journey of healing and transformation through the way of the horse. Novato,California: New World Library\nKlontz B.T. Bivens A., Leinart D, Klontz T. (2007) The Effectiveness of Equine-Assisted Experiential Therapy: Results of an Open Clinical Trial in Society and Animals 15, 257-267. 9\nLancia J. (2007) Equine Assisted Psychotherapy Genesse Valley Psychiatric Association Newsletter March 2007.\nMann D. (1998) Measuring outcomes of equine assisted psychotherapy with juvenile delinquents. Unpublished study. Walberg. CO\nMann D. and Williams D. (2002) In L. Thomas, Horseplay can be therapeutic: Equine assisted psychotherapy. Retrieved March 5, 2006 from http://www.strugglingteens.com/opinion/horseplay.html.\nMcCann J. (2001, Spring) Equine equilibrium. Tempe, AZ: Arizona State University, ASU Research Magazine.\nO’Connor C. (n.d.) The silent therapist: A review of the development of equine assisted psychotherapy. Retrieved March 5, 2006, from http://www.catra.net/info/silent.html.\nRussell-Martin L. A. (2006) Equine Facilitated Couples Therapy and Solution Focused Couples Therapy: a comparison study. A dissertation submitted to the graduate faculty of the Department of Psychology in partial fulfilment of the requirement of Doctor of Philosophy. Prescott, Arizona, September 2006.\nScheidhacker M., Friedrich D. and Bander W. (2002) About the treatment of anxiety disorders by psychotherapeutic riding: Long term observations and results of an experiemental clinical study. Krankenhauspsychiatric, 13, 145-152\nShultz B. (2005) The effects of Equine Assisted Psychotherapy on the psychosocial functioning of At-risk Adolescents ages 12-18, Counselling Thesis 2005, Denver Seminary.\nTetreault A. (2006) Horses that Heal: The Effectivenss of Equine Assisted Growth and Learning on the Behaviour of Students diagnosed with Emotional Disorder. Prepared in partial fulfilment for the requirements of the Master of Arts Degree in Multicategorical Special Education. Governors State University, University Park, Illinois, 2006.\nTrevelyan J. (2005) Equine assisted psychotherapy. Retrieved October 3, 2005, from http://www.winningstrides.com/articleframe.html.\nTrotter K.B. (2006) The efficacy of Equine Assisted Group Counselling with at risk children and adolescents. Doctorate of Philosophy (Counselling) University of North Texas.\nWoodbury Reports Inc.(2002) Horseplay can be therapeutic: equine assisted psychotherapy. Retrieved March 25, 2006, from http://www.strugglingteens.com/opinion/hrseplay.html. Barbara Lester Clinical Social Worker"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:4f3ebe99-3022-44c1-8504-454489948f9a>","<urn:uuid:585b151a-da4a-4a51-a7d7-258c09d70380>"],"error":null}
{"question":"How do marine biodiversity assessments vs boat steward inspections help protect aquatic environments?","answer":"Marine biodiversity assessments and boat steward inspections serve different protective roles. Biodiversity assessments involve recording weather and water conditions, identifying and counting specimens collected in trawl nets to analyze marine habitat health and track species population trends over time. In contrast, boat steward inspections focus on preventing the spread of aquatic invasive species by ensuring boats are clean, drained, and dried before entering waterbodies, with stewards inspecting boats and equipment for invasive species like hydrilla, water chestnut, and spiny waterflea.","context":["Views From the Tower\nSpring 2015 · Volume 43 · No. 1\nDiving Deeper into Science Education There is no better way to learn about the environment than to get out and explore it! However, exploring certain habitats, like our underwater worlds, can be quite tricky. That is why The Wetlands Institute offers Science Education at Sea (SEAS) programs for students in grades 4 through college. The SEAS program is a unique field trip experience, originally developed by former Outreach Coordinator, Travis Davis. The program allows students to learn about their local marine ecosystems while experiencing them firsthand. This three hour, boat-based program allows children to explore the ocean and bay habitats through activities such as crabbing, dolphin watching, fish and invertebrate sampling, and a live plankton lab. The SEAS program focuses on marine biology and combines hands-on, live marine animal interactions with traditional science concepts such as food webs and life cycles. While interaction with live animals is an important component in engaging students, we wanted to dive a little deeper and expand the scientific content of the SEAS program. Utilizing new methods and materials, our goal is to challenge students, allow them to formulate questions, and get them thinking about the bigger picture when it comes to the health and future of our oceans. To reach our goal, we began by enhancing our most popular activity on the boat, the trawl net tow. A trawl net is used by both research scientists and commercial fishermen to collect marine organisms on the bottom of the sea floor. Students are involved in deploying the net into the water and hauling it back on board. This part of the program is always a huge hit and the students are amazed that they actually get to see what’s living beneath the surface of the water! To expand this activity, in spring 2014 we introduced\nby Kaitlin Gannon\na biodiversity assessment component to the program. The biodiversity assessment mimics how actual marine biologists analyze the health of a marine habitat. Just like the scientists, students record weather and water conditions and then identify, count and record the specimens collected in the trawl net. While conducting the biodiversity assessments, we have seen students utilize skills such as species identification, math, and team work, while also still engaged in the activity and having fun. The biodiversity assessment will also provide The Wetlands Institute with some useful data and allow us to identify species population trends over time. In time, our goal is to have this biodiversity assessment data available for teachers to use as an educational tool in the classroom. But wait, we’re not done yet! After the success of the biodiversity assessments, this year we plan on incorporating a water quality component into the SEAS program. During this new activity, students will test and analyze the physical and chemical properties of both bay and ocean water. The water testing will complement the student’s biodiversity assessments, helping to explain why we see specific species inhabiting a certain marine environment. Differences in salinity, temperature, or dissolved oxygen are all big factors in determining how much (or little) biodiversity is present. Water quality testing will also help open discussions on topics that affect students and their community, such as storm water, water treatment, watersheds, marine debris, just to name a few. It is important to us that the SEAS program continues to be an impactful experience, one that students will remember for years to come. With these enhancements to the program, we hope students will not only have a lasting impression, but will leave the trip feeling empowered to become environmental stewards in their community. Stay tuned as we continue to dive deeper into science education!","Starting this Memorial Day Weekend, Paul Smith’s College Adirondack Watershed Institute’s (PSC AWI) Stewardship Program will begin its work at public boat launches throughout the Adirondacks.\nIn partnership with NYS’s Department of Environmental Conservation, boat stewards will be assisting to CLEAN. DRAIN. DRY boats in the essential work to help protect the state’s waters from aquatic invasive species like hydrilla, water chestnut, and spiny waterflea.\nIn 2019, stewards talked with more than 250,000 water recreationists about aquatic invasive species and what can be done to prevent their spread. They also kept a lookout for invasive species at the waterbodies where they worked.\nPlease respect New York’s stewards. Stewards are the front line and help the state prevent the spread of aquatic invasive species which benefits everyone who enjoys our lakes and rivers.\nBoaters are asked to do their part.\n- Clean, drain, and dry your watercraft and equipment thoroughly before visiting other waterbodies.\n- Inspect and remove debris and mud from boats, trailers, and equipment before and after each use.\n- Dispose of all debris and bait in trash cans or above the waterline on dry land.\n- Drain all water-holding compartments including live wells, bait wells, and bilge areas. If possible, disinfect with hot water (140°F) for at least 30 seconds.\n- Dry boats, trailers, and all equipment before use in another water body. A minimum of 5-7 days in dry, warm conditions is recommended.\n- Do not dispose of unwanted aquarium pets or bait fish in waterbodies, ditches, or canals.\nStewards will follow CDC/DOH guidelines and wear masks and practice social distancing to protect themselves and others. Boaters should arrive with boats and equipment already clean, drained, and dried and be willing to help stewards conduct inspections while maintaining social distance. Visitors should follow protocols for social distancing and wearing masks in public at the launches.\nNew protocol for two Lake George sites\nNew this year, DEC’s Mossy Point and Rogers Rock Boat Launches will be gated overnight.\nThe gates at the Mossy Point and Rogers Rock Boat Launches on Lake George will be closed overnight this boating season as part of the Lake George Park Commission’s (LGPC) Boat Inspection Program (https://lgpc.ny.gov/lake-\nAn LGPC Vessel Inspection Team will be present at Mossy Point Boat Launch from 6 am to 8 pm to inspect boats, trailers, and equipment for the presence of aquatic invasive species and to educate boaters of the importance of Clean, Drain, and Dry. The gate to the boat launch site will be closed and locked when the team leaves at night and reopened in the morning when the team returns.\nA callbox is located next to the door of the Lake George Park Commission shed at each of the boat launches. Boaters who do not get off the water until after the gate is closed can use the callbox. Calls will go directly to the DEC Emergency Dispatch. A DEC Dispatcher will provide the caller with instructions for opening the gate. The callboxes were provided by the Fund for Lake George.\nLGPC’s Vessel Inspection Team will be present from 5 am to 9 pm at the Mossy Point Boat Launch as the days lengthen in June. Overnight closure of the gate at the Rogers Rock Boat Launch will begin when the campground opens and Vessel Inspection Teams will start at 8 a.m.\nFor all the sites statewide, signs will reinforce social distance messaging specific to boating (https://parks.ny.gov/recreation/boating/).\nTo find locations of free boat inspections and decontamination stations around you, and to find more information in general, please visit: https://www.adkwatershed.org/stewardship/boat-wash-stations"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:8dd446e0-5f1f-43dc-b9ae-61d8d7cf9703>","<urn:uuid:ce64bb48-23f2-4754-bf8a-12225eb47d37>"],"error":null}
{"question":"What are the diagnostic procedures used at pediatric clinics for bladder issues compared to the follow-up tests for childhood cancer survivors?","answer":"The HAWK Center uses several diagnostic tools for bladder issues, including uroflow tests, kidney/bladder ultrasounds, video urodynamic studies, and voiding cystourethrogram (VCUG). For cancer survivors, the Treatment After Cancer & Late Effects Center conducts case-specific diagnostic tests focusing on various systems including heart, blood vessels, lungs, liver, kidneys, and bones. Both centers emphasize comprehensive evaluations, though they focus on different aspects - HAWK on urological function and the cancer center on multiple organ systems that may be affected by previous cancer treatments.","context":["HAWK Clinic (Help Awaiting Wet Kids)\nThe HAWK (Help Awaiting Wet Kids) Center at Georgia Pediatric Urology provides specialized care for children with wetting issues and other forms of abnormal urination (voiding dysfunction). Symptoms of abnormal urination or dysfunctional voiding include:\n- Daytime wetting\n- Urinary tract infection\n- Urinary frequency or infrequency\n- Nocturnal enuresis (bed wetting)\n- Constipation (soiling)\n- Posturing to avoid voiding (squatting or dancing)\n- Urinary urgency\nVoiding dysfunction can cause a great deal of anxiety for patients and parents. These children are often excluded from social events such as sleep-overs and summer camps. At Georgia Pediatric Urology, we are committed to providing the best care for your child’s health, lifestyle and well-being.\nThe HAWK Center in Atlanta is devoted to pediatric bladder and pelvic floor muscle dysfunction. Because every child’s situation is different, an individual treatment plan will be recommended and may include a rehabilitation program.\nTo make an appointment, call 404-252-5206.\nHow Are the Emotional Problems that Accompany Bed Wetting and Voiding Dysfunction Handled at the HAWK Center?\nHAWK stands for Help Awaiting Wet Kids. Dysfunctional voiding is not usually caused by emotional factors, but it can take an emotional toll on children and their families. The psychologist assists families in finding ways to integrate the treatment plan into their daily lives so that a successful outcome is likely.\nWhy Do Children Wet?\nThere are many reasons why children wet. Many do not want to stop fun activities to go to the bathroom. Some children urinate only two or three times a day. They simply are too busy to go to the bathroom until it is too late and then they cannot make it to a toilet in time. Other children have uncontrolled bladder contractions that make them feel like they need to go to the bathroom “right now!”\nStill, other children do not fully empty their bladder when they do go to the bathroom, putting them at risk for urinary tract infections. Children who wet only at night wet for completely different reasons. Children do not generally wet out of laziness, emotional problems or inappropriate toilet training.\nSorting out why your child wets, and developing a plan to make the wetting stop, is the goal of the nurse practitioner.\nWhat Will Happen at my Child’s First Appointment?\nA physician or nurse practitioner (a nurse with an advanced degree) will take a thorough history and provide a physical examination of your child. In addition, we will want to know how often your child goes to the bathroom, how often he or she has accidents, and whether your child has a history of urinary tract infections. We will conduct a physical examination of the abdomen, spine and genitals. Contact us at 404-252-5206 to make an appointment at any of our HAWK Center locations.\nWhat Diagnostic Tools Will Be Utilized and What Tests Will Be Performed?\nWe may recommend one or more of the following tests:\nYour child will void into a special uroflow chair that measures the urine flow rate and the time needed to empty the bladder. After that, we will check for any urine left in the bladder with a special ultrasound called a bladder scan. Your child needs to come to the appointment with a full bladder to get accurate results.\nUltrasound of the Kidneys and Bladder\nThis painless procedure assesses the size and shape of the kidneys and looks for bladder abnormalities.\nVideo Urodynamic Study\nThis study is recommended when a more thorough bladder evaluation is deemed necessary. A special catheter is placed into the bladder to measure the pressure while the bladder is filled with fluid. A soft catheter is also placed in the rectum to measure the abdominal pressure on the bladder. We apply sticky electrodes on your child’s bottom to measure their sphincter (hold-on muscle) activity. Periodic x-rays are obtained throughout the study so we can look for bladder abnormalities. Once the child’s bladder is full and he or she can no longer hold urine in, the child will void into a special uroflow chair to evaluate the urine flow rate and the time needed to empty the bladder.\nVoiding CystoUrethroGram (VCUG)\nWe may recommend this study if your child had a urinary tract infection and a fever. A catheter is inserted into the bladder and filled with fluid that can be seen by x-ray. This study can determine if there is vesicoureteral reflux, a condition where urine backs up toward the kidney. Reflux may persist in the presence of dysfunctional voiding patterns and may cause a bladder infection to wash back up into the kidney. Reflux can cause kidney infections (pyelonephritis), which can lead to permanent damage to the kidneys.\nWhat Form of Treatment Will my Child Receive?\nBased on the results of your child’s evaluation, we may suggest:\nChanges in Voiding/Stooling Habits\nWe commonly recommend that children start stool softeners in order to treat any underlying constipation. We will also request that parents help children structure their schedule so that they are making attempts to void and stool regularly throughout the day.\nIncreasing Fluid Intake\nFrequently, we find that children are not drinking enough water throughout the day. In an effort to control the wetting, families sometimes discourage the consumption of fluids. However, it is important that your child be taught to drink water throughout the day. We will explain to your child why drinking water is important and make recommendations as to how much water your child should drink each day.\nBiofeedback training is a way to teach your child to relax the pelvic floor muscles so that the bladder can fully empty. Small sticker electrodes are attached to the child’s abdomen and buttocks, and the electrodes are connected to a computer. Our nurses will teach your child to perform Kegel exercises while viewing a computer monitor that shows the child’s muscle activity.\nThe initial training session takes about 90 minutes and each session after that is 45 to 60 minutes. Initially, we may recommend that you bring your child back every 2 to 4 weeks. As your child learns the techniques and improves voiding habits, we may recommend sessions further apart. Most children require a minimum of 3 biofeedback sessions with a maximum of 6 sessions.\nWe use medications most frequently to treat frequent urinary tract infections, for children with overactive bladder, and for children with nighttime wetting.\nHow Do I Make an Appointment?\nOur friendly and efficient office staff will help you find what you need and provide pediatric outpatient appointments at our main campus in Atlanta as well as our satellite offices in Marietta, Alpharetta, Riverdale, Johns Creek, Lawrenceville, Decatur. Contact us at 404-252-5206 to make an appointment at any of our pediatric Atlanta area locations.","Treatment After Cancer & Late Effects Center\nPediatric cancer survivors in New Orleans\nIn the past 40 years, medicine has made major advancements in the fight against pediatric cancer. A child diagnosed with cancer in 1970 had only a 10 percent chance of survival, whereas children diagnosed today have a nearly 80 percent chance. But for the more than 40,000 children who undergo treatment each year, their struggle does not end when their disease is eradicated.\nThree out of five who survive pediatric cancer suffer late-developing side effects as a result of their disease, its treatment, or both, which may include long-term medical, psychosocial and/or neurocognitive problems. To help the growing number of children in the Gulf South who are beating cancer yet facing potential treatment-related problems, Children's Hospital opened a Treatment After Cancer and Late Effects Center.\nEligibility: Patients who are at least two years from completion of therapy for cancer or five years from diagnosis. Families can self-refer if they were not treated at Children’s Hospital New Orleans.\nConditions we treat\nThe center offers a comprehensive follow-up program to help childhood cancer survivors stay well. Through case-specific diagnostic tests and evaluations, Children's Hospital healthcare professionals are able to help patient families identify, understand, prevent and treat many of the maladies cancer survivors endure, including:\n- Heart problems, including an increased risk of heart arrhythmias\n- Blood vessel problems, including an increased risk of stroke or clots\n- Lung problems, which can cause difficulty breathing\n- Liver problems\n- Kidney problems\n- Dental problems\n- Glandular problems such as thyroid problems\n- Bone problems, such as bone thinning (osteoporosis) and joint pain\n- Short stature, caused by slow bone growth or growth hormone deficiency\n- Reproductive health problems and infertility\n- Memory problems and learning disabilities\n- Psychological problems\n- Vision loss\n- Hearing loss\n- Increased risk of other types of cancers\n- Chronic pain\nWhat services does the treatment after cancer & late effects center provide?\n- Thorough review of your medical record with a multi-disciplinary team\n- Development of an individualized Survivor Care Plan - a \"roadmap\" or guide with past treatment information and late effects related to treatment\n- Comprehensive health history and physical exam\n- A \"Survivor Handbook\" - information on physical, emotional and daily living issues specific to cancer survivors\n- Coordination between oncology and primary care physicians and specialists\n- Assistance with social, emotional and daily living issues\n- Navigation to national, community and online resources\nHow does my oncologist relate to the treatment after cancer & late effects center?\nThe Treatment After Cancer & Late Effects Center does not replace the relationship with your primary oncologist. You will be seen annually and can still follow-up with your oncologist for other cancer related issues.\nWhat will happen on your first visit?\nOur most important goal is to help survivors have a healthy and productive life. At the visit:\n- Our pediatric oncologist, who specializes in caring for childhood cancer survivors, will meet you and perform a complete physical exam and diagnostic tests.\n- Your individualized treatment summary and potential long term side effects will be explained and discussed with you.\n- The Center will guide patients in ways to prevent future problems. This treatment center is ONLY dedicated to cancer survivors. We will answer questions and discuss any needs related to your cancer or its treatment."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:4e8a41a0-fb40-4618-af20-db02a2b0bfa1>","<urn:uuid:32055a13-5e46-4a43-83d5-fae4dbf92262>"],"error":null}
{"question":"Please compare the roles and compensation coverage of medical professionals versus family caregivers in end-of-life care. How are their responsibilities different? 医疗专业人员和家庭护理人员在临终关怀中的角色有何不同？","answer":"Medical professionals in hospice care (including nurses, social workers, physicians, chaplains, and hospice aides) provide specialized palliative and supportive services, which are typically covered by Medicare Part A and most insurance plans. Their services include pain management, medical equipment provision, and professional care coordination. In contrast, family caregivers, while lacking professional expertise, provide direct care and pain management at home, often making personal sacrifices. Family caregivers can experience satisfaction from providing care but are at risk for depression and health problems due to caregiver stress. While they don't receive direct compensation, they can benefit from social support and psychological interventions to help them cope with their caregiving duties.","context":["If a loved one can be dying, discussions about the conclusion of existence can be uncomfortable and difficult. Nonetheless, discussing end-of-life care is very important.\nDepending on the conditions, you might be able to help the one you love make essential end-of-life decisions — just like whether to keep at home, go on to a medical home or other service, or look for hospice care. Also, you may work with the loved one’s health care staff to make sure your loved one remains comfy at the end of life. Discomfort, anxiety and other end-of-life symptoms can often be cured.\nEven at the conclusion of your life, you can carry on and support and nurture the relationship along with your loved one. Simply being there can be an important way to obtain strength and comfort for everybody. Grief When a loved one dead, grief can easily feel like a dagger inside your heart. Frequently , grief causes raw, intense emotions. You may wonder how you’ll ever pick up the pieces and heal the wounds — yet not really feel as if you’re betraying your loved one’s memory.\nThere are no speedy fixes pertaining to the tremendous grief and anguish that follow a loved one’s death. Because you face your grief, admit the pain and know that it’s area of the healing process. Conserve of your self, and search for support coming from friends and loved ones. Even though your life are never quite similar, the searing pain of grief will certainly eventually turn into less strong. Accepting your “normal” may help you reconcile your losses and move on with your life.\nHospice Care Also referred to as: End-of-life care Hospice treatment is end-of-life care provided by health professionals and volunteers. They provide medical, psychological and religious support. The aim of the treatment is to help people who will be dying include peace, enjoyment dignity.\nThe caregivers make an effort to control pain and other symptoms so a person might remain since alert and comfortable as possible. The hospice programs offer services to compliment a patient’s family. Usually, a the hospice patient is definitely expected to live 6 months or less.\nThe hospice care may take place Family often produce sacrifices to care for family. Families present care, pain management, and protect the patient. Although they may lack expertise, caregivers gain satisfaction and pride by providing attention, but are also at risk pertaining to depression and health problems relevant to caregiver tension (Haley & Bailey, 99: Haley ain al., 2001; Weitzner, Haley, & Chen, 2000). A few cultures may possibly believe qualified is the community’s duty and obligation. Caregivers benefit from social support, maintaining social activities and roles, and psychological interventions that teach coping skills.\nMost people want their family to be offered choices regarding treatment and few needed the medical professional to decide alone (Bradley, 1998). End of life: Taking care of a declining loved one Whether you provide a declining loved one residence or keep vigil with the hospital, you can earn measures to supply comfort and relief at the end of life. Looking after a perishing loved one isn’t easy. Even if you know the end of life is approaching, you might not feel prepared. Understanding what to anticipate — and what you can do to enhance your adored one’s convenience — may help. * Choosing where to perish Your loved one may have different choices for end-of-life care.\nChoices may include: 5. Home proper care. Many persons choose to perish at home or in the home of any family member. You are able to assume the role of caregiver or hire house care services for support.\nHospice attention — providers that support ensure the very best quality of life for no matter what time is still — can be provided at your home as well. 5. Inpatient treatment. Some people may well prefer round-the-clock care in a nursing home, clinic or devoted inpatient the hospice facility.\nHospice and palliative care — a holistic treatment approach intended to ease symptoms, relieve pain, and treat spiritual and psychological concerns — could be provided in any of these environments. When you talk about the options with your loved one, consider his or her tastes as well as special physical, emotional and psychosocial needs. Assess how much support can be offered by family members and friends.\nPertaining to help deciding the best option, talk to your liked one’s medical team or a social worker. You might look for a affiliate to palliative or hospice care professionnals — health care providers trained in specific care for people nearing the finish of existence. * Spirituality at the end of life Otherwise you loved one techniques the end of life, she or he may speak about spirituality or the meaning of life. Don’t force the niche — but if it comes up, encourage your spouse to explore and address his or her feelings.\nYou could ask the one you love open-ended queries about her or his beliefs and experiences or most important moments. You might want to invite a spiritual innovator to visit your beloved as well. 5. Saying goodbye You can support your loved one talk his or her final wishes for family and good friends. Encourage your spouse to share their feelings, including thanks or perhaps forgiveness, and present others the opportunity to say goodbye. This might stimulate discussion about significant, unsaid thoughts, which can be significant for everyone.\nYour spouse might also believe it is comforting to leave a legacy — such as creating a recording regarding his or her life or producing letters to loved ones, especially concerning important future events. * Realizing when fatality is near It’s challenging to predict precisely when someone will die. As loss of life approaches, however , your loved one might show various signs and symptoms demonstrating the fact that the end of life is close to. Look for: 5. Restlessness and agitation.\nYour loved one may usually change positions. * Withdrawal. Your loved one may well no longer desire to engage in social occasions or additional favorite activities. * Sleepiness. Your loved one may well spend the majority of his or her time asleep. * Loss of urge for food. Your loved one might eat and drink below usual. 5. Pauses or perhaps other within breathing.\nThis could happen once your loved one is usually asleep or awake. Featuring comfort The active phase of perishing usually commences several days before death. Although you can’t change what’s occurring to your beloved, you can support him or her think as comfortable as possible — ideally with all the support of palliative or perhaps hospice proper care specialists. Your beloved also may knowledge a brief, last surge of one’s.\nThough it is usually confusing to see your loved one with renewed vigor, remember that this can be a normal component to dying. If it happens, use the opportunity to get pleasure from your loved one and say your final goodbyes. * Keeping vigil For a lot of families, keeping vigil near a declining loved one’s bed is actually a way to demonstrate support and love. If you opt to keep vigil, continue discussing with your loved one. If you believe your loved one would want to share now with other folks, invite members of the family or close friends to show all their support too.\nExpress the love, nevertheless also let your loved one know that it’s perfectly to let proceed. What is working? Mental wellness providers with palliative knowledge can increase communication and resources.\nMental health experts help providers understand the patient’s worries and tradition. They explain confusing medical terms and clarify CPR, pain administration, and other treatment options and motivate collaboration. Mental health providers also support relieve the most popular emotional distress and tremendous grief resulting from a terminal disease or treatment giving. * Coping With Loss The loss of a loved one is life’s most stress filled event and may cause a key emotional catastrophe.\nAfter the fatality of someone you like, you experience bereavement, which literally means “to end up being deprived by death. ” Remember — It takes time to fully absorb the impact of any major loss. You never stop missing your loved one, nevertheless the pain assists in easing after as well as allows you to go on with your life. 5. Knowing What to Expect When a loss of life takes place, you could experience a wide range of emotions, even though the fatality is anticipated.\nMany people report sense an initial stage of numbness after initial learning of a death, yet there is no genuine order to the grieving method. Some thoughts you may experience include: These feelings are normal and common reactions to damage. You may not be equipped for the power and duration of your emotions or how swiftly your moods may alter. You may even start to doubt the soundness of your mental health.\nNevertheless be assured that these kinds of feelings will be healthy and appropriate and definitely will help you fully understand your reduction. * Mourning A Loved One It is not easy to cope after having a loved one dead. You will mourn and cry. Mourning is the natural procedure you go right through to accept a major loss.\nMourning may include religious traditions honoring the dead or gathering with friends and family to share your reduction. Mourning can be personal and may last several weeks or years. Grieving may be the outward phrase of your loss. Your tremendous grief is likely to be stated physically, psychologically, and psychologically. For instance, crying and moping is a physical expression, although depression is a psychological manifestation.\nIt is very important to permit yourself to express these emotions. Often , fatality is a subject that is averted, ignored or denied. Initially it may seem helpful to separate yourself from the pain, but you cannot avoid grieving forever. Sooner or later those thoughts will need to be resolved or they might cause physical or emotional illness. Many people survey physical symptoms that accompany grief.\nStomach discomfort, loss of cravings, intestinal upsets, sleep disturbances and loss of energy are typical common symptoms of acute tremendous grief. Of all life’s stresses, mourning can critically test your organic defense devices. Existing ailments may worsen or new conditions may well develop.\nDeep emotional reactions may happen. These reactions include anxiety attacks, chronic exhaustion, depression and thoughts of suicide. An obsession with all the deceased is also a common a reaction to death.\n5. Dealing with a Key Loss The death of your loved one is usually difficult. Your reactions are influenced by circumstances of a death, particularly when it is abrupt or unintended. Your reactions are also influenced by your relationship with the individual who died.\nA child’s death arouses an overwhelming sense of injustice — for shed potential, unfulfilled dreams and senseless struggling. Parents may well feel in charge of the child’s death, regardless of irrational which may seem. Father and mother may also believe that they have dropped a vital part of their own identity. A spouse’s fatality is very upsetting. In addition to the extreme emotional impact, the death may cause a potential financial crisis in case the spouse was your family’s primary income source.\nThe death might need major cultural adjustments requiring the surviving spouse to parent by itself, adjust to one life and perhaps even go back to work. Seniors may be specifically vulnerable after they lose a spouse as it means burning off a lifetime of shared activities. At this time, emotions of solitude may be compounded by the loss of life of buddies. A damage due to suicide can be one of the most difficult loss to bear. They might leave the survivors using a tremendous burden of guilt, anger and shame.\nSurvivors can even feel responsible for the fatality. Seeking therapies during the first weeks after the suicide is particularly useful and advisable. Living with Tremendous grief Coping with fatality is vital to your mental well being.\nIt is only natural to experience grief each time a loved one dead. The best thing you can do is allow yourself to grieve. There are many strategies to cope efficiently with your discomfort. * Search for caring people.\nFind family and good friends who can appreciate your feelings of loss. Become a member of support groups with others whom are suffering from similar failures. * Share your feelings. Notify others how you are sense; it will help one to work through the grieving process. * Manage your health. Preserve regular contact with your family medical doctor and be sure to eat well and get plenty of relax.\nBe aware of the risk of designing a dependence on medication or alcohol to deal with the grief. 2. Accept that life is pertaining to the living. It takes hard work to begin to have again in the present and not place the past. 5. Postpone key life alterations. Try to hold off on producing any significant changes, just like moving, remarrying, changing careers or having another child.\nYou should offer yourself time to adjust to the loss. 5. Be patient. Usually it takes months or perhaps years to absorb a major reduction and agree to your improved life.\n5. Seek outside the house help when necessary. If your sadness seems like it really is too much to bear, seek specialist assistance to help work through your grief. It’s a sign of strength, certainly not weakness, to find help.Get your custom Essay","What is hospice?\n- Hospice is a coordinated program of palliative and supportive care with the focus on comfort care rather than curative care for those individuals diagnosed with a terminal illness.\nWhat is palliative care?\n- Palliative care is relief of pain: the treatment and relief of mental and physical pain without curing the causes, especially in patients suffering from a terminal illness.\nWhat does “terminally ill” mean?\n- A medical prognosis of approximately six months or less if the disease runs its natural course. Common examples of terminal illnesses are:\n- End-stage Cardiopulmonary Conditions\n- End-stage Heart Disease\n- End-stage Lung Disease\n- End-stage Liver Disease\n- End-stage Renal Disease\n- Cancer (All Types)\n- Neurological Conditions\n- ALS (Lou Gehrig’s Disease)\n- End-stage HIV/AIDS\n- End-stage Dementia\n- End-stage Alzheimer’s Disease\n- Other Disorders/Diagnoses\nHow is hospice care paid for?\n- Medicare Part A\n- Most commercial and private insurance companies\nWe view each situation as unique and will review the benefit plan with you individually in order to maximize your hospice benefit and insurance coverage.\nWhat is covered under the hospice program?\n- Staff services including nurses, social workers, physicians, chaplains, hospice aides, volunteers, etc.\n- Medications related to the hospice diagnosis as well as comfort medications\n- Durable Medical Equipment (DME) such as wheelchairs, walkers and oxygen, as they pertain to terminal illness\n- Medical supplies such as catheters and bandages, as they pertain to terminal illness\n- Many additional services including bereavement and counseling services\nWill I have to change doctors?\n- We believe that a continued relationship with your primary care physician is important; therefore, the patient or family member may choose to continue their physician relationship or have one of our specialized hospice physicians oversee your care.\nHow long can I remain on hospice?\n- The hospice benefit will continue to cover palliative and comfort care for an individual with a terminal illness for an initial 90-day period, a subsequent 90-day period, and indefinite subsequent 60-day periods as determined by the hospice medical director, and as long as you continue to meet the requirements of the hospice benefit.\nWill I have to stop all of my medications?\n- Our hospice views each case individually. We will work with your physician and pharmacy to determine which medications we will cover under the Medicare Hospice Benefit, which ones will be covered under your Part D plan, and which medications are determined to be no longer medically necessary and if continued, would become the financial responsibility of the patient.\nHow will hospice manage my pain?\n- Our hospice team works with the patient and family to determine the needs for pain management. Each situation is individualized, with the goal being to provide the most effective pain relief.\nDo I have to stay home all the time?\n- You do not have to be homebound to receive hospice services. We encourage our patients to enjoy life as much as possible.\nDoes hospice provide sitters?\n- The hospice benefit does not include sitters. The hospice may provide volunteers to stay with you for short periods of time if appropriate. Our hospice can provide you with a variety of resources listing sitter agencies who may be of service to you. The sitters are not employees of the hospice agency and therefore are not the responsibility of the hospice agency.\nIf I live in a nursing home, can I receive hospice care?\n- Yes, our hospice provides hospice care where ever you live. This includes home, independent living facilities, assisted living facilities and nursing homes.\nIs it necessary that I have a DNR (Do Not Resuscitate) Order to receive hospice?\n- It is not necessary to have a DNR; however, our hospice will work with the patient and family to obtain a LaPOST, a living will, power of attorney and/or DNR, as necessary.\nWhen is it time to get hospice?\n- It is time for hospice when all measures to cure the patient of the terminal illness have been exhausted and when the physician declares the patient has a prognosis of six months or less, if the disease runs its natural course. You can call us and get more information at any time. Click here to CONTACT US.\nHow do I get hospice?\n- Your doctor may make the referral or you can request that someone from our hospice meet with you to give you information about the hospice benefit. Once an initial meeting is established, our hospice representative may contact your physician regarding your needs and request an approval for hospice services."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:a3a00f85-414d-4731-98f4-c457340f77dc>","<urn:uuid:b23f1eb5-d1be-40bd-bc40-ae5807ae7718>"],"error":null}
{"question":"Which requires more strategic planning - implementing HVO fuel storage systems or developing Australia's national security strategy?","answer":"Developing Australia's national security strategy requires significantly more complex strategic planning. While HVO storage mainly requires following standard oil storage regulations and installing appropriate containment systems based on specific capacity requirements, Australia's national security strategy demands comprehensive analysis of multiple threats (military, social, economic), consideration of force structure, procurement decisions, and logistical preparations including fuel security. The security strategy must account for changing global power dynamics, multiple potential adversaries, and various combat scenarios, making it far more strategically complex than HVO storage implementation.","context":["Over the next 10 years, Australia will dedicate $200 billion to rearmament. We are not only buying new hardware such as the F-35 Joint Strike Fighter, we are also investing in defence industry, with the goal of developing our sovereign capabilities. These are much-needed steps in the right direction, but more needs to be done to shore up Australia’s defence in a changing world. Above all else, we need to develop a national security strategy.\nAustralia has had one previous attempt at putting a national security strategy in place under the Gillard government in 2013. Although it was a decent first attempt, it is has already been overtaken by events. Terrorism was the principal security challenge it focused on, and although the threat of terrorism has not disappeared, other changes in the world are demanding our focus.\nThe world has changed dramatically in the six years since the release of the last national security strategy. Of primary concern is the decline of American power. At the end of the Cold War, the US planned for the contingency of fighting, and winning, ‘two and a half wars’ simultaneously. This meant it could wage two large scale regional wars and a small scale conflict elsewhere and prevail in all of them.\nToday, after pouring blood and treasure into drawn-out Middle Eastern wars and budget sequestration under President Obama, they are not even confident that they can prevail in one large war. They are starting to rebuild their capabilities, but doing so will take time.\nAnd while American strength has been declining, their rivals are growing stronger and more assertive. Their officials speak of challenges from ‘four nations and an ideology’ – China, Russia, Iran, North Korea, and radical Islam. Since 2013, we have seen no abatement in Islamist terror, while Iran and North Korea have continued to work on their nuclear capabilities.\nRussia has grabbed the Crimea and fought a low-level conflict in the Eastern Ukraine, while its other neighbours watch anxiously. Closer to home, China has established artificial islands in the South China Sea, escalated its threatening behaviour towards Taiwan, and invested heavily in missile strike capabilities and a blue water navy. Recently, in a major address in January 2019, President Xi Jinping declared that China’s military must “prepare for a comprehensive military struggle”.\nThe relative decline of American power has huge implications for Australia. Since World War II we have relied on the US as the ‘centre pole’ of our defence strategy. Our approach has been to assist the Americans around the world, in the expectation that if a threat to our security were to arise they would come to our aid. The changes in our strategic environment mean that Australia cannot afford to keep doing this.\nWe need to take more responsibility for our own defence, while maintaining our close relationship with the US.\nDeveloping a national security strategy would be an important step towards improving Australia’s ability to defend itself. We need to start with a sober assessment of the likely threats and scenarios the country could face in the future. At the moment, there is only limited consensus about what the principal future threats to Australia are.\nThey might not only be military threats, but also social or economic. We need to determine, in a realistic manner, what they are. Only then can we consider the requirements of the ADF and other arms of government with security functions. Without a national security strategy, and the clarity it would bring, we cannot know whether we are focusing on the right goals as we expand the ADF and the defence industry sector.\nThe uncertainty that comes from a lack of a national security strategy has major flow-on effects. One is that there is little agreement in relation to the best approaches to force structure and procurement.\nWe lack consistent assumptions about who we are likely to fight, where we are likely to fight, and when we will need to fight. As a consequence, we argue about what we need to buy and produce in order to win a fight. As an example of what I am talking about, I am often asked by the media whether 12 submarines is the right number for the RAN. The answer, of course, depends on what you need to do with them.\nThe ongoing debate around Australia’s future submarine fleet is symptomatic of the bigger problem. Defence discussion and debate often focuses on equipment without any reference to strategy. But without knowing what we need to use the equipment for, and the scenarios they would likely be deployed in, we cannot know whether we are buying the right equipment, and in sufficient quantities.\nA national security strategy would provide a basis for answering important questions related to force size and structure. A national security strategy would also force us to consider important matters that go beyond hardware. I am thinking particularly of the logistical chains essential to maintaining operations in a time of crisis.\nSince entering the Parliament I have invested a lot of time bringing attention to Australia’s fuel security; our lack of domestic reserves and refining capacity. But fuel is only one part of the equation. What use is it having 72 marvellous F-35s at Williamtown if we lack the essential fuel, missiles, spare parts, ammunition and other necessities to support their operations?\nWe have managed to get away with not having a national security strategy only because we have lived in a tranquil region since 1945. But our strategic environment is changing quickly, and we need to prepare for a turbulent future.\nDeveloping a national security strategy would be a vital first step towards building the capacity we need to face the potential challenges that are coming.\nJim Molan is a senator for NSW. He retired as a Major General from the Australian Army in 2008.","Tuffa Tanks are a leading storage tank manufacturer. With have over 30 years’ experience manufacturing tanks and boast a huge product range including steel and plastic tanks designed for fuels, AdBlue®, chemicals and water.\nOur guide to HVO fuel tanks has been made to educate fleet operators, those using electricity generators, oil-heated homeowners and anyone with an interest in reducing their carbon footprint. Topics discussed include the benefits of HVO, regulations, storage options and more.\nWhat is HVO?\nHydrotreated Vegetable Oil (HVO) is a sustainable, low-carbon biofuel that derives from waste products. The fossil-free fuel is currently available as a drop-in alternative to mineral diesel (DERV & gas oil), however, it will likely become commercially available as a replacement for kerosene to help decarbonise off-grid properties.\nHow is HVO made?\nHydrotreated vegetable oil is produced by treating oils with hydrogen. This involves adding hydrogen to oil’s molecules and removing esters and contaminants from the fuel. The process makes a paraffinic fuel that is almost chemically identical to mineral diesel or kerosene but with many additional advantages over the fossil fuels.\nWhat can HVO be made from?\nHVO can be made from a mixture of vegetable oils and animals fats. HVO from reputable suppliers does not contain virgin palm oil and has been certified by the ISCC (International Sustainability and Carbon Certification) as a sustainable fuel. Waste products that HVO can be made from include:\n• Animal waste:\no Fat from food industry waste\no Fish fat from fish processing waste\no Tallow – a rendered form of beef or mutton fat\n• Vegetable waste:\no Residues from vegetable oil processing\no Used cooking oil\no Technical corn oil\no Tall oil pitch palm oil\no Palm oil mill effluent (POME)\nWhat is the difference between HVO, diesel and FAME?\nMineral diesel is a fossil fuel made from refined crude oil. FAME is a first generation biofuel made from fresh organic matter. HVO is a second generation biofuel which is derived from sustainable waste products and emits up to 90% less CO2 emissions than mineral diesel. While the chemical composition of all three fuels is very similar, certain properties of HVO makes it cleaner, safer and improves the storage life. For example, HVO has higher cetane levels which means the fuel ignites\nfaster and more completely giving the engine higher performance and producing fewer emissions.\nCheck out the table below to compare the properties of HVO with diesel and FAME:\nWhat is a first generation biofuel?\nFirst generation biofuels are produced from fresh organic matter such as rapeseed and cereals. Effectively, first generation biofuels use land to grow crops that could otherwise be consumed. Additionally, first generation biodiesel is made up of fatty acid methyl esters (FAME) so is also more susceptible to oxidisation and diesel bug.\nWhat is a second generation biofuel?\nHVO is a second generation biofuel as it is produced from 100% waste products such as used cooking oils and animal fats. As HVO derives from waste products it is considered 100% sustainable and renewable. With no FAME or sulphur content HVO is a more stable than first generation biofuels which are susceptible to oxidation and diesel bug.\nWhat is a third generation biofuel?\nThere is currently greater research into and production of third-generation biofuels comprising of microalgae. If commercially viable, this could be particularly beneficial to carbon targets as microalgae can ‘absorb’ more carbon than trees. This process then creates more algae which can be converted into fuel suitable for industries including aviation.\nWhat are the benefits of HVO?\nThere are many benefits of HVO when compared to mineral diesel, kerosene or even first generation biofuels. The advantages of fueling your machinery with HVO doesn’t just stop at making a smaller carbon footprint or improving corporate social responsibility, there are tangible benefits to your business and equipment too. The advantages of HVO include:\nA reduction in greenhouse gas emissions and harmful byproducts\nWhen compared to diesel or kerosene, HVO fuel reduces CO2 emissions by almost 90%. HVO usage also reduces nitrogen oxide (NOx) emissions by up to 27% and particulate matter (PM) emissions by up to 84%. This not only reduces greenhouse gas emissions but contributes to overall cleaner air.\nHVO fuel is 100% renewable and has been certified by the International Sustainability and Carbon Certification (ISCC) as sustainable. It is also a second-generation biofuel which means that it derives entirely from waste products that would likely otherwise go to landfill. It should also be noted that the production of HVO from reputable suppliers does not contain any products which contribute to deforestation.\nPure hydrotreated vegetable oil is odourless, non-toxic and biodegradable. Therefore, leaks and spills of HVO have a considerably less detrimental impact to the environment than diesel or kerosene. The flash point of HVO is also higher than mineral diesel which decreases the risk of a fire hazard.\nLong storage life\nHVO fuel is perfect for long-term fuel storage and can be stored for up to 10 years which makes it ideal for applications where long-term storage is required such as backup generators. As the hydrogenation process removes oxygen from the fuel, there is a significantly reduced risk of degradation or oxidation. HVO does not absorb water like first generation biofuels so does not provide an environment where diesel bug can thrive. This also removes the need for regular fuel testing and maintenance programs to remove water.\nCold weather performance\nHVO has a considerably lower freeze point (-40°C) than diesel (-8°C). While this isn’t often a concern in the UK, it is one reason why HVO is so suitable for the decarbonisation of the aviation industry.\nFor most applications HVO is completely interchangeable with diesel and can completely replace diesel or be blended with diesel in any ratio. Many Original Engine Manufacturers (OEMs) including popular passenger car manufacturers, freight vehicle manufacturers and non-road vehicle manufacturers have approved the use of HVO fuel in their vehicle’s engines. If your vehicle has an OEM that has approved the fuel then there is no risk of voiding the warranty.\nUsing HVO for heating with existing oil-fired boilers will likely require only minor modifications to the boiler. Trials have shown the process is quick and relatively inexpensive at around £500.\nBetter for machinery\nHVO’s clean-burning properties significantly reduced particulate production (up to 84%) which helps to improve the engine cleanliness, prolong the lifetime of emission control systems (where fitted) and decrease the ageing of engine oils. Additionally, as HVO does not react with water or oxygen, storage of the fuel avoids sludge build-up and diesel bug so prevents filters from blocking and contaminants entering your equipment.\nWhich manufacturers have approved HVO in their vehicles?\nDue to the chemical composition of HVO being near identical to diesel, HVO works as a direct diesel replacement or blend in the vast majority of vehicles. Many Original Equipment Manufacturers (OEMs) have tested HVO in their vehicles and have approved HVO as a valid fuel. This means HVO100 can be used in the vehicle without invalidating the warranty. Here is a list of OEMs who have approved HVO in their vehicles:\nVehicle manufacturers who have approved HVO\nHeavy duty road vehicles\nWhile not all OEMs have approved HVO100 in their vehicles it should be noted that some blends of HVO meet EN590 fuel specification (the same as diesel) and can be used without requiring OEM approval.\nTo check whether your model of vehicle has been approved to use HVO100 please check your handbook or contact the manufacturer. To check whether a HVO diesel blend meets EN590 check with your fuel supplier.\nCan HVO be used as a heating oil?\nThe short answer is yes. After a year of successful trials converting domestic and commercial oil-fired boilers to burn HVO, a second phase of trials is underway to test the logistics of making it available to the mass market. Like HVO biodiesel, HVO heating oil (the same fuel but different application) reduces greenhouse gas emissions by nearly 90%. While not yet commercially available, HVO heating oil has been recognised in the UK’s Heat and Buildings Strategy (2021) as a route to decarbonise off-grid homes. Many boiler manufacturers such as Worcester Bosch and Grant have developed HVO\ncompatible boilers in anticipation of the biofuel’s use in UK heating. HVO used for heating has numerous financial and practical benefits particularly when compared to heat pumps. The cost to adapt an existing boiler to burn HVO is around £500. Comparatively, a heat pump installation can cost around £11,000 or £25,000 if retrofitting work is required to make the property’s insulation sufficient for the heat pumps low heat output.\nFor more information about the benefits, legislation and availability of HVO for heating check out our article The route to off-grid heating.\nWhat are the HVO storage regulations?\nIn the UK there are no regulations specifically for HVO biodiesel. Although HVO is safer than mineral diesel or kerosene (as a non-toxic and biodegradable fuel) it follows the same regulations as regular oils. Everyone in the UK storing oil (including diesel, biodiesel, kerosene and blends) in a container with a capacity of over 200 litres must follow oil storage regulations.\nOil storage regulations specify that oil storage tanks above a certain capacity (depending upon the industry and country) must have a secondary containment system with the capacity to store a minimum of 110% of the primary tank’s contents. This is to capture any leaks from the primary tank and prevent oil from contaminating waterways and the environment.\nAdditionally, you will require a secondary containment if the tank is sited in a location where oil spills could reach public water sources, including:\no Where oil spills could run over hard ground and reach coastal waters, inland fresh waters or a drinking water source.\no Where oil spills could run into an open drain or a loose manhole cover.\no Where the tank vent pipes cannot be seen when the tank’s being filled, for example, because the delivery tanker is parked too far away.\no Within 10 metres of coastal waters or inland fresh waters like lakes or streams.\no Within 50 metres of a drinking water source, for example, wells, boreholes or springs.\no In the inner zone of groundwater source protection zone 1\nDo I need a bunded HVO tank?\nUse the below table to identify whether you need a bunded HVO fuel tank.\nWe always recommend buying a bunded tank or constructing a secondary containment for good environmental practice. Not only is it safer for the environment, but many insurance companies will not cover you for spills and leaks if the tank does not have an integral bund or external secondary containment.\nWhat types of HVO fuel tanks are available?\nJust like our standard diesel tank, HVO fuel tanks are available in plastic and steel, as a storage only tank or with dispensing, and in capacities from 900L to 100000L. Unlike diesel, HVO is not currently available at UK fuel stations so it must be stored in private bulk tanks.\nHVO dispensing tanks\nHVO dispensing tanks are forecourt-style fuel dispensers that contain all the equipment needed to store, measure and dispense HVO or HVO and diesel blends. These self-contained dispensers are integrally fitted with all the required dispensing equipment so all that is required is a solid concrete base and an electrical connection. However, we do manufacture plastic tanks with 12/24V pumps charged directly from your vehicle, so even mains electricity isn’t necessary.\nOur HVO dispensing tanks are all bunded, compliant with UK regulations and are available in capacities from 1,350 to 100,000 litres as standard. Optional extras are also available to adapt the tank to individual site requirements. These include hose reels, higher flow rates, flowmeters and fuel\nHVO storage tank\nHVO storage tanks are a simple bunded tank available with a top or bottom outlet or with a bespoke layout if required. Our range of standard HVO fuel tanks come in capacities from 900 to 100,000 litres and are manufactured in plastic and steel. This is a cost-effective solution where integral dispensing isn’t required, for example for oil-fired heating, electricity generators or sites with existing external pumps. HVO storage tanks are ideal when used as a backup power supply with a UPS (Uninterruptible Supply System) such as the one in our case study Test, Trace & Tuffa: Providing emergency power for NHS Lighthouse Lab. This is because HVO has a longer storage lifespan than diesel (up to 10 years) and does not require regular fuel maintenance to remove water or sludge.\nCurrently around 100 homes and businesses around the UK are trialing HVO as a drop-in alternative to kerosene. We can confirm that our range of heating oil storage tanks are compatible with HVO and HVO blends.\nAt a time when HVO becomes commercially available as an alternative to kerosene for heating, our range of HVO storage tanks will be ideal for the safe and cost-effective storage of HVO heating oil.\nSteel HVO fuel tanks\nSteel HVO fuel tanks are very strong and hard-wearing with a long design lifespan of at least 30 years. These solid constructions provide more protection from fuel theft and impacts than plastic tanks. As they are hand fabricated (rather than using moulds) they are adaptable and can reach a high capacity.\nHowever, the cost of the material and additional skilled labour required makes steel storage tanks more expensive than plastic. Also, while the design lifespan is longer than plastic tanks, steel tanks do require regular maintenance to prevent rust and keep them in optimum condition. For a full comparison of steel and plastic tanks, read our article Steel Vs Plastic Tanks – Virtues and Pitfalls.\nTuffa’s steel HVO fuel tanks are available in capacities from 900 litres as storage only or from 5,000 to 100,000 litres with dispensing equipment. As standard, our steel HVO dispensing tanks are fitted with a high-security cabinet with a roller shutter door (walk-in from 20,000 litres) which houses premium ancillary equipment including a C2020 contents gauge with bund alarm, K33 mechanical flowmeter and 10 micron water and particulate filtration. Optional extras include a high-flow rate, hose reel, and a fuel management system.\nPlastic HVO fuel tanks\nOur plastic HVO fuel tanks are bunded and rotomoulded using a durable, UV stabilized and corrosion-resistant polyethylene which makes a strong and safe single unit. These are available in capacities from 1,350 to 15,000 litres as a single tank or 30,000 litres using interlinking. Our plastic HVO storage tanks are designed to be simple to install and maintain with robust and easily replaceable ancillary equipment. Plastic HVO tanks are more cost-effective than steel but have a shorter design lifespan of 20 years and are an easier target for fuel theft.\nOur plastic tanks come with a high-spec as standard including a high polymer shot weight (which creates a thicker tank wall) and premium ancillary equipment including flowmeter, 10-micron water and particulate filter and FMS gauge and bund alarm all housed within a lockable lid or cabinet. While the rotomoulding process creates a fixed tank size and shape, we do offer a variety of options to adapt the tank to the site’s individual requirements. These include a 12V/24V dispensing, a pulse meter, high flow rate pumps and fuel management.\nWhat maintenance does my HVO tank require?\nFuel tank maintenance is usually the responsibility of the homeowner in domestic properties or the business owner in commercial premises. By conducting regular inspections and maintenance you can prolong the lifespan of the tank and reduce the chances and damage caused by a leak. While visual inspections can be conducted by homeowners or untrained staff, servicing and maintenance should be conducted by a Competent Person.\nChecking your oil tank\nIt’s recommended that you check your HVO tank on a monthly basis and after any episodes of extreme weather. Some of the visible signs you should look for on the tank include:\n• The fill point arrangement for soundness and leaks\n• Any outlet valves should be checked for leaks and operation (open and close successfully)\n• The testing of contents gauge, any high level / overfill alarm and bund alarm.\n• If vents can be seen that they are clear and unblocked and free of debris.\n• A visual inspection around the tank with emphasis on the base of the tank. The inspection for plastic tanks should include any deformation of the surface of the tank such as:\no Excessive bulging\no Change in colour due to chemical attack\no Crazing or stress fractures.\n• The inspection of steel tanks should include looking for evidence of:\no Rust and heavy corrosion\no Damp patches on seams & seam fractures.\n• The bund to be visually inspected for soundness and integrity, water, spilt product, or other\nIf your HVO tank is connected to an oil-fired boiler then we recommend that you use a competent technician to maintain your tank every year – this can be done at the same time your boiler is serviced. Your technician should check the tank, bund and pipework and remove any condensation water. Upon completion, you should receive a written report on the state of the tank and any work done. This service can be performed by members of Oil Firing Technical Association (OFTEC) or the Association of Plumbing & Heating Contractors (APHC).\nOne way we have worked to reduce the costs of oil tank maintenance is by supplying all of our bottom outlet fuel tanks with an Ultra Compact Isolation Valve. As the valve provides safe isolation as the very first component it can save technicians hours on jobs such as replacing the filter valve. With basic valves usually supplied with oil tanks this would require draining and refilling the tank."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:9f334725-ceff-4389-bd08-2a1577f5db9a>","<urn:uuid:377f2fcf-678a-401a-bb0f-69e65ff812e5>"],"error":null}
{"question":"What makes English unsuitable as a 'lingua franca' in social sciences compared to natural sciences?","answer":"English cannot function as a 'lingua franca' in social sciences because of fundamental differences in knowledge construction. While natural sciences use third-person, present-tense narrative forms that remove the scientist from the discourse, social science texts cannot remove the narrator. Social science writing requires a mediator (using 'I' or 'we') and involves complex translation issues beyond mere word equivalence. Additionally, social science concepts are tied to specific intellectual traditions and political contexts that cannot be simply translated without losing their meaning.","context":["by Renato Ortiz, State University of Campinas, Brazil\nEnglish is the official language of globalization. I say ‘officially’ because the presence of other languages is constitutive of our contemporary condition, even though one language, above others, takes a privileged position. In the global market of linguistic goods English becomes the language of global modernity. What are the implications for the social sciences?\nI would like to avoid two positions commonly encountered in intellectual debates. On the one hand, there is the view that the predominance of English is an artifact of imperialism. I do not believe that imperialism is a useful concept for the understanding of contemporary globalization. On the other hand, there is the view that national identity makes one’s own language authentic as against others that are fake. As Saussure teaches us, the arbitrariness of sign is tied to the context of territory and history – no language is superior to others, they only capture the real in distinct manners.\nA banal statement in contemporary debates is that English is a ‘lingua franca’ in the scientific community. But what is a ‘lingua franca’? A language emptied of its multiple connotations with the intention of maximizing communication among scientists. This is partly possible in the natural sciences, but English cannot function as a ‘lingua franca’ in the social sciences. It is not as a question of national pride, but by virtue of the process of knowledge construction. The sociological object is constructed through language. Using this or that language is not accidental, but a decisive dimension of final result. Thus, there are differences in the practice of the natural and social sciences. Let me cite just a few examples. The natural science text, not only has a specific order of presentation, it uses a particular narrative form. It is written in the third person and generally the present tense. For example, biologists write: “the radiation doses delineate three strips…” or “the mutation distinctly presents itself centripetally…” The verb tense is the present and the utilization of the third person confers on the discourse an objectivity based on the absence of the scientist. Texts in the social sciences cannot remove the narrator, which is why C. Wright Mills described social science as an intellectual craft. The narrator could be an ‘I’ or a ‘we’, but certainly writing is not limited to the third person. Whether we use ‘I’ or ‘we’, in narrative discourse there is always a mediator. There is also the problem of translation, which is not limited to words, that is to the search for equivalent terms in two distinct languages. In the process of translation different intellectual traditions must be taken into consideration. The term ‘national question’ cannot be reduced to nationalism. The ‘national question’ implies a specific political context in which a specifically Latin American intellectual debate takes place – a context that involves the problematic of national identity, the construction of modernity, the critique of importing foreign ideas, the inferiority complex of colonized countries, and the dilemmas of peripheral modernity. It refers us to an entire bibliographic and artistic tradition – from Mexican muralists to Brazilian modernism. The ‘national question’ is a shorthand expression connected to the history of Latin American countries in search of their identities. This is not the same as nationalism.\nHowever, despite these obstacles, the domination of English in the Social Sciences continues. There is a consolidation of certain scientific styles, global in scale, that favor the English language. This is the case, for example, in the use of databases whose production is conditioned by various factors, such as technical factors, costs, and market distribution. Organizing texts and citations requires a linguistic register which is minimized or hidden when one partakes in the pretention that such databases offer a reliable portrait of the scientific world. The Institute for Science Information (ISI) produces four different types of catalogues, each of which is marked by linguistic distortion. Between 1980 and 1996 in the Social Science Citation Index database, English language publications count for between 85% and 96% of all articles. If we accept the idea that a citation is a requirement for scientific authority, this signifies a clear hierarchy (grounded in nothing) based on linguistic exclusion. The choice of English in the production of databases, as in the publication of scientific reports and books, is a question of markets. The big corporations (Reed Elsevier, Wolters Kluwer) dominate the world market in English due to the ease of circulation of texts. In this way arbitrary linguistic criteria become the basis of the global legitimacy of ‘science making’ (or ‘doing science’). This arbitrariness has been reinforced by the advent of digital technology (texts in PDF, bibliographic indices) and an unequal distribution of translation on an international scale. In the U.S.A. and the U.K., translated foreign texts (including all genres) do not exceed 5% of the total published texts. While in countries such as Sweden and the Netherlands, this figure is approximately 25%, in Greece it is 40%. In other words, the more central a language the fewer are the texts translated into that language. After all, nothing of relevance could exist outside of it.\nIf, in the social sciences, English cannot function as a ‘lingua franca’, what is the meaning of its predominance? My impression is that English, by virtue of its ubiquity, acquires the capacity to ‘guide’ intellectual debate on a global scale. To ‘guide’ means to select those issues that will become relevant and visible from a much wider range of possible issues. Phrased another way, the English language has the power to shape the intellectual agenda. There are still other implications. Eugene Garfield, founder of ISI, said that in the 1970s the weakness of the French sciences was due to one fact: they were becoming provincial because they are written in French. This line of argument considers the universal to be an attribute of English, while provincialism defines all other languages. Global English becomes universal English. It is forgotten, however, that cosmopolitanism is not an attribute of the globalization process, and while particularism appears as dialect in the local it also appears as a defining feature of contemporary globalization. Under the condition of global modernity, then, it is perfectly plausible and commonplace, to be globally provincial."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:b3213900-860a-45fd-8e0a-f8a43f25b23a>"],"error":null}
{"question":"How do the accommodation options compare between the Summer Camp wildlife program and the Nike Tennis Camp at USD?","answer":"The Summer Camp wildlife program offers authentic teepees that sleep 12 campers each, with separate teepees for boys and girls, plus bunk houses available for wet weather. In contrast, the Nike Tennis Camp at USD provides modern college dorm rooms with air conditioning and shared bathrooms, with 2 campers per room.","context":["Summer Camp offers children ages 8-16 the opportunity to become immersed in wildlife and nature while enjoying all the fun activities offered by ordinary summer camps. Camp sessions last for five days and four nights, but can be attended as a day camp if desired. Campers get to sleep in authentic teepees and participate in hayrides, hiking, swimming, horseback riding, white-water tubing, team-building obstacle courses and much more. *Bunk House provided for wetter weather. Other Activities: •\nIndian Heritage (Songs, Dances, Stories, History)\nSurvival Hike (Learn to live in the wild and about different native plants)\nCub Camp Ages 8-9 Live in a real teepee and learn about the wildlife that surrounds us. Learn about the Native Indian History of the area. Go on creek hikes and river swims, fish in native streams, and learn Indian skills and much more. Jr. 1 & Jr. 2 Camp Ages 10-12 Live in a real teepee and learn about the wildlife that surrounds us. Learn about the Native Indian History of the area. Now as an older more experienced camper you will have an experience of a lifetime as you get to learn to work and play with the animals, go on creek hikes and river swims, fish in the native streams, learn Indian skills and meet real Indians. Also you will get to learn many pioneer living skills such as basket weaving, candle making, and gold pan in a real stream or slush box finding real gold. Tween Camp Ages 12-13 An awesome summer camp just for our almost teens. Having all the fun of teen camp but getting the best of both camps at a younger age. You will get to stay in an authentic teepee village learning the culture and skills of our Native American brothers. If you choose an extra activity you might even tube / raft down one of our north Georgia Mountain Rivers or go horseback riding over a mountain trail. And don't forget about the animals, learning to care play with and release some cool critters. Family Camp (All ages w/Adult)\nThe coolest family camp ever imagined as you get to experience a little touch of all our camp programs. Spending time with America’s most endangered mammal, the Eastern Panther, and many other animals that live in our north Georgia Mountains. Learning things from veterinarians and vet-techs about wildlife that you never dreamed of. Many of our daytime activities such as our Native American program, Pioneer living skills, Rain forest program, and Channel 9's Ben Roy and the Science Theater will be doing dynamic programs throughout the camp. Don’t forget about horseback riding down a mountain trail, or cooling off tubing / rafting down a mountain river. Last but not least is our theme, Independence Day banquet with special prize for best-dressed couple, bring own outfit, we supply the fun. Then end each evening with one of our super FUNTASTIC campfire theme programs including our July 4th Independence Day American Spectacular, complete with music & fireworks, It's FUNTASTIC! Families will stay in real T.P.s, 2 families’ per T.P. sleeps 12 or so depending on size of campers. T.P. will be divided in half with curtain. Note- a family may pay an extra $75.00 if you want whole T.P. to self. Families may bring their own tents if you prefer. You will be assigned one of our 6 man tent camping areas. Please send sleeping preference on separate sheet of paper with application & explain. Only spaces for 12 families so sign up early!!! Teen Camp 1 & 2 Ages 13-16 Teen camps like never before offered. This special camp will have a Native American theme, complete with a pow-wow each Wednesday night, and a live Native American concert. Indian crafts and classes such as Indian jewelry, blowguns, drums, and wild edible plants to mention a few. Of course there’s always the animals to enjoy and work with. Teen camps allow sign up for horseback riding and white water tubing / rafting. See camp activity choice with fee. Last but not least is our Native American theme banquet with special prize for best-dressed couple, bring own outfit, we supply the fun. Registration Registration is at 9:00 a.m. on Mondays. Please, no request for early registration. Our staff is involved in many duties until the announced registration time. It is important that your camper does arrive on time, due to the time it takes to register and get settled and get assigned to their classes and lodges. Checkout time is Fridays at 3:00 p.m. sharp. Our staff will be preparing camp for the next week of camp, so we must request timely pickup of campers.\nCalculations 6 teepees 3 for boys | 3 for girls 12 campers each teepee (72 campers) | 12 counselors 4 Office Staff 4 General Maintenance\n$250.00 per child 5 days, 4 nights. meals, crafts, activities included, camp shirt. Gross per week -18,000 7 weeks-126,000 Expenses: Meals X3 per day Activities Supplies Shirts Cost to run facility Staff Pay- $700 a month ($8,400)-Counselors Visitors (Indian guides, science instructors, wildlife expert, survival guide) Facilities: Restroom- Staff Men | Women Restroom-Campers Boys | Girls *Showers Kitchen | Mess Hall Office Maintenance Building Outdoor Auditorium Teepees Bunk Houses","Nike Tennis and Language Camps, University of San Diego\nImprove your game and have serious fun\nat Nike Tennis Camps\n\"Come work hard, improve your game and make new friends. We focus on sportsmanship, individual improvement and having tons of fun both on and off the court.\" - Coach Bill Scott\nThe Nike Tennis camp held at the University of San Diego provides an ideal environment to learn from some of the best collegiate coaches and players in the country, play with peers from all over the world and improve your English! The USD Nike Tennis Camp boasts superior tennis facilities, weather, food and location! The camp directors: Bill and Shelly Scott, and Sherri Stephens, (Head womans' coach at USD,) have 70+ combined years of directing tennis camps. Our Nike Tennis camps ensure a positive tennis experience for all who attend. ELS classes can be added to your Nike Tennis Program for additional English practice and learning. These classes are held at the Francis Parker School and are not affiliated with the University of San Diego.\n- Campers come from around the world to enjoy the great facilities, coaching and weather!\n- 4-5 hours of on-court tennis instruction and match play daily\n- 2-50 minute ELS Language classes - Monday-Thursday (Held at Francis Parker School)\n- Experience campus and university life and create lasting friendships\n- Secure, comfortable on-campus accommodations,\n- Delicious meals offered at campus cafeteria offer a variety of cuisines and healthy options\n- Every camper receives a Nike Tennis Camp T-shirt\n- Round trip airport transfers included\n- Low camper to staff ratio, 6:1\n- View More Details ⟩\nVolunteer Assistant Director Bill Scott\nBill is well known in Southern California as the former Director of Tennis at The Bishop’s School in La Jolla and is currently the Director of Tennis at Santa Catalina School in Monterey.View Bill Scott's Bio ⟩\nOver the years Bill has coached more than 1400 High School tennis matches while over 9500 juniors have attended his tennis camps. Bill was recently inducted into the San Diego Hall of Champions Coaching Legends and is a former men’s 35 singles national champion.\nHead Director Sherri Stephens\nGoing into her 34th season, Sherri has been the Head Women’s Tennis Coach at USD since 1984 and has since transitioned her teams into a national NCAA Division I contending program. She owns a 367-346-2 (.513) career record. Sherri grew up in Arizona where she was a nationally ranked junior player before competing at the University of Arizona.View Sherri Stephens's Bio ⟩\nSherri Stephens recently wrapped up her 34th season at USD. She owns a 367-346-2 (.513) career record.\nIn 2012, Stephens led the Toreros to their first ever WCC championship with a 4-2 win over Pepperdine and garnering her second consecutive WCC Coach of the Year honor. Stephens' squad made their 11th overall trip to the NCAA Tournament in 2011-12 and second in a row. In 2010-11, Stephens helped lead the Toreros to a 19-6 record, the highest win total in her tenure at the University of San Diego, and winning her second-career West Coast Conference Coach of the Year honor. Stephens guided the Toreros to their first NCAA appearance since 1999, defeating UNLV in the first round by a score of 4-2 before falling to host UCLA 4-0 in the second round. The second round finish matched the best NCAA finish in USD history and the fifth time Stephens has led the Toreros to the second round.\nUnder Stephens' guidance the Toreros came in second in the WCC Championships behind Pepperdine in 2011 and placed all six regulars on the All-WCC singles and doubles teams. The Toreros also posted their best team winning percentage in 2011 with a .760 mark under Stephens, while also setting a new team record with a 14-1 record at Hogan Tennis Center and tying the team record with nine dual match shutouts on the year. Stephens helped guide USD to a team-record 11-consecutive dual match victories and their highest ranking (23rd) since the 1994 season. The Toreros also spent five straight weeks in the Campbell/ITA Top-25 after opening the season with a No. 67 ranking.\nIn 2010, Stephens notched her 300th career win en route to a 13-12 dual record, a final ITA ranking of #65, and a third place finish at the WCC Championships. Also in 2010, former Torero great, Zuzana Lesenarova, the 1999 NCAA Division I Singles Champion and four-time ITA All-American, was inducted into the WCC Hall of Honor.\nStephens arrived at USD in the fall of 1984 and immediately began to reshape the women's tennis fortunes. During her time coaching the Toreros, she has advanced her team to the NCAA Tournament 11 times (1989, 1990, 1991, 1992, 1995, 1996, 1997, 1998, 1999, 2011 and 2012). The Toreros have finished among the nation's top-25 in eight seasons, with a high of #14 in 1989, (18-8 overall record), which was USD's first team to advance to the NCAA's. Stephens has also had five Toreros receive a total of twelve NCAA All-American honors: Tonya Fuller (1991), Laura Richards (1992, 1993), Julie McKeon (1992, 1993, 1994), most recently Zuzana Lesenarova (1997, 1998, 1999, 2000), and Katarina Valkyova (1999, 2000).\nWith Coach Stephen's leadership, the Toreros have gained respect as a national contender and she has turned the women's tennis program into one of the most respected programs in the nation. Coach Stephens has had two especially memorable seasons with the Toreros. In 1999-2000, Zuzana Lesenarova advanced to the third round of the singles tournament, eventually losing to Stanford's Laura Granville in three sets (6-0, 4-6, 6-3). Katarina Valkyova lost in the first round to Cincinnati's Kara Molony in three sets (6-0, 3-6, 6-3). The Lesenarova/ Valkyova duo entered the NCAA doubles tournament ranked No. 1 in the nation, but had to withdraw due to injury. Both Lesenarova and Valkyova earned NCAA All-American honors in 2000.\nIn the 1998-1999 season, her squad finished 14-11 overall, advancing to the 2nd round of the NCAA's and finishing with a national ranking of No. 28. Lesenarova won the 1999 NCAA Singles Championship, holding her No. 1 ranking all spring and winning three of four ITA Grand Slam events. Valkyova was a third alternate at the NCAA's and she advanced to the quarters where she was dealt a three-set loss by Lesenarova. The duo teamed up in doubles play to advance to the NCAA semifinal round. Lesenarova and Valkyova were named 1999 NCAA All-Americans.\nWell-respected among her peers in the coaching profession, Stephens has been a featured speaker at several ITA Coaches' Conventions. Twice she has had the privilege of coaching at the Olympic Sports Festival (1993/South, 1995/West), with her 1995 squad winning the gold medal. She was named the 1994 Female Coach of the Year by the USTA, Southern California Section/San Diego District. Sherri has been involved with numerous administrative positions within collegiate tennis such as: the NCAA Ranking Committee, the NCAA Rules Committee, and as Tournament Chairman for the All-American National Championships the past five years. She also runs summer camps every year.\nStephens is a native of Phoenix, Arizona, and was a nationally ranked player on the junior circuit before enrolling at the University of Arizona. After completing her collegiate playing career in 1979, she began her coaching career as an assistant for the Arizona Wildcats.\nAll Inclusive Tuition\nThe prices listed below include all Nike Tennis Training, ELS English Language instruction and materials, on-campus housing, 3 meals a day, round trip airport transfers, weekend stayover(s), and predetermined activities.\nNike Tennis Camp Philosophy\nPlay the sport you love and get better this summer with our excellent Nike Tennis Camp staff of collegiate athletes and veteran coaches. On the first day campers are evaluated on the courts and placed into smaller groups based on their age and ability. Featuring up to 20 hours of tennis instruction and play per week - includes a combination of drills, match play, strategy sessions, along with a flighted tournament each week. This tennis camp is perfect for the developing or accomplished player. 6:1 camper to coach ratio.\nELS Language Classes\nGain confidence in your conversational English skills. Classes focus on communication skills with their new friends at camp and on the courts. All levels welcome. Campers are evaluated at the first class and grouped according to skill. Beginner, Intermediate, and Advanced level groups. Eight, 50-minute lessons are provided each week, Monday – Thursday (see detailed sample schedule under More Details.) ELS classes are held on the campus of Francis Parker, across the street from USD. Students are walked over to this location by staff.Show Less See More Camp Details\nCheck In & Check Out\nCampers should plan to arrive on the start day of camp (Sunday) and depart on the last day of camp (Friday). Campers may schedule an early arrival or late departure for an additional fee of $125/night.\nRegistering Online or Submit a PDF Application\nUse the links below to choose the session you'd like to attend, or download an application. Email it to email@example.com.\nAccommodation & Roommates\nTypical College Dorm Room. 2 campers to a room. Air conditioning, shared bathroom. American roommate if requested.\nLinens and Laundry\nBed sheets, pillow, and towel provided. Onsite laundry facilities. $2.50/per wash and dry.\nBreakfast, lunch, and dinner are included everyday expect check-in and check-out days. Dietary restrictions can be accommodated if alerted before camp.\nEvening activities planned Monday through Thursday, these activities are included in tuition.\nWeekends & Trips\nTeam competitions, camp tournaments, fun camp activities, movies, beach days, boardwalk day, camp BBQ, dance, and swimming!\nRound-trip airport transfers provided from San Diego International Airport. Provide flight itinerary when registering or at least 3 weeks prior to camp start date.\nUnaccompanied Minor Services\nNike Sports Camps will provide a greeter at the airport if your camper is flying to camp with an unaccompanied minor plane ticket. Typically the airlines require the greeter's details such as name, driver's license number, phone number, and address. Nike Sports Camps will not have this information until the week before your child arrives at camp. Please email firstname.lastname@example.org to collect all information one week before your child comes to camp to avoid any hassle or extra wait time fees at the airline.\nFor an additional $60, add supplemental health coverage. On-site school nursed and trainers available for on-site injuries. You must be medically insured while at camp. If your health insurance will not cover you while in America, you must find alternative coverage whether that is the one US Sports Camps provides or otherwise.\nWi-Fi & Communication\nWi-Fi access in common areas and dorm rooms available to campers. Camp office provides computer access for Skype and Email.\nSuggested $100/week for spending money.\nA detailed camper welcome packet containing health & release forms, emergency contact info, and a packing list will be emailed to all registered campers in Spring 2018. Our health and release forms require a doctor's signature and will be collected on the first day of camp. International campers must have health insurance valid in the US in order to attend camps.\nSample Daily Schedule\n- 7:00 Rise and Shine!\n- 8:00 Breakfast\n- 8:15 Stretching and warm up\n- 8:30-11:20 Nike Tennis Instruction\n- 11:30 Lunch at Student Dining Pavilion\n- 11:45-2:30 ELS Language Instruction\n- 2:45 Return to courts for match play and additional tennis instruction\n- 5:00 Dinner\n- 7:00-9:30 PM Evening Activities\n- 10:00 PM Campers to rooms\nThe University of San Diego is a beautiful campus, which offers incredible views of beautiful San Diego Mission Bay. Campers stay at the USD student residences which are modern, clean and comfortable apartments. The campus provides a safe, secure environment, and resident campers can absorb the college environment, while staying in the college dorms and dining at the Student Life Pavilion. Each student residence has round the-clock-security, access to vending machines and laundry facilities. While on campus, student have access to many other amentities such as:\n- An Olympic sized swimming pool\n- Access to tennis, volleyball and basketball courts\n- Quick bus rides to shopping malls, movie theatres and beaches\n- The USD West Tennis courts\nThe “Skip and Cindy Hogan Tennis Center”, located on the West side of the USD campus, is home to the USD women’s and men’s tennis teams. It is a newly renovated eight-court facility featuring a new tournament desk area; and additional bleacher seating.\nCamp ReviewsSubmit a review\nI want to thank you, for all you did for my son during the weekend in San Diego...Simone was very happy....we are ready to another experience in the next year!\n— Simone M's Mother - Italy0\nCan't Wait Till Next Year!\nThe camp at USD was truly amazing!!!! I can't wait till next year!\n— Parent of Camper0\nWe'll be back!\nLooking forward for our daughter to return next summer for camp. She had an awesome experience and made some new friendships during the whole week. All the counselors seemed knowledgeable about the sport and were very nice to work with. Our daughter had a fantastic experience and it should help with her tournaments since she is interested in getting a college tennis scholarship at a college when she graduates from high school.\n— Parent of Camper0\nBill Scott was great!\nLooking forward to attending camp next year, Coach Bill Scott was very supportive and knowledgeable.\n— Overnight Camper\nCamp Dates & Prices\nDates & Prices Coming Soon!\nPlease join our email list to be notified when this program is available for registration."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:7f89d757-d913-4d92-8c30-60571e48d912>","<urn:uuid:886af12c-a490-49eb-85f9-836e06323842>"],"error":null}
{"question":"How do recovery techniques differ between wilted seedlings and struggling cloned plants? What specific care is recommended for each?","answer":"For wilted seedlings, the recovery process involves moving them out of direct sun, placing container plants with dry soil in water-filled trays, misting the foliage, and providing protection from strong sun and heavy wind while they recover. For struggling clones, the approach is different - they may wilt in the first couple of days but should rebound from the shock naturally. It's crucial not to pull on clones to check for roots as this can damage new root growth. Clones should be kept in high humidity conditions with low light and consistent moisture until they develop strong root systems over 14-21 days.","context":["Jumpstarting propagation by cutting and cloning might sound high-tech, but it’s not. When you were a kid, did you ever watch your mom take cuttings from a neighbor’s rose bush and “root it” for her own garden? Well, she was cloning it! Today we’ll look at how to propagate plants from cuttings: it’s easy and rewarding!\nSo … cloning plants is taking a cutting from an adult female (momma plant) … forcing it to grow roots… and voila! New baby plant with the exact same genetic makeup (including sex) as the original plant.\nWhy wait for seeds to germinate when you can produce 6″ plants in a couple of weeks?\nUsing cuttings and cloning is a very good way to propagate new plants (for free) from an adult plant that has proven to have “good genes”. And this method has been practiced for virtually centuries: it is not futuristic, nor does it require any scientific knowledge or specialized skills.\nThe Proper Climate for Cloning Plants\nThe most successful way to get a new cutting to sprout roots is to keep the upper part of the plant (the leaves) at the lowest metabolic rate possible. This encourages growth below, as the new baby has to “go and look for food” (by sprouting roots).\nSo how do you create this “root-friendly” atmosphere? By providing weak food, low light, warm temperatures, and high humidity.\n- If using GH Flora series for cloning, mix a one-gallon jug of water with ¼ teaspoon of each of the three solutions: micro, grow, and bloom.\n- Dimmer and shorter light cycle: low wattage fluorescent light (like a 20-40 watt under-counter lamp), on only 12 hours a day, 2” above the\n- Temperature: 78-80°\n- Humidity: RH 90-100% the first week; then drop to 80-85%\n- Food: use only water or Superthrive ‘til you see the first roots; then switch to ¼ strength nutrient solution.\nSupplies for a good plant cloning program\n- Rooting hormone (Clonex gel is best, or use Olivia’s cloning gel)\n- Optional: Superthrive (use instead of water for the first week or two, then switch to the weak nutrient solution mix)\n- Grow plugs: use 1.5” Rockwool starter cubes\n- Sharp razor blade or utility knife; dip in alcohol to sterilize it\n- Optional but much easier: the perfect atmosphere is most easily achieved with an inexpensive domed nursery flat and warming mat.\n- And the Cadillac Deluxe: Botanicare Power Cloner\nA Perpetual Plant Factory\nTIP: Keep the source plant (Momma) by itself in a bucket bubbler unit for 6-9 months before replacing it with a fresh mother plant. Click here for free bubbler plans.\nYou want to take cuttings only from healthy, mature (over two months old) female plants with “good genes”, which have not yet flowered. (Or if there are buds, strip them off). Don’t use plants that have been treated with pesticides or fungicides.\nMomma plants can be kept strictly as a cloning source, and are kept in a perpetual “growth” stage, and not allowed to flower (by keeping them under MH lights for 18 hours per day).\nThis practice is popular with growers of ornamentals, kitchen, and medicinal herbs.\nHow To Propagate Plants From Cuttings\nFirst, prepare the starter plugs by dipping them in water, and enlarge the hole if necessary with a stick, nail, or utensil about the size of a chopstick.\nChoose a good, fresh, vigorous growing tip for your clone, preferably from the lower branches, and then cut off the stem with your sterile razor, about 3-5” long, with 3-4 sets of leaves.\nNext, trim the lower leaves until there are only 2 sets of leaves left). After that, you will shorten the cutting using the “Sip Of Life” technique.\nThe Sip of Life? Well, when you first take a cutting, a bubble of air can be drawn into the stem, preventing the solution from getting to the plant later (sorta like an “air embolism”). The plant will die if this happens.\nSo how do you prevent air bubbles in the stem? Glad you asked: you are going to make a second cut under water. Place the cut end of the stem in a bowl of warm water, then take your clean razor knife and cut the stem about an inch up from the original cut, at a 45° angle (under water).\nLeave in the water until ready to plant. You want to end up with cuttings about 2-4” long, with only 2 sets of leaves (strip off the rest).\nKeep the cuttings moist\n- Next, take a cutting out of the water bowl, and immediately insert the cut stem into rooting gel, like Clonex for about 15 seconds. Then place the stem 1/2” to 3/4” into the hole of a pre-moistened starter plug or cube.\nImportant tip: do not dip the stem directly into the original bottle of gel. Instead, pour a small amount into a shallow dish. Throw away any excess gel. Do not pour back into the bottle as you will contaminate it with organisms.\n- Set the grow plug upright in your domed nursery, and provide optimum “rooting conditions” as described above. Keep the cubes evenly moist, but not soggy, and be sure to open the little vent holes in the dome for some fresh air.\n- If you can manage it, mist the clones with clean water several times a day: this helps retard leaf metabolism and invigorates root growth. Get a\ncheap mister for a buck at Wal-Mart. (Don’t use one you’ve stored Windex in).\n- After a week or so, remove the dome cover, but keep misting.\n- The clones may actually wilt the first couple of days but should rebound from the shock. Do NOT PULL on the plant to try to determine if\nit is rooting. This will damage the new baby roots.\n- After about 14-21 days, the clones will have grown a few inches and formed small but strong root systems, growing out the sides of the grow plug.\nTime to place the clones, cube and all, into the hydroponic garden.","Can I put seedlings in direct sunlight? Initially place seedlings outdoors in a sheltered spot – protected from wind and direct sun. Each day following, expose plants to another 30-60 minutes of filtered sunlight. By the end of the hardening-off time frame, seedlings should be experiencing the same amount of sunlight they’ll receive in the garden.\nWhen should you expose seedlings to direct sunlight? When they have grown their second or third set of serrated leaves (after the the round cotyledons that initially emerge from the seed) seedlings are usually hardy enough to flourish in direct sunlight. Seedlings can be kept by a sunny window, until they’re ready to grow outside.\nCan seedlings get too much sun? Usually we harden off young plants to the cold, but you should also take care not to burn a seedling that has grown in a greenhouse, never exposed to the sun’s full fury. Even “full sun” plants get sunburn if they are not used to the sunshine. Use plenty of water and compost and “mud” your seedlings in the soil.\nShould you put seedlings in the sun? A sunny windowsill is a good place to put sprouted seedlings. Lightly brushing the seedlings encourages the growth of strong stems. Most seeds will not germinate without sunlight and will perform best with 12 to 16 hours each day.\nCan I put seedlings in direct sunlight? – Related Questions\nCan wilted seedlings be revived?\nMove the wilted plant out of the sun, if possible. Set wilted container plants with dry soil in a sink or tray filled with water. Spray the plant’s foliage with water; misting can help rejuvenate the plant quickly. Provide protection from strong sun and heavy wind while the plant recovers.\nCan seedlings get too much light?\nTo put it bluntly, yes, too much light can eventually kill your plant. The light intensity can produces increasingly severe damage to your plant to the point where it dies. It can also dry out the plant to the point where it no longer has the water it needs for growth and photosynthesis.\nShould I water my seedlings everyday?\nHow much should you water seedlings? The soil seedlings grow in needs to be moist or wet but not too damp, and it should never dry out between waterings. To achieve this, you should check on your seeds more than once per day, and you’ll probably need to water them at least daily.\nHow close should LED grow lights be to seedlings?\nThere is no universal rule for setting the distance but it’s recommended that LEDs are placed 12 to 18 inches away from the plants. Light is among the most vital factors to consider when growing plants because it triggers the photosynthesis process.\nHow close should light be to seedlings?\nDifferent plants have different light intensity needs, but most seedlings grown for the garden will need higher intensity light to flourish. In general, the leaves should be about 2 – 4 inches away from the light source (assuming use of a fluorescent bulb – see below).\nHow do I make my seedlings stronger?\nPut a small fan next to your seedlings on a timer so that the plants are blown in the breeze for a couple of hours a day and gently passing your hand over the tops of seedlings a few times every day to stimulate stronger growth. Some leggy seedlings can be saved with modified transplanting techniques.\nCan I put tomato seedlings in direct sunlight?\nBright light is super-important for healthy tomato seedlings! Seedlings need 12-18 hours of light each day. Do yourself a favor and give it to them. Otherwise they will become leggy and weak very quickly, which will set back production in your garden.\nCan I leave seedlings out overnight?\nStep 3: Leave seedlings outside overnight\nEventually, allow your plants to stay in full sun and outside overnight as long as night temperatures do not drop below freezing. They can’t stand below-freezing temperatures, even after the seedlings are hardened off. So continue to bring indoors if nights remain cool.\nWhat causes seedlings to wilt?\nSeedlings collapsing from the top & experiencing leaf wilting. If the leaves are wilting, they may also be wilting due to a lack of water – monitor your soil to ensure that it is moist at all times, but not water-logged. Overwatering can happen even to experienced growers.\nHow often should you water your seedlings?\nPlants do best when watered about three times a week, factoring in the rain. If the plants are seedlings, water twice a day until established. But don’t just water without thinking. Feel your soil!\nWhat temperature should seedlings be at?\nAlthough the seeds of some plant species require a temperature as low as 50 degrees Fahrenheit to germinate, the optimal temperature for seedlings is between 65 and 75 degrees Fahrenheit, The Old Farmer’s Almanac says.\nShould I mist my seedlings?\nCombat dry air with humidifiers, misting or humidity trays (draining saucers filled with gravel and water). Your leaves will be dry; fungal spores will have less chance to settle on foliage and the stems of your seedlings will be stronger and more supple if they grow in an area with good air circulation.\nHow do you keep seedlings watered when away?\nMoisten a bath towel and use it to line the bottom of a large, clear-plastic bag. Set the seedlings on top of the towel. Blow air into the bag to inflate it, then seal the bag with a rubber band. When seedlings release water from their leaves, the water will reach the top of the bag, then drip back down into the soil.\nHow often should I mist my seedlings?\nHow often to mist air plants? In this case, mist the plants 3 to 7 times a week, depending how dry your home air is and what time of year. Summertime plants need more water while they can sustain on less in winter.\nAre LED lights good for seedlings?\nSummary. You can use LED lights to start your vegetable seeds indoors and you don’t need special plant grow lights to do so for plants that will eventually be planted outside. If you have a lot of fixtures you can rewire them a few at a time while still gaining the benefits of LED bulbs in all your fixtures.\nHow do you use LED grow lights for seedlings?\nThe answer to this one is simple. Your grow lights should be turned on (or your seedlings should be put under lights) as soon as the first seed starts to sprout. Many types of seedlings grow very fast, and they will begin reaching for the light as soon as they emerge. So give them plenty of it right from the start.\nHow do you know if your plant is getting too much light?\nIf your plant is not getting enough light, the most common sign is the yellowing and dropping of leaves, stunted leaf growth, elongated stems, and a dull-green color. If your plant is getting too much light, then its leaves will have singed tips, burned patches, or will be falling off (yikes!).\nHow many watts do I need for seedlings?\nGrowing seedlings is a great way to jump-start your outdoor garden. One of the challenges to indoor growing is making sure your seedlings get the right amount of light they need to thrive. Seedlings need approximately 32 watts per square foot of growing area for LED grow lights and 100 watts per plant for CFLs.\nWhat is the best fertilizer for seedlings?\nLook for a 1-2-1 N-P-K (nitrogen-phosphorus-potassium) ratio on the fertilizer label. A liquid or water-soluble fertilizer is typically the easiest and quickest way for the seedlings to access nutrients. You’ll also have a choice between organic and synthetic fertilizer, which often comes down to personal preference.\nHow long should seedlings be on a heat mat?\nHow Long Do I Leave My Heating Mat On? Once you sow your seeds and place your plant tray onto your seedling mat, keep it on for 24 hours a day; this process will not involve any intermittent on/off operation. Your seeds must be subjected to consistent heating to keep the propagation process going.\nIs it OK to leave seedlings outside?\nYou can start to harden off your seedlings once they’ve grown at least two to three sets of leaves. At that point, they’re mature enough to move outside. About 7 to 10 days before your seedlings are ready to be transplanted, take them outside and leave them in the shade for a few hours in the morning or afternoon."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:18cbe23b-8fd6-42d5-a500-554d6c0985ab>","<urn:uuid:b380d3d6-0790-43ad-9b19-a470f22d5f04>"],"error":null}
{"question":"What limitations exist for resizing Celtic rings, and what are the key technical requirements for proper channel setting of melee diamonds?","answer":"Celtic rings with all-around designs can only be made slightly larger or smaller without distorting the pattern, as significant size changes typically result in pattern distortion. For channel setting melee diamonds, specific technical requirements include: maintaining proper seat angles of 72-78 degrees, ensuring channel walls aren't too close (which would cover more than 15% of the stone) or too far apart (which would cause loosening), achieving even spacing between stones, setting all diamonds at the same height, and having the diamond tables level with the channel wall tops. The process requires careful preparation, including layout planning, precise seat cutting, and gradual metal bending to secure the stones.","context":["People resize rings for many different reasons. For some it is weight loss or weight gain, and for others it is simply to be able to wear the ring on a different finger. Resizing is very common and can be done on most rings, but there are some exceptions. To better understand when sizing can and cannot be done, one must understand the process.\nMaking a Ring Smaller\nDecreasing the band size on a ring is fairly easy when done by a jeweler. For the ring to be made smaller, the jeweler must cut out a small portion of the band. The ring must then be reshaped to the proper circular shape and then it can be soldered back together. The jeweler must make a weld that is virtually invisible, and it must then be polished and smoothed so that no indication of the sizing is visible.\nThis method can easily be used for rings with a plain shank or band. Rings which are ornate or have a design which carries around the complete band will need to be rebuilt over the sizing. There is sometimes an area on ornate rings which has been left for resizing. This area, however, is usually used for making the ring larger instead of smaller.\nSome rings have jewels all around the band or are channel style less than half way around the band, and may require the jeweler to remove the gems before sizing. This depends on the setting and pattern. For rings being made smaller, the diamonds or gems may be moved to balance the setting of the ring.\nMaking a ring larger\nIncreasing the size of a ring can be done two ways. When a ring needs to be made just slightly larger, sometimes a jeweler can stretch the ring to the desired size. The ring needs to be cut and an additional piece of the shank or band soldered in if the size increase is a half size or larger. If a jeweler needs to resize an ornately patterned ring, or one with jewels throughout the band, the sizing can pose a problem. The jeweler will discuss options with you which may include changing the setting.\nRings not to re-size\nYou should not try to re-size a ring which has channel set stones more than half way around the band. If the ring has an elaborate setting or certain types of gems, some of the stones may need to be removed and reset before the ring can be sized. If the ring is an antique or is an older white gold ring, there may be some discoloration around the repair area. It is not always possible for the jeweler to know the cause of the discoloration. Most jewelers will make every effort to minimize lines or discoloration on the ring. Usually it is only noticeable with the use of a magnifying glass. It is imperative that you discuss options with your jeweler.\nCeltic rings with the design all the way around the band can be made slightly larger or smaller without distorting the pattern. Increases or decreases of a significant amount are usually not successful without distortion to the pattern.","Channel setting is the most common setting used to set melee (small\nround brilliant cut) diamonds. Melees can be set in channel in various\nHere, I will discuss about Double Undercut Technique. As its name suggests, in this technique a seat is undercut in the both metal walls of the channel.\nProcess of Setting Melee in Channel\nFollowing are the steps which describes about process of setting melees in channel:\nPreparing layout is essential as it helps in anticipating and avoiding problems. Before setting the diamonds you need to know where diamonds have to be set.\nThere should be a slight gap between each stones in the layout position (table down). This gap will cover up when you turn the diamonds in the set position (table up). During layout procedure you should keep in mind that deeper the diamonds are set into the mounting, they will get closer.\nWhen the diamonds are in layout position, their center line on both sides of the outside of the ring is marked with a sharp tool. After marking, diamonds are removed, cleaned and kept in proper order.\nSeat cutting is a slow, step-by-step process and requires patience. The stones are set into seats individually grooved into the opposite parallel walls (double undercut technique). The seats must be deep enough so that the table of each stone is in same level with the top of the channel walls.\nYou can use a pair of dividers to transfer and mark the guidelines of depth of the diamonds (from the bottom of the girdle to the table) along the inside of the channel walls.\nNow, start cutting the groove at each end of the ring where the diamonds will be finally placed. Remember to check that diamonds fit in the groove you’ve already cut. If diamonds don’t fit comfortably you will need to make some changes using appropriate tools.\nStart placing each diamonds individually, place the first diamond, wax it in place and then start with other diamond.\nIt’s important that diamond fits well into the seat as per its girdle’s thickness. There should not be any gap visible from the top. The junction angle of the crown and pavilion angles with seat should be 72o to 78o. If the seat angles are larger than the diamonds dimensions then the diamond will loosen and may fall.\nNow, work to finally set your diamonds. Tap and bend the channel walls downward on to the diamonds to secure the diamonds in place. Work on the opposite side too and remember to bend only small amount of metal at a time.\nAny hurry at this stage will spoil your work done so far. Slowly repeat this process till grip of channel on all diamonds is tight and diamonds are secure.\nYou need to remove the wax by either steam or ultrasonic cleaning. After removing wax the stones might become loose. So, re-tightening is required.\nBefore moving further, confirm following:\n|Support Bars (top view)||Support Rings (top view)|\n|Area of Stone Covered under Metal Channel Wall|\n|Same Table Height of Set Stones|\nCommon Flaws of Channel Set Melee Diamonds\nWalls too Close or too Far Apart\nIf the opposite channel walls are too close then they will cover up most of the diamonds top view. If more than 15% of the stone’s diameter is covered, diamond will appear smaller and may get damaged while setting. If the opposite walls are too far apart then it will loosen diamonds leading to their fall.\n|Channel Walls too Close||Channel Walls too Far Apart|\nGap between Stones\nIf there is any visible gap between diamond and metal channel walls then it means there is error in workmanship. As this may cause diamond to loosen and fall.\nDiamonds set at Different Height\nIf the diamonds to be set are of different heights then seats in the metal channel walls should be placed accordingly. If the diamonds are set at different height then it’s a faulty craftsmanship.\n|Improper Height of Channel Set Stones|\nImproper Spacing between Diamonds\nThere should be even spacing between each diamonds in row.\nDiamond's Table and Channel Wall at not Same Level\nThe table of diamonds in row set in a ring should be in same level with the top of channel wall."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:d65ef033-2636-43a1-bc38-de00dbb34064>","<urn:uuid:40327806-ceba-4d5c-b1d2-90144715d8d0>"],"error":null}
{"question":"Compare how sea turtles and seals adapt to deep diving - what are their maximum diving depths and special physiological adaptations for deep water survival?","answer":"Sea turtles and seals both have impressive diving capabilities with distinct adaptations. Leatherback sea turtles can reach depths of more than 1000 meters and stay underwater for over 80 minutes. Meanwhile, seals can dive even deeper, with northern bull elephant seals recorded diving below 1500 meters. Both animals have special adaptations for deep diving. Sea turtles, being reptiles, can sleep underwater for several hours. Seals have sophisticated adaptations including collapsible lungs that force air back into the windpipe to prevent nitrogen absorption, 10 times more oxygen-carrying myoglobin than humans in their muscles, and the ability to reduce their heart rate by 10-20% while diving. They also divert blood from less essential organs to vital ones like the brain during dives. Additionally, seals have a special blubber layer that doesn't compress at depth, maintaining their heat retention properties.","context":["Many visitors of the Canary Islands come to admire one of the famous inhabitants of this archipelago: the sea turtles. These are beautiful animals that are the joy of those lucky enough to meet them. Here are 5 facts that will surprise you about them:\n- Sea turtles have lived with the dinosaurs! Scientists have discovered fossil traces attesting their existence more than 200 million years ago!\n- Turtles are reptiles that are adapted to the marine environment. But these animals need to return to the mainland for egg-laying. By orienting themselves with the Earth’s magnetic field, turtles can travel thousands of miles to return to where they were born and lay their eggs in the sand overnight.\n- And since they are reptiles, they also need to breathe air from the surface! But a turtle can stay underwater for a long…long time. They can sleep underwater for several hours without having to reach the surface and they can descend very deep into the water (sometimes more than 1000 meters!)\n- Turtles can live many years: until 40 to 70 years old. Unfortunately, nowadays, their life expectancy is decreasing as they face many dangers due to climate change, pollution, destruction and urbanization of breeding beaches, overfishing, and so on. That’s why these animals are protected by the Canarian government and must be respected by all. But action plans for protection are not always efficient and it is very difficult to ensure the long-term survival of certain species.\n- There are 7 species of marine turtles in the world and the Canary Islands are home to 6 of these species. Here is a short description of each of them:\n- The leatherback sea turtle (Dermochelys coriacea) is the largest of the seven species of marine turtle. It can measure 2 meters and weigh between 450 and 950 kilos. It does not have a large carapace with scales but rather a cartilage and a thick skin that protect its organs. We can recognize it by the lighter lines that go from his head to his tail and its dark blue skin. This animal lives more than 50 years and can stay more than 80 minutes under water and reach more than 1000 meters deep!\n- The hawksbill sea turtle (Eretmochelys imbricata): It is recognized by its thick scales which are also very popular for trade, making it one of the most endangered marine turtles because of poaching. It is smaller than the previous one: it measures between 60 and 100 cm and weighs between 43 and 75 kg. This species can not breed until it reaches 10 years old.\n- The green sea turtle (Chelonia mydas) is a turtle that is often seen in the waters of Tenerife. It is this species that was the star of el Puertito de Armeñime bay but they disappeared from this place last year. This creature weighs between 80 and 130 kg and measures a little over a meter. It is the fastest sea turtle and, contrary to what we can expect, it really means that it can swim very fast: 35 km/h! What sets it apart from other species is that it becomes herbivorous at a certain age. This is why they have a green color. The eggs are as big as a golf ball and the turtle lays them in a single hole but digs a dozen holes on the same beach to lure predators.\n- The loggerhead sea turtle (Caretta caretta) is about 90 cm long and weighs 135 kg and its carapace is heart-shaped. It is one of the most common turtles in the Canary Islands. It can stay 4 hours under water, which is more than the other species. This turtle migrates a lot because it gets into a lethargic state when the water becomes too cold.\n- The Kemp’s ridley sea turtle (Lepidochelys kempii) is highly endangered. It is one of the smallest species of sea turtles (up to 70 cm and 45 kg). These are the only species that spawn during the day.\n- The olive ridley sea turtle (Lepidochelys olivacea) has a very domed and olive-colored shell. It does not have many safe nesting sites, so the species is in danger of extinction. Its presence in the Canary Islands is quite rare.\nSea turtles are remarkable animals full of surprises. When you encounter one, enjoy this special moment with these creatures that are in danger of extinction and remember to protect them by avoiding touching them or pursuing them. Just watching them and admiring their graceful swim is an unforgettable moment.","Spectacular, surprising seals\nAround the world, seals and sea lions represent different things to different people.\nTo marine theme park visitors, they are cute and talented performers able to balance balls and walk on their flippers; to environmentalists, they are defenceless pups slaughtered for their pristine fur; to commercial fishermen they are a threat to fish stocks; and to wild-life enthusiasts they are among the most spectacular creatures to watch at play in the wild.\nThroughout history, seals have played a substantial role in many cultures, providing food, fuel and clothing for indigenous tribes in the Northern Hemisphere’s frozen regions. Because of their expressive faces, these marine mammals have also been the focus of many legends, ranging from the ‘selchie’ stories of north-western Europe (in which seals are believed to be women and children condemned to a life where neither land nor sea provide a permanent home) to the superstitions that it is bad luck to kill a seal because they embody the souls of dead sailors.1\nSeals, sea lions and walruses are grouped together under the name ‘pinnipeds’ (from Latin: ‘wing-footed’ or ‘fin-footed’).\nPinnipeds are divided into three families: the Phocidae, Otariidae and Odobenidae.\nThe Phocidae are known in scientific circles as ‘true seals’. They are fantastic swimmers, using their hind flippers to propel themselves through the water while their small front flippers act as rudders or stabilizers. They lack external ears, hearing through small holes on either side of their head (see How they hear without ears below).\nThe Otariidae are known as ‘eared seals’ because, as the name suggests, they have (small) external ears. They also have long front flippers (measuring up to one-third of their body length), which propel them when swimming, while their hind flippers serve mainly as a rudder for steering. These animals are commonly referred to as sea lions.\nAll members of the Odobenidae family are walruses, and they combine features of both other families: they lack ears, but use both front flippers and hind flippers to move in the water.\nIt’s easy to remember the difference between ‘true seals’ and ‘sea lions’: true seals (no external ears) have small front flippers and can only move awkwardly on land by shuffling their large bodies, while the eared sea lions not only have the larger front flippers on which they can walk, but they are also able to turn their hind flippers forward under their body, thus enabling ‘four-footed’ locomotion. The relative agility of eared seals on land helps to explain why the Californian sea lion is the most commonly used pinniped in marine theme parks.\nBaby sea lions and true seals are called ‘pups’ and baby walruses ‘calves’. For simplicity, we will refer to all pinnipeds as ‘seals’ in this article.\nSeals are most abundant in cold circumpolar seas, where there are 14 species of eared seals (including fur seals) and 19 species of true seals (including harp, leopard, elephant and harbour seals). Exceptions to this include the Hawaiian monk seal, Californian sea lion, and species in the Mediterranean and Galápagos, all found in warmer climates.\nFor most seals, a good meal consists of fish, cuttlefish, octopuses and crustaceans, although several seals are more predatory, with the Australian sea lion and leopard seal feeding largely on penguins.2 The crabeater seal, the most abundant seal in the world, mostly lives on krill, a prawn-like crustacean abundant in polar waters.2\nSeals have a number of amazing design features that make them perfectly suited to their life on both land and sea. Many live and hunt their food in the ocean, but come ashore to rest, mate and bear their young. The harbour seal (a ‘true seal’) can be found sleeping belly-up on top of the water,3 or can even lie asleep on the sea bed for up to an hour. Although eared seals spend less time in the water than ‘true seals’, they too can sleep at sea while ‘sailing’ in the ‘tea cup’ position, i.e. floating belly-up with one front flipper tucked under the other.4\nAt birth, a newborn pup can travel on land and swim, although it takes a few weeks for them to develop enough blubber to keep them floating and insulate them against the cold. During this time, their mother’s milk is low in water content and high in fat, encouraging rapid growth. This also helps the mother in habitats where water conservation is important.5\nThe seal’s body shape not only helps it move efficiently in the water, but also effectively retains heat as the mammals move in and out of often freezing water. Along with whales and dolphins, seals have a circulatory system that allows arteries carrying warm blood to transfer heat to veins carrying cooler blood from the body surface, helping to stop warmth being lost.6\nIn addition to these amazing features, seals have sophisticated methods of insulation involving an outer coat of protective guard hairs, dense water-repelling undercoat, and a special layer of blubber. During their deep diving feats (see Effortless divers in the deep below), this fat layer does not compress, thus maintaining its heat-retaining properties.\nSeals have good sight underwater, even at night, and their eyes are able to adjust quickly to changing light, both when emerging from dark water into bright daylight,7 and when descending to the gloomy depths.8 Sensitive whiskers help the animal locate prey, particularly in those species feeding on the bottom of the ocean.2\nMost people would recognize the sound of a seal ‘barking’. This vocalization may play a role in navigation, social behaviour and foraging. Males may bark to show dominance and defend territory, while females may use the communication to locate their young on returning from feeding in the sea. Seals can also be heard to roar, honk, chirp, bleat, grunt or cough.7\nOne of the most engaging sights in the wild is a large number of seals swimming close together and waving their fore-flippers in the air. This is not, of course, a trick to entertain tourists, but a way for pinnipeds such as fur seals and sea lions to cool down; their insulation is effective in the cold, but can lead to over-heating problems when the temperature rises, and this action provides relief. On land, elephant seals tackle the problem by throwing sand over themselves with their flippers, keeping the sun off their skin.9\nWhile there are many seals in the wild, several types are endangered, such as monk seals (likely named for their preference for solitude or the loose skin around their necks, which resembles the hood of a monk’s robe). The total number of Hawaiian monk seals is estimated at between 1,200 and 1,500, the Mediterranean monk seal is rarely seen, and the Caribbean monk seal, last seen in 1952, is considered extinct.10\nEvolutionists tend to disagree on the ‘natural history’ of seals, sea lions and walruses, but agree that the ‘earliest’ fossil records—supposedly 20 million years old—reveal seals that look very much like those alive today.11 So much so that monk seals are often referred to as ‘living fossils’ because ‘they have remained virtually unchanged for 15 million years’.10\nThe fact that the three families share a number of characteristics creates lively debate among evolutionist scientists. One theory suggests sea lions, fur seals (Otariids) and walruses evolved from a bear-like ancestor on the shores of the Pacific, while the true seals (Phocids) arose ‘more recently’ from an otter-like ancestor around the Atlantic.11There is no fossil evidence to justify that claim,12 or any other theory on the evolution of pinnipeds.\nClaims of ‘convergent’ evolution—that two types of animals could evolve similar adaptations and features separately—are also without evidence, and, in fact, lack credibility, given the highly specialized features all three families possess (for heat retention and diving, as mentioned above).\nThere is no mystery if we accept that these specialized features are not the result of some chance succession of evolutionary flukes, but were perfectly designed by the Creator, who not only created animals perfectly suited to their environment and life, but made creatures that are beautiful to watch and study.\nHow they hear without ears\nHow are earless seals (and dolphins) able to hear? With only pinprick holes for ears, somehow marine mammals collect sounds and conduct them to the middle and inner ears, deep in their heads. Scientists suspected facial fat might be involved, but they couldn’t explain how the fat conducted sound.\nNow sophisticated technology has revealed that bundles of fat in the lower jaws and ear canals conduct sound extraordinarily well. ‘These fats have a shape like an ear trumpet,’ says one researcher, describing seals and dolphins as ‘acoustic fatheads’.1\n- How dolphins hear without ears, New Scientist 164(2218):17, December 25, 1999 / January 1, 2000.\nEffortless divers in the deep\nUsing sonic transmitters, researchers have been astounded to find that some seals are able to dive repeatedly to depths of more than 100 m (330 ft) in search of food. Weddell seals—with recorded deep-water dive times of up to 73 minutes1—are capable of diving to almost 600 m (2,000 ft). A northern bull elephant seal was recorded diving to depths below 1,500 m (4,900 ft), deeper than some whales are known to venture.2 When diving, a muscular reflex not only closes the nostrils, but also the larynx and oesophagus, so seals can open their mouth to catch prey without swallowing water.3\nBefore submerging, seals do not take in a large breath of air. This would create difficulties with buoyancy and could lead to ‘bends’ when they resurface (caused by dissolved nitrogen forming bubbles in the blood). Instead, seals breathe out first, and carry the oxygen they need attached to special pigments in their blood and muscle tissue. Seals have 10 times the amount of oxygen-carrying myoglobin (a protein pigment) than humans in their muscles. Their lungs are designed to collapse under pressure, so what little air there is, is forced back into the windpipe, where nitrogen cannot be absorbed into the blood.3,4 The increasing lung collapse, as the pressure increases with depth, changes the animal’s volume, decreasing its buoyancy. This makes for effortless deep diving, involving little or no expenditure of energy.5\nSeals also reduce their heart rate by 10 to 20% while diving, at the same time diverting blood from parts of the body where it is less needed, such as the liver, to essential organs such as the brain.2\n- Miller, D., Seals & Sea Lions, Voyager Press, Stillwater, MN, USA, p. 36, 1998.\n- Ref. 1, p. 36.\n- Ref. 1, p. 35.\n- New Scientist 166(2233):73, April 8, 2000.\n- Camera catches secrets of the deep divers, New Scientist 166(2234):19, April 15, 2000\nReferences and notes\n- Miller, D., Seals & Sea Lions, Voyager Press, Stillwater, MN, USA, p. 7, 1998. Return to text.\n- The New Encyclopaedia Britannica, 15th Edition, 23:423, 1992. Return to text.\n- Harbor Seal, www.letsfindout.com/subjects/undersea/rfiharse.html May 5, 2000. Return to text.\n- Conversation with Sea World, Gold Coast, Australia, May 5, 2000. Return to text.\n- Ref. 2, p. 424. Return to text.\n- Ref. 1, p. 31. Return to text.\n- Ref. 2, p. 424. Return to text.\n- New Scientist 163(2199):23, July 31, 1999. Return to text.\n- Ref. 1, p. 32. Return to text.\n- Hawaiian Monk Seals, leahi.kcc.hawaii.edu/~et/wlcurric/seals.html February 8, 2000. Return to text.\n- Ref. 1, p. 9. Return to text.\n- Flynn, J.J., Ancestry of sea mammals and Wyss, A.R., Evidence from flipper structure for a single origin of pinnipeds, Nature 334(6181):383–384, 427–428, 1988. Return to text."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:b6ce57f6-a6bd-46ce-8725-5251888ecedd>","<urn:uuid:de0a0ffb-49d4-4c88-8136-6664718eb9c8>"],"error":null}
{"question":"Did Isadora Duncan and Rudolph Valentino share similar views about their public image and artistic expression?","answer":"No, they had contrasting attitudes. Duncan embraced her unique artistic philosophy, refusing to follow rigid rules and freely expressing herself through natural dance movements, even designing flowing costumes that allowed freedom of movement. Meanwhile, Valentino was extremely sensitive about his public image, particularly regarding his masculinity. He strongly resented implications about his femininity, challenged critics who questioned his masculinity (like the Chicago Tribune's \"Pink Powder Puffs\" editorial), and even took boxing lessons to prove his manliness.","context":["Isadora Duncan was a dancer who was born in 1877 or 1878, in San Francisco. What distinguishes Isadora from all her other contemporaries is that her dancing didn’t adhere to a form, to rules, or rigid ballet techniques. She had a completely different and pioneering philosophy towards dance.\nShe perceived dance as a natural movement of the body and a medium for the expression of the human spirit. Isadora was deeply moved and inspired by ancient Greek art, which she combined with her American sense of freedom. She is considered the creator of modern dance.\nDuncan’s parents divorced when she was just an infant, and she lived with her mother and three other siblings in extremely poor conditions. The children, who were all dancers, didn’t have any other choice but to contribute to their household income by giving dancing lessons to the other kids in the neighborhood. Isadora continued with this throughout her teenage years. She loved dancing, and she always improvised and experimented with her moves. She traveled to Chicago and became part of the Augustin Daly’s theater company. From there, Isadora moved to New York City, where, unfortunately, the stage wasn’t ready for her unique movements.\nFeeling disappointed and unappreciated, Isadora left America and moved to London in 1898. In London, she danced in wealthy peoples’ drawing rooms, while she was drawing her inspiration from the Greek art in the British Museum. Her earnings were sufficient for renting a studio where she could create “magic” for the stage. After London, Isadora traveled to Paris, drawing more inspiration from the Louvre.\nIn 1902, Isadora was invited by Loie Fuller to tour with her. They traveled all around Europe and Isadora could perform freely, creating a more innovative technique. She influenced the perception of dance at the time by giving the audience natural movement dance instead of rigid ballet techniques.\nEven though the critics were divided in their opinion, Isadora inspired many artists such as Abraham Walkowitz, Arnold Ronnebeck, Auguste Rodin, and Antoine Bourdelle, who created works based on her.\nUnusual for a stage artist, Isadora wasn’t fond of the commercial aspects of public performance, such as contracts and touring. Her mission was to share the dance and her philosophy of movement, so she opened schools and dedicated herself to teaching young people.\nDuncan opened the first school in Berlin-Grunewald, Germany, in 1904. This was the place where the “Isadorables,” Isadora’s protégées, were educated. This was a group of six girls – Erika, Irma, Gretel, Maria-Theresa, Liesel, and Anna, who continued their teacher’s legacy, while the name “Isadorables” was given to them by the French poet Fernand Divoire.\nIsadora legally adopted all six of them in 1919. She also opened a school in Paris, but it didn’t last long due to the outbreak of WWI.\nAleister Crowley, whom Duncan met in 1910, wrote of her: “Isadora Duncan has this gift of gesture to a very high degree. Let the reader study her dancing, if possible in private than in public, and learn the superb ‘unconsciousness’- which is magical consciousness – with which she suits the action to the melody.” – Aleister Crowley, “Magick: Liber ABA: Book 4: Parts 1-4”.\nHe also refers to Isadora under the name, “Lavinia King” in his “Confessions” and his novel “Moonchild.”\nDuncan’s dancing costumes were also unique and extraordinary, as they allowed her to move freely and gave the impression that her body is extremely comfortable, which is the complete opposite of the corseted ballet costumes. Ancient Greek art always inspired Isadora’s clothes, and her most famous costume was a white Greek tunic she wore while barefoot. In 1911, while at a lavish party organized in a rented mansion, the Pavillon du Butard in La Celle-Saint-Cloud, by the French fashion designer Paul Poiret, Isadora, wearing a Greek evening gown designed by the host, danced barefoot on tables among 300 people and 900 bottles of champagne.\nAs much as she did not respect the rules and laws in dance, she was also less keen to observe morality and traditional mores in her way of life. She was an atheist, communist sympathizer, and bisexual. She had two children born in 1906 and 1910, one of which was with the theater designer Gordon Craig, and the second with Paris Singer. Both her children drowned with their nanny when their runaway car went into the Seine in 1913. It took Isadora years to recover from her children’s deaths and she never actually fully came back to herself.\nIn 1921, Isadora moved to Moscow where she met the 18 years younger poet Sergei Yesenin. They married after a few months, and although Yesenin joined her on tour in the United States and Europe, after less than a year, he returned to Moscow, leaving the marriage.\nHe committed suicide in 1925. Isadora had a brief relationship with the poet and playwright, Mercedes de Acosta. Most of her later life featured her drunkness, debts, and love affairs.\nIn 1927, while driving with friends in Nice, in an Amilcar automobile, she wore a hand-painted, long, and flowing silk scarf, designed by the artist Roman Chatov. It was a present from her friend Mary Desti who was also driving in the car. The vehicle was open-air, and the most bizarre accident happened to Isadora – her silk scarf became entangled around the open-spoked wheels and rear axle while still draped around her neck. It hurled Isadora from the car and broke her neck.\nFollowing this horrific incident, Duncan was brought to the hospital and declared dead and was later cremated, and her ashes were placed next to those of her children, in the columbarium at Père Lachaise Cemetery in Paris, 1927.","With the Roaring Twenties in full swing and the first talkies on the horizon, Hollywood’s booming film industry already had its share of bankable stars—Charlie Chaplin, Greta Garbo, Douglas Fairbanks, Buster Keaton. But in the summer of 1926, an Italian immigrant named Rodolfo Alfonso Rafaello Pierre Filibert Guglielmi di Valentina D’Antonguolla would join them. Known as the “Latin Lover,” Rudolph Valentino would, by summer’s end, single-handedly change the way generations of men and women thought about sex and seduction.\nIt’s sad Valentino never live to see that autumn. And it’s sadder that he spent his final weeks engaged in an indecorous feud with an anonymous editorialist who had questioned his masculinity and blamed him for America’s “degeneration into effeminacy.”\nBorn in Castellaneta, Italy, in 1895, Valentino arrived at Ellis Island in 1913, at the age of 18. He lived on the streets and in Central Park until he picked up work as a taxi dancer at Maxim’s Restaurant-Caberet, becoming a “tango pirate” and spending time on the dance floor with wealthy women who were willing to pay for the company of exotic young men.\nValentino quickly befriended a Chilean heiress, which might have seemed like a good idea, but she was unhappily married to a well-connected businessman named John de Saulles. When Blanca de Saulles divorced her husband in 1915, Valentino testified that he had evidence that John de Saulles had been having multiple affairs, including one with a dance partner of Valentino’s. But his refined, European and youthful appearance at the trial had some reporters questioning his masculinity in print, and John de Saulles used his clout to have the young dancer jailed for a few days on a trumped-up vice charge. Not long after the trial, Blanca de Saulles shot her husband to death over custody of their son, and Valentino, unwilling to stick around for another round of testimony and unfavorable press, fled for the West Coast, shedding the name Rodolpho Guglielmi forever.\nIn California, Valentino began landing bit parts in films and, as he did in New York, building a clientele of older wealthy women who would pay for dance instruction. So charming was the young Italian that he would often show up at movie auditions driving fancy cars his clients had lent him. Impulsively, he married actress Jean Acker, but a regretful (and lesbian) Acker locked him out of their hotel room on their wedding night. She quickly sued for divorce.\nBy 1921, Valentino was starring in The Four Horsemen of the Apocalypse, which became one of the highest-grossing films of the silent era. Also that year, he was cast as Sheik Ahmed Ben Hassan in The Sheik—another wildly successful film, which would define Valentino’s image as a brooding but irresistible lover. It was an image he would despise.\nIn 1922, a writer named Dick Dorgan opined, in Photoplay magazine, opined that , “the Sheik is a bum Arab, that he is really an Englishman whose mother was a wop or something like that.” Valentino was infuriated by the insult to his mother and tried to have Dorgan banned from the studio. He also swore he would kill the writer if he saw him. The magazine apologized and promised some favorable pieces in the future, but a few months later, it published Dorgan’s “A Song of Hate,” in which he railed against Valentino’s “Roman face,” his “patent leather hair,” and his ability to make women dizzy. The article was somewhat good-natured—a common man’s jeremiad against a guy who danced too well and was too good-looking—but Valentino resented its references to his long eyelashes and the earrings he wore in films.\nValentino’s next few films performed erratically at the box office, and contract disputes with various studios forced him out of the movie business for a time. In 1922, he married Natacha Rambova, a costume designer, artistic director and occasional actress, but stood trial on bigamy charges because he hadn’t yet divorced Acker. He and Rambova had to have their marriage annulled; in March 1923 they remarried legally.\nTo make money until he was free to sign a new studio deal (and to pay off Acker), Valentino joined a dance tour throughout the U.S. and Canada. Sponsored by Mineralava beauty products, Valentino and Rambova performed as dancers and spokespersons, and Valentino judged beauty contests. He returned to films with the title role in Monsieur Beaucaire in 1924, under a new contract with Ritz-Carlton Pictures. Although the Louis XV drama was fairly successful, Valentino had to wear heavy makeup and ruffled costumes in an overtly feminized role. The actor, ever sensitive about his masculinity, was determined to be more careful about the roles he chose. He and Rambova would divorce in 1925, leading to public speculation that Valentino was a homosexual and that he had been engaged in “lavender marriages” of convenience to hide it. There is no definitive evidence in any credible biographies written of the two that either Valentino or Rambova was gay; rather, the speculation reflected contemporary sterotypes and prejudices, and was no doubt inspired by Valentino’s personal style and refined European tastes. Simply put, the man dubbed the “Latin lover” by the studios seems to have sought long-term relationships with women.\nIn early 1926, Valentino joined United Artists at the urging of Chaplin and Fairbanks. Mired in debt, he was practically forced into making a sequel to The Sheik. Though women continued to swoon over him, and some men imitated his mannerisms and slick-backed hair (they became known as “Vaselinos”), many more men grew skeptical of the foreign-born actor. Fairbanks was dashing and unquestionably masculine, but Valentino, with his dandy clothes, his wristwatch and a slave bracelet?\nPhotoplay published yet another piece, this one by Herbert Howe, that described Valentino’s his influence on leading men after his stellar tango in The Four Horsemen of the Apocalypse like this: “The movie boys haven’t been the same,” Howe wrote. “They’re all racing around wearing spit curls, bobbed hair and silk panties.… This can’t keep up. The public can stand just so many ruffles and no more.”\nBut it was the Chicago Tribune that really set Valentino off. On July 18, 1926, the paper ran an unsigned editorial under the headline “Pink Powder Puffs” that blamed Valentino for the installation of a face-powder dispenser in a new public men’s room on the city’s North Side:\nA powder vending machine! In a men’s washroom! Homo Americanus! Why didn’t someone quietly drown Rudolph Guglielmo , alias Valentino, years ago?… Do women like the type of “man” who pats pink powder on his face in a public washroom and arranges his coiffure in a public elevator?… Hollywood is the national school of masculinity. Rudy, the beautiful gardener’s boy, is the prototype of the American male.\nValentino seethed at the editorial’s insinuations and ridicule. Since The Son of the Sheik was about to open, Oscar Doob, the film’s press agent, suggested that Valentino challenge the “Pink Powder Puffs” writer to a duel. Valentino sent his dare to the Chicago Herald-Examiner, the Tribune’s competitor: “To the man (?) who wrote the editorial headed ‘Pink Powder Puffs’ in Sunday’s Tribune, I call you in return, a contemptible coward and to prove which of us is a better man, challenge you to a personal test.” Noting that a duel would be illegal, Valentino said he would be happy to settle things in a boxing ring. And while Doob was immensely pleased with the publicity, he had no doubt that Valentino was “burned up” about the editorial.\n“It’s so unfair. They can say I’m a terrible actor if they like, but it’s cowardly and low to hold me up as a laughing stock and make fun of my personal tastes and my private life,” Valentino told a Herald Examiner reporter. “This man calls me a ‘spaghetti-gargling gardener’s helper.’… As for being a gardener’s helper, I specialized in college in landscape gardening because in Italy, that is as fine an art as architecture or painting.”\nThe Tribune editorial writer did not come forward, but the actor traveled to New York and arranged to have boxing lessons from his friend Jack Dempsey, the heavyweight champion. Valentino was actually quite fit, and Dempsey tried to help, getting in touch with sportswriter Frank “Buck” O’Neil. “Listen, O’Neil,” Dempsey told him, “Valentino’s no sissy, believe me…. He packs a pretty mean punch.”\n“Cut the crap,” O’Neil told him. “I don’t buy it, and neither does anyone else.” O’Neil then volunteered to take on Valentino in the ring, and the actor quickly agreed to fight him the following afternoon on the roof of the Ambassador Hotel. The next morning, reporters arrived at Valentino’s suite, only to see him decked out in an “orchid bathing suit and lavender lounging robe.”\n“I’m going back to Chicago and I’ll have satisfaction,” Valentino told them, still incensed over the “Pink Powder Puffs” editorial. Privately, reporters marveled at Valentino’s bulging biceps and wondered what the star would do if he found out the editorial writer was a woman.\nValentino and O’Neil met on the roof, with reporters and photographers attending, and despite O’Neil’s promise that he would not hurt the star, he popped Valentino on the chin with a left. The actor responded by dropping his larger opponent with a left of his own. Somewhat stunned, Valentino apologized and helped the writer to his feet.\n“Next time Jack Dempsey tells me something, I’ll believe him,” O’Neil told reporters. “That boy has a punch like a mule’s kick. I’d sure hate to have him sore at me.”\nStill, the match proved nothing, and in the coming days, Valentino continued to fume about pink powder puffs. The more he mentioned the editorial to reporters, the more he invited the judgment that he must be hiding something. Valentino even met with the writer H.L. Mencken for advice, but when Mencken told him to ignore the taunts, the actor ignored him instead. Mencken would later write, “Here was a young man who was living daily the dream of millions of other young men. Here was one who was catnip to women. Here was one who had wealth and fame. And here was one who was very unhappy.”\nIn late July, Valentino attended the New York premiere of The Son of the Sheik. The temperature was close to one hundred degrees, but a mob of thousands formed around the theater, and as Valentino tried to make his way out of Times Square they ripped at his clothes. He escaped sufficiently intact to read about the melee in the next morning’s New York Times review of his film. More important to Valentino, however, was that the review said the film was full of “desert rough stuff and bully fights” and “leaves no doubt” about his masculinity. Referring to the “Pink Powder Puff” editorial, the reviewer warned any writer to think twice before accepting Valentino’s challenge, as “the sheik has an arm that would do credit to a pugilist and a most careless way of hurling himself off balconies and on and off horses. One leap from a balcony to a swinging chandelier is as good as anything Douglas Fairbanks ever did.”\nThe film was a hit, and the whispering about the star’s masculinity began to fade. As the sheik, he still appeared to be wearing eye shadow, and perhaps his lips bore a slightly darker stain of rouge, but after all, he was in show business.\nTwo weeks later, Valentino collapsed in his suite at the Ambassador and was taken to a hospital. After emergency surgery for a ruptured appendix, his doctors were hopeful he would recover. Then he developed pleuritis in his left lung and was in severe pain. At one point, he asked a doctor, “Am I still a pink powder puff?” Some reporters and readers were convinced that the actor’s hospitalization and the daily updates on his condition amounted to yet another publicity stunt. But on August 23, Rudolph Valentino slipped into a coma and died just hours later, surrounded by hospital staff.\nOn the news of his death, more than 100,000 people gathered on the streets in chaos outside the Frank Campbell Funeral Home. Flappers tore at their own clothes, clutched at their chests and collapsed in the heat. The New York Police Department tried to bring the order to the mob, and there were reports of despondent fans committing suicide. Inside the funeral home, four Black Shirt honor guards, supposedly sent by Benito Mussolini, stood nearby in stark tribute to the fallen star. (It was later learned that the men were actors, hired by the funeral home in, yes, a publicity stunt.)\nThe Polish actress Pola Negri, who had been having an affair with Valentino, fainted over his coffin. Upon reviving, she announced that she was to have been his third wife and quickly claimed the role of the dead star’s “widow.” For the funeral, she sent a massive floral display with thousands of blood-red roses surrounding white blooms that spelled out “POLA.” His body traveled back to the West Coast on a funeral train, and he was laid to rest in Hollywood.\nThe hysteria following Valentino’s death did not abate, and when The Son of the Sheik was released nationally months later, it was acclaimed as one of his best movies—a swan song of masculinity. Rumors that he actually died by the gun of a jealous husband or scorned lover kept the tabloids in business. And for decades, a veiled woman in black arrived at Valentino’s Hollywood tomb on the anniversary of his death to place twelve red roses and one white one on his grave. Once it was learned to be yet another press agent’s stunt, competing ladies in black began arriving at the tomb, knocking roses to the ground as they scuffled for position in front of newspaper photographers.\nWhether the quality of Valentino’s voice would have killed his career in talkies is a subject of endless debate. Some say his accent was too thick, others who knew him well say his rich, husky baritone would only have helped him reach even greater heights of fame. But nearly a century after he arrived on these shores, his very name remains tantamount to a male seducer of women. In that sense, his work outlasted the biases of his time.\nBooks: Allan R. Ellenberger, The Valentino Mystique: The Death and Afterlife of the Silent Film Idol, McFarland & Co. Inc. Pub, 2005. Jeanine Basinger, Silent Stars, Knopf, 1999. Michael Ferguson, Idol Worship: A Shameless Celebration of Male Beauty in the Movies, StarBooks Press, 2005.\nArticles: “Valentino Still Irate,” New York Times, July 20, 1926. “Why Wasn’t He Drowned Years Ago, Asks Article,” Boston Globe, July 21, 1926. “Valentino Challenges Editor to Fight Duel,” Hartford Courant, July 21, 1926. “Pola Sobs Out Grief During Studio Rests,” Boston Globe, August 22, 1926. “Sheik of the Movies, Wearing Hospital Nightshirt, Beseiged by Worshipping Fans and Press Agents, Even in Grave Illness,” Boston Globe, August 22, 1926. “Many Hurt in Mad Fight to Pass Valentino Bier,” Boston Globe, August 25, 1926. “Pola Negri Prostrated by News of Valentino’s Death,” Boston Globe, August 25, 1926. “Valentino Passes with No Kin At Side; Throngs in Street,” New York Times, August 24, 1926. The Rudolph Valentino Society, http://rudolphvalentino.org/index.html. “Celebrities of the 20s: Rudolph Valentino,: by Anthony Ehlers, http://raesummers.wordpress.com/2011/01/10/celebrities-of-the-20s-rudolf-valentino/."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:17aa3145-fc59-49c7-800a-5bfd45ebc5d8>","<urn:uuid:707837f6-5338-4cc3-8a62-e0b36932c077>"],"error":null}
{"question":"What makes sailing in the Society Islands relatively safe, and what specific challenges do sailors face when navigating reef passes in the Tuamotus? 🏝️ I'm planning a trip and want to understand the differences!","answer":"The Society Islands offer safe sailing conditions with efficient navigation beacons in lagoons, wide passes that are passable in all weather conditions (except Maupiti), and deep, sheltered bays. Their location at an amphidromic point means minimal tidal variation. In contrast, the Tuamotus present significant challenges, with reef passes experiencing dangerous currents up to 10 knots and standing waves of 2-3 feet. These currents are influenced by a combination of tide, swell, and wind. During swell events, water pushed into the lagoon must escape through passes, creating additional outgoing currents of 1-6 knots, which can combine with outflowing tides to create dangerous conditions of 8-10 knots.","context":["East-west trade winds make for generally easy navigating between the Society Islands and the Marquesas Islands, while a little more caution is required in the Tuamotu Islands, the Gambier Islands and the Austral Islands. One of the Society Islands’ strong distinctive features is their location at an amphidromic point, or a tidal system where the tidal range is almost zero. Only the solar tide functions, but it is weak and occurs at the same time every day. The navigation beacons in the lagoons and at the entry of passes through coral reefs in the Society Islands are very efficient. These islands offer many mooring places and nautical facilities for a variety of boats and yachts. A wind known in Tahitian as the mara’amu blows between July and September, coming from the south-east and capable of reaching speeds of Force 6-7 (25-30 knots/40-60 kph/25-38 mph).\nThis causes short and choppy seas, particularly in the channels between islands. Between December and February, a wind from the west can cause strong wind blows.\nCoral reef passes\nWhile these passes are wide and passable in all weather conditions in the Society Islands, with the exception of Maupiti in the leeward Islands, it is recommended that they be navigated when conditions are slack in the Tuamotu Islands, where there may be strong currents. In fact, these passes are not very deep and are exposed to strong swells, making them dangerous to navigate, particularly passes exposed to the south when there is a mara’amu, or strong southerly wind.\nThe majority of the Society Islands have deep and sheltered bays. The exterior coral reefs are often bordered with vast expanses of white sand on the lagoon side, are not very deep, and are scattered with coral formations which make heavenly places to drop anchor.\nRenting a sailboat with or without a crew (for the more experienced sailors) remains one of the best ways to discover The Islands of Tahiti.The almost unlimited number of moorings and the navigational conditions make it a yachter’s paradise.\nIn each island, we suggest you to heed advice in order to select the best place to drop anchor, without disturbing local activities such as fishing in the lagoon, cultured pearl farming…\nPapeete Port Authority\nThe port of Papeete is the only international commercial port in French Polynesia. It is equipped with port facilities that can accommodate commercial and cruise ships as well as pleasure crafts and luxury yachts. Extensive renovations are under way in order to ensure comfortable and secure harbor installations for foreign sailors and the local population alike.\nIn Tahiti, Moorea, Raiatea (the main center for nautical activities) and Bora Bora, several marinas and nautical bases are available for pleasure boaters.\nTypes of Yacht Experiences\n- Private Sailing Charter\nCrewed sailing catamarans or monohulls sailing multiple islands with flexible itineraries.\n- Private Motor Yacht Charter\nCrewed motorized yachts sailing multiple islands with flexible itineraries.\n- Sailing Cruise Cabins\nPrivate cabins aboard a sailing catamarans or motorized yacht with fixed itinerary, on an all-incluse package to multiple islands.\n- Bareboat sailing Charter\nCaptain of your own catamaran or monohull.\nChecklist for the Perfect Sailing Experience:\n- Trade winds are predictable and weak to moderate most of the year.\n- Inter-island sailing is short and voyages can include multiple islands and atolls.\n- Virtually every island and atoll has an 80°F (27°C) neon-blue lagoon.\n- Lagoons are calm and protected with many anchorages.\n- Passes are wide, have weaker currents, and feature beacon systems.\n- Supplies are easily found at island markets, marinas, shops and food stands of fisherman and farmers.\n- Safety is a part of the islands’ ocean culture with a permanent VHF maritime radio channel, daily meteorological reports, emergency services and medical evacuations.\n- Choices among many expert charter companies.\nFor more information, please visit our page Cruises & Sailing.","Many sailors crossing the Pacific choose not to stop in many of the Tuamotos atolls due to the challenge of navigating the reef passes — the currents can be extremely dangerous, flowing up to 10 knots, occasionally creating standing waves to 2-3 feet.\nPredicting when it is safe to navigate a reef pass can be tricky. Sailors often talk about “timing the slack tide” in Tuamotos passes, but this is somewhat misleading. What is really important is the overall current in the pass– which is caused by a combination of tide, swell and wind.\nThe tide has the most obvious effect on the current. Luckily the tidal variation in French Polynesia is only about 1-2ft, but the atolls are so large that a formidable amount of water still needs to move in and out of the lagoon twice a day.\nSlack tide is normally the calmest time in a reef pass – assuming there is no wind and swell. The wind can seriously disturb the pass when it is moving in the opposite direction to a strong current, resulting in confused standing waves. So we avoid transiting the pass when wind and current are in opposition.\nAn even more significant hazard for the pass, however, are the swell conditions. If there’s a moderate to large swell (2m+) there is a huge amount of water that is poured into the lagoon. Satellite images and nautical charts make it seem like the atolls are a complete ring of land, but the majority of the ring is actually submerged reef with a peppering of motus ( little islands of land in the barrier reef).\nWaves can come from groundswell (far away storms, with large periods) or windswell (localized strong winds with short periods) such as the ‘Maraamu’ South-East trade winds that blow 25knots+. The extra water these swells push into the lagoon must escape through the reef pass. This creates an additional outgoing current of 1-6 knots.\nWhen this swell-driven outgoing current combines with an outflowing tide, a river of water can flow towards the ocean at an incredible 8-10 knots! Even a big ship might have a hard time during such conditions.\nThe best time to enter a pass during such a swell event is usually during the peak of an incoming tide, so that it neutralizes the outgoing current. Then, the outgoing current may be a reasonable 1-2 knots. Therefore, in the case of swell events, slack current is NOT slack tide.\nNote: swell can also create large waves that break next to narrow reef passes making them difficult to impossible – like Maupiti in the western Society Islands. This is an entirely different problem, but still relevant for navigation!\nNaturally, it’s best to travel across reef passes when the swell and wind is moderate, and tide is slack. But we don’t always have that luxury. Being able to factor for the effects of swell and wind is critical for the safe navigation of reef passes in less-than-ideal conditions.\nPHOTO: shows the Tiputa pass in Rangiroa. It is a 40 mile wide atoll with a huge amount of water moving in and out of the pass, generating large standing waves which can be seen on satellite images. This famously attracts dolphins, which divers come to swim with. We entered Tiputa pass after waiting an hour for the tide to shift, and still the outgoing current was nearly 6 knots. However we were blessed with an amazing moment when a huge dolphin jumped directly in front of Aldebaran as we were barely moving forward with the engine at full throttle!"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:073b6ce9-7c2b-4a12-9b05-a7bae1d75316>","<urn:uuid:f03ad46a-96b1-4be4-81b7-3ad0e0266080>"],"error":null}
{"question":"What are the training opportunities for Avionics Systems Technicians, and what mental health risks might they face in their high-stress work environment?","answer":"Avionics Systems Technicians undergo extensive training including a 30-week Performance-Oriented Electronics Training course at Kingston and a 24-week program at Borden covering various technical aspects. They may also receive specialized training in areas like Instructional Techniques and Quality Assurance. Regarding mental health risks, as emergency service personnel working in high-stress environments with critical responsibilities, they may be vulnerable to mental health issues. Studies show that personnel in emergency services and high-responsibility roles have increased risks of stress-related conditions, including PTSD, depression, and anxiety. The pressure of maintaining aircraft safety and working shifts could contribute to these risks, similar to other transportation-related occupations where stress has been linked to mental health challenges.","context":["Avionics Systems Technician\nWhat They Do\nAvionics Systems Technicians are responsible for maintaining all electronic systems onboard Forces’ aircraft. As part of the aircraft maintenance team, the Avionics Systems Technician is responsible for first line servicing operations in launching and recovering all types of aircraft.\nThe primary responsibilities of Avionics Systems Technicians are to:\n- Carry out performance tests, preventive/ corrective maintenance, and calibration of the following systems and their associated components:\n- aircraft communication,\n- search radar,\n- fire control radar,\n- acoustic sensing,\n- infra-red radar,\n- electronic warfare,\n- compass, and\n- flight control systems\n- Set up and operate test equipment to maintain the above systems\n- Operate and maintain computer-controlled automatic test stations\n- Serve as an instructor in field technical training units, training squadrons or basic training units\n- Prepare and maintain aircraft forms and statistical data\n- Operate aircraft support equipment\n- Perform first line servicing tasks such as marshalling, parking, towing, starting, refueling, cleaning and de-icing\nAvionics Systems Technicians are employed primarily at air bases in aircraft maintenance organizations, in maintenance hangers, in airborne aircraft, lab environments and on the flight line. In the course of their career, Avionics Systems Technicians will be required to work shifts and periods of overtime. In geographic terms, employment can vary from Forces bases and wings within Canada, including the Arctic, to overseas locations throughout the world in response to NATO and UN commitments.\nThe starting salary for a fully-trained Avionics Systems Technician is $49,400 per year; however, depending on previous experience and training the starting salary may be higher. Once all required training is complete, they are posted to a location within Canada where they complete on-the-job training on the equipment specific to their home unit. After field technical training and a period of time in the position, Avionics Systems Technicians may apply for training to become a Non-destructive Testing Technician. Avionics Systems Technicians who demonstrate the required ability, dedication and potential are selected for opportunities for career progression, promotion and advanced training.\nRelated Civilian Occupations\n- Aircraft Maintenance Engineer - Avionics\n- Avionics Maintenance Technician\nBasic Military Qualification\nThe first stage of training is the Basic Military Qualification course, or Basic Training, held at the Canadian Forces Leadership and Recruit School in Saint-Jean-sur-Richelieu, Quebec. This training provides the basic core skills and knowledge common to all trades. A goal of this course is to ensure that all recruits maintain the Forces physical fitness standard; as a result, the training is physically demanding.\nBasic Occupational Qualification Training\nAvionics Systems Technicians attend the Performance- Oriented Electronics Training course at the Canadian Forces School of Communications and Electronics in Kingston, Ontario. Training takes approximately 30 weeks and teaches the following basic skills:\n- DC Circuits Theory\n- AC Circuits Theory\n- Electro-Mechanical devices\n- Solid State devices\n- Power sources\n- Amplifier circuits\n- Oscillator circuits\n- Multistage electronic circuits\n- Conductors and cables\n- AM/FM Theory\n- Audio/Video equipment\n- Digital circuits\n- Computers and peripherals\nThe second part of the training program takes place at the Canadian Forces School of Aerospace Technology and Engineering in Borden, Ontario. Training takes approximately 24 weeks and includes:\n- Common mechanical training\n- Common aircraft servicing\n- Solid-state devices\n- Digital logic\n- Aircraft wiring\n- Magnetron, Klystron, Travelling Wave Tubes and Microwave theory\n- Computer techniques and architecture\n- Inspection and repair of indicator/display, pitot static, flight instrument, compass, aircraft flight recorder and locator, air data computer, automatic flight control, electronic warfare, navigation, radar communications, aircraft data processing, Avionics (AVS) and combined Avionic (AVS)/Aviation (AVN) multi-purpose display systems\nAvionics Systems Technicians may be offered the opportunity to develop specialized skills through formal courses and on-the-job training, including:\n- Instructional Techniques\n- Calibration Technician\n- Quality Assurance\n- Computerized Fault Diagnosis and Analysis\n- High Reliability Soldering\n- Aircraft Specific Type Courses\nAs they progress in their career, Avionics Systems Technicians who demonstrate the required ability and potential will be offered advanced training. Available courses include:\n- Technical Administration\n- Leadership and Management Courses\nThe minimum required education to apply for this position is the completion of the provincial requirements for Grade 10 or Secondaire IV in Quebec. Foreign education may be accepted.\nIf you already have a college diploma, the Forces will decide if your academic program matches the training criteria for this job and may place you directly into the required on-the-job training program following basic training. Basic training and military occupation training is required before being assigned.\nNon-commissioned Member Subsidized Education Program.\nBecause this position requires specialty training, the Forces will pay successful recruits to attend the diploma program at an approved Canadian college. NCM SEP students attend basic training and on-the-job training during the summer months. They receive a full-time salary including medical and dental care, as well as vacation time with full-pay in exchange for working with the Forces for a period of time. If you choose to apply to this program, you must apply both to the Forces and the appropriate college. For more information, click on Paid College.\nServe with the Reserve Force\nThis position is available for part-time employment with the Primary Reserve at certain locations across Canada. Reserve Force members usually serve part time at an Air Force Wing in their community, and may serve while going to school or working at a civilian job. They are paid during their training. They are not posted or required to do a military move. However, they can volunteer to move to another base. They may also volunteer for deployment on a military mission within or outside Canada.\nAvionics Systems Technicians serve with the Royal Canadian Air Force. When employed on a part-time or casual full-time basis, they usually serve at Forces bases and tactical units at locations within Canada.\nReserve Force Training\nReserve Force members usually begin training with their home unit to ensure that they meet the required basic professional military standards. Following basic military training, Avionics Systems Technician candidates will proceed to the Canadian Forces School of Communications and Electronics in Kingston, Ontario to complete the Performance Orientated Electronics Training (POET), which is about 30 weeks in duration. On successful completion of the POET course, candidates will then proceed to the Canadian Forces School of Aerospace Technology and Engineering for their Common Core and Avionics Systems Technician course, which is about 47 weeks in duration. Potential Avionics Systems Technicians can expect to be under formal trade training for about 77 weeks.\nAir Reserve members are trained to the same level as their Regular Force counterparts and are employed in the same unit and perform the same job. Air Reserve members usually serve up to 12 days per month in a regular work day, with opportunities to serve full-time for short durations as needed. Reserve Force members are paid 85% of Regular Force rates of pay, receive a reasonable benefits package and may qualify to contribute to a pension plan.\nFind a unit in your area and start the application process for part-time employment now.","Mental health is closely linked to occupation, with work at the core of most adults’ lives. For instance, the American Institute of Stress (AIS) recently indicated that approximately 66% of people’s stressors are related to their jobs.1 A particular problem is the lack of work-life balance, which can trigger certain mental illnesses like depression and anxiety.2\nDo Specific Jobs Pose a Mental Health Risk?\nNumerous studies have explored the occupational characteristics related to mental health, such as job demands, supervisor support, and work stress,3 with the key finding being that people in certain occupations are more prone to mental disorders. Stress, in particular, has been found to be positively correlated with mental health.4\nThe 10 most stressful jobs in America tend to revolve around emergency services, transport control, public relations, and executive roles. 5\nEmergency and Rescue Services\nFirefighters, soldiers, police officers, and disaster response personnel are at high risk for mental health issues as a result of being involved in emergency situations and being exposed to varying degrees of violence. This population has an increased risk of being exposed to traumatic events through their daily work, often leading to work-related post-traumatic stress disorder (PTSD).6,7\nFor instance, a study found high rates of PTSD and depression in firefighters.8 Likewise, approximately 100,000 active police officers in the United States suffer from PTSD, and many also live with the comorbidities of depression, anxiety, and suicidal ideation.9 Research from Johns Hopkins University Bloomberg School of Public Health in Baltimore, Maryland, confirmed that police and firefighters are at higher risk for mental illnesses compared with civilians, and that their exposure to trauma is related to the development of alcohol use and mood and anxiety disorders.9 In a study of military personnel, almost 25% of 5500 Army soldiers were diagnosed with a mental disorder such as depression or PTSD, with PTSD rates being approximately 15 times higher than the general public.10\nThe Germanwings Flight 9525 incident in 2015 brought airline personnel’s mental health status to the forefront. Indeed, the crash was reportedly caused by Andreas Lubitz, a pilot who had previously sought treatment for suicidal tendencies, depression, and psychosomatic illness. An international survey of 3485 pilots indicated that 12.6% of the sample population met depression thresholds and 4.1% were thinking about suicide.11 In addition to jet lag, the stressors experienced by pilots include long working hours, pressure from the responsibility of passenger safety, and cockpit conditions such as low oxygen levels and high noise levels. Some pilots may also be hesitant to seek treatment due to the impact this could have on career advancement.\nTaxi driving is another highly stressful occupation. One study of 508 taxi drivers found that 33% presented with at least 5 symptoms of depression, which was mainly attributed to lack of leisure activities.12 Another study found that, compared with the general population, public transportation drivers had higher rates of alcohol abuse, major depressive episodes, burnout syndrome, and anxiety.13 Drivers are often required to deal with long working hours and night shifts, which could explain some of these symptoms and unhealthy coping mechanisms. Traffic jams and air and noise pollution may also have a negative influence on their mental health.\nPublic Relations (PR)\nLike most people in PR jobs, newspaper reporters, broadcasters, and event coordinators face tight deadlines, managing unpredictable deals, covering violent social issues, and adapting to a hectic workplace environment. These factors may explain why approximately 34% of European PR professionals experience mental illness. Almost half of them reported that they perceive their colleagues as unaccepting of mental illness, and this lack of social support and taboo regarding mental illness is counterproductive to encouraging help-seeking behavior.14\nAn Australian study showed that 21% of 261 US-based senior executives are psychopaths.15 Furthermore, the antisocial characteristics often found in executives, such as deceitfulness and a lack of empathy, may further cause psychological turmoil for their subordinates. Indeed, middle managers, who often help senior executives, have higher stress levels than their bosses due to their job demands.16 Subsequently, managerial positions appear to be linked to high levels of depression and anxiety.17\nEvidence suggests that the key link between occupation and mental illness is high stress, which can increase the risk of PTSD, anxiety, depression, and mood and sleep disturbances. It is important for physicians to identify occupational stress as early as possible so that the appropriate interventions can be implemented before problems escalate. Tools such as the Job Stress Scale,18 Workplace Stressors Assessment Questionnaire,19 and Depression Anxiety and Stress Scales20 can assist with this.\nOnce occupational stress has been identified, stress management interventions can be put into place. The physician can assist with secondary interventions by attempting to reduce the stress severity before it leads to serious health problems.21Such interventions are aimed at the individual and involve techniques like relaxation, deep breathing, meditation, time management, exercise, and goal setting.22 These techniques help individuals by encouraging them to monitor their stress levels, identify the causes of stress, and develop the necessary skills to manage the stress effectively.\n- The American Institute of Stress. Workplace stress. www.stress.org/workplace-stress/. Updated 2017. Accessed April 17, 2017.\n- Wang J, Lesage A, Schmitz N, Drapeau A.The relationship between work stress and mental disorders in men and women: findings from a population-based study. J Epidemiol Community Health. 2008;62(1):42-47.\n- Thorsteinsson E, Brown R, Richards C. The relationship between work-stress, psychological stress and staff health and work outcomes in office workers. Psychology. 2014;5:1301-1311.\n- Jiang T, Ge H, Sun J, Li R, Han R, Liu J. Relationship between Occupational Stress, 5-HT2A Receptor Polymorphisms and Mental Health in Petroleum Workers in the Xinjiang Arid Desert: A Cross-Sectional Study. Int J Environ Res Public Health. 2017;14:402-413. doi:10.3390/ijerph14040402\n- Career Cast. The most stressful jobs of 2017. www.careercast.com/jobs-rated/most-stressful-jobs-2017. Updated 2017. Accessed April 17, 2017.\n- Skogstad M, Skorstad M, Lie A, Conradi HS, Heir T, Weisæth LWork-related post-traumatic stress disorder. Occup Med. 2017;63(3):175-182.\n- Harvey SB, Milligan-Saville JS, Paterson HM, et al. The mental health of fire-fighters: An examination of the impact of repeated trauma exposure [published online Nov 24, 2016]. Aust N Z J Psychiatry. doi:10.1177/0004867415615217\n- Alghamdi M, Hunt N, Thomas S. Prevalence rate of PTSD, Depression and Anxiety symptoms among Saudi Firefighters. J Trauma Stress Disord Treat. 2017;5(3):2.\n- Moreno, D. PTSD: The hidden toll of policing. The Epoch Times. 2017. www.theepochtimes.com/n3/2115193-ptsd-the-hidden-toll-of-policing/. Accessed April 17, 2017.\n- Willingham V. Study: Rates of many mental disorders much higher in soldiers than in civilians. CNN. http://edition.cnn.com/2014/03/03/health/jama-military-mental-health/. Accessed July 17, 2017.\n- Wu AC, Donnelly-McLay D, Weisskopf MG, McNeely E, Betancourt TS, Allen JG. Airplane pilot mental health and suicidal thoughts: a cross-sectional descriptive study via anonymous web-based survey. Environ Health. 2016;15(1):121.\n- Bawa MS, Srivastav M. Study the epidemiological profile of taxi drivers in the background of occupational environment, stress and personality characteristics. Indian J Occup Environ Med. 2013;17(3):108.\n- Ruiz-Grosso P, Ramos M, Samalvides F, Vega-Dienstmaier J,Kruger H. Common mental disorders in public transportation drivers in Lima, Peru. PloS one. 2014;9(6):e101066.\n- Griggs I. A third of PR people have experienced mental ill health so what is the industry going to do about it? PR Week. www.prweek.com/article/1335436/third-pr-people-experienced-mental-ill-health-so-industry-going-it. Accessed April 17, 2017.\n- Brooks N. The emergence of non-criminal psychopathy. Presented at: 2016 Australian Psychological Society Congress. September 13-16. Melbourne, Australia.\n- Prins SJ, Bates LM, Keyes KM, Muntaner C. Anxious? Depressed? You might be suffering from capitalism: contradictory class locations and the prevalence of depression and anxiety in the USA. Sociol Health Illn. 2015;37(8):1352-1372.\n- Edwards KL, Walker SL, Bodenham RF, Ritchie H, Shultz S. Associations between social behaviour and adrenal activity in female Barbary macaques: consequences of study design. Gen Comp Endocrinol. 2013;186:72-79.\n- Lambert EG, Hogan NL, Camp SD, Ventura LA. The impact of work–family conflict on correctional staff: A preliminary study. Criminol Crim Just. 2006;6(4):371-387.\n- Mahmood MH, Coons SJ, Guy MC, Pelletier KR. Development and Testing of the Workplace Stressors Assessment Questionnaire. J Occup Env Med. 2010:52(12):1192-1200.\n- Crawford JR, Henry JD. The Depression Anxiety Stress Scales (DASS): Normative data and latent structure in a large non‐clinical sample. Br J Clin Psychol. 2003;42(2):11-131.\n- Murphy LR, Sauter SL. The USA perspective: Current issues and trends in the management of work stress. Aust Psychol. 2003;38(2):151-157.\n- Giga SI, Cooper CL, Faragher B. The development of a framework for a comprehensive approach to stress management interventions at work. Int J Stress Manag. 2003;10(4):280."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:831a6d82-cc9c-4c33-8662-e14f10cdaeae>","<urn:uuid:1e19590a-362f-40af-8fdb-ea2a0a4d8cd5>"],"error":null}
{"question":"What are the similarities between chronic pain conditions and phantom limb pain in terms of their underlying mechanisms?","answer":"Both chronic pain conditions and phantom limb pain involve disrupted communication in the nervous system. In chronic pain, there can be misfiring pain signals, similar to a car's faulty warning light, where the pain persists without clear physical cause. Similarly, in phantom limb pain, the brain receives mixed signals and may interpret any signal as pain, regardless of actual nerve injury. Both conditions can be influenced by stress and anxiety, and both may involve the brain's interpretation of pain signals rather than actual tissue damage. Additionally, both conditions can be challenging to treat and may require a combination of multiple treatment approaches.","context":["Stub your toe by mashing it into a table leg (well, don’t actually do it, just think back to the last time you did). Within milliseconds, the stubbed toe sends pain signals to the brain to let it know you stubbed your toe. The message reads, “Sorry to bother you but you just wiped out your toe on that table leg and it’s probably pretty messed up, maybe even broken.”\nNext, the brain assesses how bad the injury really is by drawing on all the credible information it has to go on. “Hmm, last time you did this your toe was black and blue and you limped around for a week.”\nNow the pain message shoots back to the nerves in your toe with the level of perceived pain they’ve determined the injury requires. Pain researchers say it’s a conversation between the central and peripheral nervous systems. This conversation can go awry like the engine warning light in a car — though the mechanic never finds anything wrong. Conditions like fibromyalgia and chronic pain may be chalked up to the sensor itself — misfiring pain signals.\nSome health providers believe it is the brain’s prerogative to ignore pain completely. “Oh, that stubbed toe, pay no attention and continue what you were doing.” That doesn’t mean your conscious brain should ignore pain. We do that at our peril.\nPain Is Purposeful\n“When people try to ignore or power through their pain, they teach their brain to get good at being in pain, warns Ya-Ling Liou, a chiropractor and author of Every Body’s Guide to Everyday Pain. This is how chronic pain sets in, she says.\nIf you can change pain — make it better or worse, by moving, resting, elevation or applying ice — you can control the pain, and Liou says there’s hope to cure it.\nPersistent aches and pains plague nearly one-fifth of adults in the U.S., according to the 2010 National Health Interview Survey, but Liou refuses to buy the idea that pain is a part of aging. She has too many elderly patients who live pain-free.\nBecome a Pain Detective\n“As soon as you feel pain, you should ask yourself what were you doing?” says Liou. What physical position were you in? What was your stress like? What was your life like? You can unearth a lot of clues by answering these questions, and it’s much harder to remember the answers years later.\nPlus, the way pain feels (burning, stabbing, sharp, dull) may help you trace it back to its trigger. Because everyone’s brain determines pain differently, the way pain feels can be misleading, but typically, a burning sensation can spell nerve pain. Dull or achy discomfort can mean muscle pain.\nWhat’s more, if you can change pain — make it better or worse, by moving, resting, elevation or applying ice — you can control the pain, and Liou says there’s hope to cure it.\nDifferent Kinds of Pain\nPain can be mechanical, chemical, emotional or a combination of those. We can even feel pain when there’s no physical reason for it because of what’s called the nocebo effect: when we think something is painful, it will be.\n- Mechanical pain is repetitive movement, the strain of overworked muscles and ligaments\n- Chemical pain is due to internal and external (environmental) irritants that cause inflammation, including foods\n- Emotional pain is when stress gives you a stomach ache, makes your shoulders hurt or brings on a migraine\nCommon Causes of Pain\n“Everyday aches and pains can be caused by minor arthritis, joint pain and stiffness, muscle aches, cramps and inflammation,” says Rebecca Lee, a New York City nurse and founder of the natural health resource www.Remediesforme.com.\nOnce certain underlying causes are ruled out with tests like bloodwork, MRI and X-rays, everyday aches and pains can be pinpointed back to other causes, such as infection, the flu, a cold, exercise, drug side effects, stress, depression or anxiety.\nA lot of people reject the idea that stress can play a role in pain or make it worse. But Liou explains that because we don’t physically react the way animals do (fight or flight) in response to most stress, we don’t have an outlet for it. That energy has to go someplace in the body, finding its way to your GI tract or your lower back, for instance.\nWhen Aches and Pains Crop Up\nWhat should you do if you suddenly have aches or pains?\nIf you’re sore after a weekend of activity, wait it out. Give yourself 48 hours to see if it passes. If it doesn’t, ask yourself if you’re able to affect the pain with movement. Are you getting relief from anything? If the answer is yes, it may be a matter of waiting, applying ice and resting. If pain doesn’t respond, it probably requires a visit to your doctor.\n“Desensitization helps, whether massage, vibration or stretching,” says Dr. Amy Baxter, an Atlanta-based emergency physician and inventor of Buzzy, a bee-shaped palm-sized device combining cold and vibration to ease the pain of injections, used by thousands of hospitals and clinics.\nWhen pain becomes chronic, investigate what else may be going on. Stress, emotions or even foods can keep your body in a state of inflammation and discomfort. Liou says a naturopath or dietitian may help pinpoint a cause. Even if you don’t have food allergies, you could be a victim of common inflammatory food triggers such as red meat, sugar, dairy or refined carbs.\nWhen you stay on top of pain, ask the right questions and seek help when needed, you can prevent most aches and pains from settling in long-term.\n“To prevent chronic pain, find exercises that are not harsh to the joints, wear comfortable shoes, eat healthy and walk as much as possible,” Lee says.","Phantom limb pain is a sensation that feels like it originates from an amputated body part. Doctors once believed this post-amputation phenomenon was psychological; however, experts now know these are very real sensations. Although the limb or body part is gone, the nerve endings at the site of the amputation continue to send pain signals.\nWhile some patients experience severe, debilitating phantom limb pain sensations, some amputees experience non-painful phantom sensations. Amputees may feel as if they are gesturing or trying to pick something up, in addition to feeling tingling, numbness, hot, or cold sensations.\nUsually, phantom limb pain decreases and disappears over time for most people. For others, pain management of phantom limb pain can be challenging, requiring help from a pain specialist.\nWhat Causes Phantom Limb Pain?\nPain is a normal part of the healing process that generally subsides as the body repairs itself. However, it’s not that simple if you are recovering from an amputation. After an amputation, the nerves ending at the site of the amputation continue to function. These remaining nerves make the brain think the entire limb remains attached to the body. Approximately 80% of amputees experience phantom limb sensations in the weeks following an amputation, and 60% of amputees report phantom pain sensations a year after surgery.\nThe exact cause of phantom pain is unclear. However, the pain appears to originate in the spinal cord and brain. During episodes of phantom limb pain, imaging scans of the brain show activity in the portions of the brain that were neurologically connected to the nerves of the amputated limb. Researchers believe areas of the spinal cord and brain that lose input from the missing limb after an amputation adjust to the detachment in unpredictable ways. These mixed signals result in the brain interpreting the signals as pain, which is the body’s most basic message that something is not right. Sometimes, the brain’s memory of pain is retained and interprets any signal it receives as pain, regardless of signals from injured nerves.\nOther studies found that after an amputation the brain seems to remap the missing part of the body’s neural circuitry to another part of the body. Since the amputated area is no longer able to receive sensory information, that information is sent elsewhere in the body. Sensations from a missing hand may instead go to a still-present cheek, for example. When the cheek is touched, the person may sense that an amputated body member, such as a hand, is also being touched. The resulting confusion of senses can result in pain.\nSome other factors may also contribute to phantom limb pain, including damaged nerve endings, and scar tissue at the site of an amputation. It is also possible the phantom pain may mimic pain present in the limb before the amputation.\nWhat are the Symptoms of Phantom Limb Pain?\nPhantom limb pain has a wide variety of symptoms ranging from tingling and itching to burning and aching. Any sensation a limb might experience before amputation may become a phantom pain. Some patients report feeling as if their missing limb is in a distorted and painful position.\nCharacteristics of phantom limb pain include:\nAn onset of pain within a few days of amputation.\nThe pain may be intermittent or continuous.\nThe pain most often affects the part of the limb farthest from the body, such as the foot or toes of an amputated leg.\nThe sensation can be shooting, stabbing, boring, squeezing, throbbing or burning.\nSometimes the phantom pain may feel as if the missing limb is being forced into an uncomfortable position.\nThe pain may occur with pressure on a remaining portion of the limb.\nThe pain can become worse by stress, anxiety, and even weather changes.\nThe patient may experience “telescoping,” the feeling of the missing limb still being part of the body, but it has shrunk to a tiny size, similar to a collapsed telescope.\nIt’s difficult to identify the frequency of phantom limb pain because patients are usually reluctant to report it. The troubling part of phantom limb pain is that the pain is very real, but patients can clearly see the limb is gone. Therefore, some phantom pain patients may worry their physician might doubt their sanity.\nHow is Phantom Limb Pain Diagnosed?\nThere is no medical test to diagnose phantom limb pain. However, doctors identify the condition from the patient’s symptoms and circumstances, such as trauma or surgery, prior to the onset of the pain.\nHow is Phantom Limb Pain Treated?\nSuccessful treatment of phantom limb pain is challenging. Up until the early 1990s, treatment for phantom limb pain was an additional amputation. By shortening the stump and nerves, doctors thought they could reduce or eliminate phantom limb pain following the initial surgery.\nToday, pain doctors base treatment for phantom limb pain on the patient’s level of pain. A combination of multiple treatments may be helpful for some patients. Treatment usually begins with medications, in conjunction with noninvasive therapies. Minimally invasive treatments are also available to help patients. In some cases, surgery may be the last resort to relieve pain.\nNext, we discuss specific treatments for phantom limb pain.\nAlthough no medications exist specifically for phantom pain, some drugs designed to treat other conditions have proven helpful in relieving phantom limb pain. Unfortunately, no single drug works for everyone, and not everyone benefits from prescription drugs. Some of the medications used in the treatment of phantom limb pain include:\nAntidepressants, drugs that work by modifying the chemical messengers that relay pain signals. Antidepressants may also help with sleep, which can help patients feel better.\nAnticonvulsants, drugs that work by quieting damaged nerves to slow or prevent uncontrolled pain signals.\nNarcotics may be an option for some people. Taken in appropriate doses under a doctor’s direction, they may help control phantom pain.\nN-methyl-d-aspartate (NMDA) receptor antagonists, this class of anesthetics works by binding to the NMDA receptors on the brain’s nerve cells and blocking the activity of glutamate, a protein that plays a significant role in relaying nerve signals.\nAs with medications, the noninvasive treatment of phantom pain is a matter of trial and observation. The following techniques may relieve phantom pain:\nHeat application. Sometimes the application of heat to the area of amputation can ease the pain.\nBiofeedback. The process of biofeedback helps a patient become aware of normally involuntary processes inside the body (such as muscle tension, temperature, and heart rate control). Biofeedback helps the patient gain some conscious control of these processes. This awareness of the body helps the patient relax, which can help relieve the pain.\nRelaxation techniques. Various methods to help the mind alter its focus to something other than the source of pain.\nMassage. Focused rubbing of the amputated area may contribute to relieving the discomfort associated with phantom limb pain. Massage can also help the patient relax, decreasing stress and tension.\nTranscutaneous Electrical Nerve Stimulation (TENS) is a device that sends a weak electrical current via adhesive patches on the skin near the area of pain. The stimulation may interrupt or mask pain signals, preventing them from reaching the brain.\nMirror therapy. The patient watches a reflection of the whole limb in a mirror while receiving physical therapy. Seeing the reflection helps the brain to remap neural pathways to register that the ‘virtual’ limb is intact and moves without pain.\nAcupuncture.Studies by the National Institutes of Health show that acupuncture can be an effective treatment for some types of chronic pain. In acupuncture, the practitioner inserts extremely fine, sterilized stainless steel needles into the skin at specific points on the body.\nMinimally Invasive Therapies\nInjection. Sometimes pain-killing medication, such as local anesthetics and steroids, can provide phantom limb pain relief.\nSpinal Cord Stimulation (SCS). A neurostimulator delivers mild electrical impulses to the epidural space near the source of chronic pain impulses. These impulses interfere with the pain signals to the brain. A trial stimulator is typically worn for five to seven days externally. If the trial successfully relieves the pain, the patient may decide to have a permanent SCS placed under the skin.\nNerve Cuff Stimulation. A small electrode is wrapped around nerves traveling to the amputated limb. Instead of blocking nerve signals, the cuff delivers an imperceptible electrical stimulation to the nerve that replaces the sensation of pain with a pleasant signal to the brain. The user manually activates the cuff with a small wireless remote control when pain is felt.\nNerve block. Medications that help interrupt pain messages between the brain and the site of the phantom pain.\nSurgery may be an option if other treatments do not help. Surgical options include:\nBrain stimulation. Similar to spinal cord stimulation, electrodes deliver a small electrical current within the brain\nStump revision or neurectomy. If the pain is from nerve irritation in the stump, surgery can sometimes be helpful. But, cutting the nerves includes a risk of making the pain worse.\nOn the Horizon\nResearchers now believe there is a way to rewire the brain to help reduce pain from a phantom limb, according to a University of Cambridge study. The technique involves distracting the mind from mixed signals it may receive as a result of losing the limb.\nAnother new approach to relieving phantom pain includes virtual reality. A computer program, combined with special goggles, mirrors the patient’s intact limb, so it appears there has not been an amputation. The patient can move the virtual limb around to accomplish various tasks, such as batting a ball hanging in midair. Although tested on only a few people, this technique appears to help relieve phantom pain.\nWhat Are the Risk Factors for Phantom Limb Pain?\nIt’s still unknown why some people develop phantom pain after an amputation while others do not. However, there are several risk factors for the development of phantom limb pain, including pain in the limb before amputation, pain in the stump, the use of a prosthetic limb, and the number of years since the original amputation surgery. The most significant risk factors include amputation of bilateral limbs and lower extremity amputation.\nSome factors that may increase the risk of phantom limb pain include:\nPain before amputation. Researchers have found that if pain was present in a limb before amputation, patients are more likely to have pain afterward, especially immediately after amputation. Researchers believe the brain retains a memory of the pain and may continue to send pain signals, even after removal of the limb.\nStump pain. Amputees with persistent stump pain usually have phantom pain, as well. Stump pain can be the result of an abnormal growth on damaged nerve endings (neuroma). These growths on the nerves often cause painful nerve activity.\nIll-fitting artificial limb (prosthesis). A prosthetic device that does not fit properly can be the source of phantom limb pain.\nIs it Possible to Prevent Phantom Limb Pain?\nIf a person experiences pain in a limb scheduled for amputation, there is a greater risk of developing phantom pain after the amputation. Some doctors recommend a regional anesthetic (spinal or epidural) beginning a few days before the scheduled amputation. The anesthetic may help reduce pain immediately following surgery, and reduce the risk of chronic phantom limb pain.\nNovus Spine & Pain Center\nIt is important to immediately discuss any phantom pain with your doctor, because early treatment by an experienced pain management expert can help reduce the chances of the pain developing into a chronic condition.\nNovus Spine & Pain Center is in Lakeland, Florida, and specializes in treating phantom limb pain. By using a comprehensive approach and cutting edge therapies, we work together with patients to restore function and regain an active lifestyle, while minimizing the need for opiates."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:f2e17aee-e9ef-4da1-97dd-465de0601b74>","<urn:uuid:9e2b063b-591f-4997-b13c-68bdfddc59de>"],"error":null}
{"question":"What are the unique reproductive capabilities of ray-finned fish, and how does this compare to the absorption process of turmeric in the human body?","answer":"Ray-finned fish exhibit diverse reproductive patterns, with most species having separate sexes and external fertilization where females spawn eggs that males fertilize afterward. Some species show sequential hermaphroditism, primarily protogyny where females convert to males. A unique example is the mangrove rivulus, which can self-fertilize as a simultaneous hermaphrodite. As for turmeric absorption, it has poor bioavailability in the human body, being quickly metabolized and removed by the liver and intestinal wall. However, its absorption can be significantly enhanced by combining it with black pepper, which contains piperine. This compound slows the liver's metabolism of curcumin, increasing its bioavailability by up to 2000% and extending its presence in body tissues.","context":["The ray-finned fishes are so called because they possess lepidotrichia or \"fin rays\", their fins being webs of skin supported by bony or horny spines (\"rays\"), as opposed to the fleshy, lobed fins that characterize the class Sarcopterygii which also, however, possess lepidotrichia. These actinopterygian fin rays attach directly to the proximal or basal skeletal elements, the radials, which represent the link or connection between these fins and the internal skeleton (e.g., pelvic and pectoral girdles).\nNumerically, actinopterygians are the dominant class of vertebrates, comprising nearly 99% of the over 30,000 species of fish. They are ubiquitous throughout freshwater and marine environments from the deep sea to the highest mountain streams. Extant species can range in size from Paedocypris, at 8 mm (0.3 in), to the massive ocean sunfish, at 2,300 kg (5,070 lb), and the long-bodied oarfish, at 11 m (36 ft).\nFinding the coelacanth dinofish\nRay-finned fishes occur in many variant forms. The main features of a typical ray-finned fish are shown in the diagram at the left.\nIn nearly all ray-finned fish, the sexes are separate, and in most species the females spawn eggs that are fertilized externally, typically with the male inseminating the eggs after they are laid. Development then proceeds with a free-swimming larval stage. However other patterns of ontogeny exist, with one of the commonest being sequential hermaphroditism. In most cases this involves protogyny, fish starting life as females and converting to males at some stage, triggered by some internal or external factor. This may be advantageous as females become less prolific as they age while male fecundity increases with age. Protandry, where a fish converts from male to female, is much less common than protogyny. Most families use external rather than internal fertilization. Of the oviparousteleosts, most (79%) do not provide parental care. Viviparity, ovoviviparity, or some form of parental care for eggs, whether by the male, the female, or both parents is seen in a significant fraction (21%) of the 422 teleost families; no care is likely the ancestral condition. Viviparity is relatively rare and is found in about 6% of teleost species; male care is far more common than female care. Male territoriality \"preadapts\" a species for evolving male parental care.\nThere are a few examples of fish that self-fertilise. The mangrove rivulus is an amphibious, simultaneous hermaphrodite, producing both eggs and spawn and having internal fertilisation. This mode of reproduction may be related to the fish'S habit of spending long periods out of water in the mangrove forests it inhabits. Males are occasionally produced at temperatures below 19 °C (66 °F) and can fertilise eggs that are then spawned by the female. This maintains genetic variability in a species that is otherwise highly inbred.\nThe earliest known fossil actinopterygiian is Andreolepis hedei, dating back 420 million years (Late Silurian). Remains have been found in Russia, Sweden, and Estonia.\nActinopterygians are divided into the subclasses Chondrostei and Neopterygii. The Neopterygii, in turn, are divided into the infraclasses Holostei and Teleostei. During the Mesozoic and Cenozoic the teleosts in particular diversified widely, and as a result, 96% of all known fish species are teleosts. The cladogram shows the major groups of actinopterygians and their relationship to the terrestrial vertebrates (Tetrapods) that evolved from a related group of fish. Approximate dates are from Near et al., 2012.","Improve the Benefits of Turmeric by Adding Black Pepper\nThis article looks at turmeric and why we should be including black pepper in our meal, to increase the benefits associated with using turmeric.\nTurmeric is increasing in popularity for its health benefits, having been used in Ayurvedic medicine over 5,000 years ago!\nBlack pepper in its own right, also, has an abundant amount of health benefits. It is a great source of manganese, which helps the body form connective tissues, bones and sex hormones. However, there is also another beneficial function of black pepper, when you combine it with turmeric, which we will now look at.\nTurmeric contains a compound called curcumin, a bright yellow chemical, which gives turmeric its vibrant colour. Curcumin has been identified as being beneficial for its anti-inflammatory properties.\nWhen you ingest turmeric with black pepper, you are increasing the amount of the curcumin you can absorb and your body can use.\nCurcumin has been associated with numerous health benefits including anti-inflammatory and an antioxidant, protecting healthy cells from free radicals which can cause damage.\nThe reason that black pepper enables this increase in our body using curcumin, is due to piperine a compound found in black pepper, which slows our liver from metabolising the curcumin too quickly and removing it through urine.\nBy slowing this process our body is able to utilise more of the curcumin and its beneficial effects!\nCurcumin is quickly metabolised and removed from the body by the liver and the intestinal wall, due to its poor bioavailability.\nWhat is ‘Bioavailability’?\nThe bioavailability of a food is the amount of a nutrient which is available and readily absorbed by the body to use for metabolic purposes in the body, from the food that we ingest.\nSome nutrients have a high bioavailability and can be digested, absorbed and metabolised by the body with ease, however, when it has a poor or low bioavailability (certain vitamins and minerals) the process of digestion, absorption and metabolism can vary and this can also be impacted by other vitamins and minerals that we consume these can either inhibit or facilitate these processes.\nTo facilitate our body to increase the bioavailability of curcumin it has been found that adding black pepper enables this increase in bioavailability.\nA 6 month randomised, double-blinded and placebo controlled (high standard for testing) study, on subjects diagnosed with type 2 diabetes, found that those who were not taking the placebo and had 3 capsules twice a day of curcumin, had a lower atherogenic risk, and an improvement in their metabolic profile (Chuengsamarn et al., 2014).\nPiperine in Black Pepper\nThe compound, piperine, found in black pepper is what gives black pepper its taste.\nPiperine has been shown to increase the bioavailability of nutrients in both food and supplements. This includes selenium, the B vitamins, and beta-carotene.\nPiperine has also been found to support and enhance the liver’s detoxification process (Murray et al., 2005).\nThe way that piperine enables the increase of bioavailability of nutrients and in this case curcumin, is that it inhibits the rate of metabolism of curcumin by increasing the time it resides in the intestines to increase intestinal absorption, and inhibits some of the enzymes (which are drug detoxifying enzymes) in the intestines that would usually break down and metabolise the curcumin (Ajazuddin, 2014).\nThis process of inhibiting enzymes is beneficial in the case for increasing the bioavailability of curcumin and another compound called EGCG (a polyphenol found in green tea which has been linked to certain health benefits). However, this can also negatively implicate the process in which our body excretes excess drugs through urine, halting the process, leading to elevated levels of the drugs in our system. This excretion of drugs helps to protect us from toxic chemical substances.\nA study found that when participants took a 2g capsule of curcumin alone, it was found at undetectable or very low levels in the serum levels in the blood (Shoba et al., 1998).\nWhen it was accompanied with 20mg of piperine, a higher concentration of serum levels was found from 0.25 to 1-hour post administration, the researchers found an increase in bioavailability of 2000%. It was found that piperine increases the bioavailability of curcumin with no adverse effects (Shoba et al., 1998).\nIt was also found that when curcumin and piperine are administered together, the intestinal absorption rate increased, and stayed significantly longer in the body tissue than when curcumin was administered alone (Suresh and Srinivasan, 2010).\nHow Much Black Pepper Do You Need?\nAlthough there is limited information on how much black pepper is required to aid bioavailability, it is advised that we eat between 1 to 3g of powdered turmeric a day.\n5% of turmeric is composed of curcumin, and 5% (varies between 4.6%-9.7%) of black pepper (by weight) is composed of piperine. Sources state that even just 1/20th of black pepper can increase the bioavailability, and just 20mg of piperine is effective in enhancing bioavailability.\nAddition of Fat\nThe curcumin is also fat-soluble, which means that it needs fat to be dissolved and then absorbed directly into the bloodstream, where it does not need to be metabolised by the liver.\nIn meals where turmeric is used, there is usually a fat and black pepper in the meal, which aids the bioavailability and absorption of the turmeric. This is why in our turmeric latte, we include both black pepper and Lucy Bee Coconut Oil.\nStorage and Use of Pepper and Turmeric\nTo get the best flavour from your pepper, you should buy whole peppercorns, and grind them up yourself. This means that you will just be receiving peppercorns, and not pepper with other spices, which can happen when you purchase pre-ground pepper.\nYou should store pepper in a cool, dark and dry place. It is also best if you add pepper towards the end of cooking, as the oils in the pepper lose their flavour and aroma if heated for too long.\nYou can get turmeric in powdered form or fresh. When fresh it should be kept in the refrigerator, where it can last for a month. You can also slice it and store it in an airtight container for 3 months.\nIf using powder, you should store it in a tightly sealed container in a cool, dark and dry place, where it will last for up to a year.\nPoints to Note\nIf you suffer with a history of oxalate-containing kidney stones, you should avoid over consuming black pepper as it contains low amounts of oxalates (these prevent the absorption of calcium) (Murray et al., 2005).\nAs black pepper slows down the rate that the liver clears drugs, it is advised not to consume over 1tsp. a day with certain medications – please consult your health advisor if you are considering consuming over 1tsp. a day and on medication including digoxin or phenytoin (Turmeric for Health, 2016).\nUnless advised or discussed with your health professional, there is no need to take turmeric capsules. You can use the powered or fresh turmeric within meals and drinks.\nLong term ingestion of turmeric capsules may lead to nausea, diarrhoea, stomach ulcers, and other problems.\nResearch has shown that turmeric may slow blood clotting, so if you’re taking medication for blood thinning you should talk to your health advisor as well, before considering taking turmeric supplements.\nIt is also recommended that pregnant women do not take turmeric supplements as it can stimulate the uterus which can cause menstrual flow, but is safe to use when seasoning foods.\nBoth turmeric and black pepper have been used in Ayurvedic medicine. Black pepper is indigenous to Kerala, and in Ayurvedic medicine it was known as an important healing spice. It was combined with long pepper and ginger, forming a herbal blend called trikatu, an important ingredient in Ayurvedic formulas.\nBlack pepper was highly prized within trading and expensive to buy – it was even found stuffed in Ramessess II nostrils as part of the mummification process.\nIn Ayurvedic medicine, turmeric was believed to balance the three doshas, and was taken both internally and externally to help with a variety of ailments (Gallant, 2016).\nTurmeric has an abundance of beneficial health effects that you can research and read up on, especially with more research being conducted on just how powerful it is.\nJust be warned when it gets onto your hands it can stain them yellow!!\nI even put it on my fried egg (cooked in Lucy Bee Coconut Oil) in the morning, with some black pepper, delicious!\nAjazuddin. Alexander, A. Qureshi, A. Kumari, L. Vaishnav, P. Sharma, M. Saraf, S. and Saraf, S. (2014). Role of herbal bioactives as a potential bioavailability enhancer for active pharmaceutical ingredients. Fitoterapia, 97, pp. 1-14.\nChuengsamarn, S. Rattanamongkolgul, S. Phonrat, B. Tungtrongchitr, R. and Jirawatnotai, S. (2014). Reduction of atherogenic risk in patients with type 2 diabetes by curcuminoid extract: a randomized controlled trial. The Journal of Nutritional Biochemistry, 25(2), pp. 144-150.\nGallant, L. (2016). Turmeric: “The Golden Goddess”. California College of Ayurveda, available: http://www.ayurvedacollege.com/articles/students/turmeric#Turmeric_and_Ayurveda\nMurray, M. T. Pizzorno, J. E. and Pizzorno, L. (2005). Black Peppercorn, Turmeric. The Encyclopaedia of Healing Foods, pp. 502-523.\nShoba, G, Joy, D. Joseph, T. Majeed, M. Rajendran, R. and Srinivas, P. S. (1998). Influence of piperine on the pharmacokinetics of curcumin in animals and human volunteers. Planta Medica, 64(4), pp. 353-356.\nSuresh, D. and Srinivasan, K. (2010). Tissue distribution & elimination of capsaicin, piperine & curcumin following oral intake in rats. Indian J Med Res, 131 pp. 682–691\nTurmeric for health, http://www.turmericforhealth.com/turmeric-benefits/health-benefits-of-black-pepper-and-turmeric\nAbout Lucy Bee Limited\nLucy Bee is concerned with Fair Trade, ethical and sustainable living, recycling and eating close to nature with additive free products for health.\nMembers of the Lucy Bee team are not medically trained and can only offer their best advice. Any information provided by us is not intended to diagnose, treat, cure or prevent disease.\nPlease note you should always refer your health queries to a qualified medical practitioner."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:6519f097-9ed5-453e-b5b3-42304738da43>","<urn:uuid:b3c39000-c101-4668-b81b-a6b3e1222765>"],"error":null}
{"question":"What are the differences between traditional nomadic lifestyles in Morocco's mountains versus tourism activities in Oman's mountainous regions?","answer":"In Morocco, traditional Berber groups have historically lived a nomadic lifestyle in the mountains, primarily relying on farming and herding animals, though this lifestyle is declining due to climate change. In contrast, Oman's 700 km long mountain range is utilized for organized geotourism activities, offering various themed routes and activities including 4WD tours, hiking, trekking, and mountain biking. While Morocco's mountain regions are associated with traditional subsistence living, Oman has developed its mountainous areas into carefully planned tourist destinations with modern amenities like GPS guidance and multimedia information systems.","context":["Innovative education and sustainable tourism, Oman\nThe Muscat Geotourism Guide, 2012\nA wealth of unique geological attractions in and around Oman’s capital Muscat is waiting to be discovered with support of the Muscat Geotourism Guide. The project, which has been introduced by the Ministry of Tourism, is offering a range of Geotourism activities on different carefully selected tracks, with support of comprehensive media and information, including maps, signboards as well as smart phone applications.\nGet more informations\nOman is located on the eastern edge of the Arabian Peninsula. It has great geological diversity with mountain ranges reaching 3,000 meters high in the north, green oases in the south, and a desert plain in between.\nA geologist once said that Oman is one big wonderful outdoor geological Museum with unique geological values. It is the only country in the world composed mostly of oceanic crust and rocks that originated from the mantle – deep below the earth’s surface. In addition, evidence can be seen of continental drift and geological processes that have dominated the earth’s surface for many millions of years.\nTherefore Oman is a well known hot spot for Geotourism activities. Geotourism has been described as a form of natural area tourism that specifically focuses on geology and landscape. It is based on the magic of discovery and the power of authenticity experienced through contact with the natural heritage of the land.\nIn Oman, geological stories can be found everywhere. Some of these are presented on a dramatic scale such as in the massive folding and faulting that can be seen on parts of Oman’s 700 km long mountain range, or the huge piles of pillow lava in Wadi AI-Jizzi which are evidence of underwater volcanoes releasing magma to be rapidly cooled deep on the ocean floor. Others stories are found in smaller detail, such as how the fossils of sea creatures can be found deep inland or the story of once mighty forests in areas that are now barren deserts.\nThese stories can even be found in the hustle and bustle of urban areas. For example visitors to Muscat Corniche need only to stand and face the ocean in order to imagine the scene back in time around 90 million years ago, when a several kilometer thick slab of the oceanic crust started to push its way over the top of the northern coastline of Oman. This unusual over thrusting continued for around 20 Million years, pushing rocks originating from deep within the ocean hundreds of kilometers inland.\nIn order to provide tourist information and to create awareness about the rich geology in the Muscat Governorate, 6 theme routes, featuring 30 geological attractions, have been developed for a unique Geotourism experience. These theme routes can be experienced on half-day tours or can be combined to joyful day trips. The tours also offer opportunities for different kinds of activities, ranging from a comfortable tour in an air conditioned 4W drive, hiking and trekking tours, mountain bike tours, as well as boat trips including swimming and snorkeling activities.\nThe Muscat Geotourism Guide is the starting point to explore Oman’s geological wonders with support of latest technologies, which will also enhance visitor’s learning experience and at the same time boost enthusiasm for understanding the surroundings in a way that is both fun and instructive. Because of the important contribution towards education and awareness, the project has been awarded twice by UNESCO as an official project of the UN Decade “Education for Sustainable Development”.\nA map is featuring an overview of the Muscat region, detailed maps of the different theme routes and is providing information about the geological features. The map is available for free in English and Arabic at the Ministry of Tourism, in information centers and at various hotels in Muscat.\nNext to the map, smartphone applications for all major operating systems provide GPS guidance on the theme routes and lead visitors safely towards the points of interest. At each attraction the app is providing multimedia information, including sound files. This comprehensive interactive and digital guide is available for free in English, Arabic, German and French from the application stores.\nFinally, wherever the environment allows, one will find signboards close to the geological attractions. The signboards include maps, graphics, and text information. With support of QR-Codes it is also possible to access the multimedia information.","Terrain in Morocco\nMorocco covers an area of more than 446 square kilometres. It has coastlines along both the Mediterranean Sea and the Atlantic Ocean. The interior of the country is mainly mountainous, with the Atlas Mountains, split into three sections, and the Rif Mountains. Lands close to the Sahara Desert are hot and dry, and the large Moroccan Plateau is relatively flat. The plains are used for agriculture, while the drier areas are used to grow many palm trees.\nTraditional Ways of Life in Morocco\nTo a large extent, the two ethnic groups of Morocco—the Arabs and the Berbers—have led very different traditional lives. While the Arabs tended to settle in communities, causing cities and towns to grow and flourish, the Berbers were historically nomadic. If the flatlands of Morocco attracted the Arabs, the mountains were definitely the domain of the Berbers. It is the Arabs who have been responsible for much of Morocco’s striking architecture. That’s not to say, however, that the Berber groups haven’t made huge contributions to the country’s history and culture.\nAlthough many Berber groups now live in mountain villages, they still typically rely on farming to make a living and survive. Additionally, Morocco still has around 25,000 nomadic people, who move around and have no fixed home. For many years there were groups who were always on the move at the fringes of the Sahara Desert, seeking water and grazing land for their animals. The number of nomadic people is decreasing though, with climate change cited as one of the main reasons for people giving up the traditional nomadic way of life.\nHow the Climate Has Altered in Morocco\nGlobal warming has led to the temperatures in Morocco becoming even more extreme. The effects are especially noticed in areas around the desert. Existing high temperatures are becoming even higher. These higher temperatures are causing conditions to be even drier. There is less rainfall, leading to serious droughts. The outlook isn’t positive; experts predict that the temperatures in North Africa, along with the Middle East, will increase twice as quickly as the average around the world.\nImpact on Morocco’s Landscapes\nHot air becomes trapped around the Sahara Desert, which leads to the arid sandy expanses growing. Places that were once arable land are now covered in sand. Land that could previously be used for farming is now barren. Sand is found in areas that were once covered in date palms. There are also fewer places where nomadic herders can find suitable places for their animals. It is gloomily forecast that certain parts of the country will actually become uninhabitable.\nIt isn’t only the expanding desert that spells sorrow for certain parts of Morocco; the lack of rain and the drying up of existing water sources is also a huge effect of the rising temperatures. The Draa River, for example, is now dry for most of the year. (The construction of a dam played a key role, however, in the river ceasing to flow.) When water is found, contamination often means that it isn’t suitable for consumption.\nVillages, such as M’Hamid, have now sprung up in places where once-nomadic people have chosen to settle.\nImpact on Moroccan Life\nThe changing climate and conditions mean that people, nomadic or otherwise, cannot adequately take care of their animals. Goats, sheep, and camels cannot survive. This removes not only meat, milk, skins, and wool from families, some of which would be sold to make an income, but also an important means of transportation. Farmers struggle to grow crops. This has a knock-on effect, with less produce available for the wider community.\nThe change from nomadic life to village life can be a challenge for individuals. Instead of living by the seasons and having huge amounts of independence, people find themselves in unfamiliar situations with a whole host of social rules and expectations that they are just not accustomed to. The vast majority of nomadic people have little to no formal education, making it difficult to secure alternative employment."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:1f311608-cd6c-484d-86bf-5dbc479c2680>","<urn:uuid:5559e013-0b8e-40b4-a4c5-29193a0904fc>"],"error":null}
{"question":"Can you compare what Lean transformation requires versus what DMAIC process involves?","answer":"A Lean transformation requires learning a new way of thinking and acting by addressing key questions about purpose (value for customers), process (continuous improvement), and people (respect and development of employees). The DMAIC process, on the other hand, follows a structured five-phase approach: Define the problem, Measure process parameters, Analyze why problems occur, Improve the process, and Control to maintain improvements. While Lean transformation focuses on organizational mindset and culture change, DMAIC provides a systematic methodology for specific process improvements and problem-solving.","context":["Lean is about creating the most value for the customer while minimizing resources, time, energy and effort. A lean approach to work is about:\n- understanding what’s really going on at the place where value is created – commonly known as the gemba.\n- improving the processes by which products and services are created and delivered.\n- developing and empowering people through problem solving and coaching.\n- developing leaders and an effective management system.\nLean thinking and practice help organizations become both innovative and competitive, which in turn allows them to become sustainable.\nToday, lean has become a new, more effective approach to doing work, no matter what the work is, the sector or the size of the organization. In a lean organization, problems are opportunities for meaningful learning rather than errors to be swept under the rug or quickly resolved. Managers act as coaches, helping others get comfortable identifying problems and practicing daily continuous improvement.\nLeadership means creating a management system to support a new kind of engagement with the real work at hand, the way the work is being done now, not the way you and your teams hope to be doing work sometime in the future. Planet Lean (and the Lean Global Network) aims to inspire people and organizations around the world to embrace lean principles and practices.\nHere’s a few sample stories from our archives, which will show you the far and wide lean has gone… and how many opportunities lie ahead:\n- Every Person Matters – a great story of leadership and transformation in a car dealership, all the way from Botswana\n- How to Transform Your Hospital Using Lean – a fantastic example of how lean is making inroads in the healthcare sectors\n- No Loafing Around – the extraordinary lean-fuelled growth of a chain of bakeries in Barcelona\n- All Rise, Lean Is in Court – not even traditionally stiff government organizations are immune to the power of lean thinking\nWhat lean is not\n- Headcount reduction (“lean = mean”).\n- A set of tools: 5S, Kaizen events, value stream maps, andon, visual management, metrics, dashboards, A3, etc.\n- A program (efficiency, process improvement, performance management, MBO, cost reduction, 6Sigma, etc.) “done” to the people doing the work (and therefore creating value) by management, outsiders or internal expert staff.\n- Something that only applies to manufacturing or operations.\n- Training for certifications and belts.\n- Regimentation through standard work\nWhat is the Lean Global Network’s definition of Lean Thinking & Practice?\nLean thinking and practice is about embracing the challenge of creating more value for each customer and prosperity for society by:\n- Showing respect by developing people to continuously improve the work through problem solving.\n- Focusing on, and continuously, improving the work.\n- Minimizing/eliminating waste — time, human effort, injuries, inventory, capital, space, defects, rework, etc.\n- Asking what type of management behavior and management system is needed to improve and transform the organization.\nTo Improve (or Transform), an Organization Must Address\n- Purpose: What value for customers?\n- Process: How to continuously improve?\n- People: How to respect, engage and develop employees?\nAligning purpose, process and people is the central task of management.\nWhat is a Lean Transformation?\n- Enterprise transformation is the process of an organization shifting its business model to a desired future state.\n- Lean transformation requires learning a new way of thinking and acting, characterized not by implementing a series of steps or solutions, but addressing key questions of purpose, process and people.\nHere’s a video on the LGN’s Lean Transformation Model, narrated by John Shook.","Lean Six Sigma and a sample application\nLean Six Sigma is a concept that aims to improve process performance by minimizing waste and reducing variations. It is a method that combines Lean Manufacturing, Lean Enterprise and Six Sigma principles to eliminate waste and improve quality.\nThe origins of Lean Six Sigma can be traced back to 1986 when Motorola came up with strategies to compete with higher quality Japanese products. Japan used the Kaizen approach (continuous improvement) in product development to produce world-class products of high quality.\nIn the 1990’s, an American businessman called Larry Bossidy introduced Six Sigma in Manufacturing and soon after he was engaged to introduce the concept in GE.\nIn early 2000’s the two concepts of Lean Manufacturing (Reduction of waste) and Six Sigma (higher process quality leading to reduced variability) came together as a single concept called Lean Six Sigma. The concept then found acceptance in other industries such as Healthcare, Finance, Retail and Supply chain etc.\nLean focusses on eight kinds of waste (Muda is Japanese word for waste) inherent in processes;\nSix Sigma focuses on improving the quality of process outputs by identifying and removing the causes of defects and minimising variability in processes.\nLean Six Sigma aims to achieve continuous flow of quality outcomes, by exposing constraints between process steps and reducing variability between and within the process steps through a cycle of iterative improvements. Lean Six Sigma uses the DMAIC (Define, Measure, Analyse, Improve and Control) phases similar to Six Sigma.\nBasic Concepts of Six Sigma\nSix Sigma quality is a statistical term used to indicate how well a process is controlled in terms of its variability from the mean. It is a fundamental nature of any process that over time and scale, variations will creep in due to a variety of reasons or factors. The aim of Six Sigma is to keep the process running within acceptable limits from a mean (or arithmetic average of a process data set).\nThe word Sigma ( σ ) is the standard deviation or the spread around the mean or central tendency. In simple terms, Six Sigma quality performance means 3.4 defects per million opportunities. It is important to note that not all processes, products or systems need to function at Six Sigma quality level. Other than for critical processes involving high safety requirements, such as healthcare, pharmaceuticals, airplanes, manufacturing, etc. it is enough for most processes to function at 3 Sigma or 4 Sigma. The trade-off between achieving Six Sigma or lower levels of Sigma is simply cost and often it is not practical or cost-effective to aim for a high level of Sigma. The table below illustrates the number of defects per million opportunities (DMPO) at various levels of Sigma. It is easily evident as to how efficient processes need to be at Six Sigma level.\nSigma Level DMPO\n2 σ 308,537\n3 σ 66,807\n4 σ 6,210\n5 σ 233\n6 σ 3.4\nLean Six Sigma Case Study\nThe objective of this case study is to illustrate how to apply Six Sigma thinking and concepts to organizational problems and processes.\nImagine a retail organization that uses disparate core systems such as CRM (Customer relationship management), ERP (Enterprise Resource Planning), Analytics and Financial Accounting to run its business. This organization has 100,000 unique Customer master records that are regularly referenced in sales, order management, delivery, invoicing and accounts receivable transactions. Each Customer master record has 10 attributes associated with it as shown below;\nCustomer Master Records (100,000 unique records)\nCustomer Pricing Code\nThis structure implies that there are 1 million elements associated with Customer master data.\nThese Customer master records are created, referenced and updated separately by different individuals, in different departments and business units, depending on their role and function. For example, the Finance Department may manage elements of Customer master data relating to invoicing and accounts receivable. The Sales team may manage elements relating to Customer orders. As is typical in many organizations and situations, disparate systems and independent work functions cause the following issues with Master data;\nDuplicated master data across systems that are out of sync\nWasted effort in data maintenance\nErrors that get accumulated over time because of data changes made in multiple systems\nBusiness risk arising from poor governance, etc.\nDMAIC Approach to improve the process of data management\nThe DMAIC (Define, Measure, Analyse, Improve and Control) concept can be applied to the above case problem, as follows;\nDefine (The Problem)\nMaster Data, maintained separately in multiple business systems, has been observed to contain an unacceptable level of errors (defects) causing unnecessary manual intervention (extra processing) that is costing the organization money, business responsiveness and customer satisfaction.\nMeasure (The Process parameters and Sigma)\nAn important step in Six Sigma Analysis is to measure the key operating parameters of the process in consideration to understand current levels of Sigma (Standard Deviation from mean). The table below shows the impact of errors (Defects per million elements) in terms of cost and time. An error can be broadly defined as any situation relating to any Customer master data element that requires changes to data arising from any non-business driven reason. Sigma (standard deviation) can be determined by sampling in a specific section or department or the entire organization at data element levels or entire Customer Master record levels.\nIt has been assumed that it takes an average of 10 minutes to fix an error at a cost of $50/hour. These assumptions can be validated in the Analysis stage by end users or by Six Sigma experts.\nLet us assume that sampling shows there are likely to be 200,000 errors (20% of the total volume of Customer Master data elements). From the table, we can see that the current process of managing customer master data reveals a Sigma between 2 and 3, implying it is costing the organization at least $556,725 in remediating these process errors. It is useful to note that data volume may also grow at 20% year on year and with growth in master data volume there is also an increase in DMPO.\nAnalysis (Why are there errors in the process?)\nThe errors in the process may be occurring due to one or a combination of the following reasons;\nAsynchronous editing of Customer master data elements in different systems\nLack of a concept of Master data and downstream systems for data leading to uncontrolled changes\nLack of formal data governance policies and procedures defining how Master data is created and edited\nImprove (How can the process be improved?)\nThe process for managing Customer master data and its elements can be improved through several options;\nNominating one of the systems (CRM or ERP or Financial or Analytics systems) as the Master system for Customer data and setting up integrations between that designated Master system to propagate changes\nImplementing a centralized, organization-wide Master Data Management (MDM) system to manage and control all Customer master data. This MDM system will then propagate all changes to master data to all other systems referencing that data through integrations (This may be a costlier option but improve process accuracy the most and help achieve 4 σ or 5 σ efficiencies)\nSetting up a manual governance process to manage changes to Master data in all systems in a coordinated way (This may be the cheapest option but may not improve process accuracy significantly and in a sustained manner)\nControl (How can the process be controlled?)\nRegardless of which option is chosen to improve the process efficiencies, it is important to ensure that process parameters are regularly measured and action taken to remediate. This is done by implementing good data governance initiatives.\nLean Six Sigma is a concept that aims to improve process performance and efficiencies by reducing waste and eliminating errors. It relies on collaboration amongst team members to achieve that. Lean Six Sigma uses the DMAIC (Define, Measure, Analyse, Improve and Control) phases to reduce errors. As such it is a evidence-based, data driven approach to improvement that focuses on defect prevention. Lean Six Sigma initiatives improve customer satisfaction and profitability by reducing variation, waste and cycle time while promoting work standardisation and flow.\nIt is recommended that organizations new to the Lean Six Sigma begin by implementing the Lean approach to make the workplace as effective and efficient as possible, reducing waste and using value stream mapping to improve throughput. When process problems persist, the more technical Six Sigma statistical tools can be applied by a team of specialists in various areas of the overall process."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:b0d3e9ea-13c2-4aff-abac-73ef82ff5390>","<urn:uuid:02bb5903-0b04-4b5d-bf7f-7f6c52131372>"],"error":null}
{"question":"What fertilizer should I use for Martha Washington geraniums to promote blooming?","answer":"For Martha Washington geraniums, avoid high-nitrogen fertilizers. Instead, use a bloom booster-type fertilizer or a high potassium fertilizer developed for vegetables. The nitrogen content (first number) should be no more than half of the other two numbers. For example, use a fertilizer labeled 4-8-10 or 2-4-1, rather than 10-10-10.","context":["Martha Washington Geranium\nEmbrace cool season color with the velvet-petaled Martha Washington Geranium, an old-fashioned favorite that’s tough to beat.\nExpand your geranium horizons with the cool-season member of the family: Martha Washington geranium (Pelargonium x domesticum). Also known as regal geraniums, this group of geraniums features richly colored blooms with petals that resemble velvet. Petals have a lovely ruffled effect that enhances the plants’ luxurious feel.\nThe color range on Martha Washington geranium flowers falls into red-purple shades, including lavender, pink, burgundy and purple. White also appears in the blossom mix, along with a host of wonderfully-painted bicolor blooms. Two common patterns are solid petals with white edging or white centers.\nMartha Washington geraniums have somewhat ruffled leaves in a bright green shade. The edges are often toothed, and leaves release a citrus fragrance when crushed. Overall, Martha Washington geraniums grow roughly 12 to 18 inches tall and 12 to 24 inches wide. The flowers appear in clusters similar to zonal geraniums, but stems tend to be shorter, making a Martha Washington geranium frequently appear to be overloaded with flowers.\nThese pretty bloomers grow best when air temperatures are below 60°F. Martha Washington geraniums set their flower buds when night temperatures hover in the 50- to 60-degree range. As a result, they’re popular as spring plants, most often bought as gifts for spring holidays, such as Easter or Mother’s Day. Once summer temperatures arrive, plants usually stop flowering. If you like the look of Martha Washington geraniums and live where summer brings on some sizzle, plan to pull plants out of pots or planting beds as heat arrives and replace them with traditional garden or zonal geraniums.\nMartha Washington geraniums prefer fertile, well-drained soil. In landscape beds, amend soil with plenty of organic matter prior to planting. In containers, use a commercial soil-less mix developed for use in planters. These mixes provide the right drainage for plants in a container to thrive. Martha Washington geraniums are susceptible to root rot, so avoid overwatering plants or tucking them into heavy clay soils in planting beds.\nPlace your Martha Washington geraniums where they’ll receive direct sun, but protect them from hottest afternoon sun in all regions. If plants don’t get enough sunlight, flower numbers drop. Encourage flower formation by removing spent blooms. This also helps reduce fungus development on rotting blooms. If you see any signs of fuzzy mold-type growth (botrytis) on Martha Washington geraniums or orange or brown spots on leaves, remove affected plant parts and destroy them.\nAvoid using high-nitrogen fertilizers on Martha Washington geraniums. Instead, select a bloom booster-type fertilizer that helps promote flower formation. A high potassium fertilizer developed for vegetables works well, too. On the fertilizer bag, the first number, which represents nitrogen content, should be no more than half of the other two numbers. For instance, a fertilizer labeled 10-10-10 isn’t the right type to use. Instead, use one labeled like 4-8-10, which is typically a flower and/or vegetable fertilizer, or 2-4-1, a typical fish-based plant food."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:0eed9a2a-91e0-4c39-9da7-6dc78ef86335>"],"error":null}
{"question":"What are the main differences between American and Japanese approaches to business relationships and agreements?","answer":"American and Japanese business cultures show distinct approaches to relationships and agreements. In the US, agreements are typically precise and contractual in nature, with quick decision-making being valued - superiors give significant leeway to subordinates to make decisions rapidly. In contrast, Japanese business culture places greater emphasis on building relationships of trust, as there is a tendency to settle issues as they arise rather than defining everything upfront in contracts. This connects to their longer-term orientation, where Japanese managers are known for taking a long-term view and accepting extended periods before achieving profitability, while American managers typically prefer to see quick results.","context":["Hofstede canada vs japan\n10 cultural contrasts between us & japanese companies btrax staff japan speed vs consistency: generally us company's decision making is quick superiors give some great leeway to subordinates so that they can decide and make decisions quickly. Lesson 10, reflects the nations of asia, and china according to hofstede's cultural dimensions, specifically regarding the nation of china who accrued the score of 80 percent in regards to the power distance perspective, which fosters the following belief at 80 china sits in the higher. In practical terms, this refers to long-term vs short-term orientation of life and is composed of the following values on the long-term orientation axis we have: persistence japan - 80 south korea - 75 brazil - 65 india - 61 thailand hofstede, geert (1997) culture. Professor geert hofstede conducted one of the most significant studies on how culture influences workplace values hofstede's most recent publications included 93 countries he emphasizes and studies five dimensions of culture: power distance (pdi) - power distance is the extent to.\nIndividualism vs collectivism individual group us, canada, uk, scandinavia, new zealand, australia, switzerland latin-america, africa, japan. 49 in every 100,000 people are currently imprisoned in japan compared to 118 in canada this entry contains the number of people in penal institutions, including pre-trial detainees. Canadian etiquette, business culture, manners, and geert hofstede analysis for canada. Trompenaars and hampden-turner's seven dimensions of culture model helps you work better with people from different cultures canada, the uk, the netherlands, germany, scandinavia and japan 3 specific versus diffuse (how far people get involved) dimension characteristics strategies. Japan, or japanese business culture, etiquette, manners, and geert hofstede analysis.\nHofstede's cultural dimensions us vs india geert hofstede's theory of cultural dimensions was a result of an analysis of a world-wide survey of employee values by ibm in the 1960's and 1970's japan vs us essay those countries on india and canada. Canada: geert hofstede analysis canada: geert hofstede analysis the majority of canadians have individualism ranked highest ethnocentrism is high throughout canada, but particularly in quebec canada has individualism (idv) as the highest ranking. Hofstede and schwartz's models for classifying individualism at the cultural level: their relation to macro-social and macro-economic tural values to that developed by hofstede (1984) cultures can be accounted for by seven basic cultural values (schwartz, 1994). Communication and culture these learned rules, values and beliefs become 'the software of the mind' (hofstede, 1992) or the filter through which we interpret events around us the canada-japan co-op program 2385 east mall, vancouver, bc, v6t 1z4, canada.\nHofstede canada vs japan\nJapan watching society, politics, culture, economy, environment how different are the japanese wednesday are less submissive tend to be advanced democracies, countries like austria, israel, new zealand, ireland, australia, canada, finland, germany, netherlands, norway, sweden. This article looks at the differences between danish and japanese national culture two using the cultural model created by geert hofstede below i offer a brief. Geert hofstede and cultural-dimensions theory an overview geert hofstede is a dutch social psychologist and anthropologist who has studied the interactions between cultures.\nOur expectations concerning the differences in individualistic and collectivistic tendencies of college students in japan and the united states are grounded primarily in 1) hofstede's (1980. View hofstede's six dimensions of culture united states vs japan from org 300 at csu-global campus running head: hofstedes six dimensions of culture: united states vs ja hofstedes six dimensions. High vs low uncertainty avoidance refers to the degree to which the members of a society feel comfortable hofstede's data showed the following canada, germany, and japan) johnson, h t and a broms 2000 profit beyond measure: extraordinary results through attention to work. Culturally speaking: individualism-collectivism cultural differences: individualism and collectivism china (20), thailand (20), us (91), japan (46), world average (43) individualistic versus collectivist 1) china is more _____ than thailand 2) the us is more _____ than china 3) thailand is.\nDifferent cultures, different styles dr hofstede found that canada and the us are low in uncertainty avoidance dr hofstede discovered that japan rated high on masculine dimensions males expect an in-charge role. Some recent reading (james hunt & joseph weintraub's the coaching manager and terry bacon & karen spear's adaptive coaching) led to further thinking about the dimensions of cultural difference: what are the ways in which cultures differ how do we. Canada chile china colombia costa rica czech republic denmark east africa ecuador el salvador japan mexico - mexican geert hofstede cultural dimensions explained 3 of 3 8/2/2007 7:32 am contemplative. Hofstede's studies this dimension is often renamed by users of hofstede's work, eg to quantity of life vs quality of life north america and europe can be considered as individualistic with relatively high scores: for example, 80 for canada and hungary in contrast.","Culture and Subculture\nCulture is part of the external influences that impact the consumer. That is, culture represents influences that are imposed on the consumer by other individuals.\nThe definition of culture offered in one textbook is “That complex whole which includes knowledge, belief, art, morals, custom, and any other capabilities and habits acquired by man person as a member of society.” From this definition, we make the following observations:\n- Culture, as a “complex whole,” is a system of interdependent components.\n- Knowledge and beliefs are important parts. In the U.S., we know and believe that a person who is skilled and works hard will get ahead. In other countries, it may be believed that differences in outcome result more from luck. “Chunking,” the name for China in Chinese, literally means “The Middle Kingdom.” The belief among ancient Chinese that they were in the center of the universe greatly influenced their thinking.\n- Other issues are relevant. Art, for example, may be reflected in the rather arbitrary practice of wearing ties in some countries and wearing turbans in others. Morality may be exhibited in the view in the United States that one should not be naked in public. In Japan, on the other hand, groups of men and women may take steam baths together without perceived as improper. On the other extreme, women in some Arab countries are not even allowed to reveal their faces. Notice, by the way, that what at least some countries view as moral may in fact be highly immoral by the standards of another country. For example, the law that once banned interracial marriages in South Africa was named the “Immorality Act,” even though in most civilized countries this law, and any degree of explicit racial prejudice, would itself be considered highly immoral.\nCulture has several important characteristics: (1) Culture is comprehensive. This means that all parts must fit together in some logical fashion. For example, bowing and a strong desire to avoid the loss of face are unified in their manifestation of the importance of respect. (2) Culture is learned rather than being something we are born with. We will consider the mechanics of learning later in the course. (3) Culture is manifested within boundaries of acceptable behavior. For example, in American society, one cannot show up to class naked, but wearing anything from a suit and tie to shorts and a T-shirt would usually be acceptable. Failure to behave within the prescribed norms may lead to sanctions, ranging from being hauled off by the police for indecent exposure to being laughed at by others for wearing a suit at the beach. (4) Conscious awareness of cultural standards is limited. One American spy was intercepted by the Germans during World War II simply because of the way he held his knife and fork while eating. (5) Cultures fall somewhere on a continuum between static and dynamic depending on how quickly they accept change. For example, American culture has changed a great deal since the 1950s, while the culture of Saudi Arabia has changed much less.\nDealing with culture. Culture is a problematic issue for many marketers since it is inherently nebulous and often difficult to understand. One may violate the cultural norms of another country without being informed of this, and people from different cultures may feel uncomfortable in each other’s presence without knowing exactly why (for example, two speakers may unconsciously continue to attempt to adjust to reach an incompatible preferred interpersonal distance).\nWarning about stereotyping. When observing a culture, one must be careful not to over-generalize about traits that one sees. Research in social psychology has suggested a strong tendency for people to perceive an “outgroup” as more homogenous than an “ingroup,” even when they knew what members had been assigned to each group purely by chance. When there is often a “grain of truth” to some of the perceived differences, the temptation to over-generalize is often strong. Note that there are often significant individual differences within cultures.\nCultural lessons. We considered several cultural lessons in class; the important thing here is the big picture. For example, within the Muslim tradition, the dog is considered a “dirty” animal, so portraying it as “man’s best friend” in an advertisement is counter-productive. Packaging, seen as a reflection of the quality of the “real” product, is considerably more important in Asia than in the U.S., where there is a tendency to focus on the contents which “really count.” Many cultures observe significantly greater levels of formality than that typical in the U.S., and Japanese negotiator tend to observe long silent pauses as a speaker’s point is considered.\nCultural characteristics as a continuum. There is a tendency to stereotype cultures as being one way or another (e.g., individualistic rather than collectivistic). Note, however, countries fall on a continuum of cultural traits. Hofstede’s research demonstrates a wide range between the most individualistic and collectivistic countries, for example—some fall in the middle.\nHofstede’s Dimensions. Gert Hofstede, a Dutch researcher, was able to interview a large number of IBM executives in various countries, and found that cultural differences tended to center around four key dimensions:\n- Individualism vs. collectivism: To what extent do people believe in individual responsibility and reward rather than having these measures aimed at the larger group? Contrary to the stereotype, Japan actually ranks in the middle of this dimension, while Indonesia and West Africa rank toward the collectivistic side. The U.S., Britain, and the Netherlands rate toward individualism.\n- Power distance: To what extent is there a strong separation of individuals based on rank? Power distance tends to be particularly high in Arab countries and some Latin American ones, while it is more modest in Northern Europe and the U.S.\n- Masculinity vs. femininity involves a somewhat more nebulous concept. “Masculine” values involve competition and “conquering” nature by means such as large construction projects, while “feminine” values involve harmony and environmental protection. Japan is one of the more masculine countries, while the Netherlands rank relatively low. The U.S. is close to the middle, slightly toward the masculine side. ( The fact that these values are thought of as “masculine” or “feminine” does not mean that they are consistently held by members of each respective gender—there are very large “within-group” differences. There is, however, often a large correlation of these cultural values with the status of women.)\n- Uncertainty avoidance involves the extent to which a “structured” situation with clear rules is preferred to a more ambiguous one; in general, countries with lower uncertainty avoidance tend to be more tolerant of risk. Japan ranks very high. Few countries are very low in any absolute sense, but relatively speaking, Britain and Hong Kong are lower, and the U.S. is in the lower range of the distribution.\nAlthough Hofstede’s original work did not address this, a fifth dimension of long term vs. short term orientation has been proposed. In the U.S., managers like to see quick results, while Japanese managers are known for take a long term view, often accepting long periods before profitability is obtained.\nHigh vs. low context cultures: In some cultures, “what you see is what you get”—the speaker is expected to make his or her points clear and limit ambiguity. This is the case in the U.S.—if you have something on your mind, you are expected to say it directly, subject to some reasonable standards of diplomacy. In Japan, in contrast, facial expressions and what is not said may be an important clue to understanding a speaker’s meaning. Thus, it may be very difficult for Japanese speakers to understand another’s written communication. The nature of languages may exacerbate this phenomenon—while the German language is very precise, Chinese lacks many grammatical features, and the meaning of words may be somewhat less precise. English ranks somewhere in the middle of this continuum.\nEthnocentrism and the self-reference criterion. The self-reference criterion refers to the tendency of individuals, often unconsciously, to use the standards of one’s own culture to evaluate others. For example, Americans may perceive more traditional societies to be “backward” and “unmotivated” because they fail to adopt new technologies or social customs, seeking instead to preserve traditional values. In the 1960s, a supposedly well read American psychology professor referred to India’s culture of “sick” because, despite severe food shortages, the Hindu religion did not allow the eating of cows. The psychologist expressed disgust that the cows were allowed to roam free in villages, although it turns out that they provided valuable functions by offering milk and fertilizing fields. Ethnocentrism is the tendency to view one’s culture to be superior to others. The important thing here is to consider how these biases may come in the way in dealing with members of other cultures.\nIt should be noted that there is a tendency of outsiders to a culture to overstate the similarity of members of that culture to each other. In the United States, we are well aware that there is a great deal of heterogeneity within our culture; however, we often underestimate the diversity within other cultures. For example, in Latin America, there are great differences between people who live in coastal and mountainous areas; there are also great differences between social classes.\nLanguage issues. Language is an important element of culture. It should be realized that regional differences may be subtle. For example, one word may mean one thing in one Latin American country, but something off-color in another. It should also be kept in mind that much information is carried in non-verbal communication. In some cultures, we nod to signify “yes” and shake our heads to signify “no;” in other cultures, the practice is reversed. Within the context of language:\n- There are often large variations in regional dialects of a given language. The differences between U.S., Australian, and British English are actually modest compared to differences between dialects of Spanish and German.\n- Idioms involve “figures of speech” that may not be used, literally translated, in other languages. For example, baseball is a predominantly North and South American sport, so the notion of “in the ball park” makes sense here, but the term does not carry the same meaning in cultures where the sport is less popular.\n- Neologisms involve terms that have come into language relatively recently as technology or society involved. With the proliferation of computer technology, for example, the idea of an “add-on” became widely known. It may take longer for such terms to “diffuse” into other regions of the world. In parts of the World where English is heavily studied in schools, the emphasis is often on grammar and traditional language rather than on current terminology, so neologisms have a wide potential not to be understood.\n- Slang exists within most languages. Again, regional variations are common and not all people in a region where slang is used will necessarily understand this. There are often significant generation gaps in the use of slang.\nWriting patterns, or the socially accepted ways of writing, will differs significantly between cultures.\nIn English and Northern European languages, there is an emphasis on organization and conciseness. Here, a point is made by building up to it through background. An introduction will often foreshadow what is to be said. In Romance languages such as Spanish, French, and Portuguese, this style is often considered “boring” and “inelegant.” Detours are expected and are considered a sign of class, not of poor organization. In Asian languages, there is often a great deal of circularity. Because of concerns about potential loss of face, opinions may not be expressed directly. Instead, speakers may hint at ideas or indicate what others have said, waiting for feedback from the other speaker before committing to a point of view.\nBecause of differences in values, assumptions, and language structure, it is not possible to meaningfully translate “word-for-word” from one language to another. A translator must keep “unspoken understandings” and assumptions in mind in translating. The intended meaning of a word may also differ from its literal translation. For example, the Japanese word hai is literally translated as “yes.” To Americans, that would imply “Yes, I agree.” To the Japanese speaker, however, the word may mean “Yes, I hear what you are saying” (without any agreement expressed) or even “Yes, I hear you are saying something even though I am not sure exactly what you are saying.”\nDifferences in cultural values result in different preferred methods of speech. In American English, where the individual is assumed to be more in control of his or her destiny than is the case in many other cultures, there is a preference for the “active” tense (e.g., “I wrote the marketing plan”) as opposed to the passive (e.g., “The marketing plan was written by me.”)\nBecause of the potential for misunderstandings in translations, it is dangerous to rely on a translation from one language to another made by one person. In the “decentering” method, multiple translators are used.\nThe text is first translated by one translator—say, from German to Mandarin Chinese. A second translator, who does not know what the original German text said, will then translate back to German from Mandarin Chinese translation. The text is then compared. If the meaning is not similar, a third translator, keeping in mind this feedback, will then translate from German to Mandarin. The process is continued until the translated meaning appears to be satisfactory.\nDifferent perspectives exist in different cultures on several issues; e.g.:\n- Monochronic cultures tend to value precise scheduling and doing one thing at a time; in polychronic cultures, in contrast, promptness is valued less, and multiple tasks may be performed simultaneously. (See text for more detail).\n- Space is perceived differently. Americans will feel crowded where people from more densely populated countries will be comfortable.\n- Symbols differ in meaning. For example, while white symbols purity in the U.S., it is a symbol of death in China. Colors that are considered masculine and feminine also differ by culture.\n- Americans have a lot of quite shallow friends toward whom little obligation is felt; people in European and some Asian cultures have fewer, but more significant friends. For example, one Ph.D. student from India, with limited income, felt obligated to try buy an airline ticket for a friend to go back to India when a relative had died.\n- In the U.S. and much of Europe, agreements are typically rather precise and contractual in nature; in Asia, there is a greater tendency to settle issues as they come up. As a result, building a relationship of trust is more important in Asia, since you must be able to count on your partner being reasonable.\n- In terms of etiquette, some cultures have more rigid procedures than others. In some countries, for example, there are explicit standards as to how a gift should be presented. In some cultures, gifts should be presented in private to avoid embarrassing the recipient; in others, the gift should be made publicly to ensure that no perception of secret bribery could be made."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:1382d62c-ba8b-415e-97eb-f3ad08aa9b2a>","<urn:uuid:cbfb9446-7b6c-4c2c-9d6f-c11d52280bc4>"],"error":null}
{"question":"What's the financial investment needed for a vineyard, and what frost protection methods can prevent damage? 🍇","answer":"Initial vineyard investment requires around £30,000 per hectare plus equipment costs, with payback expected around year 9 without frost damage. For frost protection, both passive and active methods can be used. Passive methods include site selection (mid-slope positions are warmer), varietal selection (choosing late bud burst varieties), and pruning techniques. Active protection methods include wind machines (providing 1-3°F temperature differences), over-vine sprinklers, heaters, and burning straw. Active methods work mainly against radiational frost, while advective freeze is harder to protect against.","context":["© Viv Blakey\nWith direct farm subsidy payments set to reduce after 2021, farmers are looking at additional income streams to keep farms sustainable. There are many ways to be involved in the English wine sector and not all require vine-to-bottle production. It is possible to grow grapes under contract for established wineries; sell grapes on the stock market or even make wine for others.\nMy father and I enrolled in a viticulture for dummies course a few years ago. We’re farmers and growers, so we decided to just grow the grapes because that’s our expertise, but there’s still a whole business infrastructure and forecasting to put in place. We contacted consultants who set up and install vineyards and supply everything.\nOur business consultants helped us with a 10-year forecast business plan, both with and without the vineyard, to see the profitability of both scenarios and make sure it was all sound. Vinescapes talked to us about frost risk and climatology. Then the bank manager came out. I contacted wineries in Sussex and Hampshire to see if they would be interested in us supplying them with grapes. We then worked out a 5-year deal with Ridgeview in Ditchling, Sussex. In May 2017, we planted the first vines on 20 acres in Suffolk.\nWe grow the 3 classic grapes for English sparkling wine, which is the big seller and award winner: 50% Chardonnay, 15% Pinot Meunier and 35% Pinot Noir.\n\"It’s a long-term project with a 35-year life, I think you have to invest early\"\nYou can grow grapes on a budget if you do all the work yourself. Some of this was in our plan, but we didn’t have time to do it all ourselves. When we bought the tractor and sprayer, we went for reliability and a higher cost than I’d budgeted. I bought a new sprayer from a German dealer and paid in euros which saved me £6,000. Then there’s frost protection – we went down the route of cold air drains from Australia. We got a 40% leader grant for the fans, which is still available. You have to go into it understanding that you will be writing cheques for 4 years before you get any money coming back in. Which means you need a bank manager that understands your business and the project well.\nIt’s a long-term project with a 35-year life. I think you have to invest early. Don’t assume you can spread expenses over that 35-year span. Take a deep breath and buy that fancy recycling sprayer. Cutting corners means cutting the quality of grapes. I would say you need to invest close to £30,000 per hectare for something of this size, plus the cost of equipment. The profit is a complete turnaround compared to wheat, which is relatively easy to grow. For us, the biggest risk is frost. Our business plan says we will get payback in year 9 if we don’t have frost. Lots of factors are out of your control. Weather is important. Grapes need some rainfall to replenish and keep growing but towards harvest time from the end of September to the beginning of October you want dry, bright, sunny weather and a good site on a south-facing slope.\nHaving the right people around you is important; an agronomist, a vineyard manager. Delegate, and let them answer the questions. I’m still learning, we’re only 3 years in, so now I’m about 80% confident about my decisions but I think there’s a risk in making all the decisions yourself without talking it through.\nThrough the grapevine: the figures\nThere’s a saying in the wine sector: \"To make a small fortune start with a large one.\" The initial capital cost involved in a vineyard is hard to estimate because it’s dependent on size. Once you get to a certain size you get economies of scale because regardless of the size of the vineyard you can’t live without machinery, tractors, a sprayer. Some things you can hire or contract people to do and a lot depends on how much groundwork is needed and your location. For instance, where we are in Alfriston, Sussex, we have no need for deer fencing, which is expensive. You have to get a vineyard to about year 4 when things start to produce, so that’s about £25,000 per hectare, then add plant machinery costs on top.\nEven if you’ve got the land and you can afford to plant vines, vineyards are hugely labour-intensive, then there’s the cost of chemicals, and tractor operations. It’s expensive because things are done by hand that can’t be mechanised, or that are difficult or expensive to do so. Pruning, for example, requires someone to go to every vine and make cuts. Once the vineyard is producing, returns are very healthy at the moment in comparison to lots of other agriculture.\nThe most important thing is location. Nothing can beat a good site. For a successful UK vineyard, you need a good spot, not too high, not too frosty or exposed, in a warm part of the country with just the right amount of rainfall. A frost-free site is ideal because frost can be devastating financially. It can wipe you out. Even on sites where you can fight frost, it’s labour-intensive and costly.\n\"Even if you’ve got the land and you can afford to plant vines, vineyards are hugely labour-intensive\"\nAnother huge consideration is to know what your end product will be. Whether you are thinking about contract growing or producing a wine, which is a whole other kettle of fish, take professional advice. On a good site with good years if you are contract growing you’d see a return between year 8 and 10. If you’re making wine, particularly sparkling wine, you need 4 years to get the vines in production then 3 years to age the wine before any money comes in at all. Other than frost, cashflow is the greatest risk. And the weather, which you can’t do a lot about.\nLong-term rental of land or selling under contract are definitely viable options for traditional landowners that are otherwise leasing land for arable. I would think most wine companies would pay a premium on what the rental was for arable if you can get a long-term rental for 30 years. Selling under contract is another option, just make sure you have a contract before you plant. Tying down a wine company to ensure there’s a home for that fruit is crucial and helps sell the story to the bank manager.\nRathfinny bought the property in 2010 and did the first planting in 2012. We grow Chardonnay, Pinot Noir and Pinot Meunier, the traditional grapes for sparkling wine, plus some Pinot Gris for our still wine. Within those varieties we have some different clones, as in traditional selection, they each give different characteristics; some will be high yield, others full of flavour, others more resistant to diseases, so we spread our bets.\nIf you make wine, you need to ask yourself how you will get it to market. If you’re small you can sell through local outlets. If you’re really big you can talk to big distributors but if you’re in the middle, you can get stuck with too much product for local restaurants and your cellar door but not enough for a distributor. I’d say one of the most crucial business decisions is \"What are we going to sell and how are we going to sell it?\"\nDr Alistair Nesbitt is chief executive officer at Vinescapes email@example.com\nRelated competencies include: Land use and diversification","During the growing season, all green parts of the grape vine are susceptible to frost. Spring is a particularly delicate period for the vines, since spring frost often damages opening buds and young shoots, thus affecting the crop load. Not all vine varieties are equally susceptible to frost as susceptibility depends on bud development stages of the different varietals. A closed bud during dormancy is protected from the cold by its thick walls, which enables it to resist temperatures as low as -15°C. Critical temperatures for grape vines differ based on the growth stage, while during the winter, dormant buds can resist temperatures below -10°C and even down to -20°C and more. However, new growths can be damaged at -1,1°C.\nThere are two different weather events that can harm vines –Radiational Frosts and Advective Freeze.\nAdvective Freeze : This takes place when a large cold air mass, accompanied with winds, cloudy conditions, and low humidity, blows into an area and replaces warmer air. In such days, temperatures often drop below 0 °C and stay in this range all day. Advective Freeze may cause more damage than radiational frost, because active protection measures are not effective against it.\nRadiational frost : This occurs in clear nights with little to no winds, and as the name implies is connected with heat radiation. When more heat radiates away from the earth surface than the surface receives, the temperatures drops, and so the coolest air is closer to the ground. Apart from a clear sky-temperature inversion, low dew-point temperatures, night air temperatures below 0°C, and daily air temperatures above 0°C are associated with radiational frost.\nIt can also happen that a combination of advective and radiative conditions occur. For example cold air mass enters into a region,which results in the advective freeze, then for several days clear and calm conditions follow that cause radiation frost.\nWinegrowers can protect vines against frost by employing several passive and active frost protection methods. However, these methods can prevent or limit frost damages due to radiational frost while there is very little that can be done to protect vines against an advective frost.\nPassive frost protection methods : These include biological and ecological protection methods, which are often less costly than active methods and can even eliminate the need for active methods. Therefore it is advisable to focus on passive frost protection methods first and foremost, as they are used to avoid frost danger\nSite & varietal selection :The most important element of frost protection is of course site selection and choice of varieties(late vs. early variety). Since cold air flows downhill, the mid-slope positions are warmer, if there are no trees, brush or other air dams that prevent cool air to flow out of the vineyard. Different grape varieties vary in the date of budburst, so it’s somewhat recommended to choose early bud burst varieties in locations with the lowest risk of frost.\nCover crop management : Although there are several benefits of using cover crops in the vineyard, when it comes to preventing frost, cover crop does not affect the situation drastically. However, cover crops prevent soil from absorbing and storing heat, and bare soil can be 2°C higher compared to the floor with 5cm high grass. Tall cover crops can also slow down the movement of the cold air out of the vineyard. What winegrowers can do is to mow ground cover short before the frost-prone period or if there is no erosion concerns even cultivate the cover crops prior to that period.\nPruning method : With vineyard management practices such as pruning, winegrowers can have an influence on the date of bud burst and thus reduce the risk of frost injury. This can be achieved with either a delayed pruning, since unpruned vines bud burst later than pruned vines, or with double pruning. When conducting double pruning,early pruning to long spurs with 5-8 buds suppresses the growth of basal buds (buds from the base of the main grapevine), and once frost risk passes or basal buds begin to break, a final pruning can be carried out.\nActive frost protection methods : These include activities in the vineyard which increase the temperature above the « danger » level by influencing the micro-climates in the vineyard. Obviously winegrowers focus on passive frost protection methods first and foremost, as they are used to avoid frost danger.\nWind machines : These work only with radiation frosts whenthere is an inversion and can provide between 1-3°F temperaturedifferences. Wind machines basically mix cooler air that is locatedaround the vines with the warmer air above the inversion layer, whichis usually at about (12-15 m) above the ground.\nWind machines are very expensive and are profitable on sites wherethere is a high probability of damaging spring frost – such as on 1 in every 5 years.\nHelicopters : Instead of purchasing wind machines,winegrowers sometimes prefer to make use of helicopters which also can mix inversion layers. This is a much more expensive method to protect vines from frost damages, but in areas with a low probability of spring frost more than a welcome option.\nHeaters : Heating the vineyard air is one of the oldest practices to protect vines against spring frost. Some winegrowers still burn cuttings from pruning to heat the air, while fossil-fueled heaters are not largely used as they are expensive due to the cost of fuel and labor, as well as being rather inefficient with lot’s of energy being lost to the sky, not to mention the environmental concerns. Heaters work best with temperature inversions, if there is little to no inversion or wind is blowing the heaters may not provide adequate protection. In order to properly protect vines, heaters should be uniformly distributed throughout the vineyard and turned on before the critical temperature is reached. To lower the cost of operation heaters can be used in combination with sprinklers or wind machines.\nBurning straw or hay : This is a similar technique which consists in burning bales of stray around the edges of the vineyard.The smoke that is given off provides a « protective blanket »which limits the loss of heat from the soil in absence of cloud cover.\nOver-vine sprinklers : Vines can be protected against frostalso with the help of water sprinklers. When water is sprayed andfreeze around green tissues it releases heat and thus protects vines.For this method, a large volume of water is required since constantliquid water is needed to form a freezing coating around vines budsand shoots to release heat and rise the temperature. This is the onlymethod that can provide frost protection during the advection frost as well, if used properly.\nConclusions : Passive methods often eliminate the need for active methods, plus they are much less costly. Active frost protection methods are chosen based on vineyard site specifics and winegrowers financial capabilities. Often winegrowers are combining different methods to protect vines and use for example sprinklers in combination with wind machines, heaters with wind machines or sprinklers with heaters, to efficiently protect vines and lower the costs."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:1936a6b1-274e-4777-aeca-c3b30296c4c2>","<urn:uuid:d050c61d-9260-47b5-8509-51d3351d2cbf>"],"error":null}
{"question":"What's the deal with training requirements - are they different for Ontario employers vs maritime employers? Need to know!","answer":"Ontario employers must provide comprehensive workplace-specific hazard training, orientation programs, regular safety sessions, and retraining after accidents - regardless of whether workers are direct employees or subcontractors. Even if workers have certificates and experience, employers must provide ongoing safety training. For maritime employers under the Longshore Act, there are no explicitly detailed training requirements specified in the provided documents - instead, the focus is on defining which types of maritime workers are covered under the Act based on their status and work location.","context":["Even the safest and most successful business can experience a workplace accident. While the well-being of the worker is always of first concern, rarely is it the only concern. A workplace accident can hurt a business’ reputation, brand and ofcourse, its pocketbook. The Ontario Workplace Safety and Insurance Board (WSIB) and Ministry of Labour also each have their own, overlapping and independent, interests in a workplace accident.\nAgainst this daunting backdrop, here are some ways to manage the potential for costly liability.1. Get educated – Know what you’re up against\nThe most common occupational health and safety costs are associated with the following:• An order.\nA Ministry of Labour inspector can issue a range of orders causing the workplace to stop working, either in whole or in part, and to incur costs associated with lost productivity and compliance. An order may include a stop-work order, an order that prevents certain equipment from being used, an order to correct an alleged safety hazard and an order that prevents workers from accessing certain parts of the workplace. Business as usual cannot resume until the inspector’s order is complied with and the order is lifted. • A charge.\nEven in the case of a routine inspection, an employer can be charged with an alleged violation of the Occupational Health and Safety Act and its associated regulations. Each charge carries a maximum penalty of $500,000 for an employer and $25,000 (or a 12-month jail term) for an owner, director and even a supervisor.• Settlement or trial.\nA trial will almost always be a costly endeavour financially, emotionally and physically. Unlike in a civil trial between private parties, the defendant in an occupational health and safety trial has no opportunity to ask for reimbursement of costs in the event of a favourable finding. Even a settlement or sentencing agreement can be costly, particularly when the accident is considered serious. The appropriate sentence will depend on the size of the organization, scope of the organization’s economic activity, actual and potential harm to the public, and deterrence. However, in the case of a first offence resulting in a critical injury, it is not unusual for the sentence to be more than $50,000. A fatality can be well over $100,000.\nThe most common workers’ compensation costs are associated with the following: • A penalty for failing to meet all reporting requirements.\nIn the event of a workplace accident, a Form 7 must be filed within three days if the worker requires health care or is unable to earn full wages. If the worker requires modified duties but has not suffered a wage loss, the Form 7 must be filed within seven days. An employer that fails to file a Form 7 in a timely manner may face a maximum penalty of $100,000.00, and $25,000 (or a 12-month jail term) for an owner or director. Similar to Occupational Health and Safety Act charges, this is a regulatory offence and the ultimate fine will vary depending on the specific circumstances.• WSIB benefits such as loss of earnings, healthcare and an award for permanent impairment.\nWhen a worker is off of work due to an injury, the worker will generally receive 85 per cent of his or her take home salary to compensate the worker for loss of earnings during recovery. For example, if a worker took home $1000 a week, he or she would receive $850 a week in compensation.\nThe worker’s healthcare costs are also paid for by the WSIB (not the provincial government through what is commonly referred to as OHIP). This can include the costs of an MRI, x-ray and physiotherapy.\nFinally, the worker will be compensated if his or her injury causes a permanent disability or impairment. A permanent impairment award is calculated by determining what percentage of the worker’s physical, functional or psychological abilities are permanently impaired. An award can range from a few hundred dollars to tens of thousands of dollars depending on the nature of the injury.\nAs the WSIB is an insurance fund, a payment made to the worker will be transferred to an employer’s yearly cost statement. This system is similar to home or car insurance. If there is a claim, insurance costs are adjusted appropriately. In the case of a workplace accident where there is prolonged recovery and a permanent disability, it is not unusual for a WSIB claim to cost an employer tens of thousands of dollars. In addition, just like home or car insurance, a WSIB claim will continue to impact an employer’s yearly cost statement and related experience rating for three to five years (depending on the experience rating program). • A breach of the re-employment obligation.\nIn many circumstances, an employer has an obligation to re-employ an injured worker for up to two years following a workplace injury. This obligation includes providing modified work that meets the worker’s limitations (if required) and ultimately returning the worker to his or her pre-injury duties.\nAn employer must exercise extreme caution and seek legal advice if terminating or laying off a worker before the re-employment period is up. A breach of the re-employment obligation can lead to a monetary penalty equivalent to the worker’s annual salary. 2. Get active – It’s the employer’s responsibility.\nEmployers are not helpless. The following are everyday practices that will help keep workers safe and at the same time protect an employer’s bottom-line should an accident occur.Training\nA robust health and safety training program is an ongoing responsibility. Ensuring a worker has the requisite training certificates is important but not sufficient to demonstrate the worker is appropriately trained. An employer must provide training specific to the hazards associated with the workplace, and must do so regardless whether the employer hires employees directly or through a subcontractor. In addition, the employer must ensure all workers undergo a comprehensive orientation program, including a review of the employer’s occupational health and safety policy. Training sessions, toolbox talks and quick safety tune-ups should be frequent. Finally, employers should retrain all workers when there has been a safety violation or accident.\nFor example, in one case an electrician was injured when he failed to shut down the power breaker panel before starting work. The electrician admitted he had not followed proper safety procedures. Regardless, the employer was charged under the Occupational Health and Safety Act for failing to ensure the worker was appropriately trained. The employer argued the worker had a training certificate, experience and had been trained on safety procedures during his apprenticeship. Nevertheless, the employer was found guilty because it did not take steps to provide ongoing safety training and ensure compliance with safety procedures. Due diligence\nSimilar to traffic offence, a charge under the Occupational Health and Safety Act is a strict liability offence. This means once charged, innocence is not assumed — it must be proven. The most common type of defence is known as ‘due diligence’ — proof the employer took all reasonable precautions in the circumstances. However, within the scheme of occupational health and safety, there is an added twist. Because an Occupational Health and Safety Act charge is quasi-criminal, the defence of due diligence must be proven beyond a reasonable doubt. This is a very high standard.\nFor example, in one case a supervisor was charged with failing to take every precaution reasonable to ensure compliance with fall protection requirements. The court found while a supervisor was not expected to “stand around all day watching workers,” general, unplanned and coincidental surveillance of workers on his way to lunch was not sufficient for a successful due diligence defence. The supervision should be planned and deliberate.Back to work\nIn the event of a workplace accident, getting a worker back to work is the quickest way to reduce liability. Once back to work, the worker is no longer entitled to receive loss of earning benefits from the WSIB. As well, studies have found once a worker returns to work the chances the injury will result in a long-term disability decrease substantially. And, of course, ending loss of earning benefits and avoiding a permanent impairment award will reduce the impact of a workplace accident on an employer’s cost statement and experience rating.\nShould it be necessary to accommodate a worker upon return to work, the process must be a joint effort between the employer, worker and union (if applicable). The employer has the right, and obligation, to ask for information regarding the worker’s limitations, and the worker has the obligation to actively participate in the process. If the proposed accommodation meets the worker’s limitations, the worker must return to work.Documentation\nThe best way to demonstrate training, due diligence and efforts to put the employee back to work is through documentation. This should include:\n• An occupational health and safety policy reviewed and updated on a regular basis.\n• Records of all orientation, training and toolbox talks. Keep binders on site or fax information to a central location to stay organized.\n• Checklists of daily safety checks for workers and supervisors to use at the start of their shift. These will help make safety precautions routine, and can be useful evidence if needed.\n• Records of regular maintenance and safety inspections for all tools and equipment.\n• Records from the joint health and safety committee’s monthly inspections, and copies of the company’s own notes and checklists from regular workplace inspections.\n• Records of every interaction with the Ministry of Labour.\n• Records of the organization’s own investigation after a workplace accident.\nAlways record the good and the bad — it’s all relevant and can be used in the event of a WSIB appeal or occupational health and safety charge to demonstrate a strong health and safety culture. However, if you record a health and safety violation, be sure to also record all remedial steps taken, including improvements made and discipline issued.3. Stay positive\nInteractions with the WSIB and Ministry of Labour can be time-consuming, costly and stressful. However, if an organization has made a sincere and thoughtful effort to properly train its workers and prepare its workplace, it will have put itself in the best possible position to respond to an unfortunate accident.\nSo stay positive and keep focused. A safe workplace is in your hands.\n-------------Danielle Allen and Carissa Tanzola are lawyers with Sherrard Kuzz LLP, Toronto-based employment and labour law firm representing the interests of employers. Danielle and Carissa can be reached at 416.603.0700 (Main), 416.420.0738 (24 Hour) or by visiting www.sherrardkuzz.com.The information contained in this article is provided for general information purposes only and does not constitute legal or other professional advice. Reading this article does not create a lawyer-client relationship. Readers are advised to seek specific legal advice from members of Sherrard Kuzz LLP (or other legal counsel) in relation to any decision or course of action contemplated.","What is the Longshore & Harbor Workers Compensation Act?\nWorkers who are injured while working in certain occupations around and over bodies of water may be covered by the Longshore and Harbor Workers Compensation Act. In the beginning, the Act was intended to cover a only maritime workers employed by a maritime employer. If such an employee sustained an injury on the Navigable waters of the United States, the employee may be covered by the Longshore Act. As the law has develped, benefits have been extended to types of employees who were not so directly connected to maritime activity. The Act is and has always been regulated by the U.S. Department of Labor but has changed dramatically over the years with regard to the types of benefits that can be paid, the process for an injured worker's payments and the way that disputes are handled. In addition, the Act has moved toward including more workers that worked on the land but around navigable waters.\nIn addition, to injuries that occur over navigable waters, the Act also governs work injuries that arise in other circumstances such as:\nThe Longshore & Harbor Workers Compensation Act also governs other work related injuries such as:\nA. Defense Base Act The Defense Base Act (DBA) came into law on August 16, 1941. The Act extended essentially the same coverage longshoreman enjoyed to contractors employees who performed work pursuant to contracts with the United States Government. The Act is referenced in short as the \"DBA\". The DBA has been amended on a number of occasions and covers all contractor employees who work any place on earth outside of the United States. The fact that employees employed as contractors essentially are \"at work\" all the time and the typical types of work involved have led Courts to offer very broad interpretations of who is covered under the Act.\nB. Outer Continental Shelf Lands Act The Outer Continental Shelf Lands Act (OCSLA) is similar to the DBA in that it is an extension of benefits available to Longshoreman for a very select group of workers whose employment involves extraction, transportation and other activities related to natural resources that are discovered on the outer Continental Shelf. Oil workers who perform their work in the ocean are specifically addressed by the Act and its interpreters. Employees who perform work on fixed oil platforms greater than 3 miles beyond the water's edge are covered. Within the three mile area, injured workers are covered by workers compensation systems administered by the contiguous State. In some cases that do not involve fixed oil platforms, workers can elect to be covered by OCSLA or the Jones Act.\nC. Employees working on United States Military bases throughout the world who are not paid with funds extended by Congress may be covered by the Nonappropriated Fund Instrumentalities Act. A broad range of facilities are covered including facilities managed by the Marine Corp, Navy, Army and Airforce. This Act extends the type of benefits offered to Longshoremen.\nWho is covered by the Longshore Act?\nThere are three requirements for an employee to be covered by the Longshore Act:\n- Must be employed by a maritime employee\n- Must not be specifically excluded by the Act\nSitus means that the injury occurred on the Navigable waters of the United States or any:\n- Adjoining Pier\n- Dry Dock\n- Building way\n- Marine railway\n- Other adjoining area used by an employer loading, unloading repairing, dismantling or building a vessel. 33 U.S.C. § 903(a)-(d).\nDifferent tests have been developed by different Courts which has lead to non-uniform application of the Act. We are in the 4th Circuit which has adopted what some consider to be the most restrictive test. Situs specifically does not include:\n- An officer or employee of the United States or any of its agencies\n- An employee of any state\n- An employee of any municipality\n- An agent of any foreign government\n- An employee whose injury is caused solely by his intoxication\n- An employee whose injury occurs solely as a result of his attempt to injure or kill himself or another\n- If the Secretary of Labor so certifies, an employee working at the facility of an employer who is engaged exclusively in the business of building, repairing or dismantling small vessels, defined as commercial barges under 900 light-ship displacement tons and commercial tugboats, crew boats, supply boats, fishing vessels, or other vessels under 1,600 tons gross, unless:\n- The injury occurs on the navigable waters of the United States or while on any adjoining pier, wharf, dock, facility over land for launching vessels, or facility over land for launching vessels, or facility over land for hauling, lifting or drydocking vessels\n- The facility receives Federal maritime subsidies\n- The maritime employee is not covered under a State workers' compensation act\n- The facility constructs noncommercial vessels such as military patrol boats even though they meet the size limitations. 33 U.S.C. § 903(b), (c) & (d)\n“Status” refers specifically to maritime employment and is specifically defined as:\n- Any person performing maritime work who injured landward of the Jensen line on a maritime site fulfills the ‘status' requirement if he works for a maritime employer and is not specifically excluded.\n- Any longshoreman or other person not a longshoreman, engaged in longshoring operations including\n- Winch operators;\n- Hold men;\n- Clerks and checkers;\n- Dock men;\n- Forklift operators;\n- Warehousemen performing tasks peripheral to longshoring operations.\n- Any harbor-worker including but not limited to:\n- (1) Ship repairmen;\n- (2) Shipbuilders;\n- (3) Ship-breakers;\n- (4) Pile-drivers and workers constructing piers, wharves, sewer outfalls, or any facility used as an aid to navigation or maritime commerce. 33 U.S.C. § 902 (3).\n- The following do not have \"Status\"\n- Office clerical, secretarial, security, or data processing personnel who exclusively perform non-maritime tasks.\n- Personnel working for a club, camp, recreational operation, restaurant, museum, or retail outlet; there is no distinction between profit making and non-profit making clubs;\n- Personnel employed by a marina including those taking reservations, servicing boats, preparing and serving food and performing routine maintenance;\n- Personnel working for suppliers, transporters or vendors temporarily doing business on the premises of a maritime employer, but who are not engaged in work normally performed by the employees of the maritime employer\n- Aquaculture workers which include personnel who clean, process or can fish and fish products; a commercial enterprise involved in the controlled cultivation and harvest of aquatic plants and animals\n- Personnel working on the construction, repair or dismantling of any recreational vessel under sixty-five feet in length\n- 1-6 are only excluded if the employee would otherwise be eligible for State Workers Compensation benefits.\n- A master or member of a crew of any vessel. 33 U.S.C. § 902(3)(G);\n- Any person engaged by a master to load or unload or repair any small vessel under eighteen tons net. 33 U.S.C. § 902(3)(H).\nMaritime Employer An employer whose employees are employed in maritime employment is a maritime employer. If an employee is engaged in a maritime occupation, his employer automatically meets the definition of a maritime employer. 33 U.S.C. § 902(4).\nWhat benefits are offered by the Longshore Act and what must be proven?\nFact of an Injury & Presumptions\nAn injured worker must prove the \"fact of an injury\". Once the \"fact of an injury\" is proved, the harm caused by the injury is entitled to a presumption that links the harm with the employment. Of course, the accident must have occurred in the \"course of employment\". In other words, the accident must have occurred in the time and space boundaries of the employment and/or during an activity that is related to the work.\nWhen an employee is injured, the employer must offer to the injured worker medical treatment which allows the employee to seek medical treatment. Medical treatment available is very broad under the Act. In addition, the range of medical providers available for treatment is quite broad including, but not limited doctors of medicine, surgeons, dentists, psychologists etc. Unlike some workers compensation systems, the injured worker is free to choose the doctor of his or her choice subject to the doctor having not been disciplined by the Department of Labor. Like most workers compensation cases, other issues often arise regarding an injured workers medical treatment including, but certainly not limited to, when and how a change in physicians is warranted, when an employee may or may not refuse medical treatment and how much a doctor can charge.\nTemporary Total & Temporary Partial Wage Loss\nWhen an employee, as a result of an injury, has the inability to earn any wages for a temporary time period, the employee is entitled to 2/3 of the employee's \"average weekly wage\". If an employee earns less has some earnings but the earnings are less than the pre-injury average weekly wage as result of the injury, the employee is entitled to 2/3 of the difference between the post injury earnings for up to five years.\nPermanent Total Disability\nIf there is no improvement in the injured worker's medical condition and no alternative employment can be secured leaving the employee unable to earn any wages, the employee is entitled to 2/3 of his pre-injury average weekly wage. If an employee has lost both hands, both feet, both arms, both feet, both legs, both eyes, or any two of these body parts, the employee is presumed to be permanently and totally disabled. At this point, the burden shifts to the employer/carrier to prove that the employee can perform some other employment or make efforts to vocationally rehabilitate the employment within the employee's medical limitations.\nPermanent Partial Disability\nMany times an injured worker remains partially disabled and the partial disability is permanent. Payment under this circumstance depends on whether the injury is a \"scheduled\" or \"unscheduled\" injury. If the injury is a scheduled injury, the amount that the injured worker can obtain is governed by a specific number of weeks for that scheduled injury. Legs, feet, hands and other body parts are \"scheduled\" injuries. Back and neck injuries are non-scheduled injuries and can leave the injured worker entitled to a partial payment for an extended period of time.\nThis article only only skims the surface of the laws governing the Longshore & Harbor Workers Act. It is important for the injured worker to understand that the Act has specific regulations for giving notice to the employer, statutes of limitation, the manner in which wages are calculated and how attorneys fees are paid. While many claims are straightforward, some claims are very complex. Please do not hesitate to contact our law office to discuss your claim."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:6bd201f6-cdf9-4465-bbcf-24843aea1f71>","<urn:uuid:c99e812a-8267-4337-8187-0e549f333a3c>"],"error":null}
{"question":"How do historical military losses compare to environmental losses in terms of casualties and carbon emissions?","answer":"In the Battle of Salamanca and subsequent actions, the French suffered severe casualties with around 1400 prisoners taken and documented losses of 986 men from various units, with many suffering severe sabre cuts and injuries. In comparison, the environmental casualties in coastal deltas have been equally devastating but in terms of carbon emissions - seven coastal deltas alone have released more than 500 million tons of CO2 each since their wetlands were drained, mostly in the past 100 years. This amount from a single delta exceeds Mexico's entire carbon dioxide emissions for 2007, which were just over 470 million tonnes.","context":["By Colin Jones & Vic Powell\nOne of the most famous conflicts throughout the Peninsular War was the Battle of Salamanca, or Los Arapiles, as the French and Spanish call it. Taken from the village and heights of that name which formed the centre of the action. Essentially, the French Marshal Marmont with his 'Army of Portugal' made a serious blunder by marching his army around the heights of the Greater Arapiles forming his forces into a semi-circle which over extended his line to an almost careless degree, leaving gaps between one body and another. Wellington's allied army were encapsulated, as it were, inside the mouth of the semi-circle and therefore could force a higher concentration of troops at any given point along the enemy's front. Many historians claim this to be one of Wellington's greatest victories, in Wellington's eyes at the time, it was just a question of seizing the initiative at the right moment. The French General Foy said that the victory raised the Duke of Wellington to the level of Marlborough, nevertheless, the losses on both sides were horrendous. The allied casualties amounted to 5,000 whilst the French losses numbered 14,000 (including prisoners), 2 Eagles, 20 guns and 8 Standards.\nAt the close of the day, the French were fighting a retreat and finding it hard to avoid being driven into the River Tormes. The retreat was being conducted by General Clausel who had been wounded in the leg. The French withdrawal was covered by Foy's 1st Infantry Division, a battery of guns and some light cavalry from Curto's Division. Foy's men had retained their discipline and morale as they had seen little of the previous day's fighting, being kept in a relatively safe position on the extreme right of Marmont's main line.\n1st Division: Commander Foy\n1st Batt. 6th Leger 500 men\n1st Batt. 76th Ligne 650 men\nCurto's Light Cavalry Detachment\n3rd Hussars (3x Squadrons) 198 men 66 per Squadron\n1 x 6 pdr battery (6 Guns)(Guns did not partake in the action)\nThe allied troops designated to pursue Foy were under the command of Maj. Gen. Eberhardt Otto George Von Bock, who had taken temporary command of the Cavalry Division after Le Marchant was killed and Stapleton-Cotton (the Divisional Commander) was also wounded. These troops consisted of:\nBaron Von Bock's Heavy Brigade:\n1st K.G.L. Heavy Dragoons (3x Squadrons) 300 men 100 per\nC. Anson's Light Brigade:\n11th Light Dragoons (1x Squadron) 105 men\nThe approach from the Tormes in this direction was through a narrow marshy valley, along which ran a small rivulet bounded by steep banks. The road was rough and stony and so confined as to cause a great extension and consequent delay in the march of the cavalry, nearly, an hour elapsed before the head of the column had cleared the defile and reached the stony plain beyond it.\nBock and Anson were soon in full trot towards the village of Garcia Hernandez. After proceeding about a league in this direction, the leading brigade came in sight of the enemy who were found advantageously posted with some squadrons of cavalry in line on the plain in front, several battalions of infantry in square on the heights in advance and to the right of the cavalry, with some guns in the intervals between the infantry.\n\"The boldest charge of cavalry in the whole war\" - General Foy\nThe best description of what followed comes from Beamish's History of the Kings German Legion:\n\"The French infantry and artillery being at first, concealed by the inequalities of the ground, the brigades were ordered by Lord Wellington to attack the cavalry, and their pace was accordingly increased to a gallop. The German regiments, confined by the narrowness of the valley, had been unable during their progress through it, to move upon a larger front than sections of threes, and now, being an echelon of squadrons, they attempted to form line upon the first squadron. Who without waiting hurried forward, however, by the excitement of the moment, the leading squadron of the first regiment under Captain Von Hattorf - having also in front General Bock; the field officers of the regiment and Lt. Col. May of the English artillery, who had brought the order from Lord Wellington - dashed on without waiting for the remaining squadrons, and made straight for the enemy's cavalry.\"\n\"The left wing of the French horsemen retired from the charge of Anson's brigade and those in front went about on the approach of Hattorf's squadron; but in pursuit the flank of the squadron became exposed to the fire of the infantry on the heights, by which Colonel May and several men and horses were wounded, and the pursuit was discontinued.\"\n\"Captain Gustavus Von Der Decken, who commanded the third or left squadron of the regiment, seeing that if he advanced according to the order given, his flank would be exposed to the fire of a dense infantry square, formed the daring resolution of attacking it with his single squadron.\"\n\"This square stood on the lower slope of the heights and obedient to the signal of their chief, the German troopers advanced against it with order and determination, while a deafening peel of musketry from the enemy greeted their approach. Arriving within a hundred yards of the point of attack, the gallant squadron officer, struck by a ball in the knee, fell mortally wounded, and Lieutenant Von Voss, with several men and horses, were killed; but instantly, Captain Von Uslar Gleichen, who commanded the left troop, dashing forward, placed himself at the head of the squadron and re-animating his followers by words and example, while another shower of bullets carried destruction among their ranks, the intrepid soldiers forced onward and bringing up their right flank, appeared before the enemy's bayonets on two sides of the square.\"\n\"The two front ranks, kneeling, presented a double row of deadly steel, while in the rear of these, the steady muskets of four standing ranks were levelled at the devoted horsemen. At this critical moment, when the sword was about to be matched against the firelock, and the chivalrous horsemen against the firm foot soldier - when victory hung yet in equal scales - an accidental shot from the kneeling ranks, which killing a horse, caused it and the rider to fall upon the bayonets - gave the triumph to the dragoons!\"\n\"For a path was now opened, and the impatient troopers rushing in amid the blazing fire, while men and horses fell fast before the muskets of the French infantry, their firm formation was destroyed, and the whole battalion were either cut down or taken prisoner.\"\n\"Captain Von Reitzenstein, who commanded the second squadron, seeing the success which had attended the daring onset of his comrades on the left, and being also impeded in his forward movement by the difficulties of the ground, decided upon following up the discomfiture of the infantry, and attempting the second square, which stood on the edge of the heights. He was received with a steady and destructive fire, by which Lieutenant Heugel was killed and Lieutenant Tappe severely wounded; but the moral force of the French infantry had been shaken by the fearful overthrow which they had just witnessed, and some timid individuals leaving their ranks, Reitzenstein rushed in with his ready followers; the square broke, and the greater part of the battalion was cut down or captured.\"\n(Editor's Note: The formation referred to above was not actually a square but two companies who were fighting a delaying action to buy time for the rest of the battalion. Thus the error in the following paragraph where Beamish states that they attacked a third square. In reality it was the second square.)\n\"A third square was instantly formed by those few who had escaped from destruction, and some cavalry came to their support. Against these Captain Baron Marschalck led the third squadron of the second regiment, and, being joined by the left troop of the second squadron under Lieutenant Fumetty, charged and dispersed the enemy's cavalry; then riding boldly at the infantry, broke and completely overthrew them.\"\n\"The wreck of the routed battalions now rallied and attempted to make a stand on a rising ground near the high road to Peneranda, where they again formed a connected body. Marschalck and Fumetty led their troopers a second time to the charge, but their little force had become too much reduced, and the horses were too fatigued to admit of any impression being made upon the enemy. The French received the attack with a heavy fire and with a shower of stones, to which they now had recourse; Captain Von Uslar was killed, Lieutenant Fumetty was wounded and several men and horses were struck down. No further attempt was made by the dragoons, and the enemy resumed their retreat.\"\nThe losses of the K.G.L. were as follows:\n1st K.G.L. Drag. : 31 killed - 38 wounded - 5 missing\n2nd K.G.L. Drag.: 22 killed - 30 wounded - 1 missing\nFrench casualties were much heavier. The severity of the French situation is clearly shown in the amount of prisoners taken, generally accepted at around 1400. Colonel Molard of the 6th Leger being among the captured. From the returns between July 15th and August 1st, the losses were as follows: 6th Leger (2 Btns.) - 376, 69th Ligne (2 Btns.) - 89, 76th Ligne (2 Btns.) - 475, 39th Ligne (2 Btns.) - 46. The division was barely engaged at the Battle of Salamanca so most of the above losses must be attributed to the action at Garcia Hernandez.\nWith the 6th and 76th obviously taking the brunt of the attack, and with the total of the whole, being 986, the figure falls below the known losses for the action at around 200 killed or wounded with some 1,400 captured. This means that some of the prisoners taken must have come from other units within the immediate area i.e. the cavalry and artillery, plus the stragglers returning to the ranks before the August 1st return.\nEdward Costello, an enlisted soldier in the 95th Rifles stated: \"I set out for Salamanca with the guard appointed to escort the prisoners taken in the recent Cavalry affair by our Germans. I never before saw such severe looking sabre cuts as many of them received; several with both eyes cut out, and numbers had lost both ears. Their wounded who were carried in wagons, were extremely numerous, and it was painful even to an old soldier, to hear their groans and incessant cries for water.\"\nPhotograph: Rocky terrain that the KGL charged across. The high ground in the rear is where the second French battalion was destroyed.\nNotes On Terrain\nThe roads were cart tracks\nHow to Get There\nFrom Alba de Tormes head east to Penaranda for about 8 kilometers. Garcia Hernandez is now called Garcihernandez and will be on the left of the main road. The ridge line parallel to the road on the north side is La Serna. If you get to the Gamo River you went a couple kilometers too far.\nCostello, Edward. The Peninsular and Waterloo Campaigns. 1968\nGurwood, John. Selections from the Dispatches and General Orders of Field Marshal The Duke of Wellington; 1841; p.612\nLunt, James. Charge to Glory - A Garland of Cavalry Exploits; 1961.\nNapier, William. History of the War in the Peninsular and in the South of France. Vol. IV (1892)\nOman, Charles. A History of the Peninsular War Vol. V; 1914\nWood, Evelyn. Achievements of Cavalry; 1897\n© Copyright 1995-2004, The Napoleon Series, All Rights Reserved.","Because recent research has shown that it is often the case that mangroves store more carbon than tropical forests–from 90 tons to 588 tons carbon from above-ground and below-ground biomass combined with net primary productivity of 7 to 25 tons carbon annually(1)–while providing an estimated ecosystem services value of up to US$ 9270 per hectare per year (2), the timely publication of the World Atlas of Mangroves is an excellent reference for those of us working to protect mangroves globally. With information sourced from 1400 literature references, the atlas gives the reader the information they need so as to further understand mangrove ecosystems, and the opportunities to develop mangrove ecosystem conservation and carbon projects.\nThis easy-to-use atlas includes global and regional maps demonstrating mangrove species richness, location, and conservation strategies, including carbon sequestration quantities for all 73 species of mangroves. These maps also represent visually protected areas overlaid with the existing mangrove estate. Finally, each regional section contains excellent analysis on regional mangrove issues including a measured discussion of the impact of the 2004 Indian Ocean tsunami on villages that had protected their mangroves compared with villages that had not protected their mangroves.\nThe atlas further provides momentum to protecting our global mangrove estate given the recent announcement that Restore America’s Estuaries is developing a mangrove carbon methodology, in conjunction with Verified Carbon Standard. This proposed carbon accounting methodology is focusing on quantifying and crediting the greenhouse gas benefits of several types of wetlands conservation projects including mangroves and coastal and tidal wetlands.\nIn fact, in a recentreport by International Union for Conservation of Nature (IUCN) and wetland specialists ESA PWA, “Of the 15 coastal deltas studied for the report, seven were found to have released more than 500 million tons of CO2 each since the wetlands were drained, mostly in the past 100 years. By comparison, Mexico’s carbon dioxide emissions for 2007 were just over 470 million tonnes.” This type of ecosystem loss has ledNASA to announce a large grant to study wetlands loss in Bangladesh and for the Government of Guyana to award $100 million Guyanese dollars to Guyana’s Mangrove Restoration Project.\nWith the global mangrove estate in 123 countries impacting fisheries, biodiversity and species conservation, coastal zone development and protection, and climate change mitigation, it is important that our conservation community work with our business community and indigenous and local communities to develop equitable opportunities for carbon and conservation finance funds to protect our global mangrove estate that we depend on daily. Because the greatest threat to mangroves is arising from conversion and land clearing for aquaculture and agriculture ( food production and palm oil food production and palm oil), and land conversion to urban uses (growth of cities), it is clear that in the 21st century, the destruction of our Earth’s mangroves could potentially complicate global food security while impacting sustainable growth of our urban areas. This furthermore strengthens our needed resolve to today begin to develop carbon projects on mangroves properties so that we can mitigate climate change while developing sustainable coastal zone management policies in the 21st century.\nHow to order\nBy Mark Spalding, Mami Kainuma, and Lorna Collins\nHardcover: 319 Pages, $99.95\nPublisher: Earthscan Publications\n(1) Komiyama, A., J.E. Ong & S. Poungparn, 2008. Allometry, biomass and productivity of mangrove forests: a review. Aquatic Botany 89(2): 128-137.\n(2) > In the front line. Shoreline protection and other ecosystem services from mangroves and coral reefs. UNEP-WCMC Biodiversity Series 24 (Volume 2006) – Wells, S., Ravilious, C., Corcoran, E., UNEP-WCMC\nGabriel Thoumi frequently contributes to Mongabay.com.\n(04/05/2011) Mangroves may be the world’s most carbon rich forests, according to a new study in Nature Geoscience. Measuring the carbon stored in 25 mangrove forests in the Indo-Pacific region, researchers found that mangroves forests stored up to four times as much carbon as other tropical forests, including rainforests. “Mangroves have long been known as extremely productive ecosystems that cycle carbon quickly, but until now there had been no estimate of how much carbon resides in these systems. That’s essential information because when land-use change occurs, much of that standing carbon stock can be released to the atmosphere,” explains co-author Daniel Donato, a postdoctoral research ecologist at the Pacific Southwest Research Station in Hilo, Hawaii.\n(12/01/2010) In August, NASA and the US Geological Survey released the first-ever satellite analysis of the world’s mangrove ecosystems. What they found was dire: mangroves covered 12.3% less area than previously estimated. Now, NASA has released images of the world’s mangrove ecosystems (see below), which currently cover 137,760 square kilometers. Yet this number keeps shrinking: mangroves are vanishing rapidly due to rising sea levels, deforestation for coastal developments, agriculture and aquaculture.\n(11/29/2010) While mangrove forests are vanishing around the world, the Indian Ministry of Environment and Forests is reporting a slight uptick of mangrove forests along the nation’s eastern coast. According to a report, mangroves expanded from 4,581 square kilometers in 2005 to 4,639 square kilometers in 2007, an increase of 58 square kilometers."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:1fb90f02-0974-403d-94c1-adffa488016f>","<urn:uuid:63c4d978-eac3-48af-afb6-8532852685ef>"],"error":null}
{"question":"Historical significance 1950s aviation pioneers: What was the pioneering achievement of Premier 1 vs Boeing 707 in terms of being 'firsts' in their respective categories?","answer":"The Boeing 707 was Boeing's first jet airliner and was the first jet to achieve widespread commercial success, helping establish Boeing as a major airliner manufacturer in the late 1950s. The Premier 1, on the other hand, was Raytheon's first all-new business jet built from an original design and was the first in their family of business jets featuring composite fuselage construction.","context":["Hawker Beechcraft Premier 1, United States of America\nThe Premier 1 light business jet is the first all-new business jet built by Raytheon Aircraft from an original design and is the first in a family of business jets, which features all-composite fuselage and swept aluminium wing design.\nThe Raytheon Aircraft Company based in Wichita, Kansas, started the design of the Premier 1 light business jet in 1994 and announced the launch of the new aircraft in 1995. The aircraft completed its first flight in 1998.\nRaytheon gained over 200 orders for the Premier 1 from customers in 26 countries by 1999, before the aircraft was submitted for FAA approval.\nThe Premier 1 received FAA certification, including single pilot approval, in 2001. It received FAA RVSM (Reduced Vertical Separation Minimum) certification in May 2003. Upgrade kits for RVSM capability are available for aircraft already delivered.\nIn December 2006, Raytheon announced the sale of Raytheon Aircraft to GS Capital Partners. The new company is called Hawker Beechcraft Inc and the sale was completed in March 2007.\nFlight Options LLC (formerly Raytheon Travel Air), a subsidiary of Raytheon, ordered 22 Premier I aircraft for its fractional ownership programme. Delivery of the Premier I started in 2001 and the Premier I has joined the Flight Options fleet of King Air B200s, Hawker 400XP and Hawker 800XPs. By September 2007, 190 Premier I aircraft had been delivered.\nIn March 2003, a Premier 1 established a new speed record when it flew from Wichita, Kansas to the East Coast of the USA, 1,854km (1,152 miles) at an average speed of 1,028km/h (639mph).\nFor its size, the Premier 1 is very light (basic operating weight 3,627kg) and features a composite fuselage for superior strength and less weight and swept metal wings for greater speed. The composite fuselage also provides a larger cabin size, accommodating eight people including the pilot.\nIn May 2005, Raytheon announced an upgrade, the Premier IA, which received certification in October 2005. The aircraft has an improved interior, seating and avionics suite and 'acoustical liner' to reduce cabin noise levels.\nIn May 2008, Hawker Beechcraft announced the Premier II. The Premier II will have new Williams FJ44-3AP engines providing 26.8kN (6,000lb) of combined thrust, a range increased to 2,780km, maximum altitude increased to 13,716m (45,000ft) and cruise speed increased to 861km/h (465kt). The maximum gross take-off weight is also increased to 6,260kg (13,800lb). Certification of the Premier II is planned for 2010.\nThe fuselage is built without internal frames and is of graphite and epoxy laminate and honeycomb composite construction. The engines are rear mounted.\nThe swept back aluminium alloy wings are set below the fuselage which gives the aircraft a large cabin space relative to the overall length of the aircraft. The tail plane is also of swept back design.\nThe elimination of the internal frames in the design of the fuselage increases the available cabin volume by nearly 15% and reduces the weight by about 20% in comparison to a conventional alloy construction.\nIce detectors mounted in the nose of the aircraft activate the aircraft's de-icing systems. The wing leading edges and the inlets of the engine nacelles are fitted with an engine air bleed anti-icing system. Electromagnetic expulsion de-icing (EMNEDI) protects the leading edges of the tailplane. The windscreens are electrically heated.\nThe cockpit is fitted with dual controls. The aircraft can be flown by a pilot and co-pilot or by a single pilot.\nThe flight deck is equipped with a Rockwell Collins Pro Line 21 Electronic Flight Information System (EFIS) and Rockwell Collins AHC-3000 Automatic Heading Reference System (AHRS). The Rockwell Collins AFD-3010 unit has two 10in x 8in high-resolution liquid crystal displays for primary flight and multifunction displays.\nThe avionics include air data computers ADC–3000, an integrated avionics processing system IAPS-3000, flight management system FMS-3000, flight guidance system FGS-3000, automatic direction finder ADF-462, distance measuring equipment DME-442, a global positioning system GPS-4000, navigation receivers VIR-432 and a radio altimeter ALT-4000. The colour weather radar is the RTA-800 supplied by Rockwell Collins.\nA maintenance and diagnostics computer MDC-3000 is installed on the aircraft.\nThe communications system consists of dual Rockwell Collins VHF-422A transmitter/receivers with a transponder, type TR-94 Mode S, a DB438 audio system and a CL-23 navigation and communications tuner. The cabin is fitted with a pager with four speakers.\nThe Premier 1A avionics suite incorporates the Rockwell Collins IFIS-5000 Integrated Flight Information System (IFIS) and Pro Line 21 Communication, Navigation and Surveillance (CNS) suite fitted as standard. IFIS includes dual graphical multi-function displays, electronic charts and enhanced map overlays and optional 3D flight management system mapping, paperless cockpit and real-time graphical cockpit weather. The upgraded IA has three LCD displays, rather than two.\nThe 4.11m-long, heated and air-conditioned cabin can accommodate six passengers, with four club-style seats and two fixed seats at the rear of the cabin.\nThe door on the port side of the aircraft, just behind the flight deck, is fitted with airstairs. The main 1.4m³ baggage compartment is accessible externally and is sufficiently large to accommodate skis and other large items. A forward baggage compartment, with 0.28m³ capacity, is installed in the nose of the aircraft.\nA cabin noise reduction upgrade, installed from 2003, has reduced cabin noise by 3dBA to 5dBA.\nThe Premier 1A upgrade includes a new contoured cabin headliner that increases passenger headroom, adjustable LED downwash lighting and repositioned passenger reading lights. Cabin chairs have also been completely restyled for increased comfort and more legroom. The Rockwell Collins Airshow cabin entertainment system can be fitted.\nThe aircraft has two Williams FJ 44-2A turbofan engines each delivering 10.23kN. The engines are rear mounted.\nThe aircraft has both gravity and pressure refuelling. The aircraft carries a usable fuel load of 2,059l in integral wing tanks that fill the entire internal volume of the wings.\nThe electrical system consists of two starter generators, a lead-acid battery and a standby battery. There is also an external power unit.\nThe aircraft is fitted with tricycle-type landing gear, which is hydraulically operated. Each unit has a single wheel. The main wheels retract inwards and the nosewheel retracts forward. The landing gear is fitted with hydraulically operated brakes with an electrical anti-skid system.\nThe upgraded Premier 1A includes a pilot 'lift dump on demand' control for improved landing performance and an improved hydraulic brake with anti-skid system.","kidzsearch.com > wiki Explore:images videos games\n|A Qantas 707 at the 2007 Paris Air Show. This plane is owned by John Travolta.|\n|Role||Narrow-body jet airliner|\n|National origin||United States|\n|Manufacturer||Boeing Commercial Airplanes|\n|First flight||December 20, 1957|\n|Introduction||October 1958 with Pan American World Airways|\n|Primary users|| Trans World Airlines|\nContinental Air Lines\n|Unit cost||US$4.3 million (1955 dollars) US$36.5 million (2012 dollars)|\n|Developed from||Boeing 367-80|\n|Variants|| Boeing 720 |\nBoeing C-137 Stratoliner\n|Developed into|| Boeing E-3 Sentry |\nBoeing E-6 Mercury\nNorthrop Grumman E-8 Joint STARS\nThe Boeing 707 is a jet airliner. It was made by Boeing Commercial Airplanes from 1958 until 1979. It only has two rows of seats, which means it is a narrow-body plane. It also has four engines. The name is often said as \"Seven Oh Seven\". There are many different types of 707, and they can hold from 140 to 189 passengers. They can also fly from 2,500 to 5,750 nautical miles (4,630 to 10,650 km).\nThe Boeing 707 was Boeing's first jet airliner. It was the most common plane in the 1960s and it was still used a lot during the 1970s. The 707 was the first jet to have a lot of passengers fly on it. The 707 was not the first jet airliner, but it was the first one to make a lot of money. It made Boeing one of the biggest makers of airliners. It also started the group of planes with \"7x7\" names. The Boeing 727, Boeing 737 and Boeing 757 have some parts of the 707's design.\nThe 707's design came from the Boeing 367-80, which was a prototype jet. The very first 707, the 707-120, had Pratt & Whitney JT3C turbojet engines. Pan American World Airways started using the 707 on October 26, 1958. Other types of 707 are the 707-138 and the 707-320. Both of these started being used in 1959. A smaller version, the Boeing 720, was made in 1960. The 707-420 had Rolls-Royce Conway 508 turbofan engines. It was made in 1960.\nThe 707 has been used for many different types of flights. Versions of the 707 used by militaries are the E-3 Sentry and the C-137 Stratoliner. Boeing made 1,011 707s (including the Boeing 720). More than 800 military planes were made. In August 2011, 10 Boeing 707s were being used by airlines. In August 2012, there were only two.\n- 1 Designing\n- 2 Design\n- 3 History\n- 4 Different types of Boeing 707\n- 5 Users\n- 6 Deliveries\n- 7 Accidents\n- 8 Details\n- 9 Related pages\n- 10 References\n- 11 Other websites\nDuring World War II, and after it, Boeing was known for its military planes. Boeing had made very important bombers, like the propeller B-17 Flying Fortress and B-29 Superfortress and the jet B-47 Stratojet and B-52 Stratofortress. However, Douglas and other companies were far ahead of Boeing in the airliner market. The only successful airliners Boeing made before the 707 were the Boeing 314 Clipper and Boeing 307 Stratoliner. During 1949–1950, Boeing started looking at jets. Back then, aerial refueling (when a plane can get more fuel while flying) was being used a lot. The United States Air Force had ordered 800 KC-97 Stratotankers. Since planes were beginning to use jet engines, the USAF needed a jet tanker.\nBoeing looked at many wing designs and engines for the new tanker. Eventually, it chose the 367–80. The \"Dash 80\" took less than two years to make. It first took off on July 15, 1954. It had Pratt & Whitney JT3C engines.\nNobody knew if the 707 would make money. Back then, Boeing was making almost all of its money from military planes. The last airliner it made, the Boeing 377 Stratocruiser, lost the company $15 million before the United States Air Force bought some and called them the KC-97 Stratotanker. In a demonstration flight over Lake Washington outside of Seattle, on August 7, 1955, test pilot Tex Johnston performed a barrel roll in the 367-80 prototype.\nThe Dash 80 was 132-inch (3,350 mm) wide. This meant that it was wide enough to have two seats on each side of the plane. Boeing decided to make it 144 in (3,660 mm) wide. However, Douglas had made the DC-8, which was 147 in (3,730 mm) wide. Because of this, Boeing made the 707 wider again, so it was 148 in (3,760 mm) wide.\nMaking and testing\nThe very first type of 707 was the 707-120. Qantas ordered a shorter version, which was called the 707-138. The -138 could fly for as long as Qantas needed. Braniff International Airways ordered a version with Pratt & Whitney JT4A engines. This version was called the 707-220.\nThe last type of 707 was the 707-320C (C means \"Convertible\"). It had a big door for cargo. It also had a better wing.\nBoeing stopped making passenger 707s in 1978. 1,010 707s were made for airlines, but a lot of these went to militaries. Boeing made military 707s until 1991.\nThe 707's wings are swept back at 35 degrees. This means that the wings are not straight lines. Boeing made a yaw damper for swept-wing planes, which was needed because swept-wing planes move strangely if there is not a yaw damper.\nOn one flight, the yaw damper was switched off to give the new pilots some more experience with the plane. One pilot made a bad move, and the plane went out of control. Three of the engines were ripped off of the wing. The plane crashed near Seattle at Arlington, Washington. Four people on board died.\nIn his autobiography, Tex Johnston said he was flying on a 707 and he thought that there was something wrong with the yaw damper, because the plane was moving strangely. He went to the cockpit and helped fix the plane.\nThe 707 used air from the engines to pressurize the cabin.\nThe P&W JT3D-3B engines have special doors which open when the plane is taking off. The doors help to give more air to the engines. The doors close when the plane is in the air.\nPratt & Whitney decided to make the JT8D-219 the new engines for planes made from the Boeing 707. A lot of these are for military planes which were designed from the Boeing 707.\nThe first orders for the 707 happened on October 13, 1955. Pan Am ordered 20 707s. There was a lot of competition between the 707 and the Douglas DC-8. A lot of big airlines only used the DC-8. Boeing decided to make some more changes to the 707's wing so that it could fly further. The new version was called the 707-320.\nPan Am was the first airline that used the 707. The plane's first flight was from New York to Paris on October 26, 1958. It stopped for fuel in Gander, Newfoundland. Qantas was the first airline from outside the United States to use the 707.\nAt the end of the 1960s, the 707 was too small to fly all the passengers that wanted to fly. Boeing made the Boeing 747 because of this. The 707's engines were also too old.\nDifferent types of Boeing 707\nThe 707-120 was the first type of 707. The plane could hold 179 passengers. This type often had to stop for fuel in the North Atlantic. It had four Pratt & Whitney JT3C-6 turbojets. The first flight with passengers was on October 26, 1958. 56 were built, plus 7 short body −138s; the last −120 was delivered to Western in May 1960.\nThe 707-138 was a −120 which was ten feet shorter than the others. It could also fly further.\nThe 707-120B had Pratt & Whitney JT3D-1 turbofan engines. They were a lot better than the others. The −120B had some changes made to the wings. 72 were made.\nThe 707-220 had more powerful Pratt & Whitney JT4A-3 turbojet engines. Five of these were made, but only four were delivered. The first one began being used in December 1959.\nThe 707-320 Intercontinental is a longer version of the 707-120. This type could hold more passengers, and had some changes made to the wings. It first took off on January 11, 1958.\nThe 707-420 was the same as the −320, but it had Rolls-Royce Conway 508 engines. Lufthansa was the first to carry passengers on this type of plane in March 1960.\nThe 707-320B had a few changes made to the outside of the plane, as well as new engines. The wing was changed. This plane was first used in June 1962 by Pan Am.\nThe 707-320C could be changed from a passenger plane into a cargo plane. More 707-320Cs were made than any other type. The 707-320C had a cargo door added, as well as some other changes to the wing and the floor.\nMany militaries have used the 707 for many different things.\n|Cockpit crew||Three (Four with navigator if the plane needs to fly over water)|\n|Passengers|| 110 (2-class)\n179 (1-class, maximum)\n| 147 (2-class)|\n219 (1-class, maximum)\n|Length||145 ft 1 in (44.07 m)||152 ft 11 in (46.61 m)|\n|Wingspan||130 ft 10 in (39.90 m)||145 ft 9 in (44.42 m)|\n|Weight when empty||122,533 lb (55,580 kg)||146,400 lb (66,406 kg)|\n|Cruising speed||540 knots (1000 km/h)||525 kn (972 km/h)|\n|Width||12 ft 4 in (3.76 m)|\n|Engines (4 x)||Pratt & Whitney JT3D-1\nRolls Royce Conway (BOAC only):\n17,000 lbf (75.6 kN)\n|PW JT3D-3: |\n18,000 lbf (80 kN)\n19,000 lbf (84.4 kN)\n- Aircraft related to this one\n- Similar aircraft\n- \"Boeing 707 Jet Transport.\" aviation-history.com. Retrieved December 27, 2009.\n- \"707 Model Summary\". Boeing Commercial Airplanes. http://active.boeing.com/commercial/orders/displaystandardreport.cfm?cboCurrentModel=707&optReportType=AllModels&cboAllModel=707&ViewReportF=View+Report. Retrieved December 10, 2010.\n- Bowers 1989, p. 434\n- \"Boeing 707.\" airlinercafe.com. Retrieved December 27, 2009.\n- \"Tech data sheet at Boeing.com\"\n- Best source for range is http://www.boeing.com/commercial/airports/acaps/707sec3.pdf, which shows 2800 nm for a 707-120B with maximum payload and 5750 nm for a −320B with zero payload. It doesn't include a graph for the −120, for which range would be 2500 nm or less with full payload.\n- Wilson, p. 13. Quote: \"The Boeing 707, the airliner which introduced jet travel on a large scale.\"\n- Wilson 1999, p. 48. Quote: \"The USA's first jetliner, the 707 was at the forefront of jet travel revolution...\"\n- \"World Airliner Census\". Flight International. August 2011. p. 15. http://www.flightglobal.com/airspace/media/reports_pdf/emptys/87145/world-airliner-census-2011.pdf. Retrieved September 13, 2011.\n- \"World Airliner Census\". Flight International. August 2012. p. 13. http://www.flightglobal.com/airspace/media/reports_pdf/emptys/97713/world-airliner-census-2012.pdf. Retrieved September 13, 2012.\n- Wilson 1998, p. 18\n- \"Gamble in the Sky.\" Time, July 19, 1954. Retrieved December 27, 2009.\n- Ruffin, Steven A (2005). Aviation’s Most Wanted: The Top 10 book of Winged Wonders, Lucky Landings and Other Aerial Oddities. Washington D.C.: Potomac Books. p. 320. .\n- Francillon 1999, p. 34\n- Irving 1994, pp. 194–197\n- Pither 1998, p. 21\n- Accident description at the Aviation Safety Network\n- Johnston, A.M., Tex Johnston: Jet-Age Test Pilot, Smithsonian Books, December 2000, p. 247. ISBN 978-1-56098-931-8.\n- Bowers 1989, p. 433\n- \"Jets Across the U.S.\" Time, November 17, 1958. Retrieved December 27, 2009.\n- Finlan, Alastair. The Royal Navy in the Falklands Conflict and the Gulf War: Culture and Strategy (British Politics and Society). London: Rutelage, 2004. ISBN 978-0-7146-8569-4.\n- \"Farewell Flight.\" Time, November 14, 1983. Retrieved December 27, 2009.\n- \"Boeing 707.\" Goleta Air & Space Museum. Retrieved December 27, 2009.\n- Pither 1998, p. 22\n- \"KC-135E.\" Global Security. Retrieved December 27, 2009.\n- \"Aircraft and Fleet Lists\". ch-aviation.ch. http://www.ch-aviation.ch/portal/aircraft/quick?ac_manufacturer=BOE&ac_aircraft=B707. Retrieved 2013-03-21.\n- \"N707JT\". FAA Registry. Retrieved December 27, 2009.\n- \"John Travolta’s Boeing 707\". Blog.flightstory.net. http://blog.flightstory.net/45/john-travoltas-boeing-707/. Retrieved 2011-10-31.\n- \"Boeing 707 Accident summary.\" Aviation-Safety.net, May 5, 2007. Retrieved December 27, 2009.\n- \"Boeing 707 Accident Statistics.\" Aviation-Safety.net, July 5, 2005. Retrieved December 27, 2009.\n- \"707 Airplane Characteristics: Airport Planning.\" The Boeing Company, May 2001. Retrieved October 12, 2012.\n- \"Boeing 707 Family.\" Boeing. Retrieved December 27, 2009.\n- Bowers, Peter M. Boeing Aircraft since 1916. London: Putnam Aeronautical Books, 1989.\n- Bradley, Catherine. Boeing 707 Super Profile. Yeovil, Somerset UK: Haynes Publishing, 1983.\n- Breffort, Dominique. Boeing 707, KC-135 and Civilian and Military Versions. Paris: Histoire & Collections. ISBN 978-2-35250-075-9.\n- Caidin, Martin. Boeing 707. New York: Bantam Books, 1959.\n- Cearley, George Walker. Boeing 707 & 720: A Pictorial History. Dallas, TX: G.W. Cearley Jr, 1993. No ISBN.\n- Francillon, René. Boeing 707: Pioneer Jetliner. Shrewsbury, Shropshire, UK: Motor Books International, 1999. ISBN 0-7603-0675-3.\n- Cook, William H. Road to the 707: The Inside Story of Designing the 707. Bellevue, WA: TYC Publishing Company, 1991. ISBN 0-9629605-0-0.\n- Irving, Clive. Wide Body: The Making of the Boeing 747. Philadelphia: Coronet, 1994.\n- Lloyd, Alwyn T. Boeing 707 & AWACS in Detail and Scale. Falbrook, CA: Aero Publishers, 1987. ISBN 0-8306-8533-2.\n- Pither, Tony. The Boeing 707, 720 and C-135. Tonbridge, Kent, UK: Air-Britain (Historians) Ltd., 1998. ISBN 0-85130-236-X.\n- Price, Alfred. The Boeing 707. Leatherhead, Surrey, UK: Profile Publications, 1967.\n- Proctor, Jon. Boeing 720. Miami, FL: World Transport Press, 2001. ISBN 1-892437-03-1.\n- Schiff, Barry J. The Boeing 707. Blue Ridge Summit, PA: Tab Books, 1982, First edition 1967, . ISBN 0-8168-5653-2.\n- Smith, Paul Raymond. Boeing 707 – Airline Markings No. 3. Shrewsbury, Shropshire, UK: Swan Hill Press, 1993. ISBN 1-85310-087-0.\n- Stachiw, Anthony L. and Andrew Tattersall. Boeing CC137 (Boeing 347C) in Canadian Service. St. Catherines, ON: Vanwell Publishing Ltd., 2004. ISBN 1-55125-079-9.\n- Whittle, John A. The Boeing 707 and 720. Tonbridge, Kent: Air Britain (Historians), 1972. ISBN 0-85130-025-1.\n- Wilson, Stewart. Airliners of the World. Fyshwick, Australia: Aerospace Publications, 1999.\n- Wilson, Stewart. Boeing 707, Douglas DC-8, and Vickers VC-10. Fyshwick, Australia: Aerospace Publications, 1998.\n- Winchester, Jim. Boeing 707. Shrewsbury, Shropshire, UK: Airlife, 2002. ISBN 1-84037-311-3.\nBoeing 7x7 aircraft timeline, 1955–now\n|Boeing 717 (MD-95)|\n|= Not being made anymore||= Still being made|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:3e027b7b-96db-4b1e-ae6c-d601d6a7445c>","<urn:uuid:268c5319-818d-443e-941e-ab0645d5d37b>"],"error":null}
{"question":"What are the key characteristics of polyethylene plastic used in containers, and how is this type of plastic affecting our oceans? 🌊","answer":"Polyethylene is the most common plastic, characterized by being either transparent or white, with excellent insulation properties, and is very strong, versatile, and cheap. It is used for containers, bags, and packaging. This type of plastic, along with other plastics, is contributing to a massive ocean pollution crisis. Every year, 8 million tonnes of plastics enter the ocean, and marine plastic pollution has become a transboundary problem affecting all countries. Beach clean-ups alone are insufficient to solve this issue, as a big part of marine pollution comes from land sources, including rivers.","context":["WHAT ARE PLASTICS?\nPlastics are synthetic materials with a macromolecular structure that under certain conditions of temperature and pressure they can permanently change their shape.\nThere are two types of plastics: thermoplastic and thermosetting plastic.\nThermoplastics: they are pliable when heated and can be moulded to give shape to objects that harden when cooled. In theory, this process can be repeated several times, depending on the quality of the different plastics.\nThermosetting plastics: after an initial malleable phase caused by heat, this group of plastics hardens due to a three-dimensional crosslinking of molecular chains. During the softening phase, the combined effect of heat and pressure makes them pliable; however, if these plastics are heated after they have hardened, they decompose and burn.\nPET is lightweight, rigid or semi-rigid, transparent or a natural colour. It is an excellent barrier against gases and resists impacts. It is one of the easiest plastics to recycle and is used to manufacture bottles, bags and synthetic fibres for clothes.\nPolyethylene is the most common plastic. It is either transparent or white, it has excellent insulation properties and is very strong, versatile and cheap.\nHDPE is translucent, simple to process, resistant to impacts and is non-toxic. It is used for manufacturing bottles, tanks, bins and transport containers.\nLDPE can be either translucent or transparent. It is suitable for food contact and is the lightest and most heat-sensitive plastic. It is used for containers, bags, sacks, plastic coatings on wires, bins, pipes and toys.\nPVC is a very versatile plastic. It is hard wearing and resistant to chemical and atmospheric agents, and fire. It is used in the paper and packaging industry, food containers, credit cards, furniture, clothes and toys.\nThis material is transparent, lightweight and resistant. It can be used for both plastic and fibres. Polypropylene does not absorb water and is easy to colour. It is used to manufacture textile fibres, couplings, transport containers, furniture, carpets, ropes and food containers.\nThis is one of the most important thermoplastic materials. It is transparent, hard and inflammable, very shiny and inert against many corrosive agents. It can be coated in shiny or opaque colours.\nPolystyrene is commonly used to replace glass, aluminium and wood, as it is cheaper. It can also be used in packaging materials (including food), containers, boxes, lamps, disposable items, cups and toys.\nUsed to produce goods that have been especially manufactured to resist impacts, such as suitcases, large and small domestic appliances, telephones and accessories for the car industry.\nUsed to make many products manufactured in different consumer-goods sectors, such as glasses frames, typewriter case mouldings and transparent toothbrush packages.\nGenerally used in the production of coextruded films for the electrical and medical fields, as well as in the footwear and toy industry.\nUsed to make toys, parts of fridges, ball point pens, batteries, technical and decorative items and sports articles.\nUsed for producing synthetic fibres (nylon) and flexible food-container film.\nUsed for mechanical engineering.\nUsed for transparent products, protective helmets and car components.\nUsed to produce transparent panels, roofing sheets, illuminated signs and optical equipment.\nMainly used to produce precision parts for mechanics.\nUsed for jobs that require high performance and high temperatures; for example, in electronics, health industry, transport and industrial applications.\nUsed for many technical applications in the electrical electronic, photographic, aeronautical and mechanical industries, as well as for manufacturing specific electrical appliances.\nUsed in the production of adhesives, water-based paint and inks.\nThis plastic is obtained from the polymerisation of vinylidene fluoride and is characterised by a high level of chemical inertia accompanied by excellent stiffness and heat resistance. It is used in the chemical industry and can withstand temperatures of up to 120 °C. Its piezoelectric characteristics mean that it is also used in the electrical and electronic industries. It is used as a power supply for equipment that needs to withstand temperatures of over 150/180 °C.\nUsed in the manufacture of artificial leather, shoe soles and heels, films for electrical insulation and sports equipment. It is also employed in the medical sector and for technical uses.\nUsed for a wide range of technical applications in different industries, such as household goods, outer casings of small electrical appliances, cosmetics, stationary and electronic items.\nDEMETO project has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement N° 768573.\nA project co-funded by the Ministry of Industry, Energy and Tourism in the grants awarded for the 2012 Re-industrialisation Programme and ERDF Operational Programme, Autonomous Region of Valencia 2007-2013 (PET COMPAÑÍA PARA SU RECICLADO, SAU. A programme for implementing new technologies and processes in order to modernise the company. File no.: REI-040000-2012-61)\nPET COMPAÑÍA PARA SU RECICLADO, SAU\nPolígono Industrial La Pahilla\nEl Blanquizar S/N\n46370 Chiva (Valencia) – Spain\nTel.: +34 962 524 148\nFax: +34 962 524 259","Originally published by WWF-Indonesia and WWF-Singapore. Written by Sharon Salim.\nLast Sunday, a 9.5-metre sperm whale was found stranded off the coast in Kapota Island, Wakatobi — dead. Cause of death: unknown. But what we do know: a staggering 5.9 kg of plastic items found in its stomach.\nWWF-Indonesia’s Dewi Satriani tell us more about this appalling incident.\nBelow, exclusive information povided by WWF-Indonesia on the timeline and all the things you need to know:\n#1 The whale was found by a local on Sunday evening\nWWF-Indonesia received a report from a community member of Kapota Island in Wakatobi on Sunday evening (Nov 18) informing them about an incident of a dead whale stranded off the coast.\nThe next Monday morning (Nov 19) at 7.30 AM local time, WWF-Indonesia, Wakatobi National Park, Wakatobi Marine and Fisheries Community Academy were deployed to the scene and discovered a whale carcass suspected to be a sperm whale.\n#2 The whale was already in an advanced state of decay\nThis is the reason why it was not possible to conduct a necropsy to investigate the cause of death. In this stage of decay (level 4), the carcass was already releasing an overpowering stench and the body was not intact. A necropsy can only be done if the stranded whale is still in level 2 stage of decay; when the skin still appears tight, emitting no smell, and the eyes still shine.\n#3 Identifying the whale was still possible\nEven though the whale carcass was no longer intact, WWF-Indonesia Marine Species Specialist Dwi Suprapti conducted a photo analysis of the carcass sent by the WWF-Indonesia team and identified the stranded whale as sperm whale (physeter macrocephalus). It has a block-shaped head, narrow jaw and teeth.\nSperm whale is also the largest toothed-whale, unlike other large-sized counterparts that are toothless. The possibility of it being a baleen whale was also ruled out thanks to the absence of prominent, iconic features of baleen like the rostral ridge and ventral grooves. This further confirms the fact that the stranded whale is a sperm whale (and not a blue whale as some news outlets have reported).\n#4 Finding a stranded whale in Wakatobi waters is not common\n“Whales do migrate through Wakatobi waters. In certain seasons we can see many different kinds of whales passing through Wakatobi islands, but stranding is not common. This is the only time we’ve found a stranded whale, which is also (alarming) because we found plastics in its abdomen,” Dewi revealed.\n#5 The locals decided to cut open the abdomen of the dead whale\nThe chunks of black material (left) are plastic raffia strings. A rubber-canvas sandal (right) was among the finds.\nTo be exact: there were 115 of plastic cups (750g), 19 pieces of hard plastic (140g), four plastic bottles (150g), 25 plastic bags (270g), a nylon sack (200g), and more than 1,000 pieces of plastic raffia string (3,260g) which totals to 5.9 kg inside the stomach, according to the identification result conducted by Wakatobi Marine and Fisheries Community Academy.\n“This discovery is deeply upsetting. It is a wake-up call for Indonesia about how plastic pollution is causing irreparable damage to our oceans and marine life. We urge businesses and governments to work together to address this issue urgently to prevent further plastic leakage into our oceans.” said Dwi Suprapti, Marine Species Specialist WWF-Indonesia.\n#6 There was no crowd management or public boundaries during the incidence\nSo as not to interfere or disturb the stranded whale, public members without any Personal Protective Equipment (PPE) including eye and face protection, gloves, and coveralls were advised to remain at a distance. This is a crucial protective measure to avoid any exposure of bacteria, virus or other dangerous microorganism emitted by the mammal and transmissible to human.\n#7 The whale was buried two days after it was discovered\nIt was buried on Tuesday (Nov 20) at Kolowawa Beach, North Kapota in Wakatobi for later retrieval of the bone specimen by the Wakatobi Marine and Fisheries Community Academy.\n#8 Plastic pollution is a transboundary problem that all countries share\nAlthough it remains uncertain whether the plastics were lodging the sperm whale’s ingestion organ or caused infections, we can’t turn a blind eye to how plastics production and pollution are still growing exponentially.\nEvery year, 8 million tonnes of plastics enter the ocean. By 2050, the total mass of ocean plastic will exceed that of fish. Plastic debris kills an estimated 100,000 marine mammals annually, as well as millions of birds and fish.\n#9: Beach clean-ups are not enough to solve the problem\nA big part of marine pollution comes from land sources, including rivers. An effective response to this crisis requires a global systemic change involving businesses and governments — and supported by consumers.\n#10 We cannot solve this issue alone\nKnowing that marine plastic pollution goes beyond Indonesia and the region, the global crisis requires global solutions.\nBusinesses need to take responsibility for the full life cycle of their products and play their part in helping governments deal with this issue."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:bd60a476-51cf-4e99-80ef-5764b031d5d1>","<urn:uuid:d1103ef1-d057-45b2-9e68-b78458d5ce54>"],"error":null}
{"question":"How fast could the Oriana cruise ship go and what special award did it hold in the P&O fleet?","answer":"The Oriana achieved a high speed of 26.2 knots on trials, with a service speed of 24.0 knots. It held the 'Golden Cockerel' trophy for being the fastest ship in the P&O fleet, which it received from the Canberra during a handover ceremony when both ships were anchored off Cannes.","context":["Swansong of a Modern British Cruise Ship\nThe announcement in July 2018 by P. & O. Cruises that their pivotal cruise ship Oriana, completed in Germany in 1995, would be retired in August 2019, as the company continued to modernise and expand it’s U.K. cruise programme, brought an end to 24 years of valiant worldwide cruising by the vessel. She was transferred during the same month by Carnival Cruises, the American parent company of P. & O. Cruises, from the ownership of P. & O. Cruises to a Carnival company with a view to using her in the growing Chinese cruise market for cruising the South China Sea to ports in neighbouring countries. Oriana was the first British purpose built cruise ship, and she has very much served as a benchmark for all the larger cruise ships that have followed her.\nDesign of Oriana\nOriana was the most traditional of the fleet of large megacruise ships owned by P. & O. Cruises, and carried 1,828 passengers on several hundred long and short cruises after she was specifically designed and purpose built for the U. K. cruise market. Robert Tillberg of Sweden and John McNeece of the U.K. were the two main designers of Oriana, and had spent a considerable time onboard the P. & O. cruise ship Canberra, completed in 1961, investigating the needs of British passengers, so as to include as many as possible of the features of Canberra into the design of Oriana. These features included an engines aft design to allow more passenger space, reduced engine noise, and with the engine fumes dissipated to the wake of the vessel.\nIt is worthwhile, as the design concepts of Oriana of 1995 are in many respects the same as the design of Canberra of 1961, to look at the life of the designer of the earlier cruise ship, John West. He was born on 13th August 1927 in Hebburn on Tyne and won a scholarship to Jarrow Grammar School and then studied naval architecture at King’s College in Newcastle. He joined P. & O. at the age of 25 years and two years later he became Assistant Manager in charge of technical and design work. He was promoted to be in overall charge of the design and supervision of newbuildings, with the order for the new cruise ship Canberra going to the Belfast yard of Harland and Wolff Ltd. The vessel was yard number 1621 and was launched on 16th March 1961 by Dame Patti Menzies, wife of the Australian High Commissioner in London. She cost a staggering £16 million in 1960 with the interiors of her public rooms designed by Sir Hugh Casson and hung with canvasses by a young artist named David Hockney. John West received many awards and medals for the design of Canberra and the many other ships he designed, and became a Visiting Professor to two English universities. He was a very committed Christian and lived long enough to see his beloved Canberra replaced by Oriana, and he died on 4th November 2003 at the age of 76 years.\nThree interior designers for Oriana were engaged in Robert Tillberg of Sweden, John McNeece of London and Petter Yran. John McNeece and his team of designers gave the unique touches to rooms such as Anderson’s Lounge, the Knightsbridge shops, Harlequins disco and nightclub, the Pacific Lounge, the photo gallery, casino and related public spaces, as well as the onboard information graphics. Oriana has ten decks for passengers, four decks in her hull and six superstructure decks, with the Promenade Deck given an extra wide wrap around walking space, with her sixteen lifeboats being placed inboard on ‘D’ deck. The cruiser stern was tiered above to overlook the aft deck, pool and children’s play facilities. The elegant four deck high atrium and waterfall was topped by a dome of vibrant Tiffany glass, an Art Deco feature, and the central walkways leading to it gave good passenger flow. The base of the atrium consisted of a set of stairs flanked by two black painted elegant flower bouquet holders. The décor of her public walkways, shop fronts, and the corridors on each deck leading to the staterooms were restrained and conservative, and in no way ‘glitzy’.\nOriana obtained the high speed of 26.2 knots on trials with her service speed of 24.0 knots giving her the ability of keeping to schedule on long distance voyages to Australia, the destination of many of P. & O. liners of the past. Oriana holds the ‘Golden Cockerel’ trophy for the fastest ship in the P. & O. fleet, previously held by the Barrow built fleetmate of Canberra, the Oriana of 1960 with her twin ‘pepper pot’ funnels and a speed over the measured mile on trials of a fast 30.64 knots. The award passed to Canberra on the retirement of the first Oriana in 1986. The ‘Golden Cockerel’ was handed over to the new Oriana from Canberra when both ships were anchored off Cannes and each ship sent boats over to perform the handover ceremony. Oriana of 1960 had a very successful maiden voyage out to Australia after sailing from Southampton on 3rd December 1960. She then moved to the Transpacific service from Sydney (NSW) to Auckland and then under the Lion’s Gate Bridge at Vancouver before finishing at San Francisco.\nOriana is powered by four M.A.N.-B & W L58/64 diesel engines of 47,750 kW combined capacity driving two controllable pitch propellers through two Renk-Tacke gearboxes. The gearboxes are coupled to engines via Vulkan-Rato couplings. The diesel engines comprise two nine cylinder centre engines and two six cylinder wing engines built at Augsburg with a total power of 54,040 bhp. This type of wing engine arrangement gives flexibility in the amount of power transferred through to the propellers, and thus control of fuel consumption. The propulsion system also integrates three bow thrusters, one stern thruster and two rudders. Oriana has very large stabilisers for the comfort of passengers, these covering a surface area of 21.5 square metres and reduce the rolling motion by 90% at a speed of nineteen knots. Two auxiliary steam boilers for heating and ancillary equipment use, four M.A.N.-B & W 6L40/54 generators to provide electrical power, and other pumps and equipment completed the engine room outfit, with compartments in the double bottom and alongside the engine room containing 2,400 tonnes of fuel oil bunkers.\nP & O. would have wanted a British yard such as Harland and Wolff Ltd. of Belfast to build the ship, but fitting out such an important ship was problematic in a British yard, so the order went to the Meyer Werft yard at Papenburg in Lower Saxony in Germany. Construction in the large Building Hall was by a series of 500 tonne prefabricated sections, with her funnel and forward navigation mast fitted alongside the fitting out quay.\nThe single funnel was designed to look like the twin elegant funnels of Canberra, the basic design of both vessels being very similar with lifeboats being carried at the same deck level. She was laid down on 11th March 1993 and launched on 30th June 1994, making the slow two day passage down the river Ems to the sea when fitted out by March 1995. She was named by H. M. The Queen on 6th April 1995 at Ocean Dock in Southampton, and was towed stern first dressed overall with flags to the Western Docks two days later, passing Canberra, which was about to sail on a cruise and was also dressed overall with flags.\nOriana has an overall length of 853.02 feet (260.0 metres) with a moulded beam of 105.64 feet (32.2 metres) and a loaded draft of 25.92 feet (7.90 metres), and is equipped with forward and stern thrusters for manoeuvrability in port. Oriana was designed to have accommodation for 1,828 passengers on a cabin capacity basis of two passengers, with a total of 914 cabins (594 outside and 320 inside) with 112 single cabins, 118 balcony cabins on one deck, and eight cabins reserved for wheelchair passengers.\nThe Balcony Deck is on ‘B’ deck and comprises the most spacious and elegant Suites, Mini Suites and Deluxe Balcony staterooms sleeping up to four persons, with the other outside and inside staterooms normally for two person occupancy. The gross tonnage worked out at 69,153 with a net tonnage of 36,829, and she carries a crew of 794, with British officers and international stewards and dining staff. Oriana cost the expensive amount of over £200 million to build, and her name refers to Queen Elizabeth I, in the same way that Gloriana was used to refer to her in poetry.\nPublic Rooms of Oriana\nThe exemplary public rooms and facilities onboard comprise three outdoor swimming pools, the Oasis Health and Spa Club, a casino, three main Dining Room choices plus two speciality restaurants and two other dining options, and six entertainment choices, and other multi-purpose rooms. These are:-\nSwimming and Health\nRiviera Pool is situated forward on Lido Deck with the pool surrounded by a bandstand, two whirlpools, a bar and many sun loungers. A raised walkway above on Sun Deck extends around both sides of the ship for walking and jogging exercise.\nCrystal Pool is further aft on Lido Deck, and at one end of the pool is a bronze sculpture by Andre Wallace of a man in a boat beside a reclining woman in another boat.\nTerrace Pool is at the stern of the vessel on ‘D’ deck and has its own whirlpool. The open decks of Oriana feature a sports court, golf nets, shuffleboard and teak wooden promenades.\nOasis Health and Spa Club was originally run by Champneys and is located high on Lido Deck towards the bow of the vessel, offering massages, facials, and health and slimming treatment. The Spa also has a whirlpool, thermal chairs, steam rooms and saunas.\nThe Fitness Centre is within the Spa and runs exercise classes, personal training, with many exercise machines, free weights, treadmills, bicycle exercisers, and other equipment, with also an area for aerobics. The Salon is also in the Spa and offers hair styling, barber shop, make-up and manicures.\nTheatre Royal with 664 seats is the largest entertainment venue with well known guest entertainers as well as productions by the ship’s own entertainers. The theatre was designed by John Wyckham and is decorated in rich red plush seats, curtains and fittings to give the feel of a West End theatre with high technology audio and lighting equipment to give good acoustics plus a revolving stage and orchestra pit. The seats are individually air conditioned to give guests a memorable experience in a very beautiful theatre.\nChaplin’s Cinema seats 189 and shows both classic and recent film releases, with the room also used for lectures and talks on Promenade Deck.\nHarlequin’s Disco and Nightclub seats 230 has a very large dance floor for both daytime ballroom dancing and a late night disco dancing on Promenade Deck.\nPacific Lounge seats 430 and is located at the aft end of the Promenade Deck, and in the evenings hosts cabaret with stand-up comedians, magicians, British singers and acts, and musical performances. There is a full service bar, and it is also used during the daytime for a range of classes and activities.\nCurzon Room named after Lord Curzon of India fame hosted classical music concerts and sessions for 140 guests, but was replaced in the 2006 refit at Bremerhaven costing £12 million of the ship by the new Oriana Rhodes restaurant for 96 diners designed by chef Gary Rhodes, after the success of the Arcadian Rhodes restaurant on her fleetmate Arcadia.\nOriana was re-registered at Bermuda at the time of the refit so that weddings could be held by her Master at sea.\nMonte Carlo Casino is an intimate club style casino offering roulette, card and other games, with the gaming tables hosted by professional croupiers, and the room is also surrounded by slot machines.\nPeninsular Restaurant is ‘midships on ‘E’ deck and, as with the very similar Oriental Restaurant aft on the same deck, seats are allocated according to cabin grade and chosen cabin. It seats 524 and offers open seating breakfast, lunch and dinner, the latter being limited to passengers who have opted for P. & O. Cruises flexible dining system who can arrive at any time. There are tables for two, four, six and eight, with excellent decorated treatment of the ceilings, chandeliers and décor with Art Deco touches.\nOriental Restaurant is the same size as the Peninsular Restaurant but seats 454 and has fabulous views over the stern and wake of the vessel, with windows on three sides, and is usually open only for dinner with passengers assigned to a specific table according to cabin grade and chosen cabin for either the first or second sitting. The menu includes signature dishes by Anton Mosimann for this excellent and much recommended dining experience.\nConservatory Buffet Café is a self service buffet restaurant with plenty of natural light through full length windows on each side, and offers good panoramic views over the sea. It is open throughout the day and well into the evening as the third major restaurant on the ship, serving continental breakfasts, afternoon luncheons and snacks, to themed evening buffet dinners. The beverage stands are also self service but this does not detract for many passengers who enjoy a more casual ambience. Al Fresco Dining space is located forward of the Riviera Pool and offers self service Mediterranean outdoor dishes on its full menu.\nTiffany Court offers light snacks and pastries and is located next to the Tiffany glass ceiling of the magnificent atrium.\nSindhu Indian Restaurant is a speciality restaurant that was introduced after the ship had been in service for a number of years at the request of passengers who wanted a wider choice of food. The Indian cuisine was developed in co-operation with celebrity chef Atul Kochhar and is located ‘midships on ‘D’ deck near the atrium, with a cover charge payable on entering.\nBeach House Buffet is another speciality restaurant in a section of the Conservatory Buffet Café for evening dining. This a very relaxed dining option offering a wide range of grilled meals and with panoramic views of the sea.\nShops, Children’s Rooms And Library\nKnightsbridge Shops are located in a curved area and row on Promenade Deck near the atrium, and offer everything from expensive, high end jewellery to more modest priced fragrances, fridge magnets, duty free liquor and tobacco. The Photo Gallery is nearby, as is the Plaque Room where many plaques and treasured mementos have been placed after being gifted by Ambassadors and leaders of the many countries that Oriana has visited during the last 24 years.\nThe Library is a beautiful light brown wood panelled room with ten bookcases filled with hardback books, two reading tables, comfortable armchairs, reading lamps and a lectern, and was designed by Viscount Linley. There are also the usual bridge, chess, and backgammon for serious players of these games, and the cyber study has fast wi-fi and Internet access with again beautiful wooden armchairs. This room is a joy for all serious readers to while away a few hours on a long day at sea with no port calls.\nChildren’s Rooms include the Decibels teenage disco with very loud music, as well as indoor and outdoor facilities for the younger children. The rooms were refurbished during the 2006 refit, and then converted in 2011 to cabins during her transformation to an adult only cruise ship.\nThackeray Writing Room is a traditional writing room lit by lamps on each table and with relaxing furniture and armchairs, and was also designed by Viscount Linley. The room is named in honour of author William Thackeray (1811-1863), a P. & O. passenger during the early days of the company in 1844 and who wrote many books and magazine articles.\nCrichton’s Room is used for card games, board games e.g. bridge, chess and backgammon tournaments, as well as evening quizzes and is named after the former P. & O. director Sir Andrew Crichton.\nMedina Room is located next to the Crow’s Nest bar on Sun Deck and is used for multi-purpose meetings and other uses.\nSign-up today to read the full article!\nSimply click below to sign-up and read the full article, as well as many others, instantly!"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:b97f4acb-3db1-4862-89f8-5ae1e82c844c>"],"error":null}
{"question":"Could you explain how fatigue manifests as an early warning sign of heart attack?","answer":"Fatigue as an early warning sign of heart attack manifests as an overwhelming sense of lethargy and general tiredness that can appear days, weeks, or even months before the actual heart attack. Importantly, this fatigue appears without any clear explanation - it's not associated with sleep deprivation or mental health issues like depression. Despite being one of the earliest signs, it's often overlooked due to its vague nature.","context":["- Chest Pain\nPain from a heart attack is often wide spread and acute (sudden onset). It probably won’t happen as a result of exertion, but can occur while being active or at rest. Pain is often described differently from pressure or fullness to tingling and sharp.\n- Radiating Pain to the Arm\nMen are likely to experience a radiating pain to their left arm, while women may experience pain in either or both arms. This pain is directly related to the pain and distress in the chest. You can however, have one without the other.\n- Radiating Pain to The Neck or Jaw\nRadiating pain in the left side of the neck or jaw is also associated with the distress the heart is going through in the chest. Jaw pain is typically described as tightness or ache in patients with this symptom.\nAn overwhelming sense of fatigue, lethargy and general tiredness may show up days, weeks or even months prior to a heart attack. Though sometimes the earliest sign, fatigue is often overlooked because it is so vague. This fatigue won’t be associated with sleep deprivation or mental health issue like depression, it will seemingly have no explanation.\n- Dizziness or Feeling Light Headed\nAs the heart struggles and fails to deliver oxygen, the brain is affected. Without enough oxygen you may feel dizzy and light headed or even faint. Your blood pressure will likely be effected.\n- Irregular Heartbeat\nIt seems a little obvious, but an irregular heartbeat is a big sign of heart attack. You may experience slight episodes of irregularity prior to your heart attack. Irregular heart beat is never a good or ok thing. It typically points to a much more serious heart issue.\n- Shortness of Breath\nMany women who have heart attacks report shortness of breath in the weeks prior to a heart attack. But, like fatigue it is often overlooked. The pressure and not being able to take a full breath may seem like a lung problem like bronchitis, but it is one of the first signs of heart problems.\n- Nausea, Vomiting or GI Upset\nMost commonly reported in women, stomach pains and GI upset is yet another atypical sign of a heart attack. While it probably doesn’t mean anything too serious by itself, maybe just a bug or something. When paired with other serious signs on this list nausea and GI discomforts are just as much a symptom as chest pain.\n- Back Pain\nAnother less common symptom seen mostly in women is back pain. Radiated or referred pain from the chest causes the feelings to occur in the mid or lower back. Back pain can present with or without the more common chest pain and can even radiate to the legs.\nIn the minutes before a heart attack you may begin sweating excessively. It is generally described as cold sweats and has recently been added to the accepted symptoms of a heart attack.\nAny combination of these symptoms may precede or occur during a heart attack. To avoid life threatening situations, talk to your physician and always pursue emergency medical care in case of chest pain."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:c59675e5-3ec3-4b4d-9a63-c135b0bc2c4b>"],"error":null}
{"question":"Hey! Can you tell me how professional standards and trust play into both digital preservation and cybersecurity? I'd love to know! 😊","answer":"Professional standards and trust are critical in both areas. FADGI 2023 has newly added professional staff guidelines and requirements as a parameter for compliance, including specific training requirements. The guidelines also introduced a Code of Ethics for the Still Image Working Group. In the cybersecurity context, trust is directly tied to an organization's commitment to security, which requires transparency, effective communication, and rapid incident remediation. Even organizations with robust security defenses aren't immune to cyber crime, making professional standards and trust essential components in both digital preservation and cybersecurity efforts.","context":["With the finalization of the 2023 FADGI guidelines, now is a good time to review, revisit and think about how FADGI fits into the\nbroader Imaging landscape.\nWhat is FADGI?\nFADGI, the Federal Agencies Digital Guidelines Initiative, is a technical manual describing the way in which we should aim to digitize documents in an archival setting. By integrating some level of awareness or compliance with FADGI into our digital projects, we align ourselves with the larger body of work being produced by the Heritage community. FADGI compliance is often viewed as 4 star or nothing; however, there are several levels of quality that we can fit into, giving a program a bit of leeway. Knowing where a program fits in the FADGI star scale can be just as important as aligning with 4 star quality levels. The FADGI document goes well beyond describing the pass/fail objectives for image quality, and gives recommendations on space design, large and small scale workflow design, metadata and file naming. It is an essential read for a new program looking for guidance, or an existing program looking to stay current.\nFADGI 2023 contains a range of changes, updates and revisions compared to the previous version, dating back to 2016. The new guidelines take on a more narrative approach, expanding on the purpose and requirements of the document, and furthering what was already a robust technical document. Additionally, the new document contains the addition of a Code of Ethics for the working group responsible for creating FADGI, the addition of Professional Staff to the conformance parameters, additional metrics and evaluation methods and updates to a number of sections. A full list of the major revisions can be found in section 1.2 of the guidelines themselves, but here is a quick summary of the highlights.\n|FADGI 2016||FADGI 2023|\n|Resolution Requirements||All object types have a PPI target, plus or minus a given percentage.\nie. 400 ppi +/- 1%\n|All object types have a nominal PPI with a lower bound for compliance.\nie. ≥ 396 ppi (400 ppi -1%)\n|Evaluation Criteria Values||8 bit RGB||L*a*b*|\n|Metadata||2016 standards.||Updated to reflect current standards. Additional information and links included for the Digital Curation Center.|\n|“Post-Processing”||2016 standards.||Updated to reflect current technology and best practices. Includes more information on image stitching, Color management section has been moved to Conformance Evaluation.|\n|Modern Textual Records Media Type||–||Newly added category informed by specifications and data from NARA (National Archives and Records Administration).|\n|Code of Ethics||–||Includes a code of ethics to be followed by the Still Image Working Group (the body who creates the guidelines).|\n|Professional Staff Guidelines and requirements||–||Professional staff and training have been added as a parameter for FADGI compliance.|\nArguably most relevant for those of us currently working working with the guidelines is the shift to L*a*b* values for evaluation, and the removal of the upper resolution guideline on all media types. These changes allow for a more accurate and consistent evaluation of color and tone parameters, and gives us the ability to over resolve different media types, if that is more convenient for our workflow.\nGolden Thread NXT\nEvaluation through software will be just as important with the revision of the guidelines. Golden Thread NXT reflects these changes, and has been developed to support the 2023 guidelines along with some general user experience improvements. The legacy version of Golden Thread is no longer compliant for validation against the new standard. Users new to the NXT version of Golden Thread will be greeted by an easier to use interface, backed by the same deep analytical tools they have come to expect.\nNXT reads both RGB digital count values, as well as the new Colorimetric L*a*b* values, allowing existing programs to understand what . This shift to L*a*b* allows us to review color independent of color space, ensuring consistent quality metrics across any number of institutions. NXT also organizes the project types by media type, so we can select contextually what guideline we are evaluating against. These different project types take into consideration any of the different color, tone, or resolution metrics that can differ across the various media types, rather than comparing against generic values.\nDigital Transitions is a dealer for Golden Thread, and in addition to providing your program with the software and appropriate targets, we can provide training on an ongoing basis for your institution.\nFADGI 2023 is an exciting shift for the field that works to align itself with the international community, and be a holistic reference point for up and coming programs. Now more than ever, the FADGI document can be used to reference every aspect of a digitization project. Perfect for seasoned professionals looking to keep current, as well as emerging professionals just starting at their first digitization position.\nRead the full guideline HERE!\nTo learn more about evaluating your images using Golden Thread NXT, check out the DT 301 Characterization and Evaluation course HERE!\nAll of DT’s solutions meet or exceed all National and International standards, including ISO19264, FADGI and Metamorfoze.\n“Do it once; do it right” is an incredibly important tenet in heritage imaging. Digitizing at inferior image quality inevitably leads to re-imaging which is monetarily wasteful and causes deterioration of fragile materials. All of our hardware and services provide preservation-grade image quality and verify that performance using international standards. This provides us and our clients an objective assurance that our quality is preservation-grade. We believe in standards-based heritage imaging so deeply that we are a member of the ISO committee TC42 which guides their development and adoption.\nCultural Heritage Technical Support Specialist\nBen Cort has been working in professional imaging and cultural heritage for the past 12 years. He began his career as a digital tech and lighting assistant, while working at the Portland Art Museum to develop an in-house imaging program. His tenure at PAM saw the imaging program grow from a volunteer position to a core function of the museum, and centerpiece of the Pacific Northwest cultural heritage landscape. He is active in the community as well, serving as the MCN Digital Imaging Special Interest Group Chair from 2018 to 2021, and delivering talks on heritage imaging nationwide.","How the next cyber incident may impact you\nEntire communities can feel the effects — and bear the costs — when cyber criminals breach a single organization. Here’s what each of us can do about it.\nAs our world becomes increasingly digitized and connected, cyber crime has emerged as one of our society’s most serious threats. Criminals continue to refine methods of infiltrating digital networks and deceiving employees at organizations, which can result in businesses being unable to operate, data being stolen and consumers losing services.\nIncreasingly, the criminals are targeting essential industries and service providers, such as hospitals, energy delivery companies, food suppliers and software companies. The cost to these organizations is immense: Damages related to cyber crime approached $1 trillion in 2020 — a 50% increase since 2018.1\nBut this estimate does not fully account for costs to consumers, who may experience higher prices, hardship due to loss of essential services and an overall feeling of mistrust when organizations they depend on experience a breach.\nIt can be difficult to understand the seriousness of cyber crime unless we are directly affected by it. Yet it is important to recognize that as our economy becomes increasingly globalized and interconnected, no one is immune from the impacts of cyber insecurity.\nHere are some ways you or your community might experience the effects of a cyber incident that targets an organization you depend on for goods, services or safekeeping of your personal information:\nEssential services can be disrupted, and highly sensitive personally identifiable information (PII) can be stolen.\nElectricity and water availability or quality can be compromised, leading to service disruptions.\nCompromised business software can result in denial of service or inoperable networks for downstream users.\nBreaches can lead to production delays that result in higher prices and food shortages.\nCities experiencing cyber incidents may become unable to make payroll, and their essential services could be suspended.\nStudents may be unable to attend digital classes, and their personally identifiable information can be compromised.\nFurthermore, every citizen has a stake in supporting a culture of cyber awareness and defense that extends to private businesses, the public sector and our personal lives. The better the threat is understood, the more resources we have to defend against it.\nConsumers and citizens often experience residual effects of cyber crime, even if they are far downstream from the initial breach or incident.\nAll industries, companies and communities are at risk for cyber crime\nCyber incidents involving large companies make headlines for good reasons: These breaches often involve the compromise of millions of customer account details or a demand for millions of dollars in ransom. But criminals are opportunistic and willing to exploit any weakness in any organization’s digital defenses if there is a potential for profit, even (and in some cases especially) when public safety will be compromised. For example, when hospitals are suddenly unable to access their servers, patient records or connected devices, patient health and privacy are at risk.\nCyber crimes that focus on supply chains can create effects that trickle downstream and are experienced by consumers as goods shortages, higher prices or interrupted services. In some cases, affected consumers and businesses may be in completely different countries. During an incident where software used by many businesses is compromised, service interruptions can happen in multiple locations.\nPublic trust is also at risk\nIf essential organizations and service providers experience cyber crime, consumers and constituents may experience doubt about those organizations’ security, and they may even become concerned for their own personal safety. The reputational damage that can accompany a serious breach can be severely damaging to almost any institution.\nYet it is important to remember that even the most robust security defenses and most diligent organizations are not immune to cyber crime. Trust is a function of a commitment to cyber security, which includes a high level of transparency, effective communication and rapid remediation after an incident occurs.\nAs a private citizen, you can demand accountability and responsiveness from institutions and businesses, before and after a cyber incident occurs.\nHow you can contribute to your community’s cyber security\nConsumers and citizens can have an indirect impact on cyber security by prioritizing it. By learning about cyber best practices, we can be more proactive in making sure the organizations where we work, shop and use for delivery of essentials are invested in their own security – and ours.\nYou can help build a culture of cyber security in several ways:\n- Support businesses and organizations that show accountability and dedicate resources to their cyber security practices.\n- Learn about the cyber security protocols of any organization where you work, volunteer or regularly attend events.\n- Follow good cyber hygiene protocols while using your personal online accounts, including social media.\n- Share good cyber practices with your family and friends.\nTurning cyber security into a society-wide objective requires proactive buy-in from individual citizens, business and community leaders, educational institutions, and security professionals. Keeping our core institutions and essential businesses safe is an ongoing challenge, but the more you know about digital security and how to respond to cyber incidents, the better prepared your community becomes."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:134aa64d-d217-461e-a0bd-34d869c86466>","<urn:uuid:7330a154-a3a9-4d45-9433-a95869737a42>"],"error":null}
{"question":"Hey! I'm curious about how different colleges are doing hands-on sustainability projects - can you compare Lansing Community College's home retrofitting program with Vanderbilt's waste reduction initiatives? 💚🏠","answer":"Lansing Community College and Vanderbilt have different approaches to hands-on sustainability. Lansing Community College's program involves direct community engagement through their Restoration Works program, where over 200 students from 12 classes participate in retrofitting residential homes scheduled for demolition, focusing on energy efficiency and green construction. In contrast, Vanderbilt's hands-on initiatives focus on waste reduction, including comprehensive food waste collection in dining facilities, installation of water bottle filler stations across campus, and implementation of sustainable procurement practices. While Lansing's program emphasizes residential construction and community revitalization, Vanderbilt's approach centers on campus-wide waste management and reduction systems.","context":["The Greenforce® Initiative is working with a network of schools that are interested in green jobs training programs and campus sustainability efforts. Coordinating with other programs and initiatives, Greenforce® is assisting colleges in connecting the dots as it relates to sustainability, hands-on learning, employer engagement and career pathway programs for lower skilled adults.\nThe following Michigan Greenforce® Initiative partners were awarded innovation grants to advance their efforts in the areas of green workforce development and campus sustainability:\nDelta College: The Sustainability Ambassadors Program builds on the accomplishments of Delta College of furthering sustainability across the campus but with much farther and sustained reach. The program acts as the breeding ground for sustainable operations, projects, processes, and educational venues. The program acts as the communication link between the Sustainability Coordinators and their discipline, service area, or department to bring forth issues and ideas for projects in their respective areas, and to suggest, consider, and bring about new projects to grow campus sustainability. The group also serves as the advisory to the Sustainability Coordinator and Academic Sustainability Officer who, in turn, identifies projects and programs to incorporate into learning venues for our students, that is, to utilize the campus as a learning lab.\nLake Michigan College: Researched and created a \"How-To Guide\" on the topic of repurposing and converting shipping containers into eco-friendly functional space. Check out their blog post about how they engaged the community in this effort.\nLansing Community College: Through their college's Restoration Works program and the Allen Neighborhood Center, LCC is involving over 200 students from 12 classes to take part in retrofitting at least 2 local residential homes in the revitalization of the Allen Neighborhood of Lansing. The homes were scheduled for demolition, and through this project, the homes will be rebuilt with the environment and energy efficiency in mind. This is the first time that the program will have students conducting hands-on energy efficiency and green construction work on a residential home in the community.\nGrand Rapids Community College: Students are participating in the remodeling and relocation of a model green home and converting it into a functional learning lab for teaching sustainable construction, energy efficiency and conservation, and renewable energy. Upon completion of the program, students will serve up to 300 hours in a paid internship related to their training that may lead to full time employment.\nSt. Clair County Community College: Through two mini-grants, SC4 is working on promotional materials for their green/sustainability programming. Their first mini-grant assisted in the development of an interpretive sign that will kick start their green walking tour. Their second mini-grant is in the works now and when finished, three new short videos will showcase the green features on campus, including their alternative energy (wind, solar, and geothermal) and their green roof. All these materials will help put SC4 on the map for their hands-on training programs and green campus.\nThe event link below features event materials, including agenda and presentations\nThe National Wildlife Federation is providing resources to help families and caregivers across the country provide meaningful educational opportunities and safe outdoor experiences for children during these incredibly difficult times.Learn More\nPresident and CEO Collin O’Mara reveals in a TEDx Talk why it is essential to connect our children and future generations with wildlife and the outdoors—and how doing so is good for our health, economy, and environment.Watch Now\nDitch the disposables and make the switch to sustainable products.Shop Now\nSearch, discover, and learn about wildlife. Anywhere, any time.Get the Apps\nYou don't have to travel far to join us for an event. Attend an upcoming event with one of our regional centers.","Our Goal: Vanderbilt will power its campus entirely through renewable energy and commits to carbon neutrality by 2050.\nZero Waste Study and Master Plan\nThe Zero Waste Study and Master Plan was developed by the Zero Waste Advisory Committee to address the portion of Scope 3 emissions related to waste disposal and recycling and to help progress towards Vanderbilt’s carbon neutral and Net Positive + Resilience energy goals by 2050.\nVanderbilt’s history of recycling has expanded in recent years to include food and material waste reduction. The Zero Waste Master Plan continues this forward progress to attain a higher standard of waste prevention, reduction, reuse and diversion.\nBased on past data, the Committee recommended that the university consider the following two goals, along with two supporting actions:\nGoal 1: Achieve Zero waste (90 percent diversion from landfill) by 2030\nGoal 2: Achieve 30% waste generation reduction from 2017 levels by 2030\n- End institutional single-use plastic purchases by 2025, except in laboratories*; and\n- Expand food waste collection to include all dining areas and residential halls by 2025.\n*Laboratories are exempt due to lack of available alternatives and safety concerns.\nRecent waste reduction initiatives include:\nThrough collaboration with Campus Dining, the university has already implemented food waste collection for composting at all major Dining facilities and will be expanding this program throughout campus over the next few years. Additionally, Campus Dining is employing software and practices to reduce waste by avoiding overbuying and participating in unwanted food donation programs.\nLearn more about campus dining.\nEliminating single-use plastic water bottles across markets and dining facilities across campus will be a significant step in reducing waste. The university installed rapid water bottle filler stations in key locations across campus with efforts underway to install more. See a map of the rapid water bottle filler stations here.\nSustainable Procurement Practices\nPurchasing products made of sustainable materials and with recycled content will be prioritized at Vanderbilt, as well as reducing consumption of materials such as single-use disposable products, paper and cardboard.\nLearn more about Vanderbilt’s procurement policies.\nLandfill Waste Reduction\nWhile difficult to eliminate 100 percent of landfill waste, the Zero Waste Working Group will make recommendations for waste diversion, waste reduction, food waste reduction, and single-use disposable plastic elimination goals, significantly reducing the university’s waste.\nCampus Recycling Program\nIn 1990, Vanderbilt University began actively working on a program to reduce waste for the University community. Formally established in 1992, the Vanderbilt University recycling program has evolved and continues to grow through the active involvement and participation of its student body, staff and faculty.\nThe Department of Plant Operations is now operationally responsible for the University’s Recycling Program, providing building recycling services to academic campus staff, students, and residents and managing a community recycling initiative at special events such as athletic games and move-out.\nLearn more about campus recycling.\nThe production of paper and the printing of publications use large amounts of natural resources (wood, water, energy, etc.) as well as potentially hazardous materials. Fortunately, many green printing options are now available to the Vanderbilt community through the VU Printing Services and Creative Services. These include post consumer waste recycled-content papers, papers certified by the Forest Stewardship Council (FSC), vegetable-based inks, papers processed without chlorine, and products made with renewable energy.\nLearn more about green printing."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:09e7d411-8fd6-4a4f-bfcd-61d12c233dab>","<urn:uuid:6d1dc464-68fd-48f9-a726-0182987e55c7>"],"error":null}
{"question":"How do FICO V8 and VantageScore 3.0 credit scores compare in terms of their impact on mortgage applications?","answer":"While both FICO V8 and VantageScore 3.0 measure general credit health, they aren't typically used for mortgage applications. The difference between these scores can be significant - for example, there can be a 27-point difference between them. This difference matters because mortgage lenders actually use different versions: they primarily use FICO V2, V4, or V5 scores. Most mortgage lenders follow Fannie Mae and Freddie Mac guidelines and try to review three specific scores: FICO Score 2 (Experian), FICO Score 5 (Equifax), and FICO Score 4 (TransUnion), using the middle score to determine mortgage eligibility.","context":["When talking to customers, our team will often hear something like, “What? I thought my credit was ____” or “That doesn’t make sense. My credit score from CreditKarma is....” This is so common we wanted to explain how credit scores are determined for those of you that have the same question. In particular, we will focus on credit scores when used in home buying and refinancing transactions.\nLenders use credit scores for one main purpose: As a way to gauge the probability a buyer will default on payments. The lender wants to pick buyers whose credit is good enough that for every roll of the dice, default is unlikely to come up. The higher the probability, the higher the interest rate. The challenge for buyers is understanding what data lenders are using since credit scores come from different sources.\nYes, you heard it right. There is not one credit score. There are many. Here is a primer.\nComponents of a Credit Score\n1) Data sources for a credit score: Typically the data source is the information on your credit report. However, any legal data source could hypothetically be used to help inform a credit score. For example, there are companies that have explored how to incorporate your social media data into a credit score. But that is a discussion for another day. For the sake of this article, we assume data is your credit report only and comes from one of the three main data sources: Experian, TransUnion, or Equifax.\n2) Date a credit score was pulled: A credit score is a measure of your financial health, according to a given credit bureau, at a specific moment in time. If a credit card company reports a late payment, or that you paid off your debt, the score calculated after that data is incorporated will be different from your previous score.\n3) The company compiling the credit score: People usually associate FICO with credit scores. FICO is the trademark of Fair Isaac Company, which is a company that uses data from credit bureaus to create a credit score. But they are not the only company that issue credit scores. Another example is VantageScore Solutions which creates the VantageScore.\n4) The credit score model: Each company sometimes has different models or versions of the credit score, like a car company with cars that may appear similar but have different features. Some credit score models could be updated models that are better, or others predict different things in relation to credit. For example, FICO has models that are more accurate in predicting auto loan late payments or credit card late payments. And did you know that FICO has about 28 different models?\nOf Math and Mortgages\nSo what does this all mean and in particular how does it affect you in home financing? In mortgages, the vast majority of lenders either use FICO V2, V4, or V5. If you are visiting CreditKarma, you are seeing a VantageScore 3.0. If your credit company or bank sends you a credit score in your monthly statement, you may be seeing a FICO V8.\nAll of these scores measure your general credit health, but the difference between models can be significant. For example, at the time of writing this article the difference between my VantageScore 3.0 and FICO V8 was 27 points. That may not seem like a lot when the range of scores is between a 350-850, but many lenders will give the best rates to buyers with scores above 720. If you come in with a 719, even though it is only 1 point away, the mortgage rate offered to you could go up. Small changes in interest rates can have large impacts to total cost in mortgages. An interest rate change of just .125% or 1/8th of one percent can equate to over $10,000 more paid on a $400,000 mortgage over 30 years.\nAt Own Up, we strive to bring education and transparency to a complicated process. Knowing exactly what credit scores lenders use and the exact score they will see in advance of them accessing it makes you more prepared. Right now, Experian offers a free FICO 8 score which is, at least, from the same company lenders will use when evaluating you for a mortgage. Experian also offers the opportunity to purchase your FICO V2 score for $4.95 so you can get an apples to apples comparison when you are ready to buy a house and want to look for the best mortgage rates.","Should You Ever Pay for Your Credit Score?\nIt’s easier than ever to check your credit score. Your banks, credit union, credit card issuer, and a handful of online memberships sites all offer free access. However, while it generally doesn’t make sense to pay for something you can get for free, there are times when you might want to open your wallet — such as when you’re applying for a mortgage.\nTHERE ARE MANY CREDIT SCORES AVAILABLE\nTo start, it’s important to realize that there are many different credit scores. A credit score is like a grading program that looks over one of your credit reports to determine your grade, and these programs get updated over time. Currently, FICO makes dozens of scores for lenders to use when reviewing applications, and VantageScore, a major rival in the U.S., offers four different credit scores.\nFICO and VantageScore credit scores both use similar scoring criteria, create a score based on the information in one of your credit reports, and (for the most part) use a 300 to 850 score range. As a result, the scores tend to track in the same direction. For example, if your FICO Score 8 (one scoring model) is improving over time, your FICO Score 9 and VantageScore 4 could be as well.\nThe tricky part is you don’t know which scoring model the creditor will use, and which of your three credit reports (from Experian, Equifax, or TransUnion) your score will be based on. So, even if you check one of your credit scores before applying for a loan or card, the creditor might use a different score when reviewing your application.\nWHEN TO BUY A CREDIT SCORE (AND WHICH SCORES TO BUY)\nAn exception is when you apply for a mortgage. Most mortgage lenders follow Fannie Mae and Freddie Mac underwriting guidelines, which require the lender to use specific credit scoring models.\nMortgage lenders try to review three credit scores, one based on each of your credit reports, and use the middle score to determine your eligibility for a mortgage. The scores they use are:\n- FICO Score 2, also known as Experian/Fair Isaac Risk Model V2SM\n- FICO Score 5, also known as Equifax Beacon 5.0\n- FICO Score 4, also known as TransUnion FICO Risk Score, Classic 04\nBecause you know which scores most mortgage lenders will use, you might want to check your scores if you want to buy a home. However, these scores aren’t available for free.\nYou can buy them directly from FICO by visiting the MyFICO website, or you may be able to find third-party companies that include the scores. Additionally, your mortgage broker or lender may be able to check your scores, although the check might count as a hard inquiry (the type that may hurt your scores).\nHOW TO GET YOUR CREDIT SCORES FOR FREE\nYou can check and monitor several of your credit scores for free. Although these won’t be the exact scores mortgage lenders use, other types of creditors may use these scores, and they can give you a general idea of where you stand in terms of credit scoring.\nSome of these programs also include free credit monitoring, which can notify you if there’s a new account or suspicious activity on your credit report. This could be an indication that you’ve been a victim of identity theft, helping you act quickly to close the account and limit the impact.\nHere’s an overview of some of the major free sources, which credit scoring model they offer, and which credit reports the scores are based on. We’ve also limited the list to services that also include free credit monitoring, which can send you an alert if there’s a significant or suspicious change to your credit report.\n|COMPANY||SCORING MODEL||BASED ON:|\n|American Express MyCredit Guide||VantageScore 3.0||TransUnion|\n|Credit Karma||VantageScore 3.0||TransUnion and Equifax|\n|Credit Scorecard from Discover||FICO Score 8||Experian|\n|Credit Sesame||VantageScore 3.0||TransUnion|\n|CreditWise from Capital One||VantageScore 3.0||TransUnion|\n|CreditWorks Basic from Experian||FICO Score 8||Experian|\nYou can also get free credit scores from hundreds of banks, credit unions, credit card issuers, and other financial institutions through VantageScore and FICO programs. However, the scores might not come with access to your credit reports or credit monitoring.\nTHE FREE SCORES ARE USUALLY ENOUGH\nYou might want to buy access to specific credit scores while shopping for a home. But generally, the free credit scores you can get are enough to help you determine where you fall in the scoring range. Regardless, you can improve most scores by paying down credit card balances and make your monthly payments on time."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:029f0575-ccd7-449b-9c73-40cb46fce79b>","<urn:uuid:87e12f06-3a63-4357-9822-0049ddffdc2d>"],"error":null}
{"question":"How do KeyShot and Blender compare in terms of rendering capabilities and target users? 🎨","answer":"KeyShot and Blender offer different rendering approaches. KeyShot provides real-time rendering with preset environments (HDRIs) and scientifically accurate materials, focusing on creating photorealistic visuals quickly and simply. It's designed for designers who want user-friendly software without complicated settings. Blender, on the other hand, features a powerful unbiased rendering engine called Cycles for ultra-realistic rendering, and it's aimed at both novice and advanced users who benefit from its comprehensive pipeline. While KeyShot specializes in rendering, Blender is a complete 3D suite that includes modeling, animation, simulation, and other features beyond rendering.","context":["By Mario Malagrino, Italy\nBefore I begin the tutorial, let me say a few words about KeyShot. KeyShot is a very user friendly 3D rendering application that allows you to create photorealistic visuals in a very short time. It’s the solution for many designers who don’t want to waste time with complicated rendering software.\nWhen I first imported a model to KeyShot, my jaw dropped. “WOW, real time reflections of the HDR image on the model.”, I thought to myself. For those who create hundreds of test renderings just to achieve the right angle for reflections, you’ll understand how much time you can save with that feature alone. Many designers have great models but bad renderings–a loss of quality in their portfolio that can affect job prospects or landing a project. KeyShot changes that completely, putting the ability to create stunning imagery in the hands of every designer.\nYou may wonder what the key is to create great renderings. I will tell you. The key to a great rendering is the quality of light and use of material. That is exactly where we see the power of KeyShot. It offers preset environments (HDRI’s) as well as physical lighting, hundreds of scientifically accurate materials and settings that are simple to adjust. All of the changes and adjustments to the scene happen right in front of your eyes. This tutorial covers these features along with the settings used for the rendering of the car you see in the image above.\nIn your modelling software you have to give the same color to those objects that in Keyshot should have the same material. In this way you GROUP the objects for Keyshot. Attention, in older versions of Keyshot it’s the color that you must choose, in the new version it works trough materials !\nAfter this step EXPORT the model (I use OBJ files…but there many other choices). Ones you are in Keyshot “IMPORT” the model. You will see a nice real-time rendering in your view. This will allow you to understand what you should change. Remember that in your modelling software you have to set-up the units. For example METERS! This will guarantee you to be able to import in a second moment other objects with correct scale/rotation/size compared to the already existing project.\nThe two most important panels (buttons) are the “PROJECT” panel and the “LIBRARY” panel. The project Panel shows you what you have in your scene. The Library panel shows you what you can add to the scene ( for example an other material on your car, or simply an other HDR image etc…).\nLet’s give a quick look to the Library. You have this sections: Materials, colours, environments, backplates, textures, renderings. Materials: here you can find a list of materials to apply (trough drag&drop on you model). Environments: Here you can find many great set-ups of HDR images to use as background and light source (you can also import your own HDRI). Backtemplates: This are backgrounds with different choices of colours or images (you can create your own in Photoshop). Textures: If you apply them on your model you can choose between: it’s colour, bump map, opacity or label (it is a kind of material editor). This for are sections that we use in this tutorial.\nBefore I begin the tutorial, In the Material panel you have different sections. In our case I need a car paint material, so I search in the PAINT section a nice material. As soon you have applied (drag&drop) the material you can of course change the settings of the material to get other effects that you need. Make a double click on the object and you will see in the Project panel the material with several settings. They have very self explaining names. After changing it you can SAVE it to the library and use it again in other projects.\nYou can change the location, resize and rotate all objects in the PROJECT panel under position. Just click on the “parts” and use the slots writing down a number or use the move tool.\nThe HDR images are really very different from each other. There is one for every taste or need. Under environment you have the possibility to get light and reflection from the HDR and have a very realistic result.\nIf you click on EDIT HDR you have the possibility to add your own highlights or light sources. It is really simple and effective. In bright renderings I would avoid to much of those extra lights. It looks amazing if you have an dark rendering and if you need an interesting atmosphere. If you make a “photo-studio” rendering remember that on your HDR reflections that are visible on your model there should be no threes or other outdoor elements visible. Should you choose a outdoor image you can “blur” the HDR in the HDR-EDITOR. This makes disappear a bit the disturbing elements in your reflections. If you have a too blue sky, just DESATURATE it in the editor, maybe not totally, since a light blue can have a nice effect.\nShould you Not like a gradient background or the image that your HDRI is creating in the background in your render, you can check the COLOR slot and choose the color that you like as background. This will not change light or reflections, only the background. Remember that the colour will NOT be reflected on you model.\nThe HDR Edit mode allows you to create light sources in a few clicks. The results are very good, and sometimes necessary. Especially if you have dark scenes and your HDRI is not illuminating the part that you like have a bit brighter. In this case it will really help to add a Highlight or Pin.\nThe Pin can have a colour of your choice. This makes the scene for sure more interesting. I suggest a very soft bright orange for WARM atmospheres, and a bright BLUE for cold atmospheres. Do not colourize all the scene with strong colours,…just a little touch of colour (in my sample there is a strong RED, but just to show you the setting).\\\nBackplates are background images that you can choose to make your render looking more interesting. You can create your own in Photoshop, or just use a photography to simulate a outdoor scene. It is so simple to create amazing compositings of cars on street with Keyshot.\nHere you have a blurred, de-saturated HDR as light and reflection source. The background is just grey. How can we improve significantly this scene? There is a small trick that I recommend to use, especially to simulate a photo-studio.\nCreate a Box, or any other shape (but the Box is the most used one in this kind of effects), place it above the car (or in a position that fits better to your project), and apply a LIGHT material. The difference is clearly visible.\nThe last tip for this tutorial is to create a curved background, and import it as “wall-ground” for your project. I suggest to make the curvature veeeery soft and big, this will guarantee a very soft gradient in the background of your render. Why should we import this object ? If you go to use a backplate or color, it will not be reflected on your materials/objects. But as soon you apply now a colour on this special object, it’s colour will be reflected on your project 🙂\nThis are the most used shapes that you can use as photo-studio background, should you choose to use objects instead of backplates or the HDRI in the background.\nThe Render settings are quite simple, and they do not really need to be explained. What I recommend is to keep the samples around 16, and the shadow around 6-7 (this is a good project/portfolio quality). Higher numbers will increase the render time really a lot. In PASSES there is the CLOWN pass which basicly is an alpha mask, but with different colours for each group. Very useful in Photoshop :).\nSamples of other HDRI:\nSamples of Real-time View renderings:\nI hope you liked this tutorial.\nI would thank Luxion for making this useful software for designers.","Blender is a free and open-source 3D animation suite software. It supports the entirety of the 3D pipeline—modeling, rigging, animation, simulation, rendering, compositing and motion tracking, even video editing and game creation.\nAdvanced users employ Blender’s API for Python scripting to customize the application and write specialized tools; often these are included in future releases. It is well suited to individuals and small studios who benefit from its unified pipeline and responsive development process.\nBlender is cross-platform and runs equally well on Linux, Windows, and Macintosh computers. Its interface uses OpenGL to provide a consistent experience. It has no price tag, but you can invest, participate, and help to advance a powerful collaborative tool: Blender is your own 3D software.\nFeature of Blender:\nBlender now features a powerful new unbiased rendering engine called Cycles that offers stunning ultra-realistic rendering.\nBlender’s comprehensive array of modeling tools make creating, transforming and editing your models a breeze.\nWith this software new rendering engine, the possibilities for materials are endless.\nTransforming a model into a possible character has never been easier!\nBlender offers an impressive set of rigging tools including:\n- Envelope, skeleton and automatic skinning\n- Easy weight painting\n- Mirror functionality\n- Bone layers and colored groups for organization\n- B-spline interpolated bones\nBlender’s animation feature set offers:\n- Character animation pose editor\n- Non-Linear Animation (NLA) for independent movements\n- IK forward/inverse kinematics for fast poses\n- Sound synchronization\nExperience the joy of sculpting organic subjects using the built-in sculpting feature set of Blender.\nFast UV Unwrapping\nEasily unwrap your mesh right inside Blender, and use image textures or paint your own directly onto the model.\nThe blender comes with a fully-fledged compositor built right in. That means no more exporting to third party programs, you can do it all without leaving the program.\nWhether you need a crumbling building, rain, fire, smoke, fluid, cloth or full-on destruction, Blender delivers great-looking results.\nIncluded in Blender is a complete game engine, allowing you to create a fully-featured 3d game right inside Blender.\nCamera and Object tracking\nThis software now includes a production-ready camera and object tracking. Allowing you to import raw footage, track the footage, mask areas and see the camera movements live in your 3d scene. Eliminating the need to switch between programs.\nLibrary of Extensions\nWith a large community of enthusiasts and developers, It comes loaded with a vast array of extensions that you can turn on or off easily.\nNovice and advanced users will love the ability to customize their layout completely. From simply splitting their viewport, to fully customizing it with python scripting, so it works for you.\nIt comes packed with import/export support for many different programs. Image: JPEG, JPEG2000, PNG, TARGA, OpenEXR, DPX, Cineon, Radiance HDR, SGI Iris, TIFF. Video: AVI, MPEG and Quicktime (on OSX). 3D: 3D Studio (3DS), COLLADA (DAE), Filmbox (FBX), Autodesk (DXF), Wavefront (OBJ), DirectX (x), Lightwave (LWO), Motion Capture (BVH), SVG, Stanford PLY, STL, VRML, VRML97, X3D.\n|Processor||64-bit quad-core CPU|\n|Memory||2 GB RAM (8 GB RAM Recommended)|\n|Graphics Card||OpenGL 3.2 compatible card with 2 GB video RAM (CUDA or OpenCL for GPU rendering)|\n|Display||1920×1080 pixels, 24-bit color|\n|OpenGL Version||2.1 (Blender 2.77 up to 2.79b)|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:fac1ca7f-9001-4e38-86f1-dff8b4706d8a>","<urn:uuid:5b2c29de-fa7b-4cee-8ef8-966783508fae>"],"error":null}
{"question":"What role does security architecture play in both application development and Industrial Control Systems, and what are the key vulnerabilities in both areas?","answer":"In application development, security architecture must be clearly defined with standards incorporating confidentiality, integrity, and availability, supported by suitable procedures and patterns. Similarly, in ICS environments, inadequate security architecture and design is listed as a key policy vulnerability. Both domains share common architectural vulnerabilities, including weak network security architecture, lack of proper authentication mechanisms, and insufficient access controls. The challenges extend to configuration management, with both application development and ICS facing risks from default configurations, unpatched systems, and inadequate security policies. The consequences of poor security architecture can be severe, potentially leading to operational shutdowns, financial losses, and safety risks, particularly in ICS environments.","context":["Application security is an integral part of software development projects, which directly impacts corporate and customer confidence. Security needs to be integrated throughout the software lifecycle — right from requirement analysis and release, all the way to retirement of the application. In this context, these four tips should be kept in mind on the application security front.\nBy submitting your personal information, you agree that TechTarget and its partners may contact you regarding relevant content, products and special offers.\nTip 1: Define application security standards\nYour organization must establish clearly defined application security standards, which incorporate the fundamental concepts of confidentiality, integrity and availability (CIA). These standards should be complemented by suitable procedures and patterns, since development teams rarely get the time to read policies.\nTip 2: Address the fundamental information security concepts\nBesides addressing CIA, there are other equally important application security fundamentals that you need to keep in mind. These six application security basics are: authentication, authorization, auditing, session, exception, and configuration management. Auditing is particularly significant on these fronts, since it works as a deterrent and a detection control.\nTip 3: Inculcate security across the SDLC\nThe retirement of legacy applications is an oft ignored aspect of application security. After identifying vulnerabilities, you may need to re-architect legacy applications. Companies usually don't have enough subject matter knowledge and documentation related to a legacy application. In such cases, you must reverse-engineer the compiled codebase to arrive at software design. If there is no possibility of re-architecting, you may have to fall back on patching the software. As far as possible, it's best to avoid the patch and release cycle.\nTip 4: Write defensive code\nKeep the acronym \"INSECURE\" framework in mind when trying to write defensive code. INSECURE spells out to the following aspects.\n• Inject-able code: Different kinds of injection attacks like SQL, LDAP, OS command or XML attacks have one thing in common — that data is not validated before it's accepted by the system. Data validation is crucial to prevent injection attacks.\n• Non-repudiation: This ensures that a system or a user cannot deny an action. Auditing can ensure that non-repudiation is not exercised, due to logging of all actions.\n• Spoofing of code: While writing a code, the developer needs to keep in mind that it should not be vulnerable to application security threats like spoofing, tempering, repudiation, information disclosure, denial of service and elevated privilege (STRIDE).\n• Exception error handling: Input validation helps you to mitigate almost 70% of application security attacks. Integration of error handling with the process of sending data back to the client also ensures that there is no disclosure of the software makeup. You should ensure that errors sent to the client are laconic and non-verbose.\n• Cryptographically weak code: Don't try to write your own crypto algorithms. Use industry-standard tested algorithms and the advanced encryption standard (AES).\n• Unsafe, unused functions in code: Ensure that developers don't use banned application programming interfaces (APIs). These are unsafe and prone to buffer overflow attacks and memory issues. Banned APIs are usually published on various vendor Websites. Through code review it's possible to determine headers and libraries used by the banned APIs. In unavoidable cases, you should ensure that you at least re-architect those portions of the code.\n• Reversible code: Obfuscation can be used to prevent reversibility of code, as it makes the code more difficult to read. Make sure that you obfuscate the complied code at the least, before it is deployed in the production environment. You must also ensure the availability of a de-obfuscator to avoid denial of service.\n• Elevated privileges: While writing code, ensure that it does not have to run with elevated privileges. The development environment often lacks security controls. Hence such code usually goes into production, which is more of a restricted environment. In the haste of going live, you usually don't get time to rectify mistakes, and often end up running codes with elevated privileges.\nAbout the author: Manoranjan (Mano) Paul is the Software Assurance Advisor for (ISC)2. His experience includes designing and developing security programs from compliance-to-coding, security in the SDLC, writing secure code, risk management, security strategy, and security awareness training and education.\n(As told to Dhwani Pandya.)\nKeep personality in mind when developoing software processes","Industrial Control Systems (ICS) are found everywhere–from automated machines that manufacture goods to an office building’s cooling system.\nPreviously, it was standard that ICS were based on specific OS and specific communication protocols. However, in recent years, system development costs have been reduced and productivity has been improved by implementing network connection based on general purpose OS and standard communication protocols.\nTo compete in today’s market-driven economy, businesses and organizations opt for efficient control systems that can automatically manage processes. ICS can be found in manufacturing, processing facilities, and even power plants–which play a vital role in running a country. On the other hand, the increased efficiency that ICS introduce also presents new problems on security. In reality, threat actors have much to gain when they attack such companies. A successful attack on ICS has serious impact on any organization. Some of these effects include operational shutdowns, damaged equipment, financial loss, intellectual property theft, and substantial health and safety risks.\nMotivations for attacking ICS\nThreat actors have different motives when choosing an enterprise to target. When carrying out attacks, these threat actors are often motivated by financial gain, political cause, or even a military objective. Attacks may be state-sponsored or they could also come from competitors, insiders with a malicious goal, and even hacktivists.\nOne of the earliest examples of an ICS attack happened in 2005 when 13 DaimlerChrystler U.S. car manufacturing plants went offline for nearly an hour. The main cause was Zotob PnP worm infections that exploited a Windows Plug and Play service. The total downtime has resulted in a backlog in production costing the company thousands of dollars. While the attack was not linked to an individual or a cybercriminal group, cybercriminals may also be hired by competitors who have much to gain from the damage caused by an attack.\nHow are ICS attacked?\nThe first stage of an attack against ICS usually involves reconnaissance that allows the attacker to survey the environment. The next step would be to employ different tactics that will help attackers gain a foothold in the target network. The strategies and tactics at this point are highly similar to a targeted attack. To launch a malware, an attacker will make use of all the possible vulnerabilities and specific configurations of an ICS. Once these vulnerabilities have been identified and exploited, the effects of an attack can cause changes to certain operations and functions or adjustments to the existing controls and/or configurations.\nThe complexity of launching an attack on ICS depends on different factors, from the security of the system to the intended impact (e.g., a denial-of-service attack that disrupts the target ICS is easier to achieve than manipulating a service and concealing its immediate effects from the controllers). While there are already a lot of ways for attackers to damage an ICS, new tactics will continue to emerge as more and more devices are introduced to every ICS environment.\nWhat vulnerabilities are exploited in ICS?\nSince all ICS deal with both Information Technology (IT) and Operational Technology (OT), grouping vulnerabilities by categories assists in determining and implementing mitigation strategies. The National Institute for Standards and Technology’s (NIST) security guide for ICS divides these categories into issues related to policy and procedure, as well as vulnerabilities found in various platforms (e.g., hardware, operating systems, and ICS applications), and networks.\nPolicy and Procedure Vulnerabilities\n- Inadequate security architecture and design\n- Few or no security audits of the ICS environment\n- Inadequate security policies for the ICS\n- Lack of ICS specific configuration change management\n- No formal ICS security training and awareness program\n- Lack of administrative mechanisms for security enforcement\n- No ICS specific continuity of operations or disaster recovery plans\n- No specific or documented security procedures were developed from the security policies for the ICS environment\nPlatform Configuration Vulnerabilities\n- Data unprotected on portable devices\n- Default system configurations are used\n- Critical configurations are not stored or backed up\n- OS and application security patches are not maintained\n- OS and application security patches are implemented without exhaustive testing\n- Inadequate access control policies such as ICS users have too many or two few privileges\n- OS and vendor software patches may not be developed until after security vulnerabilities are discovered\n- Lack of adequate password policy, accidental password disclosures, no passwords used, default passwords used, or weak passwords used\nPlatform Hardware Vulnerabilities\n- Inadequate testing of security changes\n- Lack of redundancy for critical components\n- Unsecure remote access of ICS components\n- Lack of backup power from generators or Uninterruptible Power Supply (UPS)\n- Dual network interface cards to connect networks\n- Inadequate physical protection of critical systems\n- Undocumented assets connected to the ICS network\n- Unauthorized personnel have physical access to equipment\n- Loss of environmental control could lead to overheating of a hardware\n- Radio frequency and electromagnetic pulses (EMP) cause disruptions and damage to circuitry\nPlatform Software Vulnerabilities\n- Denial-of-Service (DoS) attack against ICS software\n- Intrusion detection/prevention software not installed\n- Installed security capabilities are not enabled by default\n- ICS software could be vulnerable to buffer overflow attacks\n- Mishandling of undefined, poorly defined, or “illegal” network packets\n- Unnecessary services are not disabled in the OS and could be exploited\n- No proper log management, which makes it difficult to trace security events\n- The OLE for Process Control (OPC) communications protocol is vulnerable to Remote Procedure Call (RPC) and Distributed Component Object Model (DCOM) vulnerabilities\n- Use of unsecure industry-wide ICS protocols such as DNP3, Modbus, and Profibus\n- Inadequate authentication and access control for configuration and programming software\n- Many ICS communications protocols transmit messages in clear text across the transmission media\n- ICS software and protocols’ technical documentation are easily available and can help adversaries plan successful attacks\n- Logs and endpoint sensors are not monitored real-time and security breaches are not identified quickly\nMalware Protection Vulnerabilities\n- Anti-virus software not installed\n- Anti-virus detection signatures not updated\n- Anti-virus software installed in the ICS environment without exhaustive testing\nNetwork Configuration Vulnerabilities\n- Weak network security architecture\n- Passwords are not encrypted in transit\n- Network device configurations are not properly stored or backed up\n- Passwords are not changed regularly on network devices\n- Data flow controls e.g. Access Control Lists (ACL), are not used\n- Poorly configured network security devices e.g. incorrectly configured rules for firewalls, routers, etc.\nNetwork Hardware Vulnerabilities\n- Lack of redundancy for critical networks\n- Inadequate physical protection of network equipment\n- Loss of environmental control could lead to hardware overheating\n- Noncritical personnel have access to equipment and network connections\n- Unsecured USB and PS/2 ports that can be used to connect unauthorized thumb drives, keyloggers, etc.\nNetwork Perimeter Vulnerabilities\n- No network security perimeter defined\n- Firewalls are nonexistent or are incorrectly configured\n- ICS control networks used for non-control traffic e.g. web browsing and email\n- Control network services are not within the ICS control network e.g. DNS, DHCP are used by the control networks but are often installed in the corporate network\n- Critical monitoring and control paths are not identified\n- Authentication of users, data, or devices is substandard or nonexistent\n- Many ICS communications protocols have no integrity checks built-in making it easy for adversaries to manipulate communications undetected\n- Standard, well-documented protocols are used in plain text e.g. sniffed Telnet, FTP traffic can be analyzed and decoded using protocol analyzers\nWireless Connection Vulnerabilities\n- Inadequate authentication between clients and access points\n- Inadequate data protection between clients and access points\nNetwork Monitoring and Logging Vulnerabilities\n- No security monitoring of the ICS network\n- Inadequate firewall and router logs make it difficult to trace security events\nPossible weaknesses in ICS network\nEvery ICS environment may contain weaknesses depending on their configuration and their purpose. The size of an ICS environment can also be a factor–the bigger the environment, the greater the chance for an error to occur. An ICS environment that replaced its legacy system with modern systems and introduced tools like Industrial Internet of Things (IIoT) devices may also have more weaknesses for threat actors to exploit.\nIndustrial IoT and How It Affects ICS\nAs ICS continue to modernize, an increasing number of Internet of Things (IoT) devices are introduced to improve productivity and enhance system control. With the use of related IoT devices; process controls, data monitoring, and communication with other systems are made simpler. However, there are risks involved when smart devices are used for such tasks.\nIIoT incorporates machine learning and big data analysis. It also harnesses sensor data, machine-to-machine (M2M) communication, and automation technologies that have previously existed in the industrial setting. IIoT can perform tasks such as data aggregation, predictive analysis, prescriptive analysis, data value addition, and even the creation of new business models.\nSimilar to how the introduction of smart phones was followed by the rise of vulnerabilities and malware related to the platform, integrating Human Internet of Things (HIoT) and IIoT devices may create similar problems. In fact, managing IoT devices in the ICS environment can create major challenges in security, as each device will have to be properly defended and secured. Not applying adequate security leaves the entire ICS ecosystem highly vulnerable to attacks.\nWith the use of IIoT there are also a few unique challenges to overcome:\n- Technology fragmentation complicates network processes. As devices of different and/or independent operating systems are used, the varying patching schedules may be difficult to address. An example of this is when an ICS uses a mix of legacy systems and new software. Not only will the two not communicate properly, the vulnerabilities found in unpatched legacy systems may also be used by threat actors to break into an ICS network.\n- Machine to Machine (M2M) and IoT application development is difficult. Unlike manufacturing HIoT, which are mass produced, the development of M2M and IoT applications for ICS requires special skill sets on hardware and software development, IT, and communications.\n- Legacy systems and legacy communication protocols are still widely used in industrial environments. An example of legacy systems is Windows 3.1, which still runs the program DECOR (used in Airplane takeoff and landing). Then there are also legacy communications protocols that include PROFIBUS, which is still widely used today. These systems have to be integrated via standards-based protocol gateways to send and receive data and commands easier.\nAlthough hacking IoT devices may be challenging, threat actors behind targeted attacks are both knowledgeable and persistent–which could lead to successful breaches in a target’s network. In addition to this, device loss is also a major cause of data breach. One misplaced device may give cybercriminals the necessary access to penetrate the target’s network.\nPotential Impact on ICS Components following Cyber Attacks\nThe impact of cyber attacks on industries using ICS depends on the target’s nature of operation or the motivation of cybercriminals pursuing the attack. Every effect listed below may be felt by a target’s internal, as well as external, clientele.\n- Changes in a system, an operation system, or in application configurations. When systems are tampered with, it may produce unwanted or unpredictable results. This may be done to mask malware behavior or any malicious activity. This may also affect the output of a threat actor’s target.\n- Change in Programmable Logic Controllers (PLC), Remote Terminal Units (RTU), and other controllers. Similar to a change in systems, a change in controller modules and other devices can lead to damaged equipment or facilities. This can also cause process malfunction and disabled controls over a process.\n- Misinformation reported to operations. This scenario may lead to the implementation of unwanted or unnecessary actions due to wrong information. Such an event can result in a change in the programmable logics. This can also help hide malicious activity, which includes the incident itself or the injected code.\n- Tampered safety controls. Preventing the proper operation of fail safes, and other safeguards puts the lives of employees, and possibly even external clients, at risk.\nLike it? Add this infographic to your site:\n1. Click on the box below. 2. Press Ctrl+A to select all. 3. Press Ctrl+C to copy. 4. Paste the code into your page (Ctrl+V).\nImage will appear the same size as you see above."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:b85ab8a4-41d5-4ab1-95e8-2d40ea0e6b7f>","<urn:uuid:a16ccbd6-041d-4489-8a93-f4173871c8d6>"],"error":null}
{"question":"Could you explain how the green sonochemical synthesis of silver nanoparticles compares to the microwave-assisted synthesis method in terms of their reaction conditions and stabilizing agents?","answer":"The green sonochemical synthesis uses ultrasonic irradiation (400W, 24kHz) for 90 minutes at room temperature, with k-carrageenan (a natural polymer from red seaweeds) as the stabilizer. The process requires stirring for 1 hour followed by sonication and uses different concentrations of k-carrageenan (0.1-0.3 wt%). In contrast, the microwave-assisted synthesis employs low-molecular-weight sulfoethyl chitosan (SECS) as both reducing and capping agent, with SECS having masses of <50 kDa and requiring high substitution levels with sulfoethyl groups for stable nanoparticle formation.","context":["Green Sonochemical Route to Silver Nanoparticles\nGreen Ultrasonic Synthesis of Silver Nanoparticles\nElsupikhe et al. (2015) have developed a green ultrasonically-assisted synthesis route for the preparation of silver nanoparticles (AgNPs). Sonochemistry is well known to promote many wet-chemical reactions. Sonication enables to synthsize AgNPs with κ-carrageenan as natural stabilizer. The reaction runs at room temperature and produces silver nanoparticles with fcc crystal structure without any impurities. The particle size distribution of the AgNPs can be influenced by the concentration of κ-carrageenan.\n- The Ag-NPs were synthesized by reducing AgNO3 using ultrasonication in the presence of κ-carrageenan. To obtain different samples, five suspensions were prepared, by adding 10 mL of 0.1 M AgNO3 to 40-mL κ-carrageenan. The κ-carrageenan solutions used were 0.1, 0.15, 0.20, 0.25, and 0.3 wt%, respectively.\n- The solutions were stirred for 1h to obtain AgNO3/κ-carrageenan.\n- Then, the samples were exposed to intense ultrasonic irradiation: The amplitude of the ultrasonic device UP400S (400W, 24kHz) was set to 50%. Sonication was applied for 90min at room temperature. The sonotrode of the ultrasonic liquid processors UP400S was immersed directly into the reaction solution.\n- After sonication, the suspensions were centrifuged for 15min and washed with double distilled water four times to remove the silver ion residue. The precipitated nanoparticles were dried at 40°C under vacuum overnight to obtain the Ag-NPs.\n- nH2O —sonication–> +H + OH\n- OH + RH –> R + H2O\n- AgNo3–hydrolysis–> Ag+ + NO3–\n- R + Ag+ —> Ag° + R’ + H+\n- Ag+ + H –reductions–> Ag°\n- Ag+ + H2O —> Ag° + OH + H+\nAnalysis and Results\nTo evaluate the results, the samples were analyzed by UV-visible spectroscopic analysis, X-ray diffraction, FT-IR chemical analysis, TEM and SEM images.\nThe number of Ag-NPs increased with increasing κ-carrageenan concentrations. The formation of Ag/κ-carrageenan was determined by UV-visible spectroscopy where the surface plasmon absorption maximum was observed at 402 to 420nm. The X-ray diffraction (XRD) analysis showed that the Ag-NPs are of a face-centered cubic structure. The Fourier transform infrared (FT-IR) spectrum indicated the presence of Ag-NPs in κ-carrageenan. Transmission electron microscopy (TEM) image for the highest concentration of κ-carrageenan showed the distribution of Ag-NPs with an average particle size near to 4.21nm. Scan electron microscopy (SEM) images illustrated the spherical shape of the Ag-NPs. The SEM analysis shows that with increasing κ-carrageenan concentration, changes in the surface of Ag/κ-carrageenan occurred, so that small-sized Ag-NPs with spherical shape were obtained.\n- Elsupikhe, Randa Fawzi; Shameli, Kamyar; Ahmad, Mansor B; Ibrahim, Nor Azowa; Zainudin, Norhazlin (2015): Green sonochemical synthesis of silver nanoparticles at varying concentrations of κ-carrageenan. Nanoscale Research Letters 10. 2015.\nWhen powerful ultrasound is applied to chemical reactions in solution (liquid or slurry state), it provides specific activation energy due to a physical phenomenon, known as acoustic cavitation. Cavitation creates high shear forces and extreme conditions such as very high temperatures and cooling rates, pressures and liquid jets. These intense forces can initiate reactions and destroy attractive forces of molecules in the liquid phase. Numerous reactions are known to benefit from ultrasonic irradiation, e.g. sonolysis, sol-gel route, sonochemical synthesis of palladium, latex, hydroxyapatite and many other substances. Read more about sonochemistry here!\nSilver nano-particles are characterized by a size of between 1nm and 100nm. While frequently described as being ‘silver’ some are composed of a large percentage of silver oxide due to their large ratio of surface-to-bulk silver atoms. Silver nanoparticles can appear with different structures. Most commonly, spherical silver nanoparticles are synthesized, but diamond, octagonal and thin sheets are also utilized.\nSilver nanoparticles are highly frequented in medical applications. The silver ions are bioactive and have strong antimicrobial and germicidal effects. Their extremely large surface area allows for the coordination of numerous ligands. Other important characteristics are conductivity and unique optical properties.\nFor their conductive features, silver nanoparticles often incorporated in composites, plastics, epoxies and adhesives. The silver particles increase the electrical conductivity; therefore silver pastes and inks are frequently used in the manufacturing of electronics. Since silver nanoparticles support surface plasmons, AgNPs have outstanding optical properties. Plasmonic silver nanoparticles are used for sensors, detectors and analytical equipment such as Surface Enhanced Raman Spectroscopy (SERS) and Surface Plasmon Field-enhanced Fluorescence Spectroscopy (SPFS).\nCarrageenan is a cheap natural polymer, which is found in various species of red seaweeds. Carrageenans are linear sulphated polysaccharides that are widely used in the food industry, for their gelling, thickening, and stabilizing properties. Their main application is in dairy and meat products, due to their strong binding to food proteins. There are three main varieties of carrageenan, which differ in their degree of sulphation. Kappa-carrageenan has one sulphate group per disaccharide. Iota-carrageenan (ι-carrageenen) has two sulphates per disaccharide. Lambda carrageenan (λ-carrageenen) has three sulphates per disaccharide.\nKappa carrageenan (κ-carrageenan) has a linear structure of sulfated polysaccharide of D-galactose and 3,6-anhydro-D-galactose.\nκ- carrageenan is widely used in the food industry, e.g. as gelling agent and for texture modification. It can be found as additive in ice cream, cream, cottage cheese, milkshakes, salad dressings, sweetened condensed milks, soy milk & other plant milks, and sauces to increase the product viscosity.\nFurthermore, κ-carrageenan can be found in non-food products such as thickener in shampoo and cosmetic creams, in toothpaste (as stabilizer to prevent constituents separating), fire fighting foam (as thickener to cause foam to become sticky), air freshener gels, shoe polish (to increase viscosity), in the biotechnology to immobilize cells/enzymes, in pharmaceuticals (as an inactive excipient in pills/tablets), in pet food etc.","Low-molecular-weight sulfonated chitosan as template for anticoagulant nanoparticles\nAuthors Heise K, Hobisch M, Sacarescu L, Maver U, Hobisch J, Reichelt T, Sega M, Fischer S, Spirk S\nReceived 25 April 2018\nAccepted for publication 12 June 2018\nPublished 30 August 2018 Volume 2018:13 Pages 4881—4894\nChecked for plagiarism Yes\nReview by Single anonymous peer review\nPeer reviewer comments 3\nEditor who approved publication: Prof. Dr. Thomas J. Webster\nKatja Heise,1,2 Mathias Hobisch,3,4 Liviu Sacarescu,5 Uros Maver,6 Josefine Hobisch,3 Tobias Reichelt,7 Marija Sega,6 Steffen Fischer,1 Stefan Spirk3,4\nMembers of EPNOE and NAWI Graz\n1Institute of Plant and Wood Chemistry, Technische Universität Dresden, Tharandt, Germany; 2Department of Bioproducts and Biosystems, Aalto University, Espoo, Finland; 3Institute for Chemistry and Technology of Materials, Graz University of Technology, Graz, Austria; 4Institute for Paper, Pulp and Fiber Technology, Graz University of Technology, Graz, Austria; 5“Petru Poni” Institute of Macromolecular Chemistry, Romanian Academy, Iasi, Romania; 6Faculty of Medicine, University of Maribor, Maribor, Slovenia; 7Zentrum für Bucherhaltung GmbH, Leipzig, Germany\nPurpose: In this work, low-molecular-weight sulfoethyl chitosan (SECS) was used as a model template for the generation of silver core-shell nanoparticles with high potential as anticoagulants for medical applications.\nMaterials and methods: SECS were synthesized by two reaction pathways, namely Michael addition and a nucleophilic substitution with sodium vinylsulfonate or sodium 2-bromoethanesulfonate (NaBES). Subsequently, these derivatives were used as reducing and capping agents for silver nanoparticles in a microwave-assisted reaction. The formed silver-chitosan core-shell particles were further surveyed in terms of their anticoagulant action by different coagulation assays focusing on the inhibition of either thrombin or cofactor Xa.\nResults: In-depth characterization revealed a sulfoalkylation of chitosan mainly on its sterically favored O6-position. Moreover, comparably high average degrees of substitution with sulfoethyl groups (DSSE) of up to 1.05 were realized in reactions with NaBES. The harsh reaction conditions led to significant chain degradation and consequently, SECS exhibits masses of <50 kDa. Throughout the following microwave reaction, stable nanoparticles were obtained only from highly substituted products because they provide a sufficient charge density that prevented particles from aggregation. High-resolution transmission electron microscopy images reveal that the silver core (diameter ~8 nm) is surrounded by a 1–2 nm thick SECS layer. These core-shell particles and the SECS itself exhibit an inhibiting activity, especially on cofactor Xa.\nConclusion: This interesting model system enabled the investigation of structure–property correlations in the course of nanoparticle formation and anticoagulant activity of SECS and may lead to completely new anticoagulants on the basis of chitosan-capped nanoparticles.\nKeywords: chitosan ethylsulfonate, silver nanoparticles, antithrombotic activity, cofactor Xa\nThis work is published and licensed by Dove Medical Press Limited. The full terms of this license are available at https://www.dovepress.com/terms.php and incorporate the Creative Commons Attribution - Non Commercial (unported, v3.0) License. By accessing the work you hereby accept the Terms. Non-commercial uses of the work are permitted without any further permission from Dove Medical Press Limited, provided the work is properly attributed. For permission for commercial use of this work, please see paragraphs 4.2 and 5 of our Terms.Download Article [PDF] View Full Text [HTML][Machine readable]"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:6b9df735-b758-4133-bdca-36aac7e836fd>","<urn:uuid:84fb0900-eb97-43ed-9581-92ffac0d7bb8>"],"error":null}
{"question":"What are the main advantages and disadvantages of investing in municipal mutual funds versus government bond funds?","answer":"Municipal mutual funds offer key benefits including tax-exempt interest, professional management, diversification across multiple issuers, easy liquidity, and convenient features like dividend reinvestment and checkwriting. However, they have drawbacks such as lack of fixed maturity dates and possible taxable capital gain distributions. Government bond funds, while not tax-exempt, provide greater safety due to U.S. government backing and offer clearly defined duration options (short-, intermediate-, or long-term). They have lower default risk compared to other bond types but are still subject to interest rate risk, with longer-duration funds being more sensitive to rate changes. Both fund types provide alternatives to buying individual bonds, but their suitability depends on factors like an investor's tax bracket and risk tolerance.","context":["- What are tax-free investments?\n- What different types of municipal securities are available to investors?\n- What factors should investors consider when choosing between taxable and tax-exempt securities?\n- Are there risks associated with municipal securities?\n- How can investors gain exposure to tax-free investments in their portfolios?\n- What are the benefits of tax-free mutual funds?\n- Are there drawbacks to tax-free mutual funds?\n- Who should consider tax-free investments?\nState and local governments around the country issue a large quantity of debt securities to raise needed capital. The majority of these securities—often referred to as municipal bonds or simply \"munis\"—provide investors with interest that is exempt from federal income taxes. This income may also be exempt from state and local taxes for investors who reside in the issuing state or locality. A New York City bond, for example, would be triple-tax-free (i.e., exempt from federal, state, and local taxes) for an investor living in New York City. Because of this tax exemption, the terms \"tax-free investments\" and \"municipal investments\" are often used interchangeably.\nGeneral obligation bonds (GOs) and revenue bonds are two major classes of municipal securities differentiated by the source of funding for their interest payments. GOs are issued to finance various government operations and are backed by the issuer's power to raise taxes, if necessary, to make scheduled interest and principal payments. Revenue bonds, meanwhile, finance specific projects, such as transportation and utilities, and are backed by the revenue generated from the projects. Due to their potentially variable cash flows, revenue bonds are often considered riskier than GOs.\nIn addition, municipalities sometimes issue securities to help finance private development considered beneficial to local economies. The income from these \"private activity\" bonds is exempt from federal income tax but may be subject to the alternative minimum tax.\nMunicipal securities are issued for a wide variety of purposes and, as such, have varying maturities and yields. Many munis are short-term notes issued in anticipation of pending tax receipts or other revenues. These money market securities generally offer low yields due to their short maturities. Major projects, on the other hand, tend to be funded by longer-term bonds offering higher yields. In either case, coupon payments may be fixed or tied to a floating interest rate that resets periodically.\nDue to the potential tax advantage, investors typically accept lower yields from munis than they would from similar taxable securities. Because of this yield differential, one's tax status plays a major factor in the attractiveness of tax-free investments. While municipal securities could benefit investors in any tax bracket, they tend to appeal the most to those who are in the highest tax brackets or live in high-tax jurisdictions.\nA simple way to gauge whether investing in a given municipal security would be more attractive than investing in a comparable taxable security is to calculate its equivalent taxable yield. This can be done in three steps:\n|(1)||Find the current yield of the tax-free investment you are considering (e.g., 5%).|\n|(2)||Subtract your federal tax bracket, expressed as a decimal, from 1.0\n(e.g., 1.0 – 0.25 = 0.75).\n|(3)||Divide the tax-free yield in step 1 by the number obtained in step 2\n(e.g., 5% ÷ 0.75 = 6.67%).*\nIn this example, an investor in the 25% tax bracket would need a taxable security yielding at least 6.67% to receive the same amount of income, after the deduction of federal taxes, as a tax-exempt security yielding 5%. If no such taxable security is available, the tax-free security would be the better option. Of course, investors should make sure to compare securities with similar risk attributes such as credit quality and time to maturity.\nIn addition, the decision to invest in tax-free securities should be made in the larger context of maintaining a diversified portfolio of stocks and bonds that is in line with your risk tolerance, time horizon, and investment objectives. Also bear in mind that tax-free securities typically are not appropriate for inclusion in tax-deferred accounts such as IRAs.\nLike other types of fixed income securities, munis are subject to interest rate and credit risk. Interest rate risk is the potential for price fluctuations due to changes in interest rates—as interest rates rise, bond prices fall (and vice versa). In general, the longer a bond's maturity, the more sensitive its price will be to interest rate movements.\nCredit risk is the possibility that the security issuer will not be able to make scheduled interest or principal payments. Although municipal bond defaults historically have been rare events, a weak local economy and reduced tax revenues could present serious challenges for a state or local government's finances. To gauge credit risk, the major credit rating agencies grade municipal bonds' credit qualities in a similar manner to corporate bonds. A downgrade to a bond's credit rating could result in a lower bond price and a higher yield to compensate for the additional risk.\nOther municipal market risks include liquidity risk—or the ability to easily sell a security, if needed, at a desired price—and uncertainty about future tax laws. In addition, some income may be subject to the federal alternative minimum tax.\nYou can purchase municipal bonds through a broker or bond dealer. Another option is to invest in a mutual fund focused on municipal securities. Many large fund companies offer tax-free bond and money funds for investors nationwide as well as funds targeted to residents of certain states. Funds may also focus on specific credit-quality or maturity segments of the municipal market.\nA major benefit of mutual funds is diversification. When buying individual bonds, it may be difficult to develop a portfolio that has a sufficiently diverse range of holdings to reduce the impact of losses on individual securities. Tax-free mutual funds—even those investing in a single state—often hold dozens of different issuers and types of securities. Of course, diversification cannot assure a profit or protect against loss in a declining market.\nMutual funds also have professional managers and municipal analysts who perform the essential credit research and security selection processes that would be time-consuming and impractical for most individuals to do on their own. Funds also provide liquidity by allowing investors to easily sell all or a portion of their shares at the day's closing market price, often without the transaction costs associated with individual bonds. Finally, many fund companies offer conveniences such as automatic dividend reinvestment and checkwriting.\nA downside to municipal funds is that they do not have fixed coupons or maturity dates like individual bonds. Thus, there is less certainty about future income. With an individual bond, an investor knows—barring a default or the early retirement of a bond with a call option—the timing and amount of cash flows.\nAnother downside to municipal funds is the possibility of taxable capital gain distributions. Although investors in individual bonds may be subject to capital gains taxes if they sell municipal securities above their purchase price, they have greater control over the distribution decision.\nInvestors should also carefully compare a mutual fund's annual expense ratio, which is expressed as a percentage of fund assets, with the costs and fees they would incur from purchasing individual muni bonds.\nInvestors often overlook municipal securities when building a portfolio. Due to the potential for lower investment taxes and regular income, investors in every tax bracket should consider whether munis are a good fit for the fixed income portion of their portfolios. This is especially true when there are expectations for tax rates to rise.\n*A more precise approach is to also consider state and local taxes that are deductible at the federal level. To do this, subtract your combined state and local tax rate, expressed as a decimal, from 1.0, and then multiply the result by the number obtained in step 2. Finally, divide the tax-free yield in step 1 by the product of the two numbers.","Government bond funds and inflation protection funds\nGovernment bond funds provide a way for investors to hold a portfolio of income-producing debt securities without the expense and increased risk of buying individual bonds. Investors who are interested in bond funds have many different choices. Corporate bond funds, municipal bond funds and high-yield bond funds are just a few of the different types of mutual funds that invest in bonds.\nInvestors who compare bond funds should keep in mind that the funds with the highest yields are not always the safest funds. When an investor searches for the best CD rates or the highest rates on savings accounts, they know that all bank deposits are protected by FDIC insurance up to the insurance limit of $250,000. The presence of deposit insurance levels out the risk when comparing different banks and rates.\nInvestors evaluating bond funds can't rely on FDIC insurance. Instead, they need to factor in potential price swings, interest-rate sensitivity, prepayment risk and default risk to make an informed decision. Each bond fund can be quite different from the next. Automatically investing in the highest-yielding fund can be dangerous.\nGovernment bond funds\nGovernment bond funds are a category of funds that invest primarily in U.S. government securities. These funds provide investors a safer bond fund alternative than many other types of bond funds. The creditworthiness of the U.S. government itself decreases the default risk in comparison to funds that invest in low-grade bonds, international bonds, commercial paper, municipal bonds or corporate bonds.\nThe rate of return on a government bond fund is determined by changes in the price (net asset value) of the fund and by the value of the distributions that are paid out by the fund. The interest rate decisions of the Federal Reserve can directly affect the price of short-term government bond funds, while the prices of long-term government bond funds are typically driven by market forces.\nThe duration of a government bond fund is the weighted average of the time to maturity for the bonds held in the portfolio. In general, government bond funds with shorter durations will experience less interest rate sensitivity and volatile price swings. If inflation picks up, bond funds are forecast to have more moderate returns. Always check a fund's prospectus for complete information regarding fees, expenses, holdings and investment goals before investing.\nShort-term government bond funds\nShort-term government bond funds invest primarily in U.S. government securities with maturities of less than five years. These securities may include Treasury bills, notes, bonds, mortgage-backed securities issued by government lending agencies and other Treasury securities with maturities less than five years. Cash instruments including money market accounts, money funds and CDs can also be used by portfolio managers.\nShort-term government bond funds are typically less volatile to interest rate changes than intermediate or long-term government bond funds.\nIntermediate-term government bond funds\nIntermediate-term government bond funds are funds that primarily invest in U.S. government securities that may include Treasury bills, notes, bonds, mortgage-backed securities issued by government lending agencies and other Treasury securities with maturities typically ranging between five and 10 years.\nLong-term government bond funds\nLong-term government bond funds are funds that primarily invest in U.S. government securities with maturities 10 years and longer. Bond fund holdings may include Treasury bonds, mortgage-backed securities issued by government lending agencies and other Treasury securities with longer maturities. Many long term government bond funds seek to provide investment results that outperform the Long Treasury Bond Index. Funds in this category typically offer higher yields, but will also usually be more interest-rate sensitive.\nInflation-protection funds are funds that are target the rate of inflation in the U.S. economy. Inflation-protection funds are designed for investors seeking inflation protection in their portfolios. Rates of return are expected to correspond to the general increases and decreases in inflation in the U.S. economy, but can vary from fund to fund as portfolio managers choose different inflation strategies. Taxes on both income and principal adjustments (CPI increases) can apply.\nAs always, check with an adviser regarding the suitability of an investment before you purchase it."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:c1ef5665-9098-4dc3-b504-940acc5c0558>","<urn:uuid:3700dd6a-727c-4795-8df0-d389a012eced>"],"error":null}
{"question":"What are the benefits of grilling a turkey outdoors, and what food safety precautions must be taken when cooking outside?","answer":"Grilling a turkey outdoors provides several benefits: it tastes better due to the smoke flavor, frees up the oven for other dishes, creates an opportunity to spend time outdoors with friends, and produces a gorgeous mahogany-colored bird with crispy skin and juicy meat. It also avoids large amounts of oil used in frying. However, when cooking outdoors, specific safety measures must be followed: hands and utensils must be kept clean to prevent cross-contamination, food shouldn't be left out for more than 2 hours (or 1 hour in temperatures above 90 degrees), hot food must be kept above 140 degrees, cold food must be kept below 40 degrees, and a food thermometer must be used to ensure proper cooking temperature. Additionally, if there's no potable water source at the destination, water for cleaning must be brought along.","context":["Is it time to grill the bird?\nTired of the same old bird for the holidays? Give your turkey an extreme makeover by taking the cooking – and the party – outside.\n“A turkey smoke-roasted on the grill tastes better, thanks to the smoke flavor,” says Steve Raichlen, author of The Barbecue Bible and How to Grill and host of the PBS series “Primal Grill.” “It frees up your oven for other dishes. It gives you an excuse to spend the afternoon outdoors, gathered around the grill drinking beer or wine with your buddies.”\nAnd get ready for the “oohs” and “aaahs” when you present a turkey smoked to perfection: “a gorgeous, plump, mahogany colored bird – the skin crackling crisp, the meat tender and juicy, the whole shebang perfumed with wood smoke,” says Raichlen.\n“Guests are totally amazed because they would never guess that a whole turkey can be cooked outdoors,” says Dave DeWitt, editor of Fiery-Foods.com. It also nicely avoids the large amounts of oil used in frying turkeys.\nAmong the options for cooking a turkey outdoors are grilling, rotisserie and smoking in a ceramic smoker. DeWitt favors the rotisserie method “because it’s so versatile, you don’t need to worry about flipping the meat over, like you would with grilling, the heat is even and you don’t have to tend to it very much.”\nDeWitt is not keen on cutting up the bird to cook on the grill, which he says takes away the beauty of a whole bird in the center of the table and may lead to burning the bird if you step away for too long to watch the game.\nRaichlen favors cooking a whole turkey in a ceramic smoker or on the charcoal grill, which he says “is best for the reason that it’s easy to smoke on a charcoal grill and very difficult to smoke on a gas grill.” (See Raichlen’s recipe, below).\nHere are several of their tips to cooking your turkey outdoors:\nAssemble Your Tools\nRaichlen suggests a barbecue injector, which enables you to inject some of the marinade into the turkey. Consider food gloves for handling the turkey. Both Raichlen and DeWitt say a meat thermometer is essential.\nSmoke ‘Em Out\nRaichlen prefers natural lump charcoal, not briquettes, which can have a chemical taste if not properly lit. Soak wood chips before placing them on the charcoal once the ash is well formed. DeWitt prefers fruitwood, such as apple, which gives the turkey a mild smoky flavor.\n“Most of the barbecue flavor comes from the fat that drips from the bird onto the hot coals or wood, which interacts with the smoke and rises to coat the bird.”\nThere’s the Rub\nDeWitt likes using a low-sodium rub on his smoked turkey. Make your own rub from paprika, garlic and ground chili pepper. “Salt draws out the fluids from the turkey and you want your turkey as moist as possible,” he says\nPause Before Serving\nBe patient. “Let the bird rest for 20 minutes before carving to let the juices redistribute themselves,” Raichlen says. “It will be much moister.”\nBourbon-Injected Barbecued Turkey\nAdapted from BBQ USA by Steven Raichlen\nFor the injector sauce:\n- 2 tablespoons salted butter\n- 1/3 cup chicken stock (preferably homemade), at room temperature\n- 2 tablespoons bourbon\n- 1 tablespoon of your favorite commercial barbecue rub (Note: Finely grind in a spice mill or coffee grinder if the rub has any coarse bits or spices in it so it doesn’t clog the injector)\nFor the turkey:\n- 1 turkey (8 to 10 pounds), thawed if frozen\n- 4 tablespoons your favorite commercial barbecue rub\n- 1 tablespoon melted butter\nYou’ll also need:\n- A marinade injector\n- 3 cups of wood chips, preferably apple, soaked for 1 hour in water to cover, then drained\n1. To make the injector sauce, melt the butter in a small saucepan. Add the stock, bourbon and rub and whisk to mix. Let cool to room temperature.\n2. Remove the packet of giblets from the neck or body cavity of the turkey and set aside for another use. Remove and discard the fat just inside the cavities of the turkey. Rinse the turkey, inside and out, under cold running water, then blot dry, inside and out, with paper towels. Season the inside of both cavities with 2 tablespoons of the rub.\n3. Fill the injector with the injector sauce. To do this, push the plunger all the way down, place the tip of the needle in the sauce, and slowly draw the plunger up. The syringe will fill with sauce. Inject the sauce into the turkey breast, thighs, and drumsticks. Don’t be surprised if a little sauce squirts out; this is okay.\n4. Set up the grill for indirect grilling and preheat to medium. If using a gas grill, place all of the wood chips or chunks in the smoker box or in a smoker pouch and run the grill on high until you see smoke, then reduce the heat to medium. If using a charcoal grill, place a large drip pan in the center, preheat the grill to medium, then toss 1 cup of the wood chips or chunks on the coals.\n5. When ready to cook, place the turkey, breast side up, in the center of the hot grate, over the drip pan and away from the heat. Put the lid down and cook the turkey until the skin is nicely browned and the meat is cooked through, 2-1/2 to 3 hours. To check for doneness, insert an instant-read thermometer in the thickest part of a thigh but not so that it touches the bone. The internal temperature should be about 165 degrees F. If the wing tips start to burn, cover them loosely with aluminum foil; if the skin starts to brown too much, cover the bird loosely with aluminum foil.\n6. Transfer the grilled turkey to a platter, cover it loosely with aluminum foil and let it rest for 10 minutes. Serves 8 to 10.\nLooking for an unusual brined take on the more traditional roast turkey recipe? See Julianne Glatz’s, “Roasting a better bird,” Nov. 12.","Elizabeth S. Reames | 5/30/2006 10:26:03 PM\nKeeping food safe at picnics or while eating outdoors poses special problems. The challenge of keeping hands and utensils clean is greater when preparing and eating food outdoors and away from the kitchen.\nLSU AgCenter nutritionist Dr. Beth Reames says a major food safety concern is cross-contamination, which occurs when harmful microorganisms from raw meat and poultry are transferred to cooked and other ready-to-eat foods from improperly cleaned hands, utensils and cutting boards.\nThe U.S. Department of Agriculture offers a number of reminders about safe picnicking.\nKeep everything clean. Find out if there's a source of potable (safe drinking) water at your destination. If not, bring water for preparation and cleaning; or pack clean, wet, disposable cloths or moist towelettes and paper towels for cleaning hands and surfaces. Cross-contamination during preparation, grilling and serving food is a prime cause of foodborne illness.\nAlways wash your hands before and after handling food, and don’t use the same platter and utensils for raw and cooked meat and poultry. Soap and water are essential to cleanliness, so if you are going somewhere that will not have potable water, bring water with you. Even disposable wipes will do. Include lots of clean utensils, not only for eating but also for serving the safely cooked food.\nKeep hot food hot and cold food cold. It’s essential to keep hot food hot and cold food cold on the way to, and throughout, the meal. Keeping food at an unsafe temperature is a prime cause of foodborne illness. Already-hot summertime temperatures can spike higher in direct sunlight on the beach or in a boat. Food should not be left out of the cooler or off the grill more than two hours (one hour when the outside temperature is above 90 degrees).\nMost bacteria do not grow rapidly at temperatures below 40 degrees or above 140 degrees. The temperature range in between is known as the \"danger zone.\" Bacteria multiply rapidly at these temperatures and can reach dangerous levels. Raw meat and poultry may contain bacteria that cause foodborne illness. They must be cooked to destroy these bacteria and held at temperatures that are either too hot or too cold for these bacteria to grow.\nStudies have shown that using a food thermometer is the only way to tell if harmful bacteria have been destroyed. For instance, even if they look fully cooked, one in four hamburgers may not be adequately cooked.\nKeep hot food hot. If bringing hot takeout food such as fried chicken or barbecue, eat it within two hours of purchase. Or plan ahead and chill the food in your refrigerator before packing it into an insulated cooler. In addition to a grill and fuel for cooking food, remember to pack a food thermometer to check that your meat and poultry reach a safe internal temperature. When reheating food at the outing, be sure it reaches an internal temperature of 165 degrees\nKeep cold foods cold. Carry cold perishable food like hamburger patties, hotdogs, luncheon meats and chicken in an insulated cooler packed with plenty of ice or frozen gel packs. Be sure raw meat and poultry are wrapped securely to prevent juices from cross-contaminating ready-to-eat food. Perishable cooked foods such as meats, chicken and potato or pasta salads must be kept cold, too.\nStore food in the cooler except for brief times when serving. Cook only the amount of food that will be eaten to avoid the challenge of keeping leftovers at a safe temperature. Discard any leftovers that have not remained cold.\nFor additional information about keeping food safe to eat, contact the extension agent in your parish LSU AgCenter office.\nOn the Internet: LSU AgCenter: www.lsuagcenter.com\nSource: Beth Reames (225) 578-3329, or email@example.com"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:eaaa5e71-9941-44c2-a931-c10f49bc2311>","<urn:uuid:7e02d302-192a-49b8-9065-321ded8dd3bf>"],"error":null}
{"question":"What percentage of IDD patients need behavioral assistance for dental treatment?","answer":"Nearly 40% of patients with intellectual and developmental disabilities require some form of behavioral assistance to receive dental treatment.","context":["May 11, 2017\nDevelopmental disabilities affect the mind, the body and the skills people use in everyday life. People with intellectual and developmental disabilities (IDD) often need extra help to achieve and maintain good oral health. And they are particularly at-risk for oral health issues such as severe tooth decay and periodontal disease. Poor communication skills, lack of manual dexterity, fear, uncontrolled movements, and other physical, emotional or behavioral factors can make it difficult for them to maintain proper oral hygiene.\nAdditionally, there is a lack of properly trained dentists around the country to serve the unique needs of disabled populations. “Adults with intellectual and developmental disabilities suffer from poor oral health as access to care is a serious issue in this population,” according to Dr. Bob Rada, Clinical Professor, Oral Medicine and Diagnostic Sciences at UIC College of Dentistry. “In part this is due to funding issues and part is due to the limited experiences dentists have in treating these patients. Additional training is necessary as nearly one-quarter of the patients have only a limited ability to accept any dental intervention without the application of advanced behavior management techniques, and nearly 40% require some form of behavioral assistance to receive dental treatment.”\nGraduates of UIC College of Dentistry are prepared to provide oral health care to intellectual and developmental disabled patients.\nGiven the unique physical and social needs of an individual with a disability such as cerebral palsy or autism, providing dental care requires extra preparation and training. This is why students at UIC College of Dentistry receive specialized training necessary to provide oral health care to intellectual and developmental disabled patients. Part of this training includes visits to area health centers and agencies that specialize in serving these needs.\nServing at United Cerebral Palsy (UCP) Seguin of Greater Chicago\nUnited Cerebral Palsy (UCP) Seguin of Greater Chicago is a charitable not-for-profit agency serving individuals with disabilities in metropolitan Chicago. Its personnel ensure that adults with disabilities can live and socialize within the community by offering residential services in multiple small, community-based homes.\n“Our University of Illinois at Chicago College of Dentistry students have become a big part of keeping the UCP Seguin clients healthy while learning to care for individuals with intellectual and developmental disabilities,” explained Dr. Bob Rada, Clinical Professor, Oral Medicine and Diagnostic Sciences. Under Dr. Rada’s direction, students held three clinics at the agency in January and February of 2017. Over the course of the clinics, the students served about 95 patients with procedures including operative, extractions, partial denture and crown cementation, preventive, and a gingivectomy. “Some of the patients receive oral antianxiety meds and some require medical immobilization,” Dr. Rada noted. “As the students work with behaviorists and social workers it is also a great inter-professional education experience. Students receive relative value units for clinical credit.”\nDr. Rada has had a long relationship providing dental care to UCP Seguin clients. “Recently we began using portable dental equipment to provide care on-site at their center in Cicero,” he noted. “Seguin clients come to the center to participate in various activities and workshops. While they are there, they can easily have dental treatment completed, without having to travel and in the comfort of their own environment.”\nStudents who participated were Vivian Castellanos, Rhythm Fadia, Laurel Frausto, Sumayya Hameed, Risha Khan, Camila Peralta-Sugano, Morini Rahman, Gabija Revis, Daniel Rosales, Gayatri Satam, Manali Tanna-Madhavani, Melissa Villafane, and Winnie Wilson.\n“It was truly a rejuvenating experience to have the opportunity to work with a population that goes above and beyond to genuinely convey their wholehearted gratitude for the dental services we provided,” said student Vivian Castellanos, D-4. “After each appointment, all of my patients would be smiling ear to ear and would look forward to receiving a hug, high-five, thumbs up or combination of each from me—that's what raw human connection looks like. “\nWorking with CURE (Collaborative Underserved Relief and Education) Network\nThe CURE (Collaborative Underserved Relief and Education) Network offers free dental, medical, and vision care to the uninsured and underinsured in the Chicago area. Since its inception in 2010, the CURE network has provided more than $27 million in free care to more than 4,000 patients. Students of UIC College of Dentistry participated in an event providing healthcare at CURE in LaGrange Park, IL, in the fall of 2015.\nStudents Dante Brown, Jihan Doss, and Mark White, along with faculty member Dr. Robert Rada, Clinical Professor, Oral Medicine and Diagnostic Sciences, provided both preventive care and extractions of infected teeth.\nThe students are in the Public Health and Advocacy track overseen by Dr. Caswell Evans, Associate Dean for Prevention and Public Health Sciences, at the College of Dentistry.\nA total of 308 patients visited the event, and about two-thirds of them received both dental and vision services. Equipment was provided by the Mission of Mercy organization, which also provides free healthcare to the needy. About 50 dental chairs were organized in hygiene, oral surgery, and restorative sections. Patients were triaged and walked to and from the appropriate section by volunteers.\n“The unique part is that our students provided the dental care,” Dr. Rada explained. “They did not simply assist dentists from the community. This is possible because of a contractual agreement I have with UIC so that they may provide care under my supervision. This agreement is similar to the site agreement at various community sites.”\nDr. Rada noted that, “Our Public Health and Advocacy track students performed compassionately and confidently. We can be certain that these young doctors have a special gift that they are sharing with those less fortunate.”\nDr. Rada found it “really rewarding to me to hear the local dentists and Midwestern University dental students admiring the fact that Dante, Jihan, and Mark were actually providing the care,” he said. “I might add that they were not given ‘easy’ cases and that they were exposed to some challenging procedures. I was really proud to be working with them. It was great to welcome our young UIC dentists into the profession at this event.”\n“This was an amazing, well-organized public health event that provided essential healthcare services all in one stop,” Brown said. “It was evident how appreciative the patients were. Through Dr. Rada we were able to provide the dental services, instead of just assist.”\nDental Care at Easterseals Academy\nSchool districts contract with Easterseals Academy to assist in providing educational programs for children with an autism spectrum disorder, emotional disability, developmental delay or intellectual disability. They provide an alternative school placement for these students and help them achieve independence. Easterseals Academy empowers each student to achieve peak academic performance, increase social and vocational skills, develop an effective means of communication and foster the acquisition of functional life skills for independence in the community.\n\"Many of our students at the academy have never received proper treatment from a dentist before, only brief cleanings,\" said Easter Seals Metropolitan Chicago Principal, Sarah Rose. \"With the help of UIC students, they can get needed treatments such as more complete cleanings or sealants to prevent decay.\" The partnership with UIC to provide dental care is so beneficial to our students, because having clean and healthy teeth helps them be more successful every single day.\"\n\"The students were really excited and kept asking when they could come back for more training!\" said Dr. Sahar Alrayyes, Clinical Associate Professor, Pediatric Dentistry. \"I thought they would be hesitant given the difficulty of the behaviors with autistic patients, but they were really enthusiastic. It's been a really successful training program.\"\n\"Our job is to help them maintain good oral health as part of overall health in general,\" said Camila Paralta-Sugano, third-year dental student. \"It is different in terms of patient management, but I get to learn a lot of the same skills.\" Third-year student Matt Bernard added, \"working with these patients requires creativity in terms of the treatment because of the nature of their behaviors, but this also leads to more team work and people management skills we all can use in our careers.\"\nVideo: Providing Dental Care to Easter Seals Academy Students\nServing Special Needs at the Illinois Center for Rehabilitation and Education-Roosevelt (ICRE)\nAn enthusiastic group of students, faculty and staff of the UIC College of Dentistry make an annual visit to the Illinois Center for Rehabilitation and Education-Roosevelt (ICRE) in Chicago as part of the Give Kids a Smile (GKAS) initiative. Over 30 students, 2 pediatric dentistry residents, 6 faculty members - and even the tooth fairy! - participate.\nThe event not only provides real-life experiences for dental students providing oral health education and treatment to individuals with special needs, but simultaneously serves a population that often deals with access to care issues.\nThe UIC College of Dentistry is proud to serve our community of special needs patients at the ICRE. Services include oral health education and instruction on brushing, flossing, healthy eating and smoking. The event also provides preventative care and identified several patients who will continue their care at the college.\nVideo: Students Serving Special Needs at ICRE"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:9d3eb525-c346-4f22-a714-94fd5dee5efc>"],"error":null}
{"question":"how do serrated vs plain blade hunting knives compare when cleaning game?","answer":"Serrated blades work better for cleaning game as they act like a saw and can cut through tough hide and sinew with slicing cuts. Plain blades offer better precision and control, especially for push cuts, but since most field dressing and butchering involves slicing cuts, serrated blades have become more popular among sportsmen.","context":["Besides a gun or bow, a knife is one of the most essential tools of the hunter’s trade. Without it, the game meat would never make it from field to table—and there are a host of other jobs around camp and in the woods that make a knife absolutely essential. But stroll into the sporting goods store to pick out your next blade and you’ll likely be dumbfounded because of an overabundance of choices. There are locking blades or fixed blades, straight or serrated edges and they come in all shapes and sizes.\nThere’s no right answer as to what the perfect knife is—it really depends on what you plan to use it for—but there are some basic considerations to keep in mind the next time you’re in the market for this vital outdoorsman’s tool.\nTo start, hunting knives are divided into three basic styles:\nFixed Blade Knives\nAs the name implies, a fixed blade knife is built as one piece, with the blade always open and exposed, and it is affixed to a sturdy handle. As such it is carried in a sheath to protect you from the blade when it’s not in use. A fixed blade is generally stronger since it’s a single piece with no moving parts to weaken the design. Benefits of the fixed blade, besides its strength, are that they are always open and ready for quick use. Negatives are they are larger and remain extended, which means they can take a little more space in a pack or can get caught up on brush.\n- <h2>Helle Temagami Fixed Blade</h2>The fixed blade knife is the best option for tough jobs that require rigidity and durability. Since the blade and handle are one solid piece of metal, it can take a beating without breaking. <p> An exceptional, all-purpose fixed blade is the <a href=\"http://www.helle.no/products/knives/temagami/\" target=\"_blank\">Helle Temagami</a>, a Norwegian-made knife that is built to handle the toughest conditions. The Temagami, like all Helle knives, is built to work, and is proudly endorsed by the Survivorman himself, Les Stroud. <p> <strong>Price: $180</strong>\nFolding Blade Knives\nThese blades are considered the safest to carry because the blade folds compactly into the handle of the knife. They are also more compact, sliding easily into a pocket or pack. Blades are generally held in place when by a locking mechanism, which prevents them from folding up and cutting the user. As a major benefit, this style of knife is compact and safe. On the other hand, they are not as solid for tough jobs like a fixed blade knife would be.\nBasically the only difference between these knives and folding knives is that clip knives easily fasten to the inside of a pocket or pants for more convenient carrying and access. As a benefit, clip knives are convenient to carry and great for general use. Negatively, the compact design can make them less sturdy and easier to lose because they can be knocked off the edge of your pants or pocket.\nUnderstanding Blade Materials\nThis one can be tricky since there are a lot of different materials for making knife blades, all of them delivering varying degrees of strength or ductility (how well the blade can be battered without shattering), the ability to keep an edge and resistance to corrosion. There are others, but these are the three most important characteristics for most sportsmen. Many modern blade materials are simply alloyed stainless steel of varying degrees, designed to deliver a balance of these three qualities.\nBasic stainless steel resists corrosion and is tough, but it doesn’t hold an edge for long. Carbon steels, on the other hand, tend to keep a great edge. Negatively, it tends to rust with the slightest amount of moisture. To save time on research, stick with one of the modern stainless steels. You won’t have to put much care in your knife and the blade will hold an edge and sharpen easily.\nUnderstanding Blade Shape\nClip point, drop point, tanto point, sheepsfoot, dagger point, trailing point, spear point and gut hook are among more than a dozen blade shapes available. However, for the sportsman, there are four of particular importance.\nDrop Point: A drop point blade boasts a sturdy, thick point for strength. It’s also less prone to puncturing materials, such as hides or vitals when skinning.\nClip Point: A clip point blade has a thinner tip than a drop point and can be used to make initial cuts easier because of the pointier tip. As a downside, it can also break more easily.\nTrailing Point: A trailing point blade falls between the clip point and drop point designs. It is stronger than clip point and has a back edge that trails upward, allowing for a larger curve to the cutting edge for more slicing surface. This is a great blade shape for cutting meat.\nGut Hook: More of a convenience than a necessity, the gut hook has a sharpened notch or “hook” cut into the topside of the blade that makes it easier to open an animal or bird’s abdominal cavity when you need to remove the vitals.\nSerrated vs. Plain Blades\nSerrated blades, with little cuts or teeth in them, have become more popular in recent years and are one more blade consideration a hunter must keep in mind. The traditional straight edged or plain blade allows for better precision and control when cutting. It’s best for push cuts as opposed to slicing cuts, such as cutting apples or potatoes, but I also like them better for precise jobs such as skinning.\nSerrated blades work best with slicing cuts since the blade’s teeth help act like a saw and can cut through tough hide and sinew when cleaning game. Because most cuts used when field dressing and butchering game involves slicing cuts over push cuts, the serrated blades are becoming more popular among sportsmen.\nUnderstanding Handle Ergonomics\nKnife handles are designed to provide comfort and grip to the user, some boasting contours, checkered surfaces or even a broader front near the blade to prevent your hand from slipping toward the cutting surface.\nWhen choosing a knife, find one that fits your hand well and feels good when you grip it. It’s really just a matter of personal preference. The most important thing is you don’t want one that will slip in your hand when using it.\nDoes Blade Size Matter?\nFor most hunters, the ideal blade length should fall between three and six inches. Any longer and the knife can become unwieldy when performing precision cuts—causing cuts where you don’t want them—but any shorter and it can be difficult to maintain a suitable grip and maintain leverage when making cuts.\nThink of the most common jobs you plan to use your knife for and consider these six elements and your own personal preferences to select your next perfect hunting knife."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:734d83f6-17c9-49d3-a679-7140491290d7>"],"error":null}
{"question":"Could you explain the scope and structure of the book 'Managing Agricultural Greenhouse Gases'?","answer":"The book consists of seven sections containing 29 chapters that provide regional syntheses of soil organic carbon and greenhouse gas dynamics across various agricultural land uses. It includes summaries of key GRACEnet activities such as modeling, method development, economic outcomes, adaptation research, and international collaboration. The book aims to support the implementation of scientifically-based agricultural management practices from field to national policy scales.","context":["SOIL AND GAS FLUX RESPONSE TO IMPROVED MANAGEMENT IN COLD, SEMIARID AGROECOSYSTEMS\nLocation: Northern Great Plains Research Laboratory\nTitle: Managing agricultural greenhouse gases: Coordinated agricultural research through GRACEnet to address our changing climate\nSubmitted to: Book Chapter\nPublication Type: Book / Chapter\nPublication Acceptance Date: April 25, 2012\nPublication Date: June 8, 2012\nCitation: Liebig, M.A., A.J. Franzluebbers, and R.F. Follett (Editors). 2012. Managing agricultural greenhouse gases: Coordinated agricultural research through GRACEnet to address our changing climate. San Diego, CA:Academic Press. 547 pp.\nInterpretive Summary: In 2002 the USDA Agricultural Research Service (ARS) developed a coordinated national research project called GRACEnet (Greenhouse gas Reduction through Agricultural Carbon Enhancement network) to provide information on soil carbon (C) dynamics and greenhouse gas (GHG) emissions in agricultural systems in different agroecological regions throughout the US, and evaluate how conservation management practices in these regions could reduce net GHG emissions. ‘Managing Agricultural Greenhouse Gases: Coordinated Agricultural Research through GRACEnet to Address our Changing Climate’ synthesizes recent research findings generated from more than 30 ARS locations participating in the GRACEnet project. The book, consisting of seven sections and 29 chapters, addresses major themes associated with current soil C sequestration and GHG mitigation research from across the US. Although GRACEnet is an ARS project, the reported findings have broad natural resource implications on a national level, as well as important international applications given the similarity of environmental conditions to other parts of the world.\nGlobal climate change presents numerous challenges to agriculture. Concurrent efforts to mitigate agricultural contributions to climate change while adapting to its projected consequences will be essential to ensure long-term sustainability and food security. To facilitate successful responses to climate change, relevant and timely research will be critical to ensure appropriate application of novel management practices and technologies on agricultural lands throughout the U.S. Such research should provide a mechanistic understanding of underlying processes affecting natural resources, be scalable to provide useful predictions for select management scenarios, and be translated in such a way that it effectively supports informed decision making. It is under this broad rubric of research goals that the USDA-ARS GRACEnet (Greenhouse gas Reduction through Agricultural Carbon Enhancement Network) project is based. Since 2002, 70 ARS scientists involved in GRACEnet have published over 250 research articles, and in doing so, have significantly expanded greenhouse gas mitigation science. Incumbent to disseminating GRACEnet information is the need to provide integrative syntheses to foster the communication of research accomplishments in a broad context. ‘Managing Agricultural Greenhouse Gases: Coordinated Agricultural Research through GRACEnet to Address our Changing Climate’ addresses this need. The book consists of 29 chapters that provide regional syntheses of soil organic carbon and greenhouse gas dynamics across a broad portfolio of agricultural land uses, as well as summaries addressing key activities central to GRACEnet (e.g., modeling, method development, economic outcomes, adaptation research, and international collaboration). The book is envisioned to support ARS’s goal of providing knowledge and information to better implement scientifically-based agricultural management practices from field to national policy scales."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:f37b2b71-a311-4833-81b6-87e82a5c8065>"],"error":null}
{"question":"What are the key differences in automation capabilities between Python-Rhino and Blender when it comes to 3D modeling and design automation?","answer":"Python-Rhino offers three levels of automation: command pasting (simple commands in command window), command language automation (generating commands programmatically), and COM automation (component-level control). Blender, on the other hand, provides automation through its Python Console for advanced editing and scripting development, along with integrated tools for automation like automatic walk cycles, automatic skinning options, and automatic operations through modifiers. Blender also includes features for automation like automatic physical integration and built-in game engine functions, while Python-Rhino requires manual implementation of such features.","context":["This article describes how to use Python Rhino Automation for Parametric Kite Design.\nTerminologyPython is a high level programming language with clear syntax and powerful built in data types. I have been a C++ programmer for a number of years, but Python is my first choice for quick development and concise code.\nRhino is a three dimensional CAD program which supports NURBS and surface unrolling. NURBS, Non-Uniform Rational B-Splines, are a standard mathematical model for describing curves. Surface unrolling is the ability to create a flat shape from a three dimensional surface.\nParametric automation is the ability to create an object based on key values. When the key values are updated, the object under automation reflects those changes.\nThus, \"Python Rhino Automation for Parametric Kite Design\" translates to creating a Python program which scripts a Rhino CAD model of a kite. This model can be updated by changing key features of a kite. There is no need to create the model from scratch by hand when an element of the kite design changes.\nMotivationA program such as foilmaker (stable link needed) or surfplan are the mainstream kite design programs. These are excellent in their domain, but like any program, are bound by the standard trade off of features vs. ease of use. If you have never designed a kite before, these programs are the place to start. They are effectively a system for parametric kite design where the set of parameters and the method for meeting them is determined by the program.\nWhen a kite designer is not satisfied with the available parameters or how the parameters are solved, two paths are left: using a CAD program or implementing a new kite design program to cater for their special needs. Examples:\n- Hangtime kite design software takes the \"new kite design program\" approach to achieve long panels with smooth lines for inflatable kites.\n- Tom White has programs which specialize in NPW single skin kites.\n- Olivier gives an excellent walkthrough of the complete customization of all parameters of kite design available when using a CAD program.\nThe \"new kite design program\" solution removes the limitations of the mainstream kite design program which bothered the author of the new program, but also introduce a new fixed set of parameters and solutions to those parameters. Using a CAD program gives ultimate flexibility, but if a design decision changes, the model must be rebuilt by hand to incorporate the new idea.\nThis article aims to achieve the best of both worlds: ultimate flexibility of a CAD program, combined with the ease of changing fundamental design parameters. Caveat et emptor: nothing is free! This requires some (relatively simple, depending on your ambition) programming. I don't take any credit here - I beleive it was Andy Wardley who pioneered parametric kite design using Perl. Check out his article to see the other area he pioneered.\nAutomating Rhino with PythonThere are three approaches or levels to automating Rhino:\n- Command Pasting: a simple set of Rhino commands are pasted into the command window.\n- Command Languate Automation: a program is created to generate the commands which are pasted into the command window.\n- COM Automation: Rhino is controlled at the component level.\nCommand PastingRhino has a command window which can be used tell Rhino what to do.\nCopy the following text and paste it into the command window, and some lines will show up in the Rhino viewport.\nline 3,4 22.5,3\nSee also the code used on the NPWC v8 page. This level of Parametric Design is appropriate if the parameters being varied are quite simple, like the control points for drawing the wing panel on the v8 page.\nCommand Language AutomationThis approach is a level of indirection from from Command Pasting where code is written to generate the commands, instead of editing the command code directly. To elaborate on this I will go through an example to create a kite skin based on the following parameters:\n- Tip width, how wide the tips of the kite should be.\n- Tip start angle in degrees. This controls the aspect ratio of the kite.\n- Number of notches to sew in fabric.\n- How deep to sew the notches. This controls the LE/TE ratio.\n- The total concavity of the trailing edge in degrees.\n- Trailing edge length.\n# python script to generate Rhino commands for SSTEA # 2007-4-1, v1.0, Bill Ola Rasmussen, based on NPWK code # 2007-4-6, v1.1, Bill Ola Rasmussen, vertical notch from math import sin, cos, pi, radians # parameters ------------------------------------------------------------------ tw = 3 # - tip width sa = 45 # - start angle (degrees) nc = 6 # - notch count nd = 60 # - notch depth % (controls LE/TE ratio) tc = 8 # - TE concavity (degrees) tl = 50 # - TE length # conversions ----------------------------------------------------------------- sa,ca,tc = radians(sa),radians(sa),radians(tc) # math operates with radians nd = nd*.01 # convert percentage tl = tl/float(nc+1) # convert TE length to TE segment length tc = tc/float(nc*2) # convert TE concavity to half notch concavity na = 2*ca/nc # notch angle without tc (same as TE notch deflection) # all notches are vertical, only calculate angles once cpa = na/2+tc-pi/2 # control point angle of notch lwa = (cpa-pi/2)/2 # left wall angle of notch\nThe second block sets up utility classes for calculations on lines, points, and splines. These classes represent their respective concepts, and allow themselves to be expressed as Rhino commands.\n# classes --------------------------------------------------------------------- class Point: '2D Point from x and y values.' def __init__(self, x, y): self.x,self.y = float(x),float(y) def __str__(self): # rhino script format return '_point '+self.pt() def pt(self): return '%f,%f'%(self.x,self.y) def to(self,a,m): 'Make new line from point: angle a, length m.' return Line(Point(self.x,self.y), Point(self.x+cos(a)*m, self.y+sin(a)*m)) def toP(self,p): 'Make new line to Point.' return Line(self,p) class Line: 'Line segment from two Points.' def __init__(self, p1, p2): self.p1,self.p2 = p1,p2 def __str__(self): # rhino script format return '_line %s %s'%(self.p1.pt(),self.p2.pt()) def mid(self): return Point((self.p1.x+self.p2.x)/2,(self.p1.y+self.p2.y)/2) def intersect(self, line): 'Intersection of two lines. Intersects can occur outside of segment.' # see http://local.wasp.uwa.edu.au/~pbourke/geometry/lineline2d denom = (line.p2.y-line.p1.y)*(self.p2.x-self.p1.x)- \\ (line.p2.x-line.p1.x)*(self.p2.y-self.p1.y) #If the denominator is 0 then the two lines are parallel. if 0==denom: raise # todo: error handling ua = ((line.p2.x-line.p1.x)*(self.p1.y-line.p1.y)- \\ (line.p2.y-line.p1.y)*(self.p1.x-line.p1.x))/denom return Point(self.p1.x+ua*(self.p2.x-self.p1.x), \\ self.p1.y+ua*(self.p2.y-self.p1.y)) def to(self,a,m): 'Make new line followng this one: angle a, length m.' return self.p2.to(a,m) def toP(self,p): 'Make new line followng this one: to Point.' return self.p2.toP(p) def toY(self,a,y): 'Make new line followng this one: angle a, ends at location ?,y.' al = self.to(a,1) # angle 'a' line hl = Line(Point(0,y),Point(1,y)) # horizontal line at y return Line(Point(self.p2.x,self.p2.y),al.intersect(hl)) class Spline: 'Spline from three Points.' def __init__(self, p1, p2, p3): self.p1,self.p2,self.p3 = p1,p2,p3 def __str__(self): # rhino script format return '_curve %s %s %s _enter'%(self.p1.pt(),self.p2.pt(),self.p3.pt())\nThe third block is where the heavy lifting happens. The code sets a starting location and draws lines for each trailing edge segment and splines for each notch. The key thing that happens here is that the center control point for the spline is defined so that each notch creates a concave juncture at the trailing edge (when the tc parameter is positive).\n# start of main code ---------------------------------------------------------- print '_selall\\n_delete' # clear previous drawing start = Point(0,0) te = start.to(ca,tl); print te # virtual trailing edge tip = start.toP(Point(0,tw)); print tip ete = tip.toP(te.p2); print ete # extended trailing edge for i in range(nc): # notch splines depth = (1-nd)*te.p2.y lsw = te.toY(lwa,depth) # left spline wall mnl = lsw.to(pi/2,1) # mid notch line cpl = te.to(cpa,1) # control point line ccp = mnl.intersect(cpl); print ccp # center control point print Spline(lsw.p1, ccp, lsw.p2) rsw = lsw.toY(-lwa,lsw.p1.y); # right spline wall print Spline(rsw.p1, ccp, rsw.p2) # TE ca -= na te = rsw.to(ca,tl); print te tip = te.to(pi/2,tw); print tip ete = tip.toP(te.p1); print ete # extended trailing edge print '_zoom extents' print 'done, angle error: %f, y error: %f'%(ca+sa,te.p2.y)\nWhen the above three blocks of code are joined together and run in the Python interpreter, the following output is produced:\n_selall _delete _line 0.000000,0.000000 5.050763,5.050763 _line 0.000000,0.000000 0.000000,3.000000 _line 0.000000,3.000000 5.050763,5.050763 _point 5.267103,3.543256 _curve 5.050763,5.050763 5.267103,3.543256 5.267103,2.020305 _enter _curve 5.267103,2.020305 5.267103,3.543256 5.483442,5.050763 _enter _line 5.483442,5.050763 11.669338,8.622191 _point 12.038653,6.048716 _curve 11.669338,8.622191 12.038653,6.048716 12.038653,3.448877 _enter _curve 12.038653,3.448877 12.038653,6.048716 12.407969,8.622191 _enter _line 12.407969,8.622191 19.307439,10.470899 _point 19.755940,7.345638 _curve 19.307439,10.470899 19.755940,7.345638 19.755940,4.188360 _enter _curve 19.755940,4.188360 19.755940,7.345638 20.204441,10.470899 _enter _line 20.204441,10.470899 27.347298,10.470899 _point 27.795799,7.345638 _curve 27.347298,10.470899 27.795799,7.345638 27.795799,4.188360 _enter _curve 27.795799,4.188360 27.795799,7.345638 28.244301,10.470899 _enter _line 28.244301,10.470899 35.143771,8.622191 _point 35.513086,6.048716 _curve 35.143771,8.622191 35.513086,6.048716 35.513086,3.448877 _enter _curve 35.513086,3.448877 35.513086,6.048716 35.882401,8.622191 _enter _line 35.882401,8.622191 42.068297,5.050763 _point 42.284637,3.543256 _curve 42.068297,5.050763 42.284637,3.543256 42.284637,2.020305 _enter _curve 42.284637,2.020305 42.284637,3.543256 42.500977,5.050763 _enter _line 42.500977,5.050763 47.551740,0.000000 _line 47.551740,0.000000 47.551740,3.000000 _line 47.551740,3.000000 42.500977,5.050763 _zoom extents\nCopying the above command language into the Rhino command window produces the lovely kite skin design below:\nThe key to this excercise is that we can create a totally new drawing - just change a parameter in the Python file, run the program again, then paste the output into Rhino to create another drawing. Various adjustments can be made, and we do not need to draw by hand from scratch when a requirement changes.\nThe purpose of this particular skunk works skin design will be kept secret for now. [Update: no longer a secret, see the FoilNose2 page.] However, some clues can be gleaned from my theory of sparless single skin kite design: the combination one necessary condition and one key value helps determine if the kite will fly. The necessary condition is that there are no unsupported (e.g. unbridled) convex sections on the (3D) outline of the kite. The one key value is the ratio between the length of the leading edge and trailing edge of the kite.\nThe code presented enforces the necessary condition via the tc parameter. Adding the ratio calculation and reporting is left as a excercise for the reader.\nCOM AutomationWhen even more control over Rhino is desired, COM automation can be employed to interface to Rhino. This opens up the possibility to manipulate objects after drawing them. I will leave this for an entirely new article, as this one has already grown large enough. Until then, you can click on the image to see a kite model created using Python via the Rhino COM interface.\nClosingUse an existing kite design program if it fits your needs. Programmed CAD automation can be used for design cases where existing programs are too limiting.\nVariations are possible. This article uses Python and Rhino, which means a Windows environment. My main computer now runs Ubuntu, so I would love to learn how to accomplish something similar with Blender.","Introduction to Blender Tools\nBlender Tool is a 3D computer graphics software which has all the toolset required for creating, modifying animated films, visual effects, arts, 3D printing models, interactive 3D gaming models and all this for free, yes Blender tool is an open source 3D Graphics software available in the market. It is developed and supported by Blender Foundation. It is used for 3D modeling, UV Unwrapping, raster graphics editing , texturing, rigging, skinning, destruction, fluid and smoke simulation, particular simulation, soft body simulation, sculpting, animation, rendering, motion graphics, video editing and compositing all the features of end to end animation, gaming and visual effects making software solution.\nThe latest version has its integrated game engine which helps the gamers to a designee and tests their models without any external software. Blender is used for making animation, gaming, and visual effects. Many MNC’s use blenders as the project scope application to work for in there project working chat because of its user-friendly interface and easy access to effects, tools, and rendering. We can make good looking CG arts and illustrations using a blender. Video editing and stimulation process are endless with best visual outputs quality. Sculpturing complex characters, animation motion tracking, and compositing handling are pretty cool and impressive compared too much other 3D animation software which makes blender to stand as one of the professionally used software in the market.\nTypes of Blender Tools\nBlender has multiple tools and their appliances can be adjusted at any point of time left, right, top or bottom.\nThe information helps in handling files, rendering, adding new windows and properties and setting scenes and information about the poly count in the design.\n1. Left panel\nLeft Panel contains 6 attributions.\n- 1st Tools to translate, rotate, scale, mirror, edit, duplicate or delete the objects it also contains edits history list to undo or redo the edits.\n- 2nd Create adding new shapes like cube, rectangles, circles, cone editing and creating curves, adding different lamps point, sun, spot, area and few other attributions like adding text, speakers and cameras can also be done.\n- 3rd Relation creating and editing groups with multiple objects in frame and properties settings can be done.\n- 4th Animation inserting, removing keyframes for animation time frames and adding motion paths can be done.\n- 5th Physic adding and removing the rigid body and changing its shape and calculating mass and applying transformations can be done.\n- 6th Grease Pencil freehand drawing lines and polygons and erasing and converting final objects by applying rules can be done.\n2. Right pane\nThe right pane contains outliner of the design to check the flow of work.\n- 3D View helps in a visual display of designs in 3D.\n- Time Liner is used for keying and setting animation movement for times frame.\n- Graphic editor is used for editing drivers and keyframe interpolation.\n- Drop Sheet is used to adjusting keyframe so of time sheets.\n- NLA Editor combines the layer actions.\n- UV/Image Editor is used to view or edit image and make texture adjustments and changes in the UV map of the characters.\n- Video Sequence Editor is for editing videos in multiple aspects.\n- Movie clip Editor Motion tracking can be done using this tool.\n- Text Editor helps in editing scripts and inters filed documents in the process.\n- Node Editor editing node base shading and compositing.\n- Logic Editor helps games to apply and remove logics in game making.\n- Properties describe the active objects and relative database which is important for animation, VFX and gaming artists.\n- User Preferences is used to edit the configuration settings of Blender as per required by customer.\n- File Browser open, import and export file assets.\n- Python Console is an interactive programming console window option in a blender for advanced editing and scripting developments.\nWhat is Blender used for?\nBlender is used for multiple projects of digital computer graphics such as animation, video editing, effects, gaming making, game models making, creative VFX making, image illustration, 3D model printing and many more. It’s a single solution of all such projects in the market and many MNC’s adopted and are using blender as a primary software for animation and gaming. It contains all tool and features from start to end solution for creating the ultimate unique work for the projects.\n4.6 (2,374 ratings)\nFeatures of Blender\nIt is the basis for creating game environments and animation characters and probes models are designed using the combinations of points, lines and polygons, and their shapes to get the nearest shape of the design and brushes are used to deposit material in required using different deposition quality. Modifiers are automatic operations that affect the object in a dissenting way of editing. We can perform curving, smoothing and many other effective surface related edits to blend our model. UV Unwrapping is a must for modeling through which we can apply textures to our models. Texturing can be done using Photoshop or also even UV sculpt to add colors to the models.\nIt is a process of adding motions to character with help of keys, nonlinear animation can be easy, automatic walk cycles can be set, character animation editor is available where we can instantly see the animation on rendered screen with fast rigging options. Mirror functionality easy painting, Skeleton, and automatic skinning options, bone and spin making and movements can be interpolated easily.\nA much-needed task in animation handling software’s and also we need a good CPU and Graphics car to handle or get renders done quick. Geometry mesh handling, BVH build and fit updates can be done. Texturing, cam handling, lighting, surface modeling, shading and many more can be adjusted and make the best frame out of the work.\n4. Video Editing\nIt allows to perform basic actions like splicing, cutting, speeding and slowing, live preview, Lumia waveform, Chroma vectorscope, Audio mixing, Syncing, Scrubbing, Visualizing, adding 32 slots of image, video, and effects, adjusting layers and keyframe filters and transformations and more.\n5. Game Creation\nFull functional creative tools and stuff is built in a blender with the gaming engine functions such as Porting models applying codes and own game logic, complete physical integration and python scripting with advanced controls and AI. All open GL dynamic lighting, Shading, animatic materials, and mapping. 3d Spatial audio using Open AL.\nThe blender comes with loaded scripting array of extensions with quick on and off modes which help in generating trees, terrains, clouds and few regular probes, 3d printing Toolbox. Importing and exporting multiple file formats.\nAll deals with compositing and motion graphics tool have an impressive library of a creative cam and color grading for a visual approach. Full-length compositing of image and videos can be done with multiple layer handling files with different threads. Auto and manual motion tracking, powerful cam reconstruction and few more advanced tracking like planar tracking, tripod solvers and real-time preview to 3D scans can be done.\nAll the settings can be customized at any point of time using simple radio and On and Off buttons.\nThe deals with handling different file formats and their relations with our work in blender. All image, video, 3D file formats are supported.\nAny natural simulation such as Fire, Smoke, Fluids, Hair, Cloth, Rigid Bodies and particle brings a realistic feel to the frame.\nBlender is an open source and best 3D animation learning software for both fresher’s and experience to work for any complicated animation or gaming concept with simple handling tools. So far many artists use blender tools for their projects for best and cost less & professional skill approach to impress their clients with work.\nThis has been a guide to blender tools. Here we discussed the basic concepts of blender tools with different types and top features. You can also go through our other suggested articles to learn more –"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:6bbc496d-8023-4fb0-a26a-ed1a54c37e74>","<urn:uuid:246a1d75-024c-4b74-98bd-8adb0492907e>"],"error":null}
{"question":"Which poses a higher suicide risk for teenagers: giving away belongings or increased use of alcohol and drugs? Explain the significance of both behaviors.","answer":"Both behaviors are serious warning signs of suicide risk, but increased use of alcohol and drugs poses a higher risk as it can actively impair judgment and worsen existing symptoms. While giving away belongings is an important warning sign that someone may be planning suicide, substance use creates additional complications - it can worsen depression, anxiety and other mental health conditions, impair decision-making, and make someone more likely to act on suicidal thoughts. The documents specifically mention that increased substance use, especially if it's a new behavior or has increased recently, indicates greater suicide risk. This is particularly concerning in teens, who are already vulnerable due to difficulties coping with stress, rejection, and other life challenges.","context":["By Dr. Gaveeta Chiba\nPsychiatrist and certified mindfulness instructor.\nBedfordview and Waverley, Johannesburg\nThese are three examples of different types of people who presented with suicidal ideation and suicide attempt. As people can present at various life stages and for various reasons and with a multitude of symptoms, it’s important to be aware of the warning signs of Suicide. I’ve broken them up into three categories: what people say, how they act and what they feel:\nListen carefully when a person talks about:\n• Killing themselves\n• Having no reason to live\n• Being a burden to others\n• Feeling trapped like there’s no way out of a situation\n• Unbearable pain\nExplore their behaviour A person’s suicide risk is greater if a behaviour is new or has increased, especially if it’s related to a painful event, loss, or change.\n• Increased use of alcohol or drugs.\n• Looking for a way to kill themselves, such as searching online for materials or means.\n• Acting recklessly.\n• Withdrawing from activities.\n• Isolating from family and friends.\n• Sleeping too much or too little.\n• Changes in eating habits - eating too much or too little.\n• Visiting or calling people to say goodbye.\n• Giving away prized possessions.\n• Exhibiting a significant change in personality, such as a person who is normally bubbly and cheerful becomes isolated and withdrawn from everyone.\nNotice their mood. People who are considering Suicide can display one or more of the following moods.\n• Loss of interest in activities including pleasurable ones.\n• Feeling intolerably alone.\nIf the patient is deemed not to be at immediate risk for engaging in selfdestructive behaviors, then:\n• Collaborate with the patient and significant others (family, partners, friends, and social support networks) to develop an action plan.\n• The goal is to protect the individual from self-harm.\nIn the process:\n• Discuss the underlying event that precipitated the crisis.\n• Have a warning system that detects early warning signs of suicide risk.\n• Enlist the help of allies, which can be family members, friends, health care providers, or religious figures in the person’s life that can assist in support and detecting warning signs.\n• Set up regular follow ups with person and family.\n• Reinforce healthy coping skills and substitute more effective responses for dysfunctional responses.\n• Refer for psychotherapy, counselling or a support group.\n• Refer to a Psychiatrist if further mental health assessment is required, to clarify diagnosis, initiate further medical management and address increasing risk.\nAny reference to Suicidal ideation, intent, or plans mandates a mental health assessment.\nIf the person is at immediate risk of Suicide:\n• Remove or secure any lethal methods of self-harm\n• Decrease isolation\n• Decrease Anxiety and agitation\n• Engage the individual in a safety plan (crisis management or contingency planning).\n• Under certain circumstances this might require hospitalisation.\nIn SA Suicide accounts for 9.6% of all unnatural deaths and there is approximately one completed suicide every hour. 75% of all Suicides can be prevented. Using the above information can help you detect Suicide risk earlier on and hopefully assist in preventing it.\n\"Dan is a 23-year-old single male admitted via casualty to ICU for an attempted overdose. His attempt was precipitated by a recent break up with his girlfriend as well as financial stressors incurred in his new business. Prior to the attempt he’d started feeling depressed, unmotivated to go to work and wasn’t sleeping well. In order to cope, he’d started drinking more alcohol, which made his symptoms worse and impaired his judgement.\nLeanne is a 64-year-old woman recently separated from her husband of 23 years. She had taken early retirement due to an overwhelming work burden that had affected her marriage. Just as she left work in an attempt to save her marriage, her husband announced he was leaving her. Her GP prescribed an antidepressant for anxiety and depression. She expressed feeling frustrated by her life and couldn’t see a reason to live.\nJohn is a 45 year old ex-policeman, now working at a security firm. He suffered post-traumatic stress symptoms due to repeated traumas faced in the line of duty. He came to me feeling angry about life, easily irritated and felt hopeless, like nothing would ever make him happy again. He’d actively thought of suicide and his access to weapons at work put him at risk.\"\nWhen any of the above is noticed, look for additional risk factors for\nSuicide, such as:\n• One or more prior Suicide attempts\n• History of Mental Illness - Depression, Anxiety, Bipolar Mood Disorder, Schizophrenia\n• Family history of MentalIllness/Substance Abuse\n• Family history of Suicide\n• A chronic physical illness, including chronic pain\n• Physical or sexual abuse\n• Minimal social support\n• Recent losses – physical, financial or personal\n• Age, gender, race (elderly or young adult, unmarried, white, male, living alone)\nWhat do you do if you think someone is considering suicide?\n• Trust your instincts that the person may be in trouble\n• Talk with them about your concerns and LISTEN\n• Ask direct questions without being judgmental\n• Don’t leave the person alone or with access to means (sharp implements, firearms, etc.)\n• Don’t swear to secrecy\n• Don’t act shocked or judgmental\n• Don’t counsel the person yourself\n• Get further professional help if indicated, even","Teen suicide: What parents need to know\nKnow the risk factors for teen suicide, the warning signs and the steps you can take to protect your teen.By Mayo Clinic Staff\nIs your teen at risk of suicide? While no teen is immune, there are factors that can make some adolescents more vulnerable than others. Understand how to tell if your teen might be suicidal and where to turn for help and treatment.\nWhat makes teens vulnerable to suicide?\nMany teens who attempt or die by suicide have a mental health condition. As a result, they have trouble coping with the stress of being a teen, such as dealing with rejection, failure, breakups, school difficulties and family turmoil. They might also be unable to see that they can turn their lives around — and that suicide is a permanent response, not a solution, to a temporary problem.\nWhat are the risk factors for teen suicide?\nA teen might feel suicidal due to certain life circumstances such as:\n- Having a psychiatric disorder, such as depression, an anxiety disorder, bipolar disorder or oppositional defiant disorder\n- Family history of mood disorder, suicide or suicidal behavior\n- History of physical or sexual abuse or exposure to violence or bullying\n- A substance use disorder\n- Access to means, such as firearms or medications\n- Exposure to the suicide of a family member or friend\n- Loss of or conflict with close friends or family members\n- Physical or medical issues, such as changes related to puberty or a chronic illness\n- Being lesbian, gay, bisexual or any other sexual minority youth\n- Being adopted\nChildren who have attempted suicide in the past are also at greater risk.\nIn the U.S., suicide attempts are more common in adolescent girls than boys. But boys are more likely to die by suicide than are girls.\nWhat are the warning signs that a teen might be suicidal?\nWarning signs of teen suicide might include:\n- Talking or writing about suicide — for example, making statements such as \"I'm going to kill myself,\" or \"I won't be a problem for you much longer\"\n- Withdrawing from social contact\n- Having mood swings\n- Increasing use of alcohol or drugs\n- Feeling trapped, hopeless or helpless about a situation\n- Changing normal routine, including eating or sleeping patterns\n- Doing risky or self-destructive things\n- Giving away belongings when there is no other logical explanation for why this is being done\n- Developing personality changes or being severely anxious or agitated when experiencing some of the warning signs listed above\nWhat should I do if I suspect my teen is suicidal?\nIf you think your teen is in immediate danger, call 911, your local emergency number or a suicide hotline number — such as the National Suicide Prevention Lifeline at 1-800-273-TALK (1-800-273-8255) in the U.S.\nIf you suspect that your teen might be thinking about suicide, talk to him or her immediately. Don't be afraid to use the word \"suicide.\" Talking about suicide won't plant ideas in your teen's head.\nAsk your teen to talk about his or her feelings and listen. Don't dismiss his or her problems. Instead, reassure your teen of your love. Remind your teen that he or she can work through whatever is going on — and that you're willing to help.\nAlso, seek medical help for your teen. Ask your teen's doctor to guide you. Teens who are feeling suicidal usually need to see a psychiatrist or psychologist experienced in diagnosing and treating children with mental health problems.\nThe doctor will want to get an accurate picture of what's going on from a variety of sources, such as the teen, parents or guardians, other people close to the teen, school reports, and previous medical or psychiatric evaluations.\nWhat can I do to prevent teen suicide?\nYou can take steps to help protect your teen. For example:\n- Talk about mental health and suicide. Don't wait for your teen to come to you. If your teen is sad, anxious, depressed or appears to be struggling — ask what's wrong and offer your support.\n- Pay attention. If your teen is thinking about suicide, he or she is likely displaying warning signs. Listen to what your child is saying and watch how he or she is acting. Never shrug off threats of suicide as teen melodrama.\n- Discourage isolation. Encourage your teen to spend time with supportive friends and family.\n- Monitor and talk about social media use. Keep an eye on your teen's social media accounts. While social media can give teens valuable support, it can also expose them to bullying, rumor spreading, unrealistic views of other people's lives and peer pressure. If your teen is hurt or upset by social media posts or messages, encourage him or her to talk to you or a trusted teacher. Feeling connected and supported at school can have a strong protective effect.\n- Encourage a healthy lifestyle. Help your teen eat well, exercise and get regular sleep.\n- Support the treatment plan. If your teen is undergoing treatment for suicidal behavior, remind him or her that it might take time to feel better. Help your teen follow his or her doctor's recommendations. Also, encourage your teen to participate in activities that will help him or her rebuild confidence.\n- Monitor medications. Though it's uncommon, some teens might have an increase in suicidal thoughts or behavior when taking antidepressants, especially in the first few weeks after starting or when a dose is changed. But antidepressants are more likely to reduce suicide risk in the long run by improving mood. If your teen has suicidal thoughts while taking an antidepressant, immediately contact the doctor or get emergency help.\n- Safely store firearms, alcohol and medications. Access to means can play a role if a teen is already suicidal.\nIf you're worried about your teen, talk to him or her and seek help right away.\nTeen suicide prevention\nReach out — Preventing teen suicide\nMay 18, 2021\nGet the latest health information from Mayo Clinic’s experts.\nSign up for free, and stay up to date on research advancements, health tips and current health topics, like COVID-19, plus expertise on managing health.\nErrorEmail field is required\nErrorInclude a valid email address\nTo provide you with the most relevant and helpful information, and understand which\ninformation is beneficial, we may combine your email and website usage information with\nother information we have about you. If you are a Mayo Clinic patient, this could\ninclude protected health information. If we combine this information with your protected\nhealth information, we will treat all of that information as protected health\ninformation and will only use or disclose that information as set forth in our notice of\nprivacy practices. You may opt-out of email communications at any time by clicking on\nthe unsubscribe link in the e-mail.\nThank you for subscribing\nOur Housecall e-newsletter will keep you up-to-date on the latest health information.\nSorry something went wrong with your subscription\nPlease, try again in a couple of minutes\nSee more In-depth\n- Teens and suicide: What parents should know. American Foundation for Suicide Prevention. https://afsp.org/teens-and-suicide-what-parents-should-know. Accessed March 18, 2021.\n- Kennebeck S, et al. Suicidal behavior in children and adolescents: Epidemiology and risk factors. https://www.uptodate.com/contents/search. Accessed March 19, 2021.\n- Moreland CS, et al. Effects of antidepressants on suicide risk in children and adolescents. https://www.uptodate.com/contents/search. Accessed March 23, 2021.\n- Kennebeck S, et al. Suicidal behavior in children and adolescents: Evaluation and management. https://www.uptodate.com/contents/search. Accessed March 23, 2021.\n- Suicide in children and teens. American Academy of Child & Adolescent Psychiatry. https://www.aacap.org/aacap/families_and_youth/facts_for_families/fff-guide/teen-suicide-010.aspx. Accessed March 23, 2021.\n- AskMayoExpert. Suicide assessment. Mayo Clinic; 2020.\n- Risk factors and warning signs of suicide. American Foundation for Suicide Prevention. https://afsp.org/risk-factors-and-warning-signs. Accessed April 8, 2021.\n- Preventing suicide. Centers for Disease Control and Prevention. http://www.cdc.gov/violenceprevention/suicide/. Accessed March 23, 2021.\n- When a loved one has made an attempt. American Foundation for Suicide Prevention. https://afsp.org/find-support/my-loved-one-made-attempt/loved-one-made-attempt/. Accessed March 23, 2021.\n- Shain B. Suicide and suicide attempts in adolescents. Pediatrics. 2016; doi:10.1542/peds.2016-1420.\n- Kim J, et al. Cyberbullying and victimization and youth suicide risk: The buffering effects of school connectedness. The Journal of School Nursing. 2020; doi:10.1177/1059840518824395.\nProducts and Services\n- Book: Tired Teens"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:c6c38a0e-1188-421e-a24a-d896098567a0>","<urn:uuid:4c468450-f16a-466b-9ab1-d0362c3c624a>"],"error":null}
{"question":"What basic time range does ultrasonic welding typically need to complete a weld? 😊","answer":"Most ultrasonic welds occur in less than 500 milliseconds (less than half a second).","context":["by Jeffrey Frantz, Branson Ultrasonics Corp.\nUltrasonic welding is a technology that has been used for decades to assemble plastic components. There are many benefits of this technology. It allows for plastic parts to be assembled without consumables. This not only eliminates the cost of the consumable (such as screws or rivets), but in the case of adhesives and solvents, eliminates the set-up or cure time, which dramatically improves throughput. It is an extremely fast technology as most welds occur in less than a second. It easily can be integrated into semi- or fully automated systems, and it also is a very cost-competitive process. With all of these benefits, it is easy to understand why ultrasonic welding often is the first choice for plastic joining needs.\nLets begin with a brief description of the process. The ultrasonic vibrations are created by a series of components – power supply, converter, booster, horn and actuator – to deliver mechanical vibration and force to the parts. This generates heat at the interface of the parts to be joined, melting the plastic and creating a strong bond.\nFigure 1 shows how the power supply, converter, booster and horn function together to create mechanical vibration. The power supply takes standard electrical line voltage and converts it to an operating frequency (in this illustration, 20kHz). Power supply frequencies are set, but are available between 15 – 70kHz. The most common frequencies are 20, 30 and 40kHz. This electrical energy is sent through an RF cable to the converter. The converter utilizes piezoelectric ceramics to convert the electrical energy to mechanical vibrations at the operating frequency of the power supply. This mechanical vibration either is increased or decreased based on the configuration of the booster and horn. The proper mechanical vibration, known as amplitude, typically is determined by an applications engineer and based on the materials being welded.\nMechanical vibrations are delivered to the parts to be welded. The parts also are put under a mechanical load, primarily through a pneumatic actuator. Under this load, the mechanical vibrations are transmitted to the interface between the parts. In most cases, there is a triangular-shaped bead, known as an energy director, designed into this interface. This creates a point for the vibration to be focused, resulting in intermolecular and surface friction. This friction creates heat and a subsequent melt.\nThe main parameters in an ultrasonic weld can be derived through the fundamental equation shown in Figure 2.\nAmplitude is the dominate parameter and has a significantly greater impact on the weld than the other parameters. Amplitude is the peak-to-peak movement of the horn. This motion, coupled with force being generated by pressure and downspeed, creates a condition where the amplitude produces waves of energy that move through the part contacted by the horn. These mechanical waves of energy create stress at the joint interface in the form of intermolecular and surface friction. This creates heat that propagates from the point of contact between the parts to the entire joint area. Once the ultrasonic energy is stopped, the joint cools and solidifies to form a weld. All of this takes place, in most cases, in less than 500 milliseconds.\nThe weld process can be broken down into some very basic sections. It is important to distinguish them and make sure they are individually controlled. First is the approach to the part. This is the distance between the home position and the part. Next is the point of contact to the part. This is known as trigger. The weld duration is next, followed by hold.\nLet’s start with the approach to the part. This distance most often is predicated by having enough space to load and unload the part in manual operations and minimal distances in automation. This typically is controlled through the downspeed setting, which regulates through a flow meter on the output side of the air cylinder. It is important to note that this setting not only controls the velocity of the horn to the part, but also the buildup of force during the weld.\nThere are many ways to control the ultrasonic weld. This most often is done through a controller that comes with the welder. In its most basic form, the weld is controlled by time. Time generally is set in milliseconds. The next level of control is energy. This is done through a watt meter that calculates the watts per second, known as joules. The illustration in Figure 3 demonstrates a typical power graph that illustrates these two weld modes. As seen in the energy mode, the weld time will vary slightly due to minor variations in part-to-part tolerances. Energy mode is used in some applications where there are multi-cavity combinations being welded.\nThe original energy setting was based on the center power profile. The area under the curve is the weld energy. The surrounding graphs show power curves that have a slightly different power draw. The weld time fluctuates to meet the weld energy set in the controller.\nIn more sophisticated units, a linear encoder is attached to the actuator. In most cases, it has a resolution of 0.0001″, which allows for many different functions to be utilized and controlled. In the approach to the part, the point (in distance) that a pre-trigger will initiate the ultrasonics can be precisely set. A pre-trigger often is used in shear joint, staking and insertion applications to turn the ultrasonics on prior to the horn contacting the part. This prevents the parts from being pressed together. In an actuator without distance capability, the pre-trigger would be turned on as soon as the horn leaves its home position, which can create excessive noise, horn failures and inconsistent weld results.\nThe linear encoder also is used to provide two additional modes of weld control: Collapse and Absolute. Collapse is a controlled measurement between the point of contact and the part. For instance, if a part has an energy director joint design that is 0.015″ high, the Collapse could be set to that exact amount. The welder would reset the linear encoder readings once the horn contacts the part, and then moves the 0.015″ set in Collapse and then turns off the ultrasonics. Absolute is a control mode that sets the distance the actuator will travel. It is used when the part requirement is to maintain an overall height dimension.\nThere also is a Peak Power capability which will turn off ultrasonics when a peak power point is reached. This mode is not often used, but can be a benefit in plunge welding of textiles. Due to the openness of the materials, they go through a rapid transition once molten. This results in a quick spike in power consumption. Peak Power mode prevents what is known as “blow though”, where the weld flash melts through the surrounding area.\nOften overlooked in a weld sequence is the trigger point. This is the point in the process where the actuator has made contact with the part, the cycle is initiated and the processing mentioned above takes place. In most weld systems, a mechanical trigger is used. This is adequate, but for more precise control a load cell that measures force provides a higher level of control.\nLet’s now look at the set up of the welder. As mentioned earlier, amplitude is the most important parameter for successful welding. The amplitude is created by the gain ratios of the stack, which encompasses the converter, booster and horn. The converter has a fixed ratio determined by the manufacturer. For this example, we will work in 20kHz which has an output of 20microns. The booster and horn gains are determined individually by the mass ratio of their input to output masses. Figure 4 shows a 1:1 booster and a 1:2 gain booster. The horn design is determined by the horn it is to contact. It should be designed to contact over the area to be welded. Based on size, frequency and material limitations, gain may or may not be incorporated. When these three components are attached, they create what is known as stack amplitude.\nIt is imperative to have the proper stack amplitude to match the material being welded. Each material has a range of amplitude for ideal weld results. For instance, Polycarbonate has an amplitude range of 60-100microns. It will weld with amplitudes outside of this range, but should be well within the range for optimum results. The supplier of the horn should provide horn gain information so the user can calculate which booster is best for the material.\nOnce the stack components have been selected, properly torqued and installed in the actuator, the next setting is weld pressure. In most cases, a setting between 30 and 50psi is adequate. Naturally, lower pressures should be used for smaller thinner walled parts, with high pressures used for larger parts with thicker walls. The next setting is downspeed or velocity. This determines the rates of descent of the horn to the part, but ultimately it determines the rate of force build up during the weld. Most weld setups utilize a setting between 1.5 -2.5 in./sec.\nThe next parameter to set is weld mode and duration. With all of the weld modes available, where do you start? Many of us utilize our past experiences to select a weld mode that worked previously. This may or may not be successful. Ideally, you should always start in the time mode. The other modes do have benefits, but also can mask some potential issues or restrict the process from behaving naturally. The best practice is to use the time mode and let the parts tell you what is best for them. Let me explain.\nYou will need to run some trials and use your judgment in refining the weld settings until you get an acceptable part. Once you have achieved an acceptable part that passes all of your test criteria, you should set up a DOE (Design of Experiments) to determine the optimum settings for amplitude, pressure and downspeed. This will lead to your ideal settings. From there you can begin work on selecting the optimum weld mode. To do this, you will need to weld a grouping of parts (quantity to be determined, but usually no less than 50) and the tools to collect weld data. The more cavity combinations incorporated in this analysis, the more accurate the findings. It is imperative that you weld and label the parts to correspond with the weld data. At a minimum, the weld data should include energy, peak power, collapse and absolute.\nThe next step is to inspect and test the parts. Look them over visually and then put them through whatever tests are applicable. There most likely will be a few of these parts that fall outside of acceptable ranges. Compare those parts with the weld data. There will no doubt be some variation in the data. It may be in energy or collapse or absolute, but there will be variation. Compare the data between the good and bad parts, and let the data indicate the mode with the most consistency. Change the weld mode and run the experiment again. Results will improve.\nOnce the weld mode has been optimized, you then can move to the next step, which is amplitude control. You already have determined the stack amplitude with the converter, booster and horn, but the amplitude also can be changed electronically during the weld. This is known as amplitude profiling. The principle behind this technique is to use a high level of amplitude in the early stages of the weld to bring the material to its molten or softened state. Once heated, it no longer requires that high level of amplitude. To increase control of the melt, decrease the amplitude setting at some point midway through the cycle. In many cases, a decrease from 100 percent to 70-50 percent will provide another level of weld consistency. Another DOE on the amplitude profile settings is recommended.\nIt seems like this process is quite extensive and may take a good deal of time to complete, but in reality it is time well spent in the early stages of product and process development. Time spent here will pay huge dividends when full scale production begins. Throughput will be higher and the time spent tweaking the process on the floor will be minimized.\nJeff Frantz is director of marketing and product development and has been employed at Branson Ultrasonics for 35 years. Frantz is the current president of the Welding of Plastics and Composites Division for the American Welding Society. He currently is on the Board of Directors for the Society of Plastic Engineers for the Decorating and Assembly Division. He has been a member of the SPE since 1993 and currently is a Senior Member. For more information, visit www.bransonultrasonics.com."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:757b0c44-17e6-4621-8e29-5faa00a026ed>"],"error":null}
{"question":"Could you explain why stomach acid reduction might actually worsen acid reflux symptoms instead of helping?","answer":"Reducing stomach acid can actually worsen acid reflux because high stomach acid is crucial for keeping the lower esophageal sphincter tightly closed. When stomach contents are not acidic enough, this sphincter loosens, allowing stomach contents to leak back up into the esophagus and cause discomfort. Therefore, excessive stomach acid is usually not the primary cause of reflux, making proton pump inhibitors (PPIs) sometimes unnecessary for treating this condition.","context":["Have you ever taken a short or long course of oral antibiotic therapy? Perhaps you had frequent, recurring ear infections during your childhood, or maybe you were placed on long-term antibiotic therapy for adolescent or even adult acne. Well, every single time we take oral antibiotic medications, we are not only killing off the pathogenic bacteria that we don't want, but we are also eliminating all of the beneficial bacteria that perform vital functions for our entire body as a whole.\nIn recent years, more and more research has been done in an attempt to identify all of the organs and systems that the microflora in our gut have a direct affect on. Current research has shown that overgrowth of dysfunctional or pathogenic bacteria (i.e. dysbiosis) can play a direct role in conditions ranging from inflammatory bowel disease and obesity, to diabetes and autoimmune diseases1,2,3,4.\nIn addition, did you know that oftentimes proton pump inhibitors (PPIs) are prescribed for patients with acid reflux when they are not even indicated? It may sound counterintuitive, but excessive stomach acid is usually not what is causing the reflux in the first place. One of the main feedback mechanisms for ensuring that the lower esophageal sphincter remains tightly closed is high stomach acid; therefore, when the contents of the stomach are not acidic enough, this sphincter loosens and the contents of the stomach leak back up into the esophagus and cause significant discomfort. Additionally, when PPIs are taken for a prolonged period of time, not only does it lead to nutrient deficiencies down the line, but it also makes your stomach more prone to infections. The low pH (or highly acidic environment) of the stomach is one of our biggest defenses against the bacteria and toxins that we ingest in the foods and drinks we consume. When the acidity of the stomach is compromised, so are our defense mechanisms against pathogens, which can lead to small intestinal bacterial overgrowth (SIBO); this is when you actually have bacteria growing higher up in your intestinal tract than you should! When you have an overgrowth of bacteria in your small intestines, the microvilli (or little finger extensions) cannot absorb nutrients as efficiently, which ends up exacerbating the problem.\nMany of the chronic conditions that we see, which can range from skin conditions to more serious endocrine and autoimmune diseases, are often linked to our gastrointestinal health. In order to ensure that we have an optimally functioning gut, we need to stop pathogenic bacteria from growing where it should not be, and ensure that we are feeding our colon with the good bacteria that is mutually beneficial for achieving our best state of health.\n1 Microbiome and mucosal inflammation as extra-articular triggers for rheumatoid arthritis and autoimmunity\n2 Gut Microbiota Dysbiosis in Obesity-Linked Metabolic Diseases and Prebiotic Potential of Polyphenol-Rich Extracts\n3 High-throughput clone library analysis of the mucosa-associated microbiota reveals dysbiosis and differences between inflamed and non-inflamed regions of the intestine in inflammatory bowel disease\n4 Gut Dysbiosis and Detection of “Live Gut Bacteria” in Blood of Japanese Patients With Type 2 Diabetes"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:e545b6a6-5cab-47d2-bf76-6f3af267950e>"],"error":null}
{"question":"I'm scared of exercising because of my back pain - is it actually safe to start moving more? Really anxious about making things worse! 😰","answer":"Moving more is actually a crucial part of managing back pain, even though it's common to feel hesitant. According to experts, gentle movement in pain-free ways is more beneficial than just stretching or relaxation. Maintaining muscle mass, flexibility, and mobility helps protect the musculoskeletal system. It's recommended to start with physician-guided exercise programs and progress gradually. Active participation in treatment typically leads to better outcomes than passive therapies.","context":["- Researchers compared aquatic exercise to physical therapy and found time in the pool was more effective for back pain.\n- The aquatic results continued even months after participants stopped doing the exercise.\n- These findings do not mean physical therapy is a waste of time—simply moving more often can have meaningful results.\nPeople with chronic back pain may want to invest in a new swimsuit. A recent clinical trial published in JAMA Network Open finds that aquatic exercise had a greater effect on pain, quality of life, sleep quality, and mental state than physical therapy (PT) after 3 months. Plus, the effect remained 1 year later.\nAbout the Study\nResearchers recruited 113 men and women with diagnosed chronic back pain, ranging in age from 18 to 65, and split them into two groups. Half did therapeutic aquatic exercise, and the other half did a form of physical therapy.\nAfter the initial study period of 90 days, those who did pool-based exercise showed greater alleviation of disability, even months later. They also reported lower pain levels, which had a ripple effect of improving sleep and mood.\nThese findings are in line with previous research that highlights the benefits of aquatic exercise. For example, a meta-analysis in the American Journal of Physical Medicine & Rehabilitation looked at eight studies on the effectiveness of this type of movement and found it significantly reduces pain and increases physical function.\nThe benefits of being in a pool include decreased load-bearing thanks to buoyancy provided by water—lessening the pull of gravity on the spine—and natural resistance that causes the muscles to work harder than they would normally. Aquatic exercise also eliminates fall risk, which can be a major consideration for those with limited mobility.\nImportance of Movement\nAlthough the recent study highlighted the advantages of aquatic therapy over several types of physical therapy interventions, that does not mean you should avoid PT in favor of pool time. One of the main reasons for the effectiveness of aquatic exercise was gentle movement.\nResearchers compared gentle movements to PT modalities focused on passive relaxation. Specifically, the PT group received electrical nerve stimulation or infrared ray thermal therapy for 30 minutes each session.\nBy contrast, those in the aquatic group followed a more rigorous protocol with session twice a week for 12 weeks. For instance, they did a 10-minute warmup to enhance neuromuscular activation and a 40-minute exercise at 60% to 80% of maximum heart rate. This was followed by a 10-minute cooldown.\nCarol Mack, DPT, CSCS\n— Carol Mack, DPT, CSCS\nEven if you do not live close to a pool or have a therapist offering aquatic exercise, you can still simulate the results by focusing on gentle movement, particularly if you put a tailored program together with a physical therapist or physician.\n“Even a small amount of movement is beneficial when it comes to back pain,” says Carol Mack, DPT, CSCS, doctor of physical therapy at CLE Sports PT & Performance in Cleveland. “Many people think back pain can be alleviated by stretching or relaxation, but often, moving in smarter and pain-free ways is more beneficial.”\nOvercoming Fear of Exercise\nWhen incorporating more movement into a treatment for chronic back pain, it is common for people to be hesitant about exercise, according to Amir Mahajer, DO, assistant professor of orthopedics at Mount Sinai in New York.\nThat is especially true if back pain may have been caused by playing sports. But it is an incredibly important part of pain management, he notes.\nAmir Mahajer, DO\n— Amir Mahajer, DO\n“Maintaining a healthy body mass index, larger muscle mass, flexibility, and mobility will lead to a protected musculoskeletal system,” Dr. Mahajer says. “The mainstay of treatment for many orthopedic conditions is a rehabilitation treatment plan with a physician-guided home exercise program at its core.”\nAnother crucial component for better back health is staying motivated, he adds. People with back pain often have a much better outcome if they are engaged in their treatment plan and willing to do the kind of progressive, gentle movement that gets them back on track.\n“There’s often not a single procedure or treatment plan that will ameliorate a patient’s back pain in the long run,” says Dr. Mahajer. “I always endorse active participation versus passive therapies.”\nWhat This Means For You\nResearchers found that gentle movement in an aquatic exercise program helped those with chronic back pain by boosting their quality of life, sleep, mood, pain level, and mobility. If you are experiencing chronic back pain, talk to a healthcare provider about incorporating an aquatic element into your treatment plan. They can help you determine if it is right for you.\nRead the full article here"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:31850050-7704-4139-914f-a0a3156c9884>"],"error":null}
{"question":"How do Section 42 and Section 36 of the Arbitration Act differ in terms of court jurisdiction requirements for arbitration proceedings vs award execution?","answer":"Section 42 mandates that once an application related to arbitration is made in a court, that court alone has exclusive jurisdiction over all subsequent applications arising from that agreement and proceedings, to avoid multiple proceedings and conflicting decisions. In contrast, Section 36, which deals with award execution, doesn't specify which court has jurisdiction. The Supreme Court clarified that arbitral awards can be executed in any court where assets are located, regardless of which court had jurisdiction over the arbitration proceedings.","context":["An arbitration award or arbitral award is a determination on the merits by an arbitration tribunal, which include interim awards. Domestic awards are governed by Part I whereas foreign awards are governed by part II of the Arbitration and Conciliation Act of India. The arbitrator’s final decision on the case is called the “award.” Once the arbitrator decides that all of the parties’ evidence and arguments have been presented, the arbitrator will close the hearings. This means no more evidence or arguments will be allowed. Although arbitral awards may be subject to being challenge but the grounds of challenge available against arbitral awards are limited. The award given by the arbitrator is equivalent to a decree of a court of law and the same can be executed directly, without making it a decree of the court. Now, the question arises are whether Jurisdiction lies where asset are located? Applicability of the Civil Procedure Code to matters before the Civil Courts under the Arbitration and Conciliation Act, 1996?\nApplicability of CPC:- Hon’ble Supreme Court of India, in the case of ITI Ltd. v. Siemens Public Communications Network Ltd (2002) 5 SCC 510 while dealing with Section 5 and Section 36 of the Act and also Section 115 CPC, has laid down the law that the applicability of CPC having not been expressly prohibited in the Act, the High Court’s power under Section 115 CPC, against an order made by the civil court, in an appeal preferred under Section 37 of the Act, is not barred.\nJurisdiction of Court and Challenge to Awards:- Seven Judges Bench of Supreme Court in the matter of S.B.P. & Co. Vs. Patel Engineering Ltd. & Ors. [(2005) 8 SCC 618], while examining relative scope of Ss.11(6) and 8 of the Act, per majority held that power exercised by the Chief Justice of High Court or CJI under Section 11(6) of the Act is not an administrative power but it is a judicial power by overruling its earlier decision in Konkan Railway Corporation Ltd. & Anr. v. Rani Construction Pvt. Ltd. [(2000) 2 SCC 388]\nQuestion is which District Court has the jurisdiction to decide the petition u/s 34 of Arbitration & Conciliation Act 1996 with regard to the challenge to Arbitral Award? It was held by Rajasthan High Court in Indian Potash Ltd vs Bohra Industries Ltd. And Ors (S.B. Civil Revision No. 55/2016) Rajasthan High Court Jodhpur once Delhi High Court has appointed sole arbitrator to resolve the dispute between parties by exercising its judicial power under Section 11(6) of the Act and though the same was concurred by Rajasthan High Court but it cannot ipso facto confer jurisdiction on the subordinate Courts of Rajasthan to exercise power under Section 34 of the Act. Participation of the respondent in arbitral proceedings conducted by the Tribunal at New Delhi without any demure is yet another significant circumstance to tone down the ambitious plea of respondent that learned Court below is clothed with territorial jurisdiction to entertain its application under Section 34 of the Act.\nJurisdiction and Execution of Awards:- Previously under Arbitration Act, 1940, which required an award made to be filed in Court and a decree to be passed thereon whereupon it would be executable. However same was amended in Arbitration & Conciliation Act 1996. But Delhi High Court, Kerala High Court, Madras High Court, Rajasthan High Court, Allahabad High Court, Punjab & Haryana High Court and Karnataka High Court were of the opinion: “An award is to be enforced in accordance with the provisions of the said Code in the same manner as if it were a decree of the Court as per Section 36 of the said Act does not imply that the award is a decree of a particular court and it is only a fiction. Thus, the award can be filed for execution before the court where the assets of the judgment debtor are located.”\nHowever, the Madhya Pradesh and Himachal Pradesh High Courts held:“The transfer of decree should first be obtained before filing the execution petition before the Court where the assets are located.”\nAfter discussing various provisions of the Act and the various orders of the High Courts at length, Apex court on conjoint reading of with Code of Civil Procedure with Arbitration Act 1996, it was held in Sundaram Finance Limited v. Abdul Samad, 2018 SCC OnLine SC 121 that enforcement of an award through its execution can be filed anywhere in the country where such decree can be executed and there is no requirement for obtaining a transfer of the decree from the Court, which would have jurisdiction over the arbitral proceedings.","November 9, 2023\nArbitration is a form of alternative dispute resolution (ADR) that allows parties to settle their disputes or claims without resorting to litigation. Arbitration is governed by the Arbitration and Conciliation Act, 1996 in India, which is based on the UNCITRAL Model Law on International Commercial Arbitration. One of the key aspects of arbitration is the arbitral award, which is the final and binding outcome of the arbitral process.\nThe Arbitration and Conciliation Act, of 1996 does not provide a clear definition of “award” in its provisions. However, it can be inferred from the context that an award is the final decision or determination of a dispute or claim that has been submitted for arbitration by the parties. The award can either be monetary or non-financial, such as a cessation of a particular act or an addition of employment. The award can also be interim or final, depending on whether it resolves some or all of the issues in dispute.\nThe jurisdictional issues related to the award are addressed in Section 42 of the Act, which states that “Not withstanding anything contained elsewhere in this Part or in any other law for the time being in force, where with respect to an arbitration agreement any application under this Part has been made in a Court, that Court alone shall have jurisdiction over the arbitral proceedings and all subsequent applications arising out of that agreement and the arbitral proceedings shall be made in that Court and in no other Court.”This means that once an application related to an arbitration agreement is made in a court,that court will have exclusive jurisdiction over all matters arising out of that agreement and the arbitration proceedings. This provision is intended to avoid a multiplicity of proceedings and conflicting decisions by different courts. However, this provision does not apply to execution applications when it comes to the enforcement of an award through its execution.\nThe execution of an award is the process of giving effect to the award by ensuring that the party who has won the award receives what they are entitled to. The execution of an award can be done either voluntarily by the losing party or compulsorily by the intervention of a court. The execution of an award is governed by Section 36 of the Act, which states that “Where the time for making an application to set aside the arbitral award under section 34 has expired, or such application having been made, it has been refused, the award shall been forced under the Code of Civil Procedure, 1908 (5 of 1908) in the same manner as if it were a decree of the Court. ”This means that an arbitral award can be executed as a decree of a court after the expiry of the time limit for challenging the award or after the dismissal of such challenge.\nHowever, unlike Section 42, Section 36 does not specify which court will have jurisdiction to execute the award. This issue was clarified by the Supreme Court in Sundaram Finance Ltd. v. Abdul Samad, where it held that an arbitral award can be filed for execution in any court whereas sets are located, irrespective of which court passed the award or decree. This decision was reiterated by the Allahabad High Court in Cheran Properties Ltd v. Kasturi and Sons Ltd, where it held that there is no need to obtain a transfer of decree from one court to another for executing an arbitral award. It is important to note that Section 32 of the Act states that arbitral proceedings stand terminated by the final arbitral award, and execution can only be sought after the final award is rendered. Therefore, an execution application can be filed by an award holder before any Indian court where the award is enforceable, without the need to obtain a transfer of decree from the court that passed the award or decree.\nThe Arbitration and Conciliation Act of 1996 provides a comprehensive framework for arbitration in India. It covers various aspects such as definition, jurisdiction, and execution of arbitral awards. The primary goal of the Act is to promote arbitration as a speedy and effective mode of dispute resolution. It also aims to ensure minimal judicial intervention and maximum party autonomy. Furthermore, the Act seeks to align Indian arbitration laws with international standards and best practices."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:bfb77d17-67f5-4f51-a86c-5186974153ae>","<urn:uuid:a6546db7-80b1-4933-bee9-560e385639db>"],"error":null}
{"question":"What's the relationship between plate boundaries and mountain formation in western North America, and how does this differ from previously held theories?","answer":"The relationship between plate boundaries and mountain formation in western North America involved the Farallon plate being subducted under the North American plate, with the plate gradually peeling away from the continent's underside. This process triggered a wave of mountain building that moved from British Columbia to Mexico over 22 million years. This finding contradicts the previous theory that suggested these mountains developed from a Tibet-like plateau that arose simultaneously across the western U.S. and then collapsed. At convergent plate boundaries, where two plates meet, such mountain formation occurs through several processes, including subduction, collision, and terrane accretion. The mountains reached elevations of about 4 kilometers (14,000 feet), much lower than the previously theorized Tibet-like plateau of 15,000 feet.","context":["Ancient raindrops reveal a wave of mountains sent south by sinking Farallon plateDecember 17th, 2010 in Earth / Earth Sciences\nHari Mix, a doctoral candidate in Environmental Earth System Science, analyzed samples taken from dozens of basins around the western United States.\n(PhysOrg.com) -- Analyzing the isotope ratios of ancient raindrops preserved in soils and lake sediments, Stanford researchers have shown that a wave of mountain building began in British Columbia, Canada about 49 million years ago and rolled south to Mexico. The finding helps put to rest the idea that there was once a Tibet-like plateau across the western US that collapsed and eroded into the mountains we see today.\n50 million years ago, mountains began popping up in southern British Columbia. Over the next 22 million years, a wave of mountain building swept (geologically speaking) down western North America as far south as Mexico and as far east as Nebraska, according to Stanford geochemists. Their findings help put to rest the idea that the mountains mostly developed from a vast, Tibet-like plateau that rose up across most of the western U.S. roughly simultaneously and then subsequently collapsed and eroded into what we see today.\nThe data providing the insight into the mountains so popularly renowned for durability came from one of the most ephemeral of sources: raindrops. Or more specifically, the isotopic residue fingerprints, effectively of ancient precipitation that rained down upon the American west between 65 and 28 million years ago.\nAtoms of the same element but with different numbers of neutrons in their nucleus are called isotopes. More neutrons make for a heavier atom and as a cloud rises, the water molecules that contain the heavier isotopes of hydrogen and oxygen tend to fall first. By measuring the ratio of heavy to light isotopes in the long-ago rainwater, researchers can infer the elevation of the land when the raindrops fell.\nThe water becomes incorporated into clays and carbonate minerals on the surface, or in volcanic glass, which are then preserved for the ages in the sediments.\nHari Mix, a PhD candidate in Environmental Earth System Science at Stanford, worked with the analyses of about 2,800 samples several hundred that he and his colleagues collected, the rest from published studies and used the isotopic ratios to calculate the composition of the ancient rain. Most of the samples were from carbonate deposits in ancient soils and lake sediments, taken from dozens of basins around the western U.S.\nUsing the elevation trends revealed in the data, Mix was able to decipher the history of the mountains. \"Where we got a huge jump in isotopic ratios, we interpret that as a big uplift,\" he said.\n\"We saw a major isotopic shift at around 49 million years ago, in southwest Montana,\" he said. \"And another one at 39 mya, in northern Nevada\" as the uplift moved southward. Previous work by Chamberlain's group had found evidence for these shifts in data from two basins, but Mix's work with the larger data set demonstrated that the pattern of uplift held across the entire western U.S.\nThe uplift is generally agreed to have begun when the Farallon plate, a tectonic plate that was being shoved under the North American plate, slowly began peeling away from the underside of the continent.\n\"The peeling plate looked sort of like a tongue curling down,\" said Page Chamberlain, a professor in environmental Earth system science who is Mix's advisor.\nAs hot material from the underlying mantle flowed into the gap between the peeling plates, the heat and buoyancy of the material caused the overlying land to rise in elevation. The peeling tongue continued to fall off, and hot mantle continued to flow in behind it, sending a slow-motion wave of mountain-building coursing southward.\n\"We knew that the Farallon plate fell away, but the geometry of how that happened and the topographic response to it is what has been debated,\" Mix said.\nMix and Chamberlain estimate that the topographic wave would have been at least one to two kilometers higher than the landscape it rolled across and would have produced mountains with elevations up to a little over 4 kilometers (about 14,000 feet), comparable to the elevations existing today.\nMix said their isotopic data corresponds well with other types of evidence that have been documented.\n\"There was a big north to south sweep of volcanism through the western U.S. at the exact same time,\" he said.\nThere was also a simultaneous extension of the Earth's crust, which results when the crust is heated from below, as it would have been by the flow of hot magma under the North American plate.\n\"The pattern of topographic uplift we found matches what has been documented by other people in terms of the volcanology and extension,\" Mix said.\n\"Those three things together, those patterns, all point to something going on with the Farallon plate as being responsible for the construction of the western mountain ranges, the Cordillera.\"\nChamberlain said that while there was certainly elevated ground, it was not like Tibet.\n\"It was not an average elevation of 15,000 feet. It was something much more subdued,\" he said.\n\"The main implication of this work is that it was not a plateau that collapsed, but rather something that happened in the mantle, that was causing this mountain growth,\" Chamberlain said.\nMore information: Mix will present results of the study at the American Geophysical Union annual meeting in San Francisco on Friday, Dec. 17.\nProvided by Stanford University\n\"Ancient raindrops reveal a wave of mountains sent south by sinking Farallon plate.\" December 17th, 2010. http://phys.org/news/2010-12-ancient-raindrops-reveal-mountains-south.html","plate tectonics | Definition, Theory, Facts, & Evidence | misjon.info\nPlate tectonics, theory dealing with the dynamics of Earth's outer . There are two types of crust, continental and oceanic, which differ in their .. Furthermore, the relationship between hotspots and plumes is hotly debated. The theory of plate tectonics accounts nicely for the slow and steady volcanic activity that occurs at .. Peridotite, a rock type commonly found deep in hot spot Note the relationship between temperature and mineral composition and stability. This was a major puzzle in relation to plate tectonics. A Canadian Adding to Wilson's theory, Jason Morgan furthered the idea of the hot spot. Morgan As the magma reaches the surface, it cools quickly and forms pillow lava. This pillow .\nWhat causes hot spot volcanism? It is imagined that these plumes rise as a plastically deforming mass that has a bulbous plume head fed by a long, narrow plume tail. As the head impinges on the base of the lithosphere, it spreads outward into a mushroom shape. This causes decompressional melting of the hot mantle material, i. It is thought that the massive flood basalt provinces on earth are produced when large mantle plumes reach the lithosphere.\nNote the bulbous plume heads, the narrow plume tails, and the flattened plume heads as they impinge on the outer sphere representing the base of the lithosphere. Illustration how the progressively older islands formed above the stationary mantle plume Courtesy of the USGS.\nMantle plumes appear to be largely unaffected by plate motions. While a plume that feeds hot spot volcanoes remains stationary relative to the mantle, the plate above it usually moves.\nThe result is that a chain of progressively older volcanoes are created on the overlying plate. During the late 20th and early 21st centuries, scientific understanding of the deep mantle was greatly enhanced by high-resolution seismological studies combined with numerical modeling and laboratory experiments that mimicked conditions near the core-mantle boundary.\nAt a depth of about 5, km 3, milesthe outer core transitions to the inner core. The polarity of the iron crystals of the OIC is oriented in a north-south direction, whereas that of the IIC is oriented east-west.\nWhat is a Hot Spot? | Volcano World | Oregon State University\nEarth's coreThe internal layers of Earth's core, including its two inner cores. Plate boundaries Lithospheric plates are much thicker than oceanic or continental crust. Their boundaries do not usually coincide with those between oceans and continentsand their behaviour is only partly influenced by whether they carry oceans, continents, or both. The Pacific Plate, for example, is entirely oceanic, whereas the North American Plate is capped by continental crust in the west the North American continent and by oceanic crust in the east and extends under the Atlantic Ocean as far as the Mid-Atlantic Ridge.\nA general discussion of plate tectonics. In a simplified example of plate motion shown in the figure, movement of plate A to the left relative to plates B and C results in several types of simultaneous interactions along the plate boundaries.\nAt the rear, plates A and B move apart, or diverge, resulting in extension and the formation of a divergent margin. At the front, plates A and B overlap, or converge, resulting in compression and the formation of a convergent margin.\nAlong the sides, the plates slide past one another, a process called shear. As these zones of shear link other plate boundaries to one another, they are called transform faults. Theoretical diagram showing the effects of an advancing tectonic plate on other adjacent, but stationary, tectonic plates.\nAt the advancing edge of plate A, the overlap with plate B creates a convergent boundary. In contrast, the gap left behind the trailing edge of plate A forms a divergent boundary with plate B.\nAs plate A slides past portions of both plate B and plate C, transform boundaries develop. Divergent margins As plates move apart at a divergent plate boundarythe release of pressure produces partial melting of the underlying mantle. This molten material, known as magmais basaltic in composition and is buoyant. As a result, it wells up from below and cools close to the surface to generate new crust.\nBecause new crust is formed, divergent margins are also called constructive margins. Continental rifting Upwelling of magma causes the overlying lithosphere to uplift and stretch. Whether magmatism [the formation of igneous rock from magma] initiates the rifting or whether rifting decompresses the mantle and initiates magmatism is a matter of significant debate. If the diverging plates are capped by continental crust, fractures develop that are invaded by the ascending magma, prying the continents farther apart.\nSettling of the continental blocks creates a rift valleysuch as the present-day East African Rift Valley. As the rift continues to widen, the continental crust becomes progressively thinner until separation of the plates is achieved and a new ocean is created. The ascending partial melt cools and crystallizes to form new crust. Because the partial melt is basaltic in composition, the new crust is oceanic, and an ocean ridge develops along the site of the former continental rift. Consequently, diverging plate boundaries, even if they originate within continents, eventually come to lie in ocean basins of their own making.\nThe Thingvellir fracture lies in the Mid-Atlantic Ridge, which extends through the centre of Iceland. Samples collected from the ocean floor show that the age of oceanic crust increases with distance from the spreading centre —important evidence in favour of this process.\nThese age data also allow the rate of seafloor spreading to be determined, and they show that rates vary from about 0. Seafloor-spreading rates are much more rapid in the Pacific Ocean than in the Atlantic and Indian oceans.\nAt spreading rates of about 15 cm 6 inches per year, the entire crust beneath the Pacific Ocean about 15, km [9, miles] wide could be produced in million years. Divergence and creation of oceanic crust are accompanied by much volcanic activity and by many shallow earthquakes as the crust repeatedly rifts, heals, and rifts again. Brittle earthquake -prone rocks occur only in the shallow crust.\nDeep earthquakes, in contrast, occur less frequently, due to the high heat flow in the mantle rock. These regions of oceanic crust are swollen with heat and so are elevated by 2 to 3 km 1. The elevated topography results in a feedback scenario in which the resulting gravitational force pushes the crust apart, allowing new magma to well up from below, which in turn sustains the elevated topography.\nIts summits are typically 1 to 5 km 0. This is accomplished at convergent plate boundaries, also known as destructive plate boundaries, where one plate descends at an angle—that is, is subducted—beneath the other. Because oceanic crust cools as it ages, it eventually becomes denser than the underlying asthenosphere, and so it has a tendency to subduct, or dive under, adjacent continental plates or younger sections of oceanic crust.The Earth's crust: tectonic plate movement, volcanoes, tsunami, earthquakes\nThe life span of the oceanic crust is prolonged by its rigidity, but eventually this resistance is overcome. Experiments show that the subducted oceanic lithosphere is denser than the surrounding mantle to a depth of at least km about miles.\nThe mechanisms responsible for initiating subduction zones are controversial. During the late 20th and early 21st centuries, evidence emerged supporting the notion that subduction zones preferentially initiate along preexisting fractures such as transform faults in the oceanic crust.\nIrrespective of the exact mechanism, the geologic record indicates that the resistance to subduction is overcome eventually. Where two oceanic plates meet, the older, denser plate is preferentially subducted beneath the younger, warmer one. Where one of the plate margins is oceanic and the other is continental, the greater buoyancy of continental crust prevents it from sinking, and the oceanic plate is preferentially subducted. Continents are preferentially preserved in this manner relative to oceanic crust, which is continuously recycled into the mantle.\nThis explains why ocean floor rocks are generally less than million years old whereas the oldest continental rocks are more than 4 billion years old.\nBefore the middle of the 20th century, most geoscientists maintained that continental crust was too buoyant to be subducted. However, it later became clear that slivers of continental crust adjacent to the deep-sea trenchas well as sediments deposited in the trench, may be dragged down the subduction zone. The recycling of this material is detected in the chemistry of volcanoes that erupt above the subduction zone. Two plates carrying continental crust collide when the oceanic lithosphere between them has been eliminated.\nEventually, subduction ceases and towering mountain ranges, such as the Himalayasare created. See below Mountains by continental collision. Because the plates form an integrated system, it is not necessary that new crust formed at any given divergent boundary be completely compensated at the nearest subduction zone, as long as the total amount of crust generated equals that destroyed.\nSubduction zones The subduction process involves the descent into the mantle of a slab of cold hydrated oceanic lithosphere about km 60 miles thick that carries a relatively thin cap of oceanic sediments.\nThe factors that govern the dip of the subduction zone are not fully understood, but they probably include the age and thickness of the subducting oceanic lithosphere and the rate of plate convergence. Most, but not all, earthquakes in this planar dipping zone result from compressionand the seismic activity extends to km to miles below the surface, implying that the subducted crust retains some rigidity to this depth.\nAt greater depths the subducted plate is partially recycled into the mantle. The site of subduction is marked by a deep trench, between 5 and 11 km 3 and 7 miles deep, that is produced by frictional drag between the plates as the descending plate bends before it subducts. The overriding plate scrapes sediments and elevated portions of ocean floor off the upper crust of the lower plate, creating a zone of highly deformed rocks within the trench that becomes attached, or accreted, to the overriding plate.\nThis chaotic mixture is known as an accretionary wedge. The rocks in the subduction zone experience high pressures but relatively low temperatures, an effect of the descent of the cold oceanic slab.\nUnder these conditions the rocks recrystallize, or metamorphose, to form a suite of rocks known as blueschists, named for the diagnostic blue mineral called glaucophanewhich is stable only at the high pressures and low temperatures found in subduction zones. See also metamorphic rock. At deeper levels in the subduction zone that is, greater than 30—35 km [about 19—22 miles]eclogiteswhich consist of high-pressure minerals such as red garnet pyrope and omphacite pyroxeneform.\nThe formation of eclogite from blueschist is accompanied by a significant increase in density and has been recognized as an important additional factor that facilitates the subduction process. Island arcs When the downward-moving slab reaches a depth of about km 60 milesit gets sufficiently warm to drive off its most volatile components, thereby stimulating partial melting of mantle in the plate above the subduction zone known as the mantle wedge.\nMelting in the mantle wedge produces magmawhich is predominantly basaltic in composition. This magma rises to the surface and gives birth to a line of volcanoes in the overriding plate, known as a volcanic arctypically a few hundred kilometres behind the oceanic trench.\nThe distance between the trench and the arc, known as the arc-trench gap, depends on the angle of subduction. Steeper subduction zones have relatively narrow arc-trench gaps. A basin may form within this region, known as a fore-arc basin, and may be filled with sediments derived from the volcanic arc or with remains of oceanic crust.\nIf both plates are oceanic, as in the western Pacific Ocean, the volcanoes form a curved line of islandsknown as an island arcthat is parallel to the trench, as in the case of the Mariana Islands and the adjacent Mariana Trench. If one plate is continental, the volcanoes form inland, as they do in the Andes of western South America. Though the process of magma generation is similar, the ascending magma may change its composition as it rises through the thick lid of continental crust, or it may provide sufficient heat to melt the crust.\nIn either case, the composition of the volcanic mountains formed tends to be more silicon -rich and iron - and magnesium -poor relative to the volcanic rocks produced by ocean-ocean convergence. Back-arc basins Where both converging plates are oceanic, the margin of the older oceanic crust will be subducted because older oceanic crust is colder and therefore more dense.\nThis results in a process known as back-arc spreading, in which a basin opens up behind the island arc. The crust behind the arc becomes progressively thinner, and the decompression of the underlying mantle causes the crust to melt, initiating seafloor-spreading processessuch as melting and the production of basalt; these processes are similar to those that occur at ocean ridges. The geochemistry of the basalts produced at back-arc basins superficially resembles that of basalts produced at ocean ridgesbut subtle trace element analyses can detect the influence of a nearby subducted slab.\nThis style of subduction predominates in the western Pacific Oceanin which a number of back-arc basins separate several island arcs from Asia. However, if the rate of convergence increases or if anomalously thick oceanic crust possibly caused by rising mantle plume activity is conveyed into the subduction zone, the slab may flatten.\nSuch flattening causes the back-arc basin to close, resulting in deformationmetamorphismand even melting of the strata deposited in the basin. Mountain building If the rate of subduction in an ocean basin exceeds the rate at which the crust is formed at oceanic ridges, a convergent margin forms as the ocean initially contracts.\nThis process can lead to collision between the approaching continentswhich eventually terminates subduction.\nMountain building can occur in a number of ways at a convergent margin: Many mountain belts were developed by a combination of these processes. For example, the Cordilleran mountain belt of North America —which includes the Rocky Mountains as well as the Cascadesthe Sierra Nevadaand other mountain ranges near the Pacific coast—developed by a combination of subduction and terrane accretion.\nAs continental collisions are usually preceded by a long history of subduction and terrane accretion, many mountain belts record all three processes. Over the past 70 million years the subduction of the Neo-Tethys Seaa wedge-shaped body of water that was located between Gondwana and Laurasialed to the accretion of terranes along the margins of Laurasia, followed by continental collisions beginning about 30 million years ago between Africa and Europe and between India and Asia.\nThese collisions culminated in the formation of the Alps and the Himalayas. Jurassic paleogeographyDistribution of landmasses, mountainous regions, shallow seas, and deep ocean basins during the late Jurassic Period. Included in the paleogeographic reconstruction are the locations of the interval's subduction zones. Subduction results in voluminous magmatism in the mantle and crust overlying the subduction zoneand, therefore, the rocks in this region are warm and weak. Although subduction is a long-term process, the uplift that results in mountains tends to occur in discrete episodes and may reflect intervals of stronger plate convergence that squeezes the thermally weakened crust upward.\nFor example, rapid uplift of the Andes approximately 25 million years ago is evidenced by a reversal in the flow of the Amazon River from its ancestral path toward the Pacific Ocean to its modern path, which empties into the Atlantic Ocean.\nIn addition, models have indicated that the episodic opening and closing of back-arc basins have been the major factors in mountain-building processes, which have influenced the plate-tectonic evolution of the western Pacific for at least the past million years.\nMountains by terrane accretion As the ocean contracts by subduction, elevated regions within the ocean basin—terranes—are transported toward the subduction zone, where they are scraped off the descending plate and added—accreted—to the continental margin.\nSince the late Devonian and early Carboniferous periods, some million years ago, subduction beneath the western margin of North America has resulted in several collisions with terranes. The piecemeal addition of these accreted terranes has added an average of km miles in width along the western margin of the North American continentand the collisions have resulted in important pulses of mountain building.\nThe more gradual transition to the abyssal plain is a sediment-filled region called the continental rise. The continental shelf, slope, and rise are collectively called the continental margin. During these accretionary events, small sections of the oceanic crust may break away from the subducting slab as it descends. Instead of being subducted, these slices are thrust over the overriding plate and are said to be obducted.\nWhere this occurs, rare slices of ocean crust, known as ophiolitesare preserved on land.\nThey provide a valuable natural laboratory for studying the composition and character of the oceanic crust and the mechanisms of their emplacement and preservation on land.\nA classic example is the Coast Range ophiolite of Californiawhich is one of the most extensive ophiolite terranes in North America.\n- Intraplate (hot-spot) volcanism\n- Plate Tectonics and the Hawaiian Hot Spot\n- Hawaiian Islands and Hot Spots\nThese ophiolite deposits run from the Klamath Mountains in northern California southward to the Diablo Range in central California."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:e2fd785b-795b-435a-a9d7-3b1b4b2ee62a>","<urn:uuid:88e9d5fb-76f0-4055-a65d-0acc9315fe84>"],"error":null}
{"question":"What's the importance of community involvement in climate adaptation projects, and how does this relate to post-harvest agricultural challenges in Africa?","answer":"Community involvement in climate adaptation projects is crucial as it leads to long-lasting and successful achievement of development and adaptation goals. When community members are included in project design and co-management, projects become more sustainable. As for post-harvest agricultural challenges in Africa, smallholder farming households are well aware of the importance of good food storage and view it as a strength in adapting to climate change. However, getting climate-smart post-harvest practices into wider social and economic use faces significant challenges, including a lack of skilled post-harvest service providers and the private nature of grain storage practices which usually occur behind closed doors. The solution requires a well-functioning agricultural innovation system that emphasizes experiential co-learning to overcome institutional constraints.","context":["|A Field Guide to Community Based Adaptation|\nA Field Guide to Community Based Adaptation\nForeword by Howard White\nGo to bottom of this page to learn how to search electronically within the book.\n‘Tim Magee, and his colleagues at CSDi, are to be commended for producing a book which should change the way development is practiced, and so directly contribute to the improvement of millions of lives around the world.’ – Howard White, Executive Director, 3ie, USA\n‘A fascinating and informative guide to a subject of growing international importance. Tim Magee skillfully explains ways to combine external expertise and local perspectives on adaptation to climate change. This useful book should be read by development practitioners as well as students of climate change policy and international development.’ – Tim Forsyth, London School of Economics and Political Science, UK\n‘This is a most-awaited book for development practitioners who are increasingly confronted with the challenge of addressing climate risks in designing and implementing programmes and projects. This book will help them to do just that in a way that places the interest of communities at the heart of the process.’ – Kareff Rafisura, Climate Risk Management Practitioner, Ghana\n‘This book provides an insightful and comprehensive field guide to community-based adaptation. Magee brings together an impressive range of tools, resources and case examples in a clear and systematic step-by-step guide, while ensuring that the concerns of local people are kept at the centre of the analysis. This book is a timely and welcome addition to the literature, and will be useful to experienced practitioners as well as newcomers to CBA.’ Lars Otto Naess, Climate Change Team, Institute of Development Studies, UK\nThe world’s poor will be the most critically affected by a changing climate—and yet their current plight isn’t improving rapidly enough to fulfill the UN’s Millennium Development Goals. If experienced development organizations are finding it difficult to solve decades-old development problems, how will they additionally solve new challenges driven by climate change? A Field Guide to Community Based Adaptation illustrates how including community members in project design and co-management leads to long-lasting, successful achievement of development and adaptation goals.\nThis field guide provides a system of building block activities for staff on the ground to use in developing and implementing successful adaptation to climate change projects that can be co-managed and sustained by communities. Based on years of use in 129 different countries, the techniques illustrated in this field guide use a step-by-step progression to lead readers through problem assessment, project design, implementation, and community take over. The book equips development staff with all the tools and techniques they need to improve current project effectiveness, to introduce community based adaptation into organizational programming and to generate new projects. The techniques provided can be applied to broad range of challenges, from agriculture and soil and water challenges, to health concerns, flood defences and market development. The book is supported by a user-friendly website updated by the author, where readers can download online resources for each chapter which they can tailor to their own specific projects.\nThis practical guide is accessible to all levels of development staff and practitioners, as well as to students of development and environmental studies.\nHow to preview the electronic edition of the book—and actually search inside it.\n- read the full Table of Contents to get a sense of what the book contains.\n- read the Introduction (minus page 1) to the book which gives background information and chapter summaries.\n- read the section on Resources used in the book.\n- read the Bibliography.\n- read the full Index of topics covered.","Global warming is bringing complex and diverse climate change and impacts in sub-Saharan Africa (SSA; see Box). The economies of, and livelihoods in, many SSA countries are based on smallholder rain-fed agriculture. Whilst agricultural production in many higher-latitude countries is initially likely to benefit from moderate global warming, in tropical regions where crops are already close to critical environmental thresholds, crop yields and areas suitable for growing them will decline. Studies suggest that by 2080, countries such as Tanzania and Zimbabwe could lose up to 30 per cent of their 1990 cereal yields (Parry et al., 2004). Declining yields are likely to trigger further agricultural expansion, deforestation, green house gas (GHG) emissions and subsequently global warming.\nAnticipated climatic changes in sub-Saharan Africa (SSA)\nProjections suggest that by the year 2030, temperatures across SSA will have risen by about 1 °C compared to those of 1980–1999 (Lobell et al., 2008). Additionally, southern Africa is likely to experience a 10 per cent rainfall decrease and more frequent drought, while East Africa is expected to see rainfall increases in the north and decreases in the south. Increasing occurrences of high rainfall events and flooding are also anticipated (Christensen et al., 2007).\nHowever, climatic change is just one stressor among many complex, interacting and dynamic factors that influence smallholder farming households in SSA. Other factors include: population growth, urbanisation, education, health, especially HIV and Aids, financial service provision and market changes. Vulnerability to climate change and adaptive capacity is determined by a similarly wide combination of interacting socio-ecological factors.\nPost-harvest systems are diverse, reflecting the varied nature of the people, place, focal crop or product and the different activity stages involved. Post-harvest systems are influenced by the activities and interactions of many different players. An agricultural innovation systems perspective provides an analytical framework with which to examine technological and institutional change in post-harvest systems; identifying the players and factors affecting demand for, and use of, existing and new post-harvest and climate change knowledge.\nFood security and post-harvest agriculture\nMost cereals consumed in SSA are produced by smallholders, with commercial imports accounting for roughly 25 per cent of the cereal consumption in the region and food aid for about 5 per cent. However, post-harvest losses of cereal grains in SSA are estimated to reach nearly four billion US dollars annually, which in cash terms, equates to wasting 15 per cent of SSA’s annual cereal production (World Bank et al., 2011). As yields are expected to decline and the value of harvested and traded commodities subsequently increases, the cost of not reducing these post-harvest losses also increases. Furthermore, in this scenario, where extra food has to be produced to compensate for losses due to ineffective post-harvest management, this is a waste of valuable resources. With Africa’s population projected to double to two billion people by 2050, and living standards and populations elsewhere also increasing, estimates suggest that global food production will need to increase by 70 per cent. Under a scenario of continuing high population growth and regional disparities in income, an additional 550 million people globally could be at risk of climate-related hunger by 2080, with 65 per cent of this increase occurring in Africa (Parry et al., 2009). There are key post-harvest elements of food availability, stability, access and utilisation. For example, maintaining high quality and sufficient stocks of stored grain enables a household (or a nation) to provide itself with a nutritional and safe supply of food until the next harvest. Given that the market value of grain typically increases up until the next harvest, grain stocks also provide a market-linked asset, part of which can be sold if needed to cover income shocks or emergencies.\nPost-harvest impacts of climate change\nFive key climate change trends affecting different parts of SSA were identified:\nThese climate change trends are unlikely to occur in isolation from each other or other drivers of change.\nThe potential impacts of each of these climate change trends on the different post-harvest activities, assets (human, natural, physical, social and financial) and human well-being outcomes (food security, social, financial and economic) were identified. An example of this analysis for the potential impacts of a general increase in temperature on the drying, pest management and storage activity stages, and selected assets and well-being outcomes is given in the Table.\nPost-harvest agricultural adaptation to climate change\nDespite the significant uncertainty regarding the scale, type and interactions of climate change impacts, mitigation and adaptation activities are needed if we are to avoid the most serious consequences of global warming. After establishing the potential impacts, we identified a range of climate-smart post-harvest agricultural adaptation opportunities (see Box).\nClimate-smart post-harvest agricultural adaptation opportunities\n• Growing and/or storing crops and varieties which are less susceptible to post-harvest pest attack;\n• Prompt harvesting;\n• Adequate and protected drying;\n• Maintenance of the physical storage structures;\n• Careful store cleaning and hygiene;\n• Accurate estimation of food stock requirements;\n• Protection and monitoring of grain to be stored for more than three months;\n• Use of low GHG emission food preparation methods;\n• Understanding and application of basic food safety principles;\n• Increasing farmer access to market information and transport options;\n• Use of early warning seasonal forecasts to project how the climatic conditions might impact on food storage or marketing strategies;\n• Use of more water, energy and resource efficient processing, packaging and transport operations;\n• Ensuring plant breeders evaluate post-harvest as well as pre-harvest crop characteristics; and\n• Helping farmers to learn from others’ and their own experiments.\nSmallholder farming households across SSA are well aware of the importance of good food storage, and perceive their ability to store food as a strength influencing their capacity to adapt to climate change and variability. While the review highlighted just how many climate-smart post-harvest adaptation opportunities are already known and even practised by some farmers, it also illuminated the scale and problems faced in getting these ‘no-regrets’ post-harvest practices into wider social and economic use.\nFactors influencing the adaptive capacity of post-harvest systems\nThe successful application of post-harvest technical solutions is dependent on a well-functioning agricultural innovation system, which through experiential co-learning practice can overcome institutional constraints which are preventing the scaling out and up of post-harvest products and processes. However, across SSA, there is a desperate lack of skilled post-harvest service providers at all levels. As well as the post-harvest skills, understanding is needed of the futility of ‘one-size-fits-all’ solutions and the importance of responsive client-focused services which support experiential learning processes to build the adaptive capacity of smallholder farmers to deal with increasingly uncertain futures. Post-harvest aspects are under-represented in most agricultural curricula. Peer learning is stifled by the very private nature of activities such as grain storage practices which usually occur behind closed doors. Additional knowledge gaps exist as regards understanding post-harvest gender roles. The lack of investment in post-harvest compared to pre-harvest agricultural development, research and policy activities only accentuates the problems of getting post-harvest knowledge into use. Perhaps climate change impacts and shocks will gradually draw attention to the crucial role that post-harvest agricultural adaptation can play in strengthening livelihoods, attracting support and developing skills for getting the many ‘no-regrets’ climate-smart post-harvest adaptation opportunities into use at scale.\nTanya Stathers, Richard Lamboll\nNatural Resources Institute (NRI) University of Greenwich, United Kingdom\nBrighton M. Mvumi\nUniversity of Zimbabwe\nReferences /Sources for further reading\nChristensen et al. 2007. Regional climate projections. Climate Change 2007: The Physical Science Basis. WGI 4AR IPCC.\nLobell et al. 2008. Prioritizing climate change adaptation needs for food security in 2030. Science, 319, 607-610.\nParry et al. 2004. Effects of climate change on global food production under SRES emissions and socio-economic scenarios. Global Environmental Change, 14, 53-67.\nParry et al. 2009. Climate change and hunger: responding to the challenge. WFP.\nWorld Bank et al. 2011. Missing Food: the case of postharvest grain losses in sub-Saharan Africa."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:f35bb71f-3aa8-4fba-b06e-6808df69d863>","<urn:uuid:85fb10be-8a71-4532-bd58-00c1d05772e3>"],"error":null}
{"question":"How do you properly tune insulated ground radials for an antenna system?","answer":"To tune insulated ground radials, follow these steps: 1) Configure a pair of radials as a dipole, 2) Elevate them about 3 feet to bring the impedance up to a measurable level, 3) Use an RF-1 or noise bridge to adjust the length to resonance in the middle of the band, 4) Cut all other radials to that same length. When putting them back on the ground, the resonant frequency will drop a few percent lower, which is typically desirable. However, it's worth noting that tuning isn't strictly necessary - many ham ground radial systems are untuned and still work, though some work better than others.","context":["I am seeing posts indicating that some are equating a 1:1 SWR with resonance\nand attempting to adjust the antenna/radial/ground tuning on the basis of\nSWR... The two items are separate issues...\n1... Resonance (1st harmonic) is the point of lowest Z at the antenna\nterminals when measured by your RF-1... This can be validated by using a noise\nbridge as a cross check... It is rare (or blind luck) for Z to turn out to be\n2... SWR at resonance may or may not be 1:1... If the feed point approximates\n50 ohms you will see something approximating 1:1 on a nominal 50 ohm bridge...\nIf the feed point is in the vicinity of either 25 ohms or 100 ohms, then you\nwill see an SWR approximating 2:1... and so on...\n3... At frequencies away from resonance you will have reactance, expressed as\n+/- J , which affects the SWR bridge reading... There are combinations of J\nand Z which can make the SWR bridge look pretty good, while the antenna\nitself is hoplessly mistuned... Which is why you always have to go back to\nbasics, get the antenna resonant, and THEN deal with matching the feed line to\nthe load to get a SWR reading that keeps your 3CX3000A7 Godzilla Stomper\nDoes the antenna HAVE to be resonant?\nOf course not... There are many nonresonant antennas in use, a shunt fed tower\nbeing a common example... But a mismatched antenna/feedline will have lots of\ncirculating current in the feedline, and a highly reactive feed point in the\nshack can make life miserable... High circulating currents can cause\nsignificant power loss in the feedline, although ladderline works pretty well\nin such situations....And you have to match the feedline to the transmitter in\nthe end, anyway... So why not do the matching at the antenna, and if you can\nmake the antenna resonant in the process so much the better for useable\nOn the question of tuning insulated ground radials, either 1/4 wave, or loaded\nOf course you can tune them... They will be physically shorter than if they\nwere elevated... For those who say that laying on the ground totally detunes\nthem, I have a proposal... Touch the far end of one of the radial wires to\nyour tongue and have a friend (fiend?:) key up the rig - about ten watts\nshould do it nicely... (Also, scoffers may review the literature on\nunderground/submerged antennas as a less painful method of enlightenment :\n)... Ground proximity drastically lowers the impedence to the point that\nstandard bridges are unuseable for setting the resonance point... I suggest\nthat you configure a pair of the radials as a dipole - elevate them about 3\nfeet (which will bring the impedence up to where you can measure) and use your\nRF-1 or noise bridge to adjust the length to resonance in the middle of the\nband, then cut all the radials to that length... Putting them back on the\nground will pull the resonant frequency down another few percent, just about\nwhere you want it...\nDo you have to tune them?\nNope... I will bet that most ham ground radial systems are untuned... and most\nof them work, though some work better than others...\nFAQ on WWW: http://www.contesting.com/towertalkfaq.html\nAdministrative requests: towertalk-REQUEST@contesting.com"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:af4e597c-b431-4cb5-bc39-91bae60c24c5>"],"error":null}
{"question":"How do the storytelling techniques in The Nutcracker compare to those used in MacMillan's Romeo and Juliet, particularly in terms of how the love stories are conveyed to the audience?","answer":"The Nutcracker relies heavily on mime and gestures to tell its story, especially in Act I's party scene and Act II when Hans-Peter explains his story to the Sugar Plum Fairy. The mime must look natural and be combined with facial expressions to convey the narrative effectively. In contrast, MacMillan's Romeo and Juliet emphasizes choreographed pas de deux (dance duets) to tell the love story, with the ballet being specifically structured around these duets. The balcony scene pas de deux was particularly significant, taking only three rehearsals to choreograph, and was designed to show Juliet as the headstrong character making decisions while Romeo was 'swept off his feet by love.'","context":["16 December 2016 at 12.14pm | 12 Comments\nNarrative ballet seldom has a real ‘narrator’ – a person to tell us the plot out loud – but it has always managed to find ways to tell its stories. Sometimes the story is simply told through the dance, with ensemble numbers or solos propelling the action forwards. And sometimes the dancers behave more like actors: through the careful use of gestures, they communicate the essence of the story without needing to speak. The tradition of mime in ballet stretches back centuries, but it is alive and well in a number of Royal Ballet productions – including The Nutcracker and The Sleeping Beauty.\n‘There’s a lot of mime in The Nutcracker’, says Guest Principal Ballet Master Christopher Carr, who stages both ballets for the Company. ‘Especially in the first act’, he adds – perhaps surprisingly, as the best known mime sequence in the ballet is the extract above, which comes from Act II. But the party scene in Act I is filled with subtle gestures that have to be conveyed with just as much finesse as Hans-Peter’s narrative later on. ‘People arriving at the party, people saying goodbye – that they’ve had a good time at the party – and the cake-cutting, Drosselmeyer giving the Nutcracker to Clara…’. Carr reels off examples of mime in the party scene, stressing that all of this has to be understood clearly by the audience. ‘There’s a lot of language in that section, so we try to slow the music down a little bit. It’s hard for an audience – if it’s too quick, they’ll miss it.’\nMime should never be hard to understand, however. ‘Most of it is fairly obvious’, Carr says: ‘“I” is pointing to your chest, “you” is pointing to the other person, “here” is normally just pointing to the floor… It’s good if you have a little knowledge, but you don’t need to have that much.’\nIn Act II, Hans-Peter – freed from the spell that trapped him in the Nutcracker – explains his and Clara’s story to the Sugar Plum Fairy and her Prince through an unusually long mime sequence. As the rehearsal extract above shows, Carr takes care to get things right when teaching mime to the dancers. ‘We try to do mime that looks natural – not really staged in any way. And you have to use your face as well, as if it’s a conversation… It can be overdone, but we tend just to keep it natural and normal so the audience can tell what’s going on.’\n‘“Death” can be quite difficult to understand if you don’t know, which is two fists being crossed at the wrists’, Carr adds – an example of one particular ballet mime gesture that is useful to know about. The Nutcracker is free from that particular mime, but it does crop up in a number of ballets, including Giselle and also The Sleeping Beauty. In the fairytale classic, the gesture features in the mime sequence delivered by the evil fairy Carabosse as she explains the curse she has cast upon Princess Aurora. Carabosse is a great character role filled with mime, as Monica Mason explains when teaching the role:\nThere is one final element to mime in ballet, which is out of the dancers’ hands but an integral part of the action: the music. ‘The music and the dance should be totally united, all the time’, Carr says. ‘Music inspires choreography – it inspires stories, it inspires steps, and one tries to keep the dance and the music connected to each other: it’s what classical ballet is.’\nThe Nutcracker runs until 12 January 2017. Tickets are sold out, but returns may become available.\nThe production is given with generous philanthropic support from Hans and Julia Rausing, Lady Jarvis, Peter Lloyd and the Friends of Covent Garden.\nThe production is staged with generous philanthropic support from Mrs Aline Foriel-Destezet, Hans and Julia Rausing, Lindsay and Sarah Tomlinson and The Royal Opera House Endowment Fund. The production is sponsored by Van Cleef & Arpels. Original production (2006) made possible by The Linbury Trust, Sir Simon and Lady Robertson and Marina Hobson OBE.","Romeo and Juliet (MacMillan)\n|Romeo and Juliet|\nRoyal Opera House, London\n|Original ballet company||The Royal Ballet|\nKenneth MacMillan had previously choreographed the balcony scene for Lynn Seymour and Christopher Gable to dance in September 1964 for Canadian Television. This scene provided an essential part of the ballet's overall structure. Seymour stated that the balcony scene pas de deux only took three rehearsals to fully choreograph. This experience made him seem a good candidate to choreograph the entire ballet for Covent Garden, when the Soviet Union refused to allow Leonid Lavrovsky's classic production to tour to London. MacMillan prepared his version with the blessing of Frederick Ashton. MacMillan only had five months to choreograph the full ballet as The Royal Ballet hoped to perform Romeo and Juliet in its upcoming American tour. He, Seymour, and Gable planned the ballet around the characters and their pas de deuxs. They envisioned Juliet as the headstrong character, making decisions, while Romeo was \"swept off his feet by love\". Nicholas Georgiadis designed the set and costumes with specific intent regarding the characters and feel of the performance. The imposing, large set designs were utilized to emphasize how small and vulnerable Juliet was in comparison and position her and Romeo as helpless against the society they live in. MacMillan and Georgiadias were inspired by Italian Quattrocento paintings and architecture; Shakespeare, and Franco Zeffirelli's 1960 Romeo and Juliet production. MacMillan also took inspiration from Cranko's Romeo and Juliet to include the rowdy harlots in the market scenes.\nKenneth MacMillan's Royal Ballet production of Sergei Prokofiev's Romeo and Juliet premiered at the Royal Opera House, Covent Garden on 9 February 1965. Though MacMillan had conceived the ballet for Lynn Seymour and Christopher Gable, for \"bureaucratic reasons\" Margot Fonteyn and Rudolph Nureyev danced the opening night, to MacMillan's disappointment. The casting change was disheartening not only to MacMillan, but to the entire company, contributing to MacMillan and Seymour's eventual move away from the Royal Ballet and Gable's transition away from dancing entirely. Mainly, Fonteyn and Nureyev were given the leading roles because of their fame and box office draw. The impresario for the American tour, Sol Hurok said that the ballet would only be included and profitable in the US if Fonteyn and Nureyev were given the title roles. Fonteyn and Nureyev brought new life to the characters, as did the set and costume designs by Nicholas Georgiadis; Fonteyn, considered to be near retirement, embarked upon a rejuvenated career with a partnership with Nureyev. Lynn Seymour left the Royal Ballet for three years after this slight to dance with the German Opera Ballet in West Berlin, but she returned in 1970 to dance many principal roles.\nThe first production of Romeo and Juliet was met with overwhelmingly positive critical and box office response. Fonteyn and Nureyev received 43 curtain calls, eventually needing the safety curtain to descend in order to encourage the audience to leave the theater. Critics agreed across the board that the ballet was a fantastic addition to the Royal Ballet's repertoire as well as an accomplishment for MacMillan. The Observer, The Daily Mail, and the Sunday Telegraph were a few of the magazines and papers to review the performance. Andrew Porter with The Financial Times, who was the first critic to discuss the last minute casting change, noted that the ballet could not be fully understood until Seymour performed the role designed for her.\nLynn Seymour and Christopher Gable danced the lead roles in the second cast, also receiving rave reviews, though not the same level of overt audience appreciation. They were followed by three other pairings in the first tour and many more throughout the decades since.\nThe first five performances of Romeo and Juliet have remained highly lauded by critics. Alastair Macaulay spoke of Fonteyn and Nureyev's performance as \"If there was a single moment in my life that turned me into a ballet obsessive, that was it\". In the New York Times in 2007. He also lauded Seymour's rebellious Juliet.\nRomeo and Juliet has become a staple of the Royal Ballet's Repertoire. MacMillan went on to restage the ballet for other companies around the world such as The Royal Swedish Ballet, American Ballet Theatre, and the Birmingham Royal Ballet. The Birmingham Royal Ballet also included a new set and costume design by Paul Andrews.\nThe film was one of a series of movies financed between Rank and the NFFC. It received some strong reviews but was a box office disappointment. Since then it has been live streamed and recorded multiple times, the most recent of which being the 2012 filmed production of the ballet starring Lauren Cuthbertson and Federico Bonelli, filmed by Ross MacGibbon. A 90-minute abridgment by writer-producers (and dancers) Michael Nunn and William Trevitt for BBC television was broadcast in 2020 on PBS Great Performances.\n- Margot Fonteyn, Juliet\n- Rudolph Nureyev, Romeo\n- David Blair, Mercutio\n- Desmond Doyle, Tybalt\n- Anthony Dowell, Benvolio\n- Derek Rencher, Paris\n- Michael Somes, Lord Capulet\n- Julia Farron, Lady Capulet\n- Leslie Edwards, Escalus, Prince of Verona\n- Georgina Parkinson, Rosaline\n- Ronald Hynd, Friar Laurence\n- Franklin Whyte, Lord Montague\n- Betty Kavanagh, Lady Montague\n- Jann Parry, p274\n- \"Romeo and Juliet Balcony Pas de Deux\"\n- Jann Parry, p275\n- Jann Parry, p276\n- \"Romeo and Juliet\"\n- Jann Parry, p285\n- Macaulay, Alastair. \"Sex, violence, and Kenneth MacMillan\" in Reading dance: a gathering of memoirs, reportage, criticism, profiles: p. 422\n- Kavanaugh, 328\n- \"Romeo and Juliet\"\n- \"Lynn Seymour\"\n- \"Romeo and Juliet\"\n- Macaulay, 2007\n- \"Romeo and Juliet\"\n- Kavanaugh, 329\n- Petrie p 7-8\n- Petrie p 12\n- MacGibbon, 2012\n- \"Romeo and Juliet\". Kennethmacmillan.com. Retrieved 15 October 2014.\n- Gottlieb, Robert. Reading Dance: A Gathering of Memoirs, Reportage, Criticism, Profiles, Interviews, and Some Uncategorizable Extras. Pantheon, 2008.\n- Parry, Jann. Different Drummer: The Life of Kenneth MacMillan. London: Faber & Faber, 2009. ISBN 978-0-571-24302-0\n- Petrie, Duncan James (2016). \"Resisting Hollywood Dominance in Sixties British Cinema : The NFFC/Rank Joint Financing Initiative\" (PDF). Historical Journal of Film, Radio and Television.\n- Kavanagh, Julie. Nureyev: The Life. VINTAGE, 2008\n- MacGibbon, Ross, dir. Romeo and Juliet. 1965; London, UK: Royal Opera House, 2012. DVD\n- \"Romeo and Juliet Pas De Deux.\" Kenneth MacMillan. MacMillan Estate. Accessed 7 June 2020.\n- \"Romeo and Juliet.\" Kenneth MacMillan. MacMillan Estate. Accessed 7 June 2020.\n- Macaulay, Alastair. \"Confessions of a 'Romeo' Fiend\". The New York Times, The New York Times, 1 Apr. 2007\n- The Editors of Encyclopædia Britannica. \"Lynn Seymour\". Encyclopædia Britannica. Encyclopædia Britannica, inc., 4 March 2019"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:3da07dca-8adb-4b99-8140-73847ac3db80>","<urn:uuid:f7572c46-866e-43d6-a9b1-71d539daa1f9>"],"error":null}
{"question":"Could you explain how Monte Carlo simulations relate to quantum systems, and what challenges do biological modelers face with combinatorial complexity in their simulations?","answer":"Monte Carlo simulations are computations based on random samples that help make quantum many-body problems more predictable. However, they face a 'sign problem' - a cancellation of positives and negatives that creates barriers in quantum systems. Meanwhile, in biological modeling, combinatorial complexity poses significant challenges. Even a simple system with just a kinase binding to a substrate at two positions can produce 13 possible molecular species, and adding just one more component (like a phosphatase) adds 21 more species. This complexity grows exponentially - the EGFR signaling pathway would require over 10^30 equations to model completely, making it practically impossible to simulate without significant simplifications.","context":["Questions of whether our reality is a simulation of something deeper have kept philosophers and freshmen awake since Plato was a pup.\nA pair of physicists sleep a lot easier at night now that they've shown that quantum weirdness involving twists in space-time can't conceivably be simulated, adding to a list of problems that The Matrix would have no answer for. Sorry Neo.\nTheoretical physicists Zohar Ringel and Dmitry Kovrizhin from the University of Oxford and the Hebrew University in Israel found a solid road-block to solving algorithms involving quantum-based Monte Carlo simulations.\nThe short version is, it basically means we can't model the physics we know of on even the biggest computer imaginable.\nYou're not in a simulation. Probably not, at least.\nStill with us? Ok, come on down.\nMonte Carlo simulations are computations based on random samples of a system. They're not particular to quantum physics, but they are useful for turning the fuzzy world of maybes into something a bit more predictable.\nFor the most part they can help make short work of certain many-body problems – systems involving multiple quantum objects moving about through various dimensions.\nQuantum Monte Carlo simulations are by no means perfect, though. A certain cancelling out of positives and negatives can arise, something referred to as a sign problem.\nSign-free representation would help get around it, but the way to do this for a lot of physics problems remains unclear. In fact, for some it might be downright impossible.\nThat's the question Ringel and Kovrizhin were tackling; is there some sort of barrier to finding a sign-free way of applying Monte Carlo simulations to certain quantum systems?\nIf there isn't, then maybe – just maybe – you're lying bathed in gel in a pod somewhere with tubes in your head while a giant computer milks you for electricity in the world's most inefficient battery.\nBut should there be an obstacle, it means classical computers could never solve the underlying mathematics to represent what we're observing in quantum mechanics. Rest assured, that steak is 100 percent bovine muscle and not just binary code.\nIn condensed matter physics there's a phenomenon called the thermal Hall effect, where placing a solid object with a hot end and a cold end inside a magnetic field produces a thermal gradient across it as well.\nIf you're a high energy physicist, you might describe the same thing as a gravitational anomaly, which in simplistic terms is a bit like thinking of the fabric of space-time as biased or warped.\nThe theorists crunched the numbers on models involving Monte Carlo simulations solving gravitational anomalies, demonstrating no matter which way you cut it, that sign problem is there to stay.\n\"Our work provides an intriguing link between two seemingly unrelated topics: gravitational anomalies and computational complexity,\" says Ringel.\n\"It also shows that the thermal Hall conductance is a genuine quantum effect: one for which no local classical analogue exists.\"\nHollywood aside, questions on whether a Universe – either this one, or one constructed at our own hand – can be simulated through some sort of computer are taken seriously in some philosophical circles.\nBritish philosopher Nick Bostrom has argued it's likely, based on several premises on time and technological advances.\nPhysicists have pointed out that quantum physics makes this incredibly unlikely, given electrons and atoms aren't tiny balls whizzing predictably through space.\nRingel and Kovrizhin have given us just one more reason to suspect that if we're all operating on a supra-dimensional alien version of Windows 11, it's not a computer system we can easily imagine.\nLooks like we're stuck with this reality. Might as well start making the best of it.\nThis research was published in Science Advances.","An \"Uncertainty Principle\" for traditional mathematical approaches to biological modeling\nIf you're a biological modeler, chances are there are two words that keep you up at night and that on occasion, might even have given you serious pause to question the wisdom of your choice of profession. Those two words are combinatorial complexity.\nFor anyone not entirely familiar with this concept, imagine one of the simplest possible biomolecular systems, with a kinase K that can bind to and phosphorylate a substrate S at either of two positions a and b, as shown in this first diagram. Even this very simple system can produce 13 possible molecular species: K unbound, S unbound in one of its 4 phosphorylation states, K bound at a with S in one of its 4 states, K bound at b with S in one of its 4 states.\nTaking the traditional biological modeling approach of using ordinary differential equations (ODEs), you would therefore have to write 13 rate equations to describe this system. So far so good.\nBut now let's add the phosphatase P that dephosphorylates the sites a and b on S. If we do a similar analysis of the possible molecular species for our new system, taking into account now, the possible bound and unbound states of PandK on S, we discover that the addition of this single agent P yields 21 new molecular species in addition to the 13 that we already had! Furthermore, since we are working with a model of interdependent ODEs, we will also need to rewrite our original set of rate equations.\nIf it takes all this work to describe what is almost the simplest imaginable kind of system, how many equations would we need for a real biological system? How many rate equations would we need to describe the canonical epidermal growth factor receptor (EGFR) signaling pathway for example?\nHold on to your hats ... drum roll ... somewhere north of 1030 equations.\nAll this said however, biological modelers have built models of complex cellular systems like the EGFR pathway, so how on earth have they done it? The answer is by simplifying the system, typically by either ignoring features that are presumed to minimally impact the system's behavior, or by aggregating features to create a less granular description of the system, again under the presumption that this will not significantly affect the model's behavior.\nThe danger inherent in such approaches is that they require a set of a priori hypotheses about what are and what are not, the important features of the system i.e. they require a decision about what aspects of the model will least affect its behavior before the model has ever been run.\nThe famous Uncertainty Principle that we all learned in high school physics states that it is impossible to simultaneously determine with any accuracy, both the position and the momentum of an electron. A recasting of this principle for traditional biological modeling might be\n\"Scope or resolution, but not both at the same time\"\nOne could argue that whereas the original physical principle is absolute, in the case of biological modeling the limitation is one of technology - \"If we had a big enough, fast enough computer ...\" etc. Perhaps, but when you compare the storage and processing time required to solve a system of 10^30 equations with the scale of our universe, the biological modeling version of the principle seems pretty darn absolute to me.\nDid I hear someone say \"quantum computer\"?\nJust let me know when they've built one that could address this problem and I will gladly publish an update :-)\n© The Digital Biologist"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:1dc3ae1b-ee57-43fb-ba1d-3296ba732a37>","<urn:uuid:ce72db11-a441-482e-a056-61e666d3ea9a>"],"error":null}